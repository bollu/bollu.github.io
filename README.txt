<h2> A Universe of Sorts
<img style="float:left;display:inline-block;padding-right: 16px; width: 48px" src="/static/banner.png">
</h2>
<h3> Siddharth Bhat </h3>

- [Sign the Guestbook (Anonymously if you like!)](https://www.admonymous.co/bollu) / Email me:  <a href='mailto:bollu@pixel-druid.com'> `bollu@pixel-druid.com` </a>
- [Github](http://github.com/bollu) / [Math.se](https://math.stackexchange.com/users/261373/siddharth-bhat) /  [Resume](resume/main.pdf) / [Link hoard](todo.md) / [Sheet music](/articles/sheet-music.html)
- <a type="application/rss+xml" href="feed.rss"> RSS feed </a>
- **It's useful to finish things.**


# Software bugs are real bugs?

The coolest thing I learnt from the book was [STADS: software testing as species discovery](https://arxiv.org/pdf/1803.02130.pdf),
which models the problem of "how many bugs exist in the program?" as "how many bugs exist in this forest?". It turns
out that ecologists have good models for approximating the **total number of species in a habitat** from the
**number of known species in a habitat**. The paper then proceeds to argue that this analogy is sensible,
and then implements this within [AFL: american fuzzy lop](https://lcamtuf.coredump.cx/afl/). Definitely the
most fun idea in the book by far. 


#### Also, unexpected Deluze and Guattari:

> An assemblage is a group of individuals belonging to a number of different
> species that occur together in space and time.
For example, all birds that live on an island today form an assemblage; all plants currently on Earth form an assemblage; etc.

#### References

- https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/11-1952.1

# Gosper's algorithm

- Given a hypergeometric function $a(n)$, gosper's algorithm finds the function $S(k) = \sum_{i=0}^k a(k)$, iff $S$ is hypergeometric.
- 

##### References
- A = B
- Concrete Mathematics

# WZ (Wilf Zeilberger) pairs

- Pair of functions $F, G$ such that $F(n + 1, k) - F(n, k) = G(n, k + 1) - G(n, k)$, and $\lim_{K \to \infty} G(n, K) = 0$.
- If $F, G$ form a WZ pair, there is a rationl function $R$ such that $G(n, k) = R(n, k) F(n, k - 1)$. $R(n, k)$ is the certificate.

##### References
- Generatingfunctionlogy
- A = B
- Concrete Mathematics

# Sister Celine's Algorithm

- Given a hypergeometric function $F(n, k)$, we want to find a recurrence that $F(n, k)$
  satisfies.
- Crucially, we want a recurrence with coefficients in $n$, but *not* in $k$.
- So the recurrence eqn comes from the right $\mathbb Q[n, n^{-1}, S_n, S_k]$ 
  where $S_n(F) \equiv \lambda n, k. F(n + 1, k)$, and $S_k(F) \equiv \lambda n, k. F(n, k + 1)$ (shift operators).
- The algorithm is to guess a length of the recurrence, then write the equation e.g. $a[0][0]F(n, k) + a[0][1] F(n + 1, k) + a[1][0] F(n, k + 1) + a[1][1] F(n + 1, k + 1) = 0$.
- We set the recurrence to zero, which gives us a polynomial of the form $p_0(n, \vec a) k^0 + p_1(n, \vec a) k^1 + \dots p_D(n, \vec a) k^d = 0$.
- This gives a system of equations $p_i(n, \vec a) = 0$.
- We write this as $M(n) \cdot \vec a = 0$ with coefficients for $M(n)$ in the ring $\mathbb \mathbb Q[n, n^{-1}]$. 
- This system is solved (can be, since $\mathbb Q[n, n^{-1}]$ is a field!) giving us solutions for $\vec a$.

#### Example: rising factorial

- suppose $F(n, k) = (n + 0) (n + 1) \dots (n + k - 1)$.
- Let's guess a recurrence of the form $a[0][0] F(n, k) + a[0][1] F(n + 1, k) + a[1][0] F(n, k + 1) + a[1][1] F(n + 1, k + 1) = 0$.
- Rewrite to $a[0][0] + a[0][1] F(n + 1, k) / F(n, k) + a[1][0] F(n, k + 1) / F(n, k) + a[1][1] F(n + 1, k + 1) / F(n, k) = 0$.
- To evaluate $F(n + 1, k) / F(n, k)$, let's estimate with $n = 4, k = 3$.
  This gives $(4 \cdot 5 \cdot 6 \cdot 7) / (3 \cdot 4 \cdot 5 \cdot 6) = 7 / 3 = (n + k) / n$.
- To evaluate $F(n, k + 1) / F(n, k)$, let's estimate with $n = 4, k = 3$.
  This gives $(4 \cdot 5 \cdot 6 \cdot 7) / (4 \cdot 5 \cdot 6) = n + k$
- To evaluate $F(n + 1, k + 1) / F(n, k)$, let's estimate with $n = 4, k = 3$.
  This gives $(5 \cdot 6 \cdot 7 \cdot 8)/(4 \cdot 5 \cdot 6) = 7 \cdot 8 / 4 = (n + k) (n + k + 1) / n$
- See that this gives us a $k^2a[1][1]$ term, and no other term contributes a $k^2$, so $a[1][1] = 0$.
- So we only need to solve the recurrence with $a[0][0], a[0][1], a[1][0]$.


# I like New Formalism Poetry

- Took a heck of a lot of searching and sheer dumb luck to name the
  kind of poetry I was looking for. What helped was looking for threads on
  reddit complaining about the sorry state of contemporary poetry.

- A poet I'm going to be picking up is A. E. Stallings.
- [The society of classical poets](https://classicalpoets.org/about-us/)
- [Light: A journal of light verse](https://lightpoetrymagazine.com/)
- [Lighten Up Online: Clever Rhyming Verse](https://www.lightenup-online.co.uk/)
- [Asses of Parnassus: Short witty poetry](https://www.tumblr.com/assesofparnassus)
- [The HyperTexts: Large collection of poetry](http://www.thehypertexts.com/About_The_Hypertexts.htm)
- [Annie Finch: 60 places to publish formal poetry](https://anniefinch.com/places-publish-poetry/)

# Kinds of Fiction Genres I Like

- hard sci fi
- ergodic literature
- [Weird literature](https://www.reddit.com/r/WeirdLit/)
- Existential dread / CCRU / Nick land
- Borgesian
- Speculative Fiction (Imagination Machines)


#### Cool Poets (Contemporary)

-  A. E. Stallings.

#### Cool Poets (Older)

- William Blake (Tyger)
- Samuel Taylor Coleridge (Kublai, Khan)

#### History

- [Sparks of Calliope: Informative articles and poets in the tradition](https://sparksofcalliope.com/)
- [The fireside poets](https://en.wikipedia.org/wiki/Fireside_poets)

#### Journal Articles

##### EVERYBODY HATES KANT Blakean Formalism and the Symmetries of Laura Moriarty

> New Formalist poetry has seemed interested largely in returning to
> forms—sestina, villanelle, sonnet, and so on—that, according to
> New Formalist poets, have fallen into disuse through decades of freeverse practice.

##### What Is New Formalism (Marjorie Levinson)

> Jonathan Loes berg's A Return to the Aesthetic and Isobel Armstrong's The Radical Aesthetic

> About a quarter of the
> studies trace the discipline's neglect of form to new historicism's alleged denunciation of form
> as an ideological mystification.

> The above distinction between two
>  strains of new formalism translates into a
>  practical division between (a) those who want
>  to restore to today's reductive reinscription of
>  historical reading its original focus on form
>  (traced by these critics to sources founda
>  tional for materialist critique?e.g., Hegel,
>  Marx, Freud, Adorno, Althusser, Jameson)
>  and (b) those who campaign to bring back a
>  sharp demarcation between history and art,
>  discourse and literature, with form (regarded
>  as the condition of aesthetic experience as
>  traced to Kant?i.e., disinterested, autotelic,
>  playful, pleasurable, consensus-generating,
>  and therefore both individually liberating
>  and conducive to affective social cohesion)
>  the prerogative of art. In short, we have a new
>  formalism that makes a continuum with new
>  historicism and a backlash new formalism.

> I call the first kind of practice "activist formalism" (2),
> I call the second kind "normative formalism," not because
>  it achieves normative status but because it as
>  signs to the aesthetic norm-setting work that
>  is cognitive and affective and therefore also
>  cultural-political.

> The central work of the movement as a
> whole is rededication, a word I choose be
> cause new formalism seeks not only to rein
> state the problematic of form so as to recover
> values forgotten, rejected, or vulgarized as
> the direct or indirect consequence of new
> historicism's dominance but also to generate
> commitment to and community around the
> idea of form. The language of "commitment,"
> "conviction," "devotion," "dedication" is fre
> quent and often focal in these essays, and it
> points up the advocacy slant of the movement
> as well as its emphasis on affect, a recoil from
> what is cast as the arid rationalism ("scholastic" is the term one critic uses).


>  In closing, let me cite a very different kind
>  of essay, Elizabeth Harris Sagaser's "Flirting
>  with Eternity: Teaching Form and Meter in a
>  Renaissance Poetry Course." The excellence of
>  this essay is in its hands-on approach to the
>  problem of helping students address "basic
>  questions such as why?politically, philosophi
>  cally, psychologically?a culture would develop
>  form and meter so intensely" without lapsing
>  into an alienating technicalism (185). Because
>  hers is a rigorously interactive notion of form
>  ("form and meter only exist in practice?in
>  reciting verse, listening to it, reading it, writ
>  ing it, remembering it, teaching it" [186]),
>  she designs exercises (recitation, memoriza
>  tion, etc.) to counteract the reification effects
>  of contemporary print and academic culture.
>  Even as she stresses the acoustic, she quot


#### II Theory over Method, or In Defense of Polemic (Tom Eyers)

> What does form explain? Does form explain? 

#### Tactical Formalism: A Response to Caroline Levine


> For some time now, a knee-jerk contempt for
>  formal inquiry as such has, in its own turn, become as firmly established
>  within programs of advanced training as the dogma of formalism used
>  to be. 

Triumphant antiformalism has to answer, besides, for a more
 serious dereliction: the enervation of literary close reading in critical
 practice. A review of the habits of literary analysis that have prevailed
 during the last academic generation or so reveals widespread atrophy of
 a disused set of critica


 To let the tools of formal literary analysis rust unburnished is to risk
 discovering one day that our services are no longer wanted. While it is not
 too late to recoup that fine-motor coordination between eye and hand on
 which our guild's distinctive contributions are likely to depend, it is
 decidedly not too soon to enter rehab and start practicing



#### Narrative Networks: Bleak House and the Affor dances of Form (Carloine Levine)

> Faced with a doorknob, most of us know what to do. We turn it in one direc
 tion, and if that doesn't unlatch the door, we turn it in the other. We then use the
 same doorknob to pull the door toward us or push it away from us. We perceive
 what design theorists and cognitive psychologists call the doorknob's affordances.

# The Gradual Guarantees

- Says that static and dynamic type systems match up, and thus
  interpolating makes sense.
- The ur-example is `(\y y) ((\x x) 42))`.
- This program dynamically executes and produces `42`.

##### statically correct programm

- The correctly type annotated program `(\(y : Int) y) ((\(x : Int) x) 42)`
  will pass the type checker, and run to produce the same value `42`.

```py
# Inferred f : Int -> Any
def f(x : Int): return x

# Inferred g: Int -> Any
def g(y): return y

a = 42 # Inferred a : Int
b = f(a) # Inferred b : Any
b' = upcast b Int # Inferred b' : Int
c = g(b') # Inferred c : Any
```

##### statically incorrect programm

- Consider the program `(\y y) ((\(x : Bool) x) 42)`. This elaborates into:

```
# Inferred f : Bool -> Any
def f(x : Bool): return x

# Inferred g: Any -> Any
def g(y): return y

a = 42 # Inferred a : Int
b = f(a) # Type error, f : Bool -> Any mismatch argument a : Int
c = g(b) # See that this is type-correct, (b : Any), (g : Any -> Any)
```

##### dynamically incorrect programm

- Consider the program `(\(y : Bool) y) ((\x x) 42)`. This elaborates into:

```
# Inferred f : Any -> Any
def f(x): return x

# Inferred g: Bool -> Any
def g(y : Bool): return y

a = 42 # Inferred a : Int
b = f(a) # Inferred b : Any
b' = upcast b Bool # dynamic error at upcast, since at runtime, (b := 42)
c = g(b)
```

##### What have we learnt?

- If we add all the types, we get a type checker that passes which accepts correct programs (fully anootated).
- Some ways of adding type information will throw *static type errors*
- Some ways of adding types will give us a runtime error *from upcasts*.
- Since the upcasts are inserted "in between" calls to the statically typed functions, we never get an error *inside* 
  a statically typed function.
- In particular, we can state that the error arises from the *call* to the *dynamic* functions.

##### Gradual guarantees

- if a program is well typed, removing types keeps the program well typed.
- If a well typed program evaluates to a value, then removing types from this program also evaluates to the same value.
- adding type annotations can add either static errors, or dynamic errors *from untyped code*.
  Typed code that passes static type checking cannot create new errors dynamically.

##### References

- [Refined Criteria for Gradual Typing](https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.SNAPL.2015.274)
- [The ins and outs of gradual type inference](https://www.cs.umd.edu/~avik/papers/iogti.pdf)

# Lean Naming Convention for Contexts

- `LocalContext` *contains* `LocalDecl`s, and is *owned* by a `Metavar`.
- `MetavarContext` *contains* `Metavar`s, and is *owned* by a `MetaM`.
- `TacticM` *contains* the list of goal `[goal : MVarId]`.

# Right hand for arpeggios

- I've been trying to figure out how to get the right hand to be the "supporting role" when playing
  the melody with the left hand.
- A recent discovery: use 9ths! Play `9531` with the right hand as an arpeggio, sounds quite nice.
- So, for Cm, here are the following:
- Gm9: `A D Bb G`
- Fm9: `G C Ab F`
- Cm9: `D G Eb C`

# Simulating Inductives Via Coinductives (And Vice Versa)

- Given inductive types, it's fairly standard to simulate coinductives by writing them
  as an inverse limit of inductive types. For this, we need function spaces to write down the inverse limit sequence.

- What about the other way round? Given a language with $\Sigma$, $\Pi$, and coinductive, how do we simulate inductive?

##### Simulating List from Stream

- Step 1: define `Stream a where head :: a; tail :: Stream a`.
- Step 2: define church numerals: 

```hs
type Church = (a -> a) -> (a -> a)

zero :: Church
zero f = id

succ :: Church -> Church
succ n f = (n f) . f
```
- We need one more ingredient, which is `Option a`.

```
type Tuple a b where
  fst :: a
  snd :: b

-- Final encoding of option.
type Option a = {b : Type} -> Tuple b (a -> b) -> b

none :: Option a
none tup = tup.fst

some :: a -> Option a
none a tup = tup.snd a
```

- We will define lists via the final encoding, and show that this type contains inhabitants.

```
-- List, final encoding.
type List a = (b : Type) -> (hnil : b) -> (hcons : b -> a -> b)
```

- We will inhabit it as a coinductive stream of `Option`s, which are eventually `none`.

- First, a coinductive predicate that the stream has only nones.

```
coinductive OnlyNone (s : Stream (Option a)) : Prop where
  hdNone :: (hd s) = none
  tailNone :: OnlyNone (tail s)
```

- Next, a predicate that the stream is *eventually* only nones. For this, we say that there is a number $n$ such that applying $n$
  gives us a stream with `OnlyNone`.

```
type EventuallyNone (s : Stream (Option a)) : Prop := 
  ∃ (n : Church), OnlyNone ((n Stream.tail) s)
```

- Now, one can see that a `List a` is an `EventuallyNone (Stream a)`.
- See that one ca also define `Option a` as a `{ s : Stream a // OnlyNone s \/ OnlyNone (tail s) }`.
- In toto, this lets us simulate inductive types inside coinductive types, by building the large object,
  and then "cutting away" the subobject we want!
- See that we need function spaces to get ourselves an e.g. `Option`. In general, with just products,
  we can't get sums :)
- In some sense, we're using functions to build the "categorical" objects (inverse limits, sums)
  to get to the data type.


# Amelie Arpeggiation Explanation

- I notate notes in different octaves as `C1 C2` etc.
- I notate notes played at the same time in parentheses. So, `(C1 D1)` plays `C` and `D` simultaneously.

#### The bass arpeggio line

- (a) `(E1E2) B1 (G1E2) B1`
- (b) `(D1D2) B1 (G1G2) B1`
- (c) `(D1D2) B1 (F#1D2) B1`
- (d) `(D1D2) A1 (F#1D2) A1`

#### Interpretation

- If we grab the notes, we see that it's:
- (a) `E-G-B`: Major
- (b) `D-G-B`: 1st note changed (`E` to `D`). 1st inversion of major `G-B-D`. Ambiguous in tonality, 
- (c) `D-F#-B`: 2nd note chanted (`G` to `F#`). 2nd inversion of `B-D-F#` minor. Minor.
- (d) `D-F#-A`: 3rd note chanted (`B` to `A`). Major. Back to happy!

#### Key ideas

- Change one note at a time.
- Vary moods: major to ambiguous to minor/
- Use no inversion on chord[0], 1st inversion on chord[1], 2nd inversion on chord[2], and no inversion (3rd inversion) on chord[3]?
- Many thanks to [GodotMisogi](https://godot-bloggy.xyz/) for the help in figuring this stuff out,
  he's a much better musician than I ever will be!


# Inductive Predicate as Least Fixed Point, directly

```
inductive IsEven : Nat → Prop
| zero : IsEven 0
| succ : ∀ n, IsEven n → IsEven (n + 2)


def IsEvenProp (p : Nat → Prop) : Prop :=
  p 0 ∧ (∀ n, p n → p (n + 2))

theorem IsEvenPropOfIsEven : IsEvenProp IsEven := by
  unfold IsEvenProp
  constructor
  · exact IsEven.zero
  · intro n h
    exact IsEven.succ n h

/--
least fixed point of IsEvenProp.
See that this uses impredicativity.
It is quantifying over all (p : Nat → Prop).
In doing so, it is quantifying over *itself* (IsEven' : Nat → Prop).
-/
def IsEven' : Nat → Prop := fun n =>
  ∀ (p : Nat → Prop) (hp : IsEvenProp p), p n

theorem IsEven'_zero : IsEven' 0 := by
  intro p hp
  unfold IsEvenProp at hp
  obtain ⟨h0, _hsucc⟩ := hp
  exact h0

theorem IsEven'_ind (h : IsEven' n) : IsEven' (n + 2) := by
  intro p hp
  unfold IsEvenProp at hp
  obtain ⟨h0, hsucc⟩ := hp
  apply hsucc
  unfold IsEven' at h
  apply h
  unfold IsEvenProp
  simp only
  constructor <;> assumption


theorem IsEvenOfIsEven' : ∀ n, IsEven' n → IsEven n := by
  unfold IsEven'
  intros n
  intros h
  specialize h IsEven IsEvenPropOfIsEven
  exact h

theorem IsEven'OfIsEven : ∀ n, IsEven n → IsEven' n := by
  intro n
  intros h
  induction h
  case zero => exact IsEven'_zero
  case succ m heven heven' =>
    exact IsEven'_ind heven'

theorem IsEven_eq_IsEven' : ∀ n, IsEven n ↔ IsEven' n := by
  intro n
  apply Iff.intro
  · apply IsEven'OfIsEven
  · apply IsEvenOfIsEven'
```

# Interpolants: Vibes

- References: [Applications of craig interpolants and model checking](http://mcmil.net/pubs/TACAS05.pdf)
- We shall explain what an interpolant in two ways.

#### Implication based definition

- Let $A(p, q)$ and $B(q, r)$ be propositional formulae (where $p, q$ are vectors of variables) such that $A \implies B$.
- Then, there exists a formula $C(q)$ such that $A(p, q) \implies C(q)$ and $C(q) \implies B(q, r)$.
- So, the "crux" of why $A$ implies $B$ lies in $C$.
- One can ask: why is this useful? and how does one compute such an object? and why does sucn an object even exist?

#### Existence proof for interpolant

- Choose a particular $A(p, q)$ and $B(q, r)$ such that $A(p, q) \implies B(q, r)$, We are trying to build an interpolant $C(q)$.
- For example, suppose $a, b, c$ are variables, and the assignment $M(a, b, c)$ be $a \mapsto 1$, $b \mapsto 0$, and $c \mapsto 1$. ($M$ for model).
- Let $F(M(a, b c)))$ be a formula that is true when the values of variables in $a$ is equal to $M(a, b, c)$.
- Then $F(A(a, b, c)) \equiv a \land \lnot b \land c$. 
- That is, it's the formula that's true when the values of $a, b, c$ match the assignment $M(a, b, c)$.
- Now, we will try to build an interpolant $C(q)$.
- TODO: this needs a bit more thought.

#### Contradiction of Conjunction Viewpoint

- Let $A(p, q) \land B(q, r)$ be unsatisfiable.
- Then, interpolation implies that there exists a formula $C(q)$, such that $A(p, q) \implies C(q)$ and $C(q) \land B(q)$ is UNSAT.
- This tells us that "unsat core" of $A$ and $B$ actually lives in $C$.

##### Proof that implication interpolant implies conjunction unsat interpolant

- We can phrase that $A(p, q) \land B(q, r)$ being UNSAT as saying that $\lnot (\lnot A \lor \lnot B)$ in UNSAT,
  or that $\lnot A \lor \lnot B$ as being TAUTO, or that $A \implies \lnot B$.
- We can apply interpolation to tell us that there is a formula such that $A(p, q) \implies C(q)$ such that $C(q) \implies \lnot B$.
- Reversing the logic, we can see that $C(q) \land B(q, r)$ must be UNSAT.
- Roughly, we use the fact that $A \implies B$ is a tautology implies that whenever $A$ is true, $B$ must be true. This means that $A \implies \lnot B$
  is UNSAT, which is the same as $\lnot A \lor \lnot B$ being unsat, which is the same as $\lnot (A \land B)$ being UNSAT.
- I would appreciate a more direct way of seeing this fact!

#### Interpolant as telling us which clause is refuting

- From the UNSAT perspective, we know that $(A(p, q) \land B(q, r))$ is UNSAT.
- We can think of the interpolant $C(q)$ as telling us why the unsat happened.
- Recall that $C(q)$ is such that (i) $A(p, q) \implies C(q)$ and (ii) $C(q) \land B(q)$ is UNSAT.
- (i) implies $\lnot C(q) \implies \lnot A(p, q)$.
- (ii) implies $\lnot (C(q) \land B(q))$ is a tautology, or $\lnot C(q) \lor \lnot B(q)$, or $C(q) \implies \lnot B(q)$.
- So, consider a model $M$. We know that $M \lnot \model A \land B$.
- Let's now test what value $C(q)$ ought to have given the two above constraints.

##### Case 1: contradiction from clause in $A$
- Suppose the contradiction arose from a clause in $A$.
- We must have $M \models A(p, q) \implies C(q)$. This imposes no conditions on $A(p, q)$ since $A(p, q)$ is false, and thus
  the formula will be true regardless of $C(q)$.
- We must also have $M \lnot \models C(q) \land B(q, r)$. 
- For this to happen regardless of $B(q, r)$, we must have $C(q) = 0$ in $M$.
- See that this also agrees with $M \models \lnot C(q) \implies \lnot A(p, q)$. 
  So we can think of this as telling us to "label" $M$ with $C(q) = 0$ when the failure in $M \lnot \models A \land B$
  arises from $A$.

##### Case 2: contradiction from clause in $B$.
- Suppose the contradiction arose from a clause in $B$.
- We must have $M \models A(p, q) \implies C(q)$. For this to be true regardless of the truth value of $\llbracket A(p, q) \rrbracket_M$, we must choose $C(q) = 1$.
- We must also have $M \lnot \models C(q) \land B(q, r)$. This will hold because $\llbracket B(q, r) \rrbracket_M = 0$,
  regardless of $C(q)$. 
- See that this also agrees with $M \models C(q) \implies \lnot B(p, q)$. 
  So we can think of this as telling us to "label" $M$ with $C(q) = 1$ when the failure in $M \lnot \models A \land B$
  arises from $B$.

##### Recipe for exponential sized $C$

- Combining the two above, we can see that $C$ is really a labelling function, that labels for an UNSAT clause $A \land B$,
  and for an arbitrary model $M$, whether $M \lnot \models A \land B$ because of $A$ or because of $B$.
- If it's because of $A$, then $\llbracket C \rrbracket = F$, and otherwise it's because of $B$, so $\llbracket C \rrbracket_M = T$.
- This gives us a recipe to write a $C$ down.
- Create a clause of the form $\forall m \in M, (A(M) = 0 \implies F) \land (B(M) = 0 \implies T)$.
- This may not look propositional since we are quantifying over models.
- However, the set of models is finite, so we can build a gigantic (exponential in the number of variables)
  disjunct over all models, and create a huge clause. 
- For example, if we want to know that we are in a model $[x_1 \mapsto T, x_2 \mapsto F]$, we can literally write the
  expression $x_1 = T \land x_2 = F$, or in more shorthand, $x_1 \land \lnot x_2$.
- This gives us an algorithm to compute an exponential sized interpolant, so we now know that interpolants always exist!


#### Linear time algorithm for computing interpolants

- We now want an algorithm that gives us smaller interpolants.
- Note that this algorithm is linear in the size of the *refutation proof*, which could be exponentially large!
- The idea is to use the fact that the interpolant tells us which clause is refuting.
- So, recall from above that we have that (i) $\lnot C(q) \implies \lnot A(p, q)$, and that (ii) $C(q) \implies \lnot B(q, r)$.
- Next, see that in a resolution proof, we can walk a resolution proof "backwards" to figure out which clause
  gave rise to a contradiction.
- We will build a $C(q)$ by performing induction on the resolution proof, maintaining (i) and (ii) as invariants of the
  clauses we have seen so far. 

##### Using clause from $A$

- If we are using a clause $A_i$ of $A$, then the associated term for the interpolant will be $I(A_i) \equiv 0$.
  The idea is that if the UNSAT for a particular model $M$ came from $A_i$, then we must have that the interpolant $I(A_i)$ has value $0$ from the previous analysis. In this case, we know for sure that the UNSAT came from $A_i$, and thus the interpolant is just $0$.

##### Using clause from $B$

- By the exact same argument, if we use clause $B_i$ of $B$, then the associated term for the interpolant will be $I(B_i) \equiv 1$.


#### Resolving, both from $A$.

- Suppose we resolve two clauses $A_i, A_j$ Now, if the contradiction came from either $A_i$ or $A_j$,
  then this part of the resolution is the cause of UNSAT. 
- Now see that $I(Resolv(A_i, A_j))$ should be $0$ if the UNSAT came from $A$, and $I(Resolve(A_i, A_j))$ should be $1$
  if the UNSAT came from $B$.
- But if this part of the resolution is the cause of UNSAT, then we will have either $I(A_i) = 0$ or $I(A_j) = 0$.
  In either of theses cases, the UNSAT came from $A$.
- So, we need $I(Resolv(A_i, A_j)) = 0$. To achieve this, we set $I(Resolv(A_i, A_j)) = I(A_i) \land I(A_j)$.
- Or, in less terse terms, "if $I(A_i)$ or $I(A_j)$ is $0$, then so is $I(Resolv(A_i, A_j))$". Convert that to a formula.

#### Resolving, both from $B$.

- Suppose we resolve two clauses $B_i, B_j$ Now, if the contradiction came from either $B_i$ or $B_j$,
  then this part of the resolution is the cause of UNSAT. 
- Now see that $I(Resolv(B_i, B_j))$ should be $0$ if the UNSAT came from $A$, and $I(Resolve(B_i, B_j))$ should be $1$
  if the UNSAT came from $B$.
- But if this part of the resolution is the cause of UNSAT, then we will have either $I(B_i) = 0$ or $I(B_j) = 0$.
  In either of theses cases, the UNSAT came from $B$.
- So, we need $I(Resolv(B_i, B_j)) = 1$. To achieve this, we set $I(Resolv(A_i, A_j)) = I(B_i) \lor I(B_j)$.
- Or, in less terse terms, "if $I(B_i)$ or $I(B_j)$ is $1$, then so is $I(Resolv(B_i, B_j))$". Convert that to a formula.

#### Resolving, one from $A$, one from $B$

- In very similar fashion, we build a resolvent of $I(Resolv(A_i, B_j))$.
- If we have resolved with $x \in A_i$ and $\lnot x \in B_i$, and suppose that the resolvent lead to a UNSAT.
- Now, we see that $x = F$, then the contradiction came from $A_i$, and so we must use the interpolant $I(A_i)$ in this case.
- Similarly, if $x = T$, then the contradiction came from $B_i$, and we must use the interpolant $I(B_j)$ in this case.
- Putting this together, we see that we want the formula $(\lnot x \implies I(A_i)) \land (x \implies I(B_i))$.

#### Interpolant as "forward image"

- Thinking once again from the UNSAT perspective, suppose that we are trying to prove that all executions are good.
- Actually, I realized I don't understand this. will come back to it.


# AWS MathFest 2024

- We had an interesting question at the AWS MathFest.
- Suppose there are 31 days, and there are 31 jugglers.
- on each day, jugglers put on a show. A show contains a set of jugglers.
- Call a configuration of shows by jugglers *good* if no two days contain the same jugglers.
- We are told that the initial plan is a *good* plan.
- Now, Is it possible to always kill a juggler such that the days remain good?
- Let's restrict to 2 jugglers and two days. Let the days be `1, 2` and jugglers be `a, b`. We can represent a 
  good configuration as a matrix:

```
       a  b
-----+-----
day 1| x  o
day 2| x  x
```

- This means that the show on day 1 has only a, and the show on day 2 has both a and b.
- See that it is not safe for us to kill juggler `b`, because if we do so, then on both days, only juggler `a` performs.
- See that it is safe for us to kill juggler `a`, because if we do so, then on day 1, no juggler performs, and on day 2, only juggler `b` performs
  which was different shows.
- In general, is it always possible to find a juggler to kill (like we found `b` in this case), given that we have `n` days and `n` jugglers?

#### Proof that this is always possible
- For a given day, interpret the "jugglers appearing on that day" as a string. So for example, day 1 is `xo` and day 2 is `xx`.
- See that the property that we had can be rephrased by saying that the strings for all days are distinct.
- This means that if we build an automata, then it will have unique terminal states, one for each string.
- So, we will think of this from the point of view of nerode equivalence.
- We have a sequence of equivalence relations on the set of days. The more of the strings we consume, the more days we can tell apart.
- At the end, we can tell apart all the days.
- We want to prove that one of the characters is superfluous.
- Going back to the example:
- Before consuming any character, we will have the equivalence classes `{day1, day2}` (no distinction).
- After revealing the first column (ie, learning on what days the 1st juggler performs), we will have the equivalence classes `{day1, day2}`.
  That is, we learnt nothing new.
- After revealing the second column (ie, learning on what days the 2nd juggler performs), we will have the equivalence classes `{day1}`, `{day2}`.
- We say that learning when juggler `a` performs did not let us distinguish any new states, so we can kill juggler `a` and still have the property
  that at the end, we have distinguished all days.
- In general, see that we have `n` letters. We will have states that correspond to `0` letters seen, `1` letters seen, ..., `n` letters seen.
- See that at the final state with index `n`, all states are in their own equivalence class with `1` element.
- So what we have is a chain of length `(n + 1)` in the lattice of partitions,
  startig with the partition `{1...n}`, ending with the partition `{{1}, {2}, .. {n}}`.
- However, see that this lattice only has height `n`! e.g. when `n=3`, the lattice looks as follows:

```
    {[1] [2] [3]}
{[1] [2 3]} {[1 2] [3]} {[1 3] {2}]
     {[1 2 3]}
```

- Thus, given a chain of length $n + 1$ in a lattice of height $n$, there must be two elements that are equal.
- So we can find a letter (which is the transition between these two elements) to kill.


# Proving False with partial functions even with Inhabited types 

- The idea is to define an inconsistent function where `foo = !foo`.
- Then, we case split on the value of `foo` (via LEM), and show that we get contradiction in both cases.
- See that such a function is inhabited, and yet we get a contradiction!
  So it's not legal to add equations for partial functions.

```
partial def foo (_ : Unit) : Bool := ¬ foo ()
axiom foo_eqn : foo () = ¬ foo ()

theorem false : False := by
  have hcontra : foo () = ¬ foo () := foo_eqn
  by_cases h : (foo ()) <;> simp [h] at hcontra

/-- info: 'hfoo_false' depends on axioms: [foo_eqn, propext] -/
#guard_msgs in #print axioms hfoo_false
```


# Table Maker's Dilemma

- [Table Maker's Dilemma Wiki Page](https://en.wikipedia.org/wiki/Rounding#Table-maker's_dilemma)
- [Floating point computation](https://www.cl.cam.ac.uk/teaching/1011/FPComp/)

# Techne, Da Vinci, Michalangelo, and Art

- It would probably be the case that davinci and michalangelo would be considered as engineers, not artists!
- Fine arts today has now become a vessel for philosophy. It seems to be disconnected from [techne](https://en.wikipedia.org/wiki/Techne)


# Ffmpeg one liner to re-encode mp4 so chrome can open it 

```
ffmpeg -y -i "doctor.who.2005.s14e00.the.star.beast.1080p.web.h264-hornedsplendidpuduoffocus.mkv" -ar 22050 -ab 512 -b 800k -f mp4 -strict -2 -c:a aac "OUTPUT.mp4"
```

# Notes on Copy and Patch Compilation

- [Brandt Bucher: A JIT Compiler for CPython](https://www.youtube.com/watch?app=desktop&v=HxSHIpEQRjs)
- [quenya.lean](git@github.com:bollu/quenya.lean.git)


# Setting up SAIL for porting to Lean

- Since I have no idea how to use `opam`, but I do not the older Coq setup via makefiles,
  that's what I'll be using.

##### Directory Structure

```
.
├── bbv -> sail-src/bbv/
└── sail-src
    ├── bbv@master:c53d5b95c7
    ├── coq-sail@main:843059
    └── sail@sail2:ba9f7f1
```

- In general, it's a welcome, pleasant surprise that everything works on tip-of-tree.
- We first build `bbv`, which is a library for bitvector theory. We then build `coq-sail`. 
  Finally, we build `sail`.
- Yes, we need two copies of `bbv`. `coq-sail` uses the `bbv` from:

```
root/sail-src/coq-sail$ ../../bbv`
 -> root/bbv
```

- `sail` itself, in its test suite, uses the `bbv` from:

```
root/sail/test/coq$ ../../../bbv
 -> root/sail-src/bbv/
```


#### Grabbing the right `ocaml`

```
root$ opam switch create 5.1.0
root$ eval $(opam config env) 
```

##### Building `bbv`

```
root$ cd bbv && make -j$(nproc) && make install
```

##### Building `bbv`

```
root$ cd sail-src/coq-sail/src && make -j$(nproc) && make install
```

##### Building `sail`

```
root$ cd sail && cat INSTALL.md
root$ cd sail && make -j $(nproc) && make install
```

##### What's needed to port to Lean


> There's quite a bit of obsolete stuff in the Coq backend at the moment that you could safely skip.
> sail_coq_backend by default generates a shallow embedding.
> It's probably worth looking at katamaran, though. I don't think a deep embedding is too hard,
> it's partly just a case of deciding what the output language should look like.

# Gregorian chant and numes

- [A Beginners guide to reading gregorian chant notation](https://www.ststephenvc.com/wp-content/uploads/2020/02/beginner-guide-chant.pdf)
- [Basic gregorian chant and sight reading by sister mary demetria](https://media.musicasacra.com/books/basicgregorianchant_1960.pdf)
- [Neumes on wikipedia](https://en.wikipedia.org/wiki/Neume)

- Invented by [guido of arezzo](https://en.wikipedia.org/wiki/Guido_of_Arezzo).
- The notation is called neumes, or "square notes".
- 4 line staff.
- Clefs are `C` and `F`, can be changed in the middle of a piece.
- Monophonic, no harmony (chords)
- No meter.
- Read left to right, bottom to top. So if two notes are stacked one on top of another, we read the lower then the higher.
- Has notation that can be decoded into modern notation fairly straightforwardly.

# Decreasing Metric for Mutual Recursive Functions

```
mutual
def bar (fooN : Nat) (barN : Nat)  : Nat :=
  match barN with 
  | 0 => foo fooN
  | n'+ 1 => bar fooN n'
termination_by (fooN, barN + 1) -- when dropping from bar to foo, give yourself an extra point.
decreasing_by
  . simp_wf; apply Prod.Lex.right; omega
  . simp_wf; apply Prod.Lex.right; omega

def foo (fooN : Nat) : Nat :=
  match fooN with
  | 0 => 42
  | fooN' + 1 => bar fooN' fooN

termination_by (fooN, 0)
decreasing_by
  · simp_wf; apply Prod.Lex.left; omega
end
```

- This took me a while to figure out
- Actually, what we are saying is that `fooN` terminates by `(fooN, bot)`, `barN` terminates by `(fooN, barN)` with the condition that `bot < _`.
- In general, I guess this is how we want the termination criteria to be.
- I should read the Isabelle docs on how they prove termination. 

# FOL + Fixpoint + Counting does not capture P

- I learnt this proof from Anuj Dawar's course in "logic and complexity, lent 2024".
- [Reference handout](https://www.cl.cam.ac.uk/teaching/2324/L15/notes5.pdf)

## The Language

- We add a new quantifier for bounded quantification over integers
- We add new terms that are given by `#φ` which counts the number of elements that satisfy phi.
- We add addition and multiplication operators on number terms.
- We continue to have the fixpoint operator to take a fixpont of a positive predicate of a relation symbol.

## Game 1: k tuple pebble game

## Game 2: cops and robbers game

Game proceeds as follows:
- Cops announce where they are moving to on the graph. Can move to arbitrary vertices.
  (cops have helicopters)
- The cops lack secure crypto, so the robber learns of their new planned locations as they form the plan,
  and decides on a new vertex to move based on this information.
- Robber has a motorbike, so all the robber needs is *some* path from her current position to her new position
  that is free of cops (who are still their their current positions)
- Robber moves to her new position and chills there.
- Police then move with their (slow) helicopters to their committed position, and play continues.
- Robber wins if robber can play the game infinitely without being caught.
- Cops win if they can trap the robber into a configuration such that 

In code:

```py
def do_cops_win (robber_cur_pos : Vec2, 
  cops_cur_pos : List[Vec2], 
  graph : Graph,
  robber_stragy,
   cop_strategy):
   while True:
     # cops make strategy.
     cops_new_pos = cop_strategy (cops_cur_pos) # cops don't know where robber is?
     # insecure channel, robber learns of this and plots strategy
     robber_new_pos = robber_strategy(graph,
       cops_cur_pos, # robber knows where the cops currently are
       cops_new_pos, # robber also wknows where the cops plan to be (insecure channel)
       robber_cur_pos)
     # robber tries to go to new position. If an avoiding path does not exist,
     # robber is trapped.
     if not avoiding_path_exists(robber_cur_pos, cops_cur_pos, robber_new_pos):
        return "cops win"
     # robber successfully makes it.
     robber_cur_pos = robber_new_pos
     # cops slowly make their way to their new position.
     cops_cur_pos = cops_new_pos
```
  

### Warmup:`n+1` cops needed for `nxn`grid.

Proof by picture. Consider a `3x3` grid, cells denoted by `o`:


```
  XYZ
1|ooo
2|ooo
3|ooo
```

Cops will occupy the first column and the first cell of the first row:

```
  XYZ
1|cco
2|coo
3|coo
```

This forces the robber to live in the rest of the grid, and crucially, cuts of access
to the top left position  `1X`. So in the next round, the cops will take the cop at `1X`
and move her to `2Y`. The inaccessible cell is marked with `-`, where the cops have a 
guarantee that the robber cannot be:

```
  XYZ
1|-co
2|cco
3|coo
```

Now note that the cell `2Y`is similarly inaccessible, and thus also becomes `-`in the next turn.

```
  XYZ
1|-co
2|-co
3|cco
```

Now we see that `3X`is unreachable, so we can take the cop at `3X` and move her to `3Z` to make `3Y`
inaccessible:


```
  XYZ
1|-co
2|-co
3|-cc
```

Repeat:

```
  XYZ
1|-co
2|-cc
3|--c
```

Victory for the cops:

```
  XYZ
1|-cc
2|--c
3|--c
```


- In general the cops have a winning strategy if the can "sweep" the graph, and
  maintain some territory that they expand in each turn.
- Note that the for nxn grid, the **max-cut** (NOT min-cut) is `n`,
  and any smaller graph that we get after removing cut edges will have at most `n`edges.
  So we can use `n` cops to repeatedly cut of access. There's probably a `log(2n)`
  number of rounds strategy by subdivision that cuts of access by halving each round,
  either horizontally or vertically.

## Toroidal graphs

- what you get if you cut a torus into squares.
- Create an `nxn`grid, and connect vertices `(i, j) → ((i+1) % n, j)`
  and similarly connect `(i, j) → (i, (j+1)%n)`. This gives a torus.
- We claim that for the cops and robbers game, $k$ cops does not suffice to win.


#### Robber can win on a toroidal graph with $k$ cops.
- For simplicitly, once again, let $k = 4$.
- Suppose the cops are on a set $X$ of $k$ vertices.
- We want to show that $G - X$ ha a connected component with 
  at least half the vertices of $G$.
- Let's consider one possible configuration where they are in a row:

```
  WXYZ
1|oooo
2|CCCC
3|oooo
4|oooo
```

- See that this does not cut off access, since we can move from `(-, 1)` to `(-, 4)` as
  the top and bottom edges are glued. So this is useless for the cops.

- Now let's try and consider a configuration where all the cops are on distinct columns:

```
  WXYZ
1|Cooo
2|oCoo
3|ooCo
4|oooC
```

- In this case too, the graph is connected, and has a large connected component.
- The only way the cops can cut of a region is to encircle it:

```
  WXYZ
1|oooo
2|oCCo
3|oCCo
4|oooo
```

- In this case, the outside has `kˆ2 - k`vertices, which is larger that `kˆ2/2`:
  `kˆ2 - k = k(k -1) > k * k/2`.



## Linear system of equations over F2

- We will claim that system of linear equations over F2 (integers mod 2)
  cannot be solved by FPC (first order fixpoint + counting).
- The problem can clearly be solved in polytime by gaussian elimination.

#### Encoding in unordered structure
- consider structures over the domain `x1, ..., xn` and `e1...em`.
- `xi` are variables, `ei` are equations.
- unary relation `E0(ei)` if RHS of `ei` is 0.
- unary relation `E1(ei)` if RHS of `ei` is 1.
- `M(xi, ej)` if `xi in ej`. 
- Note that this suffices, since any linear equation over F2 can be written as `x1 + ... xn = 0/1`.
- See that this problem is equivalent to XOR-SAT.
- See that we can negate variables by writing `not(xi) = 1 + xi`.
- Let `Solv(F2)` be the class of structures representing solvable systems.


#### Constructing the system of equations
- Let $G$ be a toroidal graph.
- Define $E_G$, the system of equations next, based on $G$. 
- For each edge, we get two variables $x[e, 0], x[e, 1]$ for each edge $e$.
- For each vertex $v \in V$, let $e[v, 1], e[v, 2], e[v, 3], e[v, 4]$ be the edges incident on $v$.
- We make 16 equations: $x[e[v, 1], i] + x[e[v, 2], j] + x[e[v, 3], k] + x[e[v, 4], l] = (i + j + k + l)$ for $i, j, k,  l \in \{ 0, 1\}$.
- Intuitively, we pick a bitstring $\vec b$, and we write the equation $\sum_j x[e[v, j], \vec b[j]] = \texttt{parity}(\vec b)$. 
- First see that this system is satisfiable by setting $x[-, i]$ to $i$, since the RHS is given by addint $i + j + k + l$,
  so will the lhs! 

$$
\begin{aligned}
&x[e[v, 1], i] + x[e[v, 2], j] + x[e[v, 3], k] + x[e[v, 4], l] =_? (i + j + k + l) \\
&= i + j + k + l =_? i + j + k + l 
\end{aligned}
$$

- We make another version of the equation system, $\tilde E_G$, which is the same system, except for a fixed vertex $c$ (for contradition),
  we change the parity of the equation to be $\sum_j x[e[c, j], \vec b[j]] = \lnot\texttt{parity}(\vec b)$.
- See that we perturb $16$ equations, for all possible choices of $b$ for a fixed $c$.
- See that this set of equations is unsatisfiable. Add up all equations that only have variables of the form $x[e, 0]$.
- The sum of all left hand sides will be double counting each variable, since we make an equation for each vertex,
  but we have a variable per edge. So the LHS will be zero.
- However, see that due to our perturbation, the RHS must be 1, since we changed the parity (TODO: make this more rigorous / proof by example).
- Now we show that for each $k$, there is a large enough $G$ such that $E_G \equiv{C[k]}  E_{\tilde G}$. 
-  This means that FPC cannot distinguish between the cases where the solution is true and false.
- Thus the problem `Solv(Z2)`cannot be solved by FPC.

#### Putting the pieces together

- Suppose that $G$ is the above toroidal graph such that the robber has a winning strategy for the $2k$ cops and robbers game played on $G$.
- We can use this to construct a winning strategy for the duplication in the $k$ pebble bijection game on $E_G$ and $E_{\tilde{G}}$.

# Building an ELF by hand

- Blog post posted over at repo:

# Resolution is Refutation Complete

- Constructive proof.
- We take soundness for granted since it easy by induction on the proof length.
- We prove this by induction on number of literals in the full clausal set. So for a clausal set `{{A, B}, {C, D}}` our induction measure is 4.

#### One literal

- If we have 1 literal, then our clause set looks like `{{A}}` which cannot be UNSAT. Thus, we trivially will find a contradiction if one exists.

#### `n+1` literals

- Suppose there is assignment that makes the formula UNSAT.
- Then we wish to show that resolution will find `False`.
- Since we have `n+1` literals, there must be at least one clause `C` that has two literals.
- Let `L` be one of the literals in clause `C`. Suppose `L` occurs as a +ve literal (mutatis mutandis for -ve occurrence.) Write `C := C' U { L }`,
  and write the full set of clauses `S` as `S := S' U { C }`.
- Note that `S'` cannot be empty, as we know that `S` is `UNSAT`.
- If `L` does not occur in negative position in any other literal, it can be eliminated from the problem, and we have reduced the number of literals.
  Use IH to get a resolution contradiction proof of the reduced problem, which is a resolution proof of the original problem.
- Since `S := S' U { C }` is UNSAT, this means that `S' /\ C`, or `S' /\ (C \/ L)` is false. This is to say that `(S' /\ C) \/ (S' /\ L)` is false, which means that
  *both* `(S' /\ C)` as well as `(S' /\ L)` is false.
- So, by IH, there must be resolution proofs for both `S' U {C}` as well as `S' U {{L}}`.
- Now, consider the resolution DAG for `S' U {C}`. If `{C}` is not used in the final derivation of the contradiction, we have a resolution proof using only `S'`.
  We can reuse the same resolution proof for `S' /\ (C \/ L)`, so we are done!
- By the exac same argument, we can disregard the case where in the resolution proof in `S' U {{L}}`, `L` was not used.
- So now, we have two resolution dags, one with `S', {C} |- ... |- False`, and one with `S', {L} |- ... |- False`.
- Recall that we finall want a resolution proof for the clause `{C, L}`. So what we do is we "percolate" the resolution proof of `S', {c}` with `L`, giving us 
  a resolution DAG of the form `S', {C, L} |- ... |- L`. We then "graft" this tree onto the one with `S', {L} |- ... |- False` to get the full
  resolution proof for `S', {C, L} |- ... |- False`!

# Fagin's theorem

- Consider sublanguages of all languages that encode models via the standard model encoding.
- Which of these languages can be recognized by NP?
- Crazy theorem: the ones that are exactly describable by *monadic second order logic*.
- Subtlety: we first *fix* the formula, and we then solve the problem if a model (encoded as a string) makes the formula true
- Sketch of MSO can be accepted by NP: First see that MSO can be figured out by NP: Make the guess for the relation, then do the usual thing of testing a fixed formula.
   We need as many loops as there are quantifiers in the formula. But since the formula is fixed, this is $n^k$ where $n$ is the size of the model / size of the input string.
   So we are done.

#### Hard part: every NP model property can be figured out by MSO

- Key idea: we want to run cook-levin, but we don't have booleans.
- Note that the largest numbers we will ever need to do cook levin are at most $n^k$ for some fixed $k$ (running time of NP machine).
- Use MSO to pick a total order on the model.
- On a finite model, a total order is an ordinal!
- From this, get integers `[0...n)`. Example: `0` is the smallest integer. so it is given by the least element in the ordering, so `exists x, forall y, x <= y`.
- Successor is given by "next" element in the ordering. `succ(x)` is the element `y` such that `x < y` and there is no `z` such that `x < y < z`.
- OK, but we need `n^k`.
- Get `n^k` by building tuples `MxMx..xM` and imposing lex ordering! lex ordering can also be expressed as a FOL formula.
- Done, we have arithmetic upto `n^k`.
- Sweet, now run cook-levin inside the model using our arithmetic. sugoi!


# EF (Ehrenfeucht–Fraïssé) games

- Games used to show that two structures are rank-q equivalent in FOL via game semantics.
- We make a restriction: we assume that the theory contains no function symbols. Recall that function symbols can be encoded via relations, so no
  expressive power is lost, merely annoynance is thwarted.
- If we had function symbols also, then we would need to perform induction on function call nesting depth as well as quantifier depth, and our completion of the substructre
  would need to complete by function symbols also.

- One direction is easy: if two models are rank `q` equivalent, then they are also game-round-q equivalent.

### Game equivalence implies rank equivalence

- We prove by contrapositive. Assume the two models are rank-k disequivalent (so there is a formula of that rank that distinguishes the models),
  we will show that the models are game-k disequivalent (so there is a winning strategy for spoiler.)

#### Example 0: Rank 0 equivalence

- Suppose we have a theory with no constant symbols. Then, at rank 0, it's impossible to tell them apart, because we cannot write *any* propositional equations about them!
- So suppose a theory $T$ does have a constant symbol `c`. Now suppose we have two model `M, M'` which are not rank-0 equivalent. This means that some propositional formula,
  involving `c`, can tell the two models apart. Call the formula `f`. Then it must be the case that WLOG, `M |= f` and `M' !|= f`.
- Now, from the view of the game, this means that we play a round 0 game, and build an *empty* partial isomorphism between the two models `M, M'`. What do we compare?
- Fear not, we must *generate* the substructure from the empty partial iso, which will be the submodel of `M` (say `C` for contradiction) which only has the symbol `c`,
  and similarly `M'` has submodel `C'` which has only `c'`. 
- Now, the formula `f`, when evaluated on the submodel `C` will be true, and when evaluated on `C'` will be false!
- Thus, game-0 equivalence iff rank-0 equivalence.


#### Example 1: Existential Rank 1 equivalence

- Suppose the two models are rank-1 disequivalent, and this formula that shows their disequivalence is an existential formula. Let the formula be `f := exists x, f'`.
  Suppose WLOG that `M |= f` and `M' !|= f`.
- What does this mean? This means that there is some element `m` in `M` such that `M |= f'(m)`. It also means that for *all*  `m'` in `M'`, `M' !|= f'(m')`. 
- So, for the spoiler to win, it needs to pick a submodel `C` of `M` that contains `m`, since any submodel `C'` of `M'` *will not* be able to
  model `f'`!
- that's exactly what the spoiler does: it pick `m` in `M`. Now whatever `m'` duplicator chooses, the formula `exists x, f'` can tell them apart: the formula is true in `C'`
  and will be false in all choices of `C'` that duplicator can make!
- Note that in this case, spoiler chose an element `m` in `M`.


#### Example 2: Universal Rank 1 equivalence

- Suppose the two models are rank-1 disequivalent, and this formula that shows their disequivalence is a universal formula. Let the formula be `f := forall x, f'`.
  Suppose WLOG that `M |= f` and `M' !|= f`.
- What does this mean? This means that for every element `m` in `M`, it is true that `M |= f'(m)`. It also means that there is *some* element `m'` in `M'` such that 
  `M' !|= f'(m')`.
- So, now, spoiler chooses `m'`. This way, spoiler ensures that it gets a submodel `C'` where `C' !|= forall x, f'` since we have `m'` in `c'` such that `C' |= f'(m')`.
- Duplicator cannot win, since for any submodel `C` of `M` it chooses, it must be the case that `C' |= forall m, f'`, since for every element `m` in `M` (and thus `m` in `C`),
  we have that `M |= f'(m)`, and thus `C |= f'(m)`. 
- Note that in this case, spoiler chose an element `m'` in `M`'.


#### Full Proof Sketch
- See that spoiler really needs the ability to pick from both `M` and `M'` to corner duplicator.
- Clearly, one can see how to generalize this to an induction. So perform the induction, replacing the level 1
  case with an inductive case.
- Note that the spoiler needs to be able to choose elements from either set to be able to correctly.

# DPLL

- DPLL algorithm is a decision procedure for propositional logic.
- Keeps a set of clauses, brute forces them by case splitting on literals, and optimizes existing clauses with heuristics:
- **Unit propoagation**: For a literal `L`, If we have a clause `{L}` (a unit clause), we set `L` to true,
  since for the clause to be true, `L` should be true.
- **Pure literal elimination**: If a literal `L` occurs as only +ve in the entire formula, then we can assign it to be true and
  clear it from the other clauses.
- Now, for any clause where `L` occurs in the +ve can be eliminated, since the clauses are ORd together, the clause is true.
- For any clause where `L` occurs in the -ve (ie, `!L` occurs), remove the `!L` and make a smaller clause.

- If we derive an empty clause, then we have derived `False` as one of the conjunct clauses, and thus we have UNSAT.
- If we manage to clear all clauses, ie, our *set* of clauses is empty, then we have found a satisfying assignment, and we terminate.
- Optimization 2: Pure literal elimination

#### Cleanup optimization - Subsumption:

- Clause `{A, B}` subsumes a clause `{A, B, C}`, so delete larger clauses that are subsumed by smaller clauses.

# Why FOL models must be nonempty

- We ask for nonemptiness to ensure rules like `(forall x. x = x)` is equialent to `exists x. x != x`.

# Concrete calculation of hopf fibration

- Take any point `(a, b, c, d) ∈ S3`.
- This determines a quaternion `a + bi + cj + dk`.
- Let the rotation determined by a quaternion `q` be written as `R_q`.
- Recall that this determines a rotation of 3 space `(b, c, d)` and angle $2 cos^{-1}(a)$.
- Let $P_0$ be any point on `S2`, say `(1, 0, 0)`.
- Then, the hopf fibration `h : S3 → S2` sends `p ∈ S3 → R_p(P_0) ∈ R3`.
- Now, see that there are many points in `S3` which have image `(1, 0, 0)`.
- For example, one can check that all points `(cos t, sin t, 0, 0)`.
- We can show that for any point `p ∈ S2`, the inverse image `h^{-1}(p) ∈ S3` will be a unit circle in `S^3`.
- The full fibration will therefore be `S1 → S3 -h→ S2`, since each of the fibers of `h` is a circle (`S1`).

#### Rendering

- For a given point on `p ∈ S2`, we can render $h^{-1}(p) \subseteq S^3$
  as a set of points in `R3` via stereographic projection, which furthermore preserves circles (sends circles to circles).
- The map sends a point $(w, x, y, z)$ to the point $(x/(1-w), y/(1-w), z/(1-w))$. The only singularity is at $w=1$ which we
  conveniently ignore.
- See that this map sends circles to circles. Suppose we have the locus of points `(w, x, y, z)` where `w^2 + x^2 + y^2 + z^2 = 1`.
- Then the length of the sterographic projection vector is `(x^2 + y^2 + z^2)/(1-w)^2`, which is `1-w^2/(1-w)^2` ??
  SOMETHING IS WRONG!
- Recall the intuition for the sterographic projection, wrt `S2` and `R3`.
- For a point `p ∈ S2`, draw a line `l`, from the north pole `(0, 0, 1)`
  to the point `p`. The projection is the point of intersection of `l` with the `xy` plane.
- Same thing a dimension up.

#### References
- An Elementary Introduction to the Hopf Fibration, by David W Lyons.

# Canonical bundle over RP2 is not trivial

- Recall that `RP2` can be defined as the set of all lines in `R3`.
- The trivial bundle is the bundle `RP2xR -> RP2`. We shall call it `T`.
- The canonical bundle `L` is defined as follows: It is a subspace of `RP2xR3`, which has elements
  `{ (l, v) : l ∈ v }`. That is, it is all lines, and elements on these lines.

#### Intuition: Canonical bundle is not trivial

- One might try to construct an isomorphism from the trivial bundle `T` to the canonical bundle `L`
  by sending `(l ∈ RP2, t ∈ R)` to `(l, tv_l)` where `v_l` is the unit vector along `l`, or the intersection of `l` with the
  upper hemisphere of `S2`.
- Think of `RP2` as the upper hemisphere. See that on the equator, we only need *half* of the equator, since the
  "other half" is already given by the first half of the equator.
- Unfortunately, this does not work for the following subtle reason.
- Let us use the above """isomorphism""" to consider what happens to the trivial section
  `RP2 x {1}` (ie, the scalar field that is `1` everywhere on `RP2`.
- We will assign to each line, the unit vector along that line.
- On the equator, for the "front half", we will get unit vectors emenating from the origin into the boundary.
- For the "back half", we will get unit vectors *pointing towards the origin of the sphere*.
- But for all points "just above" the sphere, we will have unit vectors emenating out from the sphere.
- So, it will be discontinuous at the "back half" of the equator!

#### Formal proof: Canonical bundle is not trivial

- Consider a section of `s` of `L`, the canonical line bundle.
- `s : (l : RP2) → l` is  a function that sends a line `l ∈ RP2` to a point on the line `v ∈ l`.
- This can be seen as a map that sends, for points in the upper hemisphere, `s(l ∈ RP2) = ((λ(l) x) ∈ l)` for some function
  `λ: RP2 → R`, where `x` is the intersection of `l` with the upper hemisphere. `λ` must be continuous in `l`.
- We will create a new function `s' : S2 → R3`, such that the map `s'(x ∈ S2) = s(l)` for all points `x`, where `l` is the
  line that contains `x`. So `s'(x)` is going to be a point on `l`, where `l` is the line that contains `x`.
- We will write `s'(x ∈ S2) = λ'(x) x` for some function `λ': S2 → R`.
- We now calculuate what `λ'` is like.
- We must have that `s'(x) = s'(-x)`, since both `x` and `-x` lie on the same line `l`, and thus
  `s'(x) = s(l) = s'(-x)`.
- Let us now calculate this in terms of `λ'`.
- We see that `s'(x) = λ'(x)x`, and `s'(-x) = λ'(-x)(-x) = -λ'(x) x`.
- But since `s'(x) = s'(-x)`, we must have that `λ'(x) x = - λ'(x) x`, or `λ'(x) = - λ'(-x)`.
- Intuitively, the line `l` is determined only by the positive vector, but the
  function `λ` is given as input the vector on the sphere. Thus, on input `-x`,
  it must rescale the vector *negatively*, to push the vector in the positive direction! (as `s` needs us to do).
- So this means that we have a continuous odd function `λ' : S2 → R`, such that `λ'(x) = - λ'(-x).`
- By the intermediate value theorem, this function must vanish.
- Said differently, take a curve `c : [0, 1] → S2` on the sphere connecting `x` to `-x`.
  Then `λ' . c : [0, 1] → R` gives us a continous function which is positive at `0` and negative at `1`, and thus
  must have crossed `0` at some point by the intermediate value theorem.
- This means that the vector field `s` must have vanished at some point, since there is a point where `λ'` equals `0`,
  which means there is a point where `s'` vanishes (on S2), which means there is a line where `s` vanishes (on `RP2`).
- Thus, there cannot exist a canonical line bundle on `RP2`, which means that the canonical line bundle is not trivial.

- Now see that we need 
- Now `RP2` is this vector field restricted to the top hemisphere.
- If `λ` is zero somewhere, then we are done.
- We will show that `λ` must be zero somewhere.
- consider the scalar field on `S^2` that sends `x` to `λ(x)`. 

# Concrete description of spinors

- Consider how in physical space, $|\uparrow\rangle$ and $\downarrow\rangle$ in physical space are 180 degrees away
  (pointing up or down), but in the qubit state space, they are orthogonal. So there is an "angle doubling",
  where 180 degrees in physical space is 90 degrees in state space. How to encode this?
- Idea: some matrices can be written as a product of two vectors, as `[x y] [a b]^T`. Do the same to a vector!
- Take a vector `[x, y, z]`. Convert to a pauli matrix. `[z  x-yi; x+yi z]`. This can be written as `[s1 s2] [-s2 s1]^T`.
- Just as we can rotate a 3D vector with a rotation matrix, we can rotate a pauli vector with `2x2` matrices:

$$
\begin{bmatrix}
\cos \theta/2 & i \sin \theta/2 \\
i \sin \theta/2 & \cos \theta/2
\end{bmatrix}
\begin{bmatrix}
z & x - yi \\
x+yi & -z
\end{bmatrix}
\begin{bmatrix}
\cos \theta/2 & i \sin \theta/2 \\
i \sin \theta/2 & \cos \theta/2
\end{bmatrix}^\dagger
$$

- But this can be written as:

$$
\begin{bmatrix}
\cos \theta/2 & i \sin \theta/2 \\
i \sin \theta/2 & \cos \theta/2
\end{bmatrix}
\begin{bmatrix}
s_1 \\ s_2 
\end{bmatrix}
\begin{bmatrix}
-s_2 & s_1 
\end{bmatrix}
\begin{bmatrix}
\cos \theta/2 & i \sin \theta/2 \\
i \sin \theta/2 & \cos \theta/2
\end{bmatrix}^\dagger
$$

- So a spinor is like a "rank 1/2 object", between scalars and vectors.
  We can combine two spinors to get a vector. 
- Pauli spinors are associated with 3D space (what was explained now).
- Weyl spinors are associated with 4D spacetime.

##### Clifford algebras

- Geometric algebra, nuff said.
- Spinors arise for free in a geometric algebra.
- For example, the spin up state is $1/2(1 + e_z)$ where $e_z$ is the basis $z$ vector.
  The spin down state is $1/2(e_x + e_x e_y)$.
- Apparently, we can say that "spinors are elements of minimal left ideals in clifford algebras".

#### References

- [Spinors for beginners by eigenchris](https://www.youtube.com/watch?v=j5soqexrwqY)

#### Spinorial tensors

- For tensors, we need only co and contravariant indeces.
- For spinors, they have chirality as well, so we get `{left, right} x {co, contra}`.
- This notation for denoting chirality based on dots is the [Van der waerden notation](https://en.wikipedia.org/wiki/Van_der_Waerden_notation).

# Paracompact spaces

- A space is paracompact iff every open cover $\{ U_\alpha \}$
  has a locally finite refinement $\{ V_\beta \}$.
- That is, every $V_i$ has some $U_i$ such that $V_i \subseteq U_i$,
  and the set of covers $\{ V_\beta \}$ is locally finite.
- Locally finite cover $V_\beta$: every point $x \in X$ only has finitely many $V_i$ such that $x \in V_i$.
  Said differently, $|\{ V_i : x \in V_i \}|$ is finite.

#### Hausdorff Paracompact spaces admit partition of unity
- one liner: take locally finite refinement and bash with Urhyson lemma.

#### Compact Implies Paracompact
- Take the open cover $U$, build the finite subcover $V$.
- This is clearly a refinement, because it only has sets from $U$, and it is 
  clearly locally finite, because there is literally only a finite number of sets in $V$.

#### compact space that is not paracompact

- Stone space, or infinite product of $\{0, 1\}$ in the product topology.
- Recall that the open sets here differ from the "full cover" at only a finite number of indexes.
- Suppose that a point $p_i$, which is $1$ at index $i$ and zero everywhere else, does not have infinite cover.
- intuition: so all but a finitely many collection of covers can choose to cover $p_i$.
- But this must happen for each $i$, so there must be soe cover that avoids $p_i$ for all $i$.
- This is impossible?
- Oh god, this proof needs baire category to "push around" an infinite intersection of dense subsets.


# Latin prefixes for words

- `in`: in. Greek: `endo`
- `ex`: out of. Greek: `ecto`.
- `con`: with (e.g. construction -- to build with, compose -- to put with).
  Greek: `syn` (e.g. synthesis -- composition)
- `ob`: against. (e.g. obstructrion).
- `circum`: around. Greek: `peri`.
- `de`: from (e.g. denature, detract). Greek: `?`
- `re`: again e.g. redo): Greek: `?`
- `super`: above. Greek: `hyper`.
- `sub`: below. Greek: `hypo`.
- `per`: for (perceive -- take for). Greek: `para`.
- `ab`: from (abstain -- hold from, abstract -- pull from / draw from). Greek: `?`
- `ad`: to (administer -- to minister / rule, access -- ad; cess -- ). Greek: `?`
- `pre`: before (e.g. preposition). Greek: `?`
- `post`: after (e.g. postposition). Greek: `?`
- Anything without these in maths is probably greek. 

# Crash Course on Prosody

- Syllable: Smallest unit.
- Feet: Sequence of syllables.
- Line: Sequence of feet. Used to be called `verse`, which now stands for a poem in general.
- Stanza: Sequence of lines. 
- Iamb: a feet which is or ["da", "DUM"] or `[x, /]` as is written in notation.
- Iambinc pentameter: a sequence of 5 iambs. `x/| x/| x/| x/| x/|`.


/     x  |x  /|x  / |   x  /   | /   /
earth has not a-ny-thing to show more fair
/    x     x  /  x  /    x   x     /    /
dull would he be of soul who could pass by
x|/     x| /     x  x | x   /  x  /
A sight so touch-ing in its maj-es-ty

#### Iamb Substitutions

- `x/` to `/`: defective foot or bare stress: BEGINNING.
- `x/` to `/x`: trochee (badger) . BEGINNING or AFTER PAUSE.
- `x/` to `//`: spondee (duck soup). ANYWHERE.
- `x/x/` to `xx//`: double iamb. ANYWHERE.
- `x/` to `xx/`: anapest. [UNCOMMON]

# What the hell is a nix flake?


I finally found a coherent explanation [on reddit](https://www.reddit.com/r/NixOS/comments/131fvqs/comment/ji0f3gl/?utm_source=share&utm_medium=web2x&context=3), inlined here:

> The basic idea of flakes isn't that complicated, but it does require a little
> bit of basic understanding of the nix programming language. A flake.nix file is
> an attribute set with two attributes called inputs and outputs. The inputs
> attribute describes the other flakes that you would like to use; things like
> nixpkgs or home-manager. You have to give it the url where the code for that
> other flake is, and usually people use GitHub. The outputs attribute is a
> function, which is where we really start getting into the nix programming
> language. Nix will go and fetch all the inputs, load up their flake.nix files,
> and it will call your outputs function with all of their outputs as arguments.
> The outputs of a flake are just whatever its outputs function returns, which
> can be basically anything the flake wants it to be. Finally, nix records
> exactly which revision was fetched from GitHub in flake.lock so that the
> versions of all your inputs are pinned to the same thing until you manually
> update the lock file.


> Now, I said that the outputs of a flake can be basically anything you want, but
> by convention, there's a schema that most flakes adhere to. For instance,
> flakes often include outputs like `packages.x86_64-linux.foo` as the derivation
> for the foo package for `x86_64-linux`. But it's important to understand that
> this is a convention, which the nix CLI uses by default for a lot of commands.
> The reason I consider this important to understand is because people often
> assume flakes are some complicated thing, and that therefore flakes somehow
> change the fundamentals of how nix works and how we use it. They don't. All the
> flakes feature does is look at the inputs you need, fetch them, and call your
> outputs function. It's truly that simple. Pretty much everything else that
> comes up when using flakes is actually just traditional nix, and not
> flakes-related at all.


> The only other significant difference from traditional nix is "purity". Flakes
> disallow a lot of "impure" ideas, like depending on config files or environment
> variables that aren't a part of the flake's source directory or its inputs'.
> This makes it so that a derivation / system / etc. is reproducible no matter
> what context you're evaluating the flake from.



# How to prove `noConfusion`

Suppose we take a type 

```
inductive Eg 
| A | B
```

- how do we show that `Eg.A <> Eg.B` from first principles? (using only recursors?)
- This is the same as showing `Eg.A = Eg.B -> False`.

- First, some gadgets: congruence of function arguments:

```
-- path induction
def fun_functional (f : A → B) (x y : A) (EQ : x = y) : f x = f y := 
   Eq.recOn EQ (motive := fun k K_EQ_X => f x = f k) rfl
```

- Principle of explosion

```
def false_elim (f : False) : α := False.rec f (motive := fun _ => α) 
```

- Key idea: create a type by using the recursors of `x, y` such that 
  when `x = y` we have True and when `x <> y` we have False. 
- Then, when given a proof that `Eg.A = Eg.B`, we can go through the cases
  and we want to produce false, we can use `Eq.rec` on this type, and produce 
  the inhabitant `True.intro` for the cases when they are equal. Then, path
  induction / the recursor for equality will give us an inhabitant of `False`,
  by promoting this to hold "in general".

```
abbrev Eg.noConfusionType' (x y : Eg) : Prop := 
  x.casesOn (motive := fun _ => Prop)
    (y.casesOn (motive := fun _ => Prop) True False)
    (y.casesOn (motive := fun _ => Prop) False True)
```

- We show that this type is inhabited when `x = x`.

```
abbrev Eg.noConfusionType'_inhabitant_rfl : Eg.noConfusionType' x x :=  
   x.casesOn True.intro True.intro
```

- We show that if `x <> y`, then an inhabitant of `Eg.noConfusionType' x y` produces `False`.

```
abbrev Eg.def2 (x y : Eg) (NEQ: x ≠ y) (NC: Eg.noConfusionType' x y) : False :=  
  match H : x with 
  | .A => 
     match K : y with 
     | .A => NEQ rfl 
     | .B => NC
  | .B => match K :  y with 
      | .A => NC 
      | .B => NEQ rfl
```

- How to translate the above into a raw formula?

```
  Eg.rec (motive := fun x_1 =>
    ∀ (NEQ : x_1 ≠ y) (NC : Eg.noConfusionType' x_1 y), x = x_1 → (fun x NEQ NC => False) x_1 NEQ NC)
    (fun NEQ NC H =>
      Eg.rec (motive := fun x =>
        ∀ (NEQ : Eg.A ≠ x) (NC : Eg.noConfusionType' Eg.A x), y = x → (fun y NEQ NC => False) x NEQ NC)
        (fun NEQ NC K => NEQ (Eq.refl Eg.A)) (fun NEQ NC K => NC) y NEQ NC (Eq.refl y))
    (fun NEQ NC H =>
      Eg.rec (motive := fun x =>
        ∀ (NEQ : Eg.B ≠ x) (NC : Eg.noConfusionType' Eg.B x), y = x → (fun y NEQ NC => False) x NEQ NC)
        (fun NEQ NC K => NC) (fun NEQ NC K => NEQ (Eq.refl Eg.B)) y NEQ NC (Eq.refl y))
    x NEQ NC (Eq.refl x)
```


# Origami box pleating

- Box pleating: subdivide paper into grid, then create into grid.
- To creases into model, use the [Elias stretch](https://abrashiorigami.com/how-to-collapse-box-pleated-crease-pattern/)
- We get 3 types of creases: hinge, ridge, axial
- red for ridge, blue for hinge.
- hinge: what we cut along to dissect the model along hinges.
- ridge creases: creases that are diagonal / angle bisector of the polygons (in 
  box pleating, is always square).
- BPstudio (box-pleating studio) is the tool used to make box pleating.

#### Minimum grid size computatation

- `(sum of lengths of tree edges * 2)/4`.
- for an edge flap, it takes `2 * edgelen` of perimeter when unfolded.
- for a river, it also takes `2 * riverlen` of permiter when unfolded.
- in total, we take `sum (2 * len)` over all  edges/rivers of perimeter.
- perimeter is `4 * square-side-len`. 
- So we get that `square-side-len` equals `(sum of lengths of tree edges * 2)/`.



#### Axial box pleating

- In the folded model, pick an imaginary line on which only *valley creases* lie
- also, all the hinge creases are perpendicular to this imaginary line.
- A model is axial box pleated if there is an axis such that all hinge creases are 
  orthogonal to this imaginary line.


#### Axial plus i creases

- Only creases can be referred to as 'axial plus i'.
- The 'plus i' gives us how much higher we need to go. 
- the ridges are the creases that allow go between 'axial plus i' to 'axial plus (i + 1)'.
- This gives us 3 types of creases: (1) hinges, which are orthogonal to the axis,
  (2) ridges, which connect 'axial plus i' creases, and the family of 'axial plus i' creases.

```
                  (Ridge)
(axial+1)---|--------/----------
            |       /
(axial+0)---|------/-------------
         (Hinge)
```


- If there is only one axis, then it is uni-axial.

# Vibes of Weiner Processes

- Caveat Emptor: This is totally non-rigorous, and it taken from physics / computer graphics.
- The actual formalism requires quite a lot of machinery to setup the right measure space
  and topology to talk about convergence of processes to produce brownian motion.

#### Information definition of weiner process / brownian motion

- (Continuity) For each time $t$, associate a random variable $W_t$ that is almost surely continuous in $t$.
- (Independent Increments) For any two times $s, t$ ($s \leq t$, then "random increment" $W_t - W_s$ is independent
  of any past state $W_p$ (for all $0 \leq p \leq s$)
- (Gaussian Incremenets) Each increment $W_t - W_s ~ N(0, t - s)$. That is, it is a normal distribution with mean 0,
  variance $(t - s)$.

#### Simulating Weiner process: Donsker's theorem

- Consider IID sequences $X_1, \dots X_n$.
- Define a continuous function $W[n](t) \equiv 1/\sqrt{n} \sum_{i=1}^{\texttt{floor}(tn)} X_i$ for $t \in [0, 1]$.
- **Donsker's theorem**: As $n \to \infty$, $W_n$ converges ()

# Forward versus backward euler

- Suppose we have a vector field $X$, initial point $x_0$, and we want to plot
  trajectories.
- We survey two classical algorithms, forward versus backward euler.
- [Reference](https://geometrycollective.github.io/monte-carlo/slides/Lecture11-StochasticDifferentialEquations-CMUMonteCarloFA23.pdf)

#### Forward euler

- $p$ is current "known" point, $q$ is next unknown point, $X(.)$ is the known vector field.
- $p + \epsilon X(p) \sim q$.
- This gives us the equation motion.

###### Stability analysis of Forward euler

- Suppse we have a 1D system, with $X(q) = aq$. (ie, exponential growth).
- Then, $p + \epsilon X(p) \sim q$ simplifies to $p + \epsilon a p \sim q$, or $p (1 + \epsilon a) \sim q$.
- If we relabel $p_{i+1} \equiv q, p_i \equiv p$, then we get: $p_{i + 1} \equiv p_{i} (1 + \epsilon a)$.
- Repeatedly applying, we get $p_n = (1 + \epsilon a)^n p_0$.
- This $\{ p_n \}$ sequence converges if $|1 + \epsilon a| < 1$.
- If $a > 0$, then it is impossible for this to be stable, because $\epsilon > 0$ (by defn), and therefore $(1 + \epsilon a) > 1$.
- If $a < 0$, then the exponential is damped, and the solver will converge if $\epsilon < 1/|a|$. That is,
  we step with size smaller than the exponential growth rate. 

#### Backward euler

- $(q - \epsilon X(q)) \sim p$.
- This requires us to solve for $q$. This is generally a nonlinar equation in $q$ due to the presence of $X(q)$,
  but this can be solved by using any black-box *equation* solver. 

###### Stability analysis of Backward euler

- Suppse we have a 1D system, with $X(q) = aq$. (ie, exponential growth).
- Then, $q - \epsilon X(q) \sim p$ simplifies to $q - \epsilon a q \sim p$, or $q (1 - \epsilon a) \sim p$.
- If we relabel $p_{i+1} \equiv q, p_i \equiv p$, then we get: $\equiv p_{i} \equiv p_{i + 1} (1 - \epsilon a)$.
- Repeatedly applying, we get $p_0 = (1 - \epsilon a)^n p_n$.
- Rearranging, we get $p_n = p_0 / (1 - \epsilon a)^n$.
- See that in this case, if $a < 0$, we will *always be stable*, because then the denominator will be of the form $1/v$ where $v > 1$.
- So, backward euler is *unconditionally stable* in the case of exponential decay.

# Uniform Boundedness Principle / Banach Steinhauss

- Consider a set of bounded linear operators $\mathcal F$. If $\mathcal F$ is pointwise bounded,
  that is, $sup_{T \in \mathcal F}\{ ||T(p)|| \}$ exists for all $p \in X$, then
  the family is norm-bounded: $\sup_{T \in \mathcal F} \{ ||T|| \}$ exists.

## Proof 1: Based on an ingenious inequality

- Reference: A really simple elementary proof of the uniform boundedness theorem by Alan D Sokal

##### Ingenious Inequality, Version 1

- Let $T: X \to Y$ be a bounded linear operator. Then for any $r \geq 0$ we have
  $\sup_{ ||x|| \leq r } ||Tx|| \geq ||T||r$.
- Proof: recall that $||T|| \equiv \sup_{||x|| = 1} ||Tx||$.
- Now see that $\sup_{ ||x|| \leq r } ||Tx|| \geq \sup_{ ||x|| = r } ||Tx||$.
- This can be rewritten as $r \sup_{ ||x|| = r } || T(x/r) ||$, but this $r \sup_{ ||\hat x|| = 1 } T(\hat x) = r ||T||$.

#### Ingenious Inequality, Version 2

- Let $T: X \to Y$ be a bounded linear operator, let $p \in X$ be any basepoint.
  Then for any $r \geq 0$ we have $\sup_{ y' \in B(p, r) } ||Ty'|| \geq ||T||r$.
- We rewrite the optimization problem as $\sup_{ ||x|| \leq r } ||T(p + x)||$.
- First, consider:  $\max{||T(p + x)||, ||T(p - x)||} \geq 1/2 [||T(p + x)|| + ||T(p - x)|| \geq ||T(x)||$.
- The last inequality follows from $||\alpha|| + ||\beta|| = ||\alpha|| + ||-\beta|| \leq ||\alpha + (-\beta)||$, that is,
  triangle inequality.
- Now we see that:

$$
\begin{aligned}
&\sup_{||x|| \leq r} ||T(p + x)|| = \sup_{||x|| \leq r} \max(||T(p + x)||, ||T(p - x)||)
&\sup_{||x|| \leq r} \max(||T(p + x)||, ||T(p - x)||) \geq \sup_{||x|| \leq r} ||T(x)||
&\sup_{||x|| \leq r} ||T(x)|| = ||T||r
\end{aligned}
$$

- and thus we get the bound that $||\sup_{||x|| \leq r} ||T(p + x) \geq ||T||r$.

#### Proof of theorem

- Suppose for contradiction that $\sup_{T \in \mathcal F} ||T|| = \infty$, which it is indeed
  pointwise bounded (for all $p$ $\sup_{T \in \mathcal F} ||Tp||$ is bounded).
- Then choose a sequence $T[n]$ such that $||T[n]|| \geq 4^n$. This is possible since the set is unbounded.
- Next, create a sequence of points, such that $x[0] = 0$, and $||x[n] - x[n - 1]|| \leq 3^{-n}$ (that is,
  $x[n]$ is a $3^{-n}$ radius ball around $x[n-1]$.
- See that this sequence is cauchy, and thus converges. In particular, let the limit be $L$.
  Then we can show that $||L - x[n]|| \leq 3^{-n}(1 - 1/3)) =  2/3  3^{-n}$.
- Also see that we have the bound $||T_n L || \geq 2/3 3^{-n} 4^n = 2/3 (4/3)^n$.
- Thus, $\lim_{n \to \infty} ||T_n L|| \to \infty$.
- But this contradicts the pointwise boundedness of $\mathcal F$ at the point $L$.  Hence proved.



## Proof 2 using Baire category
- Suppose that for every $x \in X$, $\sup_{T \in \mathcal F} ||T(x)|| < \infty$.
- We want to show that $\sup_{T \in \mathcal F} ||T|| < \infty$.
- For every integer $n \in \mathbb N$, we build the subset
  $X_n \equiv \{ x \in X : \sup_{T \in \mathcal F} ||T(x)|| \leq n \}$.
- Since for every $l \in X$, there is *some* $n_l$ such that $||T(l)|| < n_l$ (by assumption, $\mathcal F$ is pointwise
  bounded), we know that the sets $X_n$ cover $X$.
- Furthermore, each $X_n$ is closed: A cauchy sequence of points such that $||T x_n|| \leq k$  will converge to a limit $L$
  such that $||T L|| \leq k$.
- Thus, by the baire category theorem, there is a ball $B(p, r) \subseteq X_m$ for some $m \in \mathbb N$, $r > 0$.
- Now this means that the set $B(p, r)$ is norm bounded as $\leq m$.
- But this is a linear space, once we trap one ball we trap them all. By rescaling and translation, we can move the
  norm boundedness of $B(p, r)$ into the norm boundedness of $B(origin, 1)$ at which point we have proven that $||T(x)|| \leq infty||$.
- Now let $||u|| \leq 1$ and $T \in \mathcal F$. Calculate:

$$
\begin{aligned}
&||Tu|| \\
& = 1/r ||T (p + r u) - T(p)|| \\
& \text{(triangle inequality:)} \\
& \leq 1/r (||T(p + ru)|| + || T(p)||
& \text{($p + ru, p \in B(p, r)$)}  \\
& \leq 1/r (m + m)
\end{aligned}
$$

- This bound of $2m/r$ does not in any way depend on $T$ or $u$, then $\sup_{T \in \mathcal F} ||T|| < \infty$,
  which establishes the bound.


# Coercive operator

- This is called as the lax milgram theorem, but in lawrence and narici, it's a fucking lemma (lol).
- Suppose there is an operator $A : X \to Y$ whose norm is bounded *below*: That is, there exists a $k$
  such that for all $x$, $k||x|| \leq ||Ax||$.
- Intuitively, this forces $A$ to "spread vectors" out, making it one-one.
- Intuitively, this makes the inverse bounded, because the inequality "flips direction" when we consider the inverse operator.
- See that we do not require $A$ to be bounded! We will still get a bounded inverse operator.

#### Step 1: $A$ is one to one

- Suppose $At = 0$. We will show that this implies $t = 0$.
- $k ||t || \leq ||At||$. That is, $k ||t|| \leq 0$. Since $k > 0$, this implies $||t|| = 0$ or $t = 0$.

#### Step 2: $A^{-1}$ is bounded

- Define $A^{-1}(y) \equiv x$ when $Ax = y$.
- Since $k ||x|| \leq ||Ax||$, we write $Ax = y$, and thus $x = A^{-1} y$.
- This gives us $k || A^{-1} y || \leq y$.
- This means that $||A^{-1} y|| \leq (1/k) y$, thereby establishing the boundedness of $A$.
- Thus, $A$ is a bounded linear operator.


#### Claim: This is in fact sufficient: Every invertible operator $A$ with bounded inverse has such a lower bound $k$.

- Reverse the proof: take the bound of $A^{-1}$ to be $k$ and show that this lower bounds $A$.

- We can thus define $A^{-1} : Range(A) \to X$

# It suffices to check for weak convergence on a spanning set.

- Theorem: suppose $x[i]$ is a bounded sequence in $X$. Then, to check that $x[i] \to_w L$,
  it suffices to check on a spanning set $A \subseteq X$ such that $closure(span(A)) = X$.
- Proof: first, it easily suffices for linear combinations by triangle inequality.
- Next, to show it suffices for closures, we wish to show that $h(x[n]) \to h(L)$ given that $g(x[n]) \to g(x)$
  for all $g \in span(A)$.
- Let $h = \lim_j g[j]$ for some $g[j] \in X^\star$.
- Let us bound $|h(x[n]) - h(L)|$.
- This is equal to $|h(x[n]) - g[j](x[n]) + g[j](x[n]) + g[j](L) - g[j](L) - h(L)$
- Rearranging: $|(h(x[n]) - g[j](x[n])) + (g[j](x[n])  - g[j](L)) + (g[j](L) - h(L))|$.
- We bound each pair: $|h(x[n]) - g[j](x[n])|$ can be made arbitrary because $g[j] \to h$, and thus they are bounded
  pointwise since these are bounded linear functionals.
- $|g[j](x[n])  - g[j](L)$ can be made arbitrarily small because we know that $x[n] \to_w L$ on the set $A$.
- The third term $|g[j](L) - h(L))|$ can be made arbitrarily small because $g[j] \to h$ and these are bounded linear
  functionals.
- Thus we have shown that we can make stuff arbitrarily small, and we are done!


# Sequence that converges weakly but not strongly in $l^p$.

- Consider the sequence $e_1 = (1, 0, \dots)$, $e_2 \equiv (0, 1, \dots)$, and
  in general $e_i[j] = \delta_i^j$.
- Recall that to check weak convergence, it suffices to check on a basis of the dual space.
- We check on the basis $\pi_j (x) \mapsto x[j]$.
- Clearly, on such a basis, we see that $\lim_{n \to \infty} e_n[j] \to 0$, because after $n > j$,
  the sequence will be forever zero.
- However, see that this sequence does not strongly converge, since the basis vectors $e_i$ cannot be cauchy,
  since $||e_i - e_j|| = \sqrt(2)$ when $i \neq j$.
- The intuition is that weak convergence can only see converge "in a finite subspace", since we are
  considering what happens with bounded linear functionals.
- Thus, a sequence can appear to converge when restricting attention to any finite region of space, but cannot
  strongly converge.




# Axioms for definite integration

- [Pete Clark](https://math.stackexchange.com/a/56522/261373)'s notes on honors calculus
  provides a handy axiomatization of what properties the definite integral ought to satisfy.
- 1. If $f = C$ is a constant function, then $\int_a^b C = C (b - a)$.
- 2. If $f_1(x) \leq f_2(x)$ for all $x \in [a, b]$, then $\int_a^b f_1(x) \leq \int_a^b f_2(x)$.
- 3. If $a \leq c \leq b$, then $\int_a^b f = \int_a^c f + \int_c^b f$.

#### Proof of fundamental theorem of calculus from the above axiomatization

- Let $f$ be any integrable function over $[a, b]$. For $x \in [a, b]$, we define $F(x) \equiv \int_a^x f$. Then:
- (a) The function $F : [a, b] \to \mathbb R$ is continuous at every $c \in [a, b]$.
- (b) if $f$ is continuous at $c$, then $F$ is differentiable at $c$ and $F'(c) = f(c)$.
- (c) if $f$ is continuous and $F$ is any antiderivative of $f$, that is, $F'(x) = f(x)$, then
  $\int_a^b f = F(b) - F(a)$.
- Proof:
- First, by coninuity of $f$ and compactness of $[a, b]$, there exists a $M \in \mathbb R$ such that $|f(x)| \leq M$
  for all $x \in [a, b]$. If $M = 0$, then $f(x) = 0$ and thus from axiom 2 $F = 0$ and everything holds.
- Thus we assume that $M > 0$. For all $\epsilon > 0$, we take $\delta = \epsilon / M$.
- By the third axiom, we see that $F(x) - F(c) = \int_a^x f - \int_a^c F = \int_c^x f$.
- TODO.

# Quotient spaces of Banach space

- We will see why it is important for a subspace $M$ of a banach space $X$
  to be closed for $X/M$ to be banach.
- The algberaic properties of $+$ and $\cdot$ will go through for any subspace $M$ since they
  in no way depend on norm.
- The norm on $X/M$ will correctly interact with rescaling and triangle inequality also
  for any subspace $M$.
- However, to show that the norm is non-degenerate ($||x|| = 0$ iff $x = 0$) needs $M$ to be closed.


#### Norm on $X/M$

- We define the norm on $X/M$ as $||\overline{x}|| \equiv \inf_{m \in M} ||x + m||$.
  This is abbreviated to $||x + M||$.

#### Lemma: Norm on $X/M$ interacts correctly with rescaling
- $||\alpha \overline{x}|| = \inf_{m \in M} ||\alpha x + m||$.
- But we can replace $m \mapsto \alpha m$, giving $\inf_{m \in M} || \alpha x + \alpha m||$,
  which equals $\inf_{m \in M} \alpha  ||x + M|| = \alpha || \overline{x}||$.
- Thus, scalar product correctly rescales with norm.

#### Lemma: Norm on $X/M$ obeys triangle ineq

- The LHS is $||\overline{x} + \overline{y}|| = \inf_{m \in M} ||x + y + m||$.
- The RHS is $||\overline{x}|| + ||\overline{y}|| = \inf{k \in M} || x + k|| + \inf_{l \in M} ||y + l||$.
- We need to somehow "split" the $m$ in the LHS into $k$ and $l$.
- We do this sequentually. There must be a sequence of elements $k[i]$ such that
  $||\overline{x}|| \leq ||x + k[i]||$ such that $||x + k[i]|| \to ||\overline{x}||$.
- Similarly, there must be a sequence of elements $l[i]$ such that
  $||\overline{y}|| \leq ||y + l[i]||$ such that $||y + l[i]|| \to ||\overline{y}||$.
- Now, we see that $||overline{x} + \overline y|| \leq ||x + y + k[i] + l[i]||$.
- By triangle inequality, this is going to be $||\overline{x} + \overline{y}|| \leq ||x + k[i]|| + ||y + l[i]||$.
- Since this holds pointwise, it also holds in the limit, proving triangle inequality..

#### Theorem: proving that norm of zero is zero

- It is clear that $|| \overline 0|| = \inf_{m \in M} || 0 + m|| = || 0 + 0 || = 0$.

#### Theorem: proving that norm is nondegenerate.

- Suppose $||\overline{x}|| = 0$. We want to show that $\overline{x} = 0$, or $x \in M$.
- This means that $\inf_{m \in M} ||x + m|| = 0$.
- Thus there are a sequence of elements $m[i]$ such that $||x + m[i]|| \to 0$.
- This implies that $x + m[i] \rightarrow 0$, since this is happening using the norm of the underlying space.
- This means that $m[i] \to -x$.
- Now, we need to use the fact that $M$ is closed, to say that $-x \in M$, to get that $x \in M$.
- This gives us that $\overline{x} = 0$.


# Reisez Lemma

- Let $M$ be a closed proper subspace of a normed linear space $X$. Then for all $0 < \alpha < 1$,
  there exists a $p \in X$ (dependent on $\alpha$), such that $d(M, p) \geq \alpha$.
  That is, $\forall m \in M, d(m, p) \geq \alpha$.
- This is easy to establish for say $\mathbb R^2$. pick a unit orthogonal vector, it will be at least
  $1$ unit apart (or more) by pythogoras.
- This lemma provides a convenient substitute for orthogonality.

#### Proof via Hahn Banach
- Hahn banach is also a substitute for orthogonality.
- Pick a point $z \not in M$. Thus, $d(z, M) > 0$. Note that $d(-, M)$ is:
- (a) a sublinear function on $X$.
- (b) vanishes on $M$.
- (c) equals the projection onto $\mathbb R z \simeq \mathbb R$ on $M + \mathbb Rz$.
- By Hahn Banach, the portion of it that is linear extends to a linear
  functional on all of $M + \mathbb Rz$, and is dominated above by $d(-, M)$.
- Now, normalize the bounded linear functional so obtained to get a functional $f$ such that $|f| = 1$.
  Note that noramalization does not change the fact that $f(M) = 0$.
- Next, we build an "approximate normer" $z'$. This is an element $z'$ of unit norm such that
  $|f(z')| \sim |f|$. Such an element exists by definition of norm: $||f|| = \sup_{||x|| = 1} |f(x)|$.
  See that since $|z'| = 1$, we must surely have that $|f(z)| \leq ||f||$, thus $|f(z') \leq 1$.
  We claim that $|f(z')| = 1 - \epsilon$. (This is clear by clear and distinct perception since $f$ "behaves differently"
  along $Y$). This must happen, for if not, then $f(z') = 1$ for all $|z'| = 1$. This is patently untrue since $f(Y) = 0$,
  thus the unit vector along $Y$ must vanish at the very least.
- Now, consider $f(z' - m) = f(z') - f(m) = (1 - \epsilon) - 0 = 1 - \epsilon$.
- Next, estimate $|f(z' - m)| = |1 - \epsilon| = 1 - \epsilon$.
- This gives $1 - \epsilon = |f(z' - m)| \geq |f| |z' - m| = |z' - m|$.
- The first inequality follows from the defn of norm $|f| = \sup_k |f(k)|/|k|$, and thus $|f| < |f(k)|/|k|$, or $|f(k)| > |f||k|$.
- The second inequality follows from the fact that $|f| = 1$.
- [Reference](https://www.math.ucla.edu/~jmanaker/Expository/RieszLemma.html)

#### What about $\alpha > 1$?

- $\alpha > 1$ does not even hold in $\mathbb R^2$. If I pick $\alpha = 5$, there is no unit vector
  that is $5$ units away from the $x$-axis. A vector is at most $1$ unit away from the $x$ axis.

#### What about $\alpha = 1$?

- Apparently, this case holds for any reflexive space (double dual equals original space).
- To show counterexample, we need a non-reflexive space.
   consider $l_\infty$, space of sequences
  under max norm.
- Alternatively, pick $C[0, 1]$ under max norm.
- We begin by picking a subspace $X \equiv \{ f \in C[0, 1] : f(0) = 0 \}$. So $f$ is continuous and $f(0) = 0$.
- Let $M$ be the subspace of $X$ such that $\int_0^1 f(x) dx = 0$.
- We want to show that there exists **no function** $p \in X$ such that (a) $||p|| = 1$,
  (that is, $\sup_{x \in [0, 1]} p(x) = 1$ and (b) $d(p, m) \geq 1$ for all $m \in M$.

#### Pedestrian proof when $\alpha = 1$.
- If $d(p, m) \geq 1$, then we must have $d(p, 0) \geq 1$. This means that $\int_0^1 (p(x) - 0) \geq 1$,
  or that $\int_0^1 p(x) \geq 1$.
- Intuitively, since $p \in X$, we know that $p(0) = 0$, and since $p$ is continuous, it must "spend some time"
  around $0$, thereby losing some of the integral. Furthermore, since we know that $||p|| = 1$, the maximum
  integral any such function can attain is $1$.
- Since $p$ is continuous and $p(0) = 0$ (as $p \in X$), pick $\epsilon = 0.5$. Then there exists a $\delta$
  such that for all $0 \leq x < \delta$, we have that $p(x) < \epsilon = 0.5$. Thus, we can upper bound
  the integral of $p(x)$ over $[0, 1]$ by $\delta \times 0.5 + (1 - \delta) \times 1$. Ie, we surround
  $p$ by two rectangles, one of height $0.5$, one of height $1$, since we have the bounds.
  Since $\delta > 0$, we can see that $\int_0^1 p(x) dx < 1$ from the above estimate.
- Thus, this means that $d(p, m) < 1$, thereby violating the claim that we can find such a $p$ such that
  $d(0, p) \geq 1$. Hence proved!

#### Slightly more sophisticated proof when $\alpha = 1$.
- The same setup. We consider the integral operator $F: X \to \mathbb R$, defined as $F(f) \equiv \int_0^1 f(x) dx$.
- We note that $M = ker(f)$.
- We note that $||F|| \geq 1$. (In fact, $||F|| = 1$, since the function is maximized by being evaluated
  on $one(x) = 1$ which lies on the unit sphere).
- We note that $d(f, M) = |F(f)|/||F||$. That is, the distance of a point to the kernel of an operator $F$
  is the norm of $F(x)$ rescaled by the norm of $F$.
- We need an estimate on $|F(f)|$. By the above argument, we know that $|F(f)| < 1$ by continuity of $f$,
  $f(0) = 0$, and that $f(x) < 1$ for all $x$ (as $||f||  = 1$).
- Combine the two estimates to see tha $d(f, M) = (<1)/(>1)$, which is indeed less than $1$. Done.


# Using LLL to discover minimal polynomial for floating point number

- Explain by example. Let floating point number $f = 1.4142$.
- Clearly, this has a minpoly of $10000x - 14142 = 0$ with coefficients in $Z[x]$.
- However, we know that the correct minpoly is $x^2 - 2 = 0$.
- What's the difference in these two cases? Well, the correct minpoly has "small" coefficients.
- How do we find such a minpoly using LLL?
- Key idea: Build vectors (in our case) of the form $b_0 \equiv (1, 0, 0, 1000)$,
  $b_1 \equiv (0, 1, 0, 1000f)$, and $b_2 \equiv (1000f^2)$.
  Then LLL, on trying to find a shorter basis for these, will try very hard to make the third
  component smaller. It will do this by changing the basis vectors to $b'_0 \equiv b_0, b'_1 \equiv b_1$,
  and $b'_2 \equiv b_2 - 2b_0 = (-1, 0, 1, 1000(f^2 - 2)$. Since $f^2 - 2 \sim 0$, the length of $b'_2$
  is much smaller than $b_2$, granting us a shorter basis!
- In general, given some rational number $\theta$, we build `n` basis vectors `v_i` of dimension `n+1`
  of the form `v_i[i] = 1`, `v_i[n] = 1000(θ^i)`, and `v_i[-] = 0` otherwise.
- LLLing on these vectors `v_i` will attempt to find an integer relation on the last
  coefficient, which will be the minpoly.

# Total Boundedness in a metric space

- A set $A$ is totally bounded iff for any $\epsilon$, there exists a
  **finite** $\epsilon$ net $N_\epsilon$.

#### Totally bounded implies bounded

- Let $S$ be a totally bounded set. We want to establish a uniform bound $M$.
- Pick some $\epsilon$. We then get a finite number of points $N$ such that any point in $x$ is $\epsilon$ away from $N$.
- Any two points in $N$ can be at most $N\epsilon$ apart.
- Thus the total distance between any two points $s, t \in S$.
- Let $s, t$ be closest to points $n, n' \in N$.
- Thus $d(s, t) \leq d(s, n) + d(n, n') + d(n', t)$ all of which is bounded by
  $\epsilon + N\epsilon + \epsilon$ which is less than $(N + 3) \epsilon$.
- Thus we have established a bound of $(N + 3) \epsilon$.

#### For $\mathbb R$, bounded implies totally bounded

- Say set $S$ is bounded by distance $M$.
- Trap $S$ inside an interval of side length $M$, WLOG suppose interval is from $[0, M]$.
- For any adverserial $\epsilon$, pick points at $[0, \epsilon, 2\epsilon, \dots, M]$.
  These points are the epsilon net which contain $M$:$S \subseteq M \subseteq N_\epsilon$
- The net only needs $M/\epsilon$ points which is finite.
- See that this holds more generally for any $\mathbb R^n$ where we trap in a
  hypercube and sprinkle points.

#### In infinite dimensions, bounded need not be totally bounded.

- Classic example, sphere in $l^2$. It's clearly bounded by a constant $2$.
- we claim this is not totally bounded.
- Note that any two vectors $e_i, e_j$ have distance $\sqrt(2)$.
- Note that we have an infinite number of basis vectors $e_1, e_2, \dots$.
- Suppose it is totally bounded. Pick $\epsilon = \sqrt(2)/9999$ as an adversary. We get a finite
  neighborhood set $N_1$.
- Thus, some point in $n \in N_1$ must have an infinite number of basis vectors trapped in it.
- so there must be two basis vectors in it, $e_i, e_j$ such that $e_i \neq e_j$.
- We must have that $d(e_i, e_j) < d(e_i,  n) + d(n, e_j)$ by triangle inequality.
- This gives us $\sqrt(2) < \sqrt(2)/9999 + \sqrt(2) / 9999$ which is a contradiction.
- Thus, the sphere is not totally bounded.

#### compact => closed + totally bounded in infinite dim also

- Let $S$ be a compact set.
- it is closed by the usual argument.
- We claim $S$ is totally bounded.
- Let adversary pick $\epsilon$.
- We must establish a finite number of points $N_\epsilon$ such that any point in $S$
  is in an $\epsilon$ neighbourhood of some $n \in N_\epsilon$.
- Reread that. that's literally compactness.
- Pick an open cover $O$ consisting of an $\epsilon$ ball for each point $s \in S$.
- Extract a finite subcover from this.
- This finite subcover is the finite $\epsilon$ net.
- Thus done. Compact is totally bounded.

#### closed + totally bounded => sequentially compact in infinite dim also

- Let $S$ be a closed and totally bounded set.
- We wish to show that it is sequentially compact.
- Let $x_i$ be a sequence in $S$.
- Perform the classical Bonzalo Weirstrass bisection construction.
- Since $S$ is totally bounded, we can pick any $\epsilon$ and get a finite epsilon net.
- We claim that a closed subset of a totally bounded set is also totally bounded.

```py
def mk_cauchy_sequence(S):
  k = 1
  while True:
    s = choose(S)
    yield s
    Nk = finite_epsilon_net(S=S, epsilon=1/2^k)
    # n ∈ Nk such that n has an infinite number of points from $S$ in
    # the epsilon ball around $n$.
    n = hilbert-epsilon-choose(|{ n ∈ N : S ∩ Ball(n, epsilon) }| = infty)
    S = Ball(n, epsilon) # restrict to ball that has the inif
    k += 1
```



# Holonomic v/s non holonomic constraints

- A set of constraints such that the system under consideration becomes $TM$ where $M$ is the position space
  and $T_p M$ is the allowed velocities at position $p$ is a holonomic system
- A set of constraints such that the system under consideration *cannot* be thought of as $TM$ where $M$
  is the allowed positions. So we are imposing some artifical restrictions on the velocity of the system.
- Another restriction one often imposes is that constraint forces do no work.
- Under these assumptions, D'alambert's principle holds: the physical
  trajectory of the system is a constrained optimization problem: optimize the
  action functional of the free system restricted to paths lying on the
  constraint submanifold.
- [Reference: SYMPLECTIC GEOMETRY AND HAMILTONIAN SYSTEMS by E Lerman](https://faculty.math.illinois.edu/~lerman/467/v3.pdf)

# The Plenoptic Function

- What can we see because of light?
- Key idea: at each point $(x, y, z)$, we should be able to know, for all wavelenghts $\lambda$, the intensity
  of the wavelength in all directions $(\theta, \phi)$. Even more generally, this can vary with time $t$.
- Intuition: we should be able to reproduce at all points in spacetime, what happens if one builds a camera!
- This function $P(\theta, \phi, \lambda, t, x, y, z)$ is called as the *plenoptic function*.
- Notice that when one builds a pinhole camera, what one is doing is to, in fact, use the pencil
  of rays at that point to capture an image! Thus, the plenoptic function contains *all possible*
  pinhole images at all positions.
- The key conjecture of the paper "The plenoptic function and the elements of early vision" is that the
  visual cortex is extracting local changes / derivatives of the plenoptic function.

## Crash Course Radiometry
- Irradiance at a point: density of radiant flux (power) per unit surface area.
- Radiance at a point in a direction: density of radiant flux (power) per unit surface area per unit solid angle.

## Light field rendering
- See that if we restrict to only radiance of light at a fixed time $t_0$, then we have $(x, y, z, \theta, \phi)$,
  a 5 dimensional function.
- Also note that if there is no obstruction, then the radiance does not change along lines. So we can quotient
  $(x, y, z)$ to get a lower dimensional 4D field, given by
  $(\texttt{pos}_\theta, \texttt{pos}_\phi, \texttt{look}_\theta, \texttt{look}_phi)$.
- This 4D field is called as a light field.
- Alternatively, we can parametrize these by $(x_1, y_1)$ and $(x_2, y_2)$, and the paper canonically
  calls these as $(u, v, s, t)$. This coordinate system they call a _light slab_, and represents light starting
  from the point $(u, v)$ at the first plane and ending at $(s, t)$ at the second plane.

# Precision, Recall, and all that.

- Setting: we have some theorem goal $g$, a dataset of mathematical lemmas $D$, a set of actually useful
  lemmas $A$, and a set of predicted lemmas $P$.
- We want to provide a good measure of how "good" $P$
  is with respect to the ground truth $A$.
- We begin by defining *precision*, which is the fraction of $P$ that was correct: $|P \cap A|/|P|$.
  Probabilistically, this can be seen as `P(actual|predicted)`.
- Simlarly, we define *recall* as the fraction of `A` that was correctly predicted: $|P \cap A|/|A|$.
  Probabilistically, this is `P(predicted|actual)`.
- Let us now change the setting a little bit, where we swap the set $P$ for a \emph{sequence} over the
  full universe of lemmas $A$.
- We can get a set by truncating $P$ at some threshold.
  So we will define `precision@k` to be the precision of the set $P[:k]$.
- We note that recall as a function of k, `recall@k` is non-decreasing. As we see more predictions, we can
  only get more actually useful things. See that recall has a fixed denominator (the size
  of the number of actually useful things).
- Since `recall@k` is non-decreasing, we can build an inverse, `k@recall(r)`. For a given level of recall `r`,
  we map to the smallest $k$ (smallest number of items we need to take from the ranking) to get that level of recall.
- This lets us define a precision-recall function, where `precision@recall(r) = precision@k(k@recall(r))`.

#### Precision, Recall formulae

- Suppose for a given goal $g$, we have 3 correct premises `a, b, c`. The universe has premises `a, b, c, x, y, z`.
  Our model predicts premises in the ranking `x, a, y, b, c, z`. Then we summarize this as follows:

```
Rank | Val | Prec | Rec
1    |  x  | 0    | 0/3
2    |  a  | 1/2  | 1/3
3    |  y  | 1/3  | 1/3
4    |  b  | 2/4  | 2/3
5    |  c  | 3/4  | 3/3
5    |  z  | 3/5  | 3/3
```

- Note that recall is monotonically non-decreasing, while precisoin both increases (`0 -> 1/2`) and
  decreases (`3/4 -> 3/5`).
- We introduce an auxiliary function delta, $\delta(i) \equiv \text{lemma at i is correct}$.
  This lets us write the above quantities as follows:
- Let $s(n) \equiv \sum_{i=0}^n \delta(i)$.
- The total number of correct elements is $s(N)$ where $N$ is the total number of correct premises.
- The precision at $k$ is given by $p(k) \equiv s(k)/k$. The recall at $k$ is given by $r(k) \equiv s(k)/s(N)$.
- Now note that the discrete difference $dr(k) = r(k) - r(k-1)$, which equals $(s(k)-s(k-1)/s(N)$, which is $\delta(k)/s(N)$.

#### Mean Average Precision

- The best the `precision@recall` function can be is a flat line with `precision=1` for all levels of recall.
- Deviation from this tells us how much worse our model is from the best model.
- So, let's compute the area under the `precision@recall` curve. This is going to be the average precision,
  $ap \equiv \int_{r=0}^1 p(r) dr$.
- Recall that the "best" precision will always have `p(r) = 1`. Thus the theoretical maximum of this value
  we can have is $ap = \int_{r=0}^1 1 dr = 1$. This gives us a good scale, where $0 \leq ap \leq 1$.
- We use recall as a way to "standardize" across the size of the dataset by the recall.
- Let's change of variables into $k$. So we want to change $r$ into $r(k)$.
- This will change the bounds of integration.
- The lower limit is given by $0 = r(l)$ which solves for $l = 0$.
- The upper lmit is $1 = r(u)$ which solves for $u = N$ (the size of the dataset).
- This also changes $dr$ to $dr(k)dk$.
- In the discrete case, we set $dk = 1$, and $dr(k)$ becomes $r(k) - r(k-1)$.
  This is $\Sigma_{i=0}^k \delta(i)/s(N) - \Sigma_{i=0}^{k-1} \delta(i))/s(N)$ which evaluates to $\delta(k)/s(N)$.
- This gives us the discrete calulation of $ap$ to be $ap \equiv \Sigma_{k=1}^N p(k) \delta(k)/s(N)$.


##### Mean Average precision at K.

- I believe this to be an incoherent concept; Recall that we chose to define average precision
  as the _area under the precision recall curve_.  This is a sensible quantity, because it's a normalized
  value (recall is between $0$ and $1$). We got the expression in terms of $k$ _via a change of variables_.
  We **did not** start at $k$! We started from $r$ and got to $k$.
- We can try to hack the expression for $ap$ to artifically create $ap@K$. Let's try.
- First, to go from $k$ to $r$, we find a number $r_k$ such that the recall at $r(k) = r_k$
- Next, we calculate $ap@K \equiv \int_0^{r_K} p(r) dr$.
- We must now find we must find new lower and upper bounds in terms of $k$.
- The lower bounds needs us to find  `0  = r(l)` or `l = 0`.
- The upper bound needs us to find `r_K = r(u)`, or `u = K`.
- We will next have to calculate $dr(k) dk$. Previously, we set $dk = 1$, and we calculated $dr(k) \equiv r(k) - r(k-1)$.
  This will give us $dr(k) \equiv \delta(k)/s(N)$. But note that $s(N)$ will count _all_ documents, not just limited to the top-K.
  So let's used $s(K)$ instead --- a hack!
- Combining these, we get the formula to be $ap@K \equiv \int_{0}^K p(r(k)) dr(k) = \Sigma_{k=0}^K p(k) \delta(k) / s(K)$.
- `ap@K` feels very unprincipled, and I don't feel that this carries mathematical weight.
- Is there an alternative derivatio that sheds light on why this formula makes sense?

#### R-precision

- Recall that the recall is a nondecreasing function of $k$. The precision can vary any way it wants with respect to $k$.
- We will try to find a point where precision equals recall.
- Consider the equation $p(K) = r(K)$. Using our previous formulation, this reduces to
  $s(K)/K = s(K)/s(N)$. This of course gives us $K = s(N)$.
- So, at the index $K$ which is equal to the total number of correct lemmas, we will have the precision equal the recall.
- This value is called as the *R* precision: the precision $p(K)$ at the first index $K$ such that $r(K) = 1$.
- Empirically, this value $R$ correlates well with mean average precision.


#### $F_1$ Score

- A sensible derivation is offered by Van Rijsbergen in his PhD thesis.
- First, a quick and dirty definition: $F_1$ is the harmonic mean of precision and recall.
- This gives us `2/(1/p + 1/r)`, which works out to `2/[(tp + fp)/tp + (tp + fn)/tp]`.
- This simplifies to `2tp/(2tp + fp + fn)`.
- Now consider the quantity `E := 1 - F`. Think of `E` as `error`. This works out to `(fp + fn)/(2tp + fp + fn)`.
- See that this quantity works out the symmetric difference of the $A$actual and $P$redicted set divided by the
  sum of the sizes of the $A$ctual and $P$redicted set! $A \Delta P \equiv fp + fn$, and $|A| = tp + fn$, and
  $|P| = tp + fp$.
- Thus, the full expression for $E$ becomes $E \equiv (|A| \Delta |P|) / [|A| + |P|]$ which is a genuinely sensible quantity!

# Heine Borel

- Theorem: closed bounded subset of $\R^n$ is compact
- We will prove it for $\R$ and leave the obvious generalization to the reader.
- Key idea: recall that for metric spaces, compactness and sequential compactness are equivalent,
  so the proof must follow some ideas from Bolzano Weirstrass (sequence in closed bounded set has
  convergent subsequence).
- Recall that *that* proof goes by bisection, so let's try to bisect some stuff!
- Also recall why this fails in infinite dimensions: you can bisect repeatedly in "all directions" and
  get volume (measure) to zero, without actually controlling the cardinality. There is no theorem that says
  "measure 0 = single point". So, the proof must rely on finite dimension and "trapping" a point.
- Take an interval, say $[0, 1]$ and take a cover $\mathcal C$. We want to extract a finite subcover.
- For now, suppose that the cover is made up only of open balls $B(x, \epsilon)$. We can always reduce
  a cover to a cover of open balls --- For each point $p \in X$ which is covered by $U_p$,
  take an open ball $B_p \equiv B(p, \epsilon_p) \subseteq U$. A finite subcover of the open balls $\{ B_p \}$ tells us which $U_p$ to pick from the original cover.
- Thus, we shall now assume that $C$ is only made up of epsilon balls of the form $C \equiv \{ B(p, \epsilon_p) \}$.
- If $C$ has a finite subcover, we are done.
- Suppose $C$ has no finite subcover. We will show that this leads to a contradiction.
- Since we have no finite subcover, it must be the case that at $I_0$, there are an infinite number of balls $\{ B \}$.
  Call this cover of infinite balls $C_0$.
- Now, let the interval $I_1$ be whichever of $[0, 1/2]$ or $[1/2, 1]$ that has infinitely many balls from $C_0$.
  One of the two intervals must have infinite many balls from $C_0$, for otherwise $C_0$ would be finite, a contradiction.
  Let $C_1$ be the cover of $I_1$ by taking balls from $C_0$ that lie in $I_1$.
- Repeat the above for $I_1$. This gives us a sequence of nested intervals $\dots \subset I_2 \subset I_1 \subset I_0$,
  as well as nested covers $\dots \subset C_2 \subset C_1 \subset C_0$.
- For each $i$, pick any epsilon ball $B_i(p_i, \epsilon_i) \in C_i$.
  This gives us a sequence of centers of balls $\{ p_i \}$. These centers must
  have a coverging subsequence $\{ q_i \}$ (by bolzano weirstrass) which converges to a limit point $L$.
- Take the ball $B_L \equiv (L, \epsilon_L) \in C$ which covers the limit point $L$.
- Since the sequence $\{ q_i \}$ is cauchy, for $\epsilon_L$, there must exist a natural $N$ such that for all
  $n \geq N$, the points $\{ q_n : n \geq N \} \subseteq B_L$.
- Thus, we only have finitely many points, $q_{\leq n}$ to cover. Cover each of these by their own ball.
- We have thus successfully found a covering for the full sequence!

# The conceit of self loathing

>  Self-contempt is defined as the conceit of thinking "I am inferior" and
>  involves a sharp sense of one’s baseness and inadequacy vis-a-vis others.
>  There is even an excessive variety of it called "self-abasement"
>  which is a conceit wherein, asserts that one is inferior even to inferior
>  persons.

> Conceit, as it is generally understood, is waving one’s flag or banner highest
> over others and drawing attention to oneself. Even if one
> is asserting one’s inferiority, one is still engaged in a display of
> self-advertisement.

> "I am," "I shall be," "I might be," and "would that I
> might be." These four possibilities describe how I conceive of myself at present,
> how I might be in the future, how I might imagine myself either in doubt or
> speculation, and how I might plan to be.


# Inverse scattering transform

- Useful to solve nonlinear PDE
- classical example is the shock wave equation / burges equation: $u_x + u u_t = 0$
- [References](https://en.wikipedia.org/wiki/Inverse_scattering_transform)

### KdV equation

- Equation for shallow waves.
- Example of nonlinear PDE that can be solved exactly.
- The geometry of the KDv equation describes this on a circle


# Differentiating through sampling from a random normal distribution

- Credits to [Edward Eriksson) for teaching me this.
- The key idea is that since we can write the normal distribution with parameters
  mean $\mu$ and variance $\sigma$ as a function of the standard normal distribution.
  We then get to believe that the standard

- $y = f(\sigma z)$ where $z \sim N(0, 1)$.
- Then, by treating $z$ as a constant, we see that $dy/d\sigma = f'(\sigma z) \cdot z$ by chain rule.
- That is, we treat $z$ as "constant", and minimize the $\sigma$.
- My belief in this remains open until I can read a textbook,
  but I have it on good authority that this is correct.
- How does this relate to the VAE optimisation? It's the same trick, where we claim that
  $sample(N(0, 1))$ can be held constant during backprop, as if the internal structure of the $sample$
  function did not matter. Amazing.


```py
#!/usr/bin/env python3
import numpy as np

sigma = 1.0

# # function we are minimising over
# def f (x): return - x*x
# # derivative of function we are minimising over
# def fprime(x): return -2*x

# function we are minimising over
def f (x): return np.sin(x + 0.1)

# derivative of function we are minimising over
def fprime(x): return np.cos(x + 0.1)

# f(sigma z) = f'(sigma z) z.
# \partial_\sigma E[f(X_\sigma)] = E[\partial_\sigma f(X_\sigma)]
for i in range(1000):
    z = np.random.normal(0, 1)
    # sample from normal distribution with mean 0 and standard deviation sigma
    sz = sigma * z
    # evaluate function at x
    fx = f(sz)
    gradfx = fprime(sz)

    # update sigma
    # z2 = np.random.normal(0, 1)
    dsigma = gradfx * z

    print("z = %5.2f | f = %6.2f | df = %6.2f | sigma = %6.2f | dsigma = %6.2f" %
        (z, fx, gradfx, sigma, dsigma))
    sigma = sigma - 0.01 * dsigma
```


# BOSCC Vectorization

- Branch on superword conditional codes.

# Autodiff
- Activity analysis

# Vector Bundles and K theory, 1.1

- We define a sphere (in 3D) by all points with distance $1$ from the original. Call this $M$.
- The tangent plane $T_p M \equiv \{ v | v \perp p \}$.
- Define $TM \equiv \cup_{x \in M} T_M$
- We have a projection map $p$ from $TM \to M$ which sends the point $(x, v)$ to $x$.
- for a point $x \in X$, we define $U(x)$ to be the hemisphere with apex $x$. This is the portion of the sphere
  on one side of the hyperplane that is perpendicular to $x$.
- We want a map $p^{-1}(U(x))$ to $U(x) \times p^{-1}(x)$. The right hand is the same as $U(x) \times T_x M \times \{ x \}$,
  which is the same as $U(x) \times T_x M$.
- for a given $(y, v) \in TM$, that is, for a given $v \in T_y M$, we map it to $U(x) \times T_x M$ by sending $y \mapsto y \in U(x)$,
  and by orthogonally projecting the vector $v \in T_y M$ onto the tangent plane $T_x M$.
- Intuitively, we keep the point $y$ the same, and map the tangent plane $T_y$ to its orthogonal projection onto $T_x$.
- Since we know the basepoint $y$, it is clear that we can reconstruct the projection operator from $T_y$ to $T_x$, and that this
  operator is linear and surjective, and thus invertible.
- This shows us that what we have is really a fiber bundle, since we can locally straighten  the $p^{-1}(U(x))$ into the trivial bundle.
- Proof?

# Equicontinuity, Arzela Ascoli
- A sequence/family of functions are said to be equicontinuous if they vary equally in a given nbhd
- Necessary for Arzela Ascoli
- A subset of $C(X)$, space of continuous functions on a compact Hausdorff
  space $X$ is compact iff if it is closed, bounded, and equicontinuous.
- Corollay: a sequence of $C(X)$ is uniformly convergent iff it is equicontinuous.
- Thus, an equicontinious family converges pointwise, and moreover, since it is uniform convergence, the limit will also be
  continuous.

#### Uniform boundedness Principle

> The uniform boundedness principle states that a pointwise bounded family of
> continuous linear operators between Banach spaces is equicontinuous.

#### Equicontinuity of metric spaces

- Let $X, Y$ be metric space.
- The family $F$ is equicontinuous at a point $p \in X$ if for all $\epsilon > 0$,
  there is a $\delta > 0$ such that $d(f(p), f(x)) < \epsilon$ for all $f \in F$
  and all $d(p, x) < \delta$.
- Thus, for a given $\epsilon$, there is a uniform choice of $\delta$ that works for all *functions*.
- It's like uniform continutity, except the uniformity is enforced acrorss the _functions_ $f_i$, not on the
  points on the domain.
- The family $F$ is pointwise equicontinuous iff it is equicontinuous at each point $p$.



# Sobolev Embedding Theorem 

- Intuitive Statement: Bound on norm of derivatives gives bound on function norm
- Intuition: On a closed compact set, function can only grow as much as the derivative lets it grow.


# Eikonal Equation [WIP]

#### 1D
#### nD

- Since everything is determined by 1D parametrization (curves)
- $|\nabla \phi(r)| = 1/v(r)$
- $r$ is position in space.
- $v(r)$ is the speed of light at position $r$.
- $\phi(r)$ represents the travel time of a wavefront to reach $r$.
- So, the gradient of the travel time is

#### References
- [Video on eikonal equation](https://www.youtube.com/watch?v=G1LOsvGGQos)



# Practical example of semidirect product

```
-- | represents a string with indexes into it.
type IndexedString = (String , [Nat])
```

- If we combine the strings together as `t = s1 + s2`, how do the indexes of `s1, s2` change to become an index of `t`?

```
instance Semigroup IndexedString where
  (IndexedString s1 ixs1) <> (IndexedString s2 ixs2) =
    (s1 <> s2, ix1 <> ((+) (length s1)) <$>  ixs2)
```
- See that we "twist" the indexes of the second by the length of the string.
  Because we are sticking the "origin" of the second to the "tip" of the first,
  we need to change the indexes to point to the "new" origin.
- One can check that this is going to be a semidirect product.
- In general, if we have data, pointers into the data, and ways to combine the data,
  then the bundled up abstraction of (data+pointers into data) should have a semidirect
  structure.

# Algebraic graph calculus
- http://gabarro.org/ccn/algebraic_graph_calculus.html
- The gradient corresponds to the incidence matrix, which takes values on
  vertices and spits out values on edges.

# Change of basis from triangle x y to barycentric

- If we have $\int_T f(x, y)dx dy$ for a triangle $T$, we would often like to change to
  barycentric coordinates to compute $\int_{p=0}0^1 \int_{q=0}^p f(p, q) dp dq$. But what is the relationship
  between these two integrals?
- Note that when we parametrize $p, q$ by as $\{ (p, q) : p \in [0, 1], q \in [0, p] \}$, we are
  drawing a right triangle whose base is on the $x$ axis.

# Lean4 access metam and so forth

```
#eval show Lean.MetaM _ from do
  return 0
```

# Harmonic function

- Solve Poisson's equation (wave equation) : `Δ f = 0`.
- is a vector field $V = ∇f$ arose from a potential, then it
  satisfies $∇ x(∇f) = 0$ (by the exact sequence).

# Lax Milgram theorem

- The theorem states that given a system $B(u, -) = f(-)$, where $B$
  is a linear, bounded, coercive operator, then a unique solution exists
  and this solution depends continuously on $f$.
- This is useful to solve elliptic equation problems, for which one can find
  some kind of inner product $B(., .)$ that represents "energy".

# Why L2 needs a quotient upto almost everywhere

- We want a norm to have the property that $|x| = 0$ if and only if $x = 0$.
- But in a function space, we can have nonzero functions taht have measure zero. eg. the function
  that is $1$ on $\mathbb Q$ and zero everywhere else.
- Thus, such functions are $f \neq 0$ such that $|f| = 0$.
- To prevent this and to allow the L2 norm to really be a norm, we quotient by
  the closed subspace of functions such that $|f| = 0$.
- This has the side effect such that $f = g$ iff $|(f - g)| = 0$, or that functions agree
  almost everywhere.

# Repulsive curves

#### Gradient depends on norm

- consider a function $f: \mathbb R^n \to \mathbb R$ and an energy $e: (\mathbb R^n \to \mathbb R) \to \mathbb R$.
- We want to optimize $df/dt = - \nabla e(f)$.
- however, what even is $\nabla$?
- Recall that $de$ is the differential which at a point $f$ on the space $\mathbb R^n \to \mathbb R$, in a tangent direction $u \in \mathbb R^n \to \mathbb R$,
  computes  $de|_f(u) \equiv \lim_{\epsilon \to 0} (e(f + \epsilon u) - e(f))/\epsilon$.
- Now the gradient is given by $\langle grad(e), u \rangle_X \equiv de(u)$. So the gradient is the unique vector such that the inner product with the
  gradient produces the value of the contangent evaluated in that direction.
- Said differently, $\langle nabla(e), -\rangle = de(-)$. This is a Reisez like representation theorem.
- Note that asking for an inner product means we need a hilbert space.
- One choice of inner product is given by $L^2$, where $\langle u, v \rangle_{L^2} \equiv \int \langle u(x), v(x) \rangle dx$.
- More generaly, we can use a Sobolev space, where we define the inner product given by
  $\langle u, v\rangle_{H^1} \equiv \langle \nabla u, \nabla v\rangle_{L^2}$,
  which can also be written as $\langle \nabla u, v\rangle_{L^2}$.
- Similarly, for the sobolev space $H^2$, we would use $\langle u, v\rangle_{H^2} \equiv \langle \nabla u, \nabla v\rangle_{L^2}$. which is equal
  to $\langle \nabla^2 u, v \rangle_{L^2}$.
- In general, we can write our inner product as something like $\langle Au, v\rangle_{L^2}$.

#### Solving heat equation with finite differences

- Solving $df/dt = \nabla f = d^2 f / dx^2$.

> If we try to solve this equation using, say, explicit
> finite differences with grid spacing h, we will need a time step of size O(h 2)
> to remain stable—significantly slowing down computation as the grid is refined


#### Different norm is good for different situations

- TODO

#### Tangent point energy

- Key intuition: want energy that is small for points that are "close by" in terms of $t$ on the knot,
  want energy that repels points on the knot that are far away in terms of $t$ by close by in terms of $f(t)$.
- TODO



# Why NuPRL and Realisability makes it hard to communicate math

- [Superb answer by jon sterling](https://proofassistants.stackexchange.com/questions/1012/can-mathematical-formalizations-in-nuprl-be-trusted-as-correct-in-the-greater-ma/1046#1046)


> To me the difficulty with relating Nuprl to mathematics is basically one of
> methodology. As Andrej says, Nuprl's Computational Type Theory is based on
> "truth in one model"; as a result, there are many things that are true in
> this specific model that are false in the category of sets, false in many
> categories of presheaves, and false in many categories of sheaves. This is
> not the fault of (e.g.) realizability semantics, but rather the fault of
> confounding syntax and semantics. Both are important, but semantics benefits
> from multiplicity --- and the multiplicity of semantics is embodied in
> syntax. We can therefore expect strange results if we say that syntax is just
> a way to speak about one single example of semantics.


> So my aim is not to say "realizability is bad" --- realizability is clearly
> very good. But I think it is bad on balance to base a proof assistant on one
> single model (bad in ways that COULD NOT have been anticipated [clarification:
> by that community] in the early 1980s when this was going on!) because it
> limits the applicability of your results.

> Because Nuprl incorporates axioms that are not true in ordinary math, nor in
> the relative ordinary math of topoi, we cannot take a Nuprl proof about groups
> and use it as evidence to a "proper mathematician" for the truth of that
> statement about groups in a way that applies to that mathematician's work. This
> limits the ability to communicate and re-use results, but that is to me the
> entire point of mathematics.

> I want to end by saying that my perspective on mathematics is not the only one.
> Nuprl is much inspired by the ideas of L.E.J. Brouwer who took a very different
> viewpoint --- a proof in Brouwer's style about groups also does not necessarily
> lead to evidence that a mathematician would accept for the truth of that
> statement about groups. But Brouwer's perspective was that all the
> mathematicians were wrong, and that only he was right. If that was actually so,
> then one could not blame him for doing his proofs in a way that was not
> backward compatible.

> Therefore, the question that Nuprl raises is nothing less than: is mainstream
> mathematics wrong? Back when I was building tools based on Nuprl, I believed
> that normal mathematics was wrong. I no longer believe that though.

# Lean does not allow nested inductive families


- The checker is defined in terms of reduction to plain inductives, although
  the reduction itself is not performed before going to the kernel (it was in
  lean 3 but this lead to performance issues).
- The recursor for the type is basically "whatever the analogous mutual
  inductive would have".

```
inductive Const : Type _ | mk
inductive Const1 (t: Type _) : Type _ | mk : Const1 t
inductive E : Const → Type
| mk : {c : Const} → (args : Const1 (E c)) → E Const.mk
-- (kernel) invalid nested inductive datatype 'Const1',
-- nested inductive datatypes parameters cannot contain local variables.
```


# Weakly implicit arguments in Lean

```
variables {α : Type} (f : α → α)
def injective {α Β: Type} (f: α → β) : Prop :=
  ∀ {{x y}}, f x = f y → x = y -- NOTE: weakly implicit
def injective2 {α β : Type} (f : α → β) : Prop :=
    ∀ {x y}, f x = f y → x = y -- NOTE: implicit

def foo (h: injective f) : false := sorry
example (h: injective f) : false :=
begin
  have := @foo,
  unfold injective2 at *,
  exact this f h
end


def bar (h : injective2 f) : false := sorry
example (h : injective2 f) : false :=
begin
  have := @bar,
  unfold injective2 at *,
  exact this f h
end
```

The error becomes:

```
type mismatch at application
  this f h
term
  h
has type
  f ?m_1 = f ?m_2 → ?m_1 = ?m_2
but is expected to have type
  ∀ {x y : α}, f x = f y → x = y
```

# Big list of elf file munging / linker / ABI

- `nm`: list symbols in file.
- Useful tools are available at [binutils](https://www.gnu.org/software/binutils/)
- `readelf -a <file>`: see everything in an ELF file.
- `ldd <file>`: see shared libraries used by an ELF file.
- `file <file>`: shows filetype info of a given fuile.
- `objdump <file>`

#### `objdump` versus `readelf`:


- Both programs are capabale of displaying the contents of ELF format files,
  so why does the `binutils` project have two file dumpers ?
- The reason is that objdump sees an ELF file through a BFD filter of the
  world; if BFD has a bug where, say, it disagrees about a machine constant
  in `e_flags`, then the odds are good that it will remain internally
  consistent.  The linker sees it the BFD way, objdump sees it the BFD way,
  GAS sees it the BFD way.  There was need for a tool to go find out what
  the file actually says.
- This is why the readelf program does not link against the BFD library - it
  exists as an independent program to help verify the correct working of BFD.
- `readelf` is arch. independent, `objdump` needs the appropriate toolchain.
- [Stack overflow reference for difference between objdump and readelf](https://stackoverflow.com/a/8979687/5305365)


# Regular epi and regular category

- A regular epi `c->d` means that there is a kind of relation on `c` (concreteley,
  an object `R` and two morphisms `f: R -> c` and `g: R -> c`) such that `d` is `c` module `R`, i.e. the quotient of `c` by `R`
- A regular category is one where every arrow has a (regular epi-mono) factorization.

# Focal point

- The focal point of a space is a point whose only open nbhd is the whole space.
- In the sierpiski space `(), bottom`, the `bottom` is the focal point.
- In a local ring, the focal point is given by the maximal ideal (in the prime spectrum, ofc).
- Given any topological space $T$, consider the cone: (ie, take product with
  $[0, 1]$ and smash all the $\{0\} \times *$ together).
- Given any topological space $T$, now build the scone: take the product with
  the sierpinski space, and smash everything with the closed point. Then, the
  apex of the cone / the closed point becomes a focal point for the topological
  space. This can be seen as a
  "one point focalization".


# Operational versus Denotational semantics

> I think if you tell people that denotational semantics is just model theory for
> programming languages you've got most of the way there.

> Another consequence of this perspective is that you *must* care about
> nonstandard models, even if you think you don't! When you prove something by
> natural number induction, you are precisely constructing a non-standard model
> of Nat in Prop.


# Minimising L2 norm with total constraint

- Suppose we are trying to minimize $x^2 + y^2$ subject to $x + y = 10$.
- We can think of $(x, y)$ as two points located symmetrically about $5$, suppose
  it is $x = (5 + \epsilon)$ and $y = (5 - \epsilon)$.
- See that the function $f(k) = k^2$ is such that the output becomes larger as we go to the
  right / increase the argument than the rate at which the output becomes smaller
  as we go to the left / decrease the argument.
- This is clear by computing $\partial_k f = 2k$, which means that if $k_r > k_l$ (right/left), then
  $\partial_{k_r} f = 2 k_r$, while $\partial_{k_l} f = 2 k_l$, so if we step to the
  left and the right by $\epsilon$, keeping the total the same, the sum will change by
  $(2 k_r - 2 k_l) \epsilon > 0$.
- Said differently, because the function is convex / $f''(x) > 0$, this means that
  $\partial_k|_r f > \partial_k|_l f$, and thus we can trade the loss of the total
  from moving to the left (a $- \partial_k|_l \epsilon$ for the gain of the total
  from moving to the right (a $+ \partial_k|_r \epsilon$).

- Picture:

```
          * dx=1.2
         /|---->
        - |
       /  |
     --   |
*---/     |
-dx=0.8   |
  <-|     |
    |    x=0.6
   x=0.4
```

- We gain more by moving rightwards (in terms of $f(r+dx) \simeq f(r) + f'(r) dx = f(r) + 2f(r)dx$ than we lose by
  moving leftward (in terms of $f(l-dx) \simeq f(l) - f'(l) dx = f(l) - 2f(l) dx$. Since $f(r) > f(l)$, the total
  we gain is still net positive.
- Said differently again, we gain faster by moving from a point that is rightwards, than the rate at which
  we lose  from a point that is leftwards.
- Said differently again, the elevation gain is larger towards the right, so a small motion rightwards gains
  us more elevation than a small motion leftwards loses elevation.

#### How does this relate to convexity?

- What is the geometric intution for this being related to "below a line"?

# Bounding L2 norm by L1 norm and vice versa

- We can bound a function along the x-axis (in its domain) or along the
  y axis (in its range).

#### Bounded domain
- If a function's norm is well defined in a bounded domain, then it has not increased
  too rapidly.
- Intuitively, with L2 norm, large numbers become larger, thus it is "harder" for a function
  to stay finite.
- Thus, in bounded domain, L2 is a subset of L1.

#### Bounded range

- If a bounded function's norm is well defined on an unbounded domain, then it has
  vanished to zero sufficiently quickly.
- Intuitively, with L2 norm, smaller numbers becomes smaller, thus L2 allows functions
  to decay faster (eg. $|1/n|_1 = \sum_k 1/k = \infty$ versus $|1/n|_2 = \sqrt{\sum_k 1/k^2 < \infty}$.
- Thus, in bounded range, L1 is a subset of L2, because L2 allows more functions to decay to zero.

- intuitively, l2 error will fail to reduce small values.
- but l1 error will reduce all values equally.
- thus, l1 norm is larger than l2 norm.

# Example of unbounded linear operator

#### Differentiation

- Simplest example is differentiation.
- Let $C^0[0, 1]$ be continuous functions on interval, and $C^1[0, 1]$ be differentiable functions on the interval.
- We equip both spaces with sup norm / infty norm.
- Consider the differentiation operator $\partial : C^1[0, 1] \to C[0, 1]$.
- Since every differentiable function is continuous, we have that $C^[0, 1] \subseteq C[0, 1]$
- Clearly differentiation is linear (well known).
- To see that the operator is not bounded, consider the sequence of functions $f_n(x) \equiv sin(2\pi nx)$.
- We have that $||f_n||_\infty = 1$ for ann $n$, while the $||\partial_x f_n||_\infty \to \infty$, so clearly, there
  is no constant $M$ such that $||\partial f_n(x)|| \leq M ||f_n(x)||$. Thus, the operator is unbounded.
- Note that in this definition, the space $C^1[0, 1]$ is *not* closed, as there are sequences of differentiable
  functions that coverge to non differentiable functions. Proof: polynomials which are differentiable functoins
  are dense in the full space of continuous functions.
- Thus, in the case of an unbounded operator, we consider $L : U \to X$ where
  $U$ is some subspace of $X$, not ncessarily closed!
- If we ask for an everywhere defined operator, then constructing such
  operators $L : X \to X$ needs choice.

#### Nonconstructive example

- Regard $\mathbb R$ as a normed vector space over $\mathbb Q$. [Cannot call this a banach space, since a banach
  space needs base field $\mathbb R$]
- Find an algebraic basis $B$ containing the numbers $1$ and $\pi$ and whatever else we need.
- define a function $f: \mathbb R \to \mathbb R$ such that $f(\pi) = 0$, and $f(1) = 1$, and extend everywhere else
  by linearity.
- Now let $p_i \in \mathbb Q$ be a sequence of rationals that converge to $\pi$. Then $f(p_i) = 0$, and thus $\lim_i f(p_i) = 0$,
  while $f(\lim_i p_i) = f(\pi) = 1$. This shows that $f$ is not continuous, but is linear.


# Direct sum of topological vector spaces

- In vector spaces, direct sum (also direct product) needs projection functors $\pi_1, \pi2_: V \to X, Y$
  such that $X \times Y = V$.
- In topological vector spaces, these projections also need to be *continuous* which is a massive
  thing to ask for.

#### Direct sum need not be closed.

- Let $X$ be a Hilbert space with schrauder basis (topological basis) $e[i]$
- Consider subspaces spanned by the basis $A[k] \equiv e[2k]$, and $B[k] \equiv e[2k] + e[2k+1]/(k+1)$.
  So $A \equiv span(A[k])$, $B \equiv span(B[k])$.
- Clearly, $A, B$ are subspaces, $A, B$ are closed.
- See that the closure of $A + B$ is the full space, since it contains the hamel basis $e[i]$.
- However, also see that the vector $z \equiv  sum_k e[2k]/(k+1)$ is not in $A + B$.
  If we tried writing it as $a + b$, then we woulnd need $b \equiv \sum_k B[k]$. But this sum does not converge.
- This means that $(A + B)$ is not closed. If it were closed, it would contain the full space (because it's dense).
- Thus, we have an example of the direct sum of two closed subspaces which is not closed, because it is dense.

# Subspaces need not have complement

- Clearly, one can have open subspaces that cannot be complemented. For example,
  the subspace of polynomials in $C[0, 1]$ is dense, and thus has no complement, as a complemented
  subspace must be closed.

#### Closed subspace need not have complement

- Apparently, in $l^\infty$, the subspace $c_0$ of sequences that converge to
  zero does not have a complement.
- Proof is given in a paper "projecting $m$ onto $c_0$"

#### Lemma: countable set $I$ has uncountable family of countable subsets $S$ which are almost disjoint

- Let $I$ be countable.
- We must prove that (1) there exists a $S \subset 2^I$ that is uncountable, such that (2) every set $K \in S$ is countable, and
  (3) every two sets $K, L \in S$ have finite intersection $K \cap L$.
- Proof: let $I$ be rationals in $(0, 1)$. For each irrational  $r \in (0, 1)$ create a set
   $S_r$ to be the set of sequences of rationals that converge to $r$.
- TODO: why is each $S_r$ countable?

#### Proof of theorem

- Suppose that there is a continuous projection of $l^\infty$ into $c_0$,
- Then we must have $l^\infty = c_0 \oplus R$ for some closed subspace $R$.
- Since $l^\infty / c_0$ is isomorphic to $R$.
- TODO

# $L^\infty$ is HUGE

- Key insight: if we take any space like $L^1$ or $L^2$ or something, the terms need to eventually vanish.
- This is a small subspace $c_0$ of $L^\infty$, which is the subspace of sequences that eventually vanish.

#### Continuous functions are dense in $L^1$
#### Continuous functions are dense in $L^2$
#### Continuous functions is NOT dense in $L^\infty$

# Banach space that does not admit Schrauder basis

- Schrauder basis is a basis where we can get all elements uniquely by taking countable sequence of
  elements from the basis.
- Apparently, every banach space that obeys the approximation property has countable basis.
- An example of a banach space without this properly was given in
  "a counterexample to the approximation problem in banach spaces" by Per Enflo.
- Thus, in no argument can we say "assume we have a (schrauder) basis..."



# Open mapping theorem

- Given a surjective continuous linear map $f: X \to Y$, image of open unit ball is open.
- Immediate corollary: image of open set is open (translate/scale open unit
  ball around by linearity) to cover any open set with nbhds.

#### Quick intuition
- Intuition 1: If the map $f$ we bijective, then thm is reasonably believeable given
  bounded/continuous inverse theorem, since $f^{-1}$ would be continuous, and thus would
  map open sets to open sets, which would mean that $f$ does the same.
- In more detail: suppose $f^{-1}$ exists and is continuous. Then $f(U) = V$
  implies $(f^{-1})^{-1}(U) = V$. Since $f^{-1}$ is continuous, the iverse image of an
  open set ($U$) is open, and thus $V$ is open.

#### Why surjective
- Consider the embedding $f : x \mapsto (x, x)$ from $\mathbb R$ to $\mathbb R^2$.
- The full space $\R$ is open in the domain of $f$, but is not open in $\mathbb R^2$,
  since any epsilon ball around any point in the diagonal $(x, x)$ would leak out of the diagonal.
- Thus, not every continuous linear map maps open sets to open sets.

#### Proof

- Reference: [The Open Mapping Theorem And Related Theorems by Anton R Schep](https://people.math.sc.edu/schep/Openmapping.pdf)

#### Ingenious Lemma about Norms

- Notation: If we have two norms $N$ and $M$ on a space $X$, we denote $B_N(x, r)$ and respectively $B_M$
  to be the open ball of radius $r$ at point $x$ under norm $N$.
- We will show that if (a) the identity map $(X, N) \to (X, M)$ is continuous, and
  (b) $B_M(0, 1) \subseteq \overline{B_N(0, r)}^M$, that is, the closure
  of the ball $B_N(0, r)$ in the $M$ norm, **then**  $B_M(0, 1) \subseteq B_N(0, (1 + \mu)r)$ 
  for any $\mu > 0$.
- Inutition: completing under norm $M$ of the open ball on $N$ will continue to trap the ball of $M$
  at the cost of an infinitesimal radius bump.
- Proof: 
- From the hypothesis, we see that every point in $B_M(0, 1)$ is $\epsilon$ close to $B_N(0, r)$ under
  completion with respect to $M$.
- Thus, we get the inclusion that $B_M(0, 1) \subseteq B_N(0, r) + \alpha B_M(0, 1)$ for **any $\alpha > 0$**.
- We solve the equation $1/(1 - \alpha) = (1 + \mu)$. We can find such a $\beta < 1$, since $\mu > 0$.
  We pick whatever $\alpha$ we get from this equation to be our $\alpha$.
- We had the equation  $B_M(0, 1) \subseteq B_N(0, r) + \alpha B_M(0, 1)$.
- Proof by notation: rewrite as $B_M(0, 1) (1 - \alpha) \subseteq B_N (0, r)$
- This means that $B_M(0, 1) \subseteq 1/(1 - \alpha) B_N(0, r)$, which by definition means that
  $B_M(0, 1) \subseteq (1 + \mu) (B_N(0, r)$. This gives us what we wanted!
- The geometric picture to keep in mind: $B_M(0, 1)$ can be trapped inside a $B_N(0, r)$ followed by a "small"
  $B_M(0, 1)$. But by rewriting this "small" $B_M(0, 1)$ itself as a rescaling of $B_N(0, r)$, we can write
  the full thing as a union of rapidly decreasing balls of the form $B_N(0, r_1), B_N(0, r_2), \dots$.
- All of these will be trapped in $B_N(0, r_1 + r_2 + \dots)$.
- In the above argument, where did we use the continuity of $I$?

##### Lemma implies bounded inverse theorem
- Let $T: X \to Y$ be a one-to-one  bounded operator. Then the inverse $T^{-1} : Y \to X$ is also bounded.
- Define a new norm on $Y$ given by $||y||_T \equiv ||T^{-1}(y)||_X$.
- Then this is a norm on $Y$, and we have that $||y||_Y \leq ||T|| ||y||_T$.
- This means that sets measured with $T$ norm are larger than when measured in $Y$ norm.
- This is because $||T(T^{-1}(y)||_Y \leq ||T|| ||T^{-1}(y)||_X$ by the defn of operator norm.
  Now see that the RHS equals $||T|| ||y_T||$ and we get the desired inequality.
- Thus, the identity map $I : (Y, ||\cdot||_T) \to (Y, ||\cdot||_Y)$ is bounded, since a set that is
  bounded in the $||\cdot||_T$ norm will be *smaller* in the $||\cdot||_Y$ norm, and will thus
  continue to be bouned.
- Moreover, since $T$ is continuous, we can check that $(Y, ||\cdot||_T)$ is also a banach space,
  since a series will converge in $||\cdot||_T$ iff its preimage converges in $X$.
- By the above lemma, this means that the two norms $||\cdot||_Y$ and $||\cdot||_T$ are equivalent.
- So, we get the reverse inclusion, where the norm $||y||_T \leq K ||y||_Y$.
- But that just means that $||T^{-1}(y)|| \leq K ||y||_Y$, or that the operator $T^{-1}$ is bounded!

##### Open Mapping Theorem
- Let $T: X \to Y$ be a surjective bounded operator. Then we claim that it's an open map.
- Factorize the map into $T' : X/ket(T) \to Y$ be a bijection, and the projection $\pi : X \to X /ker(T)$
  will be an open map.
- Let $U \subseteq Y$ be some open set. Since $\pi$ is an open map, we have that $\pi(U)$ is open.
- The latter map is a 


# Closed graph theorem

- the graph of a function from a banach space to another banach space is a
  closed subset iff the function is continuous.
- Formally, given $f:X \to Y$, the set $G \equiv  { (x, f(x)) }$ is closed
  in $X \times Y$ iff $f$ is continuous.

#### Proof: Continuous implies closed

- We must show that every limit point of the graph G is in G.

- Let $(p, q)$ be a limit point. Since everything in metric spaces is equivalent
  to the sequential definition, this means that $(p, q) = \lim (x_i, f(x_i))$.

- Limits in product spaces are computed pointwise, so $(p, q) = (\lim x_i, \lim f(x_i))$

- Thus, $p = lim xi$ from above. Now we calculate:

- $q = \lim f(x_i) = f (\lim xi) = f(p)$ where we use the continuity of $f$ to
  push the limit inside.
- Thus, $(p, q) = (p, f(p))$ which is an element of $G$.
- So an arbitrary limit point $(p, q) \in G$ is an element of $G$, and thus G
  is closed. Qed.


#### Proof: closed implies continuous


- Suppose G as defined above is a closed set. We must show that f is
  continuous, ie, $f$ preserves limits.

- Let $x_i$ be a sequence. We must show that $f(\lim x_i) = \lim f (x_i)$.

- Consider $(x_i, f(x_i))$ as a sequence in $G$. Let the limit of this sequence
  be $(p, q)$. Since G is closed, $(p, q)$ in G. By defn of $G$, $q = f(p)$.

- Now we compute that

$$
\lim (x_i, f(x_i)) = (p, q)
(\lim x_i, lim f (x_i)) = (p, q)
\lim x_i = p, \lim f(x_i) = q
$$

- But since $q = f(p)$ (by defn of $G$), we have that
  $lim f(x_i) = q = f(p) = f(\lim x_i)$ which proves continuity.

### Where this fails: topological spaces

- The graph of the identity function $I : X \to X$, $\Delta \equiv \{ (x, x) \in X \} \subset X \times X$
  is closed iff space is hausdorff.
- We call the set $\Delta$ the diagonal.

#### Closed implies Hausdorff

- Suppose the diagonal set $\Delta$ is closed.
- To show that the space is hausdorff, take two points $p, q \in X$.
- We must create two open sets $O_p, O_q$ which are disjoint, such that $p \in O_p$ and $q \in O_q$.
- Since $(p, q)$ is off the diagonal ($p \neq q$), it belongs to the open set $X \times X - \Delta$.
- Thus, there must be some basic open set $O_p \times O_q$ such that $(p, q) \in O_p \times O_q$.
- Furthermore, the set $O_p \times O_q$ misses the diagonal.
- Recall that the product topology is generated by basic open sets, so we know that this $O_p, O_q$
  are open in $p$.
- We must have that $O_p$ is disjoint from $O_q$, since the set $O_p \times O_q$ misses the diagonal.
- Otherwise, we would have a $c \in O_p, O_q$ ($c$ for contradiction), or that $(c, c) \in O_p \times O_q$,
  contradicting the fact that it misses the diagonal.

#### Hausdorff implies closed

- Suppose space is hausdorff. Now we need to show that the diagonal is closed.
- That is, we need to show that every limit point is included in the set.
- Consider some point $(p, q) \not \in S$. We will show that such a point cannot be a limit point.
- Since $(p, q) \not \in S$, we have that $p \neq q$.
- Since the space $X$ is hausdorff, there will be open sets $O_p, O_q$ such that they contain $p, q$
  respectively but are disjoint.
- This means that $O_p \times O_q$ is an open set in $X \times X$ which contains $p, q$, but is disjoint
  from $\Delta$. This means that $(p, q)$ is not a limit point.
- Thus, no point $(p, q)$ that is outside of $\Delta$ is a limit point, which means that $\Delta$
  contains all its limit points, and is thus closed.

# Bounded inverse theorem

- Theorem: Every bijective bounded linear operator has bounded inverse.
- Equivaently: Every bijective continuous linear operator has continuous inverse.
- Proof: quick corollary of open mapping. Let $L: X \to Y$ be
  bijective bounded linear operator.
- Assuming open mapping, we know that $T$ maps opens $U$
  to open sets. Recall that bounded iff continuous. Thus, we can show
  that $T \equiv L^{-1} : Y \to X$ is continuous to show that $L$ is bounded.
- We need to show that inverse images of open sets under $T$ is open.
  Specifically that $T^{-1}(U \subseteq X)$ is open for $U$ open
- Since $V \equiv L(U)$ is open as $U$ is open and $L$ is an open map, this means that
  $V \equiv T^{-1}(U)$ is open, as $L = T^{-1}$. Hence done.


# Nonexistence of solutions for ODE and PDE

- ODE system, no bc: always solution by picard liendolf
- ODE system, with boundary cond:,  can have no solution. Eg. $f'(x) = 0$, with
  boundary conditoin $f(a) = 0, f(b) = 1$.
- PDE system, no bc: can still create no solutions!
- PDE system, with boundary cond: can have no solution because ODE is PDE.

#### Example 1 of PDE with no solutions

- Take a vector field on $\mathbb R^2$ with $V(x, y) = (-y, x)$. This vector field
  has concentric spirals.
- consider this vector field as a PDE, so we are looking for a function $f$
  such that $\nabla f = V$.
- No such potential function can exist, because this vector field allow us to extract work.
- Suppose such a potential exists. Then if I travel in a circle, according to the potential, net work
  is zero. But if I evaluate the integral, I will get work done. Thus, no soln exists!
- In general, asking **if a differential form is exact** is literally asking for a PDE to be solved!
- In this case, the form is also **closed**, since it's a 2D form on a 2D surface. This is an example
  of a closed form that is not exact.
- It's nice to see PDE theory and diffgeo connect

#### Example 2: use second axis as time

- Consider a PDE on a square $[0, 1]\times [0, 1]$. We will think of the first axis as space
  where the function is defined and the second axis as time where the function is perturbed.
- We start by saying $\partial f / \partial x = t$. So the function at $t=0$ is constant, and at $t=1$ is linear.
- Next, we say that $\partial f / partial t = 0$. This means that the function is not allowed to evolve through time.
- This is nonsensical, becase at $t=1$, we expect a constant function to have become a linear function, but along the time axis,
   we say that no point in space can change.
- Thus, this DE has no solutions!
- We can use the extra dimensions available in a PDE to create "conflicting" data along different time axes.

# Baire Category Theorem

- Dense set: set whose closure is full space
- Baire Category theorem: Intersection of countably many
  dense sets is dense (countable interesction of chonk is chonk)

#### Proof
- Let $D[i]$ be family of dense sets.
- Denote $C(\cdot)$ for the closure of a set.
- Let $p \in W$, we need to show that $p \in C(\cap_i D[i])$.
- So for any $\epsilon$, we need to show that there is a point $w$ (for witness)
  that is $\epsilon$ close to $p$ in $\cap_i D[i]$.
- So we need to show that $w$ is in each of the $D[i]$.
- We will create a sequence of points that will converge to $w$

```py
def find_witness(Ds, p, eps):
 """returns a point 'w' such that `w ∈ Ds[i] ∀i` and that `|p - w| < eps`."""
 seq = []
 cur = D[0].get_close_pt(p, eps/3)) # cur is 'eps/3' close to p.
 d_scale = 1 # current distance is eps / 3^d
 yield cur
 # loop invariant: 'cur' is eps/3^d from p
 for k in range(1, infty):
   for i in range(0, k):
     d += 1
	 # 1. next is closer to to point than 'cur' is by (1/3)
     next = D[i].get_close_pt(cur, eps/3**d)
	 # 2. (cur, next) distance is a monotonic decreasing function of 'd',
	 #      so d(cur, next) > d(next, next')
	 # Proof:
	 # - dist(cur, next) <= dist(cur, p) + dist(p, next)
	 # - dist(cur, next) <= eps/3**(d) + eps/3**(d+1) <= 4 eps / 3**d
	 # - this dist(cur, next) is monotone decreasing in d, and thus
	 #   sequence is cauchy.
	 yield cur
	 cur = next
```


#### Corollary 1: Space cannot be union of non chonk

- A nowhere dense set is a set whose closure is empty.
- A meagre set/ a set of first category
  is a set which can be written as a countable union of
  nowhere dense sets.
- A non meagre set/a set of second category is
  a set which cannot be written in this way
- Baire Category: A complete metric space is non-meagre / second
  category in itself.


##### Proof of Corollary 1

- By contradiction, assume that $X$ is the union of nowhere dense sets $N_i$.
- complement the set $N_i$ to get $D_i \equiv X - N_i$.
- We claim that the sets $D_i$ are dense.
- By baire category theorem, $\cap D_i$ is dense.
- But this means that $(\cap D_i)^C$ is nowhere dense, that is, $\cup D_i^C = \cup C_i$ is nowhere dense.
- If $\cup C_i$ is nowhere dense, then $(\cup C_i) \neq X$.



#### Corollary 2: One of union is chonk
- Baire Category, stmt 2: If $X$ is the union of a countable family
    of closed subsets, then at least one of the closed subsets
    contains an open set


##### Proof of Corollary 2

- TODO

#### Abstract Use: Swap Quantifiers

- Let $D$ be an enumerable set and $X$ a complete metric space.
- We have some statement $\forall x \in X, \exists  d \in D, P_d(x)$.
- We get a uniform statement: $\exists d \in D, \forall x \in X, P_d(x)$
- To do this, we first define $F_d \equiv \{ x \in X : P_d(x) \}$ (filter $x$ by $P_d$).
- If we are lucky, then each of the $F_d$ are closed. Since $d \in D$ is enumerable,
  and we have that $X = \cup_d F_d$, we apply baire category.
- Baire category tells us that there is a $\mathcal d \in D$ such that $F_{\mathcal d}$ has
  non empty interior.
- By setup the situation such that if
  $int(F_D) \neq \emptyset$, then $F_D = X$, which gives us the uniform statement.

#### Application : Vanishing derivative pointwise implies fn is polynomial

- Let $P$ be infinitely differentiable, such that for each $x \in \mathbb R$,
  there is a number $n(x) \in \mathbb N$ such that
  $\partial^{n(w)} P /\partial x^{n(w)}|_w = 0$.
- This is again a case where we switch a pointwise fact --- is locally like a poly as nth order
  derivative vanishes, into a global fact --- is actually a polynomial.
- Let us try the above proof sketch.
- Proof by contradiction, assuming $P$ is not a polynomial.
- Define $X \equiv \{ x : \forall x \in (a, b), P|_{(a, b)}~\text{is not a polynomial} \}$
- Define $F_d \equiv \{ v \in [0, 1] : (\partial^d f / partial x^d)(v) = 0 \}$
- Clearly, $\cup F_d \equiv [0, 1]$, and each of th $F_d$ are closed (zero set of fn).
- By baire category, one of the $F_d$ has an open set inside it.
- This means that for some open set, there is some natural $D$ such that the $D$th derivative vanishes.
- From this, it is "clear" that $f$ is a polynomial?

#### Application : the reals are uncountable.

- Assume $[0, 1]$ is countable.
- So $[0, 1] = \cup_i  \{x[i]\}$ for a countable number of points $x[i]$.
- See that each of the sets $\{x[i]\}$.
- But we know that a nonempty set $X$ is not a countable union of nowhere dense sets.

#### Application: Uniform boundedness

- Let $X$ be a banach space, $Y$ a normed vector space, $B(X, Y)$ be all bounded linear operators
  from $X$ to $Y$. Let $F$ be a collection of bounded linear operators from $X$ to $Y$.
  If $\forall x_0 \in X, \sup_{T \in F} ||T(x_0)||_Y < \infty$ (set of operators is pointwise bounded), then
  $sup_{T \in F} ||T||< \infty$ (set of operators is uniformly bounded)


# libOpenGL, libVDSO and Nix


- openGL is bother userspace / user facing (provides APIs) and drivers
  (talks to GPU hardware)
- Nix thinks openGL is impure becuase openGL needs to be loaded based
  on *target hardware*, which is fundamentally unknown at *host build machine*.
- Contrast this situatino to VDSO, which is a library the kernel secretly
  links/loads into any executable to provide access to syscalls.
- This is *also* a fundamentally target side infra, which the host
  build cannot know about, but this impurity is "purified" for Nix
  because userspace doesn't need to worry about loading VDSO!
- If it were the case that the kernel also links in


# Stuff I learnt in 2022

2022 was a weird year for me. I moved from India to Edinburgh to pursue
my PhD, and a lot of the year was (and still is) getting used to
what it even means to be a PhD student. Here's a run down of the
things I learnt this year, and what the experience of doing this was.

#### Semantics of MLIR in Lean

The first project I took up was to define the semantics of [MLIR](https://mlir.llvm.org/),
a new compiler infrastructure in the [Lean4](https://leanprover-community.github.io/) proof
assistant, titled boringly as [`opencompl/lean-mlir`](https://github.com/opencompl/lean-mlir).

While working on the project, I did a bunch of useful things:

- I helped write the [Lean metaprogramming.book](https://github.com/arthurpaulino/lean4-metaprogramming-book),
  an open-source book on using Lean's powerful metaprogramming facilities.
- I read through [Mario Carneiro's thesis, models of dependently typed programming languages](https://github.com/digama0/lean-type-theory)
  which explains Lean's metatheory and a proof of consistency of Lean. I quite liked this thesis, since it provides
  a very readable set-theoretic semantics for Lean!

#### Lean OSS work

I also began contributing to the proof assistant itself.
In particular, I've been slowly chipping away at adding [LLVM support](https://github.com/leanprover/lean4/pull/1837),
which got merged on the 31st, right before new years! The hardest part was learning a huge amount
about low-level linkers, loaders, and other cross platform shenanigans. The sources I leaned against
most were:

- The [CMake manual](https://cmake.org/documentation/), which actually makes CMake sensible. I quite like CMake now,
  since I actually understand its semantics.
- [Linkers and Loaders](http://14.99.188.242:8080/jspui/bitstream/123456789/12311/1/LinkerLoader.mca.pdf), to learn
  a ton of the arcane details of how precisely loading works.
- The [GNU binutils](https://www.gnu.org/software/binutils/), which were a lifesaver in debugging weird linker visibility issues.


#### Partial Evaluation

I was also interested in improving the performance of the code generator, and was frustrated that we in compilers
kept rediscovering basic optimisation techniques over an over again. Partial Evaluation seemed like a powerful
technique to prevent this waste, and I thus began reading the literature on partial evaluation. The best
book I found was called [Partial evaluation and automatic program generation](https://www.itu.dk/people/sestoft/pebook/jonesgomardsestoft-a4.pdf),
and I [implemented the algorithms from the book](https://github.com/bollu/halfred). However, I haven't had the time
to integrate these back into lean proper. Plans for next year!


#### Adjoint School And Category Theory

I wanted to learn more category theory, since I felt it was important as a type theorist in training
to be fluent with category theory.

- I was reading [Categorical logic](https://link.liverpool.ac.uk/portal/Categorical-logic-and-type-theory-Bart/zctzUzjlvJk/)
  by Bart Jacobs, which describes how to reason about type theory using the
  machinery of [fibered categories](https://en.wikipedia.org/wiki/Fibred_category).
- I attended [Adjoint School](https://adjointschool.com/), a summer school for applied category theorists, which was
  a blast. I learnt a lot from it, and read a bunch of papers from it!
- I loved the paper [Opinion Dynamics on Discourse Sheaves](https://arxiv.org/abs/2005.12798), which describes how to setup
  a 'discourse sheaf', a sheaf structure on a graph which models private versus public opinions. The punchline is that harmonic
  functions lead to 'harmonious' discourse amongst participants in the model!
- Ohad pointed me to [Probabilistic models via quasi borel spaces](https://arxiv.org/abs/1701.02547), which builds
  quasi-borel spaces, which is a closed cartesian category where one can interpret simply typed lambda calculus.
  This gives a nice denotational footing to probabilistic programming.

But to be honest, what I really took away from this was that I *don't enjoy*
category theory as much as I enjoy geometry. Thus, I'm going to try to align
next year such that I get to read more geometric concepts!

#### Logic

I wanted to learn logic and model theory, so I read George Boolos'
book ["Computability and Logic"](https://www.cambridge.org/core/books/computability-and-logic/440B4178B7CBF1C241694233716AB271).
My two favourite theorems were:

- The [Compactness theorem](https://en.wikipedia.org/wiki/Compactness_theorem), which points to the finiteness of
  the proof system we use, and how this impacts the logic itself.
- The [Lowenheim Skolem](https://en.wikipedia.org/wiki/L%C3%B6wenheim%E2%80%93Skolem_theorem) theorem, which shows that
   first order logic cannot control the size of its models.

I also wanted to learn what forcing was about, so I tried
to read through the literature:

- I began by reading [Jech: Axiom of Choice](https://link.springer.com/chapter/10.1007/978-3-642-41422-0_37#Abs1), which
  was far too terse to grok, so I switched to reading the next lecture notes.
- [Independence of CH: an intuitive explanation](https://arxiv.org/pdf/2208.13731.pdf) was a readable account of the
   machinery of forcing! I wanted to get the account of forcing from the point of view of topi, for which I started reading
   the next book.
- [Sheaves in geometry and logic](https://link.springer.com/book/10.1007/978-1-4612-0927-0) is a textbook on topos theory, which
  provide an account of forcing by building an object called a [cohen topos](https://toddtoddtodd.net/T%20Schmid%20-%20Toposes,%20Sets,%20and%20Cohen%20Forcing,%20an%20Overview.pdf). I didn't manage to get through enough of the book to really understand what the
  chapter on the cohen topos was doing, but I did get the vague idea. We seem
  to build a topos, and then use the internal logic of the topos to mimic the
  model we are building. The machinery of topos theory allows us to easily
  control the internal logic, thereby adding the axioms to ZF.

#### Frex

[Ohad Kammar](https://twitter.com/aleph_kappa?lang=en) is a senior research fellow here at Edinburgh who I really enjoy
talking to. He told me about a project he works on, `frex`, which stands for
"free extensions". The TL;DR is that they wish to study how to write down simplifiers / computer algebra systems
in a principled fashion. Their paper [Partially static data as free extensions of algebras](https://www.cl.cam.ac.uk/~jdy22/papers/partially-static-data-as-free-extension-of-algebras.pdf) is a super readable account of their ideas. I quite enjoyed re-implementing
the basic version in Haskell. I wish to implement their more recent, more complex dependently-typed version of the
theory in Lean.

#### Ideas in type theory and proof assistants

Since I'm here at Edinburgh, I keep getting stray recommendations on things to read.
A big shout-out to
[Andres Goens](https://github.com/goens),
[Chris Hughes](https://github.com/ChrisHughes24),
[Jesse Sigal](https://github.com/jasigal),
[Justus Mathiessen](https://www.inf.ed.ac.uk/people/staff/Justus_Matthiesen.html),
[Leonardo De Moura](https://leodemoura.github.io/about.html),
[Li-yao Xia](https://poisson.chat/),
[Mario Carneiro](https://github.com/digama0),
[Ohad Kammar](https://twitter.com/aleph_kappa?lang=en), and
[Sebastien Michelland](https://github.com/lephe/) for many of these pointers.

- [On Universes in Type Theory](http://www2.math.uu.se/~palmgren/universe.pdf) describes the difference between russel and tarski
  style universes.
- [Case trees](https://hackage.haskell.org/package/idris-1.1.0/docs/Idris-Core-CaseTree.html) are a data structure which are used
   in Coq and Idris to manage dependent pattern matching.
- [primitive recursors](https://leanprover.github.io/theorem_proving_in_lean/inductive_types.html?highlight=recursor#defining-the-natural-numbers) in Lean
- [congruence closure in intensional type theories](https://arxiv.org/abs/1701.04391) describes how to extend the naive
  congruence closure algorithm in the presence of definitional equalities between types.
- Difference between [match+fix, as introduced by Theirrey Coquand in 'Pattern Matching with Dependent Types'](https://wonks.github.io/type-theory-reading-group/papers/proc92-coquand.pdf) ,  `termination_by`, and primitive recursion.
- The idea of full abstraction, which asks the question of when operational and denotational semantics agree,
  first studied by [Gordon Plotkin for PCF](https://pdf.sciencedirectassets.com/271538/1-s2.0-S0304397500X0240X/1-s2.0-0304397577900445/main.pdf)
- [Andrej Nauer's notes on realizability](https://github.com/andrejbauer/notes-on-realizability), which very cleanly describes
  the theory of realisability models, where one studies mathematical objects equipped with computational structure. this naturally
  segues into discussions of models of computation and so forth.
- [I am not a number, I am a free variable](https://www.semanticscholar.org/paper/Functional-pearl%3A-i-am-not-a-number--i-am-a-free-McBride-McKinna/833cf29aa614fa26348a505f3b9a3832e1d47dd4) describes "locally nameless", a technique to manage names when implementing proof assistants.
- Higher order unification is necessary when implementing the elaborator for a proof assistant. Unfortunately,
  [the full problem is also undecidable](https://www.ps.uni-saarland.de/Publications/documents/SpiesForster_2019_UndecidabilityHOU.pdf)
- Luckily for us, [Miller found a fragment called 'pattern unification'](https://github.com/Saizan/miller), where unification is indeed
  decidable. The key idea is to add a 'linearity' constraint which ensures that variables are not repeated into the pattern match, which
  makes even higher-order patterns decidable.
- The [Beluga Proof Assistant](https://beluga-lang.readthedocs.io/en/latest/) is a proof assistant whose logic allows one to reify
  contexts. This means that one can write shallow embeddings of programming languages, have all the nice power of the proof assistant,
  while still reasoning about binders! I found the way in which Beluga makes
  such invasive changes to the metatheory in order to allow reasoning about
  binders to be very enlightening.
- The [HOL light](https://www.cl.cam.ac.uk/~jrh13/hol-light/tutorial.pdf) proof assistant and [Isabelle/HOL](https://isabelle.in.tum.de/)
  are both based on higher order logic, and alternate, untyped foundations for
  proof assistants. I feel it's important for me to know the various ideas
  folks have tried in building proof assistants, and I was glad to have been
  pointed to Isabelle and HOL. I want to spend some time this year (2023) to
  learn Isabelle and HOL well enough that I can prove something like strong
  normalization of STLC in them.
- [Fitch style modal logics](https://arxiv.org/pdf/1710.08326.pdf) are a systematic way to build type theories with
  modalities in them. These are typically used to create type theories that can reason about resources, such as
  concurrent access or security properties. The paper provides a unified account of how to build such type theories, and
  how to prove the usual slew of results about them.
- [Minimal implementation of separation logic: Separation Logic for Sequential Programs](http://www.chargueraud.org/research/2020/seq_seplogic/seq_seplogic.pdf) explains how to write a small separation logic framework embedded in a dependently typed progrmaming language.
  I [translated the original from Coq to Lean](https://github.com/bollu/slf/blob/main/Separation.lean#L1934), and the whole thing clocks in at
  around 2000 LoC, which is not too shabby to bootstrap a full 21st century
  theory of reasoning about parallelism!
- [Telescopic Mappings in Typed Lambda Calculus](https://pdf.sciencedirectassets.com/272575/1-s2.0-S0890540100X02428/1-s2.0-089054019190066B/main.pdf) builds the theory of telescopes, which is the basic notation that's used when describing binders in dependent type theory.
  I had no idea that this had to be developed; I shudder to think how ugly notation was before this paper! I can't help but
  feel that this paper did for dependent type theory what einstein summation convention did for tensor calculus: provide compact
  notation for the uninteresting bits to allow us to to talk about the interesting bits well.
- When talking to Leonardo, I learnt that the hardest part of implementing a homotopical theorem prover
  was the elaboration of pattern matching. [Pattern matching without K](https://jesper.sikanda.be/files/pattern-matching-without-K.pdf)
  explains how to do this, and also made clear for me at what step
  [UIP](https://ncatlab.org/nlab/show/uniqueness+of+identity+proofs) is used
  during pattern matching --- when refining on indexes of a type.
- [The garden of forking paths to reason about lazy programs](https://arxiv.org/abs/2103.07543) describes how to use
  [Clairvoyant call by value](https://www.cs.nott.ac.uk/~pszgmh/clairvoyant.pdf) to reason about laziness in a convenient fashion.


#### Computational group theory

I was confused about what I should pick for my PhD topic, and I briefly flirted with the idea
of working on computational group theory. I genuinely loved a bunch of the papers in this space,
but alas, I couldn't see myself seriously working on these, due to the lack of a clear and focused
problem that I coulf work on. I did read some cool papers regardless:

- [A practical model for computing with matrix groups](https://www.sciencedirect.com/science/article/pii/S074771711400056X)
  describes algorithms that form the crux of computational matrix group theory.
- [A data structure for a uniform approach to computations with finite groups](https://dl.acm.org/doi/abs/10.1145/1145768.1145811)
  provides a data structure that unifies algorithms for the two ways of representing groups computationally: (1) as subgroups
  of the symmetric group, which is given as a [strong generating set](https://en.wikipedia.org/wiki/Strong_generating_set),
  and (2) as matrices. These two approaches are radically different under the hood, but the paper provides a unified API to
  deal with both.
- [Computing in the monster](https://webspace.maths.qmul.ac.uk/r.a.wilson/pubs_files/MDurham.pdf) describes
  how to perform computations in the monster group, a group that's so large that naively trying to write down elements would
  take two gigabytes of memory.

#### Automated theorem proving

I wound up reading a little on how to implement automated theorem provers (SAT/SMT solvers).
This space is huge, and I only got a cursory glance at it from the [Decision procedures book](https://www.decision-procedures.org/).
Even so, it was neat to learn the core ideas:

- [The DPLL algorithm for solving SAT](https://en.wikipedia.org/wiki/DPLL_algorithm)
- [The CDCL strategy for refining SMT queries](https://en.wikipedia.org/wiki/Conflict-driven_clause_learning)
- [The Nelson Oppen algorithm for mixing convex theories](https://web.stanford.edu/class/cs357/lecture11.pdf)
- The [First Order Resolution](https://logic4free.informatik.uni-kiel.de/llocs/Resolution_(first-order_logic))
  rule, which exploits
  [refutation-completeness](https://cs.stackexchange.com/a/9096/122524) to
  build a SAT solver,
- The [Superposition Calculus](https://en.wikipedia.org/wiki/Superposition_calculus) for fast SAT solving, based on an extension
  of resolution.

#### Common Lisp

I got turned off of writing scripts in Python because writing parallel
processing is a pain, so I did the obvious thing: picked up common lisp!
- I mostly learnt lisp by reading [practical common lisp](https://gigamonkeys.com/book/) and hanging out on `##lisp` on libera IRC.
- I absolutely *loved* the REPL driven development enabled by
  [`emacs`+`slime`](https://slime.common-lisp.dev/), and this has definitely
  set a gold standard for how programming language interaction ought to feel like.
- I was floored by some of the comon lisp projects I saw, such as [cepl](https://github.com/cbaggers/cepl), the code-eval-play loop
  for rapid shader development! His [videos are super cool](https://www.youtube.com/playlist?list=PL2VAYZE_4wRKKr5pJzfYD1w4tKCXARs5y),
  and I highly recommend them to anyone who wants to get a flavour of LISP.
- I'd like to work through [Let over Lambda](https://letoverlambda.com/), a book that explains all sorts of macro shenanigans!


#### Non fiction and fiction

I wound up reading a bunch of sci-fi this year, since I wanted to work my way through
the Nebula award winners. My favourites were:

- All Clear by Connie  Willis paints a great picture of the blitz during WW2. It feels surreal to have
  visited london and edinburgh and glasgow and all the other places that are name dropped in the book,
  it felt visceral.
- The [Annihilation series](https://en.wikipedia.org/wiki/Annihilation_(VanderMeer_novel)), which has
  the creepiest vibes in a book I've ever read.
- [Accelerando](https://en.wikipedia.org/wiki/Accelerando), which had a really neat take on a resolution of the Fermi Paradox,
  and just an overall fun tone.
- [The book of all skies](https://www.gregegan.net/ALLSKIES/AllSkies.html) by
  Greg egan, which as usual explores a neat universe, this time with some kind
  of monodromy.
- Honorary mention to [Perfect State by Brandon Sanderson](https://www.goodreads.com/book/show/25188109-perfect-state), a cute novella
  with a really neat twist at the end I didn't see coming.

As usual, I was reading some more sciencey things, this time on chemistry and nanotechnology,
which were the books
[Ignition! An informal history of rocket liquid propellants](https://www.amazon.co.uk/Ignition-Informal-Propellants-University-Classics/dp/0813595835),
[Inventing Temperature](https://global.oup.com/academic/product/inventing-temperature-9780195337389?cc=gb&lang=en&), and
[Engines of creation](https://en.wikipedia.org/wiki/Engines_of_Creation).


#### Looking Back

When I started writing this blog post, I felt that I hadn't learnt as much as I
did in [2019](https://bollu.github.io/stuff-i-learnt-in-2019.html). However, I
now see that I've learnt a bunch of things, just in a small domain (proof
assistants / type theory / logic). To be honest, this makes me kind of sad; I
miss learning different things, and I feel like I haven't gotten closer towards
some of my life goals of things I want to learn --- the standard model of
particle physics, the proof of resolution of singularities, and other such
goals. I'm going to try to make sure 2023 is more diverse in what I read,
to make sure I'm happy and sane, while continuing to become an expert in proof assistants `:)`. With that said,
I'd like to set concrete goals for 2023:

- Learn enough QFT to know what the hell renormalization is.
- Learn enough QED to be able to explain what a feynmann path integral is.
- Get good enough at juggling to be able to juggle three balls consistenty.
- Write [my own proof kernel](https://github.com/bollu/qoc) for Lean.
- Implement and write the paper about elaboration of mutual inductives for
  Lean, and start thinking about coinductives.
- Continue working on Lean's LLVM backend, and make Lean the fastest functional
  programming language in the block.
- Learn to cook a proper three course meal consistently.
- Get good enough at [djembe](https://en.wikipedia.org/wiki/Djembe) to play
  [kuku](https://afrodrumming.com/djembe-rhythm-kuku/) consistently.
- Get good enough at the guitar to strum Snow and Can't Stop well enough.
- Build a routine for shuffle dancing, so that I can dance consistently to a song.
- Learn to rock climb well enough that I can do V4's consistently.

That looks like an ambitious list, and I'm glad it is. I'd like my years to be full of
interesting challenges and neat things I can point to at the end of year! With that said, happy new year!


# You don't know jack about data races

#### Toy example

- Consider a function `void incr() { global += 1; }`.
- On running this on multiple thread, the final value of `incr` can be too low.
- It can even be a constant! Thread 1 reads the value of `global(0)`, gets suspended, then writes `global = 0 + 1`
  at the end of the execution!
- It can even be *larger* than correect. If a 128 bit number is stored as two
  64 bit registers, data races could cause the high and low parts to desync,
  causing the final count to be off. Assume we have two decimal bits `lo, hi`.
  If we have `08` (`hi=0, lo=8`) and both threads try to update, one thread
  wants to write `09` and the other thread which writes after this wants to
  write `10`. An interleaving can cause `19`, which is way larger than `10`.


#### Rules of Racy Programs

- Sequentual consistency: A program is executed by interleaving steps from each thread.
  Logically the computer executes a step from one thread, then picks another
  thread, or possibly the same one, executes its next step, and so on.
- Real machines sometimes have non-sequentially consistent semantics, due to assignments
  being visible to threads out of order. (QUESTION: This is at the C level. But if we view it at
  the hardware level, it's still sequentially consistent?)
- All modern languages promise sequential consistency for programs **without data races**.
- What is a data race?
- Two memory operations **conflict** if they access the same location and at least one of them is a write.
- Two **conflicting data operations** form a **data race** if they are from different threads and
  can be executed "at the same time". But wen is tis possible? Clearly, this depends on the semantics
  of parallel computation, which we are trying to define in the first place!
- We break this circularity by considering only **sequentially consistent** executions.
- Two **conflicting data operations** form a **data race** iff (definition)
  one executes immediately after the other in that execution’s interleaving.
- Now we can say that a program is data-race-free if none of its sequentially
  consistent executions has a data race.
- We define this in terms of **conflicting data operations** to exclude synchronization
  operations on mutexes. Synchronization operations do not constitute a data race even if they appear
  next to each other in the interleaving.
- Thus, the programming model is:

1. Write code such that data races are impossible, assuming that the
   implementation follows sequential consistency rules.
2. The implementation then guarantees sequential consistency for such code.

#### Counter-intuitive implications

- Consider an example where the initial state is that `x,y` are false.

```
P1: if(x) { y = true; }
P2: if(y) { x = true; }
```

- There is no sequentially consistent set of executions where both assignments are executed.


#### Higher Level

- [Article](https://www.cs.helsinki.fi/group/nodes/kurssit/rio/papers/adve_boehm_2012.pdf)



# Training a custom model for Lean4

- Bert: 111m (0.1BN)
- Gato : 1.2 BN
- GPT 2: 1.5 billion
- DALL-e: 12 billion
- Codex: 12 billion
- GPT 3: 172 BN
- Leela zero: 2 GB --- 0.5 million
- Jax
- [GPT 3 on CS-2](https://www.youtube.com/watch?v=paAF8eaEqsM)
- [Zero algorithm](https://arxiv.org/pdf/1910.02054.pdf)
- composer versus deepspeed versus fairscale
- linformer for lean4? can attend to the entire file? 10^6 attention from 10^3, a
  million. That's number of lines in mathlib. But how do we generate correct proofs of weird looking
  compilers statements? what do we start with?

# Stratified synthetsis

> The key to our results is stratified
> synthesis, where we use a set of instructions whose semantics
> are known to synthesize the semantics of additional instruc-
> tions whose semantics are unknown. As the set of formally
> described instructions increases, the synthesis vocabulary
> expands, making it possible to synthesize the semantics of
> increasingly complex instructions

- [Paper reference](https://dl.acm.org/doi/pdf/10.1145/2908080.2908121)



# Mutual recursion elaboration in Lean

Lean has four backends for elaborating mutual definitions.

-   Lean, given a mutual def block, can compile to (1) partial, which is
    just an opaque blob in the kernel, (2) primitive recursion on an
    inductive type via `recOn`, (3) well founded induction via `WF`,
    and (4) `brecOn` + `casesOn`, which allows us to split the recursion
    into the pattern matching part (casesOn) and the recursion part
    (brecOn).

-   (2) `recOn` is primitive recursion, and is synthesized by the
    kernel for every inductive declaration. It is often complicated to
    elaborate pattern matching syntax into a primitive recursor, and is
    a research question for the mathematically correct, complete
    solution which handles all cases. This is the lowest level of
    recursion in Lean, and supports good definitional equality. However,
    the code generator does not currently generate code for `recOn` of
    mutal inductives, and thus cannot be executed. When working with
    objects that live in `Type`, it is a good idea to use `recOn` right
    now, since (a) it reduces correctly, and (b) has no computational
    content.

-   (3) `WF` is well founded recursion on a terminating metric, which
    allows one to express functions more easily than primitive
    recursion. Currently, mutual recursion elaborates into `WF`. The
    drawback is that it has poor definitional equality, and thus breaks
    a lot of convenient reasoning. It has support in the code generator,
    since the code generator supports evaluating `recOn` of non-mutual
    definitions (which `WF` is).

-   As an example of where `WF` is more convenient than `recOn`, think
    of ackermann in first order logic. It's not primitive recursive, but
    does terminate by well founded induction on the lexicographic metric
    of the naturals. Another example is the hydra tree, which is a crazy
    game which is known to be finite, but any proof system that can
    prove the game is finite has at least as much proof strength as PA
    (Kirby and Paris).

-   (4) `brec` + `casesOn` which is used to elaborate inductive
    predicates. `brec` is bounded recursion, which allows using
    $k$-inductoin: using inductive hypothesis upto $k$ children behind
    you. Useful for encoding things like fibonacci, where for a
    $S(S(n))$ depends on $S(n)$ and $n$ (2-induction). This way of
    elaborating mutual inductives splits the matching part (`casesOn`)
    from the indction part (`brecOn`), and is thus more convenient to
    elaborate into than a lower level `recOn`. There are some bugs
    luring in the lean elaborator for inductive predicates, so this is
    not fully figured out.

-   Coq gets away with this stuff, because coq has `fix` + `match` in
    the kernel, and they have guardedness checks *in the kernel* which
    checks that the fix is structurally decreasing or whatever. This is
    complicated, and has led to many soundness bugs in the kernel. Thus,
    Lean wishes to avoid this.

-   Thus, in an ideal world, we would improve the elaborator to
    elaborate everything into `rec`, and would teach the code generator
    how to code generate mutual `rec`.

#### Simp Bottlenecks

Benchmarking simp with perf showed us that the bottleneck in one example
was in `congr`, which recursively calls `simp` and `dsimp` (dsimp is a
variant of simp which preserves definitional equality). This needs to be
investigated further.

Another bottleneck could be that simp processes bottom-up. This can lead
to quadratic behaviour on certain tests. For example, consider:

```
(not (and A  B) = (or (not A) (not B)
```

We denote the currently processed node with square brackets `[.]` If we
proceed top-down, see that we would need a quadratic number of steps,
because we need a linear number of steps to reach the top from the
bottom, where we push down the `not`. We must repeat this till fixpoint.

```
(not (and (and  a   b )  c ))
(not (and (and  a   b ) [c]))
(not (and (and  a  [b])  c))
(not (and (and [a]  b)   c))
(not (and [and  a   b]   c))
(not [and (and  a   b)   c])
[not (and (and  a   b)   c]
;; TRANSFORM=>
(or (not  (and a b) (not c))
;; ...
```

#### Simp lemma generation

If we define functions in a mutual def block, and we tag these functions
as `simp`, then simp must generate simp lemmas. If we have a definition
of the form:

```
inductive X where
| X1 | X2 .. | Xn

def foo: X -> X -> Bool
| X1, _ => True
| _, X2 => False
```

the theorems will be:

```
theorem foo.simp1 (x x': X) (h: x = X1): foo x x' = True.
theorem foo.simp2 (x x': X) (h: x /= X1) (h': x' = X2): foo x x' = False.
```

This could be very expensive in case we have complicated mutual
definitions, since Lean can blow up if we have many inductives.


# Subject reduction in Lean

Not exactly. Subject reduction is the property that if you replace a subterm of
a term with a defeq one (especially if the subterm is the result of reduction),
the resulting big term remains typecheckable. This fails in lean because if you
reduce some of the identities in @id A (@id B (@id C t)) you can deduce
transitivity of defeq, so by applying one of the counterexamples to
transitivity you get a term such that reducing the internal identity functions
results in another term that doesn't typecheck


```
variables {A : Type} {R : A → A → Prop} (x : A) (h : acc R x)

def my_rec : ∀ x : A, acc R x → ℕ := @acc.rec A R (λ _, ℕ) (λ _ _ _, 1)
def inv {x : A} (h : acc R x) : acc R x := acc.intro x (λ y h', acc.inv h h')
example : inv h = h := rfl -- ok
#reduce my_rec x (inv h) -- 1
#reduce my_rec x h -- acc.rec _ h

-- failure of transitivity
#check (rfl : my_rec x (inv h) = 1) -- ok
#check (rfl : inv h = h) -- ok
#check (rfl : my_rec x (inv h) = my_rec x h) -- ok
#check (rfl : my_rec x h = 1) -- fail

-- failure of SR:
#check @id (my_rec x h = 1) (@id (my_rec x (inv h) = 1) rfl) -- ok
#check @id (my_rec x h = 1) (@id (1 = 1) rfl) -- fail

-- fooling tactics into producing type incorrect terms:
def T (X : 1 = my_rec x h → Type) :
  X (@id (1 = my_rec x (inv h)) rfl) = X (@id (1 = my_rec x (inv h)) rfl) :=
by { dsimp, refl }
-- kernel failed to type check declaration 'T' this is usually due to a buggy tactic or a bug in the builtin elaborator
-- elaborated type:
--   ∀ {A : Type} {R : A → A → Prop} (x : A) (h : acc R x) (X : 1 = my_rec x h → Type), X _ = X _
-- elaborated value:
--   λ {A : Type} {R : A → A → Prop} (x : A) (h : acc R x) (X : 1 = my_rec x h → Type), id (eq.refl (X rfl))
-- nested exception message:
-- type mismatch at application
--   X rfl
-- term
--   rfl
-- has type
--   1 = 1
-- but is expected to have type
--   1 = my_rec x h
```


# Big list of GNU Binutils

- `nm` to list all symbols in an object file.

#### ld

- [trace-symbol](https://sourceware.org/binutils/docs/ld/Options.html#index-symbol-tracing) to trace symbol information.

#### List symbols in a file

Use `nm` to list all symbols in a file.

# Axiom K versus UIP
- UIP: all proofs of equality are equal: `(p q: Eq A a a'): Eq (Eq A a a') p q`
- Axiom K: all proofs of equality are equal to refl: `(p: Eq A a a): Eq (Eq A a a) p (refl A a)`

#### Where is K used in pattern matching

- `K` can be proven by depenedent pattern matching on the identity type!

```
K : (p : x = x) -> p = refl
K refl = refl
```

> In fact, Conor McBride showed in his thesis ("Dependently typed functional
> programs and their proofs (2000)") that K is the only thing that dependent
> pattern matching really adds to dependent type theory.

> Indexed type definitions could be interpreted as non-indexed definitions with
> extra equality proofs in constructors that set the indices. In Agda, what
> ultimately matters is the method for unifying indices in dependent pattern
> matching, so _≡_ can be seen as a wrapper for whatever notion of equality
> stems from pattern matching. But pattern matching is ultimately reducible to
> applications of either Axiom K or Axiom J. So, even in the context of Agda,
> you should just look at the bare-bones refl/Axiom J definition of equality to
> see where the extra equalities come from.

- [What is axiom K](https://stackoverflow.com/questions/39239363/what-is-axiom-k)
- [Pattern matching without K](https://stackoverflow.com/questions/39264130/is-agda-without-k-less-powerful?noredirect=1&lq=1)


# Linear vs uniqueness types
- A function `A -o B` which is linear in `A` guarantees that the function *consumes* A
- A function `Unique<A> -> B` guarantees that the function holds the *only reference* to `A`.

# Any model of lean must have all inductives

- Or, lean knows about the sizes of types.
- See that the below proof script shows that

```
inductive one: Type
| o1

inductive two: Type
| t1 | t2

theorem one_neq_two: one ≠ two :=
have h1 : ∀ x y : one, x = y := by
  intros x y; cases x; cases y; rfl
have h2 : two.t1 ≠ two.t2 :=
  by intro h; cases h
λ h => by
rw [h] at h1
exact h2 (h1 two.t1 two.t2)
```


# Index over the past, fiber over the future

- indexed view corresponds to `check`
- fibered corresponds to `infer`: given a term, tell me the type of the term?
- Some talk by conor at topos.




# Type formers need not be injective

```
abbrev Powerset (X: Type) := X -> Prop -- the powerset of a type is the collection of all subsets.
```

- This shows that we can create type formers which are not injective.
- This means that inductives are indeed special, for us to be able to have that, eg, `cons a as = cons b bs` implies
  that `a = b /\ b = bs`.

# There cannot be a type of size the universe

```
axiom CODE : Type -- assume we have CODEs for types...
axiom decode : CODE -> Type -- and a decoding...
axiom decode_surjective: ∀ (t: Type), { code: CODE // decode code = t } -- which is surjective on types.
abbrev Powerset (X: Type) := X -> Prop -- the powerset of a type is the collection of all subsets.

abbrev codedU := Σ (code: CODE), decode code -- create the set of all values that are reachable by decoding the codes...
abbrev UcodedU := Powerset codedU -- build its powerset...
noncomputable def codedUcodedU: { code_UcodedU : CODE //  decode code_UcodedU = UcodedU } := by { -- encode this...
  apply decode_surjective;
}
noncomputable def cantor (UcodedU: Powerset codedU): codedU := -- use the fact that the UcodedU has a code....
    ⟨ codedUcodedU.val, by { have H := codedUcodedU.property; simp[H]; exact UcodedU } ⟩
-- Now run cantor diagonalization.
```

# The dependently typed expression problem

Dependently typed programming is like the expression problem.
We can either write Ohad/OOP, where we have data and proofs (behaviour)
next to each other. Or we can write in Xavier/functional style, where
the data is separate from the proofs (behaviour).

# Motivation for modal logic

- `possibly A -> necessarily (possibly A -> B) -> necessarily B`
- this weakens the precondition `A -> (A -> B) -> B` by needing only `possible A`
  and strengthens the postcondition by spitting out `necessarily B`.
- Key idea 1: if A is true in no world `w`, then `possibly A` that we have is false, and from this we derive explosion.
- Key idea 2: if A is true in some world `wa`, then suppose we are in some arbitrary world `wr`.
- Since `A` is true in `wa`, we have `possibly A`.
- Since `necessarily (possibly A -> B)` is true in all worlds, we have `(possibly A -> B)`.
- Since we have both `possibly A`, and `possibly A -> B`, we derive `B` in `wr`.
- Since `wr` was arbitrary, we then have `necessarily B` since `B` holds in any arbitrary worlds.

#### Use of this for Kant
- experience of objects is possible.
- it is necessarily the case that if experience is possible, then I must have some way to unite experience.
- thus, necessarily we have unity of experience.

#### Use of this for descartes
- it is possible for me to be certain of something (ie, I think therefore I am)
- it is neecessarily the case that if I can be certain of something, I have clear and distinct perception.
- Therefore, it is necessary that I have clear and distinct perception.

# Scones

- take $C$ a category. There is a global sections functor $\Gamma: C -> Set$ given by $Hom(1, -)$.
- take the pullback $C \xrightarrow{\Gamma} Set \xleftarrow{cod} Set^{\to}$.

- From any type theory $T$, we build $syn(T)$, where objects are the types, and morphisms are terms with
  free variables. (ie, $A \to B$ is a term of type $B$ involving a free variable of type $A$)
- whatever structure $T$ had will be visible in $syn(T)$. eg: if $T$ has products, then $syn(T)$ will have products.
  moreover, $syn(T)$ will be the initial such category. For any other $C$ with the appropriate structure, there will a functor $syn(T) \to C$.
- To use this to prove properties of $T$, we'll need to cook up a special $C$, so that $syn(T) \to C$ can tell us something.
  Further, this $C$ must somehow depend on $T$ to explore properties of $T$, so let's call it $C(T)$.
- We must use the uniqueness of the morphism $syn(T)$ to $C(T)$ (ie, the initiality of $syn(T)$), because that's what makes
  this thing universal.

- [An introduction to fibrations, topos theory, the effective topos and modest sets](http://www.lfcs.inf.ed.ac.uk/reports/92/ECS-LFCS-92-208/)
- [Scones, logical relations, parametricity](https://golem.ph.utexas.edu/category/2013/04/scones_logical_relations_and_p.html)


# Presheaf models of type theory
- Let $C$ be any category.
- Contexts are presheaves $\Gamma: C^op \to Set$. Morphisms are natural transformations of presheaves.
- an element of a context $Elem(\Gamma)$ is a global element / grothendieck construction / object in the category of elements of contexts:
  $\Sigma{I:Ob(C)} \Gamma(I)$
- A type in the context, $\Gamma \vdash T$ is a presheaf over the category of elements $\alpha \in T(I, \rho)$.
- A term $\Gamma \vdash t: T$ is $t: (I: Ob(C)) -> (\rho: \Gamma(I)) -> T(I, \rho)$.
- substitution is a natural transformation $\sigma: \Gamma \to \Delta$.


- [A presheaf model of dependent type theory by Alexis Laouar](https://perso.crans.org/alaouar/rapportm1.pdf)
- [Ref: Cubical type theory with several universes in nuprl](https://www.youtube.com/watch?v=ioa-f_nCNuE)

# Weighted limits via collages

#### Collage of a profunctor.
- more explicitly, for `P : C -|-> D`, define `Collage(P)` as the category where `Obj(Collage(P)) = Obj(D) + Obj(C)`, `Collage(P)(inl x, inl y) = D(x,y)`, `Collage(P)(inr x, inr y) = C(x,y)`, `Collage(P)(inl x, inr y) = P(x,y)`, `Collage(P)(inr x, inl y) = 0`
- It is the categorification of a cograph. A graph is where we take the product `A \times B` and then take a subset of it where `f(x) = y` (equalizer).
- A cograph is where we take the union `A \cup B` and then impose a quotient `f(x) ~ y` (coequalizer).
- When we categorify this, we don't coequalize, but we setup arrows that capture the morphisms.

#### Quick intro to enriched (pro)functors.

- In an enriched category, we replace hom sets by hom objects which live in some suitable category $V$.
- The category must be monoidal, so we can define composition as $\circ: hom(y, z) \otimes hom(x, y) \to hom(x, z)$.

#### Weighted Limits via collages

- Let `1` be the terminal enriched category, having 1 object `*` and `Hom(*,*) = I`, and `I` is the unit of the monoidal structure `(V, (x), I)` of the enrichment.
- A weighted cone over `D : J -> C` with weight `W : J -|-> 1` (where `I` is the terminal enriched category over `V`),
  is a functor `G` from the collage of `W: J -|-> 1` to `C` that agrees with `F` on the copy of `J` in the collage.
  So, `G: Col(W) -> C`, or `G: J+* -> C` where `G(J) = D`.
- Unravelling this, construct the category `Col(W) = J+*` with the morphisms in `J`, morphism `I: * -> *`, and a bunch of arrow `J -> *`. So we are adding an "enriched point",
  with an arrow `I: * -> *`.
- What does a weighted cone `G: Col(W) -> C` have that doesn't just come from `F: J -> C`?  Well, it has an object `X` (for apeX) to be the image of `(inr *): J+*`,
  and it has the collage maps `W(inl j -> inr *) -> C(j -> X)` for all `j` in `Obj(J)`, and these maps commute with the base maps of `F`.
  So far, this looks like a cone. However, note that the collage maps are enriched maps!
-  The natural transformations can only choose to move where `*` goes, since that's the only freedom two functors `G, G:':J+* -> C` have,
   since they must agree with `F` on `J`: `G(J) = G'(J) = F(J)`.
   This is akin to moving the nadir, plus commutation conditions to ensure that this is indeed a cone morphism.

- Maps of these weighted cones are natural transformations that are identity on the copy of `J`
- Terminal means what it usually does. A terminal weighted cone is a weighted limit.


```
15:51 <xplat> *C(X,F(j))
How does this look in our ordinary Set-enriched world?  a `W`-weighted cone has its ape`X` and for each `j` in `J`
  it has a `W(*,j)`-tuple of arrows `x_j,k : X -> F(j)` in `C` and for each `g : j -> j'` we have equations `x_j,k . F(g) = x_j',W(*,g)(k)`
15:57 <xplat> both correct
15:57 <xplat> wait, no
15:58 <xplat> first correct
15:58 <xplat> maps of weighted cones are natural transformations `eta : F => F' : Collage(W) -> C` that are identity on the copy of J in Collage(W)
16:04 <xplat> in the `Set`-enriched world, a map of `W`-weighted cones is a map `f : X -> X'` in `C` and for each `j` in `Obj(J)` and `k` in `W(*,j)` we have equations `x_j,k = x'_j,k . f`
16:08 <xplat> so you can take a simple example, the second power.  For this example, `J = 1`, `W(*,*) = 2`, `F` picks out some object `c`, so each weighted cone consists of `X` and `x_*,0 : X -> c` and `x_*,1 : X -> c` and no equations
16:09 <xplat> what does the terminal weighted cone look like in this example?
```

#### Weighted limit via `nlab`

- Let $K$ be a small category, which is the diagram.
- Suppose $F: K \to \mathsf{Set}$.
- See that cones of $F$ corresond to natural transformations $[K, \mathsf{Set}](\Delta(p), F)$ for $p \in \mathsf{Set}$.
- See that the limit represents cones: $\mathsf{Set}(p, \texttt{Lim} F) \simeq [K, \mathsf{Set}](\Delta(p), F)$, natural in $p$
- Generalizing this to arbitrary category $C$, we can write

- [Ref: nlab](https://ncatlab.org/nlab/show/weighted+limit)

# Disjoint Coproduct

- One says that a coproduct $X+Y$ is disjoint iff the intersection of $X$ with $Y$ in $X+Y$ is empty.
- The intersection of $A, B$ over $X$ is defined as the pullback of the diagram (in fact, cospan) $A \rightarrow X \leftarrow B$.
- Thus, in this case,  we say that $X, Y$ are disjoint iff the pullback of $X \rightarrow X+Y \leftarrow Y$ is the initial object.

- [Disjoint coproduct](https://ncatlab.org/nlab/show/disjoint+coproduct)



# Leibniz Equality in Lean4

```
@[simp, reducible]
abbrev Leibniz {A: Type} (x y: A) := ∀ (P: A -> Prop), P x -> P y

theorem Leibniz_refl {A: Type}: ∀ (x: A), Leibniz x x := fun _A _P Px => Px
theorem Leibniz_trans {A: Type}: ∀ (x y z: A), Leibniz x y -> Leibniz y z  -> Leibniz x z :=
        fun _x _y _z Lxy Lyz P Px => Lyz P (Lxy P Px)

theorem Leibniz_sym {A: Type}: ∀ (x y: A), Leibniz x y -> Leibniz y x :=
  fun x y  Lxy P Py =>
      let prop (a: A) := P a -> P x
      let proofPropX : prop x := id
      let proofPropY: prop y := Lxy prop proofPropX
      proofPropY Py

theorem defeq_implies_Leibniz (x y: A) (EQ: x = y):
  Leibniz x y := fun P Px => EQ ▸ Px

theorem Leibniz_implies_defeq (x y: A) (LEQ: Leibniz x y):
  x = y := LEQ (fun a => x = a) rfl
```

# Strong normalization of STLC

- Recall that in the category Hask, objects are types, morphisms are functions/expressions.
- Recall that in the category of contexts, objects are contexts, morphisms are substitutions.
- A local predicate $L$ will relate to an object (type/context) a collection of morphisms
    (type → expressions of that type, typing context → substitutions of the variables of the typing context where the
    expressions have the type as per the context).
- Consider STLC with the typing rules:

```
------
Γ⊢():Unit
```

```
Γ ⊢ (f:A→B); Γ ⊢ (x:A)
----------------
Γ⊢ f@x:B
```

```
Γ,(a:A) ⊢ (body:B)
----------------
Γ ⊢  (λa.body:A→B)
```

- Define the logical prediate `Ltype: Type → Set(Expression)`, by induction on the rules:

```
--------------------------
  () ∈ LType(Unit)
```


```
f ∈ LType(A→B); x∈LType(A)
--------------------------
  f @ x ∈ LType(B)
```

```
body ∈ LType(B); (∀ aval∈ Ltype(A), body[a/aval] ∈ Ltype(B))
--------------------------
  λa.body ∈ LType(A→B)
```

- It is clear that `x ∈ LType(T)` implies that `x` is strongly normalizing.
- When we try to prove that `Γ ⊢  x : T` implies  `x ∈ LType(T)`, we get stuck on the
  case of the lambda, because it's impossible to prove that a well typed term
  `(λa.body):A→B` is such that upon substitution, `body[a/aval]` will be strongly normalizing.

- So we control the context as well, and create another relatoin `LCtx(Γ)`. For a given context
  `Γ: Var → Type`, we say that a substitution `γ: Var → Expr` is in `LCtx(Γ)` iff `dom(γ) = dom(Γ)`,
  and that for all `x∈ dom(Γ)`, that `γ(x) : Γ(x)` and `γ(x) ∈ LType(Γ(x))`. Maybe written with a little abuse of notation,
  this means that if `(x:T)∈ Γ`, then `γ(x):T`, and `γ(x)∈ LType(T)`. That is, `γ` is a set of assignments
  for the typing context `Γ` where each assignment is strongly normalizing.

# Subobject classifiers of $N \to FinSet$, or precosheaf of $FinSet$

#### Subobject classifier in $S^2$

- Start with $Set^2$. This has as objects $X_0 \to X_1$. The subobjects are of the form:

```
   f
S0 -> S1
v     v
|i    |i'
v     v
X0 -> X1
   g
```

- we can identify $i(S_0)$ with a subset $T_0$ of $X_0$, and $i'(S_1)$ with a subset $T_1$ of $X_1$.
- The diagram commuting implies that $g(i(S_0)) = i'(f(S_0))$. This means that $g(T_0) = i'(f(S_0))$, or that $g(T_0) \in im(i') = T_1$.
- Thus, we have that $g(T_0) \subseteq T_1$.
- We define the subobject classifier as having values $T, \triangleright T, \triangleright^\infty T$, where $T$ is interpreted as "is a subobject" (is true),
  and $\triangleright$ is interpreted as "delay" (ie, will be a subobject in the next timestep).
- An element $s \in S_0 \subset X_0$ will be classified as $T$.
- An element $s \not in X_0, s \in X_1$ will be classified as $\triangleright T$, since it lands in $X$ in one timestep.
- An element $s \not in X_0, s \not \in X_1$ will be classified as $\triangleright^\infty T$, since it lands in $X$ after
  infinite timesteps (ie, never).
- We can alternatively think of $\triangleright^\infty \sim \triangleright^2$, since it takes "two timesteps", but the second
  timestep is never materialized.

#### Proof that this is the subobject classifier

- We formally define the subobject classifier as $\Omega_0 \xrightarrow{\omega_0} \Omega_1$, where
  $\Omega_0 \equiv \{ T, \triangleright T, \triangleright^\infty T \}$, $\omega_1 \equiv \{T, \triangleright T \}$.
- The map is $\texttt{force}_0$, $T \mapsto T$, $\triangleright T \mapsto T$,
  $\triangleright^\infty T \mapsto \triangleright^\infty T$.
- Informally, the map can be said to be given by $\texttt{force} \equiv (T \mapsto T, \triangleright^{n+1} T \mapsto \triangleright^n T)$.
- We call it "force" since it forces a layer of delay.
- We define the bijection between subobjects $(S \xhookrightarrow{f} X)$ and classification maps $(X \xrightarrow{\xi[f]} \Omega$
  as follows: Let $i$ be the least $i$ index such that $f(S_i) \in X_i$. Then have $\xi[f]_0 = \triangleright^i T$. See that
  by the square, this determines $\xi[f]_{i}$ for all larger $i$:

```
X0 ---Χ[f]0--> Ω0
|               |
f0            force0
v               v
X1 - Χ[f]1- -> Ο1
   [to be determined]
```

- We have the obvious


#### Why $N \to FinSet$ does not have subobject classifier

- The objects in this category are sequences of sets $(X_0 \to X_1 \to X_2 \to \dots)$.
- We claim this category


# Dimensions versus units
- `gram/kg` is dimensionless because it's length/length, but it indeed has units `g/kg`, since it's
  the conversion ratio between grams versus kilograms.


# HoTTesT: Identity types

- [lecture](https://www.youtube.com/watch?v=oMKl7pBRg1E&list=PLtIZ5qxwSNnzpNqfXzJjlHI9yCAzRzKtx&index=8).
- We already have judgemental equality. (computational equality: beta eta alpha equality).
- We will next introduce propositional equality.
- Proving an equality => constructing a term of the type of equalities.
- We can prove many judgemental equalities (eg. `add x 0 =judgement= x`), but not all the ones we want
  (eg. `add 0 x =judgement= x`).
- We can't because we need to do induction on `x`.
- When we use natural number elimination / induction, we must produce a term of a type.
- What type?!
- Type constructors internalize structure. Eg. at a meta level, we can talk about contexts `x:A, y:B(x), z:C(x,y)`.
- But internally, we will need to be able to talk about contents, we can use sigma types! `Σ(x:A) Σ(y: Bx) Σ z:C(x, y)`
  lets us internalize contexts!
- Similarly, we can think about dependent terms  as `meta` functions. Example, `x:A,y:B(x) |-  c(x,y): C(x, y)`.
  We can think of this as a function that takes an `x` and a `y` and produce a `c(x,y)`. See that pi types
  internalize this notion! `c: (x:A) -> (y: B(x)) -> C(x,y)`.
- Bool, Nat, etc. are internalizing the usual booleans, naturals, etc.
- The universe type internalizes the judement `A is a type` via `A: Type`.
- The identity type internalizes the meta notion of judgemental equality (how? Doesn't it prove strictly more?)



#### Identity Type

- $=$-formation: A type `a: A`, `b: B`, then we have a type `a =A b type`.
- `=`-intro: `a:A| r_a: a =A a`. (`r` = reflexivity).
- `=`-elim: `x: A, y: A, z: x =A y |- D(x, y, z) type`, and given `x:A |- d: D(x, x, r_x)`, then we have  `ind=(d, x, y, z): D(x, y, z)`

# Left and right adjoints to inverse image

#### The story in set

- Suppose $f: A \to B$ is a morphism of sets.
- Then there is an associated morphism $f^*: 2^B \to 2^A$, the inverse image.
- We get two associated morphisms, $\forall_f, \exists_f: 2^A \to 2^B$, which perform universal and existential
  quantification "relative to $f$".
- The idea is this: think of $A$ as being fibered over $B$ by $f$. Then $\forall_f(S \subseteq A)$
  gives the set of $b \in B$ such that the fiber of $b$ lies entirely in $A$. That is, $f^*(b) = f^{-1}(b) \subseteq A$.
- In pictures, Suppose the `@` mark the subset $S$ of $A$, while the `-` is outside the subset. We draw $A$ as being
   fibered over $B \equiv \{b_1, b_2, b_3\}$.

```
-   @  @
-   -  @
-   -  @
|   |  |
v   v  v
b1 b2 b3
```

- Then, $\forall_f(A)$ will give us $b_3$, because it's only $b_3$ whose entire fiber lies in $A$.
- Dually, $\exists_f(A)$ will give us $\{ b_2, b_3 \}$, because _some portion_ of the fiber lies in $A$.

#### The story in general

- Suppose we have a presheaf category $\hat C$. Take a morphism $(c \xrightarrow{f} c')$

#### The story in slice categories

- If we have $f: A \to B$ in `Set`, then we have $f^*: Set/B \to Set/A$, which
  sends a morphism $(K \xrightarrow{g} B)$ to $(K \xrightarrow{g} B \xrightarrow{f^{-1}} A)$.
- This also motivates the presheaves story, as $Set/B \simeq Set^B$.
- Recall that any morphism $K \xrightarrow{h} B \in Set/B$ can be equally seen as a morphism $b \mapsto h^{-1}(b) \in Set^B$.
  This is the mapping between slice and exponential.
- We can think of $(K \xrightarrow{h} B) \in Set/B$ as a collection $\{ h_b \equiv h^{-1}(b) \subseteq B \}$.
  This is the fibrational viewpoint.
- Then the functor $f^*(\{ h_b : b \in B\}) \equiv \{ h_{f(a)} : a \in A\}$.
- TODO


# Paredit via adjoints

- We posit that text editor movements ought to be endofunctions, and complementary keybinds
  ought to be adjoints to each other.
- With this in mind, what is the correct category for `paredit`, and what are the adjunctions?
- Suppose we wish to build a theory of `Sexp`s. Then let's consider the category of rooted trees,
  where the root is the currently selected sexp, where the morphisms are inclusion maps of trees.
- What are the operations? They are going to be endofunctions in this category. For example, moving up to the
  parent, moving to the left and right sibling, etc.
- Hopf algebras and rooted trees (https://personal.math.ubc.ca/~thomas/TeXthings/HopfAlgebras-1.1.pdf)


# Less than versus Less than or equals over Z

-  If we have a theorem whose hypotheses and goal are of the form `a <= b - 1` for `a, b` integers,
   is it always safe to replace these with `a < b`? Shockingly, no!
- Consider the theorem: `(a <= n - 1) => (2a <= 2n - 2)`.
- When we lose the information to `. < .`, it becomes `(a < n) => (2a < 2n - 1)`.
- But this can't be proved, because the best we can do is `(a < n) => 2a < 2n`!
- The key reason is that even though `(a < n) <-> (a <= n - 1)` is an equivalence, we can't
  always rewrite with an equivalence under an inequality!
- Said differently, `a <= n - 1` is equivalent to `a < n`, but once we start performing *algebra*
  on these, we start seeing the difference.
- This came up in the context of delinearization. I was trying to prove that if `i < N` and `j < M`, then `iM + j < NM`.
- This proof, while state in terms of `<`, actually needs us to go through `<=`:
- `i <= (N - !)`, so `iM <= NM - M`, so `iM + j <= (NM - M) + (M - 1)`, which means `iM + j <= M - 1`, or `iM < M`.

# Allegories and Categories

- An allegory is a category enriched over posets, where each morphism $r: A \to B$
  has a converse $r': B \to A$.

# Partial function as span

- A partial function $f: D \subseteq X \to Y$ is a span of $Y \leftarrow D \hookrightarrow X$.
  What a slick definition!
- See that if $Y = 1$, then a partial function $X \to 1$ carries only the data of $D \hookrightarrow X$, giving us
  subobjects.


# Turing degree

- [Lectures on turing degree](https://pi.math.cornell.edu/~shore/papers/pdf/SingLect2NS.pdf)
- A set $X$ is turing reducible to $Y$ iff oracle access to membership in $Y$ provides
  decidable membership for $X$. (imagine $Y$ as hovering above $X$, as we are given oracle access to $Y$). This is written as $X \leq_T Y$.
- Two sets are turing equivalent iff $X \leq_T Y$ and $Y \leq_T X$, also written as $X \equiv_T Y$
- Clealy, $\equiv_T$ is an equivalence relation.
- A **turing degree** is an equivalence class of $\equiv_T$.
- Said differently, it is a maximal strongly connected component of the $\leq_T$ graph.
- Turing degrees have a partial order, where $[X] \leq [Y]$ iff $X \leq Y$ (note that the precise representatives of each class do not matter).
- A set is **recursively enumerable in $A$** if it is the domain of some partial function recursive in $A$ (ie, can write a partial function that semidecides membership
  in $S$ given oracle access to $A$.)
- The jump of a set $A$, written $A'$, is the set of programs $p$ (treated as natural numbers such that $A' \equiv { p | eval^A(p)(p) \downarrow }$, where $\downarrow$ means converges.
  That is, it's the set of natural numbers $p$ such that when the $p$th program in the enumeration of programs with oracle access to $A$, when evaluated on $p$, converge.
- There is a unique turing degree containing all the computable sets [what does this mean? how is this (computably) a subset of the naturals?],
  called $0$ since $0 \leq_T Y$ for all $Y$. That is, oracle access to decision procedure for $0$ gives a decision procedure for $Y$
- $0'$ is the degree of the halting problem.
- The first jump is taken relative to $A \equiv \phi$.
-  The join of two sets is given by $A \oplus B \equiv \{ 2n : n \in A \} \cup \{ 2m + 1 : m \in B \}$. Claim that the turing degree of $A \oplus B$ is a LUB of the turing
  degrees of $A, B$.
- Cutland, N. Computability. Cambridge University


# Proof that there is a TM whose halting is independent of ZFC

- Start by assuming that ZFC is consistent.
- Consider a TM which enumerates proofs in ZFC (ie, sequents if we want to use sequent calculus),
 looking for a sequent that proves the inoncsistency of ZFC.
- If this TM halts, then it has proven inconsistency of ZFC, which contradicts our hypothesis.
- If it does not halt, then this means that we have proven the consistency of
  ZFC in ZFC, which contradicts Godel's incompleteness theorem.
- Thus, it is independent of ZFC whether TM M halts or not.

# Contradiction from non-positive occurence

We wish to show that allow non-positive occurences of the inductive type
in its constructor can lead to contradiction. Proof as haskell file below:

```hs
{-# LANGUAGE GADTs #-}

data Void where

data F where
  FnSpace :: (F -> Void) -> F

contra :: F -> Void
contra f@(FnSpace fn) = fn f


inhab :: F
inhab = FnSpace contra
```


# The constructible universe L

- When building **von neumann universe**, we take *all* subsets from previous state; $V(0) = \emptyset$, $V(n + 1) = 2^{V(n)}$,
  $V(\lim \alpha) = \cup_{\beta < \alpha} V(\beta)$.
- To build $L$ (the definable universe), first we need the notion of definability.
- For a set $X$, the set $Def(X)$ is the set of all $Y \subseteq X$ such that $Y$ is logically definable in the structure $(X, \in)$ (That is, we are given access to FOL and $\in$)
  from parameters in $X$ (that is, we can have free variables of elements of $X$).
- We can now build the constructible universe by iteratively constructing definable sets of the previous level.
- Can talk about definability in terms of [godel operations](https://en.wikipedia.org/wiki/G%C3%B6del_operation), which has
  ordered & unordered pairing, cartesian product, set difference, taking the domain of a binary relation, automorphisms of an ordered triple.
  These give us a "constructive" description of what we can do using
  definability. [See also: constructible universe at nLab](https://ncatlab.org/nlab/show/constructible+universe)
- [Computable universe](https://en.wikipedia.org/wiki/Constructible_universe)

#### Godel Normal Form theorem

- Theorem which says that constructible sets are those that can be built from godel operations.


# Godel completeness theorem

- If a formula is true (holds in every model), then it is derivable from the
  logic.
-  theory is syntactically consistent if one cannot derive both $s$ and $\lnot s$ from the deduction rules.
- Henkin's model existence theorem says that if a theory is syntactically consistent, then it has a model, for a 1st order theory
  with well orderable language.

#### Relationship to compactness

- Compactness and completeness are closely related.
- Compactness: If $\phi$ is a logical consequence of at most countably infinite $\Gamma$, then $\phi$ is a logical consequence of some
  finite subset of gamma.
- Completeness => compactness, since a derivation tree is a finite object, and must thus only use a finite number of rules.
- For compactness => completeness, suppose that `Γ |= φ`. We wish to show `Γ |- φ`.
- Compactness implies that `γ1, γ2, ... γn |= φ` where `{ γ1, ..., γn } ⊂ Γ`.
- That is the same as proving that `|= γ1 -> (γ2 -> (... (γn → φ)))`

#### Henkin model (term model)
- [References](https://en.wikipedia.org/wiki/G%C3%B6del%27s_completeness_theorem)


# Uniform proofs, focused proofs, polarization, logic programming

- Focusing and synthetic rules: http://requestforlogic.blogspot.com/2010/09/focusing-and-synthetic-rules.html
- girard statement about proofs as time; https://mathoverflow.net/a/179258/123769
- [Focused proof](https://en.wikipedia.org/wiki/Focused_proof)
- Polarity in type theory: https://existentialtype.wordpress.com/?s=polarity
- PhD thesis of Noam Zeilberger, polarity: http://www.cs.cmu.edu/~noam/thesis.pdf



# Why cut elimination?

- Morally spekaing, gives control over the formulae that occur in a proof.
- If we can conclude that `(X -> Y; Y -> Z)|(X -> Z)`, then the proof of `X -> Z`
  could be arbitrarily complex, since `Y` might be something crazy.
- If we have `cut`, we know that such arbitrarily crazy things cannot happen, as the `cut` rule is the
  only rule where we are forced to synthesize something "out of thin air".
- [Example of use of cut](https://mathoverflow.net/questions/8632/cut-elimination/64769#64769)

#### Cut implies consistency of first order logic (FOL)
- suppose we have cut for FOL
- If FOL is inconsistent, then there would be a proof of `False` starting from no premises.
- To be more formal, one could write `|- False` or `True |- False`.
- Written in terms of sequent calculus, this would be `[] |- []` (recall that the LHS is interpreted with `AND`, RHS with `OR`.
- But by cut, this would mean that the proof of `[] |- []` would involve only the the symbols in `Sym([]) U ([])` which is the empty set!
- Since there is no trivial proof of `False` with zero symbols, and all other derivation rules need symbols, there cannot be a proof of `False`!
- To repeat: a proof of `True |- False` or `[] |- []` could be `cut`-eliminated so it is *forced* to contain only the sumbols in `Sym([]) U Sym([]) = EMPTYSET`.
  This is absurd, and thus there is no proof of `True |- False`, which implies that the theory is consistent (assuming soundness).

#### References

- [An introduction to the complexity and combinatorics of cut elimination](https://www.ams.org/journals/bull/1997-34-02/S0273-0979-97-00715-5/S0273-0979-97-00715-5.pdf)
- [Reference](https://mathoverflow.net/questions/8632/cut-elimination)

# Forcing to add a function

- Let $M$ be a countable transitive model of ZFC.
- We will add a new function $c: \aleph_0^M \to \{0, 1\}^M$ into $M$ by creating $M[G]$.
- Let $P$ be the set of all finite partial functions from $\aleph_0$ to $\{0, 1\}$ in $M$.
- Let $G$ be a generic maximal ideal of $P$. That is, $G$ intersects every dense set of $M$.
- Also, since it is a maximal ideal, taking the full union $\cup G \equiv c$ will give us a well defined total function.
- It will be well defined since no two elements of $G$ disagree, and it will be total because if it were not, we could extend $G$,
  contradicting the maximality of $G$.
- Great, so if we can construct $M[G]$, we will also have $c = \cup G \in M[G]$.
- But how do we know that $c$ is new? Ie, how do we know that $c \not in M$?
- Well, consider for any function $h \in M$, the subset of $P$ that disagrees with $h$. That is, the subset
  $D_h \equiv \{ p \in P : \exists i, p(i) \neq h(i) \}$.
- See that $D_h$ is dense in $M$: Suppose $p \in P$, and $p$ is well-defined on some subset $S$. Either $p$ disagrees with $h$ on $S$,
  that is, there is some $s \in S$ such that $p(s) \neq h(s)$, in which case $p \in D_h$ and we are done.
- On the other hand, maybe $h|S = p$ (that is, $h$ restricted to $S$ fully agrees with $p$). Then we pick some point $s' \not in S$
  and extend $p$ into $p'$ to disagree with $h$ at $s'$. So define $p'(s') \equiv h(s') + 1$ or something. Now we have $p \leq p'$ and $p' \in D_h$.
- Since $D_h$ is generic, we have that $G \cap D_h \neq \emptyset$, thus $f$ disagrees with $h$ at some point!
- Thinking intuitively, it would be a CRAZY coincidence for it to agree with a function $h$ fully in $M$. If we build it "randomly",
  or "generically", one _would_ expect it to disagree with stuff in $M$ at some point in the construction!.
- Cool, we've now seen how to enlarge the universe to add a _single_ function of interest.
- [Reference](https://math.stackexchange.com/questions/1311667/what-are-some-simple-example-of-forcing-in-set-theory)

# Diaconescu's theorem

- Choice implies LEM
- Let $P$ be a proposition. Build the sets $T, F$ as:
- $T \equiv {x \in \{0, 1\} : (x = 1) \lor P}$, and $F \equiv x \in \{ 0, 1 \} : (x = 0) \lor P \}$.
- Note that if we had LEM, we could case split on $P$ via LEM and show that $x \equiv \{ 1 \}$ if $P$, and $x \equiv \{ 0, 1\}$ if
  $\not P$.
- However, we don't have LEM. So let's invoke Choice on the set $B \equiv \{T, F \}$. This means we get a choice function
  $c: B \to \cup c B$ such that $c(T) \in T$ and $c(F) \in F$.
- By the definition of the two sets, this means that $(c(T) = 1 \lor P)$, and $(c(F) = 0 \lor P)$.
- This can be written as the logical formula $(c(T) = 1 \lor P) \land (c(F) = 0 \lor P)$.
- This is the same as $(c(T) \neq c(F)) \lor P$.
- Now see that since $P \implies (U = V)$ (by extensionality), we have that $P \implies (f(U) = f(V))$.
- See that contraposition is available purely intuitionistically: (`(p -> q) -> (q -> false) -> p -> false`).
- Therefore, by contraposition $(f(U) \neq f(V)) \implies \lnot P$.
- This means we have $P \lor \lnot P$!

# Forcing machinery

- Let $M$ be a countable mode of ZFC (exists by lowenheim skolem).
- Let $\Omega \equiv \{0, 1\}$ ($\Omega$ for subobject classifier).
- Take $P$ to be the set of partial functions from $\aleph_2 \times \aleph_0 \to \Omega$ with finite support
- Note that elements of $P$ can be thought of as finite lists, where we know the values where they are 0, where they are 1.
- Also note that elements of $P$ can be arranged in an obvious partial order.

#### Ideal of a post
- We define an ideal $I \subseteq P$ to be a set of elements which are pairwise compatible (all pairs of elements have a union),
  and is downward closed (all elements with less information is present in the ideal).
- More formally, for any $i \in I$ and $p \in P$, if $p \leq i$, then $p \in I$. So $P \leq I \implies P \in I$.
- For every $i, i' \in I$, there is some $j \in I$ such that $i, i' \leq j$ ($I$ is a directed set).

#### Maximal ideal

- A maximal ideal $I_\star \subseteq P$ is an ideal such that for any $p \in P$, either $p$ is incompatible with $I_\star$,
  or $p$ is in $I_\star$.

#### Density in a poset

- A subset $D$ of a poset $P$ is dense iff for any $p \in P$, there is some $d \in D$ such that $d \geq p$.
  Intuitively, at any point in the poset, it is possible to "add more information" to reach $D$.

#### Generic Ideals
- We say that an ideal $G$ is generic iff $G \cap D \neq \emptyset$ for all dense $D \subseteq P$.
- For any countable model $M$, and a poset $P$ over it,
  We claim that for any $p \in P$, a generic ideal $G_p$ which contains $p$ ($p \in G$) exists.

#### Proof: Generic ideal always exists
- We wish to find a generic ideal that contains a special $p_\star \in P$.
- Let $D_1, D_2, \dots$ be an enumeration of the dense subsets of $P$ that are members of the countable model $M$.
- We can perform such an enumeration because $M$ is countable, and thus only has countable many sets.
- We will create a new sequence $\{q_i\}$ which hits each $\{D_i\}$.
- Start with $q_0 \equiv p_star$.
- Since $D_1$ is dense, there is some $d_1 \in D_1$ such that $d_1 \geq q_0$. Set $q_1 \equiv d_1$.
- This gives us a sequence $\{q_i\}$.
- Build an ideal $I^\star_p \equiv \{ p \in P : \exists i, p \leq q_i \}$. That is, we build the union of all the lower
  sets of $q_i$. So this can also be written as $I^\star_p \equiv \cup_i \downarrow q_i$, where $\downarrow(p) \equiv \{ p' : p' \leq p \}$, the down set of $p$.
- $I^\star_p$ is downward closed by construction, and is directed because for any two elements $a, b \in I$, there is some $q_i, q_j$
  such that $a \in \downarrow q_i$, $b \in downarrow q_j$, and WLOG, if $q_i \leq q_j$, then $a, b \leq q_j$, thereby making
  the set directed.


#### Separative poset
- $P$ is separative iff $p \leq q \leq p$ implies $p = q$.

#### Generic ideal of separative poset is not in the model

- Claim: if $G$ is a generic ideal of $P \subseteq M$, then $G$ is not in $M$.
- Let $H \subseteq P$, $H \in M$. Consider the set $D_H \equiv \{ p \in P : \exists h \in H, \texttt{incompatible}(p, h) \}$.
- Intuitively, $D_H$ is the set of all elements of $P$ which are incompatible with some element of $H$.
- We must have $D_H$ \in $M$  by `comprehension(M)`, since $M$ is a model of $ZFC$ ahd $D_H$ is a susbet of $P$.
- To see that $D_H$ is dense, for any element $p \in P$, we need to find an element $d \in D$ such that $p \leq d$.
  See that $d \in D$ iff there exists some $h \in H$, such that `incompatible(d, h)`.
- Since $D_H$ is dense, we have that $G \cap D_H \neq \emptyset$, This gives us some element $g \in G$ such that `incompatible(g, p)`
  for some $p \in H \subseteq P$.
- TODO: this makes no sense!

#### Definition of forcing

- An element $p \in P$ forces the sentence $\phi(\vec \tau)$ iff $\phi^{M[G]}(\vec \tau^G)$ is true for **every generic ideal**
  $G$ such that $p \in G$. For every formula $\phi$, forcing tells us for which pairs of $p, \vec \tau$ it is the case that
  $\phi^{M[G]}(\vec \tau^G)$ is true. It is written as $p \Vdash \phi(\vec \tau)$.
- Written differently, we say that  $p \in P$ forces $phi(\vec \tau)$, iff for any $G \subseteq P$, $p \in G \implies \phi^G(\vec \tau^G)$ is true.
- That is to say, we can decide the truth of $\phi^G(\vec \tau^G)$ by looking at the presence/absence of $p$ in $G$.
- See that for a fixed $\phi$, forcing gives us a relation $\subseteq P \times M^k$.
- What we want to show is this that this forcing relation, for each $\phi$, is definable in $M$.
- This will show that the collection of $p$ that force a $\phi$ is in $M$ (project the first components of $P \times M^k$.

#### Fundamental theorem of forcing

- For every formula $\phi$, for every generic ideal $G$ over $P$:
- 1. Definability: there is a set $F(\alpha, \phi) \in M$ such that $p \Vdash \phi(\vec \tau)$ ($p$ forces $\tau$) if and only if
  $(p, \vec \tau) \in F(\alpha, \phi)$. That is, the forcing relation is definable in $M$
- 2. Completeness: $\phi^{M[G]}(\vec \tau^G)$ is true iff there is a $g \in G$ such that $g \Vdash \phi(\vec \tau)$.
  That is, any true sentence in $M[G]$ must have a witnessing $p \in G$ which forces it, for any generic ideal $G$.
- 3. Coherence/Stability: If $p \Vdash \phi$, for all $q \geq p$, we have $q \Vdash \phi$. Truth once forced cannot be unforced,
  truth is inflationary, truth is stable, etc.
- The FTF (fundamental theorem of forcing) is an algorithm on the ZFC syntax. It takes a formula $\phi$, and produces a ZFC
  proof of (1), (2), (3).

#### Architecture of FTF

- TODO, here I Am!

#### Net to capture generic ideal
- If $G$ is a generic ideal of $P$, and $G \subseteq (Z \in M)$, then there is a $p \in G$, such that all $q$ such that $p \leq q$ are in $Z$.
  That is, $\forall G, \exists p \in G, \forall q \in G, p \leq q \implies q \in Z$.
- QUESTION: How can $Z \in M$ if $G$ is a proper class relative to $M$, and $G$ is a subset of $M$? Isn't a superset of a proper
  class a proper class?
- Recalling that `(p, q) ∈ P` are compatible iff `∃r ∈ P, p ≤ r ∧ q ≤ r`. If no such `r` exists, then `(p, q)` are incompatible.
- Suppose we take some `(p, q) ∈ P`. We can have `(1) p  ≤ q`, `(2) q  ≤ p`, `(3) (p, r) compatible`, `(4) (p, r) incompatible`.
  Consider:

```


a   r
 \ / \
  p   d  e
   \ /   |
    c----*
```
- If `q=a` then `p <= q`
- If `q=c` then `q <= p`.
- If `q=d` then `∃r, (p <= r, q <= r)` compatible.
- If `q=e`, then `(p, e)` incompatible.
- We wish to show that there is a $p \in G$ such that all its extensions lie in $Z$.
- That is to say, all of the extensions of $p \in G$ do not lie in $Z^c$.


#### Proof of net lemma

- To prove: If $G$ is a generic ideal of $P$, and $G \subseteq (Z \in M)$, then
  there is a $p \in G$, such that all $q$ such that $p \leq q$ are in $Z$. That
  is, $\forall G, \exists p \in G, \forall q \in G, p \leq q \implies q \in Z$.

- Let $D$ be the set of elements in $p$ that is incompatible with every element in $Z^c$:
  $D \equiv \{ p \in P: \forall q \in Z^c, p \perp q \}$
- If $D$ were dense in $P$, then an element $r \in G \cap D$ would be the
  element we are looking for, where all the extensions of $r$ is in $G$.
- Let's try to show that $D$ is dense. Let $p \in P$ be arbitrary. We need to find a
  $d \in D$ such that $p \leq d$.
- If $p \perp q$ for every $q \in Z^c$, then we are done, since $p \in D$, and thus $p \leq p \in D$.
- On the other hand, suppose there is a $q$ such that $p \not \perp p$. That is, there is an $r$
  such that $p \leq r, q \leq r$.
- Now what? Now we make an observation: See that we can freely add $\uparrow Z^c = \{ r : \exists q \in Z^c, q \leq r \}$
  into $D$, because (1) if we consider $G \cap (D \cup Z^c)$, then $G \cap Z^c = \emptyset$.
  (2) $G \cap \uparrow Z^c$ could have an element $\uparrow r \in \uparrow Z^c, \in G$. But this cannot happen,
  because this means that $\exists q \in Z^c, q \leq \uparrow r$. But since $G$ is downward closed and $r \in G$, this means that $q \in G$,
  which is a contradiction as $q \in Z^c$ which has empty intersection with $G$.
- TLDR: We can fatten up any set with $Z^c$, while not changing the result of $G \cap - $!
- So we build $D' \equiv D \cup \uparrow Z^c$, which is to say, $D' \equiv \{ (p \in P: \forall q \in Z^c, p \perp q) \} \cup \{ r \in P : (\exists q \in Z^c, q \leq r)\}$.
- We claim that $D'$ is dense. Suppose we have some $p \in P$. (1) $p \perp q$ for all $q \in Z^c$, and thus $p \leq p \in D'$ and we are done.
  Otherwise, assume that there is some $q$ such that $p \not \perp q$. then there is an $r \in P$, such that $p \leq r, q \leq r$.
  This gives us an $r \in D'$ such that $p \leq r \in D'$ and we are done.


#### Simpler proof of net lemma (Unverified)
- Let $D \equiv \{ p \in P : \forall q \in Z^c, p \not \leq q \}$.
- Let's now pick a concrete $p \in P$, and try to show that $D$ is dense. so we need to find a $d \in D$ such that $p \leq d$.
- *Easy case:* If $p$ has no extensions in $Z^c$, then $p \in D$ by defn of $D$;
   we are done since $p \leq (p \in D)$, ahd thus density is fulfilled.
- *Hard case:* Suppose $p$ does have an extension $q \in Z^c$, what then? How do I find an element of $d \in D$
  such that $p \leq d$? ($d$ for extension)?
- *Hard case:* See that we will be using $D$ to consider $r \in (G \cap D)$ to find an element $r$ whose every extension
  lies in $Z$. So suppose we add $q \in Z^c, p \leq q$ into $D$ (ie, $D' \equiv D \cup \{q\}$).
- While $q \in D$, we will still have that $q \not \in G \cap D$,
  because $q$ lies in $Z^c$, which has zero intersection with $G \subseteq Z$!
- Thus, we can throw $Z^c$ in $D$ "for free" to fatten $D$ up to make it
  more dense, while knowing that $G$ will cull this $Z^c$ portion.
- So define $D' \equiv \{ p \in P : \forall q \in Z^c, p \not \leq q\} \cup Z^c$
- We claim that $D'$ is dense.
- Suppose $p \in P$. If for all $q \in Z^c$, $p \not \leq q$, then $p \in D'$.
  Otherwise, suppose $p \leq q \in Z^c$. Then we have $p \leq (q \in Z^c \subseteq D'$. Thus $D'$ is dense.
- Let $r \in G \cap D$. Then we cannot have $r$ come from the portion of $Z^c$, since $G \cap Z^c = \emptyset$.
  This means that $r$ came from the first part of the set $D'$,
  where no extension of $p$ lies in $Z^c$. Thus we are done.

#### Intuition for Net definition
- A net $Z \subseteq P$ could be defined in two ways: (A) $\forall p \in P, \exists z \in Z, p \leq Z$,
  or (B) $\forall z \in Z, \exists p \in P, z \leq p$.
- It can't be (B), because (B) has a trivial solution $Z = \emptyset$!
- It should be (A), because (A) forces $Z$ to be "non-trivial", since I can test it against all $p \in P$.

#### Names and name creation
- Let $N$ (for names) be defined transifinitely, where $N_0 \equiv \emptyset$, $N_{i+1} \equiv \mathcal{P}(P \times N_i) \cap M$,
  and take the union in the usual way at the limit ordinal.
- Intuitively, names let us create "hypothetical sets", which are realised into real sets for each subset $S \subseteq P$.
  We keep those elements which are tagged by $s \in S$, and we remove those sets which are not.

#### Forcing equality

###### Step 1: Defining the forcing tuple set $F^{x=y}$.

- to decide equality of $\tau, \tau'$, it is very sensitive to $G$ because elements can appear/disappear based on $G$.
- We want all triplets $(p, \tau, \tau')$ where $\tau, \tau' \in \texttt{NamedSet}(M)$such that
  $p$ forces $\tau^G = \tau'^G$.
- Recall that $p$ forces $\tau^G = \tau'^G$ means: $\tau^G = \tau'^G$ **if and only if** $p \in G$.
- Thus, $p$ must be such that it is **NECESSARILY POSSIBLY TRUE** that every
  element $\sigma^G \in \tau^G$ must also be such that $\sigma^G \in \tau'^G$,
  and also vice verss: every $\sigma'^G \in \tau'^G$ must be such that
  $\sigma'^G \in \tau^G$.
- Let us prove the forward direction, where we want to force $\sigma \in \tau$ implies $\sigma \in tau'$.
- Whenever $q \geq p$,  and $(\sigma, q) \in \tau$, there must be an $r \geq q$ such that $(\sigma^G \in \tau')$.
- We might be tempted to say that $r$ implies $(sigma^G \in \tau'^G)$ iff $(\sigma, r) \in \tau'$, but this is too strong.
  There could be many different collapses that allowed for $\sigma, r \in \tau'$. That is, we could have some $\xi^G \in \tau^G$,
  and $r$ forces $\xi^G = \sigma^G$.
- Now it looks like we need to define equality in terms of equality. We just perform induction on name rank,
  because to have $\sigma \in \tau$, the name rank of $\sigma$ must be lower than $\tau$ because we built
  the name rank universe by induction.
- So we define the condition on tripets $(p, \tau, \tau')$ of name rank less than $\alpha$ to be that
  for ALL $(\sigma, q) \in tau$ where $q \geq p$, there is
  $(\xi, r) \in \tau'$ such that $r \geq q$ and
  $(r, \sigma, \xi) \in F^{x=y}_{max(nr(\sigma), nr(\xi))}$,
- So we define the relation $F^{x=y}$ by name rank induction.

##### Step 2: defining the net
- Next, we need to define the net $Z$.
- Let $Z^{=} \equiv \{ q \in P: \forall (\sigma, q) \in \tau, \exists (\xi, r) \in tau', r \geq q \land (r \models \sigma = \xi)$ \}.
- Question: What is the meaning of the $\models$ symbol in this context?
- SID: I guess $r \models \sigma = \xi$ is syntactic sugar for $(r, \sigma, \xi) \in F^{x=y}$.
- See that $Z^{=}$ is the set of all $q$ for which $\tau$ is possibly a subset or equal to $\tau'$.
- By the inductive hypothesis of name rank, FTF holds for $\sigma, \xi$ and it follows that $Z^{=} \in M$
  [I have no fucking idea what this means].

#### Step 4: The equivalence of net, modality, relativized inclusion:

- $\tau^G \subseteq \tau'^G$ implies
- $G \subseteq Z^{=}$ implies
- $\exists p \in G, \forall q \geq p, q \in Z^{=}$ implies
- $\tau^G \subseteq \tau'^G$

Therefore, all these conditions are equivalent.

- We will show that $\tau^G \subseteq \tau'^G$ implies that $G \subseteq Z^{=}$. This by the net lemma will implu that
  there is a $p \in G$ such that all larger elements will be trapped in the net $Z^{=}$.
- Then we will prove that if there is such a $p \in G$ which traps elements in the net, then we have $\tau^G = \tau'^G$.


# Partial Evaluation, Chapter 3


#### Bootstrapping and self-application

- Suppose we have a high-level compiler in the language `S`, from `S` to `T`. I will denote that as `h : S(S → T)`.
  where the compiler is `h` (for high), written in language `S`, from `S` to `T`.
- We also have a low-level compiler written in `T` from `S` to `T`, denoted by
  `l : T(S → T)`, where the compiler is `l` for low.
- Suppose the two versions agree, so `[h]_S = [l]_T`.
- Suppose we extend `h` to `h'`, to compile the language `S'` to `T`. `h'` is also written in `S`, so we have `h': S(S'→ T)`.
- Now we can use `t` on `h'` to recieve an `S'` compiler `l' : T(S' → T)`.

# Partial Evaluation, Chapter 1

- `out = [[p]](i, i')`, then `p1 = [[mix]](p, i); out = [[p1]](i')`.
- Alternatively, can write as `[[p]](i, i') = [[ [[mix]](p, i) ]](i')`
- Let `S` be the source language (Early Rust). Let `T` be the target language (assembly). Let `L`
  be the language that the interpreter for `S` is implemented in (OCaml).
- See that we have the equation `out = [source]_S (in)`, or `out = [interp]_L (source, in).`
- That's the equation for the interpreter.
- a compiler produces a target program, so we have `target = [compiler]_L(source)`. Running
  the target and source programs should have the same effect, so `[target]_T(in) = [source]_S(in)`.
- Written differently, this is `[ [compiler]_L(source) ]_T(in) = [source]_S(in)`.

##### First futamura projection

- `out = [source]_S (in)`
- `out = [int](source, in)`
- `out = [[mix](int, source)](in)`
- But by definition of `target`, we have `out = target(in)`
- Thus, we see that `target = [mix](int, source)`. We get the *compiled output program/target program* by partially
  applying the interpreter to the source program.

##### Second futamura projection

- Start with `target = [mix](int, source)`.
- Now partially apply, `target = [mix(mix, int)](source)`.
- But we know that `target = compiler(source)`. So we must have `[mix(mix, int)] = compiler`.
- A compiler is obtained by partially applying the partial applier against the interpreter. Thus, when
  fed an input, it partially evaluates the interpreter against any input, giving us a compiler.

#### Third futamura projection

- consider `cogen = [mix(mix, mix)]`, applied to an interpreter.
- Let `comp = cogen(interp) = ([mix](mix, mix))(interp) = mix(mix, interp)`
- Apply `comp(source)`. This gives us `comp(source) = mix(mix, interp)(source) = mix(interp, source) = target`.
- Thus, we have create a compiler generator, which takes an interpreter and produces a compiler.

# Diagonal lemma for monotone functions

- Statement: For a monotone function $f: P \times P \to Q$, we have the equality
  $f(\sqcup_s s, \sqcup_t t) = f(\sqcup_x (x, x))$
- Since $\sqcup_x (x, x) \sqsubseteq \sqcup_{s, t} (s, t)$, by monotonicity of $f$, we have that
  $f(\sqcup_x (x, x)) \sqsubseteq f(\sqcup{s, t} (s, t))$.
- On the other hand, note that for each $(s_\star, t_\star)$, we have that
  $(s_\star, t_\star)  \leq \sqcup (s_\star \sqcup t_\star, t_star \sqcup t_\star) = (s_\star, s_star) \sqcup (t_\star, t_\star)$.
  Thus each element on the RHS is dominated by some element on the LHS.
- So we must have equality of LHS and RHS.

#### Proving that powering is continuous

- We wish to prove that $f^n$ is continuous, given that $f$ and $(\circ)$ is continuous.
- Proof by induction. $n = 0$ is immediate. For case $n+1$:

$$
\begin{aligned}
&(\sqcup_f f)^{n+1} \\
&= (\sqcup_f f) \circ (\sqcup_g g)^n \\
&= \sqcup_g ((\sqcup_f f) \circ g^n) \\
&= \sqcup_g \sqcup_f (f \circ g^n) \\
&= \sqcup_f (f \circ f^n) \\
&= \sqcup_f (f^{n+1}) \\
\end{aligned}
$$

- See that we used the diagonal lemma to convert the union over $f, g$ into a union over $f$.

# Cantor Schroder Bernstein via fixpoint

- Given two injections $f: S \to T$, $g: T \to S$, we want to create a bijection.
- Suppose we have $S = T = N$, and $f(n) = g(n) = n + 1$.
- If $f$ were surjective, we are done, for then $f$ is the bijection.
- In this case, $f$ is not surjective, because $T-f(S) = {0}$. So $0$ has no preimage under $f$.
- We will create a new function $f'$ by perturbing $f$, such that it does map some element in $X$ to $0$ [which is currently missed].
- Start with $f' \equiv f$. This means that $f'$ misses $0$.
- We can "force" a pre-image for $0$. How? Consider $g(0) = 1$, and set $f'(g(0)) \equiv 0$, or $f'(1) \equiv 0$.
- Whoops, but we have now "lost" a preimage for $f(1) = 2$, as now $2$ is not in the image of $f'$.
- Let's repeat the same process and fix it the same way. $f'(g(2)) \equiv 2$, or $f'(3) \equiv 2$.
- Now we have lost a pre-image for $f(3)$. Well, we just repeat the construction. For how long?
- Well, this is where we invoke the glory of a fixpoint theorem!
- See that we definitely need to reverse the arrows for $(T-f(S))$. If we start with a set $Y \subseteq T$ that
  we will reverse the arrows to, we will then need to reverse the arrows for $Y \cup F(G(Y))$.
- Thus, the set that we need to fiddle in $f'$ is $Y \mapsto (T-f(S))\cup F(G(Y))$.


# Maximal Ideals of Boolean Algebras are Truth Values

##### Boolean algebras
- Has meet, join, complement, 1, 0 with usual laws


##### Atomic boolean algebras
- Consider $2^S$ where $S$ is finite. Then the elements of the form `{s} ∈ 2^S` are said
  to be atoms because if `x ⊂ {s}` then `x = 0` or `x = {s}`.


##### Atomless boolean algebras
- Let $S$ be an infinite set, and let $I$ be a collection of its finite subsets. Then $I$ is an ideal
  (downward closed subset which has all joins), because the union of two finite sets is finite, and the
  subset of any finite set is finite.
- The quotient $T = 2^S/I$ will be an *atomless* boolean algebra.
- Note that the quotient kills all finite subsets.
- So for any non-zero $x \in T$, then it must be an equivalence class with some infinite subset.
  If we take $k, k'$ to be non-empty disjoint subsets of $x$, then neither is equivalent to $x$ or to $\emptyset$,
  because they differ at infinitely many locations from each. Thus, $x$ is not an atom.
- Furthermore, the boolean algebra is not complete, because, if we have $k_1, k_2, \dots$ be a countable collection
  of countably infinite subsets of $S$ (for example, if $S \equiv \mathbb N$, then we could take $k_i$ to be the
  set of numbers with $i$ bits as 1 in their binary representation), then this collection has no least upper bound.
- Suppose $u$ is an upper bound. Then $u$ differs from each $k_i$ in only finitely many locations.
- Now build $e_i \in u \cap k_i$, and consider the set $c \equiv u / \{ e_i \}$. That is, we remove one element from $u$
  from the intersection with each $k_i$. This new $c \subseteq u$, and $c$ is still an upper bound, since it differs
  from each of the $k_i$ at finitely many locations. Thus, this algebra is not complete.

##### Or, how to embed a poset into a boolean algebra.

- Every poset $P$ can be embedded into a complete atomic boolean algebra $2^P$
  by sending $p \mapsto \{ x : x \leq p \}$ (the ideal of $p$).
- Alternatively, that's just $Hom(-, p)$. God bless yoneda embedding.
- We can thus consider a ring map from $2^p \to 2$, which gives us a maximal ideal of $2^P$ (ideal is maximal because
  quotient is field).
- This assigns to us consistent truth values of $p$.
- In this way, maximal ideals of posets completed to rings correspond to truth values.
- Dualize the story via Grothendieck/Geometry to talk about filters :)

# Crash course on DCPO: formalizing lambda calculus

In lambda calculus, we often see functions of the form $\lambda x \rightarrow x(x)$. We would
like a way to associate a "natural" mathematical object to such a function. The
most obvious choice for lambda calculus is to try to create a set $V$ of values
which contains its own function space: $(V  \rightarrow V) \subseteq V$. This
seems to ask for a set whose cardinality is such that $|V|^|V| = |V|$, which is
only possible if $|V| = 1$, ie $V$ is the trivial set $\{ * \}$.
However, we know that lambda calculus has at least two types of functions:
functions that terminate and those that don't terminate. Hence the trivial set
is *not* a valid solution.

However, there is a way out. The crucial insight is one that I shall explain by
analogy:

- We can see that the cardinality of $\mathbb R$ is different from the cardinality
   of the space of functions over it, $\mathbb R \rightarrow \mathbb R$.
- However, "the set of all functions" isn't really something mathematicians consider.
   One would most likely consider "the set of all _continuous_ functions" $\mathbb R \rightarrow \mathbb R$.
-  Now note that a function that is continuous over the reals is [determined by its values at the rationals](https://math.stackexchange.com/questions/379899/why-is-every-continuous-function-on-the-reals-determined-by-its-value-on-rationa).
   So, rather than giving me a continus function $f: \mathbb R \rightarrow \mathbb R$, you can
   give me a continuous function $f': \mathbb Q \rightarrow \mathbb R$ which I can Cauchy-complete,
   to get a function $\texttt{completion}(f') : \mathbb R \rightarrow \mathbb R = f$.
-  Now, [cardinality considerations](https://math.stackexchange.com/a/271641/261373)
   tell us that:

$$|\mathbb R^\mathbb Q| = (2^{\aleph_0})^{\aleph_0} = 2^{\aleph_0 \cdot \aleph_0} = 2^\aleph_0 = |R|$$

- We've won! We have a space $\mathbb R$ whose space of _continuous_
   functions $\mathbb R \rightarrow \mathbb R$ is isomorphic to $\mathbb R$.
- We bravely posit: all functions computed by lambda-calculus are continuous!
   Very well. This leaves us two questions to answer to answer: (1) over what space?
   (2) with what topology? The answers are (1) a space of partial orders
   (2) with the [Scott topology](https://en.wikipedia.org/wiki/Scott_continuity)



### Difference between DCPO theory and Domain theory

- A DCPO (directed-complete partial order) is an algebraic structure that can
  be satisfied by some partial orders. This definition ports 'continuity'
  to partial orders.

- A domain is an algebraic structure of even greater generality than a DCPO.
  This attempts to capture the fundamental notion of 'finitely approximable'.

- The presentation of a domain is quite messy. The nicest axiomatization of
  domains that I know of is in terms of [information systems](https://en.wikipedia.org/wiki/Scott_information_system).
  One can find an introduction to these in the excellent book
  ['Introduction to Order Theory' by Davey and Priestly](https://www.cambridge.org/core/books/introduction-to-lattices-and-order/946458CB6638AF86D85BA00F5787F4F4)


### Computation as fixpoints of continuous functions

### Posets, (least) upper bounds

- A partial order $(P, \leq)$ is a set equipped with a reflexive, transitive, relation $\leq$ such that
  $x \leq y$ and $y \leq x$ implies $x = y$.
- A subset $D \subseteq P$ is said to have an *upper bound* $u_D \in P$ iff for all $d \in D$, it is true that $d \leq u_D$.
- An upper bound is essentially a cone over the subset $D$ in the category $P$.
- A subset $D \subseteq P$ has a *least upper bound* $l_D$ iff (1) $l_D$ is an upper bound of $D$, and (2)
  for every upper bound $u_D$, it is true that $l_D \leq u_D$
- Least upper bounds are unique, since they are essentially limits of the set $D$ when $D$ is taken as a thin category

### Directed Sets

- A subset $D \subseteq P$ is said to be *directed* iff for every *finite* subset $S \subseteq D$,
  $S$ has a upper bound $d_S $ in $D$. That is, the set $D$ is closed under the upper bound of all of its
  subsets.
- Topologically, we can think of it as being *closure*, since the upper bound is sort of a "limit point" of the subset,
  and we are saying that $D$ has all of its limit points.
- Categorically, this means that $D \subseteq P$ taken as a subcategory of $P$ has cones over all finite
  subsets. (See that we *do not* ask for limits/least upper bounds over all finite subsets, only cones/upper bounds).
- We can think of the condition as saying that the information in $D$ is internally consistent: for any two facts,
  there is a third fact that "covers" them both.
- slogan: internal consistency begets an external infinite approximation.
- QUESTION: why not ask for countable limits as well?
- QUESTION: why upper bounds in $D$? why not external upper bounds in $P$?
- QUESTION: why only upper bounds in $D$? why not least upper bounds in $D$?
- ANSWER: I think the point is that as long as we ask for upper bounds, we can pushforward via a function $f$,
  since the image of a directed set will be directed.

### Directed Complete Partial Order (`DCPO`)

- A poset is said to be directed complete iff every directed set $D \subseteq P$ has a least upper bound in $P$.
- Compare to chain complete, `CCPO`, where every chain has a LUB.
- QUESTION: why not postulate that the least upper bound must be in $D$?
- In a DCPO, for a directed set $D$, denote the upper bound by $\cup D$.

### Monotonicity and Continuity

- A function $f: P \to Q$ between posets is said to be monotone iff $p \leq p'$ implies that $f(p) \leq f(p')$.
- A function $f: P \to Q$ is continuous, iff for every directed set $D \subseteq P$, it is true that $f(\cup D) = \cup f(D)$.
- This has the subtle claim that the image of a directed set is directed.
-

### Monotone map

- A function from $P$ to $Q$ is said to be monotone if $p \leq p' \implies f(p) \leq f(p')$.
- Composition of monotone functions is monotone.
- The image of a chain wrt a monotone function is a chain.
- A monotone function **need not preserve least upper bounds**. Consider:

$$
f: 2^{\mathbb N} \rightarrow 2^{\mathbb N}
f(S) \equiv
\begin{cases}
S & \text{$S$} is finite \\
S U \{ 0 \} &\text{$S$ is infinite}
\end{cases}
$$

This does not preserve least-upper-bounds. Consider the sequence of elements:

$$
A_1 = \{ 1\}, A_2 = \{1, 2\}, A_3 = \{1, 2, 3\}, \dots, A_n = \{1, 2, 3, \dots, n \}
$$

The union of all $A_i$ is $\mathbb N$.
Each of these sets is finite.
Hence $f(\{1 \}) = \{1 \}$, $f(\{1, 2 \}) = \{1, 2\}$ and so on. Therefore:

$$
f(\sqcup A_i) = f(\mathbb  N) = \mathbb N \cup \{ 0 \}\\
\sqcup f(A_i) = \sqcup A_i = \mathbb N
$$

### Continuous function

- A function is continous if it is monotone and preserves all LUBs. This is
  only sensible as a definition on ccpos, because the equation defining it is:
  `lub . f  = f . lub`, where `lub: chain(P) \rightarrow P`. However, for `lub`
  to always exist, we need `P` to be a CCPO. So, the definition of continuous
  only works for CCPOs.
- The composition of continuous functions of chain-complete partially
  ordered sets is continuous.

### Fixpoints of continuous functions

The least fixed point of a continous function $f: D \rightarrow D$ is:

$$\texttt{FIX}(f) \equiv \texttt{lub}(\{ f^n(\bot) : n \geq 0 \})$$


### $\leq$ as implication

We can think of $b \leq a$ as $b \implies a$. That is, $b$ has more information
than $a$, and hence implies $a$.

### References

- Semantics with Applications: Hanne Riis Nielson, Flemming Nielson.
- [Lecture notes on denotational semantics: Part 2 of the computer science Tripos](https://www.cl.cam.ac.uk/~gw104/dens.pdf)
- [Outline of a mathematical theory of computation](https://ropas.snu.ac.kr/~kwang/520/readings/sco70.pdf)
- [Domain theory and measure theory: Video](https://www.youtube.com/watch?v=UJrnhhRi2IE)




# Resolution algorithm for propositional logic

- Resolution is refutation complete: will find a disproof if one exists for propositional logic
-  Key idea is the resolution rule:

```
F \/ l; G \/ not(l)
-------------------
  F \/ G
```

- See that this allows us to reduce the number of occurrences of `l`. If we keep doing this, we get the empty set
  with `\/` as the monoidal operation, forcing us to conclude `False`.

#### Termination

- At each step, we introduce a new clause, but the clause has one fewer literal.
- So we decrease on the number of literals this clause can resolve with.

#### Soundness
- First node that the resolution rule is sound, in that it only infers correct clauses.
- See that we need to prove only one rule: `(X | A) & (!X | B) = (A & B)`, which can be proven by e.g. truth table.
- So if resolution finds a contradiction, the original set of cluases did have a contradiction.

### Completeness

- We need to show that if resolution did not find a contradiction, then a model exists
  (the set of clauses was consistent)
- Suppose resolution saturates, and did not find a contradiction.
- Then we claim that in this saturated set, every literal `L` either occurs as all positive, or all negative, or does not occur.
- If this is true, then clearly we have a model: for every +ve literal, assign true, for every pure -ve literal, assign false, for
  a literal that does not occur, assign it whichever.
- Suppose the claim is not true. Then a literal L occurs in some clause C as +ve, and in another clause C' as negative.
- This means that C, C' can be resolved to get a new clause!
- But this cannot be, since we assumed that the set of clauses was saturated.


# Completeness for first order logic
- This requires soundness to have been established before.
- We work with sequent calculus, where `Γ => Δ` means that `g1 /\ g1 /\ ... /\ gn => d1 \/ d2 \/ .. \/ dn`.
- First prove that `Γ => Δ` is derivable iff `Γ U ~Δ => 0` is derivable.
- By soundness, this means that `Γ U ~Δ` is inconsistent.
- Thus, see that `Γ => Δ` is derivable ifff `Γ U ~Δ` is inconsistent.
- contraposing, `Γ => Δ` is NOT derivable ifff `Γ U ~Δ` is Consistent.
- Thus, the set `CONSISTENT := { Γ=>Δ |  Γ=>Δ has a model}` is equal
  to the set `{ Γ=>Δ | Γ U ~Δ is inconsistent}`, which (by soundness)
  is the same as `{ Γ=>Δ | ΓU~Δ is not derivable}`.
- We want to show that `CONSISTENT` is a satisfiable set (obeys conditions `(S0)`...`(S8)`),
  which will allow us to produce models for all `Φ ∈ CONSISTENT` (by taking the closure `Φ#` and building the term model,
  where taking the closure needs the ambient `CONSISTENT` set to obey satisfiability).
- Thus, this shows that every element of `consistent` (proofs of sequent calculus) in fact has a model, and thus we are complete.


# Compactness theorem of first order logic

- Define a theory to be a set of sentences.
- Compactness states that if a theory `T` is such that every finite subset `Tfin ⊂ T` of the theory
  has a model, then `T` itself has a model.

#### Proof Sketch
- Let `L` be a language.
- We study `CONSISTENT := { T ⊂ 2^L : T has a model }` to be the set of
  all theories of `L` which is consistent.
- (1.a) We analyze `CONSISTENT` and see that it has properties
  satisfcation (`(S0)` ... `(S8)`).
- (1.b) We show that if `K` is a set of theories which has satisfaction, then
  so does `PROFINITE(K) := { T ∈ K : ∀ Tfin ⊂ T, Tfin has a model }`.
- (2.a) We analyze, for a model `M`, the set `TRUTHS := { T : T is true for M }`.
  We see that it has properties of called closures (`(C0)`, ..., `(C8)`).
- (3) We show that if `Δ` has `(C0)`, ... `(C8)`, then `Δ` has a model (the *term* model).
- (4) Show that if `Γ` is a theory, then `Γ#` is the *closure* of the theory,
  such that `Γ#` obeys `(C0)`...`(C8)` and `(Γ ⊂ Γ#)`.
- (5) Show that if `Γ ∈ S` where `S` has satisfaction, then one can build a `Γ ⊂ Γ# ∈ S` where `Γ#` is closed.
- (6) To prove compactness, take a theory `Δ ∈ PROFINITE(CONSISTENT)`.
      Since `CONSISTENT` has satisfaction, and `PROFINITE` preserves satisfaction,
      `PROFINITE(CONSISTENT)` has satisfaction. Now apply (5) to build the closure `Δ#`.
      Use (3) to build the term model `M(Δ#)`, a model for `Δ#`, which is also a model for `Δ`.

#### Proof sketch sketch

- 0. Define a property called "satisfaction" which is possessed by the set of consistent theories.
- 1. See that the profinite completion of a satisfaction set also obeys satisfcation.
- 2. Define a property called closure on a theory, where a closed theory possesses a term model.
- 3. Show that every theory in a satisfaction set also has a closure in the satisfaction set.
- 4. Take `Γ ∈ PROF(CONSISTENT)`, a theory `Γ` which is profinite,
     which we wish to build a model for. Create `Γ#`, the closure, such that `Γ ⊂ Γ#`.
     See that `Γ#` has a model (the term model `MΓ`), and that this is also a model for `Γ`, and thus `Γ` is consistent.

#### Non algorithmic proof sketch
- See that given a `S` which obeys `(S1)`...`(S8)`, `PROFINITE(S)` has **finite character**.
- A family `F` has finite character is defined to be: `A ∈ F` iff all subsets of `A` belong to `F`.
- Show that for any `Γ ∈ S*`, there is a maximal `Γ# ∈ S*` which contains `Γ`.
  This follows by Zorn on `S*`. Let the partial order by the subset ordering on `S*(Γ) := { Δ ∈ S* | Γ ⊂ Δ }`.
  See that every chain has a maximal element, by the finite character property. Thus, `S*(Γ)` has a maximal element, call it `Γ#`.
- Show that this `Γ#` obeys `(C0)`...`(C8)` [closure properties] This will rely on `S*` having `(S1)`..`(S8)`.
  Thus, `Γ#` possesses a model (the term model).
- This means that `Γ` also possees a term model.


#### Algorithmic proof: details

- TODO



# First order logic: Semantics
- $M \models F$ can be reads as $M$ models $F$, or $M$ makes true $F$ ($M$ for model, $F$ for formula).

#### Defining models for quantification

- We wish to define $M \models \forall x, F(x)$
- A first shot might be $M \models \exists x, F(x)$ iff for every closed term $t$, $M \models F(t)$.
- However, see that intuitively, $\exists x$ ranges over the _denotational space_, while closed terms range over
  the _image of syntax in the denotation_.
- For example, consider the language of nautrals, which we can interpret over naturals, nonnegative rationals, and reals.
  So let us think of the formula $(F \equiv \exists t, t + t = 1)$. If we only allow $t$ to take on closed terms, then
  see that since the closed terms of naturals are natural numbers, this will be false! But really, when interpreted
  over the integers, we want the formula to be true, since there is the real number $1/2$ which witnesses
  the truth of $(\exists t, t + t = 1)$. Thus, it is insufficient to range over closed terms, since the "image"
  of the closed terms in $\mathbb R$ is going to be $\mathbb N$, but in fact, we have "more in $\mathbb R$"
  than just the closed terms which are unreachable.
- So the correct notion of $M \models \exists x, F(x)$ is to take $M$, extend with a constant symbol $c$, evaluate it to some $m \in M$,
  and call this $M^c_m$. Then, we say that $M \models \exists x, F(x)$ iff there exists an $m \in M$ such that $M^c_m \models F(c)$.
- See that this allows access to denotations, without needing a syntactic closed term.
- his fells close to the notion of **adequacy**, when the operational and denotational semantics
  agree.[HackMD notes by Alexander Kurz](https://hackmd.io/@alexhkurz/Hkf6BTL6P#Adequacy)

# full abstraction in semantics

- Observational equivalence: same results when run, $\sim_O$
- Denotational equivalence: same denotation.
- Full abstraction: the two equivalences coincide: observationally equivalent iff denotationally equivalent.
- I thought full abstraction meant that everything in the denotational side has a program that realises it!

#### Parallel `or` and PCF

  For example, I thought that the problem will `por` in PCF was that it wasnt't possible to implement in the language.
- However, this is totally wrong.
- The reason `por` is a problem is that one can write a _real programs_ in PCF of type `(bool -> bool -> bool) -> num`,
  call these `f, g`, such that `[[f]](por) != [[g]](por)`, even though both of these have the same operational semantics!
  (both `f`, `g` diverge on all inputs).
- [SEP reference](https://plato.stanford.edu/entries/games-abstraction/#ProgEquiFullAbst)

#### Relationship between full abstraction and adequacy
- Adequacy: $O(e) = v$ iff $[[e]] = [[v]]$. This says that the denotation agress on observations.
- See that this is silent on _divergence_.

##### Theorem relating full abstraction and adequacy
- Suppose that $O(e) = v \implies [[e]] = [[v]]$.  When is the converse true? ($[[e]] = [[v]] \implies O(e) = v$?)
- It is true iff we have that $e =_M e'$ iff $e =_O e'$.


#### Full abstraction between languages
- say two languages $L, M$ have a translation $f: L \to M$ and have the same observables $O$.
- Then the translation $f$ is fully abstract iff $l \sim_O l' \iff f(l) \sim_O f(l')$
- See that $L$ cannot be more expressive than $M$ if there is a full abstract translation from $L$ into $M$.

- [HackMD notes by Alexander Kurz](https://hackmd.io/@alexhkurz/Hkf6BTL6P#Adequacy)


# You could have invented Sequents

- Key idea: define a notation called `Γ => Δ` iff the conjunction of sentences
  in gamma implies the disjunction of terms in delta.
- Why would anybody do this? isn't this weird?
- It's because we first note what we need to think about consequence, validity, and unsatisfiability.
- `d1` is a consequence of `Γ`  iff `g1 /\ g2 .. /\ gn => d1`
- `d1` is valid iff `empty => d1`, or written differently, `0 => {d1}`.
- `Γ` is unsatisfiable iff `g1 /\ ... /\ gn => False`, or written differently, `Γ => 0`
- Thus, see that on the RHS, we need a set with 0 or 1 inhabitant. We can think of this as `Maybe`, smooshed
  together with `\/`, since we want the empty set to represent `False`.
- Recall that haskell teaches us to replace failure with a list of successes!
- Thus we should use `Γ => Δ` where on the RHS, we have a list that is smooshed together by or (`\/`)!
- Great, we have successfully invented sequents.


# Fibrational category theory, sec 1.1, sec 1.2

- Key idea: can define a notion of a bundle `p: E → B`
- The idea is that we want to generalize pullbacks into fibres.
- A functor `p: E \to B` is called as a fibration if for each morphism `f: b → b'`
  downstairs, and an element `e' ∈ E` such that `π(e') = b'`, then we have a lift
  of the morphism `f` into `f♮`, such that this morphism has a property called
  *cartesianity*.
- Given:

```
        e'
        |

b ----> b'
```


- We want:

```

e===f♮=>e'
|       |
|π      |π
v       v
b --f-->b'
```

- Furthermore, to ensure that this is really a pullback, we ask for the condition that
  TODO

#### Omega sets

- A set with some sort of "denotation by natural numbers" for each element of the set.
- More formally, an omega set is a tuple `(S, E: S → 2^N)` such that `E(s) ≠ ∅`.
  The numbers `E(s)` are to be thought of as the denotation for the element `s`.
- A morphism of omega sets `(S, E) → (S', E')` is a function `f: S → S'`, and
  a partial function `realiser(f): N → N` such that for all `s ∈ S`, `realiser(f)(E(s)) ⊂ E'(f(s))`.
  That is, for every denotation `d ∈ E(s)`, we have that the realiser `realiser(f)` maps `d` into
  the denotation of `f(s)`, so we must have that `d' = realiser(f(d))` lives in `E'(f(s))`.

#### PERs
- This is a partial equivalence relation, so we only need symmetry and transitivity.
- We consider partial equivalence relations (PERs) over `N`.
- Let `R` be a PER. We think of those elements that are reflexively related (ie, `xRx`) as
  "in the domain" of the `PER`.
- Thus we define `domain(R) = { x | xRx }`.
- In this way, `R` is a real equivalence relation on `domain(R)`.
- We write `N/R` or `domain(R)/R` for the equivalence classes induced by `R` on `N`.
- The category of PERs has as objects these PERs.
- Intuitively, these give us subsets of the naturals ...


#### Cloven Fibrations

- A fibration is cloven if for every arrow downstairs, there is a chosen cartesian
  arrow upstairs. So we have a *function* that computes the cartesian arrow upstairs
  for an arrow downstairs. This is different from the regular definition where
  we just know that there *exists* something upstairs.
- Note that given a fibration, we can always cleave the fibration using choice.
- Recall the definition of cartesian. For a functor `p: E → B`, for every arrow
  downstairs `u: I → J ∈ B` and every object `Y ∈ E` lying above `J` (ie, `p(Y) = J`),
  there is a cartesian lift of `u` given by `X → Y` for some `X` lying above `I`. (`p(X) = I`).
- Having made such a choice, every map `u: I → J` in `B` gives a functor `u*: E_J → E_I` from the the fiber `E_J` over `J`
  to the fiber `E_I` over `I`. (Direction changes, pullback)
- Recall that `E_J` is a subcategory of `E` where the objects are `p^{-1}(J)`, and the morphisms
  are `p^{-1}(id_J)`.
- Implement the map `u*` as `u*(y)` as that object given by lifting the map `u: I → J` along `Y`.
  This is well-defined since we have a clevage to pick a unique `u*(Y)`!

```
defn
u*(Y)-->Y
        |
        v
I -u--->J
```

- For morphisms, suppose we are given an arrow `f: Y → Y'` in `E_J`. Then we use the cartesianity of the
  lifted morphism to give us the lift. Mediatate on the below diagram:

####  Split Fibrations

- A fibration is split if the cartesian lift of identity is identity, and the cartesian lift
  of compositions is the composition of the lifs (ie, the lifting is functorial).
- In a cloven fibration, this is going to only be equal upto iso.
- Example of a non-split fibration: Set-arrow, because pullbacks in set are not associative.
 Thus, the (A x B) x C != A x (B x C).
- Being split has mathemaitcal content, because it's not possible to globally fix a functor
  being non-split.

##### Pseudofunctors
- A functor where all the equalities are isos. `f(a . b) ~= f a . f b`. `f(id) ~= id`.

##### Split Indexed Category
-

##### Lemma about pulling stuff back into the fiber

- `E(X, Y) != disjoint union (u: πX -> πY) E_{πX} (X, u*(Y))`


# Simple Type Theory via Fibrations

- Objects are contexts, so sequence of `(term:type)`
- Morphisms between contents `Γ = (v1:s1, v2:s2)` and `Δ = (w1:t1, w2:t2)`
  are terms `M1, M2` such that we have `Γ |- M1 : t1` and `Γ |- M2 : t2`.
- More cleaned up, for a context `Γ`, and a context `Δ` with sequence of types `(_:t1, _:t2, ..., _:tn)`,
  a morphism is a sequence of terms `Γ|- M1: t1`, `Γ|- M2:t2`, ..., `Γ|-Mn:tn`.
- For concreteness, let us suppose `Δ = (w1:t1, w2: t2)`
- The identity morphism is `Δ -(d1, d2)-> Δ`, since we have `d1 := w1:t1, w2:t2|-w1:t1` and `d2 := w1:t1, w2:t2|-w2:t2`.
  Thus, starting from `Δ` on the context, we can derive terms of types `t1, t2`, which are given by the derivations `d1, d2`.
- Let us meditate on composition `Γ -(d1, d2)-> Δ -(d1', d2')-> Θ`. First off, let us write this more explicitly as:

```
Γ

(d1 := Γ|-M1:s1, d2 := Γ|-M2:s2)

Δ := (x1:s1, x2:s2)


(d'1 := Δ|-N1:t1, d2 := Δ|-N2:t2)

Θ := (_:t1, _:t2)
```

- See that have `(x1:s1, x2:s2)|- N1 : t1`
- If we substitute `N1[x1 := M1, x2 := M2]`,
  then under context `Γ`, we know that `M1:s1`, and `M2:s2`, so they have the
  correct types to be substituted for `x1` and `x2`. Thus, in context `Γ`, `N1[x1 := M1, x2 := M2]`
  has the same type it used to have `(t1)`.
- Thus we have that `Γ |- N1[x1 := M1, x2 := M2] : t1`.
- This gives us the composite of the section of the morhphisms, by telling us how to compose `d'1` with `d1`.
- Do the same for `d2`.
- What the hell is going on anyway?
- Given any well typed term in a context, `Γ|-M:t`, we can think of this as a morphism `Γ --M--> (Δ:=M:t)`.
- This relative point of view (ala grothendieck) lets us extend to larger contexts.
- The empty context is the terminal object, since there is precisely one morphism, consisting of the
  empty sequence `()`. Can be written as `Γ-()-> 0`.
- The categorical product of contexts is given by sequencing (see that this needs exchange),
  and the projections are the "obvious" rules: `Γ <--Γ-- (Γ;Δ)---Δ--> Δ`.



# Realisability models


For closed terms `u`, and type `𝜏` we are going to define `u ⊩ 𝜏` (read “u is a
realiser of 𝜏”). Let's say that we have PCF's type: `ℕ` and `σ → τ`.

1. `u ⊩ ℕ `if u reduces to a natural number literal
2. `f ⊩ σ → τ` if for all `s⊩σ`, `f s ⊩ τ`.


Some immediate observations:
- This definition is by induction on the types, and assumes little from the terms (it's a logical relation).
- This is “really what we mean” by `x : 𝜏` (except non-termination, not modelled here): realisability has explanatory power.
- This relation is usually undecidable.
- It is strongly related to parametricity (in parametricity we associate a binary relation to types, in realisability we associate a (unary) predicate). 4/10
- From this point of view, typing is a (usually decidable) modular approximation of realisability.
- For instance, consider `if x then 1 else (\y -> y)`. It isn't well-typed.
- However, if we add `let x = True in if x then 1 else (λy. y)` it becomes a realiser of `ℕ` [because upon reduction, it produces an `N`, even
  though it is not "well-typed".

- Typing and realisability are related by a lemma sometimes referred as adequacy.

Take the rule for λ (simplified):

```
x:X, y:Y ⊢ z : Z
-----------------------
x:X ⊢ λ(y: Y). z : Y → Z
```

You interpret it as a statement

```
∀ v⊩A, (∀ w ⊩ B, u[x\v, y\w] ⊩ C) ⟹  \lambda y.u[x\v] ⊩ C
```

- Then, you prove this statement. 7/10

Once you've done so for each rule, you can conclude (very easy induction) that
if ⊢ u : A, then u ⊩ A. This gives type safety, since realisers are practically
defined as verifying type safety.

What you've gained along the way is that this proof is an open induction. 8/10

In standard combinatorial proofs of type safety, the induction hypothesis may
depend on every case. Adding a form in your language may require redoing the
entire proof. Here the various case in the adequacy lemma will remain true. So
you can just prove the new cases. 9/10


There are many variants of realisability. Tuned for logic, with models instead
of terms, … My favourite is Krivine's realisability with both terms and stacks,
and magic happening when they interact. But this is another story and shall be
told another time. 10/10

# Naming left closed, right open with start/stop

Call the variables `startPos` and `stopPos`. Since it's called stop,
it's a little more intuitive that it's exclusive!

# Nested vs mutual inductive types:

```
inductive m1
| mk: m2 -> m1

inductive m2
| mk: m1 -> m2
```

```
inductive n1: Type :=
| mk: n2 n1 -> n1

inductive n2 (a: Type): Type :=
| nil: n2 a
| cons: a -> n2 a -> n2 a

```

# Embedding HOL in Lean

```
inductive Sets where
| bool: Sets
| ind: Nat -> Sets
| fn: Sets -> Sets -> Sets

def Sets.denote: Sets -> Type
| bool => Prop
| ind => nat
| fn i o => i.denote -> o.denote

def ifProp (p: Prop) (t: a) (e: a) : a := by
  match Classical.lem p with
  | Or.inl _ => t
  | Or.inr _ => e

def Model := Σ (s: Sets), s.denote
```

# Module system for separate compilation

- https://github.com/leanprover/lean4/issues/416
- https://www.cs.utah.edu/plt/publications/macromod.pdf
- https://raw.githubusercontent.com/alhassy/next-700-module-systems/master/phd-defence.pdf
- https://raw.githubusercontent.com/alhassy/next-700-module-systems/master/thesis.pdf

# Second order arithmetic

- First order arithmetic has variables that range over numbers
- Second order arithmetic has variables that range over sets of numbers
- [Ref: Jeremy Avigad on forcing](https://www.andrew.cmu.edu/user/avigad/Papers/forcing.pdf)
- Axiomatic second-order arithmetic is often termed “analysis” because, by
  coding real numbers and continuous functions as sets of natural numbers, one
  can develop a workable theory of real analysis in this axiomatic framework.

# Lean4 Dev Meeting

- Mathport uses matli4 to move tactics.
- Mathlib4 has syntax definitions ofr every single tactic that exists in `mathlib`.
- These only exist as syntax so far. We need to port this.
- The goal for this week is to have as many as possible knocked off.


#### Macro
- A tactic that expands to another tactic.
- Example: `_` tactic. This expands into `({})`, which shows you the current state.
- `macro_rules` need a piece of `Syntax`, and it expands into another tactic.

```
-- | do the iff.rfl as well.
macro_rules | `(tactic| rfl => `(tactic| exact Iff.rfl)
```

- Closed syntax categories: `syntax rcasesPatLo := ...`.
- Open syntax categories: `syntax X`.

#### How to collate info?
- Use `macro` to define syntax + macro
- Use `elab` to define syntax + elaborator together.
- Add command to list all places where something was extended.
- Add information into docstrings.
- `match_target`.

#### `Mapsto` arrow

- `(x: α) \mapsto e`: maybe annoying to parse.
- `\lambda (x: \alpha) \mapsto e`: easy to parse, but mathematicians don't know what lambda is.

#### `ext` tactic

- implemented as a macro tactic, which uses an `elab` tactic.

#### `colGt`

- `syntax "ext"`
- Lean4 is whitespace sensitive, like python. `colGt` says that we can have the following
    syntax on a column that is greater than the current line.

```
ext
  x -- parsed as part of `x`.
  y -- parsed as part of `y`.
z -- is not parsed as part of `x y`.
```
- If in parens, we don't need colGt, because we want to allow something like:

```
ext (x
 y) -- should parse.
```
#### `ppSpace`

- Used when pretty printing a tactic.

#### Scoped syntax
- `scoped syntax "ext_or_skip: .. `.
- This declares a syntax that is valid only for the current section/namespace.
- Trailing percent `ext_proof%` is an indicator that it is a term macro / term elaboration.
- Protected: identifier cannot appear without prefixing namespaces.

#### Trivia
- `{..}` pattern matches on a struct.


#### Tactic development: `Trace`
- Create a new file `Mathlib/Tactic/Trace.lean`
- Move the syntax line from `./Mathlib/Mathport/Syntax.lean`  into `Mathib/Tactic/Trace.lean`.
- On adding a file, add it to `Mathlib.lean`. So we add `import Mathlib.Tactic.Trace`
- We also want to re-import the syntax into `Mathlib/Mathport/Syntax.lean`.
- We have now moved `trace` into its own file and hooked into the build system and extension.
- The first thing to do is to find out what the tactic even does.
- Go to [`trace`](https://leanprover-community.github.io/mathlib_docs/tactics.html#trace) at the mathlib docs.

```
-- Tactic.lean
import Lean
open Lean Meta Elab

syntax (name := trace) "trace " term : tactic

elab "foo" : tactic => do
  -- `TacticM Unit` expected
  logInfo "hi"

```

```
open Lean Meta Elab Tactic ~=
open Lean
open Lean.Meta
open Lean.Elab
open Lean.Elab.Tactic
```
- TacticM is a `MonadRef`, which is aware of source spans to report the errors.
  so we can write:

```
elab "foo" : tactic => do
  logInfo "hi"
```

- We can use `withRef` to control the current source span where errors
  are reported.

```
elab tk:"foo" val:term : tactic => do
  withRef tk (logInfo val)
```

- We want to evaluate the `val:term`, because otherwise, it literally prints the syntax
  tree for things like `(2 + (by trivial))`.
- Use `elabTerm` to elaborate the syntax into a term.
- `set_option trace.Elab.definition true in ...` which printso ut the declarations that are being
  sent to the kernel.
- `elab` is `syntax` + `elab_rules` together, just like `macro` is `syntax` + `macro_rules` together.
- Create a test file `test/trace.lean`. Import the tactic, and write some examples.
- Recompile, and check that the test works.
- How do we check that our port works?


#### Reducible

> To clarify, @[reducible] marks the definition as reducible for typeclass
> inference specifically. By default typeclass inference avoids reducing because
> it would make the search very expensive.


# Categorical model of dependent types

- [Motivation for variants of categorical models of dependent types](https://proofassistants.stackexchange.com/questions/1086/what-are-the-motivations-for-different-variants-of-categorical-models-of-depende)
- [Seminal paper: Locally cartesian closed categories and type theory](https://www.math.mcgill.ca/~rags/LCCC/LCCC.pdf)
- A closed type is interpreted as an object.
- A term is interpreted as a morphism.
- A dependent type upon $X$ is interpreted as an object of the slice category $C/X$.
-  A dependent type of the form `x: A |- B(x) is a type` corresponds to morphisms `f: B -> A`,
    whose fiber over  `x: A` is the type `f^{-1}(x) = B(x)`.
- The dependent sum $\Sigma_{x : A} B(x)$ is given by an object in $Set/A$, the set $\cup_{a \in A} B_a$.
  The morphism is the morphism from $B_a \to A$ which sends an elements of $B_{a_1}$ to $a_1$, $,B_{a_2}$ to $a_2$ and so forth.
  The fibers of the map give us the disjoint union decomposition.
- The dependent product $\Pi_{x: A} A(x)$ is given by an object in $Set/A$.
- We can describe both dependent sum and product as arising as adjoints to the functor $Set \to Set/A$ given
  by $X \mapsto (X \times A \to A)$.
- Recalling that dependent types are interpreted by display maps, substitution
  of a term tt into a dependent type BB is interpreted by pullback of the
  display map interpreting BB along the morphism interpreting tt.
- [Reference](https://ncatlab.org/nlab/show/categorical+model+of+dependent+types)

#### Key ideas

- [Intro to categorical logic](https://www.andrew.cmu.edu/user/jonasf/80-514-814/notes.pdf)
- Contexts are objects of the category `C`
- Context morphisms are morphisms `f: Γ → Δ`
- Types are morphisms `σ: X → Γ` for arbitrary `X`
- Terms are sections of `σ: X → Γ`, so they are functions `s: Γ → X` such that `σ . s = id(Γ)`
- Substitution is pullback

#### Why is substitution pullback?

- Suppose we have a function $f: X \to Y$, and we have a predicate $P \subseteq Y$.
- The predicate can be seen as a mono $P_Y \xrightarrow{py} Y$, which maps the subset where $P$ is true into $Y$.
- now, the subset $P_X \equiv P_Y(f(x))$, ie, the subset $P_X \equiv \{ x : f(x) \in P_Y \}$ is another subset $P_X \subseteq X$.
- See that $P_X$ is a pullback of $P$ along $f$:

```
P_X -univ-> P_Y
|            |
px            py
|            |
v            v
X -----f---> Y
```

- This is true because we can think of $Q_X \equiv \{ x \in X, y \in P_Y: f(x) = py(y) \}$.
- If we imagine a bundle, at each point $y \in Y$, there is the presence/absence of a fiber $py^{-1}(y)$
  since $py$ is monic.
- When pulling back the bundle, each point $x \in X$ either inherits this fiber or not depending
  on whether $f(x)$ has a fiber above it.
- Thus, the pullback is also monic, as each fiber of $px$ either has a strand or it does not, depending
  on whether $py$ has a strand or not.
- This means that $px(x)$ has a unique element precisely when $f(x)$ does.
- This means that $px$ is monic, and represents the subset that is given by $P_Y(f(x))$.

#### Isn't substitution composition?

- If instead we think of a subset as a function $P_Y: Y \to \Omega$ where $\Omega$ is the subobject classifier,
  we then get that $P_X$ is the composite $P_X \equiv P_Y \circ f$.
- Similarly, if we have a "regular function" $f: X \to Y$, and we want to substitute $s(a)$ ($s: A \to X$ for
  substitution) into $f(x)$ to get $f(s(a))$, then this is just computing $f \circ s$.

#### Using this to do simply typed lambda calculus

- [Introduction to categories and categorical logic](http://www.cs.ox.ac.uk/people/bob.coecke/AbrNikos.pdf)
- Judgement of the form `A1, A2, A3 |- A` becomes a morphism `A1xA2xA3 → A`.
- Stuff above the inference line will be arguments, stuff below the line will be the return value.
- Eg, the identity judgement:

```
Γ,A |- A
```

becomes the function `snd: ΓxA → A`.

#### Display maps

- [Reference: Substitution on nlah](https://ncatlab.org/nlab/show/substitution)
- To to dependent types in a category, we can use [display maps](https://ncatlab.org/nlab/show/display+map).
- The display map of a morphism $p: B \to A$ represents $x:A |- B(x): Type$. The intuition is that $B(x)$
  is the fiber of the map $p$ over $x:A$.
- For any category $C$, a class of morphisms $D$ are called display maps iff all pullbacks of $D$ exist and
  belong to $D$. Often, $D$ is also closed under composition.
- Said differently, $D$ is closed under all pullbacks, as well as composition.
- A category with displays is _well rooted_ if the category has a terminal object $1$, and all maps into $1$
  are display maps (ie, they can always be pulled back along any morphism).
- This then implies that binary products exist (?? HOW?)


#### Categories with families

- [Lectures notes on categorical logic](https://staff.math.su.se/palmgren/lecturenotesTT.pdf)

# Coends

- Dual of an end
- A cowedge is defined by injections into the co-end of all diagonal elements.

```
p(a, a)   p(b, b)
  \          /
  π[a]      π[b]
   \        /
    v      v
     \int^x p(x, x)
```

- It's a universal cowedge, so every cowedge `c` other must factor.

```
p(a, a)   p(b, b)
  \   \  /    /
  π[a]  c   π[b]
  \     |    /
   \    ∃!  /
    \   |  /
    v   v  v
     \int^x p(x, x)
```

- Now we have the cowedge condition. For every morphism `h: b -> a`, and for every cowedge `c`, the following
  must hold:

```
   [p b a]
  /      \
[p a a]   [p b b]
  \      /
      c
```

- By curry howard, `type coend p = exists a. p a a`


```
data Coend p where
  MkCoend :: p a a -> Coend p
```

```
type End (p :: * -> * -> *) = forall x. p x x
```

- A functor is continuous if it preserves limits.
- Recall that `Hom` functor preserves limits.

```
-- Hom(\int^x p(x, x), r) ~= \int_x (Hom(p x x, r))
type Hom a b = a -> b
```

- `Set(\int^x p(x, r), s)` is asking for a function `Coend p -> r`.
- But e claim this  is the same as having `forall a. (p a a -> r)`.
- So we can write `Set(\int^x p(x, x), r) ~= \int_x Set(p(x, x), r)`.

```
-- | \int_x Set(p(x, x), r)
-- | \int_x Hom(p(x, x), r)
-- | \int_x RHS(x,x)
       where RHS a b = Hom(p(a, b), r)
type RHS p r a b = Hom (p a b) r -- rhs of the above expression
```


The isomorphisms are witnessed below, reminiscent of building a continuation

```
-- fwd :: (Coend p -> r) -> End (RHS p r)
-- fwd :: (Coend p -> r) -> (forall x. (RHS r) x x)
-- fwd :: (Coend p -> r) -> (forall x. Hom (p x x) r)
-- fwd :: (Coend p -> r) -> (forall x. (p x x) -> r)
fwd :: Profunctor p => (Coend p -> r) -> (forall x. (p x x) -> r)
fwd coendp2r  pxx = coendp2r (MkCoend pxx)
```

- The backward iso, reminiscent of just applying a continuation.

```
-- bwd :: End (RHS p r)             -> (Coend p -> r)
-- bwd :: (forall x. (RHS r) x x)   -> (Coend p -> r)
-- bwd :: (forall x. Hom (p x x) r) -> (Coend p -> r)
-- bwd :: (forall x. (p x x) -> r)  -> (Coend p -> r)
bwd :: Profunctor p => (forall x. (p x x) -> r) -> Coend p -> r
bwd pxx2r (MkCoend paa) = pxx2r paa
```

- Ninja coyoneda lemma: `\int^x C(x, a) * f(x) ~= f(a)`
- Witnessed by the following:

```hs
-- ninja coyoneda lemma:
-- \int^x C(x, a) * f(x) ~= f(a)
-- the profunctor is \int^x NinjaLHS[f, a](x, y)
--   where
newtype NinjaLHS g b y z = MkNinjaLHS (y -> b, g z)
```



- Forward iso:

```hs
-- ninjaFwd :: Functor f => Coend (NinjaLHS f a) -> f a
ninjaFwd :: Functor g => Coend (NinjaLHS g r) -> g r
ninjaFwd (MkCoend (MkNinjaLHS (x2r, gx))) = fmap x2r gx
```

- Backward iso:

```hs
-- ninjaBwd :: Functor f => g r -> (Coend (NinjaLHS g r))
-- ninjaBwd :: Functor f => g r -> (∃ x. (NinjaLHS g r x x))
-- ninjaBwd :: Functor f => g r -> (∃ x. (NinjaLHS (x -> r, g x))
ninjaBwd :: Functor g => g r -> Coend (NinjaLHS g r)
ninjaBwd gr = MkCoend (MkNinjaLHS (x2r, gx)) where
   x2r = id -- choose x = r, then x2r = r2r
   gx = gr -- choose x = r
```

- We can prove the ninja coyoneda via coend calculus plus yoneda embedding,
  by using the fact that yoneda is full and faithful.
- So instead of showing LHS ~= RHS in the ninja coyoneda, we will show that `Hom(LHS, -) ~= Hom(RHS, -)`.

- We compute as:

```
Set(\int^x C(x, a) * f(x), s) ~? Set(f(a), x)
[continuity:]
\int_x Set(C(x, a) * f(x), s) ~? Set(f(a), x)
[currying:]
\int_x Set(C(x, a), Set(f(x) s)) ~? Set(f(a), x)
[ninja yoneda on Set(f(-), s):]
Set(f(a) s)) ~? Set(f(a), x)
Set(f(a) s)) ~= Set(f(a), x)
```

#### Ninja Coyoneda for containers


- The type of `NinjaLHS`, when specialized to `NinjaLHS g b r r` becomes `(r -> b, g r)`.
- This is sorta the way you can get a `Functor` instance on any `g`, by essentially accumulating
  the changes into the `(r -> b)`. I learnt this trick from some kmett library, but I'm not
  sure what the original reference is.

- Start with `NinjaLHS`:

```hs
-- ninja coyoneda lemma:
-- \int^x C(x, a) * f(x) ~= f(a)
-- the profunctor is \int^x NinjaLHS[f, a](x, y)
--   where
newtype NinjaLHS g b y z = MkNinjaLHS (y -> b, g z)
```

- Specialize by taking the diagonal:

```hs
-- newtype NinjaLHS' g i o = MkNinjaLHS' (i -> o, g i)
newtype NinjaLHS' g i o = MkNinjaLHS' (NinjaLHS g o i i)
```

- Write a smart constructor to lift values into `NinjaLHS'`:

```
mkNinjaLHS' :: g i -> NinjaLHS' g i i
mkNinjaLHS' gi = MkNinjaLHS' (MkNinjaLHS (id, gi))
```

- Implement functor instance for `NinjaLHS' g i`:

```
-- convert any storage of shape `g`, input type `i` into a functor
instance Functor (NinjaLHS' g i) where
  -- f:: (o -> o') -> NinjaLHS' g i o -> NinjaLHS' g i o'
  fmap o2o' (MkNinjaLHS' (MkNinjaLHS (i2o, gi))) =
    MkNinjaLHS' $ MkNinjaLHS (\i -> o2o' (i2o i), gi)
```

See that to be able to extract out values, we need `g` to be a functor:

```
extract :: Functor g => NinjaLHS' g i o -> g o
extract (MkNinjaLHS' (MkNinjaLHS (i2o, gi))) = fmap i2o gi
```


# Natural Transformations as ends
- [Bartosz: Natural transformations as ends](https://www.youtube.com/watch?v=DseY4qIGZV4&list=PLbgaMIhjbmEn64WVX4B08B4h2rOtueWIL&index=13)
- Ends generalize the notion of product/limit. It's sort of like an infinite product plus the wedge condition.
- $\int_X p x x$ is the notation for ends, where $p$ is a profunctor.
- Remember `dimap :: (a' -> a) -> (b -> b') -> p a b -> p a' b'`. Think of this as:

```
-----p a' b'-------
a' -> [a -> b] -> b'
       --pab---
```

- The set of natural transformations is an end.
- Haskell: `type Nat f g = forall x. f x -> g x`.
- We can think of this as the "diagonal" of some end `p x x` for some profunctor `p` we need to cook up.
- `type p f g a b = f a -> g b`. Is `p f g` a profunctor?

```
dimap :: (a' -> a) -> (b -> b') -> (f a -> g b) -> (f a' -> g b')
dimap a'2a b2b' fa2gb = \fa' ->
  let fa = fmap a'2a fa'
  let gb = fa2gb fa
  let gb' - fmap b2b' gb
  in gb'
dimap a'2a b2b' fa2gb = (@fmap g b2b')  . fa2gb  . (@fmap f a'2a)
```

- Clearly, from the above implementation, we have a profunctor.
- So we have a profunctor `P(a, b) = C(Fa, Gb)`.
- In haskell, the end is `End p = forall a. p a a`.
- In our notation, it's `\int_x C(Fx, Gx)`.
- Recall the wedge condition. For a profunctor `p: Cop x C -> C`, and any morphism `k: a -> b` for `a, b ∈ C`,
  the following diagram commutes for the end `\int_X p(X,X)`:

```
 (p x x, p y y, p z z, ... infinite product)
\int_x p(x,x)
 /[πa]  [πb]\
v            v
p(a,a)       p(b,b)
 \            /
[p(id, k)]  [p(k,id)]
   \        /
    v      v
     p a b
```

- If we replace `p x x` with with our concrete `p a b = C(fa, gb)`, we get:

```
    (forall x. f x -> g x)
    /               \
  [@ a]            [@ b]
   v                v
 τa:(f a -> g a)     τb:(f b -> g b)
   \                  /
dimap id(a) k τa    dimap k id(b) τb
   \                 /
    \               τb.(@fmap f k): (f a-> g b)
     \              /
     \           COMMUTES?
     \            /
    (@fmap g k).τa(f a -> g b)

```

- This says that `gk . τa = τb . fk`
- But this is a naturality condition for `τ`!
- So every end corresponds to a natural transformation, and `τ` lives in `[C, D](f, g)`.
- This shows us that the set of natural transformations can be seen as an end (?)
- I can write `\int_a D(fa, ga) ~= [C, D](f, g)`

#### Invoking Yoneda

- Now, yoneda tells us that `[C, Set](C(a, -), f(-)) ~= f(a)`.
- Now I write the above in terms of ends as `\int_x Set(C(a, (x)), f(x)) ~= f(a)`.
- So we can write this as a "point-full" notation!
- In haskell, this would be `forall x. (a -> x) -> f x ~= f a`.

# Ends and diagonals

- [Bartosz: Wedges](https://www.youtube.com/watch?v=TAPxt26YyEI)
- Let's think of `Cop x C`, and an element on the diagonal `(a, a)`, and a function `f: a -> b`.
- Using the morphism `(id, f)`, I can go from `(a, a)` to `(a, b)`.
- If we have `(b, b)`, I can once again use `f` to go fo `(a, b)`.
- So we have maps:

```
     b,b
    / |
   /  |
  /   |
 /    v
a,a-->a,b
```

- This tells us that if we have something defined on the diagonal for a profunctor `p a a`, we can "extrapolate"
  to get data everywhere!
- How do we get the information about the diagonal? Well, I'm going to create a product of all the diagonal elements of the profunctor.
- so we need a limit `L`, along with maps `L -> p c c` for each `c`. This kind of infinite product is called a wedge (not yet,  but soon).
- The terminal object in the category of wedges is the end.
- But our cone is "under-determined". We need more data at the bottom of the cone for things to cohere.
- suppose at the bottom of the cone, we want to go from `p a a` to `p b b`. for this, I need morphisms `(f: b -> a, g: a -> b)` to lift
  into the profunctor with `dimap`.
- We might want to impose this as coherence condition. But the problem is that
  there are categories where we don't have arrows going both ways (eg. partial orders).
- So instead, we need a different coherence condition. If we had a morphism from `a -> b`, then we can get from `p a a --(id, f)-->p a b`.
  Or, I can go from `p b b --(f, id)-->p a b`. The wedge condition says that these commute. So we need `p id f . pi_1 = p f id . pi_2`

#### Relationship to haskell

- How would we define this wedge condition in haskell?
- Because of parametricity, haskell gives us naturality for free.
- How do we define an infinite product? By propositions as types, this is the same as providing `∀x.`.
- `End p = forall a. p a a`
- We can define a cone with apex `A` of a diagram `D: J -> C` as a natural transformation `cone(A): Const(A) => D`. What's the version for a profunctor?
- Suppose we have a profunctor diagram `P: J^op x J -> C`. Then we have a constant profunctor `Const(c) = \j j' -> c`.
  Then the wedge condition  (analogue of the cone condition) is to ask that we need a **dinatural transformation** `cone': Const(A) => P`.
- NOTE: a dinatural transformation is STRICTLY WEAKER than a natural transformation from `J^opxJ -> C`.
- Suppose we have transformation that is natural in both components. That is to say, it is a natural transfrmation
  of functors of the type `[J^op x J -> C]`. This means that we have naturality arrows `α(a,b): p(a,b) -> q(a,b)`. Then the following must commute, for any `f: a -> b` by
  naturality of `α`:

```
      p(b,a)
    /    |
[p(f,id)]|
  /      |
p(a,a)  [α(b,a)]
 |       |
[α(a,a)] |
 |       |
 |    q(b,a)
 |     /
 |  [q(f,id)]
 |   /
q(a,a)
```

- Similarly, other side must commute:


```
      p b a
    /   |  \
[p f id]|   [p id f]
  /     |     \
p a a  [α b a] p b b
 |      |        |
[α a a] |      [α b b]
 |      |        |
 |    q b a      |
 |     /   \     |
 |  [q f id]\    |
 |   /  [q id f] |
 |  /          \ |
q a a         q b b
```

- I can join the two sides back together into a `q a b` by using `[q id f]` and `[q f id]`. The bottom square
  commutes because we are applying `[q f id]` and `[q id f]` in two different orders. By functoriality,
  this is true because to `q(f.id, id.f) = q(f,f) = q(id.f, f.id)`.


```
      p b a
    /   |  \
[p f id]|   [p id f]
  /     |     \
p a a  [α b a] p b b
 |      |        |
[α a a] |      [α b b]
 |      |        |
 |    q b a      |
 |     /   \     |
 |  [q f id]\    |
 |   /  [q id f] |
 |  /          \ |
q a a         q b b
  \             /
 [q id f]      /
    \        [q f id]
     \      /
     q a b
```

- If we erase the central node `[q b a]` and keep the boundary conditions, we arrive at a diagram:

```
      p b a
    /      \
[p f id]    [p id f]
  /           \
p a a          p b b
 |               |
[α a a]        [α b b]
 |               |
 |               |
 |               |
 |               |
 |               |
 |               |
q a a         q b b
  \             /
 [q id f]      /
    \        [q f id]
     \      /
     q a b
```

- Any transformation `α` that obeys the above diagram is called as a *dinatural transformation*.
- From the above, we have proven that any honest natural transformation is a dinatural transformation, since the
  natural transformation obeys the diagram with the middle node.
- In this diagram, see that we only ever use `α a a` and `α b b`.
- So for well behavedness, we only need to check a dinatural transformation at the diagonal. (diagonal natural transformation?)
- so really, all I need are the diagonal maps whoch I will call `α' k = α a a`.
- Now, a wedge is a dinatural transformation from constant functor to this new thingie.


# Parabolic dynamics and renormalization

- [Video](https://www.youtube.com/watch?v=Z77mTqj_Wnk)

# Quantifiers as adjoints

- Consider `S(x, y) ⊂ X × Y`, as a relation that tells us when `(x, y)` is true.
- We can then interpret `∀x, S(x, y)` to be a subset of `Y`, that has all the elements
  such that this predicate holds. ie, the set `{ y : Y | ∀ x, S(x, y) }`.
- Similarly, we can interpret `∃x, S(x, y)` to be a subset of `Y` given by
   `{ y : Y | ∃ x, S(x, y) }`.
- We will show that these are adjoints to the projection `π: X × Y → Y`.
- Treat `P(S)` to be the boolean algebra of all subsets of `S`, and similarly `P(Y)`.
- Then we can view `P(S)` and `P(Y)` to be categories, and we have the functor `π: P(S) → P(Y)`.
- Recall that in this boolean algebra and arrow `a → b` denotes a subset relation `a ⊆ b`.

#### A first try: direct image, find right adjoint

- Suppose we want to analyze when `π T ⊆ Z`, with the hopes of getting some condition when `T ⊆ ? Z` where `?`
  is some to-be-defined adjoint to `π`.
- See that `π T ⊆ Z` then means `∀ (x, y) ∈ T, y ∈ Z`.


```
     T
   t t t
   t t t
    |
    v
---tttt---- π(T)
-zzzzzzzzz--Z
```

- Suppose we build the set `Q(Z) ≡ { (x, y) ∈ S : y ∈ Z }`. That is to say, `Q ≡ π⁻¹(Z)`. (`Q` for inverse of `P`).
- Then, it's clear that we have `π T ⊂ Z` implies that `T ⊆ Q(Z)` [almost by definition].
- However, see that this `Q(Z)` construction goes in the wrong direction; we want a functor
  from `P(S)` to `P(Y)`, which projects out a variable via `∃ / ∀`. We seem to have built
  a functor in the other direction, from `P(Y)` to `P(S)`.
- Thus, what we must actually do is to reverse the arrow `π: S ⊆ X × Y → Y`, and rather we
  must analyze `π⁻¹` itself, because its adjoints will have the right type.
- However, now that we've gotten this far, let's also analyze left adjoints to `π`.

#### Direct image, left adjoint
- Suppose that `Z ⊆ π T`. This means that for every `y ∈ Z`, there is some `x_y` such that  `(x_y, y) ∈ T`

```
     T
   t t t
   t t t
    |
    v
---tttt---- π(T)
----zz--------Z
```

- I want to find an operation `?` such that `? Z ⊆ T`.
- One intuitive operation that comes to mind to unproject, while still reminaing a subset,
  is to use `π⁻¹(Z) ∩ T`. This would by construction have that `π⁻¹(Z) ∩ T ⊆ T`.
- Is this an adjoint? we'll need to check the equation `:)`.

#### Inverse image, left adjoint.

- Suppose we consider `π⁻¹ = π* : P(Y) → P(S)`.
- Now, imagine we have `π*(Z) ⊆ T`.

```
    S
    -
    -
   tttt
   tztt
   tztt T
   tztt
    ^^
    || π*(Z)
----zz-------Z
```

- In this case, we can say that for each `z ∈ Z`, for all `x ∈ X` such that `(x, z) ∈ S`, we had `(x, z) ∈ T`.
- Consider the set `∀ T ≡ { y ∈ T: ∀ x, (x, y) ∈ S => (x, y) ∈ T}`.
- Thus, we can say that `π*(Z) ⊂ T` iff `Z ⊂ ∀ T`.
- Intuitively, `T ⊂ π*(π(T))`, so it must be "hard" for the inverse image of a set `Z` (`π*(Z)`) to
  be contained in the set `T`, because inverse images cannot shrink the size.
- Furthermore, it is the right adjoint to `π*(Z)` because the ???


# TLDP pages for bash conditionals
- [The TLDP pages](https://tldp.org/LDP/Bash-Beginners-Guide/html/sect_07_01.html) have a large list of all
  possible bash conditionals

# Remainder, Modulo

- remainder takes the sign of the first operand.
- modulo takes the sign of the second operand.

# Parameters cannot be changed *anywhere*, not just in return location

```
inductive List (a: Type): Type where
| Good: List a
| Good2: List a -> List a
| Bad: List b -> List a
        ^^^^^^^ -- not allowed!
```

- In hindsight, this makes sense, as the parameter really is a trick to
  represent, well, *parametric* polymorphism.


# LCNF

- `let x := v in e ~= (\x -> e) v`

```
let x : Nat := 2
let xarr : Vec Int x := Nil
let 2arr : Vec Int 2 := Nil
in rfl : xarr = 2arr
```

```
(\x ->
   let xarr : Vec Int x := Nil
   let 2arr : Vec Int 2 := Nil
   in rfl : xarr = 2arr) 2
      ^^^^^^^^^^^^^^^^^ <---- (ill-typed under CIC)
```


```
Erased a ~ Erased b
(\x ->
   let xarr : Vec Int (Erased x) := Nil
   let 2arr : Vec Int (Erased 2) := Nil
   in rfl : xarr = 2arr) 2
      ^^^^^^^^^^^^^^^^^ <---- (ill-typed under CIC)
```

#### Erased


```
match x with
  | F1 f1 => h f1
  | F2 f2 => h f2
```



- Design an ill-typed type system to allow *only* the types
  of errors that occur when floating let/join points?


```
def tupleN (n: Nat) (t: Type) :=
  match n with
  | 0 => Unit
  | n+1 => t * (tupleN n t)

def foo n := Vec Int n

Any ~ t
def f (n: Nat): (tupleN n t) := ...
def f (n: Nat): Any := ...
```

# Predicative v/s Impredicative: On Universes in Type Theory


#### Tarski formulation of univereses

- `U` is a code for types.
- We have a decoding function `T: U → Type`.

```
U type

a ∈ U
-----
T(a) type
```

- Universes bump up levels when we quantify over them?
- Impredicative universes are closed under quantification over types of that same universe.


> Q. Given a definition, give me an algorithm that says when the definition needs predicativity
> A. perform type + universe inference on the definition. If we get a constraint
>    of the form Type lower = Type higher where lower < higher, then the definition
>    needs impredicativity.



# Testing infra in Lean4

- to run tests in parallel, `cd build/stage1/ && CTEST_PARALLEL_LEVEL=20 ctest`.


# Autocompletion in Lean4

- for C++, use `compiledb` to generate a `compile_commands.json`
- for lean, setup a lean toolchain override for the correct `stage0`:

```
$ elan toolchain add my-lean-copy /path/to/my-lean-copy/build/stage0
$ elan override my-lean-copy
```

# Inductive types

#### Coq

##### Expressive Power
- Bare Inductives
- Nested inductives: The constructor of the nesting cannot be a mutual
   [So we can have `T := ... List T`, but not `T := ... Mutual1 T where Mutual1T := Mutual2 T and Mutual2 T := Mutual1 T`]
- Mutual inductives: All parameters of inductives in the mutual group must be the same.
- Nested Mutual inductives: Not supported, something like:

```
T
| .. U (T)

U
| .. T
```

does not work due to the presence of `U(T)`.

##### Computational content
- Bare inductives: primitive recursion principle `fix`, kernel has support for `fix` reduction (iota)
- Nested inductives: primitive recursion principle using `fix` and `match`.
  Kernel has support for `fix` reduction, and `match` is also known by the kernel.
- Mutual inductives: generates 'simple' recursion principles for each element of the mutual.
- Need to use the `scheme` command to get the full recursion principle.
- Primitive recursion principle using `fix` and `match`.

#### Lean

##### Expressive Power
- Bare inductives
- Nested inductives: works perfectly!

```
mutual
inductive U1 (S: Type): Type :=
| mk: U2 S → U1 S
| inhabitant: U1 S

inductive U2 (S: Type): Type :=
| mk: U1 S → U2 S
| inhabitant: U2 S
end

inductive T
| mk: U1 T → T
```
- Mutual inductives: All parameters of inductives types in the mutual group must be the same.

##### Computational content


# Parameter verus Index

- Parameters are fixed for all constructors, indexes can vary amongst constructors.
- Parameters represent parametric polymorphism, and one does not gain information on them during pattern matching.
- Indexes rep
- Coq calls indexes "non-uniform".

# HNF versus WHNF

#### Head normal form
- a data constructor applied to arguments which are in normal form
- a lambda abstraction whose body is in normal form

# Different types of arguments in Lean4:
- `(x: T)` regular argument
- `[S: Functor f]` typeclass argument / argument resolved by typeclass resolution
- `{x: T}`: Maximally implicit argument, to be inferred.
- `⦃x: T⦄`: Non-maximally-inserted implicit argument. It is instantiated if it can be deduced from context,
    and remains uninstantiated (ie, no metavariable is introduced) otherwise.

In Coq people shun away from this binder. I'm not sure why, I guess there are issues with it at a larger scale. We could get rid of it. For the paper it's utterly irrelevant in my opinion

# Big list of lean tactics
- `conv <pattern> => ...`: rewrite in pattern. example: `conv in x + 1 => rw ...`
- `split` allows one to deal with the cases of a match pattern. This also allows one to case on an `if` condition.
- `cases H: inductive with | cons1 => sorry | cons2 => sorry` is used to perform case analysis on an inductive type.
- `cases H; case cons1 => { ... }; case cons2 => { ... }` is the same , but with slightly different syntax.
- `rewrite [rule] (at H)?` performs the rewrite with rule. But generally, prefer `simp [rule] (at H)`, because `simp`
   first runs the rewrite, and then performs reduction. But if `simp` does not manage to perform a rewrite, it
   does not perform reduction, which can lead to weird cases like starting with `let H = x = true in match x | true => 1, false => 2`.
   On running `rewrite [H]`, we get `match true | true => 1, false => 2`. And now if we run `simp`, it performs no reduction.
   On the other hand, if we had run `simp [H]`, it would rewrite to `match true | true => 1 | false => 2` and then also
   perform reduction to give `1`.

# Hyperdoctrine
- A hyperdoctrine equips a category with some kind of logic `L`.
- It's a functor `P: T^op -> C` for some higher category `C`, whose objects are categories
  whose internal logic corresponds to `L`.
- In the classical case, `L` is propositional logic, and `C` is the 2-category of posets.
  We send `A ∈ T` to the poset of subobjects `Sub_T(A)`.
- We ask that for every morphism `f: A -> B`, the morphism `P(f)` has left and right adjoints.
- These left and right adjoints mimic existential / universal quantifiers.
- If we have maps between cartesian closed categories, then the functor `f*` obeys frobenius
  reciprocity if it preserves exponentials: `f*(a^b) ~iso~ f*(a)^f*(b)`.


#### Algebra of logic

- Lindenbaum algebras : Propositional logic :: Hyperdoctrines : Predicate logic
- Work in a first order language, with a mild type system.
- Types and terms form a category $B$ (for base.
- Interpretations are functors which map $B$ to algebras.

#### Syntax
- `e | X`. `e` is untyped. `X` is typed.
- `e` is a sequence of symbols. `X` is a set of variables, which intuitively are the free variable.
- Every variable that has a free occurence in the untyped part should also occur in the typed pat.
- eg. `R x[1] x[2] | { x[1], x[2] }`
- Not every variable in the typing part needs to occur in the untyped part.
- eg. `R x[1] x[2] | { x[1], x[2], x[3] }`. (dummy variable `x[3]`).
- Variables: `x[1], ...`
- constants: `c[1], ...`
- Separators: `|, {, }, ()`.
- `c[i] | {}` is a unary term.
- `x[i] | {x[i]}` is a unary term.
- If `t |X` is `n`ary and `s | Y` is m-ary, then `ts | X U Y` is a `n+m`ary term.
- if `t|X` is n-ary and `y` is a variable, then `t | X U {y}` is a `n-ary` term.

#### Formulas.

- if `R` is a n-ary predicate and `t|X` is a n-ary term, then `Rt|X` is a formula.
- if `phi|X` is a formula and `x ∈ X`, then `∀x, phi | X - {x}` is a formula.

#### A category of types and terms.
- Find a natural way to view terms in our language as arrows in our category.
- `s | Y`. `Y` tells us `card(Y)` name shaped gaps. `s` is a `len(s)` name shaped things.
- `s:codomain`, `Y: domain`.
- Question: when should composition be defined? the types have to match for `t|X . s|Y`.
- So we should have `card(X) = len(s)`.
- We want the composition to be substitution. `t|X . s|Y = t[X/s]|Y`.
- eg. `x3|{x3, x4}  . x1a3 | {x1, x2} = x1|{x1, x2}`. (substitute `x3` by `x1`, and `x4` by `x2`.)
- eg. `x3 x4|{x3, x4}  . x1a3 | {x1, x2} = x1 a3|{x1, x2}`. (substitute `x3` by `x1`, and `x4` by `x2`.)

#### Problem: we don't have identity arrows!
- Left identities `x1 x2 | {x1, x2}` is not a right identity!
- But in a category, we want two sided identity.
- The workaround is to work with an equivalence class of terms.
- Define equivalence as `t|X ~= t(X/Y)|Y`.
- Arrows are equivalence classes of terms.

#### Reference
- [Hyperdoctrines and why you should care about them](https://www.youtube.com/watch?v=VvSTE9oqRag)

# Fungrim

- https://fredrikj.net/math/fungrim2022.pdf
- They want to integrate with mathlib to have formal definitions.

# Category where coproducts of computable things is not computable

- Modular lattices are an algebraic variety.
- Consider the category of modular latties.
- The free modular lattice on 2 elements and on 3 elements has dediable equality, by virtue of being finite.
- The free modular lattice on 5 elements does not have decidable equality.
- The coproduct of free modular lattice on 2 and 3 generators is the free modular
  lattice on 5 generators, because $F(2 \cup 3) = F(2) \sqcup F(3)$  (where $2, 3$ are two and three element sets),
  because free is left adjoint to forgetful, and the left adjoint $F$ preserve colimits!

# Homotopy continuation


- [Rigorous arithmetic with approximate roots of polynomials --- CAG L16](https://www.youtube.com/watch?v=XC_tfjjBPLc&list=PL5ErEZ81Tyqc1RixHj65XA32ejrS2eEFK&index=38)

# Relationship between linearity and contradiction

- https://xorshammer.com/2021/04/08/but-why-is-proof-by-contradiction-non-constructive/

# Monads from Riehl

- I'm having some trouble enmeshing my haskell intuition for monads with the rigor, so this
- A category is said to be monadi
  is an expository note to bridge the gap.

#### What is a monad
- A monad is an endofunctor `T: C -> C` equipped with two natural transformations:
- (1) `return/eta: idC => T` [yeeta, since we are yeeting into the monad.]
- (2) `join/mu: T^2 => T`, such that two laws are obeyed:

- First law: `mu, T` commutation:

```
T^3(x) --T(@mu@x)--> T^2@x
|                   |
mu@(T@x)          mu@x
|                   |
v                   v
T^2(x)---mu@x-----> T(x)
```

- Second law: `mu, eta` cancellation:


```
(Tx) --eta@(T@x)--> T^2(x)
|EQ                 |
|                   |
T@(eta@x)         mu@x
|                   |
v                 EQv
T^2(x)---mu@x---> T(x)
```

- `mu .  eta T = mu . T eta = 1`



#### Monad from adjunction

- Any adjunction between a Free functor `F: L -> H` and a forgetfUl/Underlying functor `U: H -> L`
  `F |- U` gives a monad. The categories are named `L, H` for `lo, high` in terms of the amount of
  structure they have. We go from low structure to high structure by the free functor.
- The monad on `L` is given by `T := UF`.
- Recall that an adjunction gives us `pullback: (F l -> h) -> (l -> U h)` and `pushfwd: (l -> U h) -> (F l -> h)`.
  The first is termed pullback since it takes a function living in the high space and pulls it back to the low space.
- This lets us start with `(F l -> F l)`, peel a `F` from the left via `pullback`
  to create  `(l -> U (F l))`. That is we have `return: l -> T l`.
- In the other direction, we are able to start with `(U h -> U h)`, peel a `U` from the right via `pushforward` to
  create `(F U h -> h)`. This allows us to create the counit as `T^2 l = F U F U l = F (U F) U l -> F U l = T l`.

#### Algebra for a monad $C^T$.

- Any monad, given by `(T: C -> C, return: 1C => T, join: T^2  => T)` has a category of `T`-algebras associated to it.
- The objects of `T-alg` are morphisms `f: Tc -> c`.
- The morphisms of `T-alg` between `f: Tc -> c` and `g: Td -> d` are commuting squares, determined by an `arr: c -> d`

```
Tc -T arr-> Td
|           |
f           g
|           |
v           v
c   -arr->  d
```

- The notation for the category as $C^T$ makes some sense, since it consists of objects of the form `Tc -> c` which matches
  somewhat with the function notation. We should have written $C^{TC}$ but maybe that's too unweildy.


#### Factoring of forgetful functor of adjunction

- Any adjunction `(F: L -> H, U:  H -> L)` with associated monad `T` allows us to factor `U: H -> L` as:

```
H -Stx-> L^T -forget-> L
```

- So we write elements of `H` in terms of syntax/"algebra over `L`". We then forget the algebra structure to keep only the low form.
- The way to think about this is that any object in the image of `U` in fact has a (forgotten) algebra structure, which is why
  we can first go to `L^T` and then forget the algebraic structure to go back to `L`. It might be that this transition from `H` to `L^T`
  is very lossy. This means that the algebra is unable to encode what is happening in `H` very well.

#### Monadic adjunction

- Let us consider an adjunction `(F: L -> H, U: H -> L)` with monad `T`. Factor `U` via `L^T` as:

```
H -Stx-> L^T -forget-> L
```

- The adjunction is said to be monadic if in the factoring of `U` via `L^T`, it happens
   that `H ~= L^T`. That is, `Stx` is an equivalence between `H` and `L^T`.
- The way to think about this is that any object in the image of `U` in fact has a (forgotten) algebra structure, and
  this algebra structure actually correctly represents everything that was happening in `H`.
- Another way to say **the adjunction `F: L -> H: U` is monadic** is to say that is that
   **`F` is monadic over `U`**. We imagine the higher category `H` and the free functor `F` lying over `L` and `U`.
- **Warning**: This is a STRONGER condition than saying that `UF` is a monad. `UF` is ALWAYS a monad for ANY adjunction.
  This says that `H ~= L^T`, via the factoring `H -Stx-> L^T -forget-> L`.
- We sometimes simply say that **`U` is monadic**, to imply that there exists an `F` such that `UF` is an adjunction
  and that `U ~= L^T`.

#### Category of models for an algebraic theory

- A functor is finitary if it preserves filtered colimits.
- In particular, a monad `T : L -> L` is finitary if it preserves filtered colimits in C.
- If a right adjoint is finitary, then so is its monad because its left adjoint preserves all colimits.
  Thus, their composite preserves filtered colimits.
- A category `H` is a **category of models for an algebraic theory** if there
  is a finitary monadic functor `U : H -> Set`.

#### Limits and colimits in categories of algebras


- We say that `H` is monadic over `L` iff the adjunction `F: L -> H: U` such that the monad `T: L -> L := UF`
  gives rise to an equivalence of categories `H ~= L^T`.

## Riehl: Limits and colimits in categories of algebras

Here, we learn theorems about limits and colimits in `L^T`.

#### Lemma 5.6.1: If `U` is monadic over `F`, then `U` reflects isos

- That is, if for some `f: h -> h'`, if `Uf: Uh -> Uh'` is an iso, then so is `f`.
- Since the adjunction `F |- U` is a monadic adjunction (`U` is monadic over `F`), we know that `H ~= L^T`, and `U` equals
  the forgetful functor `(H = L^T) -> L`.
- Write the arrow `f: h -> h'` as an arrow in `L^T` via the commuting square datum
  determined by `g: h -> h'`:

```
Tl-Tg->Tl'
|      |
a      a'
|      |
v      v
l--g-->l'
```

- Since we assume that `U(Tg)` is iso, this means that `g` is iso. This means that there exists a `g'`
  which is the inverse of `g`. But this means that the diagram below commutes:


```
Tl<-Tg'-Tl'
|      |
a      a'
|      |
v      v
l<-g'--l'
```

- For a proof, we see that `a' . Tg = g . a'`. Composing by `g'` on left, giving: `g' . a' . Tg = a'`.
  Composing by `Tg'` on the right, we get: `g'. a' = a' . Tg'`. That's the statement of the above square.
- This means we have created an inverse `Tg'`, which reflects `g'` into `L^T`.


#### Corollary 5.6.2: Bijective continuous functions in CHaus are isos

- When we forget to `Set`, we see that bijections are the isos. Thus, in `CHaus` (compact haussdorff spaces)
  which is monadic over `Set`, we have that the arrows that forget to become isos in set, ie, continuous
  bijections are also isos.

#### Corollary 5.6.4: Any bĳective homomorphism arising from a monadic adjunction which forgets to `Set` will be iso

- Follow the exact same proof.

#### Thm 5.6.5.i A monadic functor `U: H -> L` creates any limits that `L` has.

- Since the equivalence `H ~= L^T` creates all limits/colimits, it suffices to show the result for `U^T: L^T -> L`.
- Consider a diagram `D: J -> C^T` with image spanned by `(T(D[j]) -f[j]-> D[j])`.
- Consider the forgotten diagram `U^TD: J -> C` with image spanned by `D[j]`.  Create the limit cone
  `P` (for product, since product is limit) with morphisms `pi[j]: P -> D[j]`. We know this limit exists since we assume that `L`
  has this limit that `U^T` needs to create.
- We can reinterpret the diagram `D: J -> C^T` as a natural transformation between two functors `Top, Bot: J -> C`.
  These functors are `Top(j) := T(D[j])`,
  `Bottom(j) := D[j]`.
- The the natural transformation is given by `eta: Top => Bottom`,
  with defn `eta(j) := D[j]-f[j]-> D[j]` where `f[j]` is given by the image of `(T(D[j]) -f[j]-> D[j])`.
- So we see that `eta: Top => Bot` can also be written as `eta: TD => D` since `Top ~= TD` and `Bot ~= D`.
- Now consider the composition of natural transformations `Const(TL) =Tpi=> TD =gamma=> D` all in `J -> C`.
  This gives us a cone with summit `TL`.
- This cone with summit `TL` factors through `L` via the unique morphism `lambda: TL -> L`.
  We wish to show that `(TL -lambda-> L)` is a `T`-algebra, and is the limit of `D`.
- Diagram chase. Ugh.

#### Corollary 5.6.6: The inclusion of a reflective subcategory creates all limits
- The inclusion of a reflective subcategory is monadic.
- This lets us create all limits by the above proposition.

#### Corollary 5.6.7: Any category monadic over `Set` is complete
- `Set` has all limits.
- The forgetful functor `U: H -> L` creates all limits that `L=Set` has.
- Thus `H` has all limits, ie. is complete.

#### Corollary 5.6.9: `Set` is cocomplete

- The contravariant power set functor `P: Set^op -> Set` is monadic.
- `Set` has all limits, and `P` creates all limits.
- Thus all limits of `Set^op` exist, ie, all colimits of `Set` exist.

#### Category of models for alg. theory is complete

TODO

#### Category of algebras has coproducts

- We show how to construct the free product of monoids via haskell. The same principle
  generalizes for any algebraic theory:

```hs
import Control.Monad(join)

-- |(a*|b*)* ~~simplify~~> (a|b)*
eval :: Monoid a => Monoid b => [Either [a] [b]] -> [Either a b]
eval = map (either (Left . mconcat) (Right . mconcat))

-- | a*|b* -> (a|b)* with no simplification
transpose :: Either [a] [b] -> [Either a b]
transpose = either (map Left) (map Right)

-- | (a*|b*)* -> (a|b)* with no simplification
flatten :: [Either [a] [b]] -> [Either a b]
flatten = join . map transpose


-- force: eval = flatten | via coequallizer
```

#### If $T: C \to C$ is finitary and $C$ is complete and cocomplete, then so is $C^T$

- We have already seen that if $C$ is complete then so is $C^T$
- We have also seen that $C^T$ contains coproducs
- So is we show that $C^T$ has coequalizers, then we get cocomplete, since any colimit can be
  expressed as coproduct-coequalizer.
- To show that all coequalizers exists is to show that there is an adjoint to
  the functor `const: [C^T] -> [J -> C^T]` where `J := [a -f,g-> b]`
  is the diagram category for coequalizers.
- Recall that the adjoint sends a diagram `[J -> C^T]` to the nadir that is the coequalizer in `C^T`.
- See that the constant functor trivially  preserves limits.
- To show that it possesses an adjunction, we apply an **adjoint functor theorem** (fuck me).
  In particular, we apply the general adjoint functor theorem, so we must show that the solution
  set condition is satisfied.
- Recall that the solution set condition for $F: C \to D$ requires that for each $d \in D$,
  the comma category $const(d) \downarrow F$ admit weakly initial objects.
- Unwrapping that definition: For each $d \in D$, there is a solution set.
  Tht is, there exists a small set $I$
  and a family of objects $c_I$ and a family of morphisms $f_I: d \to F(c_i)$ such that
  any morphism $d \to F(c)$ in $D$ can be factored via some $f_i$ as $d \xrightarrow{f_I} F(c_i) \xrightarrow{g} F(c) = d \to F(c)$.
- To apply the theorem, we must produce a solution set for every object in `[J -> C^T]`, that is,
  for each parallel pair of morphisms $f, g: (A, \alpha) \to (B, \beta)$.
- We will produce a solution set with a single element by creating a fork $(Q, u)$ such that any other fork
  factors through this fork (perhaps non uniquely!) So we create:

$$
(A, \alpha) \xrightarrow{f, g} (B, \beta) \xrightarrow{q} (Q, u)
$$

- If we know how to create coequalizers in $C^T$, then this would be easy: we literally just create a coequalizer.
- Instead, we create some "approximation" of the coequalizer with $(Q, u)$.
- To start with, we define $q_0: B \to Q_0$ in $C$ of the pair $(A \xrightarrow{f, g} B$).
- If $Tq_0$ would be the coequalizer of $Tf, Tg$ then we are done.
  But this is unlikely, since a monad need not preserve coequalizers.
- Instead, we simply calculate the coequalizer of $Tf, Tg$ and call this $q_1: B \to Q_1=TQ_0$.
- Repeat inductively to form a directed limit (colimit).
- Monad preserves filtered colimits, since in $UF$, $F$ the left adjoint preserves all colimits, and $U$
  the right adjoint preserves colimits since it simply forgets the data in

# Combinatorial Cauchy Schwarz

#### Version 1

- Suppose you have r pigeons and n holes, and want to minimize the number of pairs of pigeons in the same hole.
- This can easily be seen as equivalent to minimizing the sum of the squares of the number of pigeons in each hole:
  $\min_{h: i > j} (h[i] - h[j])^2$ where $h[i]$ is the hole of the $i$th pigeon.
- Classical cauchy schwarz: $x_1^2 + x_2^2 + x_3^2 \geq 1/2(x_1 + x_2 + x_3)^2$
- Discrete cauchy schwarz: On placing a natural number of pigeons in each hole, The number of pairs of pigeons in the
  same hole is minimized iff pigeons are distributed as evenly as possible.
- Pigeonhole principle: When $r = m + 1$, the best split possible is $(2, 1, 1, \dots)$.

#### Version 2

- I recently learned about a nice formulation of this connection from a version of the Cauchy–Schwarz
  inequality stated in Bateman's and Katz's article.
- Proposition: Let $X$ and $Y$ both be finite sets and let `f:X→Y` be a function.
- $|ker f| \cdot |Y| \geq |X|^2$. (Where `ker f` is the kernel of `f`, given as the equalizer of `X*X-f*f-> X`.
    More explicitly, it is the subset of `X*X`  `ker(f) := { (x, x') : f(x) = f(x') }`).
- Equality holds if and only if every fiber has the same number of elements.
- This is the same as the version 1, when we consider $f$ to be the function $h$ which assigns pigeons to holes.
  Every fiber having the same number of elements is the same as asking for the pigeons to be evenly distributed.
- Compare: $|ker(f)| \cdot |Y| \geq |X|^2$ with $(x_1^2 + x_2^2 + x_3^2) \cdot n \geq (x_1 + x_2 + x_3)^2$. Cardinality replaces
  the action of adding things up, and $|X|^2$ is the right hand side, $|ker(f)|$ is the left hand side, which is the sum of squares.

# Bezout's theorem

- [On Bezout's theorem Mc coy](https://sites.math.washington.edu/~morrow/336_19/papers19/Dathan.pdf)
- Let $k$ be algebraically closed.
- Let $R \equiv k[x, y, z]$ be ring.
- We wish to detect number of intersections betweeen $f, j \in k[x, y, z]$ counted upto multiplicity.
- For any point $a \in k$, denote $R_a$ to be the localization of $R$ at the multiplicative subset $D_a \equiv \{ f \in R: f(a) \neq \}$
  ($D$ for does not vanish).
- So $R_a \equiv D_a^{-1}(R)$, which concentrates attention around point $a$.

#### Intersection multiplicity $i[f \cap g](a)$
- Define the intersection multiplicyt of $f, g$ at $a$ by notation $i[f \cap g](a)$.
- Defined as $i[f \cap g](a) \equiv dim_k(R_a/(f, g)_a)$.
- That is, we localize the ring at $a$ and quotient by the ideal generated by $f, g$,
  and then count the dimension of this space as a $k$ vector space.

####  $f(a) \neq 0$ or $g(a) \neq 0$ implies $i[f \cap g](a) \equiv 0$
- WLOG, suppose $f(a) \neq 0$. Then localization at $a$ makes $f$ into a unit. The ideal $(f, g)_a \equiv R_a$ since the ideal
  explodes due to the presence of the local unit $f_a$. Thus, $R_a/(f, g)_a \equiv 0$.

#### $f(a) = 0$ and $g(a) = 0$ implies $i[f \cap g](a) \neq 0$.
- If both vanish, then $(f, g)_a$ is a real ideal of $R_a$.


#### Examples
- $x-0$ and $y-0$ at $(0, 0)$ have multiplicity $D_{(0, 0)}^{-1}(k[x, y]/(x, y))$ which is just $k$, which has dimension $1$.
  So they intersect with dimension $1$.
- $x-1$ and $y-1$ at $(0, 0)$ have multiplicity $D_{(0, 0)}^{-1}(k[x, y]/(x - 1, y - 1))$. The ideal $(x - 1, y - 1)$ blows up because $x - 1 \in D_{(0, 0)}$,
  and thus the quotient is $0$, making the dimension $0$.
- $x^2-y$ and $x^3-y$ at $(0, 0)$ gives quotient ring $k[x, y]/(x^2-y, x^3-y)$, which is the same as $k[x, y]/(x^2 - y, x^3 - y, 0)$, which is equal
  to $k[x,y]/(x^2, x^3, y)$, which ix $k[x]/(x^2)$. This is the subring of the form $\{ a + bx : a,b \in k \}$ which has dimension $2$ as a $k$
  vector space. So this machinery actually manages to captures the degree 2 intersection between $y=x^2$ and $y=x^3$ at $(0, 0)$.

##### Intersection cycle ($f \cap g$)
- Define $f \cap g \equiv \sum_{a \in \texttt{space}} i[f \cap g](a) \cdot a.$
- It's a generating function with intersection multiplicity as coefficients hanging on the clothesline of points.

#### Intersection number $\#(f \cap g)$
- Given by $\#(f \cap g) \equiv \sum_{a \in \texttt{space}} i[f \cap g](a)$. This is the count of number of intersections.

#### Lemma: $f \cap g = g \cap f$
- Mental note: replace $f \cap g$ with "ideal $(f, g)$" and stuff makes sense.
- Follow immediately since $(f, g) = (g, f)$ and the definition of $i[f \cap g](a) = R_a/(f, g)_a$ which is equal
  to $R_a/(g, f)_a = i[g \cap f](a)$

#### Lemma: $f \cap (g + fh) = f \cap g$
- $(f, g + fh) \equiv (f, g)$.

#### $f \cap gh \equiv f \cap g + f \cap h$
- Heuristic: if $f(a)$ and $gh(a)$ vanish, then either $f(a), g(a)$ vanish or $f(a), h(a)$ vanish, which can be counted by
  $f \cap g + f \cap h$

#### Lemma: if $f, g$ are nonconstant and linear then $\#(f \cap g) = 1$.
- Recall that we are stating this within the context of $k[x, y, z]$.
- So $f, g$ are homogeneous linear polynomials $f(x, y, z) = ax + by$, $g(x, y, z) = cx + dy$.
- Sketch: if they have a real solution, then they will meet at unique intersection by linear algebra.
- if they do not have a unique solution, then they are parallel, and will meet at point at infinity which exists
  because we have access to projective solutions.

##### Lemma: homogeneous polynomial $g \in k[p, q]$ factorizes as $\alpha_0 p^t \prod_{i=1}{n-t}(p - \alpha_i q)$: $\alpha_0 \neq 0$ and $t > 0$
- Key idea: see that if it were $g \in k[p]$, then it would factorize as $p^t \prod_i (p - \alpha_i)$
- To live in $k[p, q]$, convert from $g(p, q) \in k[p, q]$ to $g(p/q, q/q) \in k[(p/q)]$, which is the same
  as $g(t, 1) \in k[t]$.
- Since we are homogeneous, we know that $g(\lambda p, \lambda q) = \lambda^{deg(g)} g(p, q)$. This lets us
  make the above transform:

- $g(p/q, q/q) = g(p/q, 1) = (p/q)^k \prod_{i : i +k = n} (p/q - \alpha_i)$.
- $g(p/q, q/q) = g(p/q, 1) = (p/q)^k \prod_{i : i + k = n} (p - \alpha_i q)/q$.
- $g(p/q, q/q) = g(p/q, 1) = p^k/q^k \cdot (1/q^{n-k}) \cdot \prod_{i : i + k = n} (p - \alpha_i q)$.
- $g(p/q, q/q) = g(p/q, 1) = p^k / q^n \prod_{i : i + k = n} (p - \alpha_i q)$.
- $g(p, q) = q^n \cdot g(p/q, 1) = q^n \cdot p^k / q^n \prod_{i : i + k = n} (p - \alpha_i q)$.
- $g(p, q) = q^n \cdot g(p/q, 1) =  p^k \prod_{i : i + k = n} (p - \alpha_i q)$.
- This proves the decomposition that $g(p, q) = q^k \prod_i (p - \alpha_i q)$.


##### Lemma: homogeneous polynomial $g \in k[p, q]$ factorizes as $\alpha_0 q^t \prod_{i=1}{n-t}(p - \alpha_i q)$ with $t > 0$.
- This is different from the previous step, since we are pulling out a factor of $q^t$ this time!
- We cannot argue "by symmetry" since the other terms are $(p - \alpha_i q)$. If it really were symmetry, then we should
  have $(q - \alpha_i p)$ which we don't.
- So this new lemma is in fact DIFFERENT from the old lemma!

- Key idea: see that if it were $g \in k[p]$, then it would factorize as $p^t \prod_i (p - \alpha_i)$
- To live in $k[p, q]$, convert from $g(p, q) \in k[p, q]$ to $g(p/q, q/q) \in k[(p/q)]$, which is the same
  as $g(t, 1) \in k[t]$.
- Since we are homogeneous, we know that $g(\lambda p, \lambda q) = \lambda^{deg(g)} g(p, q)$. This lets us
  make the above transform:

- $g(p/q, q/q) = g(p/q, 1) = (p/q)^k \prod_{i : i +k = n} (p/q - \alpha_i)$.
- $g(p/q, q/q) = g(p/q, 1) = (p/q)^k \prod_{i : i + k = n} (p - \alpha_i q)/q$.
- $g(p/q, q/q) = g(p/q, 1) = p^k/q^k \cdot (1/q^{n-k}) \cdot \prod_{i : i + k = n} (p - \alpha_i q)$.
- $g(p/q, q/q) = g(p/q, 1) = p^k / q^n \prod_{i : i + k = n} (p - \alpha_i q)$.
- $g(p, q) = q^n \cdot g(p/q, 1) = q^n \cdot p^k / q^n \prod_{i : i + k = n} (p - \alpha_i q)$.
- $g(p, q) = q^n \cdot g(p/q, 1) =  p^k \prod_{i : i + k = n} (p - \alpha_i q)$.
- This proves the decomposition that $g(p, q) = q^k \prod_i (p - \alpha_i q)$.

## Lemma: $f \in k[x, y, z]$ and $g \in [y, z]$ homogeneous have $def(f) deg(g)$ number of solutions
- This is the base case for an induction on the degree of $x$ in $g$. here, the degree of $x$ in $g$ is zero.
- to compute $i[f(x, y, z) \cap g(y, z)]$, we write it as $i[f(x, y, z) \cap z^k \prod_{i : i + k = n} (y - \alpha_i z)]$
- This becomes $i[f(x, y, z) \cap y^k] + \sum_i i[f(x, y, y) \cap  (y - \alpha_i z)]$.
- Intersecting with $y^k$ gives us $k$ times the intersection of $y$ with $f(x, y, z)$, so we have
  the eqn $i[f(x, y, z) \cap z^k] = k i[f(x, y, z) \cap z]$.
- The full eqn becomes $k i[f(x, y, z) \cap z] + \sum_i i[f(x, y, z) \cap  (y - \alpha_i z)]$.



##### Solving for $i[f(x, y, z) \cap z]$

- Let's deal with the first part.
- See that $i[f(x, y, z) \cap z]$ equals $i[f(x, y, 0) \cap z]$, because we want a common intersection, thus can impose
  $z = 0$ on $f(x, y, z)$.
- We now write $f(x, y, 0) = \mu y^t \prod_j (x - \beta_j y)$.

##### Solving for $i[f(x, y, z) \cap (y - \alpha_i z)]$
- Here, we must impose the equation $y = \alpha_i z$.
- Thus we are solving for $f(x, z, \alpha_i z)$. Once again, we have an equation of two variables, $x$ and $z$.
- Expand $f(x, z, \alpha_i z) = \eta_i z^{l_i} \prod_{j=1}{m - l_i}(x - \gamma_{ij} z)$
- This makes the cycles to be $l_i (z \cap (y - \alpha_i z)) + \sum_j (x - \gamma_{ij} z) \cap (y - \alpha_i z)$.
- The cycle $(z \cap (y - \alpha_i z))$ corresponds to setting $z = 0, y - \alpha_i z = 0$, which sets $y=z=0$.
  So this is the point $[x:0:0]$.
- The other cycle is $(x - \gamma_{ij} z) \cap (y - \alpha_i z)$, which is solved by $(\gamma_{ij} z : \alpha_i z : z)$.
- In total, we see that we have a solution for every cycle.

#### Inductive step

- Let $deg(f)$ denote total degree of $f$, $deg_x(f)$ denote $x$ degree.
- Let $\deg_x(f) \geq deg_x(g)$.
- We treat $f, g$ as polynomials in a single variable $x$, ie, elements $(k[y, z])[x]$.
- We want to factorize $f$ as $f = Qg + R$. But to do this, we need to enlarge the coefficient ring $k[y, z]$
  into the coefficient *field* $k(y, z)$ so the euclidean algorithm can work.
- So we perform long division to get polynomials $Q, R \in (k(y, z)[x]$ such that $f = Qg + R$.
- Since $f, g$ are coprime, we must have $R$ nonzero. Now these $Q, R$ are rational *functions* since they live in $k(y, z)$.
- Take common denominator of $Q, R$ and call this $h \in k[y, z]$ (ie, it is the polynomial denominator).
- Then $hf = (hQ)g + (hR)$ which is $hf = qg + r$ where $q \equiv hQ \in k[y, z]$ and $r \equiv hR \in k[y, z]$.
  So we have managed to create polynomials $q, r$ such that $hf = qg + r$.
- Let $c = gcd(g, r)$. $c$ divides $g$ and $r$, thus it divides $qg + r$, ie, it divides $hf$.
- Dividing through by $c$, we get $h'f = qg' + r'$, where $h = h'c$, $g = g'c$, $r = r'c$.
- We assume (can be shown) that these are all homogeneous.
- Furthermore, we started with $gcd(g, f) = 1$. Since $g'$ divides $g$, we have $gcd(g', f) = 1$.
- $c$ cannot divide $f$, since $c = gcd(g, r)$, and $g, f$ cannot share nontrivial common divisors. Thus, $gcd(c, f) = 1$.
- We have some more GCDs to check, at the end of which we write the intersection equation:

$$
f \cap g = ()
$$

- [Borcherds Video](https://www.youtube.com/watch?v=UJssbO-e2yw)
- [On Bezout's Theorem: Dathan Ault-McCoy](https://sites.math.washington.edu/~morrow/336_19/papers19/Dathan.pdf)

# Example for invariant theory

- Consider $p(z, w) = p_1 z^2 + p_2 zw + p_3 w^2$ --- binary forms of degree two.
- The group $SL(2, Z)$ acts on these by substituting $(z, w) \mapsto PSL(2, Z) (z, w)$.
- We can write the effect on the coefficents explicitly: $(p_1', p_2', p_3') = M (p_1, p_2, p_3)$.
- So we have a representation of $SL(2, Z)$.
- An example

- [IAS lecture](https://www.youtube.com/watch?v=3jksqrYuvuk)

# Counterexample to fundamental theorem of calculus?

- Integral of `1/x^2` from `[-1, 1]` should equal `-1/x` evaluated at `(-1, 1)` which gives `-1/1 - (-(-1)/1)`, that is, `-1 - 1 = -2`.
- But this is absurd since $1/x^2$ is always positive in $[-1, 1]$.
- What's going wrong?

# Why a sentinel of `-1` is sensible

- See that when we have an array, we usually index it with an array index of `0 <= i < len`.
- If `len = 0`, then the only "acceptable" `i` is `-1`, since it's the greatest integer that is less that `len=0`.

# Data structure to maintain mex

#### offline

- Key idea: maintain a set of numbers that we have not seen, and maintain
  set of numbers we have seen. Update the set of unseen numbers on queries.
  The mex is the smallest number of this set.

#### online

- Key idea: exploit cofinality. Decompose set of numbers we have not seen into two parts:
 a finitary part that we maintain, and the rest of the infinite part marked by an `int` that tells
 us where the infinite part begins.

```cpp
set<int> unseen;
map<int, int> freq;
// unseen as a data structure maintains
// information about [0..largest_ever_seen]
int largest_ever_seen;


void init() {
    unseen.insert(0);
}

void mex_insert(int k) {
    freq[k]++;
    for(int i = largest_ever_seen+1; i <= k; ++i) {
        unseen.insert(i);
    }
    unseen.erase(k);
    largest_ever_seen = max(largest_ever_seen, k);
}

void mex_delete(int k) {
    assert(freq[k] >= 1);
    freq[k]--;
    if (freq[k] == 0) {
        unseen.insert(k);
    }
}

int mex_mex() {
    assert(!unseen.empty());
    return *unseen.begin();
}
```

# Scatted algebraic number theory ideas: Ramification

- I've  had Pollion on math IRC explain ramification to me.

```
15:17 <Pollion> Take your favorite dedekind domain.
15:17 <bollu> mmhm
15:17 <Pollion> For instance, consider K a number field
15:17 <Pollion> and O_K the ring of integers.
15:17 <Pollion> Then take a prime p in Z.
15:18 <Pollion> Since Z \subset O_K, p can be considered as an element of O_K, right ?
15:18 <bollu> yes
15:18 <Pollion> Ok. p is prime in Z, meaning that the ideal (p) = pZ is a prime ideal of Z.
15:18 <bollu> yep
15:18 <Pollion> Consider now this ideal, but in O_K
15:18 <bollu> right
15:19 <Pollion> ie the ideal pO_K
15:19 <bollu> yes
15:19 <Pollion> It may not be prime anymore
15:19 <bollu> mmhm
15:19 <Pollion> So it factors as a product of prime ideals *of O_K*
15:20 <Pollion> pO_K = P_1^e_1....P_r^e_r
15:20 <Pollion> where P_i are distinct prime ideals of O_K.
15:20 <bollu> yes
15:20 <Pollion> You say that p ramifies in O_K (or in K) when there is some e_i which is > 1
15:21 <Pollion> Example
15:21 <Pollion> Take Z[i], the ring of Gauss integers.
15:22 <Pollion> It is the ring of integers of the field Q(i).
15:22 <Pollion> Take the prime 2 in Z.
15:23 <bollu> (2) = (1 + i) (1 - i) in Z[i] ?
15:23 <Pollion> Yes.
15:23 <Pollion> But in fact
15:23 <Pollion> The ideal (1-i) = (1+i) (as ideals)
15:23 <Pollion> So (2) = (1+i)^2
15:23 <Pollion> And you can prove that (1+i) is a prime ideal in Z[i]
15:23 <bollu> is it because (1 - i)i = i + 1 = 1 + i?
15:24 <Pollion> Yes
15:24 <bollu> very cool
15:24 <Pollion> Therefore, (2) ramifies in Z[i].
15:24 <bollu> is it prime because the quotient Z[i]/(1 - i) ~= Z is an integral domain? [the quotient tells us to make 1 - i = 0, or to set i = ]
15:24 <Pollion> But you can also prove that primes that ramify are not really common
15:24 <bollu> it = (1 - i)
15:25 <Pollion> In fact, 2 is the *only* prime that ramifies in Z[i]
15:25 <Pollion> More generally, you only have a finite number of primes that ramify
15:25 <bollu> in any O_K?
```


# Coreflection

- A right adjoint to an inclusion functor is a coreflector.

#### Torsion Abelain Group -> Abelian Group

- If we consider the inclusion of abelian groups with torsion into the
  category of abelian groups, this is an inclusoin functor.
- This has right adjoint the functor that sends every abelian group into
  its torsion subgroup.
- See that this coreflector somehow extracts a subobject out of the larger object.

#### Group -> Monoid
- inclusion: send groups to monoids.
- coreflection: send monoid to its group of units. (extract subobject).

#### Contrast: Reflective subcategory

- To contrast, we say a category is reflective if the inclusion $i$ has a _left_ adjoint
  $T$.
- In this case, usually the inclusion has more _structure_, and we the reflector
  $T$ manages to _complete_ the larger category to shove it into the subcategory.
- Eg 1: The subcategory of complete metric spaces embeds into the category of
  metric spaces. The reflector $T$ builds the completion.
- Eg 2: The subcategory of sheaves embeds into the category of presheaves. The
  reflector is sheafification.

#### General Contrast

- $T$ (the left adjoint to $i$) adds more structure. Eg: completion, sheafification.
- This is sensible because it's the left adjoint, so is kind of "free".
- $R$ (the right adjoint to $i$) deletes structure / pulls out substructure.
  Eg: pulling out torsion subgroup, pulling out group of units.
- This is sensible because it's the right adjoint, and so is kind of "forgetful",
  in that it is choosing to forget some global data.

#### Example from Sheaves
- This came up in the context of group actions in Sheaves in geometry and logic.
- Suppose $G$ is a topological group. Consider the category of $G$ sets,
  call it $BG$.
- If we remove the topology on $G$ to become the discrete topology, we get
  a group called $G^\delta$. This has a category of $G^\delta$ sets,
  called $BG^\delta$.


# Better `man` Pages via `info`

- I recently learnt about `info`, and it provides so much more quality than `man`!
- `info` pages about things like `sed` and `awk` are actually useful.


# The Zen of juggling three balls

- Hold one ball in the left hand `A`, two in the right hand `B, C`.
  This initial configuration is denoted `[A;;B,C]`.
- throw `B` from the right hand to the left hand. This configuration is denoted
  by `[A;B←;C]` where the `B←` is in the middle since it is in-flight, and has `←`
  since that's the direction its travelling.
- When the ball `B` is close enough to the left hand that it can be caught, *throw*
  ball `A`. Thus the configuration is now `[;(A→)(B←);C]`.
- Now catch ball `B`, which makes the configuration `[B;A→;C]`.
- With the right hand, throw `C` (to anticipate catching `A`). This makes the
  configuration `[B;(A→)(C←);]`
- Now catch the ball `A`, which makes the configuration `[B;C←;A]`.
- See that this is a relabelling of the state right after the initial state. Loop back!

### The Zen
- The key idea is to think of it as (1) "throw (B)" (2) "throw (A), catch (B)", (3) "throw (C), catch (A)", and so on.
- The cadence starts with a "throw", and then settles into "throw, catch", "throw catch", "throw, catch", ...
- This cadence allows us to actually succeed in the act of juggling. It fuses the hard parts
  of actually freeing a hand and accurately catching the ball. One can then focus attention
  on the other side and solve the same problem again.

# Example of lattice that is not distributive

- Take a 2D vector space, and take the lattice of subspaces of the vector space.
- Take three subspaces; `a = x`, `b = y`, `c = x + y`.
- Then see that `c /\ (a \/ b) = c`, while `c /\ a = c /\ b = 0`,
  so `(c /\ a) \/ (c /\ b) = 0`.

# Patat

- Make slides that render in the terminal!
- https://github.com/bollu/patat

# Common Lisp LOOP Macro

#### Loop with index:

```
(loop for x in xs for i from 0 do ...)
```

#### Nested loop appending

```
(loop for x in `(1 2 3 4) append
      (loop for y in `(,x ,x) collect (* y y))
```

# Mitchell-Bénabou language

- [Link](https://ncatlab.org/nlab/show/Mitchell-B%C3%A9nabou+language)

# Hyperdoctrine

- A hyperdoctrine equips a category with some kind of logic `L`.
- It's a functor `P: T^op -> C` for some higher category `C`, whose objects are categories
  whose internal logic corresponds to `L`.
- In the classical case, `L` is propositional logic, and `C` is the 2-category of posets.
  We send `A ∈ T` to the poset of subobjects `Sub_T(A)`.
- We ask that for every morphism `f: A -> B`, the morphism `P(f)` has left and right adjoints.
- These left and right adjoints mimic existential / universal quantifiers.
- If we have maps between cartesian closed categories, then the functor `f*` obeys frobenius
  reciprocity if it preserves exponentials: `f*(a^b) ~iso~ f*(a)^f*(b)`.
- https://ncatlab.org/nlab/show/Mitchell-B%C3%A9nabou+language

# Why is product in Rel not cartesian product?

#### Monoidal category
- Intuitively, category can be equipped with $\otimes, I$ that makes it a monoid.

#### Cartesian Monoidal category
- A category where the monoidal structure is given by the categorical product (universal property...).


#### Fox's theorem: Any Symmetric Monoidal Category with Comonoid is Cartesian.

- Let `C` be symmetric monoidal under $(I, \otimes)$.

- A monoid has signature `e: () -> C` and `.: C x C -> C`.
- A comonoidal structure flips this, and gives us `copy: C -> C x C`, and `delete: C -> ()`.
- Fox's theorem tells us that if the category is symmetric monoidal, and has morphisms $copy: C \to C \otimes C$,
  and $delete: C \to I$ which obey some obvious conditions, then the monoidal product is the categorical product.

#### Rel doesn't have the correct cartesian product
- This is because the naive product on Rel produces a monoidal structure on Rel.
- However, this does not validate the `delete` rule, because we can have a relation that does not relate a set to _anything_
  in the image. Thus, `A -R-> B -!-> 1` need not be the same as `A -!-> 1` if `R` does not relate `A` to ANYTHING.
- Similarly, it does not validate the `copy` rule, because first relating and then copying is not the same
  as relating to two different copies, because `Rel` represents nondeterminisim.

#### Locally Caretesian Categories

- A category is locally cartesian if each of the slice categories are cartesian.
- That is, all $n$-ary categorical products (including $0$-ary) exist in the slice category of each object.
- MLTT corresponds to [locally cartesian categories](https://www.math.mcgill.ca/rags/LCCC/LCCC.pdf)

# `simp` in Lean4

- `Lean/Elab/Tactic/Simp.lean`:

```
"simp " (config)? (discharger)? ("only ")? ("[" simpLemma,* "]")? (location)?
@[builtinTactic Lean.Parser.Tactic.simp] def evalSimp : Tactic := fun stx => do
  let { ctx, fvarIdToLemmaId, dischargeWrapper } ← withMainContext <| mkSimpContext stx (eraseLocal := false)
  -- trace[Meta.debug] "Lemmas {← toMessageData ctx.simpLemmas.post}"
  let loc := expandOptLocation stx[5]
  match loc with
  | Location.targets hUserNames simplifyTarget =>
    withMainContext do
      let fvarIds ← hUserNames.mapM fun hUserName => return (← getLocalDeclFromUserName hUserName).fvarId
      go ctx dischargeWrapper fvarIds simplifyTarget fvarIdToLemmaId
  | Location.wildcard =>
    withMainContext do
      go ctx dischargeWrapper (← getNondepPropHyps (← getMainGoal)) (simplifyTarget := true) fvarIdToLemmaId
where
  go (ctx : Simp.Context) (dischargeWrapper : Simp.DischargeWrapper) (fvarIdsToSimp : Array FVarId) (simplifyTarget : Bool) (fvarIdToLemmaId : FVarIdToLemmaId) : TacticM Unit := do
    let mvarId ← getMainGoal
    let result? ← dischargeWrapper.with fun discharge? => return (← simpGoal mvarId ctx (simplifyTarget := simplifyTarget) (discharge? := discharge?) (fvarIdsToSimp := fvarIdsToSimp) (fvarIdToLemmaId := fvarIdToLemmaId)).map (·.2)
    match result? with
    | none => replaceMainGoal []
    | some mvarId => replaceMainGoal [mvarId]
```


# Big list of Lean4 TODOS

- Hoogle for Lean4.
- show source in `doc-gen4`.
- mutual `structure` definitions.
- Make Lean4 goals go to line number when pressing `<Enter>`
- Convert lean book into `Jupyter` notebook?

# `unsafePerformIO` in Lean4:


- First do the obvious thing, actually do the IO:

```
unsafe def unsafePerformIO [Inhabited a] (io: IO a): a :=
  match unsafeIO io with
  | Except.ok a    =>  a
  | Except.error e => panic! "expected io computation to never fail"
```

- Then wrap a "safe" operation by the unsafe call.

```
@[implementedBy unsafePerformIO]
def performIO [Inhabited a] (io: IO a): a := Inhabited.default
```

# Big List of Lean4 FAQ

- `FVar`: free variables
- `BVar`: bound variables
- `MVar`: metavariables [variables for unification].
- `Lean.Elab.Tactic.*`: tactic front-end code that glues to `Lean.Meta.Tactic.*`.



# Sheaves in geometry and logic 1.2: Pullbacks
- Pullbacks are fiber bundles.
- Pullbacks for presheaves are constructed pointwise.
- The pullback of $f$ along itself in set is going to be the set of $(x, y)$ such that $f(x) = f(y)$.
- The pullback of $f: X \to Y$ along itself in an arbitrary category is an object $P$ together parallel pair of arrows `P -k,k'-> X` called the kernel pair.
- $f$ is monic iff both arrows in the kernel pair are identity `X -> X`.
- Thus, any functor preserving pullbacks preserves monics, (because it preserves pullback squares, it sends the kernel pair with
  both arrows identity to another kernel pair with both arrows identity. This means that the image of the arrow is
  again a monic).
- The pullback of a monic along any arrow is monic.
- The pullback of an epi along any arrow is epi in set, but not necessarily always!

# Sheaves in geometry and logic 1.3: Characteristic functions of subobjects


```
    !
 S --> 1
 v     |
 |     | true
 v     v
 X---->2
  phi(S)
```

- `true: 1 -> 2` is the unique monic such that `true(1) = 1` (where `2 = {0, 1}`)
- For all monic `m: S -> X` , there must be a unique `phi(S): X -> 2` such that the diagram is a pullback.
- Then `1 -true-> 2` is called as the subobject classifier. See that `1` is also determined (it is terminal object).
  So the only "choice" is in what `2` is and what the morphism `1 -true-> 2` is.
- The definition says that every monic is the pullback of some universal monic `true`.

### Subobject category

- Define an equivalence relation between two monics `m, m': S, S' -> X` where `m ~ m'`
  iff there is an iso `i: S -> S''` such that the triangle commutes:

```
  S --i--> S'
   \      /
   m\    /m'
     v  v
      X
```

- $Sub_C(X)$ is the set of all subobjects of $X$.
- to make the idea more concrete, let `C = Set` and let `X = {1, 2}`. This has subobjects
  `[{}], [{1}], [{2}], [{1, 2}]`.
- To be clear, these are given by the map `m0: {} -> {1, 2}` (trivial), `m1: {*} -> {1, 2}` where `m1(*) = 1`,
  `m2: {*} -> {1, 2}` where `m2(*) = 2`, and finally `m3: {1, 2} -> {1, 2}` given by `id`.
- The category $C$ is well powered when $Sub_C(X)$ is a small set for all $X$. That is, the class of
  subobjects for all $X$ is set-sized.
- Now given any arrow $f: Y \to X$, then pulllback of a monic $m: S -> X$ along $f$ is another monic $m': S' \to Y$.
  (recall that pullback of monic along any arrow is monic).
- This means that we can contemplate a functor $Sub_C: C^{op} \to \texttt{Set}$ which sends an object $C$
  to its set of subobjects, and a morphism $f: Y \to X$ to the pullback of the subobjects of $X$ along $f$.
- If this functor is representable, that is,




#### $G$ bundles

- If $E \to X$ is a bundle, it is a $G$-bundle if $E$ has a $G$ action such that $\pi(e) = \pi(e')$ iff there
  is a unique $g$ such that $ge = e'$. That is, the base space is the quotient of $E$ under the group,
  and the group is "just enough" to quotient --- we don't have redundancy, so we get a unique $g$.
- Now define the space $GBund(X)$ to be the set of all $G$ bundles over $X$.
- See that if we have a morphism $f: Y \to X$, we can pull back a $G$ bundle $E \to X$ to get a new bundle $E' \to Y$.
- Thus we can contemplate the functor `GBund: Space^op -> Set` which sends a space to the set of bundles over it.
- A bundle `V -> B` is said to be a classifying bundle if any bundle `E -> X` can be obtained as a pullback of the
  universal bundle `V -> B` along a unique morphism `X -> B`.
- in the case of the orthogonal group `Ok`, let `V` be the steifel manifold. Consider the quotient `V/Ok`, which
  is the grassmanian. So the bundle `V -> Gr` is a `G` bundle. Now, some alg. topology tells us that is in fact the universal
  bundle for `Ok`.
- The key idea is that this universal bundle `V -> B` represents the functor that sends a space to its set of bundles,
  This is because any bundle `E -> X` is uniquely determined by a pullback `X -> B`! So the base space `B` determines
  every bundle. We can recover the bundle `V -> B` by seeing what we get along the identity `B -> B`.


#### Sieves / Subobject classifiers of presheaves

- Let `P: C^op -> Set` be a functor.
- `Q: C^op -> Set` is a subfunctor of `P` iff `Q(c) ⊂ P(c)` for all `c ∈ C`
  and that `Qf` is a restriction of `Pf`.
- The inclusion `Q -> P` is a monic arrow in `[C^op, Set]`. So each subfunctor is a subobject.
- Conversely, all subobjects are given by subfunctors. If `θ: R -> P` is a monic natural transformation
  (ie, monic arrow) in the functor category `[C^op, Set]`, then each `θC: RC -> PC` is an injection (remember that `RC, PC`
  live in `Set`, so it's alright to call it an injection)
- For each `C`, let `QC` be the image of `θC`. So `(QC = θC(RC)) ⊂ PC`.
- This `Q` is manifestly a subfunctor.
- For an arbitrary presheaf `C^ = [C^op, Set]`, suppose there is a subobject classifier `O`.
- Then this `O` must at the very least classify yonedas (ie, must classify `yC = Hom(-, C): [C^op, Set]`.
- Recall that `Sub_C(X)` was the functor that sent `X ∈ C` to the set of subobjects of `X`, and that
  the category `C` had a subobject classifier `O` iff `Sub_C(X)` is represented by the subobject classifier `O`.
  Thus we must have that `Sub_C(X) ~= Hom(X, O)`.
- Let `y(C) = Hom(-, C)`. Thus we have the isos `Sub_C^(yC) = Hom_C^(yC, O) =[yoneda] O(C)`.
- This means that the subobject classifier `O: C^op -> Set`, if it exists, must be defined
  on objects as `O(C) = Sub_C^(yC)`. This means we need to build the set of all subfunctors of `Hom(-, C)`.

###### Sieves

- for an object `c`, a sieve on `c` is a set `S` of arrows with codomain `c` such that `f ∈ S` and
  for all arrows `fh` which can be defined, we have `fh ∈ S`.
- If we think of paths `f` as things allowed to get through `c`, this means that some path to some
  other `b` (via a `h`) followed by an allowed path to `c` (via `f` is allowed).
  So if `b -f-> c` is allowed, so is `a -h-> b -f-> c`.
- If `C` is a monoid, then a sieve is just a right ideal
- For a partial order, a sieve on `c` is a set of elements that is downward closed/smaller closed.
  If `b <f= c` is in the sieve, then so too is any element `a` such that `a <h= b <f= c`.
- So a sieve is a smaller closed subset: if a small object passes the sieve, then so does anything smaller!
- Let `Q ⊂ Hom(-, c) = yc` be a subfunctor. Then define the set `S_Q = { f | f: a -> c and f ∈ Q(a) }`.
- Another way of writing it maybe to say that we take `S_q = { f ∈ Hom(a, c) | f ∈ Q(a) }`.
- This is a sieve because `fh` is pulling back `f: a -> c` along `h: z -> a`, and the action on the hom functor will pull back
  the set `Hom(a, c)` to `Hom(z, c)`, which will maintain sieveiness, as if `f ∈ Hom(a, c)` then `fh ∈ Hom(z, c)`.
- This means that a sieve on `c` is the same as a subfunctor on `yc = Hom(c, -)`.
- this makes us propose a subobject classifier on `[C^op, Set]` to be defined as `O(c) = set of sieves of Hom(c, -)`.


# Common Lisp Debugging: Clouseau

- Install the `clouseau` package to get GUI visualizations of common lisp code.
- Use `(ql:quickload 'clouseau)` to use the package, and then use
  `(clouseau:inspect (make-condition 'uiop:subprocess-error :code 42))` to inspect a variable.

# Drawabox: Lines

#### Superimposed liens

- Step 1: Draw a line with a ruler
- Step 2: keep the pen at the beginning of the line
- Step 3: Follow the line confidently, try to end at the endpoint of the line.

#### Ghosting lines

- Step 1: Draw two endpoints
- Step 2: Mimic drawing a line [ghosting].
- Step 3: confidently draw a line. LIFT THE PEN UP to stop the pen, don't slow down!


# Common Lisp Beauty: paths

```lisp
; Evaluation aborted on #<UNDEFINED-FUNCTION PATHNAME-TU[E {10034448F3}>
CL-USER> (pathname-type "/home/siddu_druid/**/*.mlir")
"mlir"
CL-USER> (pathname-type "/home/siddu_druid/**/foo")
NIL
CL-USER> (pathname "/home/siddu_druid/**/foo")
#P"/home/siddu_druid/**/foo"
CL-USER> (pathname-directory "/home/siddu_druid/**/foo")
(:ABSOLUTE "home" "siddu_druid" :WILD-INFERIORS)
CL-USER> (pathname-directory "/home/siddu_druid/**/foo/**/bar")
(:ABSOLUTE "home" "siddu_druid" :WILD-INFERIORS "foo" :WILD-INFERIORS)
CL-USER> (pathname-tu[ey "/home/siddu_druid/**/foo/**/bar")
; in: PATHNAME-TU[EY "/home/siddu_druid/**/foo/**/bar"
;     (PATHNAME-TU[EY "/home/siddu_druid/**/foo/**/bar")
;
; caught STYLE-WARNING:
;   undefined function: COMMON-LISP-USER::PATHNAME-TU[EY
;
; compilation unit finished
;   Undefined function:
;     PATHNAME-TU[EY
;   caught 1 STYLE-WARNING condition
; Debugger entered on #<UNDEFINED-FUNCTION PATHNAME-TU[EY {10038F92C3}>
[1] CL-USER>
; Evaluation aborted on #<UNDEFINED-FUNCTION PATHNAME-TU[EY {10038F92C3}>
CL-USER> (pathname-type "/home/siddu_druid/**/foo/**/bar")
NIL
CL-USER> (pathname-type "/home/siddu_druid/**/foo/**/bar.ty")
"ty"
CL-USER> (pathname-name "/home/siddu_druid/**/foo/**/bar.ty")
"bar"
CL-USER> (pathname-name "/home/siddu_druid/**/foo/**/*.ty")
:WILD
CL-USER> (pathname-name "/home/siddu_druid/**/foo/**/*.ty"); Evaluation aborted on #<UNDEFINED-FUNCTION PATHNAME-TU[E {10034448F3}>
CL-USER> (pathname-type "/home/siddu_druid/**/*.mlir")
"mlir"
CL-USER> (pathname-type "/home/siddu_druid/**/foo")
NIL
CL-USER> (pathname "/home/siddu_druid/**/foo")
#P"/home/siddu_druid/**/foo"
CL-USER> (pathname-directory "/home/siddu_druid/**/foo")
(:ABSOLUTE "home" "siddu_druid" :WILD-INFERIORS)
CL-USER> (pathname-directory "/home/siddu_druid/**/foo/**/bar")
(:ABSOLUTE "home" "siddu_druid" :WILD-INFERIORS "foo" :WILD-INFERIORS)
CL-USER> (pathname-tu[ey "/home/siddu_druid/**/foo/**/bar")
; in: PATHNAME-TU[EY "/home/siddu_druid/**/foo/**/bar"
;     (PATHNAME-TU[EY "/home/siddu_druid/**/foo/**/bar")
;
; caught STYLE-WARNING:
;   undefined function: COMMON-LISP-USER::PATHNAME-TU[EY
;
; compilation unit finished
;   Undefined function:
;     PATHNAME-TU[EY
;   caught 1 STYLE-WARNING condition
; Debugger entered on #<UNDEFINED-FUNCTION PATHNAME-TU[EY {10038F92C3}>
[1] CL-USER>
; Evaluation aborted on #<UNDEFINED-FUNCTION PATHNAME-TU[EY {10038F92C3}>
CL-USER> (pathname-type "/home/siddu_druid/**/foo/**/bar")
NIL
CL-USER> (pathname-type "/home/siddu_druid/**/foo/**/bar.ty")
"ty"
CL-USER> (pathname-name "/home/siddu_druid/**/foo/**/bar.ty")
"bar"
CL-USER> (pathname-name "/home/siddu_druid/**/foo/**/*.ty")
:WILD
CL-USER> (pathname-name "/home/siddu_druid/**/foo/**/*.ty")
```

# Logical Predicates (OPLSS '12)

- $R_\tau(e)$ has three conditions:
- (1) $e$ has type $\tau$
- (2) $e$ has the property of interest ($e$ strongly normalizes / has normal form)
- (3) The set $R\tau$ is closed under eliminators!
- My intuition for (3) is that expressions are "freely built" under constructors. On the other hand, it is eliminators
  that perform computation, so we need $R_\tau$ to be closed under "computation" or "elimination"
- [Video](https://www.youtube.com/watch?v=h5kDxde6PTc)



# Logical Relations (Sterling)

- Key idea is to consider relations $R_\tau$ between closed terms of types $\tau_l$ and $\tau_r$. That is, we have
  have a relation $R_\tau \subseteq \{ (t_l, t_r): (\cdot \vdash t_l : \tau_l), (\cdot \vdash t_r : \tau_r)$.
- We write a relation between two closed terms $\tau_L$ and $\tau_R$ as: $R_{\tau} \equiv (\cdot \vdash \tau_L) \times (\cdot \vdash \tau_R)$.
- A morphism of relations $f: R_\sigma to R_\tau$ is given by two functions $f_l: \sigma_l \to \tau_l$ and $f_r: \sigma_r \to \tau_r$
  such that $aR_\sigma b \implies f_l(a) R_\tau f_r(b)$.

#### Logical relations for function spaces

- Given this, we can build up logical relations for more complex cases like function types and quantified types.
  For example, given logical relations $R_\sigma$ and $R_\tau$, we build $R_{\sigma \to \tau}$ to be the relation between
  types $(\cdot \vdash \sigma_l \to \tau_l) \times (\cdot \vdash \sigma_r \to \tau_r)$, and given by the formula:

$$
(f_l: \sigma_l \to \tau_l, f_r: \sigma_r \to \tau_r) : R_{\sigma \to \tau} \equiv \forall (x_l : \sigma_l , x_r : \sigma_r) \in R_\sigma, (f_l(x_l), f_r(x_r)) \in R_\tau
$$

- This satisfies the universal property of functions in the category of logical relations, ie, there is an adjunction
  between $R_{\rho \to \sigma} \to R_{\tau}$ and $R_{\rho} \to R_{\sigma \to \tau}$.
- Next, we can interpret a base type like `bool` by the logical relation that encodes equality on that type.
  so $R_{\texttt{bool}} : (\cdot \vdash \texttt{bool}) \times (\cdot \vdash \texttt{bool})$ and is given by:

#### Logical relations for data types

$$
R_{\texttt{bool}} \equiv \{ (\texttt{true, true}), (\texttt{false, false}) \}
$$

#### Logical relations for parametric types

- for a type of the form $\tau(\alpha)$ that is parametric in $\alpha$, suppose we have a family
  of relations $R_{\tau \alpha} \subseteq  \{ (\cdot \vdash \tau_l(\alpha_l) \times (\cdot \vdash \tau_r(\alpha_r) \}_{R_\alpha}$
  which vary in $R_\alpha$.
- Then we define the logical relation for the type
  $R_{\forall \alpha, \tau(\alpha)} \subseteq (\cdot \vdash \forall \alpha \tau_l(\alpha)) \times (\cdot \vdash \forall \alpha \tau_r(\alpha))$ as:

$$
R_{\forall \alpha, \tau (\alpha)} \equiv
\{ (f_l : \forall \alpha, \tau_l(\alpha), f_r: \forall \alpha, \tau_r(\alpha))
\mid
\forall R_\alpha, (f_l(\alpha_l), f_r(\alpha_r)) \in R_{\tau(\alpha)}
\}
$$

#### Proving things using logical relations

- For $f: \forall \alpha, \alpha \to \texttt{bool}$,  we have that $f @\texttt{unit} (()) = f @ \texttt{bool}(\texttt{true})$
  That is, the function value at `() : unit` determines the value of the function also at `true: bool` (and more generally, everwhere).

- To prove this, we first invoke that **by soundness**, we have that $(f, f) \in R_{\forall \alpha. \alpha \to \texttt{bool}}$. On
  unwrapping this, this means that:

$$
\forall R_\alpha, \forall (x_l, x_r) \in R_\alpha, ((f(x_l), f(x_r)) \in R_{\texttt{bool}})
$$

- Plugging in $R_{\texttt{bool}}$, this gives us an equality:


$$
\forall R_\alpha, \forall (x_l, x_r) \in R_\alpha, (f(x_l) =  f(x_r))
$$

- We now choose $R_\alpha \subseteq (\cdot \vdash \texttt{unit}) \times (\cdot \vdash \texttt{bool})$, with the singleton element $\{ ((), \texttt{true}) \}$.


- [Jon Talk](https://www.youtube.com/watch?v=AEthjg2k718)

##### $(x/p)$ is $x^{(p-1)/2}$

- Since $x$ is coprime to $p$, we have that  $1 \equiv x^{p-1}$
- This can be written as $1^2 - x^{({p-1}/2)^2} = 0$. [$(p-1)$ is even when $p>2$].
- That is, $(1 - x^{(p-1)/2})(1 + x^{(p-1)/2}) = 0$.
- Since we are in an integral domain (really a field), this means that $x^{(p-1)/2} \equiv \pm 1 (\mod p)$.


# Pointless topology: Frames

- A frame is a lattice with arbitrary joins, finite meets, with distributive law: $A \cap \cup_i B_i = \cup_i A \cap B_i$.
- A map of frames is a lattice map between frames.
- A category of locales is the opposite category of frames.


### Thm: Any locale has a smallest dense sublocale
- For example, $\mathbb R$ has $\mathbb Q$.

### Sober spaces
- A space is sober iff every irreducible closed subset is the closure of a single point.
- A sober space is one whose lattice of open subsets determine the topology of the space.
- A space $X$ is sober iff for every topological embedding $f: X \to X'$ that adds more points to $X$,
  if the inverse image map $f: O(X') \to O(X)$ is an isomorphism, then $f$ is a homeomorphism.
  [Source: martin escardo twitter](https://twitter.com/EscardoMartin/status/1573417458178093056?s=20&t=9dbWTcOVpbLhOB1LG8BSDQ)
  This means we can't add more points to $X$ without changing its topology. it has as many points as it could.
- Equivalently: Every complete prime filter of open sets is the open nbhd filter of a unique point.
- $F \subseteq O(X)$ is a completely prime filter iff (1) $F$ is closed under all finite intersections   (including empty),
  (2) if the union of some family $O_i$ is in $F$, then some $O$ is already in $F$ (prime).
- This tries to specify a point by open sets.
- Joke: A sober space is one where what you see is there, and you don't see double.
  What you see is there: every completely prime filter is the nbhd of some point. You don't see double: the pt is unique.

# Introduction to substructural logics: Ch1

#### Terminology


#### Logic as talking about strings

- The book gives a new (to me) interpretation of rules like $X \vdash A$.
  It says that this can be read as "the string $X$ is of type $A$", where type is some
  chomskian/grammarian sense of the word "type".
- This means that we think of $X ; Y$ as "concatenate $X$ and $Y$".
- This allows one to think of $X \vdash A \to B$ as the statement "$X$ when concatenated with a string of type $A$
  produces a string of type $B$".
- This is interesting, because we can have judgements like $X \vdash A$ and $X \vdash B$ with no problem, we're asserting
  that the string $X$ is of type $A$, $B$. Which, sure, I guess we can have words that are both nouns and verbs, for example.
- Under this guise, the statement $X \vdash A \land B$ just says that "$X$ is both a noun and a verb".
- Further, if I say $X \vdash A$ and $Y \vdash B$, then one wants to ask "what is type of $X; Y$ ? we want to say
  "it is the type $A$ next to $B$", which is given by $A \circ B$ (or, $A \otimes B$ in modern notation).
- This is cool, since it gives a nice way to conceptualize the difference between conjunction and tensoring.


#### Tensor versus conjunction as vector spaces

- What I got most out of this was the difference between what they call fusion
  (what we now call tensoring in linear logic) and conjunction.
- Key idea: Let's suppose we're living in some huge vector space, and the statement
  $X \vdash A$ should be read as "the vector $X$ lives in the subspace $A$ of the large vector space.
- Then, the rule $X \vdash A$, $X vdash B$ entails $X \vdash A \land B$ means:
  if $X$ lives in subspace $A$ and $X$ lives in subspace $B$, then $X$ lives in the intersection $A \cap B$.
- On the other hand, the rule $X \vdash A$, $Y \vdash B$ entails $X ; Y \vdash A \circ B$ means:
  if $X$ lives in subspace $A$, $Y$ lives in subspace $B$, then the vector $X \otimes Y$ lives in subspace $A \otimes B$.
- See that in the case of the conjunction, we are talking about **the same** $X$, just choosing to restrict where it lives ($A \cap B$)
- See that in the case of tensor product, we have **two** elements $X$ and $Y$,
  which live in two different subspaces $A$ and $B$.


#### Cut and admissibility

- Cut is the theorem that lets you have lemmas.
- It says that if $X \vdash A$, and $Y(A) \vdash B$ then $Y(X) \vdash B$.
- I don't understand what this means in terms of the interpretation of "left hand side as values, right hand side as types",
  or under "left side is strings, right side is types".
  The rule $Y(A) \vdash B$ is, at best, some kind of unholy dependently typed nonsense under this interpretation.
- A theory is **cut-admissible** if the axioms let you prove cut.
- In general, a theory is admissible to some axiom $A$ if the axioms of the theory allows one to prove $A$.


# Integrating against ultrafilers

- Let $X$ be a set.
- Recall that a filter on $X$ is a collection of subsets $\Omega$ of $X$ that are
  closed under supersets and intersections (union comes for free by closure under supersets).
- Recall that an ultrafilter $\Omega$ on $X$ is a maximal filter. That is, we cannot add any more elements into the filter.
- Equivalently $\Omega$ is an ultrafilter if, for any $A \subseteq X$, either $A \in \Omega$ or $(X - A) \in \Omega$.
- Intuitively, we are considering the set of subsets of $X$ that contains a single $x \in X$.
- We can also say that ultrafilters correspond to lattice homomorphisms $2^X \to 2$.
- A lemma will show that this is equivalent to the following: Whenever $X$ is
  expressed as the disjoint union of three subsets $S_1, S_2, S_3 \subseteq X$, then one of
  then will be in $\Omega$ (there exists some $i$ such that $S_i\in \Omega$).

#### Lemma: Three picking equivalent to ultrafilter

#### Integration by ultrafilter

- Let $B$ a finite set, $X$ a set, $\Omega$ an ultrafilter on $X$.
- Given $f: X \to B$, we wish to define $\int_X f d\Omega$.
- See that the fibers of $f$ partition $X$ into disjoint subsets $f^{-1}(b_1), f^{-1}(b_2), \dots, f^{-1}(b_N)$.
- The ultrafilter $X$ picks out one of these subsets, say $f^{-1}(b_i)$ ($i$ for "integration").
- Then we define the integral to be $b_i$.

#### What does this integral mean?
- We think of $\Omega$ as a probability measure. Subsets in $\Omega$ have measure 1, subsets outside have measure 0.
- Since we want to think of $\Omega$ as some kind of probability measure, we
  want that $\int_X 1 d \Omega = 1$, as would happen when we integrate a probability measure $\int d \mu = 1$.
- Next, if two functions $f, g$ are equal almost everywhere (ie, the set of points where they agree is in $\Omega$),
  then their integral should be the same.



# wegli: Neat tool for semantically grepping C++

- https://github.com/googleprojectzero/weggli


# Mostowski Collapse

- Let $V$ be a set, let $U$ be a universe and let $R$ be a well founded relation on $V$.
- Recall that a relation is well-founded iff every non-empty subset contains a minimal element.
  Thus, we can perform transfinite induction on $V$.
- A function $\pi_R: V \to U$ defined via well founded induction as $\pi_R(x) \equiv \{ \pi(y): y \in V \land yRx \}$
  is called as the mostowski function on $R$. (We suppress $\pi_R$ to $\pi$ henceforth).
- The image $\pi''V \equiv \{ \pi(x) : x \in V \}$ is called as the Mostowski collapse of $R$.
- Consider the well founded relation $R \subseteq N \times N$ such that $xRy$ iff $y = x + 1$


#### Image of collapse is transitive
- Let $U$ be a universe, let $(V, <)$ be a well founded relation on $V$.
- Let $\pi: V \to U$ be the mostowski function on $V$.
- Suppose $a \in b \in \pi[V]$. We must show that $a \in \pi[V]$.
- Since $b \in \pi[V]$, there is a $v_b \in V$ such that $\pi(v_b) = b$.
- By the definition of the Mostowski function, $b = \pi(v_b) = \{ \pi(v) : v \in V \land (v < v_b) \}$
- Since $a \in b$, this implies that there exists a $v_a < v_b$ such that $\pi(v_a) = a$.
- This implies that $a$ is in the image of $\pi[V]$: $a \in \pi[V]$.
- Thus, the set $\pi[V]$ is transitive: for any $b \in \pi[V]$ and $a \in b$, we have shown that $a \in \pi[V]$.

#### Image of collapse is order embedding if $R$ is extensional
- We already know that $\pi[V]$ is transitive from above.
- We assume that $R$ is extentional. That is:  $\forall a, aRx = aRy \iff x = y$. [ie, the fibers $R^{-1}(-)$ are distinct].
- We want to show that $v_1 < v_2 \iff \pi(v_1) \in \pi(v_2)$.

##### Forward: $v_1 < v_2 \implies \pi(v_1) \in \pi(v_2)$:
- $v_1 < v_2$, then $\pi(v_2) = \{ \pi(x): x < v_2 \}$. This implies that $\pi(v_1) \in \pi(v_2)$.

##### Backward: $\pi(v_1) \in \pi(v_2) \implies v_1 < v_2$:
- Let $\pi(v_1) < \pi(v_2)$.
- By the definition of the Mostowski function, we have that $\pi(v_2) = \{ \pi(v'): v' < v_2 \}$
- Thus, there is some $v'$ such that $\pi(v') = \pi(v_1)$.
- We wish to show that $v' = v_1$, or that the collapse function is injective.

##### Collapse is injective:
- We will suppose that the collapse is not injective and derive a contradiction.
- Suppose there are two elements $v_1, v_2$ such that $v_1 \neq v_2$ but $\pi(v_1) = \pi(v_2)$.
- WLOG, suppose $v_1 < v_2$: the relation is well-founded, and thus the set $\{v_1, v_2\}$ ought to have a minimal element, and $v_1 \neq v_2$.
- We must have $\pi(v_1) \subsetneq \pi(v_2)$,





- [Reference: book of proofs](https://www.bookofproofs.org/branches/mostowski-function-and-collapse/)

# Spaces that have same homotopy groups but not the same homotopy type

- Two spaces have the same homotopy type iff there are functions $f: X \to Y$ and $g: Y \to X$
  such that $f \circ g$ and $g \circ f$ are homotopic to the identity.
- Now consider two spaces: (1) the point, (2) the topologists's sine curve with two ends attached (the warsaw circle).
- See that the second space can have no non-trivial fundamental group, as it's impossible to loop around the sine curve.
- So the warsaw circle has all trivial $\pi_j$, just like the point.
- See that the map $W \to \{ \star \}$ must send every point in the warsaw circle to the point $\star$.
- See that the map backward can send $\star$ somewhere, so we are picking a point on $W$.
- The composite smooshes all of $W$ to a single point. For this to be homotopic to the identity is to say that the space is contractible.

# Fundamental group functor does not preserve epis

- Epis in the category of topological spaces are continuous functions that have dense image.
- Take a circle $S^1$ and pinch it in the middle to get $S^1 \lor S^1$. this map is an epi: $f: S^1 \to S^1 \lor S^1$.
- See that this does not induce an epi $\pi(Z) \to \pi_(Z) \star \pi_1(Z)$.
- Maybe even more simply, the map $f: [0, 1] \to S^1$ is an epi
- Thus, fundamental group functor does not preserve epis.

# Epi in topological spaces


- Epis in the category of topological spaces are continuous functions that have dense image.
- Proof: TODO

# Permutation models

- These are used to show create models of `ZF + not(Choice)`.
- Key idea: if we just have ZF without atoms, then a set has no non-trivial `∈` preserving permutations.
- Key idea: if we have atoms, then we can permute the atoms to find non-trivial automorphisms of our model.
- Key idea: in ZF + atoms, the `ordinal`s come from the ZF fragment, where they live in the kernel [ie the universe formed by repeated application
  of powerset to the emptyset]. Thus, the "order theory" of ZF + atoms is controlled by the ZF fragment.
- Crucially, this means that the notion of "well ordered" [ie, in bijection with ordinal] is determined by the ZF fragment.
- Now suppose (for CONTRADICTION) that `A` is well ordered.
  This means that we Now suppose we have an injection `f: ordinal -> A` where `A` is our set of atoms.
- Since `A` possesses non-trivial structure preserving
  automorphisms, so too must `ordinal`, since `ordinal` is a subset of `A`. But this violates the fact that `ordinal` cannot posses
  a non-trivial automorphism.
- Thus, we have contradiction. Ths means that `A` cannot be well-ordered, ie, there cannot be an injection `f: ordinal -> A`.

# Almost universal class

- A universal class is one that contains all subsets as elements.
- A class is almost universal if every subset of $L$ is a a subset of some element of $L$. But note that $L$ does not need to have all subsets as elements.
- $L$ is almost universal if for any subset $A \subset L$ (where $A$ is a set), there is some $B \in L$ such that $A \subseteq B$,
  but $A$ in itself need not be in $L$.

# Godel operations

- A finite collection of operations that is used to create all constructible sets from ordinals.
- Recall $V$, the von neumann universe, which we build by iterating powersets starting from $\emptyset$.
  That is, $f(V) = \mathcal P(V) \cup \mathcal P (\mathcal P(V))$
- We construct $L$ sort of like $V$, but we build it by not taking $P(V)$ fully, but only taking subsets
  that are carved out by using subsets via first order formulas used to filter the previous stage.
- This makes sure that the resulting sets are independent of the peculiarities of the surrounding model, by
  sticking to FOL filtered formulas.




# Orthogonal Factorization Systems

- For a category $C$, a factorization system consists of sets of morphisms $(E, M)$ such that:
- $E, M$ contain all isos.
- $E, M$ are closed under composition.
- every morphism in $C$ can be factored as $M \circ E$
- The factorization is _functorial_:
- [Reference: Riehl on factorization systems](https://math.jhu.edu/~eriehl/factorization.pdf)

# Orthogonal morphisms

Two morphisms `e: a -> b` and `m: x -> y` are orthogonal iff for any `(f, g)` such
that the square commutes:

```
a --e--> b
|        |
f        g
|        |
v        v
x --m--> y
```

then there exists a UNIQUE diagonal `d: b -> x` such that the the triangles
commute: (`f = d . e`) and (`m . d = g`):

```
a --e--> b
|       / |
f      / g
|   /!d  |
v /      v
x --m--> y
```


# Locally Presentable Category

- A category is locally presentable iff it has a set $S$ of objects such that
  every object is a colimit over these objects. This definition is correct upto
  size issues.
- A locally presentable category is a reflective localization $C \to Psh(S)$ of a category
  of presheaves over $S$. Since $Psh(S)$ is the free cocompletion, and localization imposes
  relations, this lets us write a category in terms of generators and relations.

- Formally, $C$ :
- 1. is locally small
- 2. has all small colimits
- 3. `<TECHNICAL SIZE CONDITIONS; TALK TO OHAD>`

#### Localization

- Let $W$


#### Reflective localization

#### Accessible Reflective localization




# Remez Algorithm

- [link](https://en.wikipedia.org/wiki/Remez_algorithm)

# Permission bits reference

- I always forget the precise encoding of permissions, so I mkae a cheat sheet to
  remember what's what. It's `read,write,execute` which have values `2^2, 2^1, 2^0`.

```
+-----+---+--------------------------+
| rwx | 7 | Read, write and execute  |
| rw- | 6 | Read, write              |
| r-x | 5 | Read, and execute        |
| r-- | 4 | Read,                    |
| -wx | 3 | Write and execute        |
| -w- | 2 | Write                    |
| --x | 1 | Execute                  |
| --- | 0 | no permissions           |
+------------------------------------+
```

```
+------------+------+-------+
| Permission | Octal| Field |
+------------+------+-------+
| rwx------  | 0700 | User  |
| ---rwx---  | 0070 | Group |
| ------rwx  | 0007 | Other |
+------------+------+-------+
```

# Papers on Computational Group Theory

- A practical model for computation with matrix groups.
- A data structure for a uniform approach to computations with finite groups.
- A fast implementatoin of the monster group.

# Kan Extensions: Key idea

- The key insight is to notice that when we map from $C \to E$ via $K$, then the $K(x)$ object that we get
  whose comma we form with $K \downarrow Kx$ also has an arrow $Kx \to Kx$ via the identity arrow.
  Thus we can think of $K \downarrow Kx$ as looking like `(<stuff> -> Kx) -> Kx`. So it's really the `Kx`
  in the `<stuff> -> Kx` that controls the situation.



# Interleaved dataflow analysis and rewriting


```
fact: {} -> PROPAGATE
x = 1
fact: {x: 1}
y = 2
fact: {x: 1, y: 2}
~z = x + y~~
{x: 1, y : 2, z: 3} -> REWRITE + PROPAGATE
z = 3

-- :( rewrite, propagate. --

fact: {} -> PROPAGATE
x = 1
fact: {x: 1}
y = 2
fact: {x: 1, y: 2}
~z = x + y~~
{x: 1, y : 2} -> REWRITE
z = 3 <- NEW statement from the REWRITE;
fact: {x: 1, y: 2, z: 3}

x = 2 * 10 ; (x = 20; x is EVEN)
y = 2 * z; (y = UNK; y is EVEN)

-> if (y %2 == 0) { T } else { E }
T -> analysis
```



# Central variable as `focal`

- The NLTK code which [breaks down a word into syllables](https://www.nltk.org/_modules/nltk/tokenize/sonority_sequencing.html)
  inspects trigrams.
- It names the variables of the trigrams `prev`, `focal`, and `next`.
- I find the name `focal` very evocative for what we are currently focused on! It is free of the implications
  of a word like `current`.

# Wilson's theorem

- We get $p \equiv 1$  (mod $4$) implies $((p-1)/2)!$ is a square root of -1.
- It turns that this is because from Wilson's theorem, $(p-1)! = -1$.
- Pick $p = 13$. Then in the calculation of $(p-1)!$, we can pair off $6$ with $-6=7$, $5$ with $-5=8$ and so on.
- So we get $(p-1)/2 \times (p-1)/2 = (p-1)!$.
- This means that $(p-1)/2 = \sqrt{-1}$.
- The condition $(p-1)/2$ is even is the same as saying that $p-1$ is congruent to $0$ mod $4$,
  or that $p$ is congruent to $1$ mod $4$.
- It's really nice to be able to see where this condition comes from!

# General enough special cases

- Also, I feel thanks to thinking about combinatorial objects for a while
  I've gained some kind of "confidence", where I check a special
  case which I am confident generalizes well.

```cpp
void editor_state_backspace_char(EditorState& s) {
    assert(s.loc.line <= s.contents.size());
    if (s.loc.line == s.contents.size()) { return; }
    std::string& curline = s.contents[s.loc.line];
    assert(s.loc.col <= curline.size());
    if (s.loc.col == 0) { return; }
    // think about what happens with [s.loc.col=1]. Rest will work.
    std::string tafter(curline.begin() + s.loc.col, curline.end());
    curline.resize(s.loc.col - 1); // need to remove col[0], so resize to length 0.
    curline += tafter;
    s.loc.col--;
}
```


# XOR and AND relationship

-  `a xor b = a + b - 2 (a & b)`

# Geometry of complex integrals

- integral f(z) dz is work in real part, flux in imaginary part.
- https://www.youtube.com/watch?v=EyBDtUtyshk

# Green's functions
- Can solve $L y(x) = f(x)$.
- $f(x)$ is called as the forcing operator.
- $L$ is a linear diffeential operator. That is, it's a differential operator lik $\partial_x$ or $\partial_t \partial_t$.
  See that $\partial_t \partial_t$ is linear, because
  $\partial_t \partial_t \alpha f + \beta g = \alpha (\partial_t \partial_t f) + \beta (\partial_t \partial_t g)$
- [Video reference](https://www.youtube.com/watch?v=ism2SfZgFJg)

# CP trick: writing exact counting as counting less than

- If we can solve for number of elements `<= k`, say given by `leq(k)` where `k` is an integer,
  then we can also solve for number of elements `= k`, given by `eq(k) := leq(k) - leq(k - 1)`.
- While simple, this is hugely benificial in many situations because `<=k` can be implement as some kind of
  prefix sum data structure plus binary search, which is much less error prone to hack up than exact equality.

# CP trick: Heavy Light Decomposition euler tour tree

- To implement HLD, first define heavy edge to be edge to heaviest vertex.
- To use segment tree over HLD paths, create a "skewed" DFS where each node visits
  heavy node first, and writes vertices into an array by order of discovery time (left paren time).
- When implementing HLD, we can use this segment tree array of the HLD tree as an euler tour of the tree.
- We maintain intervals so it'll be `[left paren time, right paren time]`. We find
  right paren time based on when we exit the DFS. The time we exit the DFS is the rightmost time
  that lives within this subtree.


# Counting with repetitions via pure binomial coefficients

- If we want to place $n$ things where $a$ of them are of kind `a`, $b$ are of kind `b`, $c$
  of them are kind $c$.
  the usual formula is $n!/(a!b!c!)$.
- An alternative way to count this is to think of it as first picking $a$ slots from $n$, and then
  picking $b$ slots from the leftover $(n - a)$ elements, and finally picking $c$ slots from $(n - a - b)$.
  This becomes $\binom{n}{a}\binom{n-a}{b}\binom{n - a - b}{c}$.
- This is equal to $n!/a!(n -a)! \cdot (n-a)!/n!(n - a - b)! \cdot (n - a - b)! / c!0!$,
  which is equal to the usual $n!/a!b!c!$ by cancelling and setting $c = n - a - b$.
- Generalization is immediate.

# Fundamental theorem of homological algebra [TODO]

- Let $M$ be an $R$ module.
- A resolution of $M$ is an exact chain complex `... -> M2 -> M1 -> M0 -> M -> 0`
- A projective resolution of `P*` of `M` is a resolution such that all the `P*` are projective.

#### Fundamental theorem
- 1. Every `R` module has projective resolution.
- 2. Let `P*` be a chain complex of proj. R modules. Let `Q*` be a chain complex with
     vanishing homology in degree greater than zero. Let `[P*, Q*]` be the group of chain homotopoloy classes
     of chain maps from `P*` to `Q*`.  We are told that this set is in bijection with maps
    `[H0(P*), H0(Q*)]`. That is, the map takes `f*` to `H0[f*]` is a bijection.

#### Corollary: two projective resolutions are chain homotopy equivalent
- Let `P1 -> P0 -> M` and `... -> Q1 -> Q0 -> M` be two projective resolutions.
- `H0(P*)` has an epi mono factorization `P0 ->> H0(P*)` and `H0(P*) ~= M`.



#### Proof of existence of projective resolution
- Starting with `M` there always exists a free module `P0` that is epi onto `M`, given by taking the free
  module of all elements of `M`. So we get `P0 -> M -> 0`.
- Next, we take the kernel, which gives us:

```
     ker e
        |
        |   e
        vP0 -> M -> 0
```

- The next `P1` must be projective, and it must project onto `ker e` for homology to vanish. So we
  choose the free module generated by elements of `ker e` to be `P1`!


```
    ker e
    ^   |
    |   v  e
P1---   P0 -> M -> 0
```


- Composing these two maps gives us `P1 -> P0 -> M`. Iterate until your heart desires.


## Chain homotopy classes of chain maps

# Projective modules in terms of universal property

## (1): Universal property / Defn

- $P$ is projective iff for every epimorphism $e: E \to B$, and every morphism $f: P \to B$,
  there exists a lift $\tilde{f}: P \to E$.


```
     e
   E ->> B
   ^   ^
  f~\  | f
     \ |
       P
```


## Thm: every free module is projective
- Let $P$ be a free module. Suppose we have an epimorphism $e: M \to N$ and a morphism $f: P \to N$.
  We must create $\tilde f: M \to N$
- Let $P$ have basis $\{ p_i \}$. A morphism from a free module is determined by the action on the basis.
  Thus, we simply need to define $\tilde f(p_i)$.
- For each $f(p_i): N$, there is a pre-image $m_i \in M$ such that $e(m_i): N = f(p_i): N$.
- Thus, define $\tilde{f}(p_i) = m_i$. This choice is **not canonical** since there could be **many such $m_i$**.
- Regardless, we have succeeded in showing that every free module is projective by lifting $f: P \to N$ to a map
  $\tilde f: M \to N$.


## (1 => 2): Projective as splitting of exact sequences
- $P$ is projective iff every exact sequence $0 \to N \to M \xrightarrow{\pi} P \to 0$ splits.
- That is, we have a section $s: P \to M$ such that $\pi \circ s = id_P$.

- **PROOF (1 => 2):** Suppose $P$ solves the lifting problem. We wish to show that this implies that exact sequence splits.
- Take the exact sequence:


```
            pi
0 -> N -> M -> P -> 0
               ^
               | idP
               P
```
- This lifts into a map $P \to M$ such that the composition is the identity:

```
            pi
0 -> N -> M -> P -> 0
          ^   ^
       idP~\  | idP
            \ |
             P
```

- This gives us the section `s = idP~` such that `pi . s = idP` from the commutativity of the above diagram.



## (2 => 3): Projective as direct summand of free module
- $P$ is projective iff it is the direct summand of a free module. So there is a another module $N$ such that $P \oplus N \equiv R^n$.
- We can always pick a surjective epi $\pi: F \to P$, where $F$ is the free module over all elements of $P$.
- We get our ses $0 \to ker(\pi) \to F \to P \to 0$. We know this splits because as shown above, projective splits
  exact sequences where $P$ is the surjective image.
- Since the sequence splits, the middle term $F$ is a direct sum of the other two terms. Thus $F \simeq \ker \pi \oplus P$.

#### Splitting lemma

- If an exact sequence splits, then middle term is direct sum of outer terms.

## (3 => 1): Direct summand of free module implies lifting

- Let's start with the diagram:

```
  e
E ->>B
     ^
    f|
     P
```

- We know that $P$ is the direct summand of a free module, so we can write a `P(+)Q` which is free:

```
  e
E ->>B
     ^
    f|
     P <<-- P(+)Q
         pi
```

- We create a new arrow `f~ = f . pi` which has type `f~: P(+)Q -> B`. Since this is a map from a free module into `B`,
  it can be lited to `E`. The diagram with `f~` looks as follows:

```
  e
E ->>B <--
     ^    \f~
    f|     \
     P <<-- P(+)Q
         pi
```

- After lifting `f~` to `E` as `g~`, we have a map `g~: P(+)Q -> E`.

```
--------g~--------
|                |
v e              |
E ->>B <--       g~
     ^    \f~    |
    f|     \     |
     P <<-- P(+)Q
         pi
```


- From this, I create the map `g: P -> E` given by `g(p) = g~((p, 0))`. Thus, we win!

## Non example of projective module

- `Z/pZ` is not projective.
- We have the exact sequence `0 -> Z -(xp)-> Z -> Z/kZ -> 0` of multiplication by `p`.
- This sequence does not split, because `Z` (middle) is not a direct summand of `Z` (left) and `Z/kZ` (right),
  because direct summands are submodules of the larger module. But `Z/pZ` cannot be a submodule of `Z` because `Z/pZ`
  is torsion while `Z` is torsion free.

## Example of module that is projective but not free

- Let $R \equiv F_2 \times F_2$ be a ring.
- The module $P \equiv F_2 \times \{0\}$ is projective but not free.
- It's projective because it along with the other module $Q \equiv \{0\} \times F_2$ is isomorphic to $R$.
  ($P \oplus Q = R$).
- It's not free because any $R^n$ will have $4^n$ elements, while $P$ has only two element.
- Geometrically, we have two points, one for each $F_2$.
  The module $P$ is a vector bundle that only takes values over one of the points.
  Since the bundle different dimensions over the two points (1 versus 0), it is projective but not free.
- It is projective since it's like a vector bundle. It's not free because it doesn't have constant dimension.

#### References
- [video](https://www.youtube.com/watch?v=odva24Ro-44&list=PL2Rb_pWJf9JqgIR6RR3VFF2FwKCyaUUZn&index=37)


# How ideals recover factorization [TODO]

- consider $Z[-5]$. Here, we have the equation that $2 \times 3 = (1 + \sqrt{-5})(1 - \sqrt{-5})$.
- Why are $2, 3, (1 + \sqrt 5), (1 - \sqrt 5)$ prime?
- we can enumerate numbers upto a given absolute value.
  Since the absolute value is a norm and is multiplicative, we only need to check for prime factorization
  of a given number $n$ in terms
  of primes $p$ with smaller absolute value (ie, $|p| < |n|$).
- If we list numbers in $Z[-\sqrt{5}]$ upto norm square $6$ (because $6$ is the norm square of $1 - \sqrt{5}$), we get:


This was generated from the python code:

```py
class algnum:
    def __init__(self, a, b):
        self.a = a
        self.b = b
    def __add__(self, other):
        return algnum(self.a + other.a, self.b + other.b)
    def __mul__(self, other):
        # (a + b \sqrt(-5)) (a' + b' \sqrt(-5))
        # aa' + ab' sqrt(-5) + ba' sqrt(-5) + bb' (- 5)
        # aa' - 5 bb' + sqrt(-5)(+ab' +ba')
        return (self.a * other.b - 5 * self.b * other.b,
                self.a * other.b + self.b * other.a)
    def __str__(self):
        if self.b == 0:
            return str(self.a)
        if self.a == 0:
            return f"{self.b}sqrt(-5)"
        return f"[{self.a}, {self.b} sqrt(-5)]"

    def normsq(self):
        # (a + b \sqrt(-5))(a - b \sqrt(-5))
        # = a^2 - (-5) b^2
        # = a^2 + 5 b^2
        return self.a * self.a + 5 * self.b * self.b
    def is_zero(self):
        return self.a == 0 and self.b == 0
    def is_one(self):
        return self.a == 1 and self.b == 0

    def is_minus_one(self):
        return self.a == -1 and self.b == 0



    __repr__ = __str__

nums = [algnum(a, b) for a in range(-10, 10) for b in range(-10, 10)]

def divisor_candidates(p):
    return [n for n in nums if n.normsq() < p.normsq() \
                  and not n.is_zero() \
                  and not n.is_one() \
                  and not n.is_minus_one()]

# recursive.
print("normsq of 2: ", algnum(2, 0).normsq());
print("normsq of 3: ", algnum(3, 0).normsq());
print("normsq of 1 + sqrt(-5):" , algnum(1, 1).normsq());
print("potential divisors of 2: ", divisor_candidates(algnum(2, 0)))
# candidates must be real. Only real candidate is 2.
print("potential divisors of 3: ", divisor_candidates(algnum(3, 0)))
# Candidate must be mixed.
print("potential divisors of (1 + sqrt(-5)): ", divisor_candidates(algnum(1, 1)))
print("potential divisors of (1 - sqrt(-5)): ", divisor_candidates(algnum(1, -1)))
```

#### Recovering unique factorization of ideals
- In the above ring, define $p_1 \equiv (2, 1 + \sqrt(-5))$.
- Define $p_2 \equiv (2, 1 - \sqrt(-5))$.
- Define $p_3 \equiv (3, 1 + \sqrt(-5))$.
- Define $p_4 \equiv (3, 1 - \sqrt(-5))$.
- We claim that $p_1 p_2 = (2)$, $p_3 p_4 = (3)$, $p_1 p_3 = (1 + \sqrt(-5))$, $p_2 p_4 = (1 - \sqrt{-5})$.
- This shows that the ideals that we had above are the products of "prime ideals".
- We recover prime factorization at the _ideal level_, which we had lost at the _number level_.

- [Video lectures: Intro to algebraic number thory via fermat's last theorem](https://www.youtube.com/watch?v=1f0-pc9zYPQ&list=PLSibAQEfLnTwq2-zCB-t9v2WvnnVKd0wn)

# Centroid of a tree

- Do not confuse with **Center of a tree**, which is a node $v$ that minimizes the distance to all other nodes:
  $max_{w \in V} d(v, w)$. This can be found by taking the node that is the middle of a diameter.
- The centroid of a tree is a node such that no child has over `floor(n/2)` of the vertices
  in the tree.

## Algorithm to find centroid of a tree

- Root tree arbitrarily at $r$
- Compute subtree sizes with respect to this root $r$.
- Start from root. If all children of root $r$ have size **less than or equal to** `floor(n/2)`, we are done. Root is centroid.
- If not, some child $c$ [for child, contradiction] has size **strictly greater than** `floor(n/2)`.
- The total tree has $n$ vertices. $c$ as a subtree has **greater than**
  `floor(n/2)`
  vertices. Thus the rest of the tree
  (ie, the part under $r$ that excludes $c$) has **strictly less than** `floor(n/2)` vertices.
- Let us in our imagination reroot the tree at this child $c$. The childen of $c$ continue to have the
  same subtree size. The old node $r$, as a subtree of the new root $c$, has size strictly ness than `floor(n/2)` vertices.
- Now we recurse, and proceed to analyze `c`.
- This analysis shows us that once we descend from `r -> c`, we **do not** need to analyze the edge `c -> r` if we make `c` the
  new candidate centroid.

```cpp
int sz[N]; // subtree sizes
vector<int> es[N]; // adjacency list
int go_sizes(int v, int p) {
  sz[v] = 1;
  for (int w : es[v]) {
    if (w == p) { continue; }
    go_sizes(w, v);
    sz[node] += sz[i];
  }
}

int centroid(int v, int p) {
  for (int w : es[v]) {
    if (w != p && sz[w] > N/2)
      return centroid(w, v);
  }
  return v;
}

int main() {
  ...
  go_sizes(1, 1);
  centroid(1, 1);
};
```

- Note that one **does not need** to write the code as follows:

```cpp
int centroid(int v, int p) {
  for (int w : es[v]) {
    int wsz = 0;
    if (w == p) {
      // size of parent = total - our size
      wsz = n - sz[v];
    } else {
      wsz = sz[w];
    }
    assert(wsz);
    if (wsz > N/2) {
      return centroid(w, v);
    }
  }
  return v;
}
```

- This is because we have already established that if `p` descends into `v`, then the subtree `p` [rooted at `v`] must have less than `n/2`
  elements, since the subtree `v` [rooted at `p`] has more than `n/2` elements.

## Alternate definition of centroid
- Let the centroid of a tree $T$ be a vertex $v$, such that when $v$ is removed and the graph splits into components
  $T_v[1], T_v[2], \dots, T_v[n]$, then the value $\tau(v) = \max(|T_v[1]|, |T_v[2]|, \dots, |T_v[n]|)$ is minimized.
- That is, it is the vertex that on removal induces subtrees, such that the size of the largest component is smallest
  amongst all nodes.


#### Existence of centroid

#### Equivalence to size definition


## Centroid decomposition

- If we find the centroids of the subtrees that hang from the centroid, then we decompose the graph
  into a **centroid decomposition**.

# Path query to subtree query

- Model question: [CSES counting paths](https://cses.fi/problemset/task/1136)
- We have a static tree, and we wish to perform updates on paths, and a final query.
- We can uniquely represent a path in a tree with an initial and final node. There are $O(n^2)$ paths
  in a tree, so we need to be "smart" when we try to perform path updates.




# Pavel: bridges, articulation points for UNDIRECTED graphs

- Two vertices are 2-edge connected if there are 2 paths between them. The two paths cannot share ANU edges.
- Every bridge must occur as a DFS tree edge, because DFS connects all components together.
- More generally, every spanning tree contains all bridge edges.
- Now we check if each edge is a bridge or not.
- To check, we see what happens when we remove the edge $(u, v)$. If the edge is not a bridge, then the subtree
   of $v$ must connect to the rest of the graph.
- Because we run DFS, the subtree rooted at $v$ **must go upwards**, it cannot go cross. On an undirected graph, DFS
  only gives us tree edges and back edges.
- This means that if the subtree rooted at $v$ is connected to the rest of the graph, it must have a backedge that is "above" $u$,
  and points to an ancestor of $u$.
- Instead of creating a set of back edges for each vertex $v$, we take the *highest* /*topmost* back edge, since it's a safe
  approximation to throw away the other back-edges if all we care about is to check whether there is a backedge that goes higher than $u$.
- To find the components, push every node into a list. When we find an edge that is a bridge, take the sublist from the vertex $v$ to the end of the list.
  This is going to be one connected component. We discover islands in "reverse order", where we find the farthest island from the root first and so on.

#### Vertex connectivity

- The problem is that vertex connectivity is not an equivalence relation on vertices!
- So we define it as an equivalence relation on *edges*.
- More subtle, we cannot "directly" condense. We need to build a bipartite graph, with components on one side
  and articultion points on the other side.



# Monadic functor

- A fuctor $U: D \to C$ is monadic iff it has a left adjoint $F: C \to D$ and
  the adjunction is monadic.
- An adjunction $C : F \vdash U: D$ is monadic if the induced "comparison functor" from $D$ to the
  category of algebras (eilenberg-moore category) $C^T$ is an **equivalence of categories**.
- That is, the functor $\phi: D \to C^T$ is an equivalence of categories.
- Some notes: We have $D \to C^T$ and not the other way around since the full order is
  $C_T \to D \to C^T$: Kleisli, to $D$, to Eilenberg moore. We go from "more semantics" to
  "less semantics" --- such induced functors cannot "add structure" (by increasing the amount of semantics),
  but they can "embed" more semantics into less semantics. Thus, there is a comparison functor from $D$
  to $C^T$.
- Eilenberg-moore is written $C^T$ since the category consists of $T$-algebras, where $T$ is the induced
  monad $T: C \to D \to C$. It's $C^T$ because a $T$ algebra consists of arrows $\{ Tc \to c : c \in C \}$
  with some laws. If one wished to be cute, the could think of this as "$T \to C$".
- The monad $T$ is $C \to C$ and not $D \to D$ because, well, let's pick a concrete example: `Mon`.
  The monad on the set side takes a set $S$ to the set of words on $S$, written $S^\star$. The
  other alleged "monad" takes a monoid $M$ to the free monoid on the element of $M$. We've lost structure.


# Injective module

- An injective module is a generalization of the properties of $\mathbb Q$ as an abelian group ($\mathbb Z$ module.)
- In particular, given any injective group homomorphism $f: X \to Y$ and a morphism $q_X: X \to \mathbb Q$,
  then we induce a group homomorphism $q_Y: Y \to \mathbb Q$, where $X, Y$ are abelian groups.
- We can think of this injection $f: X \to Y$ as identifying a _submodule_ (subgroup)$X$ of $Y$.
- Suppose we wish to define the value of $q_Y$ at some $y \in Y$. If $y$ is in the subgroup $X$
  then define $q_y(y) \equiv q_x(y)$.
- For anything outside the subgroup $X$, we define the value of $q_y$ to be $0$.
- **Non-example of injective module:** See that this does not work if we replace $\mathbb Q$ with $\mathbb Z$.
- Consider the injective map $Z \to Z$ given by $i(x) \equiv 3x$
  Consider the quotient map $f: Z \to Z/3Z$. We cannot factor the map $f$ through $i$ as $f = ci$ [$c$ for contradiction].
  since any map  $c: Z \to Z/3Z$ is determined by where $c$ sends the identity. But in this case,
  the value of $c(i(x)) = c(3x) = 3xc(1)) = 0$. Thus, $\mathbb Z$ is not an injective abelian group,
  since we were unable to factor the homomorphism $Z \to Z/3Z$ along the injective $3 \times: Z \to Z$.
- **Where does non-example break on Q?** Let's have the same situation, where we have an injection $i: Z \to Q$
  given by $i(z) = 3z$. We also have the quotient map $f: Z \to Z/3Z$. We want to factor $f = qi$ where
  $q: Q \to Z/3Z$. This is given by $q(x) = $

# Proof that $Spec(R)$ is a sheaf [TODO]

- Give topology for $Spec(R)$ by defining the base as $D(f)$ --- sets where $f \in R$ does not vanish.
- Note that the base is closed under intersection: $D(f) \cap D(g) = D(fg)$.
- To check sheaf conditions, suffices to check on the base.
- To the set $D(f)$, we associate the locally ringed space $f^{-1}(R)$. That is, we localize $R$
  at the multiplicative monoid $S \equiv \{ f^k \}$.
- We need to show that if $D(f) = \cup D(f_i)$, and given solutions within each $D(f_i)$, we need to create
  a unique solution in $D(f)$.

#### Reduction 1: Replace $R$ by $R[f^{-1}]$
- We localize at $f$. This allows us to assume that $D(f) = Spec(R)$ [ideal blows up as it contains unit],
  and that $f = 1$ [localization makes $f$ into a unit, can rescale?]
- So we now have that $\{ D(f_i) \}$ cover the spectrum $Spec(R)$. This means that for each point $\mathfrak p$,
  there is some $f_i$ such that $f_i \not \equiv_\mathfrak p 0$. This means that $f_i \not \in \mathfrak p$.
- Look at ideal $I \equiv (f_1, f_2, \dots, f_n)$. For every prime (maximal) ideal $mathfrak p$ , there is some $f_i$
  such that $f_i \not in \mathfrak p$. This means that the ideal $I$ is not contained in any maximal ideal, or that $I = R$.
- This immediately means that $1 \in R: = \sum_i f_i a_i \in I$ for arbitrary $a_i \in R$.
- Recall that in a ring, the sums are all finite, so we can write $1$ as a sum of FINITE number of $f_i$, since only a finite
  number of terms in the above expression will be nonzero. [$Spec(R)$ is quasi-compact!]
- This is a partition of unity of $Spec(R)$.

#### Separability
- Given $r \in R = O(Spec(R))$, if $r$ is zero in all $D(f_i)$, then $r = 0$ in $R$.
- $R$ being zero in each $D(f_i)$ means that $r = 0$ in $R[f_i^{-1}]$. This means that $f_i^{n_i} r = 0$, because
  something is zero on localization iff it is killed by the multiplicative set that we are localizing at.
- On the other hand, we also know that $a_1 f_1 + \dots + a_n f_n  = 1$ since $D(f_i)$ cover $R$.
- We can replace $f_i$ by $f_i^{n_i}$, since $D(f_i) = D(f_i^{n_i})$. So if the $D(f_i)$ cover $R$, then so too do $D(f_i^{n_i})$.


#### Check sheaf conditions
- Suppose $r_i/f_i^{n_i} \in R[f_i^{-1}]$ is equal to $r_j/f_j^{n_j}$


#### References
- [Borcherds](https://www.youtube.com/watch?v=AYDq0qY34HU&list=PL8yHsr3EFj50Un2NpfPySgXctRQK7CLG-&index=9)


# Projections onto convex sets

- [Link](https://en.wikipedia.org/wiki/Projections_onto_convex_sets


# BGFS algorithm for unconstrained nonlinear optimization

- [Link](https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm)

# LM algorithm for nonlinear least squares

- [Link](https://en.wikipedia.org/wiki/Levenberg%E2%80%93Marquardt_algorithm)


# Backward dataflow and continuations
- Forward dataflow deals with facts _thus far_.
- Backward dataflow deals with facts about _the future_, or the _rest of the program_.
  Thus, in a real sense, backward dataflow concerns itself with _continuations_!


# Coordinate compression with `set` and `vector`

If we have a `std::set<T>` that represents our set of uncompressed values, we can
quickly compress it with a `std::vector<T>` and `lower_bound` without having to
create an `std::map<T, int>` that holds the index!

```cpp
set<int> ss; // input set to compress
vector<int> index(ss.begin(), ss.end());
int uncompressed = ...; //
int compressed = int(lower_bound(index.begin(), index.end(), key) - index.begin());
assert(xs[compressed] == uncompressed);
```

# Hilbert polynomial and dimension

- Think of non Cohen Macaulay ring (plane with line perpendicular to it). Here the dimension varies per point.
- Let $R$ be a graded ring. Let $R^0$ be noetherian. $R$ is finitely generated as an algebra over $R^0$.
  This implies by hilbert basis theorem that $R$ is noetherian (finitely generated as a module over $R^0$).
- Suppose $M$ is a graded module over $R$, and $M$ is finitely generated as a module over $R$.
- How fast does $M_n$ grow? We need some notion of size.
- Define the size of $M_n$ as $\lambda(M_n)$.Suppose $R$ is a field. Then $M_n$ is a vector space. We define
  $\lambda(M_n)$ to be the dimension of $M_n$ as a vector space over $R$.
- What about taking dimension of tangent space? Doesn't work for cusps! (singular points). Can be used to define
  singular points.
- TODO: show that at $y^2 = x^3$, we have dimension two (we expect dimension one)

# Cost of looping over all multiples of $i$ for $i$ in $1$ to $N$

- Intuitively, when I think of "looping over $i$ and all its multiples", I seem to have a gut
  feeling that its cost is $N$. Of course, it is not. It is $N/i$.
- Thus, the correct total cost becomes $\sum_{i=1}^N N/i$ (versus the false cost of $\sum_{i=1}^N N = N^2$.
- The correct total cost is a harmonic series $N\cdot \sum_{i=1}^N1/i \simeq N \log N$.
- This is useful for number theory problems like [1627D](https://codeforces.com/contest/1627/problem/D)




# Stuff I learnt in 2021

I spent this year focusing on fundamentals, and attempting to prepare
myself for topics I'll need during my PhD. This involved learning things
about dependent typing, compiling functional programs, working with the
[MLIR compiler toolchain](https://mlir.llvm.org/), and reading about
the [GAP system for computational discrete algebra](https://www.gap-system.org/).


## Guitar

I've been meaning to pick up an instrument. I'd learnt the piano as a kid,
but I'd soured on the experience as it felt like I was learning a lot of music
theory and practising to clear the [Royal school of music exams](https://in.abrsm.org/en/).
I'd learnt a little bit of playing the guitar while I was an inten at [Tweag.io](https://tweag.io/); my
AirBnB host had a guitar which he let me borrow to play with. I was eager to pick it back up.

Unfortunately, I wasn't able to play as consistenly as I had hoped I would. I can now play more chords,
but actually switching between them continues to be a challenge. I also find pressing down on barre chords
surprisingly hard. I've been told something about getting lighter strings, but I'm unsure about that.


I was also excited about learning the guitar well enough to play it while a friend sings along.
This seems to require a **lot** more practice than I currently have, as the bottleneck is whether
one can smoothly switch between chords.


## Starting my PhD: Research on Lean4

I'm excited by proof assistants, and I'd like to work on them for my PhD. So the first order
of business was to get an idea of the internals of Lean4, and to decide what exactly I would
be working on. This made me read the papers written by the Lean team over the last couple years
about their runtime, as well as made me learn how to implement dependently typed languages.

During this process, I also had calls with some of the faculty at the University of Edinburgh
to pick a co-advisor. I enjoyed reading
[Liam O connor's thesis: Type Systems for Systems Types](http://unsworks.unsw.edu.au/fapi/datastream/unsworks:61747/SOURCE02?view=true)
The thesis had a very raw, heartfelt epilogue:

> If you will permit some vain pontification on the last page of my thesis,
> I would like to reflect on this undertaking, and on the dramatic effect it
> has had on my thinking. My once-co-supervisor Toby Murray said that
> all graduate students enter into a valley of despair where they no longer believe in
> the value of their work. Certainly I am no counter-example. I do not even know if I
> successfully found my way out of it

This, honestly, made me feel a lot better, since I'd begun to feel this way even *before* launching
into a PhD!

#### Lean implementation details

I read the papers by the Lean researchers on the special features of the language.

- [Counting immutable beans](https://arxiv.org/pdf/1908.05647.pdf) describes an optimization
  that they perform in their IR (lambdarc) that optimizes memory usage by exploiting linear types.
- [Sealing pointer equality](https://arxiv.org/pdf/2003.01685.pdf) describes how to use dependent types
  to hide pointer manipulation in a referentially transparent fashion.

#### Writing a dependently typed language

I felt I had to know how to write a dependently typed language if I wanted to be successful
at working on the Lean theorem prover. So I wrote one, it's at  [`bollu/minitt`](git@github.com:bollu/minitt.git).
The tutorials that helped me the most were:

- [David Christiansen's tutorial on normalization by evaluation](https://davidchristiansen.dk/tutorials/nbe/), where
  he builds a full blown, small dependently typed language type checker.
- [Normalization by evaluation by F. Faviona](https://www.youtube.com/watch?v=atKqqiXslyo) which explains
  why we need this algorithm to implement dependently typed languages, and other cute examples
  of normal forms in mathematics. For example, to check if two lists are equivalent upto permutation,
  we can first sort the two lists, and then check for real equality. So we are reducing a problem
  of "equivalence" to a problem of "reduction to sorted order" followed by "equality". We do something
  similar to type check a dependently typed language.
- [`cubicaltt` lectures by faviona](https://www.youtube.com/watch?v=6cLUwAiQU6Q), which get the point of
  cubical type theory across very well.
- [Bidirectional type checking by Pfenning](https://www.cs.cmu.edu/~fp/courses/15312-f04/handouts/15-bidirectional.pdf)
  These lecture notes explain bidirectional typing
  well, and provide an intuition for which types should be checked and which should be inferred when performing
  bidirectional typing.

#### Paper acceptance

Our research about writing a custom backend for Lean4 was accepted at CGO'22. I was very touched at how
nice the programming languages community is. For example, Leonaro De Moura and Sebastian Ullrich, the maintainers
of Lean4 provided a lot of constructive feedback. I definitely did not expect this to happen. I feel like
I don't understand academia as a community, to be honest, and I'd like to understand how it's organized.




## Statistics

As I was working on the paper, I realised that I didn't truly understand why we were taking the median of the runtimes
to report performance numbers, or why averaging over ten runs was "sufficient" (sufficient for what?).

This led me on a quest to learn statistics correctly. My big takeaways were:

- Frequentist type statistics via null hypotheses are hard to interpret and may not be well suited for performance benchmarking.
- The High Performance Computing community does not use bayesian statistics, so using it would flag one's paper as "weird".
- The best solution is to probably report all raw data, and summarize it via reasonable summary statistics like median, which
  is robust to outliers.

I must admit, I find the entire situation very unsatisfactory. I would love it if researchers in High performance
computing wrote good reference material on how to bencharmk well. Regardless, here are some of the neat
things I wound up reading in this quest:

##### Learning statistics with R

[Learning statistics with R](htps://learningstatisticswithr.com/book/). This is a neat book which explains
statistics and the `R` programming language. I knew basically nothing of statistics and had never used `R`, so working
through the book was a blast. I was able to blaze through the first half of the book, since it's a lot of introductory
programming and introductory math. I had to take a while to digest the ideas of p-values and hypothesis testing. I'm still not
100% confident I really understand what the hell a p value is doing. Regardless, the book was a really nice read, and
it made me realize just how well the R language is designed.


##### Jackknife

The [Jackknife paper "Bootstrap methods: another look at the jackknife"](http://jeti.uni-freiburg.de/studenten_seminar/stud_sem_SS_09/EfronBootstrap.pdf)
which introduces the technique of bootstrapping: drawing many samples from a small dataset to eventually infer summary statistics. I was impressed
by the paper for three reasons. For one, it was quite easy to read as a non-statistician, and I could follow the gist of what was going on
in the proofs. Secondly, I enjoyed how amenable it is to implementation, which makes it widely used in software. Finally, I think it's
a great piece of marketing: labelling it a "Jacknife", and describing how to bootstrap is a rough-and-ready method that will save you
in the jungles of statistical wilderness makes for a great title.



## R language and tidy data

Due to the R lannguage quest, I was exposed to the idea of a data frame in a *coherent* way.
The data frames in R feels *designed* to me, unlike their python counterpart in [`pandas`](https://pandas.pydata.org/).

I realised that I should probably learn languages that are used by domain experts, and not poor approximations
of domain expertise in Python.

##### Tidyverse

This also got me interested to learn about the [tidyverse](https://www.tidyverse.org/), a collection of packages
which define a notion of "tidy data", which is a precise philosophy of how data should be formatted when
working on data science (roughly speaking, it's a dataset analogy of [3rd normal form from database theory](https://en.wikipedia.org/wiki/Third_normal_form).

In particular, I really enjoyed the [tidy data](https://vita.had.co.nz/papers/tidy-data.pdf) paper which
defines tidy data, explains how to tidy untidy data, and advocates for using tidy data as an intermediate
representation for data analysis.



## Starting a reading group: Fuzzing

I felt like I was missing out on hanging with folks from my research lab, so I decided
to start a reading group. We picked [the fuzzing book](https://www.fuzzingbook.org/)
as the book to read, since it seemed an easy and interesting read.

I broadly enjoyed the book. Since it was written in a [literate programming style](https://en.wikipedia.org/wiki/Literate_programming),
this meant that we could read the sources of each chapter and get a clear idea of how the associated topic was to be implemented.
I enjoy reading code, but I felt that the other lab members thought this was too verbose. It did make judging the length of
a particular section hard, since it was unclear how much of the section was pure implementation detail, and how much was conceptual.


##### Ideas learnt

Overall, I learnt some interesting ideas like [delta debugging](https://en.wikipedia.org/wiki/Delta_debugging),
[concolic fuzzing](https://www.fuzzingbook.org/html/ConcolicFuzzer.html), and overall, how to *design*
a fuzzing library (for example, this section on [grammar fuzzing](https://www.fuzzingbook.org/html/GeneratorGrammarFuzzer.html#Synopsis)
provides a convenient class hierarchy one could choose to follow).

I also really enjoyed the book's many (ab)uses of python's
runtime monkey-patching capabilities for fuzzing. This meant that the book could easily explain concepts
that would have been much harder in some other setting, but this also meant that some of the techniques
showcased (eg. [tracking information flow](https://www.fuzzingbook.org/html/InformationFlow.html)
by using the fact that python is dynamically typed) would be much harder to put into practice in a less flexible language.


##### Software bugs are real bugs?

The coolest thing I learnt from the book was [STADS: software testing as species discovery](https://arxiv.org/pdf/1803.02130.pdf),
which models the problem of "how many bugs exist in the program?" as "how many bugs exist in this forest?". It turns
out that ecologists have good models for approximating the **total number of species in a habitat** from the
**number of known species in a habitat**. The paper then proceeds to argue that this analogy is sensible,
and then implements this within [AFL: american fuzzy lop](https://lcamtuf.coredump.cx/afl/). Definitely the
most fun idea in the book by far.


## Persistent data structures for compilers

My friend and fellow PhD student [Mathieu Fehr](https://github.com/math-fehr) is developing
a new compiler framework based on MLIR called [XDSL](https://github.com/xdslproject/xdsl).
This is being developed in Python, as it's meant to be a way to expose the guts of the compilation
pipeline to domain experts who need not be too familiar with how compilers work.


##### Python and immutable data structures

I wished to convince Mathieu to make the data structures immutable by default. Unfortunately, python's
support for immutable style programming is pretty poor, and I never could get libraries like
[pyrsistent](https://github.com/tobgu/pyrsistent) to work well.

##### Immer

On a happier note, this made me search for what the cutting was in embedding immutable
data structures in a mutable language, which led me to [Immer: Persistence for the masses](https://public.sinusoid.es/misc/immer/immer-icfp17.pdf).
It advocates to use [RRB trees](https://dl.acm.org/doi/abs/10.1145/2858949.2784739) and describes how to design an API
that makes it convenient to use within a language like C++. I haven't read the RRB trees paper, but I have been using Immer
and I'm liking it so far.

## `WARD` for quick blackboarding

I hang out with my friends to discuss math, and the one thing I was sorely missing was the lack of a shared
blackboard. I wanted a tool that would let me quickly sketch pictures, with some undo/redo, but most importantly,
be **fast**. I found no such tool on Linux, so I wrote my own: [bollu/ward](https://github.com/bollu/ward). I was great
fun to write a tool to scratch a personal itch. I should do this more often.

## Becoming a Demoscener

I've always wanted to become a part of the [demoscene](), but I felt that I didn't understand the
graphics pipeline or the audio synthesis pipeline well enough. I decided to fix these glaring
gaps in my knowledge.

##### Rasterization

I've been implementing [`bollu/rasterizer`](https://github.com/bollu/rasterizer), which
follows the [`tinyrenderer`](https://github.com/ssloy/tinyrenderer/wiki/Lesson-0:-getting-started) series
of tutorials to implement a from-scratch, by-hand software rasterizer. I already knew
all the math involved, so it was quite rewarding to quickly put together code that applied math I already knew
to make pretty pictures.

##### Audio synthesis


Similarly, on the audio synthesis side, I wrote
[`bollu/soundsynth`](https://github.com/bollu/soundsynth) to learn fundamental synthesis algorithms.
I followed [demofox's series of audio synththesis tutorials](https://blog.demofox.org/) as well as
the very pleasant and gently paced textbook [TODO}(). I particularly enjoyed the ideas
in [karlplus strong string synthesis](https://en.wikipedia.org/wiki/Karplus%E2%80%93Strong_string_synthesis).
I find [FM synthesis](https://github.com/bollu/soundsynth/blob/master/fm-paper.pdf) very counter-intuitive to reason about.
I've been told that audio engineers can perform FM sound synthesis "by ear", and I'd love to have an intuition for
frequency space that's so strong that I can intuit how to FM synthesize a sound. Regardless, the idea is very neat for sure.

##### Plucker coordinates

I also have long wanted to understand
[Plucker coordinates](https://en.wikipedia.org/wiki/Pl%C3%BCcker_coordinates), since I'd read that they are useful
for graphics programming. I eventually plonked down, studied them, and
[wrote down an expository note](https://github.com/bollu/notes/blob/master/diffgeo/grassmanian-plucker.ipynb)
about them in a way that makes sense to me. I now feel I have a better handle on Projective space, Grassmanians, and schemes!


## Category theory

A friend started a category theory reading group, so we've spent the year working
through
[Emily Riehl's "Category theory in Context"](https://math.jhu.edu/~eriehl/context.pdf).
I'd seen categorical ideas before, like colimits to define a germ, "right adjoints preserve limits",
showing that the sheafification functor exists by invoking an adjoint functor theorem, and so on.
But I'd never systematically studied any of this, and if I'm being honest, I hadn't even understood
the statement of the Yoneda lemma properly.

##### Thoughts on the textbook

Working through the book from the ground-up was super useful, since I was forced to solve
exercises and think about limits, adjoints, and so forth. I've
[uploaded my solutions upto Chapter 4](https://github.com/bollu/notes/blob/master/category-theory-in-context/main.pdf).

I felt the textbook gets a little rough around the edges at the chapter on adjunctions. The section
on the 'Calculus of Adjunctions' made so little sense to me that I
[rewrote it](https://github.com/bollu/notes/blob/master/category-theory-in-context/calculus-of-adjunctions.pdf)
with proofs that I could actually grok/believe.

##### Curios


Regardless, it's been a fun read so far. I was also pointed to some other interesting content along
the way, like [Lawvere theories](https://bartoszmilewski.com/2017/08/26/lawvere-theories/)
and the [cohomology associated to a monad](http://www.tac.mta.ca/tac/reprints/articles/2/tr2abs.html).

## Computational mathematics


A Postdoc at our lab, [Andres Goens](https://scholar.google.de/citations?user=vjVhbJoAAAAJ&hl=en)
comes from a pure math background. While we were discussing potential research ideas (since I'm still
trying to formulate my plan for PhD), he
mentioned that we could provide a formal semantics for the
[GAP programming language](https://www.gap-system.org/) in Lean.
This project is definitely up my alley, since it involves computational math (yay), Lean (yay),
and formal verification (yay).

##### Learning GAP

I decided I needed to know some fundamental algorithms of computational group theory, so I skimmed
the book
[Permutation group algorithms by Serees](https://doc.lagout.org/science/0_Computer%20Science/2_Algorithms/Permutation%20Group%20Algorithms%20%5BSeress%202003-03-17%5D.pdf)
which explains the fundamental algorithms behind manipulating finite groups computationally, such
as the [Todd Coxeter coset enumeration algorithm](https://math.berkeley.edu/~kmill/notes/todd_coxeter.html)
and the [Schrier Sims group decomposition algorithm](https://en.wikipedia.org/wiki/Schreier%E2%80%93Sims_algorithm).
I loved the ideas involved, and implemented these at [`bollu/CASette`](https://github.com/bollu/CASette).


I'd also half-read the textbook 'Cox, Little, OShea: Computational Algebraic Geometry' which I picked
up again since I felt like I ought to revisit it after I had seen more algebraic geometry, and also
because I wanted to be better informed about computational mathematics. I felt like this time around,
I felt many of the theorems (such as the [hilbert basis theorem](https://en.wikipedia.org/wiki/Hilbert%27s_basis_theorem))
'in my bones'. Alas, I couldn't proceed more than the second chapter since other life things took priorty.
Perhaps I'll actually finish this book next year `:)`.

##### Cardistry


For something completely different, I got interested in Cardistry and shuffling thanks to Youtube.
I started learning interesting shuffles like the [riffle shuffle](https://mathworld.wolfram.com/RiffleShuffle.html),
and soon got interested in the mathematics involved. I would up reading some of
the book [Group representations for probability and statistics](https://jdc.math.uwo.ca/M9140a-2012-summer/Diaconis.pdf)
by Persi Diaconis, a magician turned mathematician who publishes quite a bit on permutation groups, shuffling, and the like.


###### Symmetric group

I really enjoyed learning the detailed theory of the representation theory of the symmetric group, which I
had read patchily before while studying
[Fourier analysis on the symmetric group](http://people.cs.uchicago.edu/~risi/research/symmetric.html).
A lot of the theory
still feels like magic to me; in particular, [Specht modules](https://en.wikipedia.org/wiki/Specht_module) are so
'magic' that I would find it hard to reconstruct them from memory.

## Competitive peogramming

I need more practice at competitive programming. In fact, I'm [downright atrocious](https://codeforces.com/profile/bollu),
as I'm rated "pupil" on codeforces. If I had to debug, it's a combination of several factors:


- I get discouraged if I can't solve a problem I think I "ought to be able to solve".
- I consider myself good at math and programming, and thus being bad at problem solving makes me feel
  bad about myself.
- I tend to overthink problems, and I enjoy using heavy algorithmic machinery, when in reality, all that's called for
  is a sequence of several observations.
- Codeforces' scoring system needs one to be *fast* at solving problems and implementing them precisely. I don't enjoy
  the time pressure. I'd like a scoring system based on harder problems, but less emphasis on time-to-solve.

To get better, I've been studying more algorithms (because it's fun). I took the
[coursera course on string algorithms](https://www.coursera.org/learn/algorithms-on-strings) and
read the textbook [algorithms on strings](https://www.cambridge.org/core/books/algorithms-on-strings/19049704C876795D95D8882C73257C70).
I loved the ideas of [building a prefix automata in linear time](https://codeforces.com/blog/entry/20861). The algorithm
is vey elegant, and involves a fundamental decomposition of regular grammar
 via the [Myhill Nerode theorem](https://en.wikipedia.org/wiki/Myhill%E2%80%93Nerode_theorem).
You can find [my string algorithm implementations here](https://github.com/bollu/notes/tree/master/strings/impl).


##### Hardness of codeforces problems

Another thing I kept getting tripped up by was the fact that problems that were rated "easy" on codeforces
tended to have _intuitive_ solutions, but with _non-trivial_ watertight proofs. An example of this
was the question [545C](https://codeforces.com/contest/545/problem/C) on codeforces, where the
tutorial gives a [sketch of a exchange argument](https://codeforces.com/blog/entry/17982). Unfortunately,
filling in all the gaps in the exchange argument is [quite complicated](https://gist.github.com/bollu/6b9d7d4b23cc4dd74d6a0fc2b66f452c).
I finally did arrive at a much longer proof. This made me realize that competitive programming sometimes calls for
"leaps" that are in fact quite hard to justify. This kept happening as I solved problems. To recitfy the state of affairs,
I began documenting formal proofs to these problems. Here's a link to [my competitive programming notes](https://github.com/bollu/notes/blob/master/competitive-programming/main.pdf),
which attempts to formally state and prove the correctness of these questions.


## Discrete differential geometry

I love the research of [Keenan Crane](https://www.cs.cmu.edu/~kmcrane/), who works on bridging old school
differential geometry with computational techniques. All of his papers are lucid, full of beautiful figures
and crazy ideas.

##### Replusive curves

Chris Yu, Henrik Schumacherm, and Keenan have a new paper on [Repulsive Curves](http://www.cs.cmu.edu/~kmcrane/Projects/RepulsiveCurves/RepulsiveCurves.pdf)
is really neat. It allows one to create curves that minimize a repulsive force, and can be subject to other arbitrary
constraints. The actual algorithm design leads one to think about all sorts of things like fractional calculus. To be honest,
I find it insane that fractional calculus finds a practical use. Definitely a cool read.

##### SAGE implementation

- I have a [work in progress PR](https://github.com/bollu/SAGE/tree/u/gh-bollu%2Fjan-17-2021-discrete-diffgeo-homology) that
  implements Keenan Crane's [Geodesics in Heat](https://arxiv.org/abs/1204.6216) algorithms
  within SAGE. Unfortunately, the problem was this implementing this requires heavy sparse numerical linear algebra,
  something that sage did not have at the time I attempted this.
- This led to me [opening an issue about sparse Cholesky decomposition](https://trac.sagemath.org/ticket/13674)
  on the SAGE issue tracker.
- Happily, the issue was fixed late this year by SAGE pulling in `cvxopt` as a dependency!
- I can get back to this now in 2022, since there's enough support within SAGE now to actually succeed!


## Writing a text editor (dropped)

I started writing a text editor, because earlier tools that I'd written for myself
such as `ward` for blackboarding, and my custom blog generator all worked really well for me,
as they fit to my idiosyncracies. I tried writing a terminal based editor
at [`bollu/edtr`](https://github.com/bollu/edtr) following the [`kilo` tutorial](https://viewsourcecode.org/snaptoken/kilo/).
Unfortunately, building a text editor is hard work, especially if one wants modern convenienes like
auto-complete.

I've postponed this project as one I shall undertake during the dark night of the soul every PhD student
encounters when writing their thesis. I plan to write a minimal lazily evaluated language, and great
tooling around that language as a means to while away time. But this is for future me!

## DnD

My partner got me into playing dungeons and dragons this year. I had a lot of fun
role-playing, and I plan to keep it up.

#### Nomic

[Nomic](https://en.wikipedia.org/wiki/Nomic)
is a neat game about changing the rules of the game. It takes a particular
type of person to enjoy it, I find, but if you have the type of people who
enjoy C++ template language lawyering, you'll definitely have a blast!

#### Continuum

I found [the continuum RPG](https://en.wikipedia.org/wiki/Continuum_(role-playing_game)),
a game about time travel
very unique, due to the massive amount of lore that surrounds it,
and game mechanics which revolve around creating time paradoxes to deal damage
to those stuck in it. It appears to have a reputation of being a game
that everybody loves but nobody plays.

#### Microscope

Microscope is a [game about storytelling](https://www.lamemage.com/microscope/). I unfortunately
was never able to host it properly because I was busy, and when I wasn't busy, I was unsure
of my abilities as dungeon master `:)` But it definitely is a game I'd be stoked to play.
I'm thnking of running it early 2022 with my group of friends.

## Odds and ends

##### The portal group

I joined the [portal group](https://theportal.group/) on discord, which consist of folks
who follow Eric Weinstein's philosophy, broadly speaking. The discod is a strange mileu. I hung
around because there were folks who knew a *lot* of math and physics. I would up
watching the [geometric anatomy of theoretical physics](https://www.youtube.com/playlist?list=PLPH7f_7ZlzxTi6kS4vCmv4ZKm9u8g5yic)
lectures on YouTube by Fredrick Schuller. The lectures are great expository material, though the hardness
ramps up like a cliff towards the end, because it feels like he stops proving things and beings to simply
state results. Regardless, I learnt a lot from it. I think my favourite takeaway was the
[Serre Swann theorem](https://en.wikipedia.org/wiki/Serre%E2%80%93Swan_theorem) which makes
very precise the idea that "projective modules are like vector bundles".

##### Differential geometry, again

Similarly, I would up realizing that my differential geometry was in fact quite weak, in terms
of computing things in coordinates. So I wound up re-reading
[Do carmo: differential geometry of curves and surfaces](http://www2.ing.unipi.it/griff/files/dC.pdf), and I implemented
the coordinate based computations in Jupyter notebooks. For example,
here is a [Jupyter notebook that calculates covariant derivatives explicitly](https://github.com/bollu/notes/blob/master/diffgeo/geodesics.ipynb).
I found that this forced me to understand what was "really going on". I now know slogans like:

> The Covariant Derivative is the projection of the global derivative onto the tangent space.
> The Christoffel Symbols measure the second dervative(acceleration) along the tangent space.


I got interested in the work of [Elizaboth Polgreen](https://polgreen.github.io/). In particular,
I found the idea of being able to extend an SMT solver with arbitrary black-box functions pretty great.
I read their [technical report on SMT modulo oracles](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2021/EECS-2021-10.pdf)
and [implemented the algorithm](https://github.com/bollu/notes/blob/master/smt-modulo-oracles.ipynb).


## What I want for next year

I wish to learn how to focus on one thing. I'm told that the point of a PhD is to become a world
expert on one topic. I don't have a good answer of what I wish to become a world expert on. I like
the varied interessts I have, so it'll be interesting as to how this pans out. However, I have
decided to place all my bets on the Lean ecosystem, and I plan on spending most of 2022 writing
Lean code almost always (or perhaps even always). I wish to understand all parts of the Lean compiler,
from the frontend with its advanced macro system, to the middle end with its dependent typing,
to the back-end. In short, I want to become an expert on the Lean4 compiler `:)`. Let's see how
far along I get!


# Cayley hamilton for 2x2 matrices in sage via AG

- I want to 'implement' the zariski based proof for cayley hamilton in SAGE and show
  that it works by checking the computations scheme-theoretically.
- Let's work through the proof by hand. Take a 2x2 matrix `[a, b; c, d]`.
- The charpoly is `|[a-l; b; c; d-l]| = 0`, which is `p(l) = (a-l)(d-l) - bc = 0`
- This simplified is `p(l) = l^2 - (a + d) l + ad - bc = 0`.
- Now, let's plug in `l = [a; b; c; d]` to get the matrix eqn
- `[a;b;c;d]^2 - (a + d)[a;b;c;d] + [ad - bc; 0; 0; ad - bc] = 0`.
- The square is going to be `[a^2 +]`
- Let `X` be the set of `(a, b, c, d)` such that the matrices `[a;b;c;d]` satisfy their only charpoly.
- Consider the subset `U` of the set `(a, b, c, d)` such that the matrix `[a;b;c;d]` has distinct eigenvalues.
- For any matrix with distinct eigenvalues, it is easy to show that they satisfy their charpoly.
- First see that diagonal matrices satisfy their charpoly by direct computation: `[a;0;0;b]` has eigenvalues `(a, b)`.
  Charpoly is `l^2 - l(a + b) + ab`. Plugging in the matrix, we get `[a^2;0;0;b^2] - [a(a+b);0;0;b(a+b)] + [ab;0;0;ab]` which cancels out to `0`.
- Then note that similar matrices have equal charpoly, so start with `|(λI - VAV')| = 0`. rewrite as `(VλIV' - VAV') = 0`, which is `V(λI - A)V' = 0`,
  which is the same `λI - A = 0`.
- Thus, this means that a matrix with distinct eigenvalues, which is similar to a diagonal matrix (by change of basis), has a charpoly that satisfies cayley hamilton.
- Thus, the set of matrices with distinct eigenvalues, `U` is a subset of `X`.

- However, it is not sufficient to show that the system of equations has an infinite set of solutions.
- For example, `xy = 0` has infinite solutions `(x=0, y=k)` and `(x=l, y=0)`, but that does not mean that it is identically zero.
- This is in stark contrast to the 1D case, where a polynomial `p(x) = 0` having infinite zeroes means that it must be the zero polynomial.
- Thus, we are forced to look deeper into the structure of solution sets of polynomials, and we need to come up with the notion of  irreducibility.
- See that the space `K^4` is irreducible, where `K` is the field from which we draw coefficients for our matrix.

- Next, we note that `X` is a closed subset of `k^4` since it's defined by the zero set of the polynomial equations.
- We note that `U` is an open subset of `k^4` since it's defined as the **non-zero set** of the discriminant of the charpoly! (ie, we want non-repeated roots)
- Also note that `U` is trivially non-empty, since it has eg. all the diagonal matrices with distinct eigenvalues.
- So we have a closed subset `X` of `k^4`, with a non-empty open subset `U` inside it.
- But now, note that the closure of `U` must lie in `X`, since `X` is a closed set, and the closure `U` of the subset of a closed set must lie in `X`.
- Then see that since the space is irreducible, the closure of `U` (an open) must be the whole space.
- This means that all matrices satisfy cayley hamilton!

# LispWorks config

- Looks like all emacs keybindings just work
- https://www.nicklevine.org/declarative/lectures/additional/key-binds.html


# Birkhoff Von Neumann theorem

- By Frobenius Konig theorem, $A$ must have block structure:

```
   r
s [B|C]
  --+---
  [0|D]
```
- Where $r + s = n + 1$

- The column sum of $B$ is $1$ for all $j$. So $B^i_j 1^j = 1$
- The row sum of $B$ is less than or equal to $1$ for all $j$. So $B^i_j 1_i \leq 1$
- From the first sum, we get the total sum as $\sum_{i, j} B[i][j] = sk$
- From the second sum, we get the total sum as $\sum_{i, j} B[i][j] \leq (n-r)k$.
- In total, we get $(n-r)k \leq sk$ which implies $s + r \leq n$ which is a contradiction because $s + r = n + 1$.

#### Proof 1 of BVN (Constructive)

- Let's take a `3x3` doubly stochastic matrix:

```
[#0.4  0.3  0.3]
[0.5   #0.2 0.3]
[0.1   0.5  #0.4]
```

- By some earlier lemma, since permanant is greater than zero, the graph has a perfect matching.
- Suppose we know how to find a perfect matching, which we know exists. Use flows (or hungarian?)
- Take the identity matching as the perfect matching (`1-1`, `2-2`, `3-3`).
- Take the minimum of the matches, `min(0.4, 0.2, 0.4) = 0.2`. So we write the original matrix as:

```
0.2 [1 0 0]    [0.2 0.3 0.3]
    [0 1 0] +  [0.5 0   0.3]
    [0 0 1]    [0.1 0.5 0.4]
```

- Second matrix has row/col sums of `0.8`. Rescale by dividing by `0.8` to get another doubly stochastic matrix.
- Then done by induction on the number of zeroes amongst the matrix entries.

```
[0.2 0.3 0.3]
[0.5 0   0.3]
[0.1 0.5 0.4]
```

- (2) Take the matching given by:

```
[#0.2  0.3   0.3]
[0.5   0    #0.3]
[0.1  #0.5   0.4]
```

- (2) This can be written as:

```
   [1 0 0]   [0    0.3   0.3]
0.2[0 0 1] + [0.5  0     0.1]
   [0 1 0]   [0.1  0.3   0.4]
```

- And so on.

##### Nice method to find permutation that makes progress
- `NxN` doubly stochastic. We must have a permutation that forms a perfect matching. How to find it?
- If all elements are `0/1`, then it's already a permutation.
- Otherwise, find a row which has an element `a` between `0/1`. Then this means that the same row will have ANOTHER element `b` betwene `0/1`.
- Then the column of this element `b` will have another element `c` between `0/1`. Keep doing this until you find a loop.
- Then find the minimum of these elements, call it $\epsilon$.
- Subtract $\epsilon$ at the element that had value $\epsilon$. Then add epislon to the element that was in the same row(column). Then
  continue, subtract $\epsilon$ for the pair of this.



# Latin Square

- A latin square of order $N$ is an $N \times N$ array in which each row and column is
  a permutation of $\{ a_1, a_2, \dots, a_n \}$.
- Example latin square (to show that these exist):

```
[1 2 3 4]
[2 3 4 1]
[3 4 1 2]
[4 1 2 3]
```

- A $k \times n$ ($k < n$) latin rectangle is a $k \times n$ matrix
  with elements $\{ a_1, a_2, \dots, a_n \}$ such that
  in each row and column, no element is repeated.
- Can we always complete a Latin rectangle into a Latin square? (YES!)

#### Lemma

- Let $A$ be a $k \times n$ latin rectangle with $k \leq n - 1$.
- We can always augment $A$ into a $(k + 1) \times n$ latin rectangle.
- If we thnk of it as a set system, then we can think of each column as telling us the
  missing sets. Example:

```
[1   2   3   4]
[4   1   2   3]
{2} {3} {1} {1}
{3} {4} {4} {2}
```

- Let's think of the subsets as a 0/1 matrix, encoded as:

```
[0 1 1 0] {2, 3}
[0 0 1 1] {3, 4}
[1 0 0 1] {1, 4}
[1 1 0 0] {1, 2}
```

- It's clear that each row will have sum $2$, since each set has 2 elements.
- We claim that each column also has sum $2$.
- For example, the first column has column sum $2$. This is because in the original
  matrix, $1$ is missing in two columns.
- We can computea perfect matching on the permutation matrix, that tells us how to extend
  the latin square with no overlaps.

# Assignment Problem

- Let $A$ be an $n \times n$ non-negative matrix.
- A permutation $\sigma$ of $[1, \dots, n]$ is called a **simple assignment** if $A[i][\sigma(i)]$ is positive
  for all $i$.
- A permutation $\sigma$ is called as an **optimal assignment** if $\sum_i A[i][\sigma(i)]$ is
  **minimized** over all permutations in $S_n$. (weird? Don't we usually take max?)
- Matrix $A[p][j]$ is the cost of assigining person $p$ the job $j$. Want to minimize cost.

#### 4x4 example

- Let the cost be:

```
[10 12 19 11]
[5  10 07 08]
[12 14 13 11]
[8  15 11  9]
```

- First find some numbers $u[i]$ and $v[i]$ (these correspond to dual variables in the LP) such that $a[i][j] \leq u[i] + v[j]$ for all $i, j$

```
     v[1] v[2] v[3] v[4]
u[1] [10  12  19   11]
u[2] [5   10  07   08]
u[3] [12  14  13   11]
u[4] [8   15  11    9]
```

- We can start by setting $u[r] = 0$, $v[c] = \min[r](a[r][c])$.
  (Can also take $v[c] = 0$ but this is inefficient)
- Circle those positions where equality holds. This becomes:

```
     v[1] v[2] v[3] v[4]
u[1] [10  12   19    11]
u[2] [5#  10#  07#   08#]
u[3] [12  14   13    11]
u[4] [8   15   11     9]
```

- Since $a[i][j] \leq u[i] + v[j]$, this implies that $a[i][\sigma(i)] \geq u[i] + v[\sigma(i)]$.
- This means $\sum a[i][\sigma(i)] \geq \sum_i u[i] + v[\sigma(i)] = \sum_i u[i] + v[i]$ (the summation can be rearranged).
- Now think of the bipartite graph where these circled positions correspond to $1$, the rest correspond to $0$s.
  If we have a perfect matching amongst the circled positions, then that is the solution (??)
- If the circled positions DO NOT have a perfect matching, then by Fobenius Konig, we can write the matrix as:

```
    s  n-s
n-r[B | C]
r  [X | D]

r + s = n + 1
```

- where in $X$, no entry is circled, because entries that are circled correspond to zeroes (conceptually?)
- We add $1$ to $u[\geq (n-r)]$s D. We subtract $1$ for $v[\geq s]$. That is:

```
    -1
   B C
+1 X D
```

- Nothing happens to $B$.
- in $C$, $v$ goes down, so that keeps the inequality correct.
- In $X$, there are no circles, which means everything was a strict ineuality, so we can afford to add 1s.
- In $D$, $u$ goes up by $1$, $v$ goes down by $1$, thus total no change? [I don't follow].
- The net change is going to be $+1(r) - 1 (n - s) = r + s - n = (n+1) - n = 1$.
- The nonconstructive part is decomposing the matrix into $[B; C, X, D]$.

#### Hungarian algorithm

- Take minimum in each row, subtract.
- Take minimumin each col, subtract.


# Interpolating homotopies

- If we have kp + (1-k) q and a contractible space X which contracts to point
  c, where image of p is x and imagine of q is y, then send the above point to
  theta(x, 2k) : k <= 1/2 and theta (y, 1-2(k - 1/2))or theta (y, 2-2k)
- This interpolates p---q to x--c--y by using bary coordinates to interpolate along homotopy.

# Example where MIP shows extra power over IP

- God tells us chess board is draw. Can't verify
- If two Gods, can make one God play against the other. So if one says draw, other says win, can have them play and find out who is lying!
- Hence, MIP has more power than IP? (Intuitively at least).

# Lazy reversible computation?
- Lazy programs are hard to analyze because we need to reason abot them backwards.
- Suppose we limit ourselves to reversible programs. Does it then become easy?

# Theorem coverage as an analogue to code coverage
- Theorem coverage: how many lines of code are covered by correctness theorems?

# Lazy GPU programming

- All laziness is a program analysis problem, where we need to strictify.
- Lazy vectorization is a program analysis problem where we need to find
  "strict blocks/ strict chains". Something like "largest block of values that
  can be forced at once". Seems coinductive?
- Efficiency of lazy program is that of clairvoyant call by value, so we need to know how to force.
- In the PRAM model, efficiency of parallel lazy program is that of clairvoyanl
  call by parallel or something. We need to know how to run in parallel, such
  that if one diverges, then all diverges. This means it's safe to run
  together!
- What is parallel STG?
- PRAM: try to parallelize writes as much as possible
- PSTG: try to parallelize forcing as much as possible
- `Reads (free) ~ forces (conflicts in ||)`
- `Write (conflict in ||) ~ create new data (free)`
- What are equivalents of common pram models?
- Force is Boolean: either returns or does not return
- We need a finer version. Something like returns in k cycles or does not return?
- Old forced values: forced values with T; wait = Infinity; Old unobserved value = forced values with Twait = -1
- Think of call by push value, but can allocate forces and call "tick" which ticks the clock. The Twait is clocked wrt this tick.
- Tick controls live ranges. Maybe obviates GC.
- Tick 1 is expected to be known/forced.
- Optimize in space-time? Looking up a recurrence versus computing a
  recurrence. One is zero space infinite time, other is zero time infinite
  space.
- Another way to think about it: application says how many people need to ask for thunk to get value. Unused values say infinity, used values say zero
- Maybe think of these as deadlines for the compiler to meet? So it's telling
  the compiler to guarantee access in a certain number of ticks. This gives
  control over (abstract) time, like imperative gives control over abstract
  space?
- TARDIS autodiff is key example. As is fib list. Maybe frac.
- Thinking about design in the data constructor side:
- Twait = 0 in data structure means is present at compile time. Twait = 1 is strict. Twait = infty is function pointer. What is Twait = 2? Mu
- Can fuse kernels for all computations in the same parallel force. If one of
  them gets stuck, all of them get stuck. So parallel force is a syntactic way
  to ask for kernel fusion.
- Can we use UB to express things like "this list will be finite, thus map can be safely parallelised" or something?
- Have quantitative: `0,1,fin,inf`?


# Backward dataflow and continuations

- Forward dataflow deals with facts _thus far_.
- Backward dataflow deals with facts about _the future_, or the _rest of the program_.
  Thus, in a real sense, backward dataflow concerns itself with _continuations_!

# The tyranny of structurelessness

- [THE TYRANNY of STRUCTURELESSNESS by Jo Freeman aka Joreen](https://www.jofreeman.com/joreen/tyranny.htm)

> "Elitist" is probably the most abused word in the women's liberation movement.
> It is used as frequently, and for the same reasons, as "pinko" was used in the
> fifties. It is rarely used correctly. Within the movement it commonly refers to
> individuals, though the personal characteristics and activities of those to
> whom it is directed may differ widely: An individual, as an individual can
> never be an elitist, because the only proper application of the term "elite" is
> to groups. Any individual, regardless of how well-known that person may be, can
> never be an elite.

> The inevitably elitist and exclusive nature of informal communication
> networks of friends is neither a new phenomenon characteristic of the women's
> movement nor a phenomenon new to women. Such informal relationships have
> excluded women for centuries from participating in integrated groups of which
> they were a part. In any profession or organization these networks have
> created the "locker room" mentality and the "old school" ties which have
> effectively prevented women as a group (as well as some men individually)
> from having equal access to the sources of power or social reward.

> Although this dissection of the process of elite formation within small groups
> has been critical in perspective, it is not made in the belief that these
> informal structures are inevitably bad -- merely inevitable. All groups create
> informal structures as a result of interaction patterns among the members of
> the group. Such informal structures can do very useful things But only
> Unstructured groups are totally governed by them. When informal elites are
> combined with a myth of "structurelessness," there can be no attempt to put
> limits on the use of power. It becomes capricious.


# Simple Sabotage Field Manual

- (1) Insist on doing everything through "channels." Never permit short-cuts to
  be taken in order to expedite decisions.
- (2) Make "speeches." Talk as frequently as possible and at great length.
  Illustrate your "points" by long anecdotes and accounts of personal
  experiences. Never hesitate to make a few appropriate "patriotic" comments.
- (3) When possible, refer all matters to committees, for "further study and
  consideration." Attempt to make the committees as large as possible - never
  less than five.
- (4) Bring up irrelevant issues as frequently as possible.
- (5) Haggle over precise wordings of communications, minutes, resolutions.
- (6) Refer back to matters decided upon at the last meeting and attempt to
  re-open the question of the advisability of that decision.
- (7) Advocate "caution". Be "reasonable" and urge your fellow-conferees to be
  "reasonable" and avoid haste which might result in embarrassments or
  difficulties later on.
- (8) Be worried about the propriety of any decision — raise the question of
  whether such action as is contemplated lies within the jurisdiction of the
  group or whether it might conflict with the policy of some higher echelon.



# Counting permutations with #MAXSAT

Using #MAXSAT, you can count permutations, weird. Build a complete bipartite
graph K(n,n), and then connect left to source, right to sink with unit
capacity. Each solution to the flow problem is an assignment / permutation.



# Coloring `cat` output with `supercat`
- use `spc -e 'error, red' ` to color all occurrences of string `error` with `red`.
- I use this in [lean-mlir]() to get colored output.

# Reader monoid needs a hopf algebra?!
- 5.1, eg (iii)
- We actually get a free comonoid in a CCC.
- having a splittable random supply in like having a markov category with a comonoid in it.

# Monads mnemonic

- multiplication is $\mu$ because Mu.
- return is $\eta$ because return is unit is Yeta.

# Card stacking

> It's not about the idea, it's about the execution
-  The idea is indeed pedestrain: Let's stack cards!
- The execution is awesome.
- [Link to homepage of insane card stacker](https://www.cardstacker.com/)



# SSH into google cloud
- Setup firewall rules that enable all SSH
- Add SSH key into `metadata` of project.
- ssh `<ssh-key-username>@<external-ip>` ought to just work.



# Comma & Semicolon in index notation

> A comma before an index indicates partial differentiation with respect to that index.
> A semicolon indicates covariate differentiation.

- Thus, the divergence may be written as `v_i,i`

# Spin groups

- Spin group is a 2 to 1 cover of $SO(n)$.
- We claim that for 3 dimensions, $Spin(3) \simeq SU(2)$. So we should have a 2 to 1 homomorphism $\rho: SU(2) \to SO(3)$.
- We want to write the group in some computational way. Let's use the adjoint action (how the lie group acts on its own lie algebra).
- What is the lie algebra $su(2)$? It's trace-free hermitian.
- Why? Physicist: $UU^\dagger = I$ expanded by epsilon gives us $(I + i \epsilon H)(I - i \epsilon H) = I$, which gives $H =  H^\dagger$.
- Also the determinant condition gives us $det(1 + i \epsilon H) = 1$ which means $1 + tr(i \epsilon H) = 1$, or $tr(H) = 0$.
- The adjoint action is $SU(2) \to Aut(H)$ given by $U \mapsto \lambda x. ad_U x$ which is $\lambda x. U X U^{-1}$.
  By unitarry, this is $U \mapsto \lambda x. U X U^{\dagger}$.
- $SO(3)$ acts on $\mathbb R^3$. The trick is to take $\mathbb R^3$ and compare it to the lie algebra $su(2)$
  which has 3 dimensions, spanned by pauli matrices.
- **Conjecture:** There is an isomorphism $\mathbb R^3 \simeq H$ as an inner product space for a custom inner product
  $\langle, \rangle$ on $H$.
- [Reference](https://www.youtube.com/watch?v=Way8FfcMpf0&list=PLPH7f_7ZlzxTi6kS4vCmv4ZKm9u8g5yic&index=27)

# Undefined behaviour is like compactification [TODO]

- We compactify something like $\mathbb N$ into $\mathbb N^\infty$.
- What does Stone Cech give us?
- Read abstract stone duality!

# God of areppo


> One day, a farmer named Arepo built a temple at the edge of his field. It was a humble thing, with stone walls and a thatch roof. At the center of the room Arepo stacked some stones to make a cairn. Two days later, a god moved into Arepo's temple.
> "I hope you are a harvest god," Arepo said, as he set upon the altar two stalks of wheat which he burned. "It would be nice."
>
> He looked down upon the ash that now colored the stone. "I know this isn't much of a sacrifice, but I hope this pleases you. It'd be nice to think there is a god looking after me."
>
> The next day, he left a pair of figs. The day after that, he spent ten minutes in silent prayer. On the third day, the god spoke up.
>
> "You should go to a temple in the city," said a hollow voice. Arepo cocked his head at the otherworldly sound, because it was strangely familiar. The god's voice was not unlike the rustling of wheat, or the little squeaks of fieldmice that run through the grass. "Go to a real temple. Find a real god to bless you, for I am not much myself, but perhaps I may put in a good word?"
>
> The god plucked a stone from the floor and sighed, "Forgive me, I meant not to be rude. I appreciate your temple, and find it cozy and warm. I appreciate your worship, and your offerings, but alas it shall come to naught."
>
> "Already I have received more than I had expected," Arepo said, "Tell me, with whom do I treat? What are you the patron god of?"
>
> The god let the stone he held fall to the floor, "I am of the fallen leaves, and the worms that churn beneath he ground. I am the boundary of the forest and the field, and the first hint of frost before the snow falls," the god paused to touch Arepo's altar, "And the skin of an apple as it yields beneath your teeth. I am the god of a dozen different nothings, scraps that lead to rot, and momentary glimpses." He turned his gaze to Arepo, "I am a change in the air, before the winds blow."
>
> The god shook his head, "I should not have come, for you cannot worship me. Save your prayers for the things beyond your control, good farmer," the god turned away, "You should pray to a greater thing than I,"
>
> Arepo reached out to stay the entity, and laid his hand upon the god's willowy shoulder. "Please, stay."
>
> The god turned his black eyes upon Arepo, but found only stedfast devotion. "This is your temple, I would be honored if you would stay." The god lowered himself to the floor. Arepo joined him. The two said nothing more for a great long while, until Arepo's fellow came calling.
>
> The god watched his worshiper depart, as the man's warmth radiated across the entity's skin.
>
> Next morning, Arepo said a prayer before his morning work. Later, he and the god contemplated the trees. Days passed, and then weeks. In this time the god had come to enjoy the familiarity of Arepo's presence. And then, there came a menacing presence. A terrible compulsion came upon the god, and he bid the air change, for a storm was coming. Terrified, the little god went to meet the god of storms to plead for gentleness, but it was no use.
>
> Arepo's fields became flooded, as the winds tore the tiles from his roof and set his olive tree to cinder. Next day, Arepo and his fellows walked among the wheat, salvaging what they could. At the field's edge, the little temple was ruined. After his work was done for the day, Arepo gathered up the stones and pieced them back together. "Please do not labor," said the god, "I could not protect you from the god of storms, and so I am unworthy of your temple."
>
> "I'm afraid I don't have an offering today," Arepo said, "But I think I can rebuild your temple tomorrow, how about that?"
>
> The god watched Arepo retire, and then sat miserably amongst the ruined stones of his little temple.
>
> Arepo made good on his promise, and did indeed rebuild the god's temple. But now it bore layered walls of stone, and a sturdy roof of woven twigs. Watching the man work, Arepo's neighbors chuckled as they passed by, but their children were kinder, for they left gifts of fruit and flowers.
>
> The following year was not so kind, as the goddess of harvest withdrew her bounty. The little god went to her and passionately pleaded for mercy, but she dismissed him. Arepo's fields sprouted thin and brittle, and everywhere there were hungry people with haunted eyes that searched in vain for the kindness of the gods.
>
> Arepo entered the temple and looked upon the wilted flowers and the shriveled fruit. He murmured a prayer.
>
> "I could not help you," said the god. "I am only a burden to you,"
>
> "You are my friend," said Arepo.
>
> "You cannot eat friendship!" The god retorted.
>
> "No, but I can give it." Arepo replied.
>
> And so the man set his hand upon the altar and spent the evening lost in contemplation with his god.
>
> But the god knew there was another god who would soon visit, and later that year came the god of war. Arepo's god did what he could. He went out to meet the hateful visage of the armored god, but like the others, war ignored the little god's pleas. And so Arepo's god returned to his temple to wait for his friend. After a worrying amount of time, Arepo came stumbling back, his hand pressed to his gut, anointing the holy site with his blood.
>
> Behind him, his fields burned.
>
> "I am so sorry, Arepo," said the god, "My friend. My only friend."
>
> "Shush," said Arepo, tasting his own blood. He propped himself up against the temple that he made, "Tell me, my friend, what sort of god are you?"
>
> The god reached out to his friend and lowered him to the cool soil, "I'm of the falling leaves," the god said, as he conjured an image of them. "And the worms that churn beneath the earth. The boundary of the forest and the field. The first hint of frost before the first snow. The skin of an apple as it yields beneath your teeth."
>
> Arepo smiled as the god spoke. "I am the god of a dozen different nothings, the god of the petals in bloom that lead to rot, and of momentary glimpses, and a change in the air-" the god looked down upon his friend, "Before the winds blow everything away."
>
> "Beautiful," Arepo said, his blood now staining the stones; seeping into the very foundations of his temple. "All of them, beautiful,"
>
> "When the storm came, I could not save your wheat."
>
> "Yes," Arepo said.
>
> "When the harvest failed, I could not feed you."
>
> "Yes,"
>
> Tears blurred the god's eyes, "When war came, I could not protect you."
>
> "My friend, think not yourself useless, for you are the god of something very useful,"
>
> "What?"
>
> "You are my god. The god of Arepo."
>
> And with that, Arepo the sower lay his head down upon the stone and returned home to his god. At the archway, the god of war appeared. The entity looked less imposing now, for his armor had fallen onto the blackened fields, revealing a gaunt and scarred form.
>
> Dark eyes flashed out from within the temple, 'Are you happy with your work?' They seemed to say. The god of war bowed his head, as the god of Arepo felt the presence of the greater pantheon appear upon the blackened fields.
>
> "They come to pay homage to the farmer," war said, and as the many gods assembled near the archway the god of war took up his sword to dig into the earth beneath Arepo's altar. The goddess of the harvest took Arepo's body and blessed it, before the god of storms lay the farmer in his grave.
>
> "Who are these beings, these men," said war, "Who would pray to a god that cannot grant wishes nor bless upon them good fortune? Who would maintain a temple and bring offerings for nothing in return? Who would share their company and meditate with such a fruitless deity?"
>
> The god rose, went to the archway; "What wonderful, foolish, virtuous, hopeless creatures, humans are."
>
> The god of Arepo watched the gods file out, only to be replaced by others who came to pay their respects to the humble farmer. At length only the god of storms lingered. The god of Arepo looked to him, asked; "Why do you linger? What was this man to you?"
>
> "He asked not, but gave." And with that, the grey entity departed.
>
> The god of Arepo then sat alone. Oft did he remain isolated; huddled in his home as the world around him healed from the trauma of war. Years passed, he had no idea how many, but one day the god was stirred from his recollections by a group of children as they came to lay fresh flowers at the temple door.
>
> And so the god painted the sunset with yellow leaves, and enticed the worms to dance in their soil. He flourished the boundary between the forest and the field with blossoms and berries, and christened the air with a crisp chill before the winter came. And come the spring, he ripened the apples with crisp red freckles that break beneath sinking teeth, and a dozen other nothings, in memory of a man who once praised his work with his dying breath.
>
> "Hello," said a voice.
>
> The god turned to find a young man at the archway, "Forgive me, I hope I am not intruding."
>
> "Hello, please come in."
>
> The man smiled as he entered, enchanted the the god's melodic voice. "I heard tell of your temple, and so I have come from many miles away. Might I ask, what are you the god of?"
>
> The god of Arepo smiled warmly as he set his hand upon his altar, "I am the god of every humble beauty in the world."
> -by Chris Sawyer


# Classification of lie algebras, dynkin diagrams

#### Classification of complex lie algebras
- $L$ is a complex vector space with a lie bracket $[., .]$.
- For example, if $G$ is a complex Lie group. For a complex manifold, the transition functions are holomorphic.

#### Theorem (Leri)

- Every finite dimensional complex Lie algebra $(L, [.,.])$ can be decomposed as $L = R \oplus_s (L_1 \dots \oplus L_n)$, where $\oplus$
  is direct sum, $\oplus_s$ is the semidirect sum.
-  $R$ is a solvable lie algebra.
- To define solvable, define $R_0 = R$, $R_1 = [R_0, R_0]$, $R_2 = [R_1, R_1]$, that is, $R_2 = [[R, R], [R, R]]$.
- We have that $R_{i+1}$ is a strict subset of $R_i$.
- If this sequence eventually stabilizes, ie, there is an $n$ such that $R_n = \{ 0 \}$, then $R$ is solvable.
- In the decomposition of $L$, the $R$ is the solvable part.
- We have $L_1$, \dots, $L_n$ which are simple. This means that $L_i$ is non-abelian, and $L_i$ contains no non-trivial
  ideals. An ideal of a lie algebra is a subvevtor space $I \subseteq L$ such that $[I, L] \subseteq I$. (It's like a ring ideal, except with lie bracket).
- The direct sum $L_1 \oplus L_2$ of lie algebras is the direct sum of vector spaces with lie bracket in the bigger space given by
  $[L_1, L_2] = 0$.
- The semidirect sum $R \oplus_s L_2$ as a vector space is $R \oplus L_2$. The lie bracket is given by
  $[R, L_2] \subseteq R$, so $R$ is an ideal. (This looks like internal semidirect product).

#### Remarks
- It is very hard to classify solvable Lie algebras.
- A lie algebra that has no solvable part, ie can be written as $L = L_1 \dots \oplus L_n$ is called as **semi-simple**.
- It is possible to classify the simple Lie algebras.
- We focus on the simple/semi-simple Lie algebras. Simple Lie algebras are the independent building blocks we classify.

#### Adjoint Map
- Let $(L, [., .])$ be a complex lie algebra. Let $h \in L$ be an element of the lie algebra.
- Define $ad(h): L \to L$ as $ad(h)(l) \equiv [h, l]$. Can be written as $ad(h) \equiv [h, -]$. This is the adjoint map wrt $h \in L$.

#### Killing form
- $K: L \times L \to \mathbb C$ is a bilinear map, defined as $K(a, b) \equiv tr(ad(a) \circ ad(b))$.
- See that $ad(a) \circ ad(b): L \to L$. the trace will be complex because $L$ is complex.
- Since $L$ is finite dimensional vector space, $tr$ is cyclic. So $tr(ad(a) \circ ad(b)) = tr(ad(b) \circ ad(a))$. This means
  that $K(a, b) = K(b, a)$, or that the killing form is symmetric!
- **Cartan criterion:** $L$ is semi-simple iff the killing form $K$ is non-degenerate. That is, $K(a, b) = 0$ implies $b = 0$.

#### Calculation wrt basis: $ad$ map.
- Consider for actual calculation the components of $ad(h)$ and $K$ with respect to a basis $E_1, \dots, E_{dim L}$.
- Write down a dual basis $\epsilon^1, \epsilon^{dim L}$.
- $ad(E_i)^j_k \equiv \epsilon^j (ad(E_i)(E_k))$.
- We know that $ad(E_i)(E_k) = [E_i, E_k]$ by definition.
- We write $[E_i, E_k] = C^m_{ik} E_m$ where the $C^m_{ik}$ are the structure constants.
- This gives us $ad(E_i)^j_k = \epsilon^j (C^m_{ik} E_m)$
- Pull out structure coefficient to get $ad(E_i)^j_k = C^m_{ik} \epsilon^j (E_m)$
- Use the fact that $E_m$ and $\epsilon_j$ are dual to get $ad(E_i)^j_k = C^m_{ik} \delta^j_m$
- Contract over repeated index $m$ to get $m=j$: $ad(E_i)^j_k = C^j_{ik}$
- This makes sense, since the $ad$ map is just a fancy way to write the bracket in coordinate free fashion.

#### Calculation wrt basis: Killing form.
- $K(E_i, E_j) = tr(ad(E_i) \circ ad(E_j))$
- Plug in $ad$ to become $K(E_i, E_j) = tr(C^l_{im} C^m_{jk})$ [see that the thing inside the trace is a matrix]
- Execute trace by setting $l = k = o$. This gives us: $K(E_i, E_j) = C^o_{im} C^m_{jo}$. This is also easy to calculate from
  structure coefficients.
- Iff this matrix is non-degenerate, then the lie-algebra is semi-simple.

#### $ad$ is anti-symmetric with respect to the killing form.
- Recall that $\phi$ is called as an anti-symmetric map wrt a non-degenerate bilinear form $B$ iff
  $B(\phi(v), w) = - B(v, \phi(w))$.
- Fact: $ad(h)$ is anti-symmetric wrt killing form. For killing form to be non-degenerate we need $L$ to be semisimple.

#### Key Definition for classification: Cartan subalgebra
- If $(L, [.,.])$ is a lie algebra, then the cartan subalgebra denoted by $H$ ($C$ is already taken for structure coeff.)
  is a vector space, and is a maximal subalgebra of $L$ such that there exists a basis $h_1, \dots, h_m$ of $H$
  that can be extended to a basis of $L$: $h_1, \dots, h_m, e_1, \dots, e_{dim(L)-m}$ such that the extension vectors
  are eigenvectors for any $ad(h)$ for $h \in H$.
- This means that $ad(h)(e_\alpha) = \lambda_\alpha(h) e_\alpha$.
- This can be written as $[h, e_\alpha] = \lambda_\alpha(h) e_\alpha$.
- Does this exist?

#### Existence of cartan subalgebra
- **Thm** Any finite dimensional lie algebra possesses a cartan subalgebra.
- If $L$ is simple, then $H$ is _abelian_. That is, $[H, H] = 0$.
- Thus, the $ad(h)$ are simultaneously diagonalized by the $e_\alpha$ since they all commute.

#### Analysis of Cartan subalgebra.
- $ad(h)(e_\alpha) = \lambda_\alpha(h) e_\alpha$.
- $[h, e_\alpha] = \lambda_\alpha(h) e_\alpha$.
- Since the LHS is linear in $h$, the RHS must also be linear in $H$. But in the RHS, it is only $\lambda_\alpha(h)$ that depends
  on $h$.
- This means that $\lambda_\alpha: H \to \mathbb C$ is a _linear map_!
- This is to say that $\lambda_\alpha \in H^*$ is an element of the dual space!
- The elements $\lambda_1, \lambda_2, \lambda_{dim L - m}$ are called the _roots_ of the Lie algebra.
- This is called as $\Phi \equiv \{ \lambda_1, \dots, \lambda_{dim L - m} \}$, the _root set_ of the Lie algebra.

#### Root set is closed under negation

- We found that $ad(h)$ is antisymmetric with respect to killing form.
- Thus, if $\lambda \in \phi$ is a root, $-\lambda$ is also a root (somehow).

#### Root set is not linearly independent
- We can show that $\Phi$ is not LI.

#### Fundamental roots
- Subset of roots $\Pi \subseteq \Phi$ such that $\Pi$ is linearly independent.
- Let the elements of $\Pi$ be called $\pi_1, \dots, \pi_r$.
- We are saying that $\forall \lambda \in \Phi, \exists n_1, \dots, n_f \in \mathbb N, \exists \epsilon \in \{ -1, +1 \}$
  such that $\lambda = \epsilon \sum_{i=1}^f n_i \pi_i$.
- That is, we can generate the $\lambda$ as natural number combinations of $\pi_i$, upto an overall global sign factor.
- Fact: such a set of fundamental roots can always be found.


#### complex span of fundamental roots is the dual of the cartan subalgebra
- In symbols, this is $span_{\mathbb C}(\Pi) = H^*$.
- They are not a basis of $H^*$ because they are not $\mathbb C$ independent (?)
- $\Pi$ is not unique, since it's a basis.

#### Defn: $H_{\mathbb R}^*$

- Real span of fundamental roots: $span_{\mathbb R}(\Pi)$.
- We have that $\Phi = span_{\pm \mathbb N}(\Pi)$.
- Thus $\Phi$ is contained in $span_{\mathbb R}(\Pi)$, which is contained in $span_{\mathbb C}(\Pi)$.

#### Defn: Killing form on $H^*$
- We restrict $K: L \times L \to \mathbb C$ to $K_H: H \times H \to \mathbb C$.
- What we want is $K^*: H^* \times H^* \to \mathbb C$.
- Define $i: H \to H^*$ given by $i(h) = K(h, \cdot)$.
- $i$ is invertible if $K$ is non-degenerate.
- $K^*(\mu, \nu) \equiv K(i^{-1}(\mu), i^{-1}(\nu))$.

#### $K^*$ on $H^*_{\mathbb R}$
- The restricted action of $K^*$ on $H^*_{\mathbb R}$ will always spit out real numbers.
- Also, $K^*(\alpha, \alpha) \geq 0$ and equal to zero iff $\alpha = 0$.
- See that $K$ was non-degenerate, but $K^*_{\mathbb R}$ is a real, bona fide inner product!
- This means we can calculate length and angles of fundamental roots.


#### Recovering $\Phi$ from $\Pi$
- How to recover all roots from fundamental roots?
- For any $\lambda \in Phi$, define the Weyl transformation $s_\lambda: H^\star_R \to H^\star_R$
- The map is given by $s_\lambda(\mu) = \mu - 2 \frac{K^*(\lambda, mu)}{K^*(\lambda, \lambda)} \lambda$.
- This is linear in $\mu$, but not in $\lambda$.
- Such $s_\lambda$ are called as weyl transformations.
- Define a $W$ group generated by the $s_\lambda$. This is called as the Weyl group.

#### Theorem: Weyl group is generated by fundamental roots
- It's enough to create $s_\Pi$ to generate $W$.

#### Theorem: Roots are prouced by action of Weyl group on fundamental roots
- Any $\lambda \in \Phi$ can be produced by the action of some $w \in W$ on some $\pi \in \Pi$.
- So $\forall \lambda \in \Phi, \exists \pi \in Pi, \exists w \in W$ such that $\lambda = w(\pi)$.
- This means we can create all roots from fundamental roots: first produce the weyl group, then find the action
  of the weyl group on the fundamental roots to find all roots.
- The Weyl group is closed on the set of roots, so $W(\Phi) \subseteq \Phi$.

#### Showdown

- Consider $S_{\pi_i}(\pi_j)$ for $\pi_i, \pi_j \in \Pi$.




# Weird free group construction from adjoint functor theorem


- We wish to construct the free group on a set $S$. Call the free group $\Gamma S$.
- Call the forgetful functor from groups to sets as $U$.
- The defining property of the free group is that if we are given a mapping $\phi: S \to UG$, a map which
  tells us where the generators go, there is a unique map $\Gamma \phi: \Gamma S \to G$ which maps the generators of the free
  group via a group homomorphism into $G$. Further, there is a bijection between $\phi$ and $\Gamma \phi$.
- Written differently, there is a bijection $\hom_\texttt{Set}(S, UG) \simeq \hom_\texttt{Group}(\Gamma S, G)$.
  This is the condition for an adjunction.
- The idea to construct $\Gamma S$ is roughly, to take all possible maps $f_i: S \to UG$ for all groups $G$,
  take the product of all such maps,
  and define $\Gamma S \equiv im(\pi_i f_i)$. The details follow.
- First off, we can't take all groups, that's too large. So we need to cut down the size somehow. We do this by considering groups
  with at most $|S|$ generators, since that's all the image of the maps $f_i$ can be anyway. We're only interested in the image
  at the end, so we can cut down the groups we consider to be set-sized.
- Next, we need to somehow control for isomorphisms. So we first take _isomorphism classes_ of groups with at most $|S|$ generators.
  Call this set of groups $\mathcal G$
  We then construct all possible maps $f_i: S \to UG$ for all possible maps $f$, for all possible $G \in \mathcal G$.
- This lets us construct the product map $f : S \to \prod_{G \in \mathcal G} UG$ given by $f(s) \equiv \prod_{G \in \mathcal G} f_i(s)$.
- Now we define the free group $\gamma S \equiv im(f)$. Why does this work?
- Well, we check the universal property. Suppose we have some map $h: S \to UH$. This must induce a map $\Gamma h: \Gamma S \to H$.
- We can cut down the map, by writing the map as $h_{im}: S \to im(h)$. This maps into some subset of $UH$, from which we can generate
  a group $H_{im} \subseteq H$.
- First off, there must be some index $k$ such that $f_k = h_{im}$, since the set of maps $\{ f_i \}$ covers all possible maps from $S$
  into groups with those many generators.
- This implies we can project the group $\Gamma S$ at the $k$th index to get a map from $\Gamma S$ into $H_{im}$.
- We can then inject $H_{im}$ into $H$, giving us the desired map!

# bashupload

```
curl bashupload.com -T your_file.txt
```

- Super useful if one wants to quickly send a file from/to a server.

# When are the catalan numbers odd

- The catalan numbers $C_n$ count the number of binary trees on $n$ nodes.
- For every binary tree, label the nodes in some standard ordering (eg. BFS).
- Pick the lex smallest _unbalanced_ node (node with different left and right subtree sizes).
- The operation that swaps the left and right subtrees of the lex smallest unbalanced node is an involution.
- This operation only fails when we have a complete binary tree, so the number of nodes is $n = 2^r - 1$, so we pair such a complete binary tree to itself.
- This breaks the set $C_n$ into an even number of trees (pairs of unbalanced trees) and a potential "loner tree" (paired with itself) which is the
  complete binary tree.
- Thus $C_n$ is odd iff $n = 2^r - 1$, which allows for us to have a complete binary tree, which is not paired by the involution.
- [Reference](https://mathoverflow.net/a/409029)


# Geodesic equation, Extrinsic

- The geodesic on a sphere must be a great circle. If it's not, so say we pick a circle at some fixed azimuth,
  then all the velocities point towards the center at this azimuth, not at the center of the sphere! But
  towards the center of the sphere is the real normal plane. So we get a deviation from the normal.

#### How do we know if a path is straight?
- Velocity remains constant on a straight line.
- So it has zero acceleration.
- If we think of a curved spiral climbing a hill (or a spiral staircase), the acceleration vector will point upward (to allow us to climb the hill)
  and will the curved inward into the spiral (to allow us to turn as we spiral).
- On the other hand, if we think of walking straight along an undulating plane, the acceleration with be positive/negative depending
  on whether the terrian goes upward or downward, but we won't have any left/right motion _in the plane_.
- If the acceleration is always along the normal vectors, then we have a geodesic.

#### Geodesic curve
- Curve with zero tangential acceleration when we walk along the curve with constant speed.
- Start with the $(u, v)$ plane, and map it to $R(u, v) \equiv (R_x, R_y, R_z)$.  Denote the curve as $c: I \to \mathbb R^3$  such that $c$ always
  lies on $R$. Said differently, we have $c: I \to UV$, which we then map to $\mathbb R^3$ via $R$.
- So for example, $R(u, v) = (\cos(u), \sin(u)\cos(v), \sin(u)\sin(v))$ and $c(\lambda) = (\lambda, \lambda)$. Which is to say,
  $c(\lambda) = (\cos(\lambda), \sin(\lambda)\cos(\lambda), \sin(\lambda)\sin(\lambda))$.
- Recall that $e_u \equiv \partial_u R, e_v \equiv \partial_v R \in \mathbb R^3$ are the basis of the tangent plane at $R_{u, v}$.
- Similarly, $\partial_\lambda c$ gives us the tangent vector along $c$ on the surface.
- Write out:

$$
\begin{aligned}
&\frac{dc}{d \lambda} = \frac{du}{d\lambda}\frac{dR}{du} + \frac{dv}{d\lambda}\frac{dR}{dv}
&\frac{d}{d\lambda}(\frac{dc}{d \lambda})\\
&=\frac{d}{d\lambda}(\frac{du}{d\lambda}\frac{dR}{du} + \frac{dv}{d\lambda}\frac{dR}{dv}) \\
&=\frac{d}{d\lambda}(\frac{du}{d\lambda}\frac{dR}{du}) + \frac{d}{d\lambda}(\frac{dv}{d\lambda}\frac{dR}{dv}) \\
&= \frac{d^2 u}{d\lambda^2}\frac{dR}{du} + (\frac{du}{d\lambda} \frac{d}{d\lambda} \frac{dR}{du})
  \frac{d^2 v}{d\lambda^2}\frac{dR}{dv} + (\frac{dv}{d\lambda} \frac{d}{d\lambda} \frac{dR}{dv})
\end{aligned}
$$

- How to calculate $\frac{d}{d\lambda} \frac{dR}{ddu}$? Use chain rule, again!
- $\frac{d}{d\lambda} = \frac{du}{d \lambda}\frac{\partial}{\partial u} + \frac{dv}{d \lambda}\frac{\partial}{\partial v}$

#### Geodesic curve with notational abuse
- Denote by $R(u, v)$ the surface, and by $R(\lambda)$ the equation of the curve. So for example, $R(u, v) = (\cos(u), \sin(u)\cos(v), \sin(u)\sin(v))$
  while $R(\lambda) = R(\lambda, \lambda) = (\cos(\lambda), \sin(\lambda)\cos(\lambda), \sin(\lambda)\sin(\lambda))$.

- [EigenChris videos](https://www.youtube.com/watch?v=1CuTNveXJRc)

# Connections, take 2

- I asked a [math.se question](https://math.stackexchange.com/questions/4309198/on-which-tangent-bundles-of-mathbb-r2-does-position-velocity-acceleration)
  about position, velocity, acceleration that recieved a great answer by `peek-a-boo`. Let me try and provide an exposition of his answer.
- Imagein a base manifold $M$, say a circle.
- Now imagine a vector bundle over this, say 2D spaces lying above each point on the circle. Call this $(E, \pi, M)$
- What is a connection? Roughly speaking, it seems to be a device to convert elements of $TM$ into elements of $TE$.
- We imagine the base manifold (circle) as horizontal, and the bundle $E$ as vertical. We imagine $TM$ as vectors lying horizontal
  on the circle, and we imagine $TE$ as vectors lying horizontal above the bundle. So something like:

<img src="./static/connection-vector-bundle-geometry.png"/>


- So the connection has type $C: E \times TM \to TE$. Consider a point $m \in M$ in the base manifold.
- Now think of the fiber $E_m \subseteq E$ over $x$.
- Now think of any point $e \in E_m$ in the fiber of $m$.
- This gives us a map $C_e: T_e M \to T_e E$, which tells us to imagine a particle $e \in E$ following its brother in $m \in M$.
  If we know the velocity $\dot m \in T_m M$, we can find the velocity of the sibling upstrairs with $C_e(\dot m)$.
- In some sense, this is really like path lifting, except we're performing "velocity lifting". Given a point in the base manifold and
  a point somewhere upstairs in the cover (fiber), we are told how to "develop" the path upstairs given information about how to "develop"
  the path downstairs.
- I use "develop" to mean "knowing derivatives".


#### Differentiating vector fields along a curve

- Given all of this, suppose we have a curve $c: I to M$ and a vector field over the curve $v: I \to E$ such that
  the vector field lies correctly over the curve; $\pi \circ v = c$. We want to differentiate $v$, _such that we get another $v': TI \to E$_.
- That's the crucial bit, $v$ and $v'$ have the same type, and this is achieved through the connection. So a vector field and its derivative are _both_
  vector fields over the curve.
- How do we do this? We have the tangent mapping $Tv: TI \mapsto TE$.
- We kill off the component given by pushing forward the tangent vector $Tc(i): TI$ at the bundle location $v(i)$ via the connection.
  This kills of the effect of the curving of the curve when measuring the change in the vector field $v$.
-  We build $[z(t_i: TI) \equiv Tv(ti) - C_{v(i)}(Tc(i))]: TI \to TE$.
- We now have a map from $I$ to $TE$, but we want a map to $E$. What do?
- Well, we can check that the vector field we have created is a vertical vector field, which means that it lies entirely within the fiber.
  Said differently, we check that it pushes forward to the zero vector under projection, so $TM: TE \to TM$ will be zero for the image of $w$.
- This means that $z$ lies entirely "inside" each fiber, or it lies entirely in the tangent to the vector space $\pi^{-1}(m)$ (ie, it lives
  in $T\pi^{-1}(m)$), instead of living in the full tangent bundle $E_m$ where it has access to the horizontal components.
- But for a vector space, the tangent space is canonically isomorphic to the vector space itself! (parallelogram law/can move vectors around/...).
  Thus, we can bring down the image of $w$ from $TE$ down to $E$!
- This means we now have a map $z: TI \to E$.
- But we want a $w: I \to E$. See that the place where we needed a $TI$ was to produce


# Dropping into tty on manjaro/GRUB

- Acces grub by holding down `<ESC>`
-  add a suffix `rw 3` on the GRUB config line that loads `linux ...`


# Why the zero set of a continuous function must be a closed set

- Consider the set of points $Z = f^{-1}(0)$ for some function $f: X \to \mathbb R$.
- Suppose we can talk about sequences or limits in $X$.
- Thus, if $f$ is continuous, then we must have $f(\lim x_i) = \lim f(x_i)$.
- Now consider a limit point $l$ of the set $Z$ with sequence $l_i$ (that is, $\lim l_i = l$). Then we have
  $f(l) = f(\lim l_i) = \lim f(l_i) = \lim 0 = 0$. Thus, $f(l) = 0$.
- This means that the set $Z$ contains $l$, since $Z$ contains all pre-images of zero. Thus, the set $Z$ is closed.
- This implies that the zero set of a continuous function must be a closed set.
- This also motivates zariski; we want a topology that captures polynomial behaviour. Well, then the closed sets _must_ be the zero
  sets of polynomials!

# Derivatives in diffgeo

- A function of the form $f: \mathbb R^i \to \mathbb R^o$ has derivative specified by an $(o \times i)$ matrix, one which says
  how each output varies with each input.
- Now consider a vector field $V$ on the surface of the sphere, and another vector field $D$. Why is $W \equiv \nabla_D V$
  another vector field? Aren't we differentiating a thing with 3 coordinates with another thing with 3 coordinates?
- Well, suppose we consider the previous function $f: \mathbb R^i \to \mathbb R^o$, and we then consider a curve $c: (-1, 1) \to \mathbb R^i$.
  Then the combined function $(f \circ c): (-1, 1) \to \mathbb R^o$ needs only $o$ numbers to specify the derivative, since there's only one
  parameter to the curve (time).
- So what's going on in the above example? Well, though the full function we're defining is from $\mathbb R^i$ to $\mathbb R^o$, composing
  with $c$ "limits our attention" to a 1D input slice. In this 1D input slice, the output is also a vector.
- This should be intuitive, since for example, we draw a circle parameterized by arc length, and then draw its tangents as vectors, and then
  _we draw the normal as vectors_ to the tangents! Why does _that_ work? In both cases (position -> vel, vel -> accel) we have a single parameter,
  time. So in both cases, we get vector fields!
- That's somehow magical, that the derivative of a thing needs the same "degrees of freedom" as the thing in itself. Or is it magical? Well, we're
  used to it working for functions from $\mathbb R$ to $\mathbb R$. It's a little disconcerting to see it work for functions from $\mathbb R$
  to $\mathbb R^n$.
- But how does this make sense in the case of diffgeo? We start with a manifold $M$. We take some curve $c: (-1, 1) \to M$. It's derivative
  must live as $c': (-1, 1) \to TM$. Now what about $c''$? According to our earlier explanation, this too should be a vector! Well... it is and it isn't,
  right? but how? I don't understand this well.
- Looping back to the original question, $W \equiv \nabla_D V$ is a vector field because the value of $W(p)$ is defined as taking $D(p) \in T_p M$,
  treating it as a curve $d_p: [-1, 1] \to M$ such that $d_p(0) = p$ and $d_p'(0) = D(p)$, and then finally taking $V()$.


# Building stuff with Docker

- create `Dockerfile`, write `docker build .`.
- File contains shell stuff to run in `RUN <cmd>` lines. `<cmd>` can have newlines with backslash ala shell script.
- `docker run <image/layer sha> <command>` to run something at an image SHA (ie, not in a running container). Useful to debug.
  protip: `docker run <sha-of-layer-before-error> /bin/bash` to get a shell.
- `docker run -it <sha-of-build-success-or-failure>` to ssh into the container interactively.
- `docker exec <container-sha> <command>` to run something in a container.
- to delete an image: `docker image ls`, `docker rmi -f <image-sha>`
- docker prune all unused stuff: `docker system prune -a`
- `docker login` to login
- `docker build -t siddudruid/coolname .` to name a docker image.
- `docker push siddudruid/coolname` to push to docker hub.
- `docker pull siddudruid/coolname` to pull from docker hub.




# Lie derivative versus covariant derivative

<img src="./static/lie-bracket-versus-covariant-derivative.png"/>

- Lie derivative cares about all flow lines, covariant derivative cares about a single flow line.
- The black vector field is X
- The red vector field $Y$ such that $L_X Y = 0$. See that the length of the red vectors are compressed as we go towards the right,
  since the lie derivative measures how our "rectangles fail to commute". Thus, for the rectangle to commute, we first (a)
  need a rectangle, meaning we need to care about at least two flows in $X$, and (b) the *flows* (plural) of $X$ force the vector field $Y$
  to shrink.
- The blue vector field $Z$ is such that $\nabla_X Z = 0$. See that this only cares about a single line. Thus to conserve the vectors,
  it needs the support of a metric (ie, to keep perpendiculars perpendicular).


- [Reference question](https://math.stackexchange.com/questions/2145617/lie-vs-covariant-derivative-visual-motivation)



# The Tor functor

Let $A$ be a commutative ring, $P$ an $A$-module. The functors $Tor_i^A(-, P)$ are defined in such a way that

- $Tor_0^A(-,P) = - \otimes_A P$
- For any short exact sequence of $A$-modules $0 \to L \to M \to N \to 0$, you get a long exact sequence.

$$
\dots \to Tor_{n+1}^A(L,P) \to Tor_{n+1}^A(M,P) \to Tor_{n+1}^A(N,P)
\to Tor_n^A(L,P) \to Tor_n^A(M,P) \to Tor_n^A(N,P)
\to \dots
$$

which, on the right side, stops at

$$
\dots \to Tor_1^A(L,P) \to Tor_1^A(M,P) \to Tor_1^A(N,P)
\to L \otimes_A P \to M \otimes_A P \to N \otimes_A P \to 0
$$


```
23:44 <bollu> isekaijin can you describe the existence proof of Tor? :)
23:45 <isekaijin> A projective resolution is a chain complex of projective A-modules “... -> P_{n+1} -> P_n -> ... -> P_1 -> P_0 -> 0” that is chain-homotopic to “0 -> P -> 0”.
23:45 <isekaijin> And you need the axiom of choice to show that it exists in general.
23:45 <isekaijin> Now, projective A-modules behave much more nicely w.r.t. the tensor product than arbitrary A-modules.
23:46 <isekaijin> In particular, projective modules are flat, so tensoring with a projective module *is* exact.
23:47 <isekaijin> So to compute Tor_i(M,P), you tensor M with the projective resolution, and then take its homology.
23:47 <isekaijin> To show that this is well-defined, you need to show that Tor_i(M,P) does not depend on the chosen projective resolution of P.
23:48 <Plazma> bollu: just use the axiom of choice like everyone else
23:48 <bollu> why do you need to take homology?
23:48 <isekaijin> That's just the definition of Tor.
23:49 <isekaijin> Okay, to show that Tor does not depend on the chosen projective resolution, you use the fact that any two chain-homotopic chains have the same homology.
23:49 <bollu> right
23:49 <isekaijin> Which is a nice cute exercise in homological algebra that I am too busy to do right now.
23:49 <bollu> whose proof I have seen in hatcher
23:49 <bollu> :)
23:49 <isekaijin> Oh, great.
23:49 <bollu> thanks, the big picture is really useful
```

# Sum of quadratic errors

- Consider the function $(x - a)^2 + (x - b)^2$
- Minimum error is at $2(x - a) + 2(x - b)$, or at `(a + b)/2`.
- As we move away towards either end-point, the _error always increases_!
- So the "reduction in error" by moving towards `b` from `(a + b)/2` is ALWAYS DOMINATED by the "increase in error"
  by moving towards `a` from `(a + b)/2`.

# Hip-Hop and Shakespeare

- For whatver reason, it appears like iambie pentameter allows one to rap shakespeaker sonnets to 80bmp / 150bpm.
- [TedX talk by  Akala](https://www.youtube.com/watch?v=DSbtkLA3GrY)


# Write thin to write well

- Set column width to be absurdly low which forces your writing to get better (?!)
- That is, when you write, say in vim or emacs, you put one clause per line.
  Then when you are done, you can use pandoc or something similar to convert
  what you wrote into standard prose. But the artificial line breaks, which
  results in thin lines, make it easier to edit, and also easier to comprehend
  diffs if you use git to track changes.


- The vast majority on book typography agrees on 66 characters per line in
  one-column layouts and 45 characters per line in multi-column layouts as
  being the optimal numbers for reading. The text-block should also be placed
  assymetrically on the page, with the margins in size order being
  `inner<top<outer<bottom`. The line height should be set at 120% of the highest
  character hight for normal book typefaces, but should be increased for
  typewriter typefaces and can be decreased slightly with shorter lines. A
  small set of typefaces are economic without losing readability, and if you
  use them you can increase these numbers slightly. But any more than 80
  characters and anything less than 40 characters is suboptimal for texts that
  are longer than a paragraph or so.
- If you adhere to these very simple principles, you will have avoided like 95% of the typographic choices that can make texts hard or slow to read.

- Try 36 letters per column.

```
Also see VimPencil
set wrap linebreak nolist
call plug#begin('~/.vim/plugged')
Plug 'junegunn/goyo.vim'
call plug#end()

"Goyo settings
let g:goyo_width = 60
let g:goyo_height = 999
let g:goyo_margin_top = 0
let g:goyo_margin_bottom = 0
```

- [Write thin to write fast](https://breckyunits.com/write-thin-to-write-fast.html)

# Hidden symmetries of alg varieties

- Given equations in $A$, can find solutions in any $B$ such that we have $\phi: A \to B$
- Can translate topological ideas to geometry.
- Fundamental theorem of riemann: fundamental group with finitely many covering becomes algebraic (?!)
- So we can look at finite quotients of the fundamental group.
- As variety, we take line minus one point. This can be made by considering $xy - 1 = 0$ in $R[x, y]$ and then projecting solutions to $R[x]$.
- If we look at complex solutions, then we get $\mathbb C - \{0 \} = C^\times$.
- The largest covering space is $\mathbb C \xrightarrow{\exp} \mathbb C^\times$. The fiber above $1 \in C^\times$ (which is the basepont) is $2 \pi i$.
- Finite coverings are $C^\times \xrightarrow{z \mapsto z^n} C^\times$. The subsitute for the fundamental group is the projective (inverse) limit
  of these groups.
- The symmetry of $Gal(\overline{\mathbb Q} / \mathbb Q)$ acts on this fundamental group.
- One can get not just fundamental group, but any finite coefficients!
- Category of coverings is equivalent to category of sets with action of fundamental group.
- [Abel Prize: Pierre Delinge](https://www.youtube.com/watch?v=9WavaUED5i8)

# `fd` for `find`

- `fd` seems to be much, much faster at `find` than, well, `find`.

# Thu Morse sequence for sharing

- Suppose A goes first at picking object from a collection of objects, then B.
- B has an inherent disatvantage, since they went second.
- So rather than repeating and allowing A to go third and B to go fourth (ie, we run `ABAB`), we should instead run `AB BA`,
  since giving `B` the third turn "evens out the disatvantage".
- Now once we're done with 4 elements, what do we do? Do we re-run `A B B A` again? No, this would be argued as unfair by `B`. So we flip this
  to get the full sequence as `ABBA BAAB`.
- What next? you guessed it... flip: `ABBA BAAB|BAAB ABBA`
- And so on. Write the recurrence down `:)`
- [Reference](https://www.youtube.com/watch?v=prh72BLNjIk)

# Elementary and power sum symmetric polynomials

- [Borcherds video on newton identites](https://www.youtube.com/watch?v=JG1F1G0S_bo)
- [Terry tao calls the power sum symmetric polynomials as 'moments'](https://mathoverflow.net/questions/402051/distribution-of-some-sums-modulo-p/402109#402109)

- Let us have $n$ variables $x[1], x[2], \dots, x[n]$.
- Let $e_k$ be the elementary symmetric polynomial that is all products of all $k$ subsets of $x[:]$.
- Let $p_k$ be the power sum symmetric polynomial that is of the form $p_k = \sum_i x[i]^k$.

#### Speedy proof when $k = n$ / no. of vars equals largest $k$ (of $e[k]$) we are expanding:

- Let $P(x) = e[n] x^0 + e[n-1]x^1 + \dots + e[1]x^{n-1} + e[0]x^n$. That is, $P(x) = \sum_i e[n-i] x^{i}$
- Let $r[1], r[2], \dots, r[n]$ be the roots. Then we have $P(r[j]) = \sum_i e[n-i] r[j]^{i} = 0$.
- Adding over all  $r[j]$, we find that:

$$
\begin{aligned}
&\sum_{j=1}^k P(r[j]) = \sum_j 0 = 0\\
&\sum_j \sum_i e[n-i] r[j]^{i}  = 0 \\
&\sum_j \sum_i e[n-i] r[j]^{i}  = 0 \\
&\sum_j e[n] \cdot 1 + \sum_j \sum_{i>0}^k e[n-1] r[j]^i  = 0 \\
k e[n] + &\sum_{i=1}^k e[i] P[n-i] = 0
\end{aligned}
$$

#### Concretely worked out in the case where $n = k = 4$:

$$
\begin{aligned}
&P(x) = 1 \cdot x^4 + e_1 x^3 + e_2 x^2 + e_3 x + e_4 \\
&\texttt{roots: } r_1, r_2, r_3, r_4\\
&P(x) = (x - r_1)(x - r_2)(x - r_3)(x - r_4)\\
&e_0 = 1 \\
&e_1 = r_1 + r_2 + r_3 + r_4 \\
&e_2 = r_1r_2 + r_1r_3 + r_1r_4 + r_2r_3 + r_2r_4 + r_3r_4 \\
&e_3 = r_1r_2r_3 + r_1r_2r_4 + r_2r_3r_4 \\
&e_4 = r_1r_2r_3r_4\\
\end{aligned}
$$

- Expanding $P(r_j)$:

$$
\begin{aligned}
P(r_1) &= r_1^4 + e_1r_1^3 + e_2r_1^2 + e_3 r_1 + e_4 = 0 \\
P(r_2) &= r_2^4 + e_1r_2^3 + e_2r_1^2 + e_3 r_1 + e_4 = 0 \\
P(r_3) &= r_3^4 + e_1r_3^3 + e_2r_1^2 + e_3 r_1 + e_4 = 0 \\
P(r_4) &= r_4^4 + e_1r_4^3 + e_2r_1^2 + e_3 r_1 + e_4 = 0 \\
\end{aligned}
$$

- Adding all of these up:

$$
\begin{aligned}
&P(r_1) + P(r_2) + P(r_3) + P(r_4) \\
&=(r_1^4 + r_2^4 + r_3^4 + r_4^4)
&+ e_1(r_1^3 + r_2^3 + r_3^3 + r_2^3)
&+ e_2(r_1^2 + r_2^2 + r_3^2 + r_4^2)
&+ e_3(r_1 + r_2 + r_3 + r_4)
&+ 4 e_4 \\
&= 1 \cdot P_4 e_1 P_3 + e_2 P_2 + e_3 P_1 + 4 e_4 \\
&= e_0 P_4 + e_1 P_3 + e_2 P_2 + e_3 P_1 + 4 e_4 \\
&= 0 \\
\end{aligned}
$$


#### When $k > n$ (where $n$ is number of variables):

- We have the identity $k e_k + \sum_{i=0}^{k-1} e_i p_{k-i} = 0$.
  (when $i = k$, we get $p_{k-i} = p_0 = 1$, this gives us the $k e_i = k e_k$ term).
- When $k > n$, this means that $e_k = 0$.
- Further, when $k > n$, this means that $s_i$ when $i > n$ is zero.
- This collapses the identity to $\sum_{i=0}^{k-1} e_i p_{k-i} = 0$ (we lose $e_k)$,
  which further collapses to $\sum_{i=0}^n e_i p_{k-1} = 0$ (we lose terms where $k - 1 > n$)
- Proof idea: We add ($k-n$) roots into $f$ to bring it to case where $k = n$. Then we set these new roots to $0$ to get the identity
  $\sum_{i=0}^n s_i p_{k-i} = 0$.

#### When $k < n$ (where $n$ is number of variables):


#### Proof by cute notation

- Denote by the tuple $(a[1], a[2], \dots, a[n])$ with $a[i] \geq a[i+1]$ the sum $\sum x[i]^a[i]$.
- For example, with three variables $x, y, z$, we have:
- $(1) = x + y + z$
- $(1, 1) = xy + yz + xz$
- $(2) = x^2 + y^2 + z^2$
- $(2, 1) = x^2y + y^2z + z^2x$
- $(1, 1, 1) = xyz$.
- $(1, 1, 1, 1) = 0$, because we don't have four variables!
  We would need to write something like $xyzw$, but we don't have a $w$, so this is zero.
- In this notation, the elementary symmetric functions are $(1)$, $(1, 1)$, $(1, 1, 1)$ and so on.
- The power sums are $(1)$, $(2)$, $(3)$, and so on.
- See that $(2)(1) = (x^2 + y^2 + z^2)(x + y + z) = x^3 + y^3 + z^3 + x^2y + x^2z + y^2x + y^2z + z^2x + z^2y = (3) + (2, 1)$.
- That is, the product of powers gives us a larger power, plus some change (in elementary symmetric).
- How do we simplify $(2, 1)$? We want terms of the form only of $(k)$ [power sum] or $(1, 1, \dots, 1)$ [elementary].
- We need to simplify $(2, 1)$.
- Let's consider $(1)(1, 1)$. This is $(x + y + z)(xy + yz + xz)$. This will have terms of the form $xyz$ (ie, $(1, 1, 1)$). These occur with multiplicity $3$,
  since $xyz$ can occur as $(x)(yz)$, $(y)(xz)$, and $(z)(xy)$. This will also have terms of the form $x^2y$ (ie, $(2, 1)$).
- Put together, we get that $(1)(1, 1) = (2, 1) + 3 (1, 1, 1)$.
- This tells us that $(2, 1) = (1)(1, 1) - 3(1, 1, 1)$.
- Plugging back in, we find that $(2)(1) = (3) + (1)(1, 1) - 3 (1, 1, 1)$. That is, $p[3] - p[2]s[1] + p[1]s[2] - 3s[3] = 0$.

In general, we will find:

$$
(k-1)(1) = (k) + (k-1, 1) \\
(k-2)(1, 1) = (k-1, 1) + (k-2, 1, 1) \\
(k-3)(1, 1, 1) = (k-2, 1, 1) + (k-3, 1, 1, 1) \\
(k-4)(1, 1, 1, 1) = (k-3, 1, 1, 1) + (k-4, 1, 1, 1, 1) \\
$$

- In general, we have:

```
(k-i)(replicate 1 i) = (k-i+1, replicate 1 [i-1]) + (k-i , replicate 1 i)
```


# Projective spaces and grassmanians in AG

#### Projective space
- Projective space is the space of all lines through $\mathbb R^n$.
- Algebraically constructed as $(V - \{ 0 \})/ \mathbb R^\times$.
- We exclude the origin to remove "degenerate lines", since the subspace spanned by $\{0\}$ when acted on with $\mathbb R^\times$
  is just $\{ 0 \}$, which is zero dimensional.

#### Grassmanian
- $G(m, V)$: $m$ dimensional subspaces of $V$.
- $G(m, n)$: $m$ dimensional subspaces of $V = k^n$.
- $G(m+1, n+1)$ is the space of $m$ planes $\mathbb P^m$ in $\mathbb P^n$. Can projectivize $(n+1)$ eqns by sending $(x_0, x_1, \dots, x_n) \in k^{n+1}$ to
  $[x_0 : x_1 : \dots : x_n] \in \mathbb P^n$.
- Duality: $G(m, V) ≃ G(dim(V)-m, V^\star)$. We map the subspace $W \subseteq V$ to the annihilator of $W$ in $V^\star$: That is, we map $W$ to the set of
  all linear functionals that vanish on $W$ [ie, whose kernel is $W$].
- The above implies $G(1, V) = G(n-1, V)$. $G(1, V)$ is just projective space $\mathbb P^1$.
  $n-1$ subspaces are cut out by linear equations, $c_0 x_0 + \dots c_{n-1} x_{n-1} + c_n = 0$.

#### G(2, 4)

- These are lines in $\mathbb P^3$. This will give us two pairs of points of the form $(x_0, y_0, z_0, w_0)$ and $(x_1, y_1, z_1, w_1)$.
  That is, we're considering "lines" between "points" (or "vectors") in $\mathbb R^3$. Exactly what we need to solve stabbing line problems
  for computer graphics :)
- Start by taking a 2D plane. The line will pass through a point in the 2D plane. This gives us two degrees of freedom.
- Then take a direction in ordinary Euclidean $\mathbb R^3$ (or $S^2$ to be precise). This gives us two degrees of freedom.
- Can also be said to be a 2-dim. subspace of a 4-dim. vector space.
- In total, $G(2, 4)$ should therefore have four degrees of freedom.
- Take $W \subseteq V$  where $V \simeq k^4$, and $W$ is 2-dimensional subspace.
- $W$ is spanned by two vectors $v_1, v_2$. So I can record it as a $2x1$ matrix:
   $\begin{bmatrix} a_{11} & a_{12} & a_{13} & a_{14} \\ a_{21} & a_{22} & a_{23} & a_{24} \end{bmatrix}$. Vector $v_i$ has coordinates $a_i$.
- If I had taken another basis $(v_1', v_2')$, there would be an invertible matrix $B \in K^{2 \times 2}$ ($det(B) \neq 0$)
  that sends $(v_1, v_2)$ to $(v_1', v_2')$. Vice Versa, any invertible matrix $B$ gives us a new basis.
- So the redundancy in our choice of parametrization of subspaces (via basis vectors) is captured entirely by the space of $B$s.
- Key idea: compute $2 \times 2$ minors of the  $2 \times 4$ matrix $(v_1, v_2)$.
- This is going to be $(a_{11} a_{22} - a_{12} a_{21}, \dots, a_{13} a_{24} - a_{14} a_{23}) \in K^6$.
- Note here that we are computing $2$ minors of a rectangluar matrix, where we take all possible $2 \times 2$ submatrices and calculate their
  determinant.
- In this case, we must pick both rows, and we have $\binom{4}{2} = 6$ choices of columns, thus we live in $K^6$.
- We represent this map as $m: K^{2 \times 4} \to K^6$ which sends $m((a_{ij})) \equiv (a_{11} a_{22} - a_{12} a_{21}, \dots, a_{13} a_{24} - a_{14} a_{23})$
  which maps a matrix to its vector of minors.
- The great advantage of this is that we have $m(B \cdot (a_{ij})) = det(B) \cdot m((a_{ij}))$, since the minor by definition takes a determinant of submatrices,
  and determinant is multiplicative.
- Thus, we have converted a _matrix_ redundancy of $B$ in $a_{ij}$ into a  **scalar** redundancy (of $det(B)$) in $m(a_{ij})$ .
- We know how to handle scalar redundancies: Live in projective space!
- Therefore, we have a well defined map $G(2, 4) \to \mathbb P^5$. Given a subspace $W \in G(2, 4)$, compute a basis $v_1, v_2 \in K^4$ for $W$,
  then compute the minor of the matrix $m((v_1, v_2)) \in K^6$, and send this to $P^5$.

#### $G(2, 4)$, projectively
- These are lines in $\mathbb P^3$.
- So take two points in $P^3$, call these $[a_0 : a_1 : a_2 : a_3]$ and $[b_0 : b_1 : b_2 : b_3]$. Again, this gives us a matrix:

$$
\begin{bmatrix}
a_0 &: a_1 &: a_2 &: a_3 \\
b_0 &: b_1 &: b_2 &: b_3 \\
\end{bmatrix}
$$

- We define $S_{ij} \equiv a_i b_j - a_j b_i$ which is the minor with columns $(i, j)$.
- Then we compress the above matrix as $(S_{01} : S_{02} : S_{03} : S_{12} : S_{13} : S_{23}) \in \mathbb P^5$.  See that $S_{ii} = 0$ and $S_{ji} = - S_{ij}$.
  So we choose as many $S$s as "useful".
- See that if we change $a$ or $b$ by a constant, then all the $S_{ij}$ change by the constant, and thus the point itself in $\mathbb P^5$ does not change.
- We can also change $b$ by adding some scaled version of $a$. This is like adding a multiple of the second row to the first row when taking determinants.
  But this does not change determinants!
- Thus, the actual plucker coordinates are invariant under which two points $a, b$ we choose to parametrize the line in $\mathbb P^3$.
-  This gives us a well defined map from lines in $\mathbb P^3$ to points in $\mathbb P^5$.
- This is not an onto map; lines in $\mathbb P^3$ have dimension 4 (need $3 + 1$ coefficiens, $ax + by + cz + d$),
  while $\mathbb P^5$ has dimension $5$.
- So heuristically, we are missing "one equation" to cut $\mathbb P^5$ with to get the image of lines in $\mathbb P^3$ in $\mathbb P^5$.
- This is the famous Plucker relation:

$$
S_{02} S_{13} = S_{01} S_{23}  + S_{03} S_{12}
$$

- It suffices to prove the relationship for the "standard matrix":

$$
\begin{bmatrix}
1 &: 0 &: a &: b \\
0 &: 1 &: c &: d \\
\end{bmatrix}
$$

- In this case, we get c (-b) = 1(ad - bc) + d (-a)

- In general, we get _plucker relations_:

$$
S_{i_1 \dots i_k}S_{j_1 \dots j_k} = \sum S_{i_1' \dots i_k'} S_{j_1' j_k'}.
$$


#### Observations of $G(2, 4)$

- Suppose $m(v_1, v_2) = (a_{ij})$ has non-vanishing first minor. Let $B$ be the inverse of the first minor matrix.
  So $B \equiv \begin{bmatrix} a_{11} & a_{12} \\ a_{21} & a_{22} \end{bmatrix}$. Set $(v_1', v_2') \equiv B (v_1, v_2)$.
- Then $m(v_1', v_2') = \begin{bmatrix} 1 & 0 & y_{11} & y_{12} \\ 0 & 1 & y_{21} & y_{22} \end{bmatrix}$.
- So the first $2 \times 2$ block is identity. Further, the $y_{ij}$ are unique.
-  As we vary $y_{ij}$, we get we get different 2 dimensional subspaces in $V$. Thus, locally, the grassmanian
   looks like $A^4$. This gives us an affine chart!
- We can recover grassmanian from the $\mathbb P^5$ embedding. Let $p_0, \dots, p_5$ be the coordinate functions on $\mathbb P^5$ ($p$ for plucker).
- The equation $p_0 p_5 - p_1 p_4 + p_2 p_3$ vanishes on the grassmanian. We can show that the zero set of the equation is *exactly* the grassmanian.

- [Computation AG: Grassmanians](https://www.youtube.com/watch?v=EPUl-J4_4sk&list=PL5ErEZ81Tyqc1RixHj65XA32ejrS2eEFK&index=14)


#### Computing cohomology of $G(2, 5)$

- Take all points of the following form:

$$
\begin{bmatrix}
&1 &:0 &:* &:* \\
&0 &:1 &:* &:*
\end{bmatrix}
$$

- Let's look at the first column: it is $\begin{bmatrix} 1 \\ 0 \end{bmatrix}$. Why not $\begin{bmatrix} 1 \\ 1 \end{bmatrix}$? Well, I can always
  cancel the second row by subtracting a scaled version of the first row! (this doesn't change the determinants). Thus, if we have a $1$ somewhere,
  the "complement" must be a $0$.
- Next, we can have something like:

$$
\begin{bmatrix}
&1 &:* &:0 &:* \\
&0 &:0 &:1 &:*
\end{bmatrix}
$$

- Here, at the second second column $\begin{bmatrix} * \\ 0 \end{bmatrix}$, if we didn't have a $0$, then we could have standardized it and put it into
  the form of $\begin{bmatrix} 0 \\ 1 \end{bmatrix}$ which makes it like the first case! Thus,we _must_ have a $0$ to get a case different from the previous.

- Continuing, we get:

$$
\begin{bmatrix}
&1 &:* &:* &:0 \\
&0 &:0 &:0 &:1
\end{bmatrix}
$$

$$
\begin{bmatrix}
&0 &:1 &:0 &:* \\
&0 &:0 &:1 &:*
\end{bmatrix}
$$

$$
\begin{bmatrix}
&0 &:1 &:* &:0 \\
&0 &:0 &:0 &:1
\end{bmatrix}
$$

$$
\begin{bmatrix}
&0 &:0 &:1 &:0 \\
&0 &:0 &:0 &:1
\end{bmatrix}
$$

- If we count the number of $\star$s, which is the number of degrees of freedom, we see that $1$ of them (the last one) has zero stars ($A^0$),
  $1$ of them has 1 star ($A^1$), two of them have 2 stars ($A^2$), one of them has 3 stars, and one of them as 4 stars.
- This lets us read off the cohomology of the grassmanian: we know the cellular decomposition. Ie, we know the number of $n$ cells for different dimensions.
- Alternatively, we can see that over a finite field $k$, we have $k^0 + k^1 + 2k^2 + k^3 + k^4$ points. On the other hand, $\mathbb P^4$ has
  $k^0 + k^1 + k^2 + k^3 + k^4$ points. Thus the grassmanian is different from projective space!
- [Borcherds](https://www.youtube.com/watch?v=bKB4Qu8ETNE&list=PL8yHsr3EFj53j51FG6wCbQKjBgpjKa5PX&index=19)


# Mnemonic for why `eta` is unit:

- Remember that given an adjunction $F \vdash G$, the unit of the adjunction is $\eta: 1 \to GF$.
- We use the symbol `eta` because it's `yunit`, and `eta` is `y` in `greek` (which is why the vim digraph for `eta` is `C-k y*`)
- $\eta$ is `unit`, since when you flip it, you get $\mu$, which is $\mu$-ltiplication (multiplication). Hence $\eta$ is the unit for the multiplication
  to form a monoidal structure for the monad.

# Fundamental theorem of galois theory

- Let $K \subseteq M$ is a finite galois extension (normal + separable), then there a 1:1 correspondence between intermediate fields $L$
  and subgroups of the galois group $G = Gal(M/K)$.
- Recall that a finite extension has finitely many subfields iff it can be written as an extension $K(\theta)/K$. This is the primitive element theorem.
- We send $L \mapsto Gal(M/L)$, the subgroup of $Gal(M/K)$ that fixes $L$ pointwise.
- We send $H$ to $fix(H)$, the subfield of $K$ that is fixed pointwise.

#### $H =  Gal(M/Fix(H))$
- It is clear that $H \subseteq Gal(M/Fix(H))$, by definition, since every element of $H$ fixes $Fix(H)$ pointwise.
- To show equality, we simply need to show that they are the same size, in terms of cardinality.
- So we will show that $|H| = |Gal(M/Fix(H))|$..

#### $L =  Fix(Gal(L/K))$
- It is clear that $L \subseteq Fix(Gal(M/L)))$, by definition, since every element of $Gal(M/L)$ fixes $L$ pointwise.
- To show equality, we simply need to show that they are the same size.
- Here, we measure size using $[M:L]$. This means that as $L$ becomes larger, the "size" actually becomes smaller!
- However, this is the "correct" notion of size, since we will have the size of $L$ to be equal to $Gal(L/K)$.
- As $L$ grows larger, it has fewer automorphisms.
- So, we shall show that $[M:L] = [M:Fix(Gal(L/K))]$.

#### Proof Strategy

- Rather than show that the "round trip" equalities are correct, we will show that the intermediates match in terms of size.
- We will show that the map $H \to Fix(H)$ is such that $|H| = [M:H]$.
- Similarly, we will show that the map $L \mapsto Gal(L/K)$ is such that $[M:K] = |L|$.
- This on composing $Gal$ and $Fix$ show both sides shows equality.

#### Part 1: $H \to Fix(H)$ preserves size

- Consider the map which sends $H \mapsto Fix(H)$. We need to show that $|H| = [M:Fix(H)]$.
- Consider the extension $M/Fix(H)$. Since $M/K$ is separable, so in $M/Fix(H)$ [polynomials separable over $K$ remain separable over super-field $Fix(H)$]
- Since the extension is separable, we have a $\theta \in M$ such that $M = Fix(H)(\theta)$ by the primitive element theorem.
- The galois group of $M/Fix(H) = Fix(H)(\theta)/Fix(H)$ must fix $Fix(H)$ entirely.
  Thus we are trying to extend the function $id: Fix(H) \to Fix(H)$
  to field automorphisms $\sigma: M \to M$.
- Since $M/K$ is normal, so is $M/Fix(H)$, since $M/K$ asserts that automorphisms $\sigma: M \to \overline K$ that fix $K$ stay within $M$.
  This implies that automorphisms $\tau: M \to \overline K$ that fix $Fix(H)$ stay within $M$.
- Thus, the number of field automorphisms $\sigma: M \to \overline M$ that fix $Fix(H)$ is equal to the number of field automorphisms $M \to M$
  that fix $Fix(H)$.
- The latter is equal to the field of the separable extension $[M:Fix(H)]$, since the only choice we have is where we choose to send $\theta$,
  and there are $[M:Fix(H)]$ choices.
- The latter is also equal to the size of the galois group

#### Part 2: $L$ to $Gal(M/L)$ preserves size

- We wish to show that $[M:L] = |Gal(M/L)|$
- Key idea: Start by writing $M = L(\alpha)$ since $M$ is separable by primitive element theorem.
  Let $\alpha$ have minimal polynomial $p(x)$. Then $deg(p(x))$ equals $[M:L]$ equals number of roots of $p(x)$ since the field is separable.
- Next, any automorphism
  $\sigma: M \to M$ which fixes $L$  is uniquely determined by where it sends $\alpha$. Further, such an automorphism $\sigma$
  must send $\alpha$ to some other root of $p(x)$ [by virtue of being a field map that fixes $L$,  $0 = \sigma(0) = \sigma(p(\alpha)) = p(\sigma(\alpha))$].
- There are exactly number of roots of $p$ (= $[M:L]$) many choices. Each gives us one automorphism. Thus $|Gal(M/L)| = [M:L]$.

# Counter-intuitive linearity of expectation [TODO]

- I like the example of "10 diners check 10 hats. After dinner they are given the hats back at random."
  Each diner has a 1/10 chance of getting their own hat back, so by linearity of expectation, the expected number of diners who get the correct hat is 1.

- Finding the expected value is super easy. But calculating any of the individual probabilities (other than the 8, 9 or 10 correct hats cases) is really annoying and difficult!


- Imagine you have 10 dots scattered on a plane. Prove it's always possible to cover all dots with disks
  of unit radius, without overlap between the disks.
   (This isn't as trivial as it sounds, in fact there are configurations of 45 points that cannot be covered by disjoint unit disks.)

- Proof: Consider a repeating honeycomb pattern of infinitely many disks. Such a pattern covers pi / (2 sqrt(3)) ~= 90.69% of the plane, and the disks are clearly disjoint. If we throw such a pattern randomly on the plane, any dot has a 0.9069 chance of being covered, so the expectation value of the total number of dots being covered is 9.069. This is larger than 9, so there must be a packing which covers all 10 dots.


# Metis

> So insofar as Athena is a goddess of war, what really do we mean by that? Note that her most famous weapon is not her sword but her shield Aegis, and Aegis has a gorgon's head on it, so that anyone who attacks her is in serious danger of being turned to stone. She's always described as being calm and majestic, neither of which adjectives anyone ever applied to Ares....

> Let's face it, Randy, we've all known guys like Ares. The pattern of human behavior that caused the internal mental representation known as Ares to appear in the minds of the ancient Greeks is very much with us today, in the form of terrorists, serial killers, riots, pogroms, and agressive tinhorn dictators who turn out to be military incompetents. And yet for all their stupidity and incompetence, people like that can conquer and control large chunks of the world if they are not resisted....

> Who is going to fight them off, Randy?

> Sometimes it might be other Ares-worshippers, as when Iran and Iraq went to war and no one cared who won. But if Ares-worshippers aren't going to end up running the whole world, someone needs to do violence to them. This isn't very nice, but it's a fact: civilization requires an Aegis. And the only way to fight the bastards off in the end is through intelligence. Cunning. Metis.

# Tooling for performance benchmarking

- Optick and Tracy and flame graphs
- https://github.com/wolfpld/tracy
- https://www.brendangregg.com/FlameGraphs/cpuflamegraphs.html
- Hotspot:  https://www.kdab.com/hotspot-video/amp/
- `perf stat -x` apparently gives CSV?


# Normal field extensions

## Normal extension

- (1) For an extension $L/K$, if a polynomial $p(x) \in K[x]$ and has a root $\alpha \in L$ has _all_ its roots in $L$. So $p(x)$
  splits into linear factors $p(x) = (x - l_1)(x - l_2) \cdot (x - l_n)$ for $l_i \in L$.
- (2) [equivalent] $L$ is the splitting field over $K$ of some _set_ of polynomials.
- (3) [equivalent] Consider $K \subseteq L \subseteq \overline K$. Then any automorphism of $\overline K/K$ (ie, aut that fixes $K$ pointwise)
  maps $L$ to $L$ [fixes $L$ as a set, NOT pointwise].
- Eq: $Q(2^{1/3})$ is not normal
- Eq: $Q(2^{1/3}, \omega_3)$ is a normal extension because it's the splitting field of $x^3 - 2$.

#### (1) implies (2)

- (1) We know that $p$ has a root in $L$ implies $p$ has all rots in $L$.
- For each $\alpha \in L$, we take the minimal polynomial $p(\alpha)$. Then $p$ splits over $L$, because $L$ contains a single root of $p$ ($\alpha$).
- Thus, $L$ is the splitting field for the set of polynomials $\{ minpoly(\alpha) \in K[x] : \alpha \in L \}$.

#### (2) implies (3)

- (2) says that $L$ is the splitting field for some set of polynomials.
- An aut $\sigma: \overline K \to \overline K$ that fixes $K$ acts trivially on polynomials in $K[x]$.
- $L$ is the set of all roots of polynomials $\{ minpoly(\alpha) \in K[x] : \alpha \in L \}$.
- Since $\sigma$ fixes $K[x]$, it also cannot change the set of roots of the polynomials. Thus the set $\{ minpoly(\alpha) \in K[x] : \alpha \in L \}$
  remains invariant under $\sigma$. ($\sigma$ cannot add elements into $L$). It can at most permute the roots of $L$.

#### (3) implies (1)

- (3) says that any automorphism $\sigma$ of $\overline K/K$ fixes $L$ as a set.
- We wish to show that if $p$ has a root $\alpha \in L$, $L$ has all roots of $p$.
- we claim that for any root $\beta \in L$, there is an automorphism $\tau: \overline K/K$ such that $\tau(\alpha) = \beta$.
- Consider the tower of extensions $K \subseteq K(\alpha) \subseteq \overline K$ and $K \subseteq K(\beta) \subseteq \overline K$.
  Both $K(\alpha)$ and $K(\beta)$ look like $K[x] / p$ because $p$ is the minimal polynomial for _both_ $\alpha$ and $\beta$.
- Thus, we can write an a function $\tau: K(\alpha) \to K(\beta)$ which sends $\alpha \mapsto \beta$.
- Now, by uniqueness of field extensions, this map $\tau$ extends uniquely to a map $\overline K \to \overline K$ which sends $\alpha to \beta$. [TODO: DUBIOUS].
- But notice that $\tau$ must fix $L$ (by (3)) and $\alpha in L$. Thus, $\tau(\alpha) \in \tau(L)$, or $\beta = \tau(\alpha \in \tau(L) = L$.
- Thus, for a polynomial $p$ with root $\alpha in L$, and for any other root $\beta$ of $p$, we have that $\beta \in L$.

#### Alternative argument: Splitting field of a polynomial is normal

- Let $L/K$ be the splitting field of $f \in K[x]$. Let $g \in K[x]$ have a root $\alpha \in L$.
- Let $\beta \in \overline K$ be another root of $g$. We wish to show that $\beta \in L$ to show that $L$ is normal.
- There is an embedding $i: K(\alpha) \hookrightarrow \overline K$ which fixes $K$ and sends $\alpha$ to $\beta$.
- See that $i(L)$ is also a splitting field for $f$ over $K$ inside $\overline K$.
- But splitting fields are unique, so $i(L) = L$.
- Since $i(\alpha) = \beta$, this means $\beta \in L$ as desired.

#### Degree 2 elements are normal

- Let us have a  degree 2 extension $K \subseteq L$
- So we have some $p(x) = x^2 + bx + c \in K[x]$, $L = K(\alpha)$ for $\alpha$ a root of $p$.
- We know that $\alpha + \beta = b$ for $\alpha \in L, b \in K$. Thus $\beta = b - \alpha \in L$.
- Thus, the extension is normal since $L$ contains all the roots ($\alpha, \beta$) of $p$ as soon as it contained one of them.


#### Is normality of extensions transitivte?

- Consider $K \subseteq L \subseteq M$. If $K \subseteq L$ is normal, $L \subseteq M$ is normal, then is $K \subseteq M$ normal?
- Answer: NO!
- Counter-example: $Q \subseteq Q(2^{1/2}) \subseteq Q(2^{1/4})$.
- Each of the two pieces are normal since they are degree two. But the full tower is not normal, because $Q(2^{1/4})/Q$ has minimial polynomial $x^4 - 2$.
- On the other hand, $Q(2^{1/4})/Q(2^{1/2})$ has a minimal polynomial $x^2 - \sqrt{2} \in Q[2^{1/2}]$.
- So, normality is not transitive!
- Another way of looking at it: We want to show that $\sigma(M) \subseteq M$ where $\sigma: aut(\overline K/K)$. Since $L/K$ is normal, and $\sigma$ is an
  autormophism of $L/K$, we have $\sigma(L) \subseteq L$ [by normal]. Since $M/L$ is normal, we must have $\sigma(M) \subseteq M$. Therefore, we are done?
- NO! The problem is that $\sigma$ is not a legal automorphism of $M/L$, since $\sigma$ fixes $L$ as a *set* ($\sigma L \subseteq L$),
  and not *pointwise* ($\sigma(l) = l$ for all $l \in L$.)

# Eisenstein Theorem for checking irreducibility

- Let $p(x) = a_0 + a_1 x + \dots + a_n x^n$
- If $p$ divides all coefficients except for the highest one ($a_n$), $a_0$ is $p$-squarefree ($p^2$ does not divide $a_0$), then $p(x)$ is irreducible.
- That is, $p | a0, p | a_1$, upto $p | a_{n-1}$, $p \not | a_n$, and finally $p^2 \not | a_0$.
- Then we must show that $p(x)$ is irreducible.
- Suppose for contradiction that $p(x) = q(x)r(x)$ where $q(x) = (b_0 + b_1 x+ \dots + b_k x^k)$ and $r(x) = (c_0 + c_1 x + \dots c_l x^l)$ (such that $k + l \geq n$,
  and $k > 0, l > 0$).
- See that $a_0 = b_0 c_0$. Since $p | a_0$, $p$ must divide one of $b_0, c_0$. Since $p^2$ **does not divide** $a_0$, $p$ cannot divide **both** $b_0, c_0$.
  WLOG, suppose $p$ divides $b_0$, and $p$ **does not divide** $c_0$.
- Also see that since $a_n = (\sum_{i + j = n} b_i c_j)$, $p$ does not divide this coefficient $\sum_{i + j = n} b_i c_j$. Thus, at least one term
   in $\sum_{i + j = n} b_i c_j$ is not divisible by $p$.
- Now, we know that $p$ divides $b_0$, $p$ does not divide $c_0$. We will use this as a "domino" to show that $p$ divides $b_1$, $b_2$, and so on, all the way upto $b_k$.
  But this will imply that the final term $a_n$ will also be divisible by $p$, leading to contradiction.
- To show the domino effect, start with the coefficient of $x$, which is $a_1 = b_0 c_1 + b_1 c_0$. Since $a_1$ is divisible by $p$, $b_0$ is divisible by $p$, and $c_0$ is
  **not** divisible by $p$, the whole equation reduces to $b_1 c_0 \equiv_p 0$, or $b_1 \equiv_p 0$ [since $c_0$ is a unit modulo $p$].
- Thus, we have now "domino"'d to show that $p$ divides **both** $b_0, b_1$.
- For induction, suppose $p$ divides everything $b_0, b_1, \dots, b_r$. We must show that $p$ divides $b_{r+1}$.
- Consider the coefficient of the term $xri$, ie $a_r$. This is divisible by $p$, and we have that $a_r = b_0 c_r + b_1 c_{r-1} + \dots + b_r c_0$. Modulo $p$, the left
  hand side vanishes (as $a_r$ is divisible by $p$), and every term $b_0, b_1, \dots, b_{r-1}$ vanishes, leaving behind $0 \equiv_p b_r c_0$. Since $c_0$ is a unit, we get
  $b_r \equiv_p 0$.
- Thus, every term $\{ b_i \}$ is divisible by $p$, implying $a_n$ is divisible by $p$, leading to contradiction.
- Again, the key idea: (1) $b_0$ is divisible by $p$ while $c_0$ is not. (This uses $p | a_0$ and $p^2 \not | a_0$).
  (2) This allows us to "domino" and show that all $b_i$ are divisible by $p$ (This uses $p | a_i$). (3) This
  show that $a_n$ is divisible by $p$, a contradiction. (This uses $p \not | a_n$).

# Gauss Lemma for polynomials

- Let $z(x) \in Z[X]$ such that $z(x) = p(x) q(x)$ where $p(x), q(x) \in Q[X]$. Then we claim that there exists
  $p'(x), q'(x) \in Z[x]$ such that $z(x) = p'(x) q'(x)$.
- For example, suppose $p(x) = a_0 / b_0 + a_1 x / b_1$ and $q(x) = c_0 / d_0 + c_1 x / d_1$, such that $p(x)q(x) \in \mathbb Z[x]$ and these
  fractions are in lowest form. So, $b_i \not | a_i$ and $d_i \not | c_i$.
- Take common demoniator, so we can then find things the denominator divides to write as a product in $\mathbb Z$. For example, we know that
  $9/10 \cdot 20 / 3 = 6$. This can be obtained by rearranging the product as $(9/3) \cdot (20/10) = 3 \cdot 2 = 6$. We wish to perform a similar rearrangement,
  by first writing $9/10 \cdot 20 / 3$ as $(9 \cdot 20)/(10 \cdot 3)$, and then pairing up $10 \leftrightarrow 20$ and $3 \leftrightarrow 9$ to get the final
  integer $(9/3) (20/10) = 6$. After pairing up, each of the pairs $(9/3)$ and $(20/10)$ are clearly integers.
- Take common demoniator in $p(x)$ and write it as a fraction: $p(x) = (a_0 b_1 + (a_1 b_0)x) / b_0 b_1$, and similarly $q(x) = (c_0 d_1 + (c_1 d_0)x)/d_0 d_1$.
- We claim that the denominator of $p(x)$, $b_0 b_1$ **does not divide** the numerator of $p(x)$, $(a_0 b_1 + (a_1 b_0)x)$. This can be seen term-by-term.
  $b_0 b_1$ does not divide $a_0 b_1$ since $a_0 b_1 / b_0 b_1 = a_0 / b_0$ which was assumed to be in lowest form, and a real fraction. Similarly for all terms
  in the numerator.
- Since the product $p(x)q(x)$ which we write as fractions as  $(a_0 b_1 + (a_1 b_0)x) (c_0 d_1 + (c_1 d_0)x) / (b_0 b_1)(d_0 d_1)$ is integral, we must have that
  $b_0 b_1$ divides the numerator. Since $b_0 b_1$ **does not divide** the first factor $(a_0 b_1 + (a_1 b_0)x)$,
  it **must divide** the second factor $(c_0 d_1 + (c_1 d_0)x)$. Thus, the polynomial
  $q'(x) \equiv (c_0 d_1 + (c_1 d_0)x)/b_0 b_1$ is therefore integral [ie, $q'(x) \in Z[x]$].
- By the exact same reasoning, we must have $d_0 d_1$ divides the product $p(x)q(x)$.
  Since $d_0 d_1$ does not divide $(c_0 d_1 + (c_1 d_0)x)$, it must divide (a_0 b_1 + (a_1 b_0)x) and therefore $p'(x) \equiv (a_0 b_1 + (a_1 b_0)x)/(d_0 d_1)$
  is integral.
- Thus, we can write $z(x) = p'(x) q'(x)$ where $p'(x), q'(x) \in \mathbb Z[x]$.
- This generalizes, since we never used anything about being linear, we simply reasoned term by term.


#### Alternate way to show that the factorization is correct.

- Start at $p(x)q(x) = (a_0 b_1 + (a_1 b_0)x) (c_0 d_1 + (c_1 d_0)x) / (b_0 b_1)(d_0 d_1)$.
- Rewrite as  $ p(x)q(x) \cdot (b_0 b_1)(d_0 d_1) = (a_0 b_1 + (a_1 b_0)x) (c_0 d_1 + (c_1 d_0)x)$
- Suppose $\alpha$ is a prime factor of $b_0$. Then reduce the above equation mod $\alpha$. We get $0 \equiv_\alpha (a_0 b_1 + (a_1 b_0)x) (c_0 d_1 + (c_1 d_0)x)$.
  Since $\mathbb Z/\alpha \mathbb Z[x]$ is an integral domain, we have that one of $(a_0 b_1 + (a_1 b_0)x)$ or $(c_0 d_1 + (c_1 d_0)x)$ vanishes, and thus $p$
  divides one of the two.
- This works for all prime divisors of the denominators, thus we can "distribute" the prime divisors of the denominators across the two polynomials.
- Proof that $Z/\alpha Z[x]$ is an integral domain: note that $Z/\alpha Z$ is a field, thus $Z/ \alpha Z[x]$ is a Euclidean domain (run Euclid algorithm).
  This implies it is integral.

# How GHC does typeclass resolution

- As told to me by davean:

- Its like 5 steps
- Find all instances I that match the target constraint; that is, the target constraint is a substitution instance of I.
  These instance declarations are the candidates.
- If no candidates remain, the search fails. Eliminate any candidate IX
- for which there is another candidate IY such that both of the following hold:
  IY is strictly more specific than IX. That is, IY is a substitution instance
  of IX but not vice versa. Either IX is overlappable, or IY is overlapping.
  (This “either/or” design, rather than a “both/and” design, allow a client to
  deliberately override an instance from a library, without requiring a change
  to the library.)
- If all the remaining candidates are incoherent, the search succeeds,
  returning an arbitrary surviving candidate.
- If more than one non-incoherent candidate remains, the search fails.
- Otherwise there is exactly one non-incoherent candidate; call it the “prime
  candidate”.
- Now find all instances, or in-scope given constraints, that unify with the
  target constraint, but do not match it. Such non-candidate instances might
  match when the target constraint is further instantiated. If all of them are
  incoherent top-level instances, the search succeeds, returning the prime
  candidate. Otherwise the search fails.
- [GHC manual](https://ghc.gitlab.haskell.org/ghc/doc/users_guide/exts/instances.html#overlapping-instances)

# Defining continuity covariantly

- Real analysis: coavriant definition: $f(\lim x) = \lim (f x)$. Contravariant definition in analysis/topology: $f^{-1}(open)$ is open.
- Contravariant in topology via sierpinski: $U \subseteq X$ is open iff characteristic function
  $f(x) = \begin{cases} T & x \in U \\ \bot & \text{otherwise} \end{cases}$
  is continuous.
- A function $f: X \to Y$ is continuous iff every function $f \circ s$ is continuous for every continuous $s: Y \to S$. That is, a function is continuous iff
  the pullback of every indicator is an indicator.
- A topological space is said to be *sequential* iff every *sequentially open set* is open.
- A set $K \subseteq X$ is sequentially open iff whenever a sequence $x_n$ has a limit point in $K$, then there is some $M$ such that $x_{\geq M}$ lies in $K$. [TODO: check]
- Now consider $\mathbb N_\infty$, the one point compactification of the naturals. Here, we add a point called $\infty$ to $\mathbb N$, and declare
  that sets which have a divergent sequences and $\infty$ in them are open.
- More abstractly, we declare all sets that are complements of closed and bounded sets with
  infinity in them as open. So a set $U \subseteq \mathbb N_{\infty}$ is bounded iff there exists a closed bounded
  $C \subseteq \mathbb N$ such that $U = \mathbb N / C \cup \{ infty \}$.
- A function $x: \mathbb N_\infty to X$ is continuous [wrt above topology] iff the sequence $x_n$ converges to the limit $x_\infty$.
- See that we use functions out of $\mathbb N_\infty$ [covariant] instead of functions into $S$ [contravariant].
- Now say a function $f: X \to Y$ is sequentially continuous iff for every continuous $x: \mathbb N_\infty \to X$, the composition $f \circ x: \mathbb N_\infty \to Y$
  is continuous. Informally, the pushforward of every convergent sequence is continuous.
- Can show that the category of sequential spaces is **cartesian closed**.
- Now generalize $\mathbb N_\infty$
- https://twitter.com/EscardoMartin/status/1444791065735729155

# Why commutator is important for QM

- Suppose we have an operator $L$ with eigenvector $x$, eigenvalue $\lambda$. So $Lx = \lambda x$.
- Now suppose we have another operator $N$ such that $[L, N] = \kappa N$ for some constant $\kappa$.
- Compute $[L, N]x = \kappa Nx$, which implies:

$$
\begin{aligned}
&[L, N]x = \kappa Nx \\
&(LN - NL)x = \kappa Nx \\
&L(Nx) - N(Lx) = \kappa Nx \\
&L(Nx) - N(\lambda x) = \kappa Nx \\
&L(Nx) - \lambda N(x) = \kappa Nx \\
&L(Nx) = \kappa Nx + \lambda Nx  \\
&L(Nx) = (\kappa + \lambda)Nx  \\
\end{aligned}
$$

- So $Nx$ is an eigenvector of $L$ with eigenvalue $\kappa + \lambda$.
- This is how we get "ladder operators" which raise and lower the state. If we have a state $x$ with some eigenvalue $\lambda$, the operator like $N$
  gives us an "excited state" from $x$ which eigenvalue $\kappa + \lambda$.

# Deriving pratt parsing by analyzing recursive descent [TODO]


# Level set of a continuous function must be closed

- Let $f$ be continuous, let $L \equiv f^{-1}(y)$ be a level set. We claim $L$ is closed.
- Consider any sequence of points $s: \mathbb N \to L$. We must have $f(s_i) = y$
  since $s(i) \in L$. Thus, $f(s_i) = y$ for all $i$.
- By continuity, we therefore have $f(\lim s_i) = \lim f(s_i) = y$.
- Hence, $\lim s_i \in L$.
- This explains why we build Zariski the way we do: the level sets of functions
  must be closed. Since we wish to study polynomials, we build our topology out of the
  level sets of polynomials.


# HPNDUF - Hard problems need design up front!
- [Norvig v/s some TDD due try to solve sudoku](http://ravimohan.blogspot.com/2007/04/learning-from-sudoku-solvers.html)


# Separable Extension is contained in Galois extension

- Recall that an extension is galois if it is separable and normal.
- Consider some separable extension $L/K$.
- By primitive element, can be written as $L = K(\alpha)$
- Since $L$ is separable, the minimal polynomial of $\alpha$, $p(x) \in K[x]$ is separable, and so splits into linear factors.
- Build the splitting field $M$ of $p(x)$. This will contain $L$, as $L = K(\alpha) \subseteq K(\alpha, \beta, \gamma, \dots)$
  where $\alpha, \beta, \gamma, \dots$ are the roots of $p(x)$.
- This is normal (since it is the splitting field of a polynomial).
- This is separable, since it is generated by separable elements $\alpha$, $\beta$, $\gamma$, and so on.


# Primitive element theorem

- Let $E/k$ be a finite extension. We will characterize when a primitive element exists, and show that
  this will always happen for separable extensions.

#### Try 0: Naive attempt

- We try to find some element $\theta \in E$ such that the multiplicative subgroup generated by $\theta$,
  $\{1, \theta, \theta^2, dots\}$ generate $E$.
- However, to find such an element is our mandate!
- What we can do, however, is to take arbitrary elements of the form $\alpha, \beta, \gamma, \delta$ and so on,
  and try to write one of them in terms of the other. If we can show that $\gamma = f(\beta, \alpha)$ and $\beta = g(\alpha)$
  where $f, g$ are polynomials, then we have reduced everything to powers of $\alpha$.
- Now, clearly, if we can do this for two elements, ie, given $E = k(\alpha, \beta)$ , find a polynomial $f$ such that
  $\beta = f(\alpha)$, we have won. So the question is in finding this $f$.

#### Part 1: Primitive element iff number of intermediate subfields is finite

##### Forward: Finitely many intermediate subfields implies primitive
- If $k$ is a finite field, then $E$ is a finite extension and $E^\times$ is a cyclic group. The generator of $E^\times$ is the primitive element.
- So suppose $k$ is an infinite field. Let $E/k$ have many intermediate fields.
- Pick non-zero $\alpha, \beta \in E$ such that $E = k(\alpha, \beta)$. We will generalize to arbitrarily many generators via recursion.
- As $c$ varies in $k$, the extension $k(\alpha + c\beta)$ varies amongst the extensions of $E$.
- Since $E$ only has finitely many extensions while $k$ is infinite, pigeonhole tells us that there are two $c_1 \neq c_2$ in $E$ such that
  $k(\alpha + c_1 \beta) = k(\alpha + c_2 \beta)$.
- Define $L \equiv k(\alpha + c_1 \beta)$. We claim that $L = E$, which shows that $\alpha + c_1 \beta$ is a primitive element for $E$.
- Since $k(\alpha + c_2 \beta) = k(\alpha + c_1 \beta) = L$, this implies that $\alpha + c_2 \beta \in L$.
- Thus, we find that $\alpha + c_1 \beta \in L$ and $\alpha + c_2 \beta \in L$. Thus, $(c_1 - c_2) \beta in L$. Since $c_1, c_2 \in k$, we have
  $(c_1 - c_2)^{-1} \in K$, and thus $\beta \in L$, which implies $\alpha \in L$.
- Thus $L = k(\alpha, \beta) = k(\alpha + c_1 \beta)$.
- Done. Prove for more generators by recursion.

##### Backward: primitive implies finitely many intermediate subfields

- Let $E = k(\alpha)$ be a simple field (field generated by a primitive element). We need to show that $E/k$ only has finitely many subfields.
- Let $a_k(x) \in k[x]$ be the minimal polynomial for $\alpha$ in $k$. By definition, $a$ is irreducible.
- For any intermediate field $k \subseteq F \subseteq E$, define $a_F(x) \in F[x]$ to be the minimal polynomial of $\alpha$ in $F$.
- Since $a_k$ is also a member of $F[x]$ and $a_k, a_F$ share a common root $\alpha$ and $a_F$ is irreducible in $F$, this means that $a_F$ divides $a_k$.
- Proof sketch that irreducible polynomial divides any polynomial it shares a root with (Also written in another blog post):
  The GCD $gcd(a_F, a_k) \in F[x]$ must be non constant since $a_F, a_k$ share a root). But the irreducible polynomial $a_F$
  cannot have a smaller polynomial ($gcd(a_F, a_k)$) as divisor. Thus the GCD itself is the irreducible polynomial $a_F$. This implies that $a_F$ divides $a_k$
  since GCD must divide $a_k$.
- Since $a_k$ is a polynomial, it only has finitely many divisors (upto rescaling, which does not give us new intermediate fields).
- Thus, there are only finitely many intermediate fields if a field is primitive.



##### Interlude: finite extension with infinitely many subfields

- Let $K = F_p(t, u)$ where $t, u$ are independent variables. This is an infinite field extension of $F_p$, since each of the
  $t^i$ are independent.
- Recall that the equation $t^p \equiv t (mod p)$ does not help here, as that only tells us that upon evaluation,
  the polynomials agree at all points. However, they are still two different polynomials / rational functions.
- Consider the subfield $k \equiv F_p(t^p, u^p)$. This too is an infinite field extension of $F_p$.
- Now consider the tower $K/k$, ie, $F_p(t, u)/F_p(t^p, u^p)$. This is of finite degree,
  as we can only have $t^i$ of power upto $p$. $t^p$ lies in the base field $k$.
  Exactly the same with $u$.
- So the extension $F/k$ has basis $\{ t^i u^j : 0 \leq i, j < p \}$, and so has degree $p^2$.
- We will first show that $K$ cannot be generated by a single element $\theta \in k$.
- Suppose we have $\alpha \in K = F_p(t, u)$. Then we must have that $\alpha^p \in F_p(t^p, u^p)$
  frobenius fixes the base field. Thus, frobenius sends $\alpha \in K$ to $\alpha^p \in k$.
- Thus, if we now had that $K = k(\alpha)$, this could not be, since by the
  previous argument, the extension has degree $p$.  But we previously saw that
  $K$ has degree at least $p^2$. Thus, this field extension $K/k$ **does not have a primitive element**.
- We will now show that $K/k$ has infinitely many intermediate subfields.
- Pick elements of the form $\{ t^p + \beta u^p \in K : \beta \in K \}$. We claim that $K_\beta \equiv k(\beta) = F_p(t^p, u^p, \beta)$ are all different fields for different $\beta \in K$.
- Suppose for contradiction that $C = K_\beta = K_\gamma$ for $\beta \neq \gamma$ ($\beta, \gamma \in K$).
  [$C$ for contradictory extension]
- This means that $t^p + \beta u^p - (t^p + \gamma u^p) \in C$, or that $(\beta - \gamma) u^p \in C$,
  which implies that $u^p \in C$, since we know that $(\beta - \gamma)^{-1} \in C$, as $C$ must contain both $\beta$ and $\gamma$.
- Since $u^p \in C$, $\beta \in C$, and $t^p + \beta u^p \in C$, we must have $t^p \in C$.
- This is a contradiction, since thus now means that $C = K$, where $C = k(t^p + \beta u^p)$,
  which makes $t^p + \beta u^p$ a primitive element, somthing that we saw is impossible.
- The key idea is that the extension is generated by a *minimal* polynomial $X^p - 1$, which *factorizes* as $(X - 1)^p$.
  We lose the connection between minimality and irreducibility, which makes the extension inseparable, since the
  minimal polynomial now has repeated roots.
- [Reference](https://www.mathcounterexamples.net/a-finite-extension-that-contains-infinitely-many-subfields/)

#### Part 2: If $E/k$ is finite and separable then it has a primitive element
- Let $K = F(\alpha, \beta)$ be separable for $\alpha, \beta \in K$. Then we will show that there exists a primitive element $\theta \in K$ such that $K = F(\theta)$.
- By repeated application, this shows that for any number of generators $K = F(\alpha_1, \dots, \alpha_n)$, we can find a primitive element.
- If $K$ is a finite field, then the generator of the cyclic group $K^\times$ is a primitive element.
- So from now on, suppose $K$ is infinite, and $K = F(\alpha, \beta)$ for $\alpha, \beta \in F$.
- Let $g$ be the minimal polynomial for $\alpha$, and $h$ the minimal polynomial for $\beta$. Since the field is separable, $g, h$ have unique roots.
- Let the unique roots of $g$ be $\alpha_i$ such that $\alpha = \alpha_1$, and similarly let the unique roots of $h$ be $\beta_i$ such that $\beta = beta_1$.
- Now consider the equations $\alpha_1 + f_{i, j} \beta_1 = \alpha_i + f_{i, j} \beta_j$ for $i \in [1, deg(g)]$ and $j \in [1, deg(h)]$.
- Rearranging, we get $(\alpha_1 - \alpha_j) = f_{i, j} (\beta_j - \beta_1)$. Since $\beta_j \neq \beta_1$ and $\alpha_1 \neq \alpha_j$, this shows that there
  is a unique $f_{i, j} \equiv (\alpha_1 - \alpha_j)/(\beta_j - \beta_1)$ that solves the above equation.
- Since the extension $F$ is infinite, we can pick a $f_*$ which avoids the finite number of $f_{i, j}$.
- Thus, once we choose such an $f_*$, let $\theta \equiv a_1 + f b_1$. Such a $\theta$ can never be equal to $\alpha_i + f \beta_j$ for _any_ $f$, since the only choices of $f$
  that make $\alpha_1 + f \beta_1 = \alpha_i + f \beta_j$ true are the $f_{i, j}$, and $f_*$ was chosen to be different from these!
- Now let $F_\theta \equiv F(\theta)$. Since $\theta \in K$, $E$ is a subfield of $K$.
- See that $K = F(\alpha, \beta) = F(\alpha, \beta, \alpha + f \beta) = F(\beta, \alpha + f \beta) = F(\theta, \beta) = F_\theta(\beta)$.
- We will prove that $K = F_\theta$.
- Let $p(x)$ denote the minimal polynomial for $\beta$ over $F_\theta$. Since $K = F_\theta(\beta)$, if $p(x)$ is trivial, the $K = F_\theta$.
- By definition, $\beta$ is a root of $h(x)$. Since $p(x)$ is an irreducible over $F_\theta$, we have that $p(x)$ divides $h(x)$
  [proof sketch: irreducible polynomial $p(x)$ shares a root with $h(x)$. Thus, $gcd(p(x), h(x))$ must be linear or higher. Since $gcd$ divides $p(x)$, we must have
   $gcd = p(x)$ as $p(x)$ is irreducible and cannot have divisors. Thus, $p(x)$, being the GCD, also divides $h(x)$].
- Thus, the roots of $p(x)$ must be a subset of the roots $\{ \beta_j \}$ of $h(x)$.
- Consider the polynomial $k(x) = g(\theta - f_* \cdot x)$. $\beta$ is also a root of the polynomial $k(x)$, since $k(\beta) = g(\theta - f_* \beta)$,
  which is equal to $g((\alpha + f_* \beta) - f_* \beta) = g(\alpha) = 0$. [since $\alpha$ is a root of $g$].
- Thus, we must have $p(x)$ divides $k(x)$.
- We will show that $\beta_j$ is not a root of $k(x)$ for $j \neq 2$. $k(\beta_j) = 0$ implies $g(\theta - f_* \beta_j) = 0$, which implies $\theta - f_* \beta_j = \alpha_i$
  since the roots of $g$ are $\alpha_i$. But then we would have $\theta = \alpha_i + f_* \beta_j$, a contradiction as $\theta$ was chosen precisely to _avoid_ this case!
- Thus, every root of $p(x)$ must come from $\{ \beta_j \}$. Also, the roots of $p(x)$ must come from the roots of $k(x)$. But $k(x)$ only shares the root $\beta_1$
  with the set of roots $\beta_2, \dots, \beta_j$. Also, $p(x)$ does not have multiple roots since it is separable. Thus, $p(x)$ is linear, and the degree of the field extension
  is 1. Therefore, $K = E = F(\theta)$.

#### References
- [Reference 1: Primitive Element theorem at Planet Math](https://planetmath.org/proofofprimitiveelementtheorem)
- [Reference 2: NPTEL which has proof based on embeddings into alg. closure](https://nptel.ac.in/content/storage2/courses/111101001/downloads/Lecture12.pdf)
- [Reference 3: ](https://sites.math.washington.edu/~greenber/MATH404-PrimElem.pdf)


# Separable extension via embeddings into alg. closure

#### Defn by embeddings
- Let $L/K$ be a finite extension.
- It is separable iff a given embedding $\sigma: K \to \overline K$ can be extended in $[L:K]$ ways (This number can be at most $[L:K]$.)
- We call the numbe of ways to embed $L$ in $\overline K$ via extending $\sigma$ to be the _separability degree_ of $L/K$.


##### At most $[L:K]$ embeddings exist

- We will show for simple extensions $K(\alpha)/K$ that there are at most $[K(\alpha): K]$ ways to extend $\sigma: K \to \overline K$ into $\sigma': K(\alpha) \to \overline K$.
- We use two facts: first, $\sigma'$ is entirely determined by where it sends $\alpha$. Second, $\alpha$ can only go to another root of its minimal polynomial $p \in K[x]$.
  Thus, there are only finitely many choices, and the minimal polynomial has at most $degree(p)$ unique roots, and $[K(\alpha):K] = degree(p)$.
  Thus, there are at most $degree(p_\alpha) = [L:K]$ choices of where $\alpha$ can go to, which entirely determines $\sigma'$. Thus there are at most $degree(p) = [K(\alpha):K]$
  choices for $\sigma'$.
- Given a larger extension, write a sequence of extensions $L = K(\alpha_1)(\alpha_2)\dots(\alpha_n)$. Then, since $[L:K] = [K(\alpha):K][K(\alpha_1, \alpha_2):K(\alpha_1)]$
  and so on, can repeatedly apply the same argument to bound the number of choices of $\sigma'$.
- In detail, for the case $K(\alpha)/K$, consider the minimal polynomial of $\alpha$, $p(x) \in K[x]$. Then $p(\alpha) = 0$.
- Since $\sigma$ fixes $K$, and $p$ has coefficients from $K$, we have that $\sigma(p(x)) = p(\sigma(x))$.
- Thus, in particular, $\sigma(0) = \sigma(p(\alpha)) = p(\sigma(\alpha))$.
- This implies that $p(\sigma(\alpha)) = 0$, or $\sigma(\alpha)$ is a root of $p$.
- Since $\sigma': L \to \overline K$, $\sigma'$ can only map $\alpha$ to one of the other roots of $p$.
- $p$ has at most $deg(p)$ unique roots [can have repeated roots, or some such, so could have fewer that that].
- Further, $\sigma'$ is entirely determined by where it maps $\alpha$. Thus, there are at most $[K(\alpha):K]$ ways to extend $\sigma$ to $\sigma'$.

##### Separability is transitive
- Given a tower $K \subseteq L \subseteq M \subseteq \overline K$, we fix an embedding $\kappa: K \to \overline K$. If both $L/K$ and $M/L$ are
  finite and separable, then $\kappa$ extends into $\lambda: L \to \overline K$ through $L/K$ in $[L:K]$ ways, and then again
  as $\mu: L \to \overline K$ in $[M:L]$ ways.
- This together means that we have $[L:K] \cdot [M:L] = [M:K]$ ways to extend $\kappa$ into $\mu$, which is the maximum possible.
- Thus, $M/K$ is separable.

##### Separable by polynomial implies separable by embeddings
- Let every $\alpha \in L$ have minimal polynomial that is separable (ie, has distinct roots).
- Then we must show that $L/K$ allows us to extend any embedding $\sigma: K \to \overline K$ in $[L:K]$ ways into $\sigma': L \to K$
- Write $L$ as a tower of extensions. Let $K_0 \equiv K$, and $K_{i+1} \equiv K_i(\alpha_i)$ with $K_n = L$.
- At each step, since the polynomial is separable, we have the maximal number of choices of where we send $\sigma'$. Since degree
  is multiplicative, we have that $[L:K] = [K_1:K_0][K_2:K_1]\dots[K_{n-1}:K_n$.
- We build $\sigma'$ inductively as $\sigma'_i: K \to K_i$ with $\sigma'_0 \equiv \sigma$.
- Then at step $i$, $\sigma'_{i+1}: K \to K(i+1)$ which is $\sigma'_{i+1}: K \to K_i(\alpha_{i+1})$ has $[K_{i+1}:K_i]$ choices, since $\alpha_{i+1}$ is separable over
  $K_i$ since its minimal polynomial is separable.
- This means that in toto, we have the correct $[L:K]$ number of choices for $\sigma_n: K \to K_n = L$, which is what it means to be separable by embeddings.

##### Separable by embeddings implies separable by polynomial
- Let $L/K$ be separable in terms of embeddings. Consider some element $\alpha \in L$, let its minimal polynomial be $p(x)$.
- Write $L = K(\alpha)(\beta_1, \dots, \beta_n)$. Since degree is multiplicative, we have $[L:K] = [K(\alpha):K][K(\alpha, \beta_i):K(\alpha)]$.
- So given an embedding $\sigma: K \to \overline K$,we must be able to extend it in $[L:K]$ ways.
- Since $\sigma$ must send $\alpha$ to a root of $\alpha$, and we need the total to be $[L:K]$, we must have that $p(x)$ has no repeated roots.
- If $p(x)$ had repeated roots, then we will have fewer choices of $\sigma(\alpha)$ thatn $[K(\alpha):K]$, which means the total count of choices for $\sigma'$ will be
  less than $[L:K]$, thereby contradicting separability.


#### Finite extensions generated by separable elements are separable

- Let $L = K(\alpha_1, \dots, \alpha_n)$ be separable, so there are $[L: K]$ ways to extend a map $\kappa: K \to \overline K$ into $\lambda: L \to \overline L$.
- Since we have shown that separable by polyomial implies separable by embedding, we write $L = K(\alpha_1)(\alpha_2)\dots(\alpha_n)$. Each step is separable
  by the arguments given above in terms of counting automorphisms by where they send $\alpha_i$. Thus, the full $L$ is separable.

##### References
- https://math.stackexchange.com/questions/2227777/compositum-of-separable-extension
- https://math.stackexchange.com/questions/1248781/primitive-element-theorem-without-galois-group


# Separable extensions via derivation
- Let $R$ be a commutative ring, $M$ an $R$-module. A derivation is a map such that $D(a + b) = D(a) + D(b)$ and $D(ab) = aD(b) + D(a)b$ [ie, the calculus chain rule is obeyed].
- Note that the map does not need to be an $R$-homomorphism (?!)
- The elements of $R$ such that $D(R) = 0$ are said to be the _constants_ of $R$.
- The set of constants under $X$-differentiation for $K[X]$ in char. 0 is $K$, and $K[X^p]$ in char. p
- Let $R$ be an integral domain with field of fractions $K$. Any derivation $D: R \to K$ uniquely extends to $D': K \to K$ given by the
  quotient rule: $D'(a/b) = (bD(a) - aD(b))/b^2$.
- Any derivation $D: R \to R$ extends to a derivation $(.)^D: R[x] \to R[x]$. For a $f = \sum_i a_i x^i \in R[x]$, the derivation
  is given by $f^D(x) \equiv \sum_i D(a_i) X^i$. This applies $D$ to $f(x)$ coefficientwise.
- For a derivation $D: R \to R$ with ring of constants $C$, the associated derivation $(.)^D: R[x] \to R[x]$ has ring of constants $C[x]$.
- **Key thm:** Let $L/K$ be a field extension and let $D: K \to K$ be a derivation. $D$ extends uniquely to $D_L$ iff $L$ is separable over $K$.

#### If $\alpha$ separable, then derivation over $K$ lifts uniquely to $K(\alpha)$

- Let $D: K \to K$ be a derivation.
- Let $\alpha \in L$ be separable over $K$ with minimal polynomial $\pi(X) \in K[X]$.
- So, $\pi(X)$ is irreducible in $K[X]$, $\pi(\alpha) = 0$, and $\pi'(\alpha) \neq 0$.
- Then $D$ has a unique extension $D': K(\alpha) \to K(\alpha)$ given by:

\begin{aligned}
D'(f(\alpha)) \equiv f^D(\alpha) - f'(\alpha) \frac{\pi^D(\alpha)}{pi'(\alpha)}
\end{aligned}

- To prove this, we start by assuming $D$ has an extension, and then showing that it must agree with $D'$. This tells us why it __must__ look this way.
- Then, after doing this, we start with $D'$ and show that it is well defined and obeys the derivation conditions. This tells us why it's __well-defined__.

#### Non example: derivation that does not extend in inseparable case

- Consider $F_p(u)$ as the base field, and let $L = F_p(u)(\alpha)$ where $\alpha$ is a root of $X^p - u \in F_p(u)[x]$. This is inseparable over $K$.
- The $u$ derivative on $F_p(u)$ [which treats $u$ as a polynomial and differentiates it] cannot be extended to $L$.
- Consider the equation $\alpha^p = u$, which holds in $L$, since $\alpha$ was explicitly a root of $X^p - u$.
- Applying the $u$ derivative gives us $p \alpha^{p-1} D(\alpha) = D(u)$. The LHS is zero since we are in characteristic $p$.
  The RHS is 1 since $D$ is the $u$ derivative, and so $D(u) = 1$. This is a contradiction, and so $D$ does not exist [any mathematical operation must respect equalities].


#### Part 2.a: Extension by inseparable element $\alpha$ does not have unique lift of derivation for $K(\alpha)/K$
- Let $\alpha \in L$ be inseparable over $K$. Then $\pi'(X) = 0$ where $\pi(X)$ is the minimal polynomial for $\alpha \in L$.
- In particular, $\pi'(\alpha) = 0$. We will use the vanishing of $\pi'(\alpha)$ to build a nonzero derivation on $K(\alpha)$ which extends the zero
  derivation on $K$.
- Thus, the zero derivation on $K$ has two lifts to $K(\alpha)$: one as the zero derivation on $K(\alpha)$, and one as our non-vanishing lift.
- Define $Z: K(\alpha) \to K(\alpha)$ given by $Z(f(\alpha)) = f'(\alpha)$ where $f(x) \in K[x]$. By doing this, we are conflating elements $l \in K(\alpha)$
  with elements of the form $\sum_i k_i \alpha^i = f(\alpha)$. We need to check that this is well defined, that if $f(\alpha) = g(\alpha)$, then $Z(f(\alpha)) = Z(g(\alpha))$.
- So start with $f(\alpha) = g(\alpha)$. This implies that $f(x) \equiv g(x)$ modulo $\pi(x)$.
- So we write $f(x) = g(x) + k(x)\pi(x)$.
- Differentiating both sides wrt $x$, we get $f'(x) = g'(x) + k'(x) \pi(x) + k(x) \pi'(x)$.
- Since $\pi(\alpha) = \pi'(\alpha) = 0$, we get that $f'(\alpha) = g'(\alpha) + 0$ by evaluating previous equation at $\alpha$.
- This shows that $Z: K(\alpha) \to K(\alpha)$ is well defined.
- See that the derivation $Z$ kills $K$ since $K = K \alpha^0$. But we see that $Z(\alpha) = 1$, so $Z$ extends the zero derivation on $K$ while not being zero itself.
- We needed separability for the derivation to be well-defined.


##### Part 2.b: Inseparable extension can be written as extension by inseparable element

- Above, we showed that if we have $K(\alpha)/K$ where $\alpha$ inseparable, then derivations cannot be uniquely lifted.
- We want to show that if we have $L/K$ inseparable, then derivation cannot be uniquely lifted. But this is not the same!
- $L/K$ inseparable implies that there is some $\alpha \in L$ which is inseparable, NOT that $L = K(\alpha)/K$ is inseparable!
- So we either need to find some element $\alpha$ such that $L = K(\alpha)$ [not always possible], or find some field $F$ such that $L = F(\alpha)$ and
  $\alpha$ is inseparable over $F$.
- Reiterating: Given $L/K$ is inseparable, we want to find some $F/K$ such that $L = F(\alpha)$ where $\alpha$ is inseparable over $F$.
- TODO!


#### Part 1 + Part 2: Separable iff unique lift

- Let $L/K$ be separable. By primitive element theorem, $L = K(\alpha)$ for some $\alpha \in L$, $\alpha$ separable over $K$.
- Any derivation of $K$ can be extended to a derivation of $L$ from results above. Thus, separable implies unique lift.
- Suppose $L/K$ is inseparable. Then we can write $L = F(\alpha)/K$ where $\alpha$ is inseparable over $F$, and $K \subseteq F \subseteq L$.
- Then by Part 2.a, we use the $Z$ derivation to non-zero derivation on $L$ that is zero on $F$. Since it is zero on $F$ and $K \subseteq F$, it is zero on $K$.
- This shows that if $L/K$ is inseparable, then there are two ways to lift the zero derivation, violating uniqueness.


#### Lemma: Derivations at intermediate separable extensions
- Let $L/K$ be a finite extension, and let $F/K$ be an intermediate separable extension. So $K \subseteq F \subseteq L$ and $F/K$ is separable.
- Then we claim that every derivation $D: F \to L$ that sends $K$ to $K$ has values in $F$. (ie, it's range is only $F$, not all of $L$).
- Pick $\alpha \in F$, so $\alpha$ is separable over $K$. We know what the unique derivation looks like, and it has range only $F$.


#### Payoff: An extension $L = K(\alpha_1, \dots, \alpha_n)$ is separable over $K$ iff $\alpha_i$ are separable

- Recursively lift the derivations up from $K_0 \equiv K$ to $K_{i+1} \equiv K_i(\alpha_i)$. If the lifts all succeed,
  then we have a separable extension. If the unique lifts fail, then the extension is not separable.
- The lift can only succeed to uniquely lift iff the final extension $L$ is separable.

# Irreducible polynomial over a field divides any polynomial with common root

- Let $p(x) \in K[x]$ be an irreducible polynomial over a field $K$. Let $p$ it share a common root $\alpha$ with another polynomial $q(x) \in K[x]$. Then we claim
  that $p(x)$ divides $q(x)$.
- Consider the GCD $g \equiv gcd(p, q)$. Since $p, q$ share a root $\alpha$, we have that $(x - \alpha)$ divides $g$.  Thus $g$ is a non-constant polynomial.
- Further, we have $g | p$ since $g$ is GCD. But $p$ is irreducible, it cannot be written as product of smaller polynomials, and thus $g = p$.
- Now, we have $g | q$, but since $g = p$, we have $g | q$. This implies $p | q$ for any $q$ that shares a root with $p$.

# Galois extension

- Let $M$ be a finite extension of $K$. Let $G = Gal(M/K)$. Then $M$ is said to be Galois iff:

1. $M$ is normal and separable (over $K$).
2. $deg(M/K) = |G|$. We will show that $|G| \leq deg(M/K)$. So $M$ is "symmetric as possible" --- have the largest possible galois group
3. $K = M^G$ [The fixed poits of $M$ under $G$]. This is useful for examples.
4. $M$ is the splitting field of a separable polynomial over $K$. Recall that a polynomial is separable over $K$ if it has distinct roots in
   the algebraic closure of $K$. Thus, the number of roots is equal to the degree.
5. $K \subseteq L \subseteq M$ and $1 \subseteq H \subseteq G$: There is a 1-1 correspondece between $L \mapsto Gal(M/L)$ [NOT $L/K$!],
   and the other way round, to go from $H$ to $M^H$. This is a 1-1 correspondence. $L$ is in the denominator because we want to fix $L$ when we go back.

- We'll show (1) implies (2) implies (3) implies (4) implies (1)

#### (4) implies (1)

- We've shown that splitting fields of _sets_ of polynomials are normal, so this case is trivial.
- Just to recall the argument, let $M$ be the splitting field of some separable polynomial $p \in K[x]$ over $K$. We need to show that $M$ is normal and separable.
- It's separable because it only adds elements to new elements to $K$ which are the roots of $p$, a separable polynomial. Thus, the minimal polynomial of new elements
  will also be separable, and the base field is trivially separable.
- We must now show that $M$ is normal. We proceed by induction on degree.
  Normality is trivial for linear polynomials, if $M$ contains one root it
  contains all of the roots (the only one).
- Let $q \in K[x]$ have a root $\alpha \in M$. If $\alpha \in K$, then divide by $(x - \alpha)$ and use induction. So suppose $\alpha \not \in K$.
- Then $\alpha$ is some element that is generated by the roots

- [Borcherds lecture](https://www.youtube.com/watch?v=g87CBjYqHWk&list=PL8yHsr3EFj53Zxu3iRGMYL_89GDMvdkgt&index=8)


# Separability of field extension as diagonalizability

- Take $Q(\sqrt 2)$ over $Q$. $\sqrt(2)$ corresponds to the linear transform $[0 1][2 0]$ over the basis $a + b \sqrt 2$.
- The chracteristic polynomial of the linear transform is $x^2 - 2$, which is indeed the minimal polynomial for $\sqrt(2)$.
- Asking for every element of $Q(\sqrt 2)$ to be separable is the same as
  asking every element of $Q(\sqrt 2)$ interpreted as a linear opearator to have separable minimal polynomial.
- Recall that the minimal polynomial is the lowest degree polynomial that annhilates the linear operator.
  So $minpoly(I) = x - 1$, $charpoly(I) = (x - 1)^n$.

# Motivation for the compact-open topology

- If $X$ is a compact space and $Y$ is a metric space, consider two functions $f, g: X \to Y$.
- We can define a distance $d(f, g) \equiv \min_{x \in X} d(f(x), g(x))$.
- The $\min_{x \in X}$ has a maximum because $X$ is compact.
- Thus this is a real metric on the function space $Map(X, Y)$.
- Now suppose $Y$ is no longer a metric space, but is Haussdorf. Can we still define a topology on $Map(X, Y)$?
- Let $K \subseteq X$ be compact, and let $U \subseteq Y$ be open such that $f(K) \subseteq U$.
- Since $Y$ is Hausdorff, $K \subseteq X$


# Example of covariance zero, and yet "correlated"

- $x$ and $y$ coordinates of points on a disk.
- $E[X], E[Y]$ is zero because symmetric about origin.
- $E[XY] = 0$ because of symmetry along quadrants.
- Thus, $E[XY] - E[X] E[Y]$, the covariance, is zero.
- However, they are clearly correlated. Eg. if $x = 1$, then $y$ must be zero.
- If $Y = aX+b$ the $corr(X, Y) = sgn(a)$.

# Hypothesis Testing

#### Mnemonic for type I versus type II errors

- Once something becomes "truth", challenging the status quo and making it
  "false" is very hard. (see: disinformation).
- Thus, Science must have high barriers for accepting hypothesis as true.
- That is, we must have high barries for incorrectly rejecting the null (that
  nothing happened).
- This error is called as type I error, and is denoted by $\alpha$ (more
  important error).
- The other type of error, where something is true, but we conclude it is false
  is less important. Some grad student can run the experiment again with better
  experimental design and prove it's true later if need be.
- Our goal is to protect science from entrenching/enshrining "wrong" facts as
  true. Thus, we control type I errors.
- Our goal is to "reject" current theories (the null) and create "new theories" (the alternative).
  Thus, in statistics, we setup our tests with the goal of enabling us to "reject the null".

#### Mnemonic for remembering the procedure
- $H_0$ is the null hypothesis (null for zero). They are presumed innocent until proven guilty.
- If $H_0$ is judged guilty, we reject them (from society) and send them to the gulag.
- If $H_0$ is judged not guilty, we retain them (in society).
- We are the prosecution, who are trying to reject $H_0$ (from society) to send them to the gulag.
- The scientific /statistical process is the Judiciary which is attempting to keep the structure of "innocent until proven guilty" for $H_0$.
- We run experiments, and we find out how likely it is that $H_0$ is guilty based on our experiments.
- We calculate an error $\alpha$, which is the probably we screw up the fundamental truth of the court: we must not send an innocent man to the gulag.
  Thus, $\alpha$ it the probability that $H_0$ is innocent (ie, true) but we reject it (to the gulag).

#### P value, Neyman interpretation
- Now, suppose we wish to send $H_0$ to the gulag, because we're soviet union
  like that. What's the probability we're wrong in doing so? (That is, what is the probability that us sending $H_0$ is innocent and we are
  condemning them incorrectly to a life in the gulag)? that's the $p$ value. We estimate this based on our expeiment, of course.
- Remember, we **can never speak** of the "probability of $H_0$ being true/false", because $H_0$ _is true_ or _is false_ [frequentist]. There is no
  probability.

#### P value, Fisher interpretation

- The critical region of the test corresponds to those values of the test statistic
  that would lead us to reject null hypothesis (and send it to the gulag).
- Thus, the critical region is also sometimes called the "rejection region",
  since we reject $H_0$ from society if the test statistic lies in this region.
- The rejection region is usually corresponds to the tails of the sampling distribution.
- The reason for that is that a good critical region almost always corresponds
  to those values of the test statistic that are least likely to be observed if
  the null hypothesis is true. This will be the "tails" / "non central tendency" if a test is good.
- In this situation, we define the $p$ value to be the probability we would have observed a test statistic that is
  at least as extreme as the one we did get. `P(new test stat >= cur test stat)`.
- ??? I don't get it.


#### P value, completely wrong edition

- "Probability that the null hypothesis is true" --- WRONG
- compare to "probability _us_ rejecting the null hypothesis is wrong" -- CORRECT. The probability is in US being wrong, and has NOTHING to do with the
  truth or falsity of the null hypothesis _itself_.

#### Power of the test

- The value $\beta$ is the probability that $H_0$ was guilty, but we chose to retain them into society instead.
- The less we do this (ie, the larger is $1 - \beta$), the more "power" our test has.



# Dumb mnemonic for remembering adjunction turnstile

- The left side of the adjunction `F` wants to "push the piston" on the right
  side, so it must be `F -| G` where `-|` allows `F` to "crush" `G` with the
  flat surface `|`.

# Delta debugging

- [Delta debugging from the fuzzing book](git@github.com:opencompl/lean-gap.git)
- Start with a program that crashes.
- Run `reduce` on it:

```
def reduce(inp: str, test: str -> bool):
  assert test(inp) == False
  # v remove 1/2 of the lines.
  n = 2 # Initial granularity
  while len(inp) >= 2:
    ix = 0
    found_failure = False
    skiplen = len(inp) / n

    while ix < len(inp):
      inp_noix = inp[:ix] +inp[ix+skiplen:]
      if not self.test(inp_noix):
          inp = inp_noix # use smaller input
          n = max(n - 1, 2) # decrease granularity by 1
          found_failure = True; break
      else:
        ix += skiplen

    if not found_failure:
      if n == len(inp): break
      n = min(n * 2, len(inp)) # double

  return inp
```

# Tidy Data

- [The paper](http://vita.had.co.nz/papers/tidy-data.pdf)

- Tidy data is a standard way of mapping the meaning of a dataset to its structure. A dataset is
  messy or tidy depending on how rows, columns and tables are matched up with observations,
  variables and types. In tidy data:

> 1. Each variable forms a column.
> 2. Each observation forms a row.
> 3. Each type of observational unit forms a table.

> While the order of variables and observations does not affect analysis, a good ordering makes
> it easier to scan the raw values. One way of organising variables is by their role in the analysis:
> are values fixed by the design of the data collection, or are they measured during the course of
> the experiment? Fixed variables describe the experimental design and are known in advance.
> Computer scientists often call fixed variables dimensions, and statisticians usually denote them
> with subscripts on random variables. Measured variables are what we actually measure in the
> study. Fixed variables should come first, followed by measured variables, each ordered so that
> related variables are contiguous. Rows can then be ordered by the first variable, breaking
> ties with the second and subsequent (fixed) variables. This is the convention adopted by all
> tabular displays in this paper.


#### Messy 1: Column headers are values, not variable names

- eg. columns are `religion |<$10k |$10-20k |$20-30k |$30-40k |$40-50k |$50-75k`.
- melt dataset to get `molten` stacked data.

#### Messy 2: Multiple variables stored in one column

- This often manifests _after_ melting.
- eg. columns are `country | year | m014 | m1524 | .. | f014 | f1524...`
- columns represent _both_ sex _and_ age ranges. After metling, we get a single column `sexage` with entries like `m014` or `f1524`
- The data is still _molten_, so we should reshape it before it sets into tidy columnlar data. We do this by splitting the column into two,
  one for `age` and one for `sex`.


#### Messy 3: Variables are stored in both rows and columns

- Original data:

```
id      year month element d1 d2 d3 d4 d5 ...
MX17004 2010 1     tmax    — — — — — — — —
MX17004 2010 1     tmin    — — — — — — — —
MX17004 2010 2     tmax    — 27.3 24.1 — — — — —
MX17004 2010 2     tmin    — 14.4 14.4 — — — — —
MX17004 2010 3     tmax    — — — — 32.1 — — —
MX17004 2010 3     tmin    — — — — 14.2 — — —
MX17004 2010 4     tmax    — — — — — — — —
MX17004 2010 4     tmin    — — — — — — — —
MX17004 2010 5     tmax    — — — — — — — —
MX17004 2010 5     tmin    — — — — — — — —
```

- Some variables are in individual columns (id, year, month)
- Some variables are spread across columns (day is spread as d1–d31)
- Some variables are smearted across rows (eg. `tmax/tmin`). TODO: what does this mean, really?
- First, tidy by collating into `date`:

```
id      date       element value
MX17004 2010-01-30 tmax 27.8
MX17004 2010-01-30 tmin 14.5
MX17004 2010-02-02 tmax 27.3
MX17004 2010-02-02 tmin 14.4
MX17004 2010-02-03 tmax 24.1
MX17004 2010-02-03 tmin 14.4
MX17004 2010-02-11 tmax 29.7
MX17004 2010-02-11 tmin 13.4
MX17004 2010-02-23 tmax 29.9
MX17004 2010-02-23 tmin 10.7
```
- Dataset above is still molten. Must reshape along `element` to get two columns for `max` and `min`. This gives:

```
id      date       tmax tmin
MX17004 2010-01-30 27.8 14.5
MX17004 2010-02-02 27.3 14.4
MX17004 2010-02-03 24.1 14.4
MX17004 2010-02-11 29.7 13.4
MX17004 2010-02-23 29.9 10.7
MX17004 2010-03-05 32.1 14.2
MX17004 2010-03-10 34.5 16.8
MX17004 2010-03-16 31.1 17.6
MX17004 2010-04-27 36.3 16.7
MX17004 2010-05-27 33.2 18.2
```

- Months with less than 31 days have structural missing values for the last day(s) of the month.
- The element column is not a variable; it stores the names of variables.


#### Multiple types in one table:


#### data manipulation, relationship to `dplyr`:

- [Data transformation in R for data science](https://r4ds.had.co.nz/transform.html)
- `mutate()` adds new variables that are functions of existing variables
- `select()` picks variables based on their names.
- `filter()` picks cases based on their values.
- `summarise()` reduces multiple values down to a single summary.
- `arrange()` changes the ordering of the rows.


#### Visualization

- Most of R's visualization ecosystem is tidy by default.
- base `plot`, `lattice`, `ggplot` are all tidy.


#### Modelling

- Most modelling tools work best with tidy datasets.


#### Questions about performance benching in terms of tidy
- Is runs of a program at different performance levels like `O1`, `O2`, `O3` to be stored as
  separate columns? Or as a categorical column called "optimization level" with
  entries stored in separate rows of `O1`, `O2`, `O3`?
- If we go by the tidy rule "Each variable forms a column", then this suggests that `optimization level` is a variable.
- Then the tidy rule `Each observation forms a row.` makes us use rows like `[foo.test | opt-level=O1 | <runtime>]` and `[foo.test | opt-level=O2 | <runtime>]`.
- Broader question: what is the tidy rule for categorical column?
- However, in the tidy data paper, Table 12, it is advocated to have two columns for `tmin` and `tmax` instead of having a column called `element` with
  choices `tmin`, `tmax`. So it seems to be preferred that if one has a categorical variable, we make its observations into columns.
- This suggests that I order my bench data as `[foo.test | O1-runtime=_ | O2-runtime=_ | O3-runtime=_ ]`.

# Normal subgroups through the lens of actions

- finite group is permutation subgroup
- ghg' is relavelling by g
- if gHg' = H, then H does not care about labelling
- thus H treats everyone uniformly
- prove that if H is normal, then if s in fix(H) then orb(s) in fix(H)
- when is stab(S) normal?when Stab(gx) equals g Stab(x) g' ?

- topology onS: closed sets are the common fixpoints of a set of group elements.

# Writing rebuttals, Tobias style

- Writing rebuttals, key take-aways:
- Make your headings for reviewers who are seeing your rebuttal projected on a screen to defend your paper.
- Don't write in Q?A style
- Write as a paragraph, where we write the strong answer first, and then point back to the question.
- Use subclause to indicate that sentence is unfinished. Eg: the bug in our compiler has been fixed (bad!).
  The reader may see "the bug in our compiler..." and conclude something crazy.
  Ratther, we should write "While there was a bug in our compiler, we fixed it ...". The `While` makes it
  clear

# LCS DP: The speedup is from filtration

- I feel like I finally see where the power of dynamic programming lies.
- Consider the longest common subsequence problem over arrays $A$, $B$ of size $n$, $m$.
- Naively, we have $2^n \times 2^m$ pairs of subsequences and we need to process each of them.
- How does the LCS DP solution manage to solve this in $O(nm)$?
- Key idea 1: create "filtration" of the problem $F_{i, j} \subseteq 2^n\times2^m$. At step $(i, j)$, consider the "filter" $F_{i, j}$
  containing all pairs of subsequences $(s \in 2^n, t \in 2^m)$ where `maxix(s) \leq i` and `maxix(t) \leq j`.
- These filters of the filtration nest into one another, so $F_{i, j} \subseteq F_{i', j'}$ iff $i \leq i'$ and $j \leq j'$.
- Key idea 2: The value of `max LCS(filter)` is (a) monotonic, and (b) can be computed efficiently from the values of lower filtration.
  So we have a monotone map from the space of filters to the solution space, and this monotone map is efficiently computable, given the
  values of filters below this in the filtration.
- This gives us a recurrence, where we start from the bottom filter and proceed to build upward.
- See that this really has _nothing_ to do with recursion. It has to do with _problem decomposition_.
  We decompose the space $2^n \times 2^m$
  cleverly via filtration $F_{i, j}$ such that `max LCS(F[i, j])` was efficiently computable.
- To find a DP, think of the entire state space, then think of filtrations, such that the solution function becomes a monotone map, and the solution
  function is effeciently computable given the values of filters below it.

# Poisson distribution

- Think about flipping a biased coin with some bias $p$ to associate a coin flip to each real number. Call this $b: \mathbb R \to \{0, 1\}$.
- Define the count of an interval $I$ as $\#I \equiv \{ r \in I | b(r) = 1 \}$.
- Suppose that this value $\#I$ is finite for any bounded interval.
- Then the process we have is a poisson process.
- Since the coin flips are independent, all 'hits' of the event must be independent.
- Since there is either a coin flip or there is not, at most one 'hit' of the event can happen at any moment in time.
- Since the bias of the coin is fixed, the rate at which we see $1$s is overall constant.



# F1 or Fun : The field with one element

- Many combinatorial phenomena can be recovered as the "limit" of geometric phenomena over the "field with one element",
  a mathematical mirage.

#### Cardinality ~ Lines

- Consider projective space of dimension $n$ over $F_p$. How many lines are there?
- Note that for each non-zero vector, we get a 'direction'. So there are $p^n - 1$ potential directions.
- See that for any choice of direction $d \in F_p - \vec 0$, there are $(p -  1)$ "linearly equivalent" directions, given by $1 \cdot d$, $2 \cdot d$,
  \dots, $(p - 1) \cdot d$ which are all distinct since field multiplication is a group.
- Thus, we have $(p^n - 1)/(p - 1)$ lines. This is equal to $1 + p + p^2 + \dots + p^{n-1}$, which is $p^0 + p^1 + \dots + p^{n-1}$
- If we plug in $p = 1$ (study the "field with one element", we recover $\sum_{i=0}^{n-1} p^i = n$.
- Thus, "cardinality of a set of size $n$" is the "number of lines of $n$-dimensional projective space over $F_1$!
- Since $[n] \equiv \{1, 2, \dots, n\}$ is the set of size $n$, it is only natural that $[n]_p$ is defined to be the lines in $F_p^n$.
  We will abuse notation and conflate $[n]_p$ with the cardinality, $[n]_p \equiv (p^n - 1)/(p - 1)$.


#### Permutation ~ Maximal flags

- Recall that a maximal flag is a sequence of subspaces $V_1 \subseteq V_2 \subseteq \dots \subseteq V$. At each step, the dimension increases by $1$,
  and we start with dimension $1$. So we pick a line $l_1$ through the origin for $V_1$. Then we pick a plane through the origin that contains the line $l_1$
  through the origin. Said differently, we pick a plane $p_2$ spanned by $l_1, l_2$. And so on.
- How many ways can we pick a line? That's $[n]_p$. Now we need to pick another line orthogonal to the first line. So we build the quotient space $F_p^n/L$,
  which is $F_p^{n-1}$. Thus picking another line here is $[n-1]_p$.  On multiplying all of these, we get $[n]_p [n-1]_p \dots [1]_p$.
- In the case of finite sets, this gives us $1 \cdot 2 \cdot \dots n = n!$.

#### Combinations ~ Grassmanian

- Recall that a grassmanian consists of $k$ dimensional subspaces of an $n$ dimensional space.


- [Reference: This week's finds 184 by baez](https://math.ucr.edu/home/baez/week184.html)

# McKay's proof of Cauchy's theorem for groups [TODO]

- In a group, if $gh = 1$ then $hg = 1$. Prove this by writing $hg = hg (h h^{-1}) = h(gh)h^{-1} = h \cdot 1 \cdot h^{-1} = 1$.
- We can interpret this as follows: in the multiplication table of a group, firstly, each row contains exactly one $1$.
- Also, when $g \neq h$ (ie, we are off the main diagonal of the multiplication table), each $gh = 1$ has a "cyclic permutation solution" $hg = 1$.
- If the group as even order, then there are even number of $1$s on the main diagonal.
- Thus, the number of solutions to $x^2 = 2$ for $x \in G$ is even, since each solution has another paired with it.
- Let's generalize from pairs to
- [Reference](http://www.cs.toronto.edu/~yuvalf/McKay%20Another%20Proof%20of%20Cauchy's%20Group%20Theorem.pdf)


# ncdu for disk space measurement

- I've started to use `ncdu` to get a quick look at disk space instead of `baobab`. It's quite handy
  since it's an ncurses based TUI.


# nmon versus htop

- I've switched to using `nmon` instead of `htop` for viewing system load. It's TUI looks much nicer than `htop`,
  and I find its process list much easier to parse.

# Schrier sims --- why purify generators times coset

- Let `p = (0 3 4)(1 2)`. Let `G = <p>`. What is the stabilizer of `k=0`?
- `purify(p) = e` so we would imagine we would have `H = e`.
- But actually, consider orbit(k). We have `0 <-> id`, `3 <-> p`, `4 <-> p^2`.
- If I now consider `p * orbit(k)` then I get `p, p^2, p^3`, where `purify(p) = id`, `purify(p^2) = id`, `purify(p^3) = p^3`.
- Thus we find the nontrivial generator `p^3`.

# Vyn's feeling about symmetry

- They are of the opinion that the correct definition of a symmetry of an object $S$ in space is that
  a transformation $T$ is a symmetry of $S$ iff $T(S) = S$ (as a set).
- The above rules out things like translations of a cube.
- Indeed, one can only recover translations by considering a line on the space and then considering the orbit of the line under
  a specific translation $T$.

# Convergence in distribution is very weak

- consider $X \sim N(0, 1)$. Also consider $-X$ which will be identically distributed (by symmetry of $-$ and $N$).
- So we have that $-X \sim N(0, 1)$.
- But this tells us nothing about $X$ and $-x$! so this type of "convergence of distribution" is very weak.
- Strongest notion of convergence (#2): Almost surely. $T_n \xrightarrow{a.s} T$ iff $P(\{ \omega : T_n(\omega) \to T(\omega) \}) = 1$.
  Consider a snowball left out in the sun. In a couple hours, It'll have a random shape, random volume, and so on. But the ball itself
  is a definite thing --- the $\omega$. Almost sure says that for almost all of the balls, $T_n$ converges to $T$.
- #2 notion of convergence: Convergence in probability.
  $T_n \xrightarrow{P} T$ iff $P(|T_n - T| \geq \epsilon) \xrightarrow{n \to \infty} 0$ for all
  $\epsilon > 0$. This allows us to squeeze $\epsilon$ probability under the rug.
- Convergence in $L^p$: $T_n \xrightarrow{L^p} T$ iff $E[|T_n - T|^p] \xrightarrow{n \to \infty} 0$. Eg. think of convergence in variance of a gaussian.
- Convergence in distrbution: (weakest): $T_n \xrightarrow{d} T$ iff $P[T_n \leq x] \xrightarrow{n \to \infty} P[T \leq x]$ for all $x$.

#### Characterization of convergence in distribution

- (1) $T_n \xrightarrow{d} T$
- (2) For all $f$ continuous and bounded, we have $E[f(T_n)] \xrightarrow{n \to \infty} E[f(T)]$.
- (2) we have $E[e^{ixT_n}] \xrightarrow{n \to \infty} E[e^{ixT}]$. [characteristic function converges].


#### Strength of different types of convergence

- Almost surely convergence implies convergence in probability. Also, the two limits (which are RVs) are almost surely equal.
- Convergence in $L^p$ implies convergence in probability and convergence in $L^q$ for all $q \leq p$. Also, the limits (which are RVs) are almost
  surely equal.
- If $T$ converges in probability, it also converges in distribution (meaning the two sequences will have the same DISTRIBUTION, not same RV).
- All of almost surely, probabilistic convergence, convergence in distribution (not $L^p$)
  map properly by continuous fns. $T_n \to T$ implies $f(T_n) \to f(T)$.
- almost surely implies P implies distribution convergence.


#### Slutsky's Theorem

- If $X_n \xrightarrow{d} X$ and $Y_n \xrightarrow{P} c$ (That is, the sequence of $Y_n$ is eventually deterministic),we then have that
  $(X_n, Y) \xrightarrow{d} (X, c)$. In particular, we get that $X_n + Y_n \xrightarrow{d} X + c$ and $X_n Y_n \xrightarrow{d} X c$.
- This is important, because in general, convergence in distribution says nothing about the RV! but in this special case, it's possible.

#### References

-   [MIT OCW stats](https://www.youtube.com/watch?v=C_W1adH-NVE&list=PLUl4u3cNGP60uVBMaoNERc6knT_MgPKS0&index=2)




# Class equation, P-group structure

#### Centralizer

- The centralizer of a subset $S$ of a group $G$ is largest subgroup of $G$ which is the center of $S$.
  It's defined as $C_G(S) \equiv \{ g \in G : \forall s \in S, gs = sg \}$. This can be
  written as $C_G(S) \equiv \{ g \in G : \forall s \in S, gsg^{-1} = s \}$.
-

#### Conjucacy classes and the class equation

- Define $g \sim g'$ if there exists a $h$ such that $g' =kgk^{-1}$. This is an equivalence
  relation on the group, and it partitions the group into _conjugacy classes_.
- Suppose an element $z \in G$ is in the center (Zentrum). Now, the product $kzk^{-1} = z$ for all $k \in G$.
  Thus, elements in the center all sit in conjugacy classes of size $1$.
- Let $Z$ be the center of the group, and let $\{ J_i \subset G \} $ (J for conJugacy) be conjugacy classes of elements other than the center.
  Let $j_i \in J_i$ be representatives of the conjugacy classes, which also generate the conjugacy class as orbits under the action of
  conjugation.
- By orbit stabilizer, we have that $|J_i| = |Orb(j_i)| = |G|/|Stab(j_i)|$.
- The stabilizer under the action of conjugation is the centralizer! So we have $|Orb(j_i) = |G|/|C(j_i)|$.
- Thus, we get the class equation: $|G| = |Z| + \sum_{j_i} |G|/C(j_i)|$.

#### $p$-group

- A $p$ group is a group where every element has order divisible by $p$.
- Claim: a finite group is a $p$-group iff it has cardinality $p^N$ for some $N$.
- Forward - $|G| = p^N$ implies $G$ is a $p$-group: Let $g \in G$. The $|\langle g \rangle|$ divides $|G| = p^N$ by Lagrange. Hence proved.
- Backward - $p$ divides |\langle g \rangle| for all $g \in G$ implies $|G| = p^N$ for some $N$: Write $G$ as disjoint union of cyclic subgroups:
  $G = \langle g_1 \rangle \cup \langle g_2 \rangle \cup \dots \langle g_n \rangle$. Take cardinality on both sides, modulo $p$.
  Each of the terms on the RHS $|\langle g_i \rangle|$ is divisible by $p$, and thus vanish. Thus, $|G| =_p 0 + 0 + \dots + 0 = 0$ modulo $p$.
  Hence, $|G|$ is divisible by $p$.

#### Center of $p$ group

- Let $G$ be a $p$-group. We know that $|G| = |Z(G)| + \sum_{g_i} |Orb(g_i)|$, where we are considering orbits under
  group conjugation.
- See that $|Orb(g_i)| = |G|/|Stab(g_i)|$. The quantity on the right must be a power of $p$ (since the numerator is $p^N$). The quantity
  must be more than $1$, since the element $g_i$ is not in the center (and thus is conjugated non-trivially by _some_ element of the group).
- Thus, $|Orb(g_i)|$ is divisible by $p$.
- Take the equation $|G| = |Z(G)| + \sum_{g_i} |Orb(g_i)|$ modulo $p$. This gives $0 =_p |Z(G)$. Hence, $Z(G) \neq \{ e \}$
  (Since that would give $|Z(G)| =_p 1 \neq 0$). So, the center is non-trivial.

#### Cauchy's theorem: order of group is divisible by $p$ implies group has element of order $p$.

- **Abelian case, order $p$**: immediate, must be the group $Z/pZ$ which has generator of order $p$. Now induction on group cardinality.
- **Abelian case, order divisible by $p$**: Pick an element $g \in G$ and let the cyclic subgroup be generated by it be $C_g$ and
  let the order of $g$ be $o$ (Thus, $|C_g| = o$).
- *Case 1:* If $p$ divides $o$, then there is a power of $g$ with order $p$ (Let $o' \equiv o/p$. Consider $g^{o'}$; this has order $p$).
- *Case 2:* If $p$ does not divide $o$. Then $p$ divides the order of the
  quotient $G' \equiv G / C_g$. Thus by induction, we have an element $h C_g \in G / C_g$ of order $p$.
- Let $o$ be the order of $h$ in $G$. Then we have that that $(h C_g)^o =  h^o C_g = e C_g$, where the last equality follows from the assumption that
  $o$ is the order of $h$. Thus we can raise $h C_g$ to $o$ get the identity in $G/C_g$. This implies $p$ (the order of $h G/C_g$)
  must divide $o$ (the order of $h$).
- Thus, by an argument similar to the previous, there is some power of $h$ with order $p$. (Let $o' \equiv o/p$. Consider $h^{o'}$' this has order $p$)

- **General case:** consider the center $Z$. If $p$ divides $|Z|$, then use the abelian case to find an element of order $p$ and we are done.
- Otherwise, use the class equation: $|G| = |Z| + \sum_{j_i} |Orb(j_i)|$.
- The LHS vanishes modulo $p$, the RHS has $|Z|$ which does not vanish. Thus there is some term $j_i$ whose orbit is not divisible modulo $p$.
- We know that $Orb(j_i) = G/Stab(j_i)$ where the action is conjugacy. Since the LHS is not divisible by $p$, while $|G|$ is divisible by $p$,
  this means that $Stab(j_i)$ has order divisible by $p$ and is a subgroup of $G$.
- Further, $Stab(j_i)$ is a proper subgroup as $Orb(j_i)$ is a proper orbit, and is thus not stabilized by every element of the group.
- Use induction on $Stab(j_i)$ to find element of order $p$.

#### Subgroups of p-group

- Let $G$ be a finite $p$ group. So $|G| = p^N$. Then  $G$ has a normal subgroup of size $p^l$ for all $l \leq N$.
- Proof by induction on $l$.
- For $l = 0$, we have the normal subgroup $\{ e \}$.
- Assume this holds for $k$. We need to show it's true for $l \equiv k + 1$.
- So we have a normal subgroup $N_k$ of size $p^k$. We need to establish a subgroup $N_l$ of size $p^{k+1}$.
- Consider $G/N_k$. This is a $p$-group and has cardinality $p^{N-k}$. As it is a $p$-group, it has non-trivial center.
  So, $Z(G/N_k)$ is non-trivial and has cardinality at least $p$.
- Recall that every subgroup of the center is normal. This is because the center is fixed under conjugation, thus
  subgroups of the center are fixed under conjugation and are therefore normal.
- Next, by Cauchy's theorem, there exists an element $z$ of order $p$ in $Z(G/N_k)$. Thus, there is a normal subgroup $\langle z \rangle \subset G/N_k$
- We want to pull this back to a normal subgroup of $G$ of order $|\langle z \rangle \cdot N_k| = p^{k+1}$.
- By correspndence theorem, the group $\langle z \rangle \cdot N_k$ is normal in $G$ and has order $p^{k+1}$. Thus we are done.


# Sylow Theorem 1

I've always wanted a proof I can remember, and I think I've found one.

- Let $G$ be a group such that $|G| = p^n m $ where $p$ does not divide $m$.
- We start by considering the set of all subsets of $G$ of size $p^n$. Call this set $\Omega$.
- We will prove the existence of a special subset $S \subseteq G$ such that
  $S \in \Omega$, and $|Stab(S)| = p^n$. That is, $|S| = p^n$ and $|Stab(S) = p^n$.
  This is somewhat natural, since the only way to get subgroups out of actions is to
  consider stabilizers.
- We need to show the existence of an $S \in \Omega$ such that $Stab(S)$ has maximal cardinality.

#### Lemma: $\binom{pa}{pb} \equiv_p \binom{a}{b}$:

- this is the coefficient of $x^{pb}$ in $(x + 1)^{pa}$.
  But modulo $p$, this is the same as the coefficient of $x^{pb}$ in $(x^p + 1^p)^a$. The latter is $\binom{a}{b}$.
  Thus, $\binom{ap}{bp} \equiv_p \binom{a}{b}$ (modulo $p$).

#### Continuing: Size of $\Omega$ modulo $p$:
- Let us begin by considering $|\Omega|$. This is $\binom{p^n m}{p^n}$ since we pick all subsets of size $p^n$ from $p^n$ m.
  See that if we want to calculate $\binom{pa}{pb}$, this is the coefficient of $x^{pb}$ in $(x + 1)^{pa}$.
  But modulo $p$, this is the same as the coefficient of $x^{pb}$ in $(x^p + 1^p)^a$. The latter is $\binom{a}{b}$.
  Thus, $\binom{ap}{bp} \equiv_p \binom{a}{b}$ (modulo $p$).
  Iterating the lemma shows us that $\binom{p^n m}{p^n} = m$. Thus, $p$ does not divide $|\Omega|$, since $m$ was the $p$-free part of $|G|$.
- This implies that there is some orbit $O \subset \Omega$ whose size is not divisible by $p$.
  --- Break $\Omega$ into orbits. Since the left hand side $|\Omega|$ is not divisible by $p$,
  there is some term in the orbits size that is not divisible by $p$.
- Let the orbit $O$ be generated by a set $S \in \Omega$. So $O = Orb(S)$. Now orbit
  stabilizer tells us that $|Orb(S)| \cdot |Stab(S)| = |G|$. Since $|O = Orb(S)|$ is not divisible by $p$,
  this means that $Stab(S)$ must be of size at least $p^n$. It could also have some divisors of $m$ inside it.
- Next, we will show that $Stab(S)$ can be at most $p^n$.

#### Lemma: size of stabilizer of subset when action is free:

- Let a group $G$ act freely on a set $S$. This means that for all group elements $g$, if for any $s$
  we have $g(s) = s$, then we must have $g = id$. In logic, this is: $\forall g, \exists s, g(s) = s \implies g = id$.
- See that an implication of this is that for any two elements $s, t \in S$, we can have at most one $g$ such that $g(s) = t$.
  Suppose that we have two elements, $g, h$ such that $g(s) = t$ and $h(s) = t$. This means that $g^{-1}h(s) = s$. But we know that
  in such a case, $gh^{-1} = id$ or $g = h$.
- What does this mean? it means that $Stab(s) = \{ e \}$ for all $s$.
- Now let's upgrade this to subsets of $S$. Let $P$ (for part) be a subset of $S$. What is $|Stab(P)|$? We want to show that it
  is at most $P$. Let's pick a unique basepoint $p_0 \in P$ [thus $p_0 \in S$ since $P \subseteq S$].
- Let's suppose that $g \in Stab(P)$. This means that $g(p_0) \in P$. Say it sends $p_0$ to $p_g \in P$.
  Now no other element of $Stab(P)$ can send $p_0$ to $p_g$ since the action is free!
- Thus, there are at most $|P|$ choices for $p_0$ to be sent to, one for each element of $Stab(P)$.
- Thus, $|Stab(P)| \leq |P|$.

#### Continuing: Showing that $|Stab(S) = p^n$.

- Since the action of $G$ on $G$ is free, and since we are considering the stabilizer of some subset $S \subseteq G$,
  we must have that $|Stab(S) \leq |S| = p^n$. Thus, since $|S| \geq p^n$ (from the orbit argument above) and $|S| \leq p^n$ (from the stabilizer
  argument), we have $|Stab(S) = p^n$. Thus we are done.

- More explicitly perhaps, let us analyze $|Stab(S)|$. We know that $Stab(S) \cdot S = S$.
  Thus, for any $t \in S$, we know that $Stab(S) \cdot t \subseteq S$.
  Thus, $|Stab(s) \cdot t| \leq |S|$.

- Also notice that $|Stab(S) \cdot t$ is a coset of $Stab(S)$. Thus, $|Stab(S) \cdot t| = |Stab(S)|$.


Combining the above, we find that $|Stab(S)| \leq |S|$. So the stabilizer of
size $|S| = p^k$ it is in some sense "maximal": it has the largest size a
stabilizer could have!



# Fuzzing book

- Statement coverage is different from branch coverage, since an `if (cond) { s1; } s2` will say that `s1` and `s2` were executed when
  `cond=True`, so we have full statement coverage. On the other hand, this does not guarantee full branch coverage, since we have not
  exectuted the branch where `cond=False`. We can't tell that we haven't covered this branch since *there is no statement* to record that
  we have taken the `else` branch!

- Branch distances: for conditions `a == b`, `a != b`, `a < b`, `a <= b`, define the "distance true/distance false" to be the number that is to be
  added/subtracted to `a` to make the condition true/false (for a fixed `b`). So, for example, the "distance true" for `a == b` is `abs(b - a)`,
  while "distance false" is `1 - int(a == b)`.

- **What are we missing in coverage?** The problem here is that coverage is unable
  to evaluate the quality of our assertions. Indeed, coverage does not care
  about assertions at all. However, as we saw above, assertions are an
  extremely important part of test suite effectiveness. Hence, what we need is
  a way to evaluate the quality of assertions.

- **Competent Programmer Hypothesis / Finite Nbhd Hypothesis**: Mutation
  Analysis provides an alternative to a curated set of faults. The key insight
  is that, if one assumes that the programmer understands the program in
  question, the majority of errors made are very likely small transcription
  errors (a small number of tokens). A compiler will likely catch most of these
  errors. Hence, the majority of residual faults in a program is likely to be
  due to small (single token) variations at certain points in the structure of
  the program from the correct program (This particular assumption is called
  the Competent Programmer Hypothesis or the Finite Neighborhood Hypothesis).


- **Equivalent mutants**: However, if the number of mutants are sufficiently
  large (say > 1000), one may choose a smaller number of mutants from the alive
  mutants randomly and manually evaluate them to see whether they represent
  faults. We choose the sample size by
  [sampling theory of binomial distributions](https://www.itl.nist.gov/div898/handbook/prc/section2/prc242.htm).
- **Chao's estimator**: way to estimate the number of true mutants (and hence
  the number of equivalent mutants) is by means of Chao's estimator:

$$
hat M \equiv
\begin{cases}
M(n) + k_1^2 / (2 k_2) & \text{if } k_2 > 0 \\
M(n) + k_1(k_1 - 1)/2 & \text{otherwise} \\
\end{cases}
$$

- $k_1$ is the number of mutants that were killed exactly once, $k_2$ is the number of mutants that were
  killed exactly twice. $\hat M$ estimates the the true numbe of mutants.
- If $T$ is the total mutants generated, then $T - M(n)$ represents **immortal** mutants.
- $\hat M$ is the  is the mutants that the testset can detect given an infinite amount of time.


# Fisher Yates

- We wish to generate a random permutation.
- Assume we can generate a random permutation of $[a, b, c]$.
- How do we extend this to a random permutation of $[w, x, y, z]$?
- Idea: (0) Consider $\{w, x, y, z\}$ in a line. Our random permutation is $[\_, \_, \_, \_]$.
- (1) Decide who goes at the rightmost blank. Suppose $y$. Then our random permutation state is $[\_, \_, \_, y]$.
- (2) What do we have left? We have $\{w, x, z \}$. Use recursion to produce a random permutation of length 3 with $[w, x, z]$.
- (3) Stick the two together to get a full random permutation.
- To save space, we can write this on a "single line", keeping a stick to tell us which part is the "set", and which part is the "array":

```
0. {w,  x,  y, z}[]
1. {w, x, y, [z}] (growing array)
1. {w,  x,  z, [y}] (swapping z<->y)
1. {w,  x,  z}, [y] (shrinking set)
```


Similarly, for the next round, we choose to swap `w` with `z` as follows:

```
1. {w,  x,  z}, [y]
2. {w, x,  [z}, y] (grow array)
2. {x,  z, [w}, y]  (swap w <-> x)
2. {x, z}, [w, y] (shrinking set)
```

For the next round, we swap `z` with `z` (ie, no change!)

```
2. {x,  z}, [w, y]
3. {x, [z}, w, y] (grow array)
3. {x, [z}, w, y] (swap z<->z)
3. {x},[z, w, y] (shrink set)
```

Finally, we swap `x` with `x`:


```
3. {x},  [z, w, y]
4. {[x}, z, w, y] (grow array)
3. {x}, [z, w, y] (swap x<->x)
3. {}[x, z, w, y] (shrink set)
```

- This way, we generate a random permutation _in place_, by treating the left portion of the sequence as a set, and the right portion of the
  sequence as a sorted permutation. At each stage, we grow the array, and choose a random element from the set to "enter" into the array
  at the location of intersection between set and array.

- In code, the index `i` tracks the location of the array border, where we must fix the value of the permutation (ie, the ordering of elements)
  at the `i`th location.
  Th index `r` is a random index chosen  in `[0, i]` which is the element to be chosen as the value at the `i`th location.

```py
@composite
def permutation(draw, n):
    # raw random
    # Fishes Yates: https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle
    xs = { i : xs[i] for i in range(n) }

    i = n-1 # from (n-1), down to zero.
    while i >= 0:
        r = draw(integers(0, i)) # r ∈ [0, i]
        temp = xs[i]; xs[i] = xs[r]; xs[r] = temp; # swap
        i -= 1
    return xs
```


# Bucchberger algorithm

- multidegree: term of maximum degree, where maximum is defined via lex ordering.
- Alternatively, multidegree is the degree of the leading term.
- If `multideg(f) = a` and `multideg(g) = b`, define `c[i] = max(a[i], b[i])`. Then $\vec x^c$ is the LCM of the leading monomial
  of $f$ and the leading monomial of $g$.
-  The S-polynomial of $f$ and $g$ is the combination $\vec (x^c/LT(f)) f - (\vec x^c/LT(g)) g$
- The S-polynomial is designed to create cancellations of leading terms.


#### Bucchberger's criterion

- Let $I$ be an ideal. Then a basis $\langle g_1, \dots, g_N \rangle$ is a Groebner basis iff for all pairs $i \neq j$, $S(g_i, g_j) = 0$.
- Recall that a basis is an Grober basis iff $LT(I) = \langle LT(g_1), \dots, LT(g_N) \rangle$. That is, the ideal of leading terms of $I$
  is generated by the leading terms of the generators.

- for a basis $F$, we should consider $r(i, j) \equiv rem_F(S(f_i, f_j))$. If $r(i, j) \neq 0$, then make $F' \equiv F \cup \{ S(f_i, f_j \}$.
- Repeat till we find that




# GAP permutation syntax
- The action of permutation on an element is given by $i^p$. This is the "exponential notation" for group actions.
- See that we only ever write permutations multiplicatively, eg `(1) (23)` is
  the composition of permutations [written multiplicatively].
- Thus the identity permutation must be `1`, and it's true that any number `n^1 = n`,
  so the identity permutation `1` fixes everything.

# Why division algorithm with multiple variables go bad

- In `C[x, y]`, defining division is complicated, and needs grobner bases to work.
- It's because they don't obey the GCD property. Just because `gcd(a, b) = g` does not mean that there exist `k, l` such that `ak + bl = g`
- For example, in `C[x, y]`, we have `gcd(x, y) = 1` but we don't have polynomials `k, l` such that `kx + ly = 1`.
- Proof: suppose for contradiction that there do exist `k, l` such that `kx + ly = 1`. Modulo `x`, this means that `ly = 1` which is absurd,
  and similarly modulo `x` it means `kx = 1` which is also absurd.

# Integral elements of a ring form a ring [TODO]

- An integral element of a field $L$ (imagine $\mathbb C$)
  relative to an integral domain $A$ (imagine $\mathbb Z$) is the root of a monic polynomial in $A$.

- So for example, in the case of $\mathbb C$ over $\mathbb Z$, the element $i$ is integral as it is a root of $p(x) = x^2 + 1$.
- On the other hand, the element $1/2$ is not integral. Intuitively, if we had a polynomial of which it is a root,
  such a polynomial would be divisible by $2x - 1$ (which is the minimal polynomial for $1/2$). But $2x - 1$ is not monic.
- Key idea: take two element $a, b$ which are roots of polynomial $p(x), q(x) \in A[x]$.
- Create the polynomial $c(x)$ (for construction) given by $c(x) \equiv p(x)q(x) \in A[x]$. See that $c(x)$ has both $a$ and $b$
  as roots, and lies in $A[x]$.

# "Cheap" proof of euler characteristic

- If we punch a hole in a sphere, we create an edge with no vertex or face. This causes $V - E + F$ to go down by 1.
- If we punch two holes, that causes $V - E + F$ to go down by two. But we can glue the two edges together.
  This gluing gives us a handle, so each hole/genus reduces the euler characteristic by two!

# Siefert Algorithm [TODO]

- Algorithm to find surface that a knot bounds.
- If we find a surface, then the genus of the boundary is one minus the genus of the surface.
- Compute genus via classification of surfaces.

# Cap product [TODO]
- https://www.youtube.com/watch?v=oxthuLI8PQk

- We need an ordered simplex, so there is a total ordering on the vertices. This is to split a chain apart at number $k$.
- Takes $i$ cocahins and $k$ chains to spit out a $k - i$ chain given by $\xi \frown \gamma \equiv \sum_a \gamma_a \xi (a_{\leq i}) a_{\geq i}$.
- The action of the boundary on a cap product will be $\partial (\xi \frown \gamma) \equiv (-1)^i [(\xi \frown \partial \gamma) - (\partial \gamma \frown \gamma)]$.
- Consequence: cocycle cap cycle is cycle.
- coboundary cap cycle is boundary.
- cocyle cap boundary is boundary.
- Cap product will be zero if the chain misses the cochain.
- Cap product will be nonzero if the chain *must* always intersect the cochain.
- This is why it's also called as the intersection product, since it somehow counts intersections.

# Cup product [TODO]

- We need an ordered simplex, so there is a total ordering on the vertices. This is to split a chain apart at number $k$.
- Can always multiply functions together. This takes a $k$ chain $\xi$ and an $l$ chain $\eta$ and produces $\xi \cup \eta$ which is a $k + l$
  cochain. The action on a $(k+l)$ chain $\gamma$ acts by $(\xi \cup \eta)(\gamma) \equiv \xi (\gamma_{\leq k}) \cdot \eta (\gamma_{> k})$.
- No way this can work for chains, can only ever work for cochains.
- This cup product "works well" with coboundary. We have $\partial (\xi \cup \eta) \equiv (\partial \xi \cup \eta) + (-1)^k (\xi \cup \partial \eta)$.
- We get cocycle cup cocyle is cocycle.
- Similarly, coboundary cup cocycle is coboundary.
- Simiarly, cocycle cup coboundary is coboundary.
- The three above propositions imply that the cup product descends to cohomology groups.
- The _algebra_ of cohomology (cohomology plus the cup product) sees the difference between spaces of identical homology!
- The space $S^1 \times S^1$ have the same homology as $S^2 \cap S^1 \cap S^1$. Both have equal homology/cohomology.
- However, we will find that it will be zero on the torus and non-zero on other side.
- The cup product measures how the two generators are locally product like. So if we pick two generators on the torus, we can find a triangle
  which gives non-zero


# Colimits examples with small diagram categories

- Given a colimit, compute the value as taking the union of all objects, and imposing the relation $x \sim f(x)$
  for all arrows $f \in Hom(X, Y)$ and all $x \in X$.

- A colimit of the form $A \xrightarrow{f} B$ is computed by taking $A \sqcup B$ and then imposing the relation $a \sim f(b)$. This is entirely useless.
- A colimit of the form $A \xrightarrow{f, g} B$ is computed by taking $A \sqcup B$ and then imposing the relation $a \sim f(a)$ as well as $a \sim g(a)$.
  Thus, this effectively imposes $f(a) \sim g(a)$. If we choose $f = id$, then we get $a \sim g(a)$. So we can create quotients by taking the colimit
  of an arrow with the identity.
- A colimit of the form $A \xleftarrow{f} B \xrightarrow{g} C$ will construct $A \cup B \cup C$ and impose the relations $b \sim f(b) \in A$ and $b \sim g(b) \in C$.
  Thus, we take $A, B, C$ and we glue $A$ and $C$ along $B$ via $f, g$. Imagine gluing the upper and lower hemispheres of a sphere by a great circle.

# Limits examples with small diagram categories

- Given a limit, compute the value as taking product of all objects, and taking only those tuples which obey the relations
  the relation $f(a) = b$ for all arrows $f \in Hom(X, Y)$.

# Classification of compact 2-manifolds [TODO]

- Oriented compact 2-surfaces: sphere, torus, 2 holed torus, etc.
- have euler characteristic $V - E + F $ as $2 - 2g$
- Strategy: cut surface into polygonal pieces. Use oriented edges to know cutting. Lay them down on the surface such that the "top part" or
  "painted surface" will be up [so we retain orientation].
- Attach all the polygons into one big polygon on the plane.
- For each edge on boundary of the big polygon, it must attach to some other boundary of the big poygon [since the manifold is compact].
  Furthermore, this edge must occur in the *opposite direction* to make the surface orientable. Otherwise we could pass through the side
  and flip orientation. Consider:

```
>>>>
|  |
>>>>
```

- When I appear from the "other side", my direction wil have flipped. [TODO]

- So far, we know the edges. What about identifying vertices?

- Next, we need to group vertices together on the big polygon. We can find this by going *around the edges incident at the vertex*
  on the *manifold surface*.


- The next step is to reduce the number of vertices to exactly one. We can cut the current polygon and re-paste it as long as we preserve
  all cutting/pasting relations.

- Suppose I glue all the B vertices to a single vertex. Then, the edges emenating from this B vertex _must necessarily be the same_.
  If not, then the edge emenating would need a complementary edge somewhere else, which would give me another "copy" of the B vertex.

- I can imagine such a B vertex as being "pushed inside the polygon" and then "glued over itself", thereby making it part of the *interior*
  of the polygon.

- We can repeat this till there is only one type of vertex (possibly multiple copies).
- If we only had two adjacent edges [edges incident against the same vertices], then we are done, since we get a sphere.
- We can always remove adjacent pairs of edges. What about non-adjacent pairs?
- Take a non adjacent pair. think of these as "left" and "right". We claim that for each edge at the "top", there is a corresponding
  edge at the "bottom". So we have left and right identified, and top identified with a continugous segment in the bottom. If there  wasn't,
   then we would need another vertex!
- This lets me create a commutator on the boundary, of the form
  $cdc^{-1}d^{-1}x$. Topologically, this is a handle, since if it were "full"
  [without the extra $x$], then we would have a torus. Since we do have the
  $x$, we have a "hole on the torus" which is a handle.
- We keep removing hanldes till we are done.

#### Why does euler characteristic become $2-2g$?
- If we add a vertex on an edge, we add a vertex and subrtact the (new) edge we have created. Thus $\xi$ is unchanged on adding a vertex on an edge.
- Joining two vertices on a face also does not change $\xi$, since we add an edge and a face.
- Given any two subdivisios, we find a common finer subdivision by these steps. Since the steps we use retain the euler characteristic,
  finally my original subdiv = common subdiv = friend subdiv.
- Key idea: at each crossing between our subdivsion and the other subdivision, make a new vertex at every crossing. Then "trace over" the
  other subdivision to make our subdivision agree on the other subdivision on the inside.

https://www.youtube.com/watch?v=dUOmU-0t2Nc&list=PLIljB45xT85DWUiFYYGqJVtfnkUFWkKtP&index=27

# Gauss, normals, fundamental forms [TODO]

- consider a parametrization $r: u, v \to \mathbb R^3$
- at a point $p = r(u, v)$ on the surface, the tangent vectors are $r_u \equiv \partial_u r$ and similarly $r_v \equiv \partial_v r$.
- Let $k = xr_u + y r_v$. Then $k \cdot k$ is the **first fundamental form**. Computed as
  $k= (xr_u + y r+v) \cdot (x r_u + y r_v)$. Write this as $E x^2 + 2F x y + G y^2$.  These numbers depend on the point $(u, v)$,
  or equally, depend on the point $p = r(u, v)$.
- Further, we also have a normal vector to the tangent plane.$N(p)$ is the unit normal pointing outwards. We can describe it in terms
  of a parametrization as $n \equiv r_u \times r_v / ||r_u \times r_v||$.
- Gauss map / Gauss Rodrigues map ($N$): map from the surface to $S^2$. $N$ sends a point $p$ to the unit normal at $p$.
- The tangent plane to $N(p)$ on the sphere is parallel to the tanent plane on the surface at $p$, since the normals are the same,
  as that is the action of $N$ which sends the normal at the surface $p \in S$ to a point of the sphere / normal to the sphere.
- Thus, the the derivative intuitively "preserves" tangent planes! [as normal directions are determined].
- If we now think of $dN$, it's a map from $T_p S$ to $T N(p) S^2 = T_p S$. Thus it is a map to the tangent space to _itself_.
- In terms of this, gauss realized that gaussian curvature $K_2 = K = k_1 k_2$ is the determinant of the map $dN_p$ [ie, the jacobian].
  Curvature is the distortion of areas by the normal. So we can think of it as the ratio of areas `area of image/area of preimage`.

https://www.youtube.com/watch?v=drOldszOT7I&list=PLIljB45xT85DWUiFYYGqJVtfnkUFWkKtP&index=34

# Second fundamental form
- Let $z = f(x, y)$ be a (local) parametrization of the surface. Taylor expand $f$. we get:
- $f(x + dx, y + dy) = f(x, y) + dx^T a + dy^T b + dx^T L dx + 2 dx^T M dy + dy^T N dy$.
- We must get such a taylor expansion since our output is 1D (a real number), inputs are $dx, dy$ which are 3D vectors, and the infinitesimals
  must be linear/tensorial. These are the only possible contractions we can make.
- So, the second degree part can be written as:

$$
\begin{bmatrix} x & y\end{bmatrix}
\begin{bmatrix} L & M \\ M & N\end{bmatrix}
\begin{bmatrix} x \\ y\end{bmatrix}
$$

- the matrix in the middle, or the quadratic form $II \equiv dx^T L dx + 2 dx^T M dy + dy^T N dy$ is the second fundamental form.

#### Classical geometry
- Let $z = f(x, y)$ be a (local) parametrization of the surface.
- At each point $p ≡ (u, v)$ on the surface within the local parametrization,
  we get tangent vectors $r_u(p) ≡ (\partial_x f(x, y)_p, r_v(p) ≡ (\partial_y f(x, y))_p$ which span the tangent space at $p$
- These define a unique normal vector $n(p) ≡ r_u(p) × r_v(p)$ at each point on the surface. This gives us a normal field.
- The coefficient of the second fundamental form project the second derivative of the function $f$ onto the normals. So they tell us
  how much the function is escaping the surface (ie, is moving along the normal to the surface) in second order.
- Recall that this is pointless to do for first order, since on a circle, tangent is perpendicular to normal, so any dot product
  of first order information with normal will be zero.
- Alternatively, first order information lies on tangent plane, and the normal
  is explicitly constructed as perpendicular to tangent plane, so any dot product of first order info with normal is zero.
- We can only really get meaningful info by dotting with normal at second order.
- So we get that $L(p) = (\partial_x \partial_x f(x, y))(p) \cdot N(p)$, $M(p) = (\partial_x \partial_y f(x, y))(p)$, and $N(p) = (\partial_y \partial_y f(x, y))(p)$,
  where we define $L, M, N$ via second fundamental form

#### Proof of equivalence between 2nd fundamental form and geometry




#### Principal curvature
- take a point $p$. Consider the normal to the surface at the point, $N(p)$.
- Take any normal plane: a plane $Q_p$ which contains $N(p)$. This plane (which is normal to the surface, since it contains the normal)
  intersecs the surface $S$ at a curve (intuitively, since a plane in 3D is defined by 1 eqn, intersection
  with plane imposes 1 equation on the surface, cutting it down to 1D).
- The curvature of this curve (normal plane $Q_p$ intersection surface $S$) at point $p$ is the normal curvature of the normal plane $Q_p$.
- The maximum and minimum such normal curvatures at a point (max, min taken across all possible normal planes $Q_p$) are the principal curvatures.

#### Shape operator has principal curvatures as eigenvalues

- https://math.stackexchange.com/questions/36517/shape-operator-and-principal-curvature
- https://math.stackexchange.com/questions/3665865/why-are-the-eigenvalues-of-the-shape-operator-the-principle-curvatures

#### Shape operator in index notation

- Let $X$ be tangent vectors at point $p$, $N$ be normal to surface at point $P$. The shape operator $S_{ij}$
  is determined by the equation:
- $\partial_i \mathbf N = -S_{ji} \mathbf X_b$

# Theorem Egregium / Gauss's theorem (Integrating curvature in 2D) [TODO]

- Let $S$ be a 2 dimensional surface.
- Gauss Rodriguez map map: $N: S \to S^2$. The derivative of this map goes from $dN: T_p S \to T_p S^2$.
- Since surfaces are parametric, we can think of it as a map from $U \subset \mathbb R^n \to S \to S^2$.
- For gauss, the curvature of the surface at $p$ is $det(dN|_p)$. This tells us how small areas (on the tangent plane of $S$)
  is distorted (on the tangent plane of $S^2$, because it's the determinant / jacobian of the map. Thus, heuristically, it is the
  ratio of the area around $N(p)$ at $S^2$ to the area around $p$ at $S$

- To show that this normal curvature view really is curvature, let's compute $dN_p$ for a normal paraboloid. Wildberger says that
  all surfaces are like normal paraboloids upto second order.
- This fits with one of our views of curvature of a curve: one way was one over the osculating circle, the other was $k \cdot ds = d \theta$
- We had a formula like $\int k ds$ was a change in angle. Similarly, in our case, we see that if we consider $\int \int k(s) darea(s)$, we
  get the area of the image of $N$, because infinitesimally is the ratio of areas.
- In particular if the surface is homeomorphic to a sphere, then we get the total area of the sphere, $4 \pi$.. This is the 2D analogue of
  the fact that if we integrate the curvature of a closed curve, we get $2 \pi$. [area of a circle]. This is by green's theorem.

# Integrating Curvature in 1D [TODO]

- All curves are parametrized by _arc length_ to avoid weird artefacts by time parametrization.
- So $r(s)$ is a function from length of the curve to $\mathbb R^3$.
- The (unit?) tangent to a curve is given by $T(s) \equiv dr/ds = r'(s)$.
- The curvature is given by $\kappa(s) \equiv |dr^2/ds^2|$.
- The unit normal is given by $\hat N(s) r''(s) / \kappa(s)$.
- We wish to consider the total curvature, given by $\int_0^L \kappa(s) ds$ where $L$ is the total length of a closed curve on the plane.
- TODO: how to prove that this will be a multiple of $2 \pi$?


# Fundamental theorem of symmetric polynomials

- Every symmetric polynomial of variables $x, y, z$ can be written in terms of the elementary symmetric polynomials $\sigma_0 \equiv 1$,
  $\sigma_1 = x + y + z$, $\sigma_2 = xy + yz + xz$. Generalize appropriately.

### Two variable case

- For even further simplicity, consider the two variable case: every symmetric polynomial of variables $x, y$ can be written in terms of the
  elementary symmetric polynomials $\sigma_0 = 1$, $\sigma_1 = x + y$, $\sigma_2 = xy$.
- Consider some symmetric polynomial $p(x)$. Define an ordering on its monomials $x^ay^b > x^c y^d$ iff either $a + b > c + d$, or $a > c$, or
  $a = c \land b > d$. So we compare first by degree, then by $(a, b) > (c, d)$ lexicographically. Thus, call this order the *lex* order.
- Define `bigmon(p)` to be the largest monomial in $p(x)$. Define `bigcoeff(p)` to be the coefficient of `bigmon(p)`. Finally, define
  `bigterm(p) = bigmon(p) . bigcoeff(p)` as the leading term of the polynomial $p(x, y)$.
- Prove an easy theorem that `bigterm(pq) = bigterm(p)bigterm(q)`.
- Now, suppose we have a leading monomial $x^5y^9$. Actually, this is incorrect! If we have a monomial $x^5y^9$, then we will also have a monomial
  $x^9y^5$, which is lex larger than $x^5y^9$. Thus, in any leading monomial, we will have the powers be in non-increasing (decreasing order).
- OK, we have leading monomial $x^9 y ^5$. We wish to write this in terms of elementary symmetric polynomials. We could try and write this
  by using the leading term $x$ in $s_1$ and leading term $xy$ in $s_2$.
- This means we need to solve $x^9y^5 = x^k (xy)^l$, or $9 = k + l$ and $5 = l$. This tells us that we should choose $l = 5$ and $k = 9 - 5 = 4$.
  If we do this, then our combination of symmetric polynomials will kill the leading term of $p(x)$. Any new terms we introduce will be smaller than the
  leading term, which we can write as elementary symmetric polynomials by induction!

### Three variable case

- Now consider three variables. Once again, suppose $p(x)$ has leading monomial $x^ay^bz^c$. We saw earlier that we must have $a \geq b \geq c$ for
  it to be a leading monomial.
- Let's write it in terms of $s_1, s_2, s_3$. So we want to write it  as product of  $(x)^p$, $(xy)^q$, and $(xyz)^r$. Their product is
  $x^{p+q+r}y^{q+r}z^r$.
- This gives us the system of equations $x^{p+q+r}y^{q+r}z^r = x^ay^bz^c$. This means (1) $r = c$, (2) $q+r = b$ or $q = b - c$, and (3) $p + q + r = a$
  or $p = a - q - r = a - (b - c) - c = a - b$.

#### General situation

- think of the monomial $x^ay^bz^c$ as a vector $[a, b, c]$. Then the leading terms of the
  symmetric polynomials correspond to $[1, 0, 0]$, $[1, 1, 0]$, and $[1, 1, 1$].
- When we take powers of symmetric polynomials, we scale their exponent vector by that power.
  So for example, the leading term of $s_2^9$ is $x^9y^9$ which is $[9, 9] = 9[1, 1]$.
- When we multiply symmetric polynomials, we add their exponent vectors. For example, the leading term of $s_1 s_2$ is $x(x+y) = x^2 y = [2, 1]$. This is
  equal to $[1, 0] + [1, 1]$
- Thus, we wish to write the vector $[a, b, c]$ as a linear combination of vectors $[1, 0, 0]$, $[1, 1, 0]$, and $[1, 1, 1]$. This is solving the equation:

```
[a]   [1 1 1][p]
[b] = [0 1 1][q]
[c]   [0 0 1][r]
```

- subject to the conditions that the unknowns $p, q, r, \geq 0$, given knowns $a, b, c$
  such that $a \geq b \geq c$.
- Let's check that the equation makes sense: $a = p + q + r$ as all of $[1, 0, 0]$, $[1, 1, 0]$ and $[1, 1, 1]$
  have a $1$ at the $a$ position. Similarly for $b, c$.
- Solve by the usual back-substitution.

# DP over submasks
- https://codeforces.com/contest/1554/problem/B
- 5e8 operations is 1
- take every (mask, submask). The bits of the pair can be `1 1`, `1 0`, and `0 0`. So the pairs of all mask, submask will be `3^n`

```cpp
for(int m = N; m >= 0; m--) {
  for(int s = m; s = (s- 1) & m; ) {
    // get all submasks.
  }
}
```

- let `s` be a submask of `m`.
  [for arbitrary bits `abc` with the `1` shown being the rightmost 1, followed by all zeroes.]
- Consider the largest submask of `m` smaller than `s`, call it `t`. We wish to show that `t = (s-1)&m = abc011`.
- `t` is clearly a submask of `m`, since it is a submask of `s`.
- We wish to show that `t=(s-1)&m` is the greatest submask of `m` smaller than `s`.
- For contradiction, suppose `s > c > t` and `c` is a submask of `m`.
- Let `x` be the index of the rightmost 1 in `s` (`x` marks the spot).
  So `s` is of the form `s[n]s[n-1]...s[x]s[x-1]...s[0]` where
  `s[x]=1` and `s[x-1]=s[x-2]=...=s[0]=0`. So we can write `s = s[n]s[n-1]...;x:1;00..0`
- Now `t` is of the form `t = t[n]t[n-1]...;x:0;00..0`.
- Any number `c < s` must have for all indeces `i > x` such that `s[i] = 0` implies `c[i] = 0`.
- If `c` is such that for some index `i > x` where `s[i]=1` we have `c[i]=0`, then such a number will be less that `t`
  since `t[i]=s[i]=1`.
- Thus, for all indexes `i > x` we have `c[i]=s[i]`.

# Dual of Planar Euler graph is bipartite

### Proof by contradiction

- Euler graph is a graph with an euleian circuit, so we pass through every edge exactly once and return to the
  node we started from.
- Alternatively, every node has even degree. Consider the cycle as starting at some vertex `v`. To pass through all edges
  adjacent to `v` must mean that every time we leave `v` on a previously unused `v->_` we must return back to `v` via a unique edge `_->v`.
  This allows us to pair edges together uniquely, giving us an even number of edges at `v`.
- This argument works at any generic `v`, since we can think of a cycle as starting from any vertex.
- Thus, every vertex of `G` has even degree.
- Consider the dual graph `H := G*`.
- Suppose `H` is not bipartite, so `H` has an odd length cycle `O`.
- Let `K := H*` be the dual of `H`. Consider the face of `H` that is bounded by the odd length cycle `O`, call it `F(O)`. This face `F(O)`
  has an odd number of neighbours, one for each edge of `O`. So an number of edges in `K` connect `F(O)` to its neighbours.
  Thus, `K` has a vertex with an odd number of edges indicent on it.
- However, `K = H* = G** = G`. This implies that `G` has a vertex with an odd number of neighbours, contradicting its eulerian nature.

### Constructive proof

- Consider a graph embedding. Since the graph is eulerian, we get a path/closed curve
  `p: S^1 -> R^2` that traverses the graph along its euler tour.
- If the closed curve `p` has self-intersections, remove them by gently "spreading" `p`.
- This gives us two regions on the sphere, one inside the curve and one outside the curve (by jordan curve theorem).


- Key takeaway: Euler graphs are graphs you can draw with a pen.

### How this is different from hamiltonian circuit

Consider:

```
a----------b
|          |
f----------c
|          |
e----------d
```

- The cycle `a->b->c->d->e->f->a` is hamiltonian.
- There is no eulerian cycle since `f` has odd degree. So if we start from `f`, it is impossible to return to `f`.
- So hamiltonian circuits do not correspond (at least in this way) to geometry.


# Yoneda preserves limits


- Let $J$ be small, $C$ locally small.
- Let $F: J \to C$ be a diagram. Let $y : C \to [C^{op}, Set]$ be the contravariant yoneda defined by $y(c) \equiv Hom(-, c)$.
- Consider $y(\lim F) : C^{op} \to Set$. Is this equal to $\lim (y \circ F : J \to [C^{op}, Set) : C^{op} \to Set$?
- We know that limits in functor categories are computed pointwise. So let's start with $\lim (y \circ F) : C^{op} \to Set$.
  Let's Evaluate at some $e \in C^{op}$.
- That gives us $(\lim (y \circ F))(e) = \lim (ev_e \circ y \circ F : J \to Set) : Set$.
- Writing the above out, we get $\lim (ev_e \circ y \circ F) = \lim(\lambda j. (y(F(j))(e))$.
- Plugging in the definition of $y$, we ge $\lim( \lambda j. Hom(-, F(j))(e))$.
- Simplifying, we get $\lim (\lambda j. Hom(e, F(j))$.
- We know from a previous theorem that $\lim Hom(e, F(-)) =  = Hom(e, \lim F)$
- Thus, we get $\lim(\lambda j. Hom(e, F(j)) = Hom(e, \lim F)$.
- So we get $(\lim (y \circ F))(e) = Hom(e, \lim F)$.
- In general, we get $\lim (y \circ F) = Hom(-, \lim F)$, which is the same as $y \circ \lim F$.
- So we find that $\lim (y \circ F) = y \circ \lim F$, thereby proving that yoneda preserves limits.



# Separable Polynomials and extensions


#### Separable polynomial

- I didn't really study galois theory over char. $p$ all that well the first time I studied it, so let's review.
- Let $J \subseteq K$ be an inclusion of fields, so $K$ is a field extension of $J$.
- An irreducible polynomial $f \in J[x]$ is separable iff it has distinct roots in the algebraic closure of $J$, $\overline{J}$.
- Said differently, the polynomial $f$ has no repeated roots in any extension of $J$.
- Said differently, the polynomial $f$ has distinct roots in its splitting field over $J$. The roots as separable since we can separate
  all the roots from each other --- they are all distinct.
- Said differently, the polynomial derivative $f'$ of $f$ is not the zero polynomial.


#### Proof that $p$ is not separable iff $p, p'$ share a root

##### Forward: $p$ is not separable implies $p, p'$ do not share a root.
- Let $p$ have a repeated root $\alpha \in \overline K$. Thus $p(x) \equiv (x -\alpha)^2 g(x)$ in $\overline K$.
- Computing $p'$ by product rule, we see that it is $p'(x) = 2(x- \alpha)g(x) + (x - \alpha)^2 g'(x)$ which can be written as
  $p'(x) = (x - \alpha)(2g(x)+ g'(x)$.
- This shows that $p'(x)$ has $(x - \alpha)$ as a root.

##### Backward:$p, p'$ share a root implies $p$ is not separable

- Let $\alpha \in \overline K$ be such that $p(\alpha) = p'(\alpha) = 0$.
- Write $p(x) \equiv \prod_i (x - r_i)$ for roots $r_i \in \overline K$.
- Let $\alpha = r_1$ [WLOG].
- We know by product rule of calculus that $p'(x) \equiv \sum_i \prod_{j \neq i} (x - r_i)$.
- Computing $p'(\alpha) = p'(r_1)$, only the first term survives, which is $\prod_{j \neq 1}(r_i - r_j)$ [all other terms have an $(x - r_1)$ term which vanishes.
- For this to vanish, we must have some $j$ such  that $r_i = r_j$.
- This implies that $p$ has a repeated root $r_i, r_j$ and is thus not separable.


#### Proof that $p$ is separable iff $gcd(p, p') = 1$

##### Forward: $p$ is separable implies $gcd(p, p') = 1$
- Let $d(x) = gcd(p, p')$.
- Suppose that it is not a unit, and not a constant (ie, a real polynomial).
- Then $d(x)$  has a root $\alpha \in \overline K$ (by previous)
- Since $d$ divides $p, p'$, this means that in $\overline K$, $p(\alpha) = p'(\alpha) = 0$ since $d(\alpha) = 0$ and $d | p, p'$.
- This implies that $\alpha$ is a repeated root of $p(x)$ since it vanishes at both $p$ and its derivative!
- This contradicts $p$ is separable.
- Thus $d(x)$ must be a unit, and $p$, $p'$ are relatively prime.

##### Backward: $gcd(p, p') = 1$ implies $p$ is separable
- Since $gcd(p, p') = 1$, there are polynomials $k, l$ such that $pk + p'l = 1$.
- Suppose $p$ is not separable. Thus it has a repeated root $\alpha$. This means that $p$ and $p'$ vanish at $\alpha$. Thus $(x - \alpha)$ divides $p, p$'.
- Thus means that $(x - \alpha)$ divides $1$, by the eqn $pk + p'l = 1$. This is absurd, and thus $p$ is separable.

#### Separable extension

- For all elements $\alpha \in L$ where $L/K$, there is a polynomial $f_\alpha \in K[x]$ such that
  $f_\alpha(\alpha) = 0$ is **separable**.
- Thus, all elements have separable polynomials that they are roots of.

#### Separable extension is transitive
- Claim: If $R/Q$ and $Q/P$ are separable field extensions, then $R/P$ is separable.
- TODO!

#### All Polynomials over character 0 is separable

- Let $L/K$ and $char(K) = 0$. Then we claim that $L$ is separable.
- Let $f$ be an irreducible polynomial in $K[x]$. (the minimal polynomial of some element in $L$)
- Recall that a polynomial $f \in K[x]$ is irreducible over a field $K$ iff it cannot be written as the product of two non-constant polynomials.
- We wish to show that $f$ is separable (has no repeated roots).
- For contradiction, suppose that $f$ has a repeated root $r$ in the algebraic closure.
  so $f(x) \equiv (x - r)^2 g(x)$ for $r \in \overline K[x]$, $g(x) \in \overline K[x]$.
- Thus, $f(x)$ and $f'(x)$ *share a common factor* in $\overline K[x]$.
- But the GCD algorithm works in $K[x]$, thus $f(x)$ and $f'(x)$ share a common factor in $K[x]$ [SID: I find this dubious!]
- Hence, this means that $gcd(f, f') \in K[x]$ is not a constant polynomial.
- If $gcd(f, f') \neq f$, then $f$ can be factored, which contradicts its irreducibility.
- Thus, $gcd(f, f') = f$ [to prevent contradiction].
- However, $f'$ has smaller degree than $f$. Thus the only way it can be divided by its GCD ($f$) which has larger degree than it is if $f'(x) = 0$.
- This means (in characteristic zero) that $f(x)$ is linear, and thus cannot have repeated roots!
- That this means that $f(x)$ is zero can be seen by computing te derivative. Suppose $f(x) \equiv \sum_{i=0}^n a_i x^i$ with $a_n \neq 0$.
  Then $f'(x) = \sum_{i=1}^n i a_i x^{i-1}$. Since $a_n \neq 0$, $n a_n \neq 0$, and thus the derivative of an $n$th degree polynomial is $(n-1)$ degree.

#### All Polynomials over character 0 is separable, alternative proof.
- Let $f$ be an irreducible polynomial in $K[x]$ (the minimal polynomial of some element in $L$). We claim that $f$ is separable.
- The key lemma is to show that if $g$ is ANY polynomial which shares a root $r$ with $f$, then $f | g$.
- Idea: since $f(r) = g(r) = 0$, this means that $(x - r)$ divides $gcd(f, g)$. Thus, $gcd(f, g)$ is non-constant.
- Further, $gcd(f, g) | f$ since the gcd divides both its factors.
- But since $gcd(f, g)$ divides $f$ while $f$ is irreducible, we must have $gcd(f, g)$ equals $f$.
- Since $gcd(f, g) = f$ divides $g$, we have $f | g$.
- Now, going back to our claim, let $f$ be some irreducible in $K[x]$. Suppose for contradiction that $f$ is not separable. Then $f, f'$ share a common root.
  By the above lemma, this implies that $f$ divides $f'$. But this is absurd, since $deg(f) > deg(f')$.
- Hence, no irreducible polynomial in $f$ can share a root with its derivative, which implies $f$ is always separable.
- This breaks down for character $p$ since $f'$ can simply "die out".



#### All finite field extensions over character 0 is separable

- Can write any finite field extension $L/K$ as $L = K(\alpha_1, \dots, \alpha_n)$. This is the same as $K(\alpha_1)(\alpha_2)\dots(\alpha_n)$.
- Since separability of field extensions is transitive, and at each step, we add an element with separable minimal polynomial (all polynomials over char. 0 are separable),
  the full extension is separable.

#### All field extensions over character $p$ is separable

- Consider $F_{p^m} \subseteq F_{p^n}$.
- build the "Fermat's little theorem" polynomial $x^{p^n} - x = f(x)$.
- All elements of $F_{p^n}$ satisfy this, thus $f(x)$ has $p^n$ roots, which means all of its roots are distinct.
- Alternatively, see that $f'(x) = p^n x^{p^n - 1} - 1 = 0 - 1 = -1$ so $f(x)$ and $f'(x)$ don't share a commmon root.


#### Purely inseparable extensions

- $K \subseteq L$ of char. p. Then the field $L$ is purely inseparable iff
  any $\alpha \in L$ is  a root of $x^{p^n} - k$ for some $k \in K$, with
  $n \geq 1$.
- Over the algebraic closure, this can be written as $x^{p^n} - (k^{1/p^n})^{p^n}$ which over finite fields
  factorizes as $(x - \sqrt{a}{p^n})^{p^n}$ by [freshman's dream](https://en.wikipedia.org/wiki/Freshman%27s_dream).
- Thus, over the algebraic closure, this has many copies of one root, which is "as far as possible" from being separable.


#### Breaking down extension into separable + purely inseparable

- Given any $K \subseteq L$ algebraic, can break it down into $K \subseteq K^{sep} \subseteq L$.
- The extension $K^{sep}/K$ contains all elements of $L$ which have separable polynomials. Can show that this is a field.
- We can show that $L/K^{sep}$ will be purely inseparable.


#### Example of inseparable extension
- Let $L \equiv F_p(t)$, which are rational functions in $t$ over $F_p$, and $K \equiv F_p(t^p)$ which are rational functions in $t^p$.
- Clearly, $K \subseteq L$, and the extension $L/K$ is of degree $p$, because $t \in L$ is a root of $X^p - t^p \in F_p(t^p) = K$.
- See that $X^p - t^p$ is irreducible over $K = F_p(t^p)$.
- Over $L = F_p(t)$, $X^p - t^p$ factorizes as $(X - t)^p$ by [freshman's dream](https://en.wikipedia.org/wiki/Freshman%27s_dream), with all roots the same.
- Thus, we have an element whose minimal polynomial is not separable.
  Here, the function $g(Y) = Y^p - X \in K(X)$ has derivative zero, and is thus inseparable.
- In some sense, the failure is because of freshman's dream, where $X^p - t^p \equiv (X - t)^p$.
- Reference: [Borcherds, separable extension](https://www.youtube.com/watch?v=YvHFJi1d5N4&list=PL8yHsr3EFj53Zxu3iRGMYL_89GDMvdkgt&index=7)

#### Primitive element theorem / Theorem of the primitive element
- Let $J \subseteq K$ be a field extesion. We say $\alpha \in K$ is primitive for the extension $K/J$ (the extension) if $K = J(\alpha)$.
- If $K/J$ is a finite separable extension, then for some $\alpha \in J$, we have $K = J(\alpha)$.
- Recall that $J(\alpha) \simeq J[x]/minpoly(x)$.
- TODO!

#### Tensor product of field extensions

- Let $K$ be a finite separable extension of $J$ and $\Omega$ be an arbitrary extension of $J$. (usually, $\Omega$ is the p-adics,
  $J$ is $\mathbb Q$, $K$ is a number field).
- Then, $K \otimes_J \Omega$ is a product of finite separable extensions of $\Omega$. So $K \otimes_J \Omega \equiv \prod_i \Omega_i$,
  where each $\Omega_i$ is a finite extension of $\Omega$.
- If $\alpha$ is a primitive element for the extension $K$ (so $K = J(\alpha)$), then the image of $\alpha \otimes 1$ in $\Omega_i$
  is a primitive element for $\Omega_i$ over $\Omega$.
- If $f$ is the minimal poly. for $\alpha \in K$ over $J$ and $f_i$ is the minimal polynomial for $\alpha_i \in \Omega_i$ over $\Omega$ then
  $f(x) = \prod_i f_i(x)$.

- **Proof**: Start with a primitive element $\alpha$ for $K/J$. Then $K \simeq_\phi J[x]/(f(x))$
   for $f(x)$ the minimal polynomial of $\alpha$ over $J$. So $\phi$ witnesses this isomorphism.
- Consider $K \otimes_J \Omega$. This is isomorphic to $(J[x]/(f(x))) \otimes \Omega$. Call the map that sends the LHS to the RHS as $\phi \otimes id$
- We claim that the ring  $(J[x]/(f(x))) \otimes_J \Omega$ is isomorphic to $\Omega[x]/(f(x))$. Intuition: tensoring by $J$ doesn't do
  anything useful, and we can re-interpret $f(x)$ as living in $\Omega(x)$. The isomorphism is
  $\psi((g(x) + K(x)f(x)) \otimes \omega) \equiv \omega \cdot g(x) + \Omega[x]f(x)$.
- Now suppose $f$ factors as $\prod_i f_i$ over $\Omega[x]$. Since $\alpha$ is separable over $J$ and $\Omega$ is an extension of $J$,
  all the $f_i$ are distinct (otherwise it contradicts separability). Thus the family of ideals $\{ (f_i) \}$ is pairwise coprime.

# Limits of a functor category are computed pointwise.

#### Reduction to discrete category

- Let's take a functor category $[X, Y]$.
- Take a diagram $D: J \to [X, Y]$. What is the limit $\lim D: [X, Y]$?
- First, let's assume that $X$ has no arrows, or that we forget all the arrows of $X$ except the identity
  arrows. denote this forgotten/discrete category by $ob(X)$, whose objects are those of $X$, and morphisms
  are only identity morphisms.
- We can define the diagram $ob(D): J \to [ob(X), Y]$. Can we compute $\lim ob(D)$?
- A functor $ob(X) \to Y$ is the same as a tuple $Y^{ob(X)}$. See that $Y^{ob(X)}$ lives in `CAT`,
  since it is a category that is the $ob(X)$ copies of $Y$.

#### Formal proof by limits of product categories

- Now, the limit $ob(D)$ can be interpreted as a limit of $ob(D): J \to Y \times Y \times \cdots \times Y$.
- By the universal property of the product, limits over product categories can be
  computed _pointwise_. So if we have a diagram $E: K \to X \times Y$, then $l \equiv \lim E$ can be calculated by
  calculating $l_x \equiv \lim (\pi_1 \circ E : K \to X)$, then $l_y \equiv \lim (\pi_2 \circ E : K \to Y)$,
  and then setting $l \equiv (l_x, l_y) \in X \times Y$.
- Thus, we split the morphism $ob(D): J \to Y \times Y \times \cdots \times Y$ into the individial tuple
  components, which correspond to the images of $x \in ob(X)$ under $D$, and we compute their limits.
  So we can compute this pointwise.

#### Draw the right diagram.

- Suppose we had `J = (f -a-> h <-b- g)`, and we had `ob(X) = (p q)`. We only have objects, no morphisms.
- Now, what is a diagram `ob(D): J -> [ob(X), Y]`? For each of `f, g, h` in `J`, we must get a functor
  from `ob(X)` to `Y`.
- Denote `F = ob(D)(f)`, `G = ob(D)(g)`, and `H = ob(D)(h)`. Each of `F, G, H` are functors `ob(X) -> Y`.
- I'll write the functors by identifying them by their image. The image of `F` is going to be `[Fp Fq]`
  with no interesting morphisms between `Fp` and `Fq`.
- Now, that we've considered the action of `ob(D)` on objects of `J`, what about the arrows?
- The images of the arrows `f -a-> h` and `h <-b- g` are natural transformations from `F` to `H` and
  `G` to `H` respectively. Denote these by  `F =α>= H` and `H <=β=G`. So we have `ob(D)(a) = α`, `ob(D)(b) = β`.
- In total, the image of `ob(D)` in `[ob(X), Y]` looks like this:

```
F =α=> H <=β= G
```

- If we expand out the functors by identifying them with the image, and write the natural transformations in terms
  of components, it looks like so:

```
[Fp     Fq]
 |       |
 αp     αq
 v       v
[Hp      Hq]
 ^       ^
 βp      βq
 |       |
[Gp      Gq]
```

- Really, the diagram consists of two parts which don't interact: the part about `p` and the part about `q`.
  So computing limits should be possible separately!

#### This extends to `[X, Y]`

- We now believe that given $D: J \to [X, Y]$, we know that we can compute $ob(D): J \to [ob(X), Y]$ pointwise.
- Formally, we define  $[\lim ob(D)](x)$ to be equal to $\lim (ev_x \circ D : J \to Y)$.
- We define the action of $\lim D$ (which is a functor from $X$ to $Y$) on objects of $X$ to be equal to the action of
  $\lim ob(D)$ on objects of $X$, which is given by the above equation.
- So what about the action of $\lim D$ on the _morphisms_ of $X$? it's a functor from $X$ to $Y$, so it should send
  morphisms to morphisms!
- Now, let's suppose we have a morphism $x \xrightarrow{a} x'$ in $X$. How do we compute the the action of $D$ on the morphism $a$?
- Well, first off, what's $D(a)$ a morphism between? It must be between $D(x)$ and $D(x')$.
- What is $D(x)$? We know that $D(x) \equiv \lim (ev_x \circ D: J \to Y)$. Similarly, we know that $D(x') \equiv \lim ev_x' \circ D: J \to Y)$.

# `a + b = (a or b) + (a and b)`

- `0 + 0 = or(0, 0) + and(0, 0)`
- `0 + 1 = or(0, 1) + and(0, 1)`
- `1 + 1 = or(1, 1) + and(1, 1)`
- Extend by linearity?


# Intuition for why choosing closed-closed intervals of `[1..n]` is $(n+1)C2$

- $nC2$ counts all intervals $\{ [i, j]: i > j \}$.
- To count intervals $[i, i]$, there are $n$ of them, so it's $nC2 + n$ which is $n(n-1)/2 + n $,
   which is $n(n+1)/2$ or $(n+1)C2$.
- Combinatorially, add a "special point `*`" to `[1..n]`. If we pick a pair `(i, *)` from the $(n+1)C2$,
  take this to mean that we are picking the interval `[i, i]`.



# Thoughtful discussion on the limits of safe spaces

> (2) You cannot make all valuable, positive, motivated people feel safe. It's really sad, but there are fundamental incompatibilities in the kind of safety that different people need (even before we get to what makes them productive--you can't even make everyone feel comfortable!). I think this discussion has demonstrated amazing attempts by people at understanding and incorporating different perspectives, but at the end of it all, some people are going to have to be triaged out, or will have to accept some lack of safety. Two examples: (a) people with low self-esteem tend to find confrontational environments unsafe emotionally, but many neurodivergent people tend to find environments that require high social awareness unsafe emotionally. You can ameliorate this contradiction somewhat with careful guidelines, but fundamentally the problem cannot be solved: the neurodivergent simply cannot do what the emotionally fragile require of them, so one or the other or both is going to have a bad time. There is nothing wicked about either of these people! But they're not compatible. (b) people of a category that has faced systematic discrimination often do not feel safe with "free speech" that is allowed to get anywhere near sounding like discrimination against them (for very good reason!), but people who have exposure to thought-policing with severe consequences for disobedience often do not feel safe with anything less than very broad construal of "free speech". This one's even harder, because both sides can have really deep emotionally salient reasons for their perspective, and yet they are incompatible. There is nothing wicked about either of these people! But different types of wickedness have been done to them or are reasonably feared by them, rendering them incompatible with
each other.


> you are not literally able to make a community welcoming to everyone who, one-on-one, you would consider a good person. Sometimes you can get a few extra valuable people by special-casing things. (E.g. a reasonable response to "I don't understand respect" might be "we are still going to call it respect, but we will maintain an additional note approximating what 'act with respect' means in terms of other concepts that might be easier to actualize for some people".)


> I agree that it is not possible to resolve fundamental incompatibilities through policy. However, it often is resolvable through mediation, a third party who can deal with the needs of both sides and is willing and able to translate, clarify, provide private feedback, and otherwise help smooth over the situation.
- [Link of NixOS RFC](https://github.com/NixOS/rfcs/pull/98#issuecomment-904229049)



# Semidirect product: Panning and Zooming

- I think I finally have an example of a semidirect product that I understand well enough I'd dare to teach a friend.
- Take the real line. We can move points on it by adding them (panning). Viewed differently, we can _pan_ the real line left and right,
  by the action of the real line on itself. This is a group $P \simeq (\mathbb R, 0, +)$ ($P$ for pan).
  I'll draw the line as follows:

```
  ^
  |
  |
  0
  |
  |
  v
```

  - Next, we can _zoom_ the real line by multiplication: So given a number, I can scale the entire real line by this number.
    This group of zoom operations is $Z \simeq (\mathbb R, \times 1)$.I'll show this by stacking copies of the real line next to each other:

```
    ^
    |       ^
    |       |        ^
Z---[z=1]---[z=1/2]--[z=1/4]----...
    |       |        V
    |       V        P
    v       P
    P
```

- So we show the group `Z` on the horizontal axis, which zooms the real line. We "attach" a copy of `P` to each element `z` of `Z`,
  appropriately scaled.

- How should I write the pan-and-zoom operation as a single unit? I'll denote by `(z, p)` the operation of panning by `p` and then
  zooming by `z`. Why not the other order? Well, if I zoom first by `z` and then pan by `p`, the pan `p` gets "disturbed" by the zoom,
  since the pan would like to talk about the _initial_ state of the world, but we now need to pan with respect to the world _after_ zooming.
  So we prefer the order where we can pan first (with no zoom interfering with our affairs), and then zoom.
- How do these combine? If we have `(1, p) . (1, p')` we get `(1, p + p')` since combining pans at zoom level `1x` is like
  us not having zooming. Similarly, combining `(z, 0) . (z', 0)` is `(zz', 0)`, since zooming by `z` with no pan followed by `z'` is the same
  as zooming in one shot by `zz'`.
- What about `(z, p). (z', p')`? What does it mean? It means we should (a) pan by `p`, (b) zoom `z`, (c) pan by `p'`, (d) zoom `z'`.
  See that the total zoom will be `zz'` at the end of this operation. What about the total pan? the second pan by `p'` happens _after_ we
  have already zoomed by `z`. So relative to _no_ zoom, this is a pan by `zp'`. So in total, we can replace by an operation which (1)
  pans by `p + zp'`, and then (2) zooms by `zz'`. So we have that `(z, p).(z', p') = (zz', zp + p')`. This is a _semidirect_ product.
- If we stare at the picture above, we see that we have many copies of `p`, one for each `z`. So the full group is like `Z x P`.
- It's hopefully clear that if we "squish" the `P`s, (ie, quotient by `P`) down towards the `Z`, we'll still have a fully functioning `Z` group.
- On the other hand, if we attempt to "squish" the `Z`s(ie, quotient by `Z`) down towards a single `P`, we'll be left with _incompatible_ copies
  of `P`, each at different scales! This tells us that we _can_ quotient by `P` (so `P` is normal), but _not_ by `Z` (so `Z` is not normal).
- So, this is sort of like a vector bundle `P -> Z |x P -> Z` where the fibers are `P` and the base space is `Z`. We can remove the fibers
  to recover the base space. You can't delete the base space, since there's no way to make the fibers "compatible".



# Longest Convex Subsequence DP

- This was an enlightening problem to solve due to the presence of many degenerate cases.
- The question: given an array `xs[]`, find the length of the longest subsequence `ys[]` such that for all indexes `0 <= l < m < r < |ys|`, we have that
  `2*ys[m] < ys[l] + ys[r]`.
- Key DP idea: `dp[maxm][maxr]` is the length of the longest convex subsequence with penultimate index `<= maxm` and final index `<= maxr`.

- The bare recurrence (without thinking about base cases) can be implemented as follows:

```cpp
int f(vector<int> &xs) {
    const int n = xs.size();
    vector<vector<int>> dp(n, vector<int>(n, 0));

    for (int r = 0; r < n; ++r) {
        for (int m = 0; m < r; ++m) {
            for (int l = 0; l < m; ++l) {
                if (2 * xs[m] < xs[l] + xs[r]) {
                    dp[m][r] = max<int>(dp[m][r], 1 + dp[l][m]);
                }
            }
        }
    }

    return ???;
}
```

- The "problem" is to deal with the degenrate cases where the array has only length 0, length 1, or length 2 when the DP conditions don't
  kick in. How does one implement these neatly?

- The insight is to see that at each location in the program, we have a _lower bound_ on the best DP value we can achieve. For example,
  at the beginning, we know that `best >= 0`. When we enter into the loop of `r`, we know that we have at least one element, so `best >= 1`,
  and so on. If we insert these lower bounds systematically into the code, we arrive at:

```cpp
int f(vector<int> &xs) {
    const int n = xs.size();
    vector<vector<int>> dp(n, vector<int>(n, 0));
    int best = 0;

    for (int r = 0; r < n; ++r) {
        ATLEAST1: best = max<int>(best, 1);
        for (int m = 0; m < r; ++m) {
            ATLEAST2: best = max<int>(best, 2);
            dp[m][r] = 2;
            for (int l = 0; l < m; ++l) {
                if (2 * xs[m] < xs[l] + xs[r]) {
                    dp[m][r] = max<int>(dp[m][r], 1 + dp[l][m]);
                }
                best = max<int>(best, dp[m][r]);
            }
        }
    }

    return best;
}
```

- We see that whenever we "learn" more information, we increase `best`, possibly without being able to even initialize `dp[.][.]`!
  This happens for example at `ATLEAST1:`, where we have one element so we know that `best >= 1`, but we don't have two elements to initialize
  the DP array.

# Representation theory of $SU(2)$ [TODO]

- `2x2` unitary matrices, so $AA^\dagger = I$.
- Lie algebra is $su(2)$, which are of the form $A^\dagger = -A$, and $Tr(A) = 0$.
- We write $M_v \equiv \begin{bmatrix} ix & y + iz  \\ -y + iz & -ix \end{bmatrix}$.
- The group elements _are_ matrices, so this is the standard representation, which goes from $SU(2)$ to $GL(2, \mathbb C)$.
  Turns out this is irreducible, 2D complex representation.
- We have a transformation which for a $g \in SU(2)$ creates a map which sends a matrix $M_v$ to $g M_v g^{-1}$.
  so the representation is $g \mapsto \lambda M_v. g M_v g^{-1}$, which has type signature $SU(2) \to GL(su(2))$.
  This is a 3D, real representation: the vectors $M_v$ have 3 degrees of freedom.
- We like complex representations, so we're going to build $SU(2) \to GL(su(2) \otimes \mathbb C)$.
- There is the trivial representation $\lambda g. (1)$.
- There is a zero dimensional representation $\lambda g. ()$ which maps $\star \in \mathbb C^0$ to $\star$. So it's the identity transformation
  on $\mathbb C^0$.

#### Theorem

For any integer $n $ there is an irrep $R_n: SU(2) \to GL(n, \mathbb C)$. Also, any irrep $R: SU(2) \to GL(v)$ is isomorphic to one of these.


#### New representations from old

- If we have $R: G \to GL(V)$ and $S: G \to GL(W)$, what are new representations?
- For one, we can build the direct sum $R \oplus S$. But this is useless, since we don't get irreps.
- We shall choose to take tensor product of representations.
- Symmetric power of $R: G \to GL(V)$  is $R^{\otimes n}: G \to GL(V^{\otimes n})$. This is not irreducible because it contains
  a subrep of symmetric tensors .
- Example, in $C^2 \otimes C^2$, we can consider $e1 \otimes e1$, $e2 \otimes e2$, and $e1 \otimes e2 + e2 \otimes e1$.

- Define $Av$ (for averaging) of $v_1 \otimes v_2 \dots v_n$ to be $1/n! \sum_{\sigma \in S_n} v_{\sigma(1)} \otimes v_{\sigma(2)} \dots v_{\sigma(n)}$.
  In other words, it symmetrizes an input tensor.
- Define $Sym^n (V) = Im(Av: V^{\otimes n} \to V^{\otimes n})$. We claim that $Sym^n(V)$ is a suprep of $V$.
  We do this by first showing that $Av$ is a morphism of representations, and then by showing that the image of a
  morphism is a sub-representation.

#### Weight space decomposition

- $SU(2)$ contains a subgroup isomorphic to $U(1)$. Call this subgroup $T$, which is of the form
   $\begin{bmatrix} e^{i \theta} & 0 \\ 0 & e^{-i \theta} \end{bmatrix}$.
-

- [Reference](https://www.youtube.com/watch?v=bS-UhmV5DaE&list=PLN_4R2IuNuuRgJb00X2J53Iq9qe7k1nyr&index=26)

# Why quaternions work better

- We want to manipuate $SO(3)$. Imagine it like $SO(1)$.
- Unfortunately, $\pi_1(SO(3)) = \mathbb Z/2\mathbb Z$. This is a pain, much like rotations of a circle need to be
  concatenated with modulo, which is a pain.
- idea for why $\pi_1(SO(3))$ is $\mathbb Z/2\mathbb Z$: $SO(3)$ is sphere with antipodal
  points identified. So a path from the north pole to the south pole on the sphere is a "loop" in $SO(3)$.
  Concatenate this loop with itself (make another trip from the south pole to the north pole) to get a full loop around
  the sphere, which can be shrunk into nothing as $\pi_1(S^2)$ is trivial. So $ns^2 = e$, where $ns$ is the north-south path in $S^2$
  which is a loop in $SO(3)$).
- Key idea: deloop the space! How? find univesal cover. Lucikly, universal cover of $SO(3)$ is $SU(2)$ / quaternions, just as
  universal cover of $SO(1)$ is $\mathbb R$.
- Universal cover also explains why $SU(2)$ is a _double_ cover. Since $\pi_1(SO(3))$ is $\mathbb Z/2Z$, we need to deloop "once"
  to get the delooped space.
- No more redundancy now! Just store a bloch sphere representation, or a quaternion (store $SU(2)$).
  Just like we can just store a real number for angle
  and add it.
- How to go back to $SO(3)$ or $SO(1)$? Move down the universal cover map $SU(2) \to SO(3)$ or $\mathbb R \to \mathbb SO(1)$.
- This is strange though. Why is $\mathbb R$ both the _lie algebra_ and the _covering space_ of $SO(1)$ ? What about in general?
- In general, the original lie group $SO(3)$ and the universal cover $SU(2)$ both have the same _lie algebra_. It is only
  that the lie group has less or more fundamental group.


# DFA to CFG via colimits?

- Can convert a CFG to DFA by keeping an arbitrary limit on the depth of the stack, counting
  how many elements are in the stack, and going to a failure state when we exceed the depth.
- If we do so, can get a DFA for each natural number --- this is the max stack depth we keep track of.
- Can we now define a _colimit_ of these DFAs? does this recover the CFG?
- If so, what is the correct category? And is the colimit completion of DFA correspond to DPDA/CFG?

# Why pointless topology is powerful

- Key idea of pointless topology: topology manipulates open sets and their lattice. Forget the set, simply manipulate lattices!
- When can a lattice be written in terms of sets?
- Birkhoff representation theorem: Lattice is distributive iff isomorphic to a lattice of subsets of join-irreducible elements.
- Hence, if we take _non distributive lattices_, we have geometry (locale) which _has no incarnation_ as subsets!
- Yay, extra power.

# Denotational semantics in a few sentences

- We want to find a math object that reflects lambda calculus
- Such an object must contain its own space of functions; $L \simeq [L \to L]$.
- This is impossible for cardinality constraints.
- Key idea: restrict to _continuous_ functions! $L \simeq [L \xrightarrow{\texttt{cont}} L]$.
- Solutions exist! Eg. space of continuous $[\mathbb N \to \mathbb N]$ with appropriate topology is like
  space of "eventually stabilizing sequences", which is equinumerous to $\mathbb N$, since sequences that eventually
  become stable have information $\cup_{i=0}^\infty \mathbb N^i$. This has the same cardinality as $\mathbb N$.
- For continuity in general, we need a _topology_.
- OK, now that we know this is what we need, how do we exhibit a space $L \simeq [L \to L]$? One invokes the hammer of [domain theory](http://www.cs.nott.ac.uk/~pszgmh/domains.html)
- Now that we have the space $L$, what's the right topology on it? That's worth
  a turing award! [The Scott topology](https://en.wikipedia.org/wiki/Scott_continuity)





# Monge Matrix

- Suppose we two line segments`AB`, `CD`:

```
A   C
@   @
@   @
@   @
B   D
```

- What is the relationship between the lengths `|AC| + |BD|` (straight lines) versus `|AC| + |BD|` (diagonals)?
- Draw the diagonal, label the point of intersection of diagonals as `I`.

```
A---C
@\ /@
@ I @
@/ \@
B---D
```

- By triangle inequality, we have that `AI + IC > AC` and `BI + ID > BD`. Adding these up, we get
  `(AI + IC) + (BI + ID) > AC + BD`.
- Rearranging we get `(AI + ID) + (BI + IC) > AC + BD`, which is equal to `AD + BC > AC + BD`.
- So, the _sum of  lengths between opposite points is greater than sum of lengths between non-opposite points_.
- If we think of this as a matrix `dist[A/B][C/D]`, we have that `dist[a][d] + dist[b][c] > dist[a][c] + dist[b][d]`.
- If we replace `A=0`, `B=1`, `C=0`, `D=1` (since those are the indexes of the points on the two line segments),
  we get `dist[0][1] + dist[1][0] > dist[0][0] + dist[1][1]`
- If we generalize to _sets_ of points on a line, let's have the indexes `i, j`.
  Then the condition would read `dist[i][j] + dist[j][i] > dist[i][i] + dist[j][j]`.
- A matrix `dist[.][.]` which obeys this condition is said to be a _Monge Matrix_.


#### Theorem: Monge matrices are totally monotone


#### Theorem: totally monotone matrices have ascending row minima

#### 1D 1D DP [TODO]

- https://robert1003.github.io/2020/02/29/dp-opt-knuth.html
- Suppose we have a dp $dp[r] = \min_{0 \leq l \leq r} f(l, r)$. That is, we need to find row minima for
  each row $r$ in a 2D matrix.
- Now assume that $f(l, r)$ has ascending row minima

# Fixpoint as decorator

```py
#!/usr/bin/env python3
class Thunk:
    def __init__(self, func, *args):
        self.func = func
        self.args = args
    def force(self):
        return self.func(*self.args)

def fix(f):
    return f(Thunk(fix, f))

@fix
def fact(f):
    def fact_n(n):
        if n == 0: return 1
        else: return n * (f.force())(n-1)
    return fact_n

print(fact(5))
```

# Combinatorial generation algorithms

- [Visual Guide to Combinatorial Search](https://computationalcombinatorics.wordpress.com/2012/11/28/a-visual-guide-to-combinatorial-search/)
- [Slides](https://faculty.coe.drexel.edu/jwalsh/Jayant_Mckay.pdf)
- [Method of homomorphisms](https://www.molgen.de/download/pubs/AlgGroupActDIMACS.pdf)
- [Canonical Construction Path/Canonical Deletion](https://computationalcombinatorics.wordpress.com/2012/08/13/canonical-deletion/)-
- [Orbital Branching](https://computationalcombinatorics.wordpress.com/2012/10/21/introduction-to-orbital-branching/)
- [Ranking/Unraking permutations](https://computationalcombinatorics.wordpress.com/2012/09/10/ranking-and-unranking-of-combinations-and-permutations/)

# Perform DP on measures, not indexes.

- In the problem of longest common subsequence (or any string problem in general), we should
  conceptually think of the DP state as the _length_. This gives us a natural base case (`length = 0`),
  as well as makes it much clearer to implement. Compare (1) LCS using indexes as DP state:

```cpp
int lcs_len(const vector<int> &xs, const vector<int> &ys) {
    // dp[i][j]: LCS between xs[0:i] and ys[0:j] [closed-closed].
    vector<vector<int>> dp(xs.size(), vector<int>(ys.size(), 0));
    int best = 0;
    for(int i = 0; i < xs.size(); ++i) {
        for(int j = 0; j < ys.size(); ++j) {
            if (i > 0 && j > 0) { dp[i][j] = max(dp[i][j], dp[i-1][j-1]); }
            if (i > 0) { dp[i][j] = max(dp[i][j], dp[i-1][j]); }
            if (j > 0) { dp[i][j] = max(dp[i][j], dp[i][j-1]); }
            if (xs[i] == ys[j]) {
                const int prev = i > 0 && j > 0 ? dp[i-1][j-1] : 0;
                dp[i][j] = max(dp[i][j], 1 + prev);
            }
        }
    }
    return dp[xs.size()-1][ys.size()-1];
}
```

- Versus using length as DP state:

```cpp
int lcs_len(const vector<int> &xs, const vector<int> &ys) {
    // dp[lx][ly]: LCS between xs[0:lx) and ys[0:ly) [closed-open].
    // lx, ly for ``length of xs, length of ys''
    vector<vector<int>> dp(1+xs.size(), vector<int>(1+ys.size(), 0));
    int best = 0;
    for(int lx = 1; lx <= xs.size(); ++lx) {
        for(int ly = 1; ly <= ys.size(); ++ly) {
            dp[lx][ly] = max(dp[lx-1][ly-1], dp[lx][ly-1], dp[lx-1][ly]);
            if (xs[lx-1] == ys[ly-1]) {
                dp[lx][ly] = max(dp[lx][ly], 1 + dp[lx-1][ly-1]);
            }
        }
    }
    return dp[xs.size()][ys.size()];
}
```

- Length is more natural, because `length=0` actually corresponds to a degenerate case.
- In general, whenever performing DP, you will likely always need _extra states_ for the degenerate case. It's a good thing
  to have this, since it simplifies a TON of the implementation work!


# Alternative version of Myhill-Nerode

- In one version of myhill-nerode I know, the states correspond to equivalence classes of strings under the equivalence relation $x \sim y$
  iff forall strings $s$, $x + s \in L \iff y + s \in L$.
- In another version (V2), we define the _right context_ of a string $w$ to be the set of all suffixes $s$ such that $w + s  \in L$.
  That is, $R(w) \equiv \{ s \in A^* : w + s \in L \}$.
- This induces an equivalence relation where $x \sim y$ iff $R(x) = R(y)$.
- In this version (V2), the states are the right contexts of all strings in the language.
- The transitions are given by concatenating strings in the set with the new character.
- The initial string corresponds to the right context of the empty word.
- The accepting states are those which correspond to right contexts of words in the language.
- This version is much more explicit for computational purposes! We can use it to think about what the automata looks like for small
  languages, in particular for the suffix automata.


# Polya Enumeration

- Let $X$ be a set of objects with the action of a group $G$. For example, $X$ is the configurations of a square, represented as 4-tuples
  by reading the vertices offin clockwise order, and let $G$ be the group of symmetries of a square.
- Let $C$ be the set of colorings $c_1, c_2, \dots c_n$.
- Let the objects of $X$ be _colored_ . That is, we have functions $f: X \to C$ which assigns a color $C$ to each element of $X$.
  Let $Y$ be the set of colorings $X \to C$.
- We extend the action of the group to the colorings, given by $g (f) \equiv \lambda x. g^{-1}(x)$. This makes the action of the group
  _consistent_.
- What's this funny inverse? Well, the idea is this. We _really_ have that $(gf)(gx) \equiv g(f(x))$, as the group must act
  in an _invariant_ way on the function space and the domain space. So to definethe expression of $(gf)(x')$, we  think of it
  as $(gf)(x') = (gf)(g(g^{-1}x')) = f(g^{-1}x')$.
- Define the weight of a coloring $h \in Y$, (ie $h: X \to C$) to be the monomial given by the product of colors;
  $wt(h) \equiv \prod_{x \in X} h(x)$. The weight $wt(h)$ is a monomial in the commutative ring $R[c_1, c_2, \dots, c_n]$.
- **Statement of Polyma Enumeration:**
  The weight enumerator for the action $G$ on $Y \equiv (X \to C)$ is equal to the cycle index polynomial $Z(G, X)$ with $z_i$ replaced
  by the power sum symmetric polynomial $P[p](\vec c) \equiv c_1^p + c_2^p + \dots + c_n^p$.

#### Proof via Weighted Burnside Lemma

- Let $g \in G$. By weighted version of Burnside Lemma, we have that

$$
\sum_{O \in Orb(Y)} wt(O) \equiv 1/|G| \sum_{g \in G} \sum_{y \in Fix(g)} wt(y)
$$

- Suppose that $g \in G$ have a cycle monomial $z_1^{k_1} \dots z_m^{k_m}$. That is, we _kount_ such that
   $g$ has $k_1$ cycles of length $1$, $k_2$ cycles of length $2$,
  and so on upto $k_m$ cycles of length $m$. So $g$ has $k_i$ cycles of length $i$.
- We want to know which colorings $y \in Y$ are fixed by $g$.
- Suppose a coloring $y: X \to C$ is fixed by $g$, so $g(y) = y$. Since $g$ pushes things around in its cycles,
  for each cycle in $g$, we must use _a constant color_.
- Said differently, all elements in the same cycle of $g$ have the same color.
- Thus for each cycle of length $l$, We must color all of the $l$ elements (of $X$) with the same color.
- We can color distinct cycles independent of each other.
- Thus the weight of a cycle of length $1$ is given by $(c_1 + c_2 + \dots + c_n)$, since we can color the single element with
  _either_ $c_1$ _or_ $c_2$ and so on upto $c_n$.
- The weight of a cycle of length $2$ is given by $(c_1^2 + c_2^2 + \dots + c_n^2)$, since we can color the _two_ elements in the cycle
  with _either_ $c_1$ _or_ $c_2$ and so on upto $c_i$.
- The weight of a cycle of length $l$ is given by $(c_1^l + c_2^l + \dots + c_n^l)$ since we can color the $l$ elements in the cycle.
- Since we the element $g$ has $k_1$ cycles of length $1$, the weight of _all_ cycles of length $1$ is $(c_1 + c_2 + dots + c_n)^k_1$.
- Since we the element $g$ has $k_2$ cycles of length $2$, the weight of _all_ cycles of length $2$ is $(c_1^2 + c_2^3 + dots + c_n^2)^k_2$.
- Since we the element $g$ has $k_l$ cycles of length $l$, the weight of _all_ cycles of length $l$ is $(c_1^l + c_2^l + dots + c_n^l)^k_l$.
- Thus, the total weight of $g$ is given by the polynomial $cyc(g)(p_1(\vec c), p_2(\vec c), \dots, p_l(\vec c))$.

#### Example: Weight enumerator for square with $D_4$ actions.

- $G \equiv D_4$
- $X$ is the configurations of a square.
- $C$ are the colors $r, g, b$.
- $Y$ is the set of colorings of $X$ by $C$.

# Weighted Burnside Lemma

- I'm learning the weighted burnside lemma as a preamble to polya enumeration.
- Define for a set $X$ with a group action $G$, a weight function on the orbits $O$.
  Said differently, we have a weight function $w: X \to W$ such that $w(x) = w(g(x))$ for all $x \in X$ and $g \in G$.
- We wish to count the orbits of $X$ weighted by the weight function $w: X \to W$ (where $W$ is a commutative ring).
  So we wish to find $\sum_{o \in Orb(X)} w(o)$.
- Recall that Burnside tells us that:

$$
|X/G| = \sum_{g \in G} |Fix(g)|
$$

- We replace cardinality with weight, giving us the statement:

$$
\begin{aligned}
&w(X/G) = 1/|G| (\sum_{g \in G} w(Fix(g))) \\
&=\sum_{[o] \in X/G} w(o) = 1/|G| (\sum_{g \in G} \sum_{x \in Fix(g)} w(x) )
\end{aligned}
$$

- In english, this reads: for each orbit in $X/G$, pick an equivalence class representative $o$. The sum of weights of the representatives
  equals the average over $G$ of the fixpoint-weights.


#### Proof

- We begin by considering the LHS:
- $y = \sum_{g \in G} \sum_{x \in Fix(g)} w(x)$.
- We switch the order of summation to get $y = \sum_{x \in X} \sum_{g \in G} [gx = x] w(x)$ where $[gx = x]$ is the Iverson bracket --- it
  evaluates to 1 if $gx = x$ and $0$ if $gx \neq x$.
- We pull the constant $w(x)$ out to get $y = \sum_{x \in X} w(x) (\sum_{g \in G} [gx = x])$.
- We see that $\sum_{g \in G} [gx = x]$ is the cardinality of the stabilizer of $x$, written as $|Stab(G, x)|$.
  So we write this as $y = \sum_{x \in X} |Stab(G, x)| w(x)$.
- By orbit stabilizer, we use $|Stab(G, x)| \cdot |Orb(G, x)| = |G|$. Thus, we get
  $y =  |G|  \sum_{x \in X}  w(x) / |Orb(G, x)|$.
- Since the set of orbits partitions $X$, we write the above as
- $y = |G| \sum_{[o] \in G/X} \sum_{x \in [o]} w(x)/|Orb(G, x)|$.
- Since $[o]$ is the orbit of $x$, we replace $Orb(G, x)$ with $o$, giving $y = |G| \sum_{[o] \in G/X} \sum_{x \in [o]} w(x)/|[o]|$.
- Since the weight is constant on orbits, we replace $w(x)$ by $w(o)$ giving $y = |G| \sum_{[o] \in G/X} \sum_{x \in [o]} w(o)/|[o]|$.
- We pull the inner terms out giving $y = |G| \sum_{[o] \in X/G} w(o)/|[o]| \sum_{x \in [o]} 1$.
- Since $\sum_{x \in [o]} 1 = |o|$, we get $|G| \sum_{[o] \in X/G} w(o)/|[o]| |[o]|$ which simplies to $y = |G| \sum_{[o] \in X/G} w(o)$.
- We are done, since we have shown that $\sum_{g \in G} \sum_{x \in Fix(g)} w(x) = |G| \sum_{[o] \in X/G} w(o)$.

- The full derivation is:

$$
\begin{aligned}
&y = \sum_{g \in G} \sum_{x \in Fix(g)} w(x) \\
&= \sum_{g \in G} \sum_{x \in X} [gx = x] w(x) \\
&= \sum_{x \in X}  \sum_{g \in G}  [gx = x] w(x)  \\
&= \sum_{x \in X}  w(x) \sum_{g \in G}  [gx = x] \\
&= \sum_{x \in X}  w(x) Stab(x) \\
&= \sum_{x \in X}  w(x) |G|/|Orb(G, x) \\
&=|G| \sum_{x \in X}  w(x)/|Orb(G, x) \\
&=|G|  \sum_{[o] \in X/G} \sum_{x \in O}  w(x) / |Orb(G, x)| \\
&=|G|  \sum_{[o] \in X/G} \sum_{x \in O}  w(o) / |Orb(G, x)| \\
&=|G|  \sum_{[o] \in X/G} \sum_{x \in O}  w(o) / |o| \\
&=|G|  \sum_{[o] \in X/G} w(o) / |o| \sum_{x \in O}  1  \\
&=|G|  \sum_{[o] \in X/G} w(o) / |o| \cdot |o|  \\
&=|G|  \sum_{[o] \in X/G} w(o)\\
\end{aligned}
$$

#### Example, Unweighted

- Suppose we squares acted on by rotations $e, r, r^2, r^3$. It takes the square:

```
a b
c d
```

to the squares:

```
e     r     r^2   r^3
----|-----|-----|-----
1 2 | 4 1 | 4 2 | 4 3
3 4 | 3 2 | 3 1 | 1 2
```


# Cycle index polynomial

- If $\sigma \in S_n$ let $cyc(\sigma)$ be the integer partition of $n$ giving cycle lengths.
- For example, if $\sigma = (1 2)(3)(4 5 6)(7 8)$, then $cyc(\sigma) = 3 + 2 + 2 + 1 \sim (3, 2, 2, 1)$.
- Recall that an integer partition $\lambda$ of $n$ is a tuple $\lambda[:]$ such that $\sum_i \lambda[i] = n$
  and $\lambda$ is non-increasing.
- The cycle index polynomial for a group $G \subseteq S_n$ is $Z(G) \equiv 1/|G| \sum_{g \in G} P[cyc(g)]$
  where $P[\cdot]$ is the **power sum symmetric polynomial** for the cycle-type partition $cyc(g)$.
- Recall the definition of power sum symmetric polynomial. First, for a natural number $k \in \mathbb N$,
  we define $P[k](\vec x) \equiv x_1^k + x_2^k + \dots + x_n^k$.
- Next, for a partition $\lambda$, we define $P[\lambda](\vec x)$ to be the product over the parts of the partition:
  $P[\lambda_1](\vec x) \cdot P[\lambda_2](\vec x) \cdot \dots \cdot P[\lambda_l](\vec x)$.

#### Cycle index polynomial of dihedral group

- For example, consider the dihedral group $D_4$ acting on a square with vertices $a, b, c, d$:
- More formally, the dihedral group $D_4$ acts on the set of labelled squares $X$.

```
a b
d c
```
- 1. For the identity $e$, the cycle is $(a)(b)(c)(d)$. The cycle partition is $(1, 1, 1, 1)$.
- 2. For the rotation $r$, the cycle is $(a b c d)$. The cycle partition is $(4)$.
- 3. For the rotation $r^2$, the cycle is $(a c)(b d)$. The cycle partition is $(2, 2)$.
- 4. For the rotation $r^3$, the cycle is $(a c b d)$. The partition is $(4)$.
- 5. For the horizontal swap $h$, the cycle is $(a d)(b c)$. The cycle partition is $(2, 2)$.
- 6. For the vertical  swap $v$, the cycle is $(a b)(c d)$. The cycle partition is $(2, 2)$.
- 7. For the diagonal `a-c`  swap $ac$, the cycle is $(b d)(a)(c)$. The cycle partition is $(2, 1, 1)$.
- 8. For the diagonal `b-d`  swap $bd$, the cycle is $(a b)(c)(d)$. The cycle partitionis $(2, 1, 1)$.


- The cycle index polynomial is $Z(D_4, X) \equiv 1/|D_4|(P[(1, 1, 1, 1)] + 2P[2, 1, 1] + 3P[2, 2] + P[4])$.

- $P[1, 1, 1, 1] = p_1^4 = (x_1 + x_2 + x_3 + \dots + x_n)^4$, where $p_1$ is a [*power sum symmetric polynomial*](https://en.wikipedia.org/wiki/Power_sum_symmetric_polynomial).
- $P[2, 1, 1] = p_2 p_1 p_1 = (x_1^2 + x_2^2  + \dots+ x_n^2)\cdot (x_1^1 + x_2^1 + \dots + x+n)^2$.
- ...and so on.



# Mnemonics For Symmetric Polynomials

#### Some notation for partitions
- Consider a partition $\lambda \equiv (\lambda_1, \lambda_2, \dots \lambda_l)$ of a partition of $N$.
- The $L_0$ norm of the partition will be $1 + 1 + \dots 1$ ($l$ times), which is equal to $N$. Thus, $|\lambda|_0 = l$.
- So the $L_0$ norm of a partition is the *number of parts* of the partition.
- The $L_1$ norm of the partition will be $|\lambda_1| + |\lambda_2| + \dots + |\lambda_l|$  which equals $N$.
- So the $L_1$ norm of a partition is the number it is partitoining. Thus, $|\lambda|_1 = N$.


#### Elementary Symmetric Polynomials (integer)

- We need to define $e_k(\vec r)$ for $k \in \mathbb N$, $r \in X^d$ a sequence of variables ($r$ for "roots").
- These were *elementary* for Newton/Galois, and so has to do with the structure of roots.
- The value of $e_k(\vec r)$ is the coefficients of the "root polynomial" $(x - \vec r)$, that is:

$$
\begin{aligned}
&(x+r_1)(x+r_2)(x+r_3) = 1x^3 + (r_1 + r_2 + r_3) x^2 + (r_1r_2 + r_2r_3 + r_1r_3) x +  r_1r_2r_3 \cdot x^0 \\
&e_0 = 1 \\
&e_1 = r_1 + r_2 + r_3 \\
&e_2 = r_1 r_2 + r_2 r_3 + r_1 r_3  \\
&e_3 = r_1 r_2 r_3 \\
\end{aligned}
$$

- Formally, we define $e_k(\vec r)$ to be the product of all terms
  $(r_a r_b\dots, r_k)$ for distinct numbers $(a, b, \dots, k) \in [1, n]$.

$$
\begin{aligned}
e_k(\vec r) \equiv \sum_{1 \leq a < b < \dots k \leq n} r_a r_b \dots r_k
\end{aligned}
$$

#### Elementary Symmetric Polynomials (partition)

- For a partition $\vec \lambda \equiv (\lambda_1, \lambda_2, \dots, \lambda_l)$, the elementary symmetric polynomial $e_\lambda$
  is the product of the elementary symmetric polynomial $e_{\lambda_1} \cdot e_{\lambda_2} \dots e_{\lambda_l}$.

#### Monomial Symmetric Polynomials (partition)

- We _symmetrize_ the _monomial_ dictated by the partition. To calculate $m_\lambda(\vec r)$, we compute
  $\vec r^\lambda \equiv r_1^{\lambda_1} r_2^{\lambda_2} \dots r_l^{\lambda_l}$, and then symmetrize the above monomial.
- For example, $m_{(3, 1, 1)}(r_1, r_2, r_3)$ is given by symmetrizing $r_1^3 r_2^1 r_3^1$. So we must add the terms $r_1 r_2^3 r_3$
  and $r_1 r_2 r_3^3$.
- Thus, $m_{(3, 1, 1)}(r_1, r_2, r_3) \equiv r_1^3 r_2 r_3 + r_1 r_2^3 r_3 + r_1 r_2 r_3^3$.


#### Power Sum Symmetric Polynomials (number)

- It's all in the name: take a sum of powers.
- Alternatively, take a power and symmetrize it.
- $P_k(\vec r) \equiv r_1^k + r_2^k + \dots + r_n^k$.

#### Power Sum Symmetric Polynomials (partition)

- Extend to partitions by taking product of power sets of numbers.
- $P_\lambda(\vec r) \equiv P_{\lambda_1}(\vec r) + P_{\lambda 2}(\vec r) + \dots + P_{\lambda_l}(\vec r)$.




# Uses of minimal string rotation

- This algorithm always struck me as useless. Now I know some uses.
- 1. Finger print identification:
  We can encode the finger print into
  many detailed circular strings.
  How to search such finger print
  again from those in very
  huge data base ? Circular comparision using lyndon factorization is requried.
- 2. Forest canonicalization. Write a tree out in terms of dyck grammar / brackets. Forest will correspond
  to sequence of such trees. When are two forests equivalent? Normalize them by minimal rotation.

# Suffix Automata

- We take for granted knowledge of the Myhill nerode theorem to build the minimal automata of the
  set of suffixes of a string $l$.
- Let the alphabet be $A$, and let us build the suffix automata of $l \in A^\star$.
- Define the language of suffixes of a string $l$ as $L \equiv \{ l[i:] : i \in \mathbb N \}$.
- By Myhill Nerode, states of the minimal DFA correspond to strings that are indistinguishable under
  extensions by a membership oracle of $L$.
- Suppose a state in the DFA corresponds to two strings $b, s \in A^\star$ ($b$ for big and $s$ for small)
  such that $|b| \geq |s|$. So we have that $b =_L s$.
- Now, for all strings $z$ such that $bz \in L$ we also have $sz \in L$.

- So the string must look like follows:

```
----bbbbzzzzzzzzz
------sszzzzzzzzz
```

- This implies that $s$ is a suffix of $b$!
- Strings in the same state correspond to suffixes of the largest string in the state.
- Next, we claim that a state consists of all suffixes upto some length. TODO.
- Therefore, it is helpful to imagine states as "funnels" or "triangles" or "narrowing trapeziums", which
  have at the top the longest string, and then shorter and shorter suffixes. The suffix link from `a` to `a->link` points from the
  base of `a` to the top of the trapezium `a->link` such that `a` and `a->link` can be "joined" into a larger trapezium.


#### Suffix Automata must be a DAG

- A cycle in the automata implies that we have an infinite number of strings in the language,
  since we can traverse along the cycle as many times as we want before we reach a final state.
- Thus, the suffix automata, which accepts a finite language must be a DAG.
- This implies that we can perform dynamic programming on the DAG.


#### Suffix automata: relinking `q` to `qsmol`


- Suppose we are inserting a character `c`. We are at a state `p` which points to a state `q` on transitition `c`.
- Now since `q` contains `p:c`, we have that `len(q) > len(p)`. If `p:c` is the longest string of `q`, then `len(p) + 1 = len(q)`.
  Otherwise, `q` has longest string a string which contains `p:c` as a proper suffix, and thus `len(p) + 1 < len(q)`.
- Since `q` contains `p:c`, the suffix link at `q` must point to a state which is a _proper prefix_ of `p:c`.
- If I therefore create a state with longest string `p:c`, this state `p:c` has a longest string longer than `q->link`.
- Thus, it is proper to attach `q->link` to the newly created state.


# Simpson's Paradox

- The example which made simpson's paradox click for me was the *extreme* case.
- Suppose
  department `E` hires _every woman_ but only half the men (`E` for every), while department `N` hires _neither_
  men nor women.
- So in each department, women are either advantaged (as in `E`) or are on-par (as in `N`).
- Suppose we have `100` men and `100` women.
- Let `90` men apply for `E` and `10` men apply for `N`.
  In total, `45` men are accepted `(90/2 + 0)`.
- Let `10` women apply for `E` and `90` women apply for `N`. In total, `10+0` women are accepted.
- Thus, it _appears_ as if only `10` women are selected to `45` men, implying some kind of bias.
- In reality, all departments are pro women hiring. The **majority of women apply to the deparment `N`**
  which is **hard to get into**, thereby making it appear as if the institute (`E` and `N` combined)
  are against women hires.
- The information that is lost is that of the split up of men and women who apply to `E` and `N`.

# Myhill Nerode Theorem

- Take a language $L$ over an alphabet $A$.
- Define $x \in A^\star$ to have a **disginguishing extension** from $y \in A^\star$
  iff there exists a $s \in A^\star$ such that either (a) $xs \in L \land ys \not \in L$, or
  $xs \not \in L \land ys \in L$
- Said differently, given $x$ and $y$, there suffix $s$ which
  can distinguish $x$ and $y$ using the membership oracle for $L$.
- Now define $x \sim_L y$ ($x$ is indistinguishable from $y$) iff there **is no distinguishing extension**
  between $x$ and $y$ with respect to $L$.
- See that this is an equivalence relation:
- *(1) Reflexivity*: $x$ cannot be distinguished from $x$ (using $L$),
  because any suffix $s$ cannot produce different
  outputs for $x$ and $x$.
- *(2) Symmetry*: If $x$ cannot be disguished from $y$ (using $L$),
  then $y$ cannot be distinguished from $x$ (using $L$).
- *(3) Transitivity*: If $x$ cannot be distinguished from $y$ (using $L$)
   and $y$ cannot be distinguished from $z$ (using $L$),
   then $x$ cannot be distinguished from $z$ (using $L$). Intuition:
   What about $y$ in this situation? It can't be indistinguishable from both $x$ and $z$.
- *Proof of Transitivity:* Suppose for contradiction $x$ can be distinguished from $z$.
  There there is a suffix $s$ such that
  $xs \in L$ while $zs \not \in L$ (WLOG). Now what about $ys$? if $ys \in L$ then we can distinguish $y$
  and $z$, contradicting assumption that $y$ is indistinguishable from $z$. If $y \not \in L$ then we can
  distinguish $x$ from $y$ contradicting assumption that $x$ is indistinguishable from $y$.
- Hence, being indistinguishable is an equivalence relation, denoted by $x \sim y$.
- Myhill nerode says that the minimal DFA for a language $L$ has as many states as there are
  equivalence classes for $\sim_L$.

#### Given DFA $D$ of language $L$ over $A$: $\sim_D$ implies $\sim_L$

- Let $L$ be a regular langugage over alphabet $A$ and let $D$ be a DFA
  (with finite number of states $|D|$ in the DFA).
- Partition the set of all strings $A*\star$ via the relation $\sim_D$:
  $x \sim_D y$ iff $x$ and $y$ end at the same state when fed to DFA.
- Thus will have $|D|$ equivalence classes for $\sim_D$, one for each state of the DFA.
- For any two strings such that $x \sim_D y$, given any suffix $s$, we have that $xs \sim_D ys$
  since we start at the same state at $x$ (or $y$) and continue when we feed the suffix $s$.
- Thus, strings such that $x \sim_D y$ are indistinguishable for the DFA.
- So we have $x \sim_L y$, since on any extension, both $xs$ and $ys$ either belong or don't belong to $L$.

#### given language $L$ over $A$: show that $\sim_L$ implies $\sim_D$.

- Let $L$ be a langugage over alphabet $A$ such that
 $\sim_L$ has finitely many equivalence classes.
- We will design DFA (called $D$)for $L$ with as many
  states as equivalence classes.
- The start state of $D$ is the equivalence class of the empty string with respect to $\sim_L$.
- At an equivalence class/state $T$, given character $c \in A$, we move to $T \diamond c$ (extend $T$
  by $c$).
- Formally, $\delta(T, c) \equiv T \diamond c$, where $T \diamond c \equiv \{ tc : t \in T \}$
- This is well defined, as if $t \sim_L t'$ are in the equivalence class $T$, then we must have
  $tc \sim_L t'c$.
- Suppose $tc$ is distinguishable from $t'c$ by a suffix $s$. Then we can distinguish between $t$
  and $t'$ via suffix $cs$. This contradicts $t \sim_L t'$. Thus we have that $t \sim_L t$ implies $tc \sim_L t'c$.
- Thus our transition function $\delta$ is well defined over equivalence classes $A/\sim_L$.
- A state $T$ in $D$ is accepting if the state contains \emph{any} string $l \in L$.
- That is, $T$ is accepting iff there exists a $l \in L$ such that $l \in T$.
- In this case, we infer that $T \subseteq L$, or any string in $T$ is accepted by $L$.
- Suppose for contradiction that  $l \in L$ such that $l \in T$ while also having a string $z \in T$, $z \not in L$.
- the empty string would distinguish the two strings $l, z$ which contradicts $z \sim_L l$
  since they are both in the equivalence class $T$.
- Thus for a regular language $L$ there is a DFA $D$ which accepts strings from $L$ and has number of
  states $|D|$ equal to number of equivalence clases $|A/\sim_L|$.

#### DFA needs at least $|A/\sim_L|$ states
- Let $n \equiv |A/\sim_L|$ be the number of equivalence classes of $\sim_L$.
- Suppose a DFA $D$ recongizes $L$ and has fewer than $|A/\sim_L|$ states.
- Let $x_1, x_2, \dots x_n$ be strings from different equivalence classes of $L$.
- Push these strings through $D$. Some two strings $x_i, x_j$ must land on the state state $d \in D$
  of $D$ (by pigeonhole).
- We must have $x_i$ and $x_j$ distinguishable, since they come from different equivalence classes.
  So the DFA must accept one and reject the other.
- But the DFA can't tell the difference between $x_i$ and $x_j$ since they landed on the same state!
  So the DFA will accept or reject both.
- Thus, we have a contradiction from the assumptions (a) $D$ has fewer states than $n$ and (b)
  $D$ recognizes $L$.
- Thus the DFA needs at least $|A/\sim_L|$ states.

#### The two imply DFA minimization

- We have seen that every DFA for $L$ needs at least $|A/\sim L|$ states.
- Now starting from $L$, we can build an automata $D^\star$ such that $|D^\star|$ is exactly $|A/\sim L|$.
- Thus the automata $D^\star$ is a (the) minimal automata for $L$.

# Linearity of expectation for sampling

```py
# process 1
def val(c): return 1 + ord(c) - 'a'
def process(addx, addy):
    s = 0
    ndraws = 10
    for _ in range(ndraws):
        x = random.choice("abcde"),  # draw a random chit
        y = random.choice(x*5+"abcde") # draw a random chit, dependent on first random chit.
        if addx: s += val(x)
        if addy: x += val(y)
    return s
```

- Linearity of expectation says that `process(True, True)` equals `process(True, False) + process(False, True)`.
- Intuitively, if we run the code for `process` infinitely many times, then each execution of `process(True, True)`
  can be split into an execution of `process(True, False)` and an execution of `process(False, True)`.
  This can be depicted as:

<img src="./static/linearity-of-expectation-theory/split-process-in-two.png">

- The above process assumes that we get the *same* results from running `process(True, True)` as we do when we run
  `process(True, False)` and `process(False, True)` in succession. Of course, this will never happen.
- However, since we are taking an average over many trials, we can imagine that for a run of `process(True, True)`, we will have
  corresponding runs of `process(True, False)` and `process(False, True)`:

<img src="./static/linearity-of-expectation-theory/matching-over-trials.png">

- The key thing to remember is that the random variable *does not care* about the process, only about the *value*
  that is spit out by the process.
- Thus we can read linearity of expectation as saying either (1) Simulate the full process in one go and accumulate the results
  as you go along `process(True, True)` or `E[a+b]`, or (2) Simulate the process in parts, and add up the accumulated
  results from the partial simulations (`process(True, False)` + `process(False, True)` or `E[a] + E[b]`).
- In *both cases*, we are allowed to simulate the process fully! The only thing that differs is when we accumulate the answers.
- This is in contrast to computing conditional probability, where the situation/process in which `P(A|B)` occurs is wildly
  different from `P(A)`.
- Linearity of expectation asks us to run the *same* process, just tally results differently.
- It tells us that randomness allows the tallies to line up, whether we tally in two separate phases
  or in a single phase, which makes intuitive sense!

#### Linearity of expectation is purity

Suppose we write:

```
x = random.choice("abcde")
y = random.choice("abcde")
s =  val(x) + val(y)
```

- If we ask for the expected value of `s`. It's going to be:

```
E[s] = E[val(x) + val(y)]
= E[val(x)] + E[val(y)]
= 2 E[val(x)]
```

- The last inequality follows because `x` and `y` are two copies of the same random variable `random.choice("abcde")`,
  thus have the same expected value for `val(x)`, `val(y)`.
- So, expecatation 'purifies' random computations.

#### "Deriving" equivalence for two processses using purity

- First write down what `process(True, False) + process(False, True)` as:

```python
def rhsI():
    sx = 0; sy = 0
    ndraws = 10
    for _ in range(ndraws):
        x = random.choice("abcde"),  # draw a random chit
        y = random.choice(x1*5+"abcde") # draw a random chit, dependent on first random chit.
        sx += val(x)

    for _ in range(ndraws):
        x = random.choice("abcde"),  # draw a random chit
        y = random.choice(x2*5+"abcde") # draw a random chit, dependent on first random chit.
        sy += val(y)
    return sx + sy
```

- Next, we use the purity of `random.choice` (within expectation) to fuse the two loops:

```python
def rhsII():
    sx = 0; sy = 0
    ndraws = 10

    # loop fusion is safe, because even though random.choice has a side effect, the order
    # of calling random.choice does not matter. It commutes with other random ops.
    for _ in range(ndraws):
        x1 = random.choice("abcde"),  # draw a random chit
        y1 = random.choice(x1*5+"abcde") # draw a random chit, dependent on first random chit.
        sx += val(x1)
        # loop fusion
        x2 = random.choice("abcde"),  # draw a random chit
        y2 = random.choice(x2*5+"abcde") # draw a random chit, dependent on first random chit.
        sy += val(y2)
    return sx + sy
```

- Next, we use purity to set `x1 = x2` and `y1 = y2`, since on expectation, their values are the same.

```python
def rhsIII():
    sx = 0; sy = 0
    ndraws = 10

    # once again, expectation purifies randomness. So within the context of expecattion, we can
    # replace `x2` with `x1` with `x1`
    for _ in range(ndraws):
        x1 = random.choice("abcde"),  # draw a random chit
        y1 = random.choice(x1*5+"abcde") # draw a random chit, dependent on first random chit.
        sx += val(x1)
        # loop fusion
        x2 = x1
        y2 = y1
        sy += val(y2)
    return sx + sy
```

- Finally, we cleanup the code to arrive at `process(True, True)`:

```python
def rhsIV():
    sx = 0; sy = 0
    ndraws = 10

    # once again, expectation purifies randomness. So within the context of expecattion, we can
    # replace `x2` with `x1` with `x1`
    for _ in range(ndraws):
        x1 = random.choice("abcde"),  # draw a random chit
        y1 = random.choice(x1*5+"abcde") # draw a random chit, dependent on first random chit.
        sx += val(x1)
        sy += val(y1)
    return sx + sy
```



#### For $N=1$, the expected number of turns is $1$.


# Min cost flow (TODO)


- Problem statement: Find a maximal flow with minimum cost.

1. Find max flow.
2. Find negative cost cycle in residual graph of max flow. Push flow around the negative cost cycle.


#### Relation between max flow and min cost circulation

- Recall that min cost circulation asks to compute a circulation with minimum cost [no maximality constraint].

- Given a flow network $(V, E, s, t, C)$ ($C$ is capacity fn), create a new cost function $c: V \to \mathbb R$ which assigns cost zero
  to all edges in the flow networ. Also add a new edge $t \to s$ which has infinite capacity, cost $-1$.
- A circulation with cost lower than zero will have to use the $t \to s$ edge. To get minimum cost, it must send as much flow through
  this edge as possible. For it to be a circulation, the full flow in the network must be zero. So suppose we send $f$ units of flow
  back from $t$ to $s$. Then we must send $f$ units of flow from $s$ to $t$ for it to be a circulation. Incrasing $f$ (max flow)
  decreases the cost of the circluation! Thus, max flow is reduced to min cost circulation.

#### Min Cost Flow in general

- First find max flow using whatever.
- Next, we need to find negative cost cycle in the residual graph.
- Use bellman ford, or SPFA to find negative cost cycles in $O(VE)$ time [run edge relaxation $|V|$ times].


#### Minimum mean cycle

- Which is best cycle to push flow around to reduce cost? The min cost cycle may not be best, since it may have very little capacity.
- A negative cycle with max capacity may not have good cost.
- Correct: `total cost/number of edges` --- that is, the mean cost.


#### shortest path as circulation.

- Need to find single source shortest path in a graph (with possibly negative edges, no negative cycles).
- We have a balance at each vertex $v$, which tells us how much extra flow must can have coming in versus going out.
  So, $\sum_u f(l \to v) - \sum_w f(v \to r) = b(v)$. Intuitively, the balance is stored in a tank at the vertex.
- We need total balance to be zero.
- We set the source $s$ to have balance $1-v$ (supply) and all the other nodes to have balance $1$ (demand).
- Let the cost of each edge be the distance, let the capacity of each edge be infinite.
- Now, what is a min cost flow which obeys the demands?
- Consider the shortest path tree. Imagine it as carrying a flow. Then the
  shortest path tree indeed obeys the flow
  constraints.
- To convert this into circulation, add back edges from each node back to the source, with a capacity of 1, cost of zero.
- This converts shortest path trees into flows/circulations.


#### Min cost circulation algorithms
- Old algorithm: start with a circulation that obeys balance, then push more around (by using negative cycles)
- New algorithm (successive shortest path): remove all negative cycles, then restore balance constraints.
- how to remove negative cycles? We can just send flow down all negative edges. The resdiual graph will contain no negative cycles.
  (NOTE: we don't have a valid flow at this point!) This leaves us with resdiual balances at each vertex,
  about how much more flow we need to send.

#### References

- [Jeff E: algorithms video](https://www.youtube.com/watch?v=k8A5kSo3EW0)


# Clojure: minimal makefile for REPL driven dev with Neovim

Create the `deps.edn` file:

```
{:deps
 {org.clojure/clojure {:mvn/version "1.10.1"}
   nrepl {:mvn/version "0.7.0"}
     cider/cider-nrepl {:mvn/version "0.25.2"}}}
```

and write the `Makefile`:

```
# https://clojure.org/guides/deps_and_cli
.PHONY: run

repl:
    clj -m nrepl.cmdline \
        --middleware "[cider.nrepl/cider-middleware]" \
        --interactive

run:
    clj -X dg/run

test:
    clj -Atest
```


# Delimited continuations

- `reset`: add a marker to delimit the capture of the continuation by `shift`.
  So called because we add a `reset mark` onto the stack.
- `shift`: .. So called because to start executing a `shift`, we move stack frames upto the closest reset from the stack into the heap.
  When the continuation of `shift` is called, move back the stack frames from the heap onto the stack.

>  Direct Implementation of Shift and Reset in the MinCaml Compiler



# Never forget monic again

- Remember monic ~ injective.
- Remember that injective is $f(x) = f(y) \implies x = y$.
- Since we're doing category theory, replace $x$ and $y$ by functions $h(p)$ and $k(p)$.
- This means that the rule of monic is $\forall p, f(h(p)) = f(k(p)) \implies h = k$.
- Thus, monic is left cancellative!


# Weird canonical example of monic and epic: left/right shift

- Consider the function `right` over an infinite sequence `a_n` which is defined as
  `right(a[:])[i] = 0 if i == 0 else a[i-1]`. That is, it shifts a sequence to the right.
- See that this is injective, and *not* surjective: for example, there is no pre-image to any sequence
  that starts with a non-zero value, such as `1, 0, 0, ...`.
- Its dual, `left(a[:])[i] = a[i+1]` is surjective, but not injective.
- This makes it ideal as an "extreme case" to test the monic/epic conditions as left/right cancellable.

#### Monic

- We know that `right` is monic. Is it cancellable if we run it before or after?
- We should run it after --- that way, if `right(f(a[:]))` equals `right(g(a[:]))` for all `a[:]`,
  we know that the sequences are `(0, f1, f2, ...)` which equals `(0, g1, g2, ...)` which implies `(f1, f2, ...)` equals `(g1, g2, ...)`.
  So we can conclude that `f = g` from `right . f = right . g`.
- On the other hand, if we consider `f(right(a[:]))` and `g(right([a:])`, we will only test the equality of `f` and `g`
  at sequences of the form `(0, a1, a2, ...)` which is insufficient, this we cannot conclude `f = g`. So we cannot conclude `f = g`
  from `f . right = g . right`.

#### Epic

- We know that `left` is epic. Is it cancellable if we run it before or after?
- Suppose `f . left = g . left`. Since `left` is epic, this tests `f` and `g` on every possible input. Thus `f = g`.
- On the other hand, suppose `left . f = left . g`. This is insufficient, since we will only test the equality of `(f2, f3, ...)`
  with `(g2, g3, ...)` leaving `f1 =? g1` untested. Thus, we cannot conclude `f = g` from `left . f = left . g`.





# Playing guitar: being okay with incorrect chords

- I find it very hard to switch chords, since I feel "afraid" of playing the wrong chord.
- I feel like this manifests in different ways: I am relunctant to write documents which I fear maybe incorrect,
  and yet would be valuable to write up. I feel relunctant to compete in competitions for fear of not knowing
  the "right answer".
- Regardless, it's very interesting how when playing the guitar, people (and you) literally don't notice!
- As long as you keep the rhythm up, it "sounds fine".
- So, if there's a hard chord change to be done, stagger it! play two beats with all strings open.
  Then hold down a single finger for a beat. Then another finger for the next beat. And so on, till perhaps
  at the final beat, we make the "complete/correct" chord.
- It's interesting, since it adds a sort of design challenge: what is the best sequence of strings to play to "musically"
  approach a given chord starting from open strings? Different choices of fingers have surprisingly different sounds!
- It's also very relieving to be able to simply.. play, experiment with leaving strings one-by-one, pressing strings
  one by one, without worrying about getting it right, as long as I allow the rhythm-beat to march forward :)
- This lends itself particularly well to the style where we mute the guitar every even beat (1 MUTE 2 MUTE) to create a
  percurssive effect. It allows one to hear the chord being "layered" up, finger by finger.
- It also mutes  the "open string" sound by the time we get the first finger on, so it helps create
- TL;DR: **strumming hand >>> chord hand**. Focus on the strumming! It's okay to screw up on chords `:)`

# Sparse table

- Given an array `as :: Semilattice a => [a]`, find semilattice join of any range `[lft..rt]` in `O(1)` time, given
   `O(n log n)` preprocessing.
- Core idea: store results of queries `[lft..l+2^k)`. So the code:

```cpp
// mins [l, l+1) = arr[l]
for(int i = 0; i < n; ++i) { mins[i][0] = arr[l]; }
for(int len = 1; len < NBITS; ++len) {
  for(int i = 0; i < n; ++i) {
    const int midix = i + 1 << (len-1);
    if (midix >= n) { break; }
    // mins [l..l+N) = min mins[l..l+N/2) mins[l+N/2..l+N]
    mins[i][l] = min(mins[i][len-1], mins[i + midix][len-1]);
  }
}
```

- Now given a query, the "naive" method is to consider the range `[lft, l+len)`. We break `len` down into its powers
  of `2`, and then query the indexes based on its binary representation. Eg. a query from `[3, 3+7)` is broken down
  into `7 = 4 + 2 + 1`, so we query `[3, 3+4)` which is `[3, 7)`,  then `[3+4, 3+4+2)` which is `[7, 9)`, and finally
  `[3+4+2, 3+4+2+1)` which is `[9, 10)`. But this is `O(log n)` time. We want `O(1)` time.

```
    [--------------)
1 2 3 4 5 6 7 8 9 10
    |       |   |  |
    [-------)   |  |
            [---)  |
                [--)
```

- The key is to notice that so far, we've only used associatvity of the lattice operation, not idempotence! We can
  exploit idempotence by not caring about *overlaps*.



- to find min in `[3, 9)`, we combine `[3, 3+4)` with `[9-4, 9)`, which is `[3, 7)` combined with `[6, 9)` which
  overlaps at `6`.

```
    [-----------)
1 2 3 4 5 6 7 8 9
    |     | |   |
    [-----+-)   |
          [-----)
```

The actual expression is:

```cpp
// [l, r)
int query_mins(int l, int r) {
  int len = r-l;
  if (len < 0) { return INFTY; }
  int j = log2(len); // round down.
  // min  [l, l+halflen), [l+halflen, r)
   return min(mins[l][j], mins[l+-(1<<j)][j]);
}
```

# Duval's algorithm

- https://stackoverflow.com/questions/55642656/how-does-duvals-algorithm-handle-odd-length-strings
- https://ritukundu.wordpress.com/2016/10/07/algorithm-to-find-the-least-lexicographic-rotation-of-a-circular-string/

# Amortized complexity from the verifier perspective

- If we want an API that can verify amortized complexity, then each method returns two costs: (a) "number of cycles" spent on the operation,
  (b) "claimed cost" of the operation. For example, `vector.push_back()` may return "number of cycles" to be as large as `O(n)` when doubling,
  while always returning "claimed cost" as `1`.
- At the end of *any* sequence of operations, the verifier verifies that `sum (claimed cost)` > `sum of (#cycles)`.
- This establishes that the claimed/amortized cost is an upper bound on the real cost!

# Relationship betwee permutations and runs

- Let the permutation be $\pi \equiv (3 9 2 5 6 7 10 11 13 15 14 16 12 1 4 8)$.
- Split into runs: $r_1:(3 9)$, $r_2:(2 5 6 7 10 11 13 15)$, $r_3:(14 16)$, $r_4:(12)$, $r_5:(1 4 8)$.
- The runs begin at indeces $p[1] = 1$, $p[2] = 3$, $p[3] = 11$, $p[4] = 13$, $p[5] = 14$. Total number of runs is $R=5$.
- Encode each number in $[1..15]$ by the run to which it belongs to. This is us mapping the integer $k$ to $run(\pi^{-1}(k))$.
- We get that:

```
1 -> run 5 | (1 4 8)
2 -> run 2 | (2 5 ... 15)
3 -> run 1 | (3 9)
4 -> run 5 | (1 4 8)
--
5 -> run 2 | (2 5 ... 15)
6 -> run 2 | (2 5 ... 15)
7 -> run 2 | (2 5 ... 15)
8 -> run 5 | (1 4 8)
--
9 -> run 1 | (3 9)
10 -> run 2| (2 5 ... 15)
11 -> run 2| (2 5 ... 15)
12 -> run 4| (12)
--
13 -> run 2| (2 5 ... 15)
14 -> run 3| (14 16)
15 -> run 2| (2 5 ... 15)
16 -> run 3| (14 16)
```

- This gives us the array $S = [5, 2, 1, 5| 2, 2, 2, 5| 1, 2, 2, 4| 2, 3, 2, 3]$
- The $k$th occurrence of symbol $s$ in $S$ corresponds to the row of the permutation $P[s] + k$.
  The occurrence will be at $\pi(P[s] + k)$.
- Suppose we want to find $\pi(P[s] + k) = y$.


#### Relationship to burrows wheeler?

- See that we do sort of the same thing, where we identify a string based on the ranks of its characters?!



# Brouwer's fixed point theorem

#### General statement:

Given an nD simplex that has been subdivided, and a function that maps vertices of the subdivision
to vertices of the simplex such that the function on the boundary of the simplex maps it to endpoints of the boundary,
we will always have a subdivided simplex with all vertices of the original
simplex.

#### 1D

- Given a line with endpoints $a, b$ and points in between, we will always have an occurrence of $ab$ on the line.
- Can prove something slightly stronger: there will always be an odd number of $ab$ on the line.

#### 2D

- Given a triangle labelled $abc$ and a subdivision of it, there will be a smaller triangle labelled $abc$.
- Consider all smaller triangles.
- Call a side with $bc$ a door.
- How many doors can a triangle have? It can have 0 doors if it is labelled $aaa$, or $abb$, or some such.
- It can have 1 door if it is:

```
 a
/ \
b==c
```

- It can have two doors if it is:

```
  c
// \
b===c
```

- We can't have three doors. So triangles can have 0, 1, or 2 doors.
- If we find a triangle with one door, we are done, since it will have $abc$.
- Now start from the bottom of the triangle where we have the side $bc$. Here we will find at least one edge $bc$.
- Walk along the triangle, entering any triangle with a door.
- If that's the only door of the triangle, we are done.
- If not, then the triangle has two doors. Exit the current triangle through the other door (the door we did not enter from). This will take us to another triangle.
- See that we cannot terminate the walk by exiting from sides $AB$ or $AC$, for such a side will be of the form $ab$. Then to have a door, we will get a $bc$,
 so the triangle must be $abc$, ie a triangle we are looking for!
- So if we ever escape the simplex, we must escape from the bottom side $BC$. This removes an even number of
  $bc$ edges from $BC$. But we know there are an odd number of $bc$ from $BC$, so we must find a triangle $ABC$ eventually.

# XOR on binary trie

If we XOR a number, then it flips the path that were taking on the binary trie! This seems
like a handy way to visualize numbers. In particular, to solve question [1554C](https://codeforces.com/contest/1554/problem/C)


# Inconvergent: beautiful generative art


- [https://inconvergent.net/faq/](Link to website)



# Prefix/Border function

Function that for a string `s`, at index `i`, returns the length of the longest border of `s[0..i]` (inclusive).
For example, consider the string `s=abababcaab`.

- at `i=0`, we have substring `s[0..0]=a` which has no border (border is proper prefix/suffix). So `pr(0) = 0`.
- at `i=1`, we have substring `s[0..1]=ab` which has no border, so `pr(1) = 0`.
- at `i=2`, we have substring `s[0..2]=aba` which has `a..a` as border. `pr(2) = 1`
- at `i=3`, we have substring `s[0..3]=abab` which has `ab..ab` as border. `pr(3) = 2`
- at `i=4`, we have substring `s[0..4]=ababa` which has `ab[a]ba` as border (that is, the prefix is `aba` and the suffix is `aba` which overlaps).
   `pr(4) = 3`.
- at `i=5`, we have substring `s[0..5]=ababab` which has `ab[ab]ab` as border (that is, the prefix is `abab` and the suffix is `abab` which overlaps).
   `pr(5) = 4`.
- at `i=6`, we have substring `s[0..6]=abababc` which has no border. `pr(6) = 0`.
- at `i=7`, we have substring `s[0..7]=abababca` which has border `a..a`. `pr(7) = 1`.
- at `i=8`, we have substring `s[0..8]=abababcab` which has border `ab..ab`. `pr(8) = 2`.

In toto, the prefix function is:

```
  ababcaab
  01234012
```

#### `s[0..i]` has a border of length at `pr(i+1)-1`

- That is, given the substring `s[0..i]`, we can predict that `s[0..i]` will have some border (perhaps not the longest border) of length `pr(i+1)-1`.
- Suppose `s[0..i+1]` has longest border of length `L=pr(i+1)` (by definition of `pr`). Suppose `pr(i+1) >= 1`. Then I can write `s[0..i+1]` as:


```
s[0..i+1] = p[0]p[1]...p[L]|s[L+1]...s[i+1-L-1]|p[0]p[1]...p[L]
            ^^^^^^^^^^^^^^^                     ^^^^^^^^^^^^^^^
```

If I now want to consider `s[0..i]`, I need to drop the last letter `p[L]`, which leaves me with:

```
s[0..i] = p[0]p[1]...p[L-1]p[L]|s[L+1]...s[i+1-L-1]|p[0]p[1]...p[L-1]
          ^^^^^^^^^^^^^^^^^                         ^^^^^^^^^^^^^^^^^
```

- where we have a border of `p[0]...p[L-1]`.
- There maybe a longer border, involving other terms of `s[0..i]`. But we know that the border is *at least* `pr(i) >= pr(i+1)-1`.
- Upon re-arranging, we see that `pr(i+1) <= pr(i) + 1`.
- This tells us that the border can *increase* by at most 1 (it can *drop* to zero, no lower bound!). So we have: `0 <= pr(i+1) <= pr(i) + 1`.
- So if we think of borders of `s[0..i+1]`, we know that the longest border can be of length of border `pr(i) + 1`. All other borders will be of length
  `<= pr(i)`, so these other borders will be borders of `s[0..i]`!
- Thus, to move from `s[0..i]` to `s[0..(i+1)]`, we simply need to be able to find the *longest* border of `s[0..(i+1)]`. All other borders will come from
  `s[0..i]`.

#### Lemma: Enumerating borders (what is a good name for this lemma?)

- Think of the longest border `123456`:

```
123456----123456
     ^         ^
     L         N
```

- Now consider a shorter border `ab`:

```
ab3456----1234ab
     ^         ^
     L         N
```

- But we must have `a~1` and `b~2` since it's the same string! So the border is really `ab34ab`, and the string is:

```
ab34ab----ab34ab
     ^         ^
     L         N
```

- This shows that given the longest border `123456` of`s[0:N]` which has length `L`,
  any other border of `s[0:N]`(such as `ab`) is also a border of `s[0:L]`.
- Generalizing, given the longest border of `s[0..n]` of length `L`,  any smaller border of `s[0:N]`
  is a border of `s[0:L]`.

#### Algorithm to enumerate borders.

All borders of `s[0:N]` can be enumerated by:

1. Taking the longest border of length `L` of `s[0:N]` (given by `pr(N)`).
2. considering the border as being the substring `s[0:L]` (given by `pr(L)`).
3. Taking the longest border of `s[0:L]`
4. ... recurse till we hit empty string.


#### Computing `pr(i+1)`

1. We know that `pr(0) = 0`.
2. At `pr(i+1)`, we know that `s[0:pr(i)] = s[-pr(i):-1]`

#### Border function is a fractal

Consider a general string which looks like:

```
abcdef--abcdef
```

If we think of the second longest border, say `12`, we will get that
the string must be:

```
12cdef--abcd12
     ^^  &&
```

But this implies that the occurrence of `ef` (marked with `&&`) and the occurrence
of `ab` (marked with `##`) must be `12, 12` respectively. This means that the
string is:

```
12cd12--12cd12
```

So we started with a full string:

```
------------------
```

Then matched the left and right (very 1/3 cantor):

```
-------    ------
       ----
```

Then matched the left and right of these again and unified the leftovers,
finding that it looks like:

```
--  --   --  --
  --       --
      ---
```

and so on. Isn't this so cool? Borders of a string are a fractal-like object!



# Shortest walk versus shortest path

- path is a sequence of vertices connected by edges.
- walk is a simple path or a path with no loops.
- djikstra's solves shortest walk, not shortest path, since it can't hangle paths with negative cycles!
- Bellman ford solves shortest path, since it reports when the question of "shortest path" does not have a
  sensible answer (ie, the set of paths ordered by length is not well founded).





# Minimal tech stack


- `st`: suckless terminal.
- `mtm`: minimal terminal multiplexer.
- text editor? I need one.



# FFT

- Evaluating a polynomial `p(x)` at `[a0, a1, ... am]` in general is hard, even though
  we have the recurrence `p(x) = po(x^2) + x pe(x^2)`. This makes the polynomials smaller
  (degree of `po`, `pe` is half of that of `p`). However, we need to evaluate at all the points
  `[a0...am]` , so to merge we need to merge values at `[a0...am]` at each step.
  So our recurrence will be `T(n) = T(n/2) + m` with `T(1) = m`. This solves to `O(nm)`.
- The special property of DFT is that we can reconstruct `p(x)` at `[w[n][0], ... wn[n][n-1]]` given the
  values of `po`, `pe` at `[w[n/2][1], w[n/2][2], w[n/2][3], ... w[n/2][n/2-1]]`.  So the number
  of points we need to evaluate the polynomial decreases with the size of the polynomial!
- This makes the recurrence `T(n) = T(n/2) + n` with `T(1) = 1` which is `O(n log n)`.

#### Worked out example of FFT of 8 elements

$$
p(x) \equiv a_0 x^0 + a_1 x^1 + a_2 x^2 + a_3 x^3 + a_4 x^4 + a_5 x^5 + a_6 x^6 + a_7 x^7
p_e(x) \equiv a_0 x^0 + a_2 x + a_4 x^2 + a_6 x^3 \\
p_o(x) \equiv a_1 + a_3 x + a_5 x^2 + a_7 x^3 \\
P(x) = p_e(x) = x p_o(x)
$$

Now suppose we know how to evaluate $p_e(x)$ and $p_o(x)$ at $[w_4^0, w_4^1, w_4^2, w_4^3]$. where $w_4$
is the 4th root of unity. We wish to evaluate $p(x)$ at $[w_8^0, w_8^1, w_8^2, \dots, w_8^7]$, where $w_8$
is the 8th root of unity. The only two properties of the roots of unity we will need are:

- $w_8^2 = w_4$.
- $w_8^4 = -1$.

Using the value of $w_8$, the above two relations, the values $p_o(w_4^k) = [p_o(1), p_o(w_4, p_o(w_4^2), p_o(w_4^3)]$
and $p_e(w_4^k) = [p_e(1), p_e(w_4), p_e(w_4^2), p_e(w_4^3)]$, we evaluate $p$ at powers of $w_8$ ( $[p(w_8^k)]$ )  as:

- $p(w_8^k) = p_e((w_8^k)^2) + w_8^k p_o((w_8^k)^2) = p_e(w_4^k) + w_8^k p_o(w_4^k)$.
- $p(w_8^0) = p_e((w_8^0)  + w_8^0 p_o(w_8^0) = p_e(1) + p_o(1)$
- $p(w_8^1) = p_e(w_8^2)  + w_8^1 p_o(w_8^2) = p_e(w_4^1) + w_8 p_o(w_4^1)$
- $p(w_8^2) = p_e(w_8^4)  + w_8^2 p_o(w_8^4) = p_e(w_4^2) + w_8^2 p_o(w_4^2)$
- $p(w_8^3) = p_e(w_8^6)  + w_8^3 p_o(w_8^6) = p_e(w_4^3) + w_8^3 p_o(w_4^3)$
- $p(w_8^4) = p_e(w_8^8)  + w_8^4 p_o(w_8^8) = p_e(w_4^4) + w_8^4 p_o(w_4^4) = p_e(1) - p_o(1)$



#### Solving the Recurrence: `T(n) = n + T(n/2)`, with `T(1) = 1`

#### Proof 1:

Expand the recurrence:


```
= T(n)
= n + 2T(n/2)
= n + 2[n/2 + T(n/4)]
= n + n + 4T(n/4)
= n + n + 4[n/4 + 2T(n/8)]
= n + n + n + 8T(n/8)
= ...
= kn + ... 2^k T(n/2^k)
= (log n)n + 2^(log n) T(n/2^(log n))
= (log n)n + n T(n/n)
= (log n)n + n* 1
= (log n)n + n
```

#### Proof 2:

Consider the tree:

```
           8
          mrg:8
   4                 4
   mrg:4           mrg:4
  2     2          2       2
 mrg:2  mrg:2     mrg:2   mrg:2
 1 1    1  1      1   1    1  1
```

- Number of leaves is `n`. Cost of each leaf is `T(1) = 1`. Total cost of leaf level is `n`.
- At each level above, total cost is `8 = 4*2 = 2*4`.
- Number of levels in `log n`.
- Total cost is cost of leaf `n`, plus cost of interior nodes `n log n`.


# codeforces rating of some GMs

- Zscoder: Is quite comforting to see the rating of someone who [started at 1400, dropped to pupil](https://codeforces.com/profile/zscoder)
  and then worked their way back up?

- [ScarletS](https://codeforces.com/profile/ScarletS)



# Continuum TTRPG

> Events don't conspire. People do. Events *can't* conspire, and people *can*.
> Causality is not a renewable resource.
> If a time machine could be constructed, it would be married to the
> trend of instant gratification.

#### Fragging

> Sentient force must be applied to undo sentient damage --- time combat.

#### As/As not

> At this moment, anything is possible.


> Causality is only one principle and psycohology essentially
> cannot be exhausted by causal methods only.

#### Blending in with levellers

> Anthropologists in the field have noted
> that to be accepted as a native to a place, one
> has to be born there. No matter how well you
> behave, or how welcome a part of the com-
> munity you become, it will be remembered
> that you came from outside.
> A curious exception to this was observed
> by anthropologist Charles Ward, working
> in the 1950s: If one leaves the community,
> and then returns after a distinct absence,
> one is then welcomed much as a returning
> native. This can be seen as a norm in most
> human cultures, as long as the person
> returning was looked upon favorably when
> they left.

#### Tipler Cylinder

> A Tipler cylinder, also called a Tipler time machine,
> is a hypothetical object theorized to be a potential mode
> of time travel—although results have shown that a Tipler cylinder
> could only allow time travel if its length were
> infinite or with the existence of negative energy.




# Words to know in target language

- Animal: dog, cat, fish, bird, cow, pig, mouse, horse, wing, animalC

- Transportation: train, plane, car, truck, bicycle, bus, boat, ship, tire, gasoline, engine, (train) ticket.

- Location: city, house, apartment, street/road, airport, train station,
  bridge, hotel, restaurant, farm, court, school, office,
  room, town, university, club, bar, park, camp, store/shop,
  theater, library, hospital, church, market, country
  (USA, France, etc.), building, ground, space (outer space), bank.

- Clothing: hat, dress, suit, skirt, shirt, T-shirt, pants, shoes, pocket, coat, stain, clothingC

- Color: red, green, blue (light/dark), yellow, brown, pink, orange, black, white, gray, colorC

- People: son, daughter, mother, father, parent (= mother/father), baby, man, woman,
  brother, sister, family, grandfather, grandmother, husband, wife, king, queen,
  president, neighbor, boy, girl, child (= boy/girl), adult (= man/woman),
  human (≠ animal), friend (Add a friend’s name), victim, player, fan, crowd, personC

- Job: Teacher, student, lawyer, doctor, patient,
  waiter, secretary, priest, police, army, soldier,
  artist, author, manager, reporter, actor, jobC

- Society: religion, heaven, hell, death, medicine, money,
  dollar, bill, marriage, wedding, team,
  race (ethnicity), sex (the act), sex (gender), murder,
  prison, technology, energy, war, peace, attack,
  election, magazine, newspaper, poison, gun, sport,
  race (sport), exercise, ball, game, price,
  contract, drug, sign, science, God

- Art: band, song, instrument (musical), music, movie, art

- Beverages: coffee, tea, wine, beer, juice, water, milk

- Food: egg, cheese, bread, soup, cake, chicken, pork,
  beef, apple, banana, orange, lemon, corn, rice, oil,
  seed, knife, spoon, fork, plate, cup, breakfast,
  lunch, dinner, sugar, salt, bottle

- Home: table, chair, bed, dream, window, door,
  bedroom, kitchen, bathroom, pencil, pen, photograph,
  soap, book, page, key, paint, letter, note, wall,
  paper, floor, ceiling, roof, pool, lock, telephone,
  garden, yard, needle, bag, box, gift, card, ring, tool

- Electronics: clock, lamp, fan, cell phone,
  network, computer, program (computer), laptop, screen, camera, television, radio

- Body: head, neck, face, beard, hair, eye, mouth, lip, nose,
  tooth, ear, tear (drop), tongue, back, toe, finger,
  foot, hand, leg, arm, shoulder, heart,
  blood, brain, knee, sweat, disease, bone,
  voice, skin, body

- Nature: sea, ocean, river, mountain, rain, snow, tree, sun,
  moon, world, Earth, forest, sky, plant, wind,
  soil/earth, flower, valley, root, lake, star, grass, leaf,
  air, sand, beach, wave, fire, ice, island, hill, heat

- Materials: glass, metal, plastic, wood, stone,
  diamond, clay, dust, gold, copper, silver

- Math/Measurements: meter, centimeter, kilogram, inch, foot,
  pound, half, circle, square, temperature, date, weight, edge, corner

- Misc Nouns: map, dot, consonant, vowel, light, sound, yes,
  no, piece, pain, injury, hole, image, pattern,

- Parts of speech: noun, verb, adjective. Use as labels to help distinguish between very similar-looking words
  (i.e., to die (verb), death (noun), dead (adjective))

- Directions: top, bottom, side, front, back, outside, inside,
  up, down, left, right, straight, north, south, east, west, directionC

- Seasons: Summer, Spring, Winter, Fall, season

- Numbers: 0 to 20, 30, 40, ... 100, 1st...5th

- Months: January, February, March, April, May, June, July, August, September, October, November, December

- Days of the week: Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, Sunday.
  Note: You’ll usually find pictures of people going to work on Mondays and partying on Fridays/Saturdays, etc.

- Time: year, month, week, day, hour, minute, second , morning, afternoon, evening, night, time.

- Verbs: work, play, walk, run, drive, fly, swim, goC, stop, follow, think,
  speak/say, eat, drink, kill, die, smile, laugh, cry, buy, pay, sell,
  shoot(a gun), learn, jump, smell, hear(a sound), listen(music), taste, touch,
  see (a bird), watch (TV), kiss, burn, melt, dig, explode,
  sit, stand, love, pass by, cut, fight, lie down, dance,
  sleep, wake up, sing, count, marry, pray, win, lose,
  mix/stir, bend, wash, cook, open, close, write, call, turn,
  build, teach, grow, draw, feed, catch, throw, clean, find, fall,
  push, pull, carry, break, wear, hang, shake, sign, beat, lift

- Adjectives: long, short (long), tall, short (vs tall), wide, narrow, big/large,
  small/little, slow, fast, hot, cold, warm, cool, new,
  old (new), young, old (young), good, bad, wet, dry, sick,
  healthy, loud, quiet, happy, sad, beautiful, ugly, deaf,
  blind, nice, mean, rich, poor, thick, thin, expensive,
  cheap, flat, curved, male, female, tight, loose, high,
  low, soft, hard, deep, shallow, clean, dirty,
  strong, weak, dead, alive, heavy, light (heavy),
  dark, light (dark), nuclear, famous

- Pronouns: I, you (singular), he, she, it, we, you (plural, as in “y’all”), they.


# DP on subarrays

We can update subarrays with the rule `dp[l][r] = merge(dp[l][r-1], dp[l+1][r], compute(l, r))`
where `merge` merges the best results of all subarrays, and `compute(l, r)` computes the
value for `[l..r]`. This guarantees that `dp[l][r]` will track the best value from all
subarrays. For this DP to work, we iterate by length of the subarray.

# Vis editor cheat sheet

#### Insert
- `x/search`: selects all things that match `search`
- `C-k`/`C-j`: extend cursor above/down
- `C-n`: select next match [This is sublime's `C-d`].
- Select a block, hit `I` to create cursors at the beginning of each line
- Select a block, hit `A` to create cursors on end of each line

#### Removal

- `C-p`: remove the primary selection.
- `C-x`: skip

#### Navigation

- `C-d`/`C-u`: navigation
- `+/-`: rotation
- `<Tab>` and `<S-Tab>`: alignment
- `_`: trim white space
- `o`: orientation: move to beginning and ending of selection.

### References
- [Youtube talk on `vis`](https://www.youtube.com/watch?v=y41MyOrPt8Q)
- [SAM text editor doc](http://doc.cat-v.org/plan_9/4th_edition/papers/sam/)
- [Vis manual](https://martanne.github.io/vis/man/vis.1.html)

# Mean, Median and Jensen's

The intuition for Jensen's is typically presented as:

```
|
| \       /
|  \  *  /
|   \   /
|    -@-
|
+--x----->
```

- `*` is the average of the $f(x)$
- `@` is the $f$ of average of the x's.
- I wish to reinterpret this: the `@` is at the *median* of the $f(x)$s. So Jensen is maybe saying that
  the value at the median is lower than the mean of the values in this case due to the convexity of $f$.
- In some sense, this tells us that the "data" $\{ f(x): l \leq x \leq r \}$ is skewed in such a way that
  median is lower than the mean.
- I don't know if this perspective helps, or even if it is correct, but I wish to dwell on this perspective
  since it's one I don't use often. I've been thinking more along these lines due to competitive programming,
  and I quite enjoy the change!

# The similarity between labellings and representations

- One way to think about labellings is that we track the "entire history" of the object.
- it's hard to count unlabelled objects. it's easier to count labelled objects.
- for example, suppose we have graphs $g = (v, e)$ and $h = (v', e')$. an isomorphism of these as unlabelled graphs
  is a bijection function $f: v \rightarrow v'$ such that $s e t$ if and only if $f(s) e f(t)$.
- there could be many such $f$, or no such $f$. it's hard to find out!
- Now let's suppose the graphs have labellings, so we have labels $l: V \rightarrow [|V|]$ and $l': V' \rightarrow [|V'|]$
  where $[n] \equiv \{1, 2, \dots, n\}$.
- An isomorphism of labelled graphs is an unlabelled isomorphism along with the constraint that $l'(f(v)) = l(v)$.
  That is, we must preseve labels. So, for example, the graph:

```
a:1 -- b:2
c:2 -- d:1
```

are isomorphic since I can send `a -> d` and `b -> c`.

- On the other hand, the graph:

```
a:1-b:2-c:3
d:1-e:3-f:2
```

is not isomorphic (though they would be if we forget the numbering), since the center vertices `b` and `e` have different labels.

- Let's think of the equation $l'(f(v)) = l(v)$. Since $f$ is a bijection, we have $|V| = |V'|$, so $l$ and $l'$ are both bijections
  to the same set $[|V|] = [|V'|]$. So we can invert the equation to write $f(v) = l'^{-1}(l(v))$. This tells us that $f$ is *determined*
  by the labellings!
- The point of having a labelling is that it forces upon us a **unique isomorphism** (if it exists), given by the equation $f(v) \equiv l^{-1}(l(v))$.
- This collapses hom sets to either empty, or a unique isomorphism, which is far tamer than having many possible graph isomorphisms that we must
  *search for*/*enumerate*!
- In analogy to representation theory, if we consider two irreducible representations of a group $G$, say $\alpha: G \rightarrow GL(V)$ and
  $\beta: G \rightarrow GL(W)$, Schur's lemma tells us that the Hom-set between the two representations (an intertwining map) is either
  the zero map (which is like having no isos) or a scaling of the identity map (which is like having a uniquely determined iso).
- In this sense, we can think of an irrep as a "labelling" of group elements in a particularly nice way, since it constrains
  the potential isomorphisms of the "labelled objects"!



# L1 norm is greater than or equal to L2 norm

Pick two points $A \equiv (x_1, y_1)$ and $B \equiv (x_2, y_2)$, and suppose $x_1 < x_2$ and $y_1 < y_2$.
So we imagine this as two sides of a triangle:

```
     B
    /
   /
  /
 /
A
```

- The L1 norm is $|x_2 - x_1| + |y_2 - y_1|$. This is the distance on connecting to an origin $O$:


```
  δx
O----B
|   /
δy /
| /
|/
A
```

- The L2 norm is $\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}$, which is the distance of the vector $AB$, or
   the hypotenuse of the right angled triangle $AOB$:

```
  δx
O----B
|   /
δy / L2
| /
|/
A
```

- By triangle inequality, $OA + OB \geq AB$, hence $L_1 = \delta_x + \delta_y \geq L_2$

# Z algorithm

- The `Z` algorithm, for a given string $s$, computes a function $Z: [len(s)] \rightarrow [len(s)]$.
- $Z[i]$ is the length of the longest common prefix between $S$ and $S[i:]$.
- So, $S[0] = S[i]$, $S[1] = S[i+1]$, $S[2] = S[i+2]$, and so on till
  $S[Z[i]] = S[i + Z[i]]$, and then $S[Z[i]+1] \neq S[i + Z[i] + 1]$.


- If we can compute the `Z` function for a string, we can then check if pattern `P`
  is a substring of text `T` by constructing the string `P#T$`. Then, if we
  have an index such that `Z[i] = len(P)`, we know that at that index, we have
  the string `P` as a substring.

- Note that the `Z`-algorithm computes the `Z` function in **linear time**.

- The key idea of the Z algorithm is to see that if we are at an index `i`, but we have an index `l < i`
  such that `i < l + z[l]`, then we have that `s[0:z[l]] = s[l:l+z[l]]`. Thus, we are "in the shade" of the `l`.

- In this situation, we can reuse `z[i-l]` as a seed for `z[i]`. There are two cases: `i + z[i-l] > l + z[l]` and the converse.
- If `i + z[i-l] < l + z[l]`, then we are still "in the shade" of `l`, so we can safely set `z[i] = z[i-l]`.
- If not, we set `z[i] = l + z[l]`, since we know that we match _at least_ this much of the beginning of the string.

### Specification

```cpp
vector<int> calcz(std::string s) {
 const int n = s.size();
 vector<int> z(n);
 z[0] = 0;
 for(int i = 1; i < s.size(); ++i) {
   z[i] = 0;
   while(i + z[i] < n && s[i+z[i]] == s[z[i]]) {
     z[i]++;
   }
 }

 return z;
}
```


#### Implementation

```cpp
vector<int> myz(std::string s) {
    const int n = s.size();
    vector<int> z(n);
    for(int i = 0; i < n; ++i) { z[i] = 0; }

    // shade that was last computed.
    int l = 0;
    for(int i = 1; i < n; ++i) {
        // shade: (l + z[l]) - i
        // guess from start: z[i-l]
        z[i] = max(0, min(l + z[l] - i, z[i-l]));

        // compare with initial portion of string.
        while (i + z[i] < n && s[z[i]] == s[i + z[i]]) { z[i]++; }

        // we exceed the current shade. Begin ruling.
        if (i + z[i] >= l + z[l]) { l = i; }
    }

    return z;
}
```

- Reference: Algorithms on strings, trees, and sequences.

# For a given recurrence, what base cases do I need to implement?

- For a linear recurrence, we need to defie base cases for as many steps as we go back.
- For combinations, we step `n` by `1`, `r` by `1`. So we need to define what happens for `n=0` OR `r=0`.


# Number of distinct numbers in a partition

- A positive integer $n$ is represented as a partition $\lambda \equiv (k_1, k_2, \dots)$ where
  $\sum_i k_i = n$ and $k_1 \leq k_2, \dots$.
  Such a $\lambda$ always contains at most $O(\sqrt n)$ distinct numbers.
- Intuition: suppose we want to have the maximum number of distinct numbers.
  Since we are tied down by the constraint $\sum k_i = n$, we must try to choose
  the $k_i$ as small as possible. But we know that even $\sum_{i=1}^p i = p(p+1)/2 \sim O(p^2)$. Now if $O(p^2) = n$, then the sum can only run upto $\sqrt p$.
- Alternate intuiton: asking to build a number $n$ out of distinct numbers $k_1, k_2, \dots$
  is asking to build a "jagged triangle" out of columns $(i, k_i)$  whose area is $n$. Area is $1/2 b h$, which is sorta quadratic (?)


# Splitting $f(x) = y$ into indicators

If the output of $f(x)$ is a natural number, then we can write the value $f(x)$ as:

$$
f(x) = \sum_{i=1}^\infty [f(x) \geq i]
$$

where $[f(x) \geq i]$ is $1$ if the condition is true and $0$ otherwise.

Another useful indicator type equation is:

$$
\sum_x f(x) = \sum_x \sum_i i \cdot [f(x) = i] = \sum_i i \cdot (\sum_x [f(x) = i])
$$


# Why searching for divisors upto `sqrt(n)` works

- It's not that all divisors are smaller than $\sqrt n$. For example, consider $14 = 7 \times 2$. $\sqrt{14} \sim 4$, but one
  of its diviors ($7$) is greater than 4.
- Rather, it is that if there is a divisor $l$ (for large) which is larger than $\sqrt n$, there will be another divisor $s$ which is smaller than $\sqrt n$.
- Proof: Suppose $l \div n$, $l \geq \sqrt n$. So there exists an $s$ such that $ls = n$, or $s = n / l$.
- Since $l \geq \sqrt n$, $n / l \leq  n / \sqrt n = \sqrt n$. Thus $s \leq \sqrt n$.
- So if we wish to find *some* factor of $n$, we can simply search within the range $\sqrt n$.
- If $n$ has no factors in the range $\sqrt n$, then $n$ must be prime, for if $n$ did have a larger factor,
  $n$ would also have a smaller factor we would have found.


# Heuristics for the prime number theorem

> "It is evident that the primes are randomly distributed but, unfortunately, we don't know what 'random' means."


- The prime number theorem says that at $n$, the number of primes upto $n$ is (approx.) $(n/\log n)$. Formally:

$$
P(n) \equiv |\{ p \text{ prime } : 2 \leq p \leq n \}| \sim \frac{n}{\log n}
$$

- Consider sieving. In the beginning, everything is potentially prime.
- When we remove the multiples of a prime `p`, we decrease the density of potential primes.
- As we remove `1/p` of the remaining potential primes
  (eg. removing `2` drops density of potential primes by half. Sieving by `3` *reduces* the density by one-third).
- See that the reduction is *additive* not *multiplicative*. That is, upon removing the `5`, we lose `1/5` of our potential primes,
  so the new density is `D2 = D - D/5`. Said differently, we have `4/5`th the number of potential primes we used to have, so `D2 = 4D/5`.
- Furthermore, removing `5` only begins to affect the density of primes after `5*5 = 25`, since smaller multiples of `5` (`5*1`, `5*2`, `5*3`, `5*4`)
  have been removed at earlier iterations of the sieve (on sieving  `5`, `2`, `3`, and `2`, respectively).
- In general: On removing a prime `p`, Our new density becomes `D2 = D - D/p` which is `(1-1/p)D`.
- In general: On removing a prime `p`, the density till `p*p` remains untouched. Density after `p*p` is multiplicatively scaled by `(p-1)/p`.
- Define a function $f(x)$ which estimates density of primes around $x$.
- We consider the effect of the primes in the interval $A \equiv [x, x+dx]$  on the interval $B \equiv [x^2, (x+dx)^2]$
- Each prime $p$ in interval $A$ decreases the density of primes in interval $B$ by subtracting $f(x^2)/p$, since we lose those many primes.
  Since each number in $[x, x+dx]$ is basically $x$, we approximate this subtraction to $f(x^2)/x$.
- In interval $A$, there are $f(x)dx$ primes.

$$
\begin{aligned}
&f((x+dx)^2) = \\
&= f(x^2) - \text{killing of from primes in $x$} \\
&= f(x^2) - \sum_{p \in [x, x+dx]} [\texttt{Prob}(p \text{ prime})] \cdot f(x^2)/p \\
&= f(x^2) - \sum_{p \in [x, x+dx]} [f(p)] \cdot f(x^2)/p \\
&= \text{($p \sim x$ in $[x, x+dx]$):} \\
&= f(x^2) - \texttt{length}([x,x+dx]) \cdot [f(x)] \cdot f(x^2)/p \\
&= f(x^2) - (dx) f(x) \cdot f(x^2)/x \\
&f((x+dx)^2) = f(x^2) - f(x^2)f(x)dx/x \\
&f((x+dx)^2) - f(x^2) = -\frac{f(x^2)f(x)dx}{x}
\end{aligned}
$$

From this, we now estimate $f'(x^2)$ as:

$$
\begin{aligned}
&f((x+dx)^2) - f(x^2) = -\frac{f(x^2)f(x)dx}{x} \\
&\frac{f((x+dx)^2) - f(x^2)}{dx} = -\frac{f(x^2)f(x)}{x} \\
&\frac{f(x^2 + 2dx + dx^2) - f(x^2)}{dx} = -\frac{f(x^2)f(x)}{x} \\
&\text{Ignore $O(dx^2)$:} \\
&\frac{f(x^2 + 2dx) - f(x^2)}{dx} = -\frac{f(x^2)f(x)}{x} \\
&\frac{f(x^2 + 2dx) - f(x^2)}{dx \cdot 2x} = -\frac{f(x^2)f(x)}{x\cdot 2x} \\
&\frac{f(x^2 + 2dx) - f(x^2)}{2xdx} = -\frac{f(x^2)f(x)}{2x^2} \\
& \text{Let $u = x^2$} \\
&\frac{f(u + du) - f(u)}{du} = -\frac{f(u)f(\sqrt u)}{2u} \\
&f'(u) = -\frac{f(u)f(\sqrt u )}{2u}
\end{aligned}
$$

#### An immediate consequence

Sice $u$ is large, we approximate $u \sim \sqrt{u}$ to get:

$$
\begin{aligned}
&f'(u) = -\frac{f(u)f(\sqrt u )}{2u} \\
&f'(u) \sim -\frac{f^2(u)}{2u} \\
&\frac{df}{du} \sim -\frac{f^2(u)}{u} \\
&\frac{df}{f^2} \sim -\frac{du}{u} \\
&\int \frac{df}{f^2} \sim - \int \frac{du}{u} \\
&-\frac{1}{f(u)} \sim -\ln(u) \\
&\frac{1}{f(u)} \sim \ln(u) \\
&f(u) \sim  \frac{1}{\ln(u)}
\end{aligned}
$$

So the density of primes around $f(u)$ is $1/\ln(u)$. So upto $n$, the number of primes is $\int_0^n f(x) dx$ which is $\int_0^n 1/ln(x) dx$, bounded by $n/ln(n)$.
This "proves" the prime number theorem.

- [Reference: Feedback, Control, and the Distribution of Prime Numbers](https://www.maa.org/sites/default/files/pdf/upload_library/2/Marshall-MathMag-2014.pdf)
- [Heuristic derivation of the prime number theorem](https://sites.williams.edu/Morgan/2008/10/11/heuristic-derivation-of-prime-number-theorem/)


# Sum of absolute differences of an array

- We are given an array `a[:]` and we are asked to compute the sum of differences $\sum_{i=1}^n \sum_{j=i+1}^n |a[i] - a[j]|$.
- To compute this efficiently, first sort `a[:]` into a sorted array `s[:]`. For simplicity, say we have `N = 4`.
- Now see that if we write down the values for `N=4`, we will see:

```
D =
|s[1] - s[2]| + |s[1] - s[3]| + |s[1] - s[4]| +
|s[2] - s[3]| + |s[2] - s[4]| +
|s[3] - s[4]|
```

- `i < j` implies `s[i] < s[j]` as `s` is sorted. So each of the terms `(s[i] - s[j]|)` is negative. We thus flip the terms, giving:

```
D =
(s[2] - s[1]) + (s[3] - s[1]) + (s[4] - s[1]) +
(s[3] - s[2]) + (s[4] - s[2]) +
(s[4] - s[3])
```

- Note that `s[1]` is always negative, so it will have coefficient `-4` on grouping.
- See that `s[2]` was positive in the grouping `(1, 2)`, and was negative in the groupings `(2, 3)` and `(2, 4)`.
  So `2` will have a coefficient `+1*(2-1) -1*(4 - 2)`.
- Similarly, `s[3]` was positive in the grouping `(1, 3)` and `(2, 3)` and was negative in the grouping `(3, 4)`.
- In general, `s[i]` will be positive when paired with `[1, 2, ..i-1, i)` and negative when paired with `(i, i+1, i+2, \dots n]`.
  So `s[i]` will contribute a coefficient of `+1*(i-1) - 1*(n-i)`
  [using the formula that for intervals `[l, r)` and `(l, r]` the number of elements is `(r-l)`]

# GCD  is at most difference of numbers

- assume WLOG $l< r$. Then, Let $g \equiv gcd(l, r)$. Claim: $g \leq r - l$.
- Proof: we have $g \div r$ an $g \div l$ by definition, hence we must have $g \div (r - l)$, and $g$, $(r-l)$ are nonnegative.
  So  $g \leq (r - l)$.
- Intuition: the gcd represents the common roots of $l, r$ in Zariski land. That is, if $l, r$ are zero at a prime
  then so is $r - l$.
- So, the GCD equally well represents the common roots of $l$ and $(r - l)$.
- Now, if a number $x$ vanishes at a subset of the places where $y$ vanishes, we have $x < y$ (the prime factorization of $y$ contains all the prime factors of $x$).
- Since the GCD vanishes at the subset of the roots of $l$, a subset of the roots of $r$, and a subset of the roots of $(r-l)$, it must be smaller than all of these.
- Thus, the GCD is at most $r - l$.
- Why does GCD not vanish at exactly the roots of $r-l$? If $l$ and $r$ both take the same non-zero value
  at some prime then $(r - l)$ does too. But this is not a loacation where $l$ and $r$ vanish.

# implementing GCD and LCM

```cpp
// gcd(x, y) = d <=> min({ ax + by : ax + b y >= 0 })= d
long gcd(long x,long y) { return y == 0 ? x : gcd(y, x%y); }
long lcm(long x,long y) {return x/gcd(x,y)*y;}
```


# Centroid of a tree

- A centroid is a node which upon removal creates subtrees of size at most `ceil(n/2)`.

#### Existence of centroid for rooted tree (algorithm to compute centroid)

- If tree has exactly one node, we are done, the centroid is the root.
- Suppose for induction a centroid exists for trees of size $n-1$. We will now prove the existence of a centroid for tree of size $n$.
- Otherwise, if the root has all children whose subtree sizes are at most `ceil(n/2)`, the root is the centroid and we are done.
- Otherwise, the root has *one* child with subtree size *strictly greater than* `ceil(n/2)`. There can't be two such children, because their
  combined size would be `2*ceil(n/2) >= n`. This is nonsensical, as the size of the subtrees plus the root node would mean the tree
  has `2*ceil(n/2) + 1 >= n+1` nodes, a contradiction.
- We recurse into the subtree. The size of the subtree of the child is at least one less than the size of the root, thus we are decreasing on the size of the tree.
- By recursion, we must terminate this process and find a centroid.

#### Centroid decomposition

- Once we find the centroid of a tree, we see that all of its subtrees has size less than `ceil(n/2)`.
- We can now recurse, and find sizes of centroids of these subtrees.
- These subtrees are disjoint, so we will take at most `O(n)` to compute sizes and whatnot.
- We can do this `log(n)` many steps since we're halving the size of the subtree each time.
- In total, this implies that we can recursively find centroids to arrive at a "centroid decomposition" of a tree.
- Note that the centroid decomposition of the tree constructs a new tree, which is different from the original tree, sorta how the dominator tree
  is a different tree from the original tree.

# Center of a tree

- The *remoteness* / *eccentricity* of a vertex $v$ is its distance from its furthest node. $r(v) \equiv \max_{w \in V} d(v, w)$.
- The *center* of a tree is the vertex with minimum remoteness.

#### Claim: center is on any diameter.

- Let $D$ be the diameter of length $L$.
- Let $c$ be the center. We claim that $c$ lies on $D$. If so, we are done.
- If not, then there is a path from $c$ to some vertex $v$ in $D$. Let WLOG the endpoints of the diameter be $s$ and $e$, and such that
  $v$ is further from $s$ than $e$. That is: $d(s, v) \geq s(v, e)$. In a picture:

```
s----------v---e
           |
           n
           |
         n-c--n
           |
           n
```

- Key idea: the important distance is the distance from $v$ to $s$. So we can forget everything in a radius of $d(v, e)$, as the distance $d(v, e) < d(v, s)$,
  and $d(c, e) < d(c, s)$. But if we forget the structure around $v$ in a radius of $e$, all we are left with is:

```
s-------------------v
                    |
                    |
                    c
```

where clearly $v$ is closer to $s$ than to $c$, and thus $c$ cannot be the center. In some sense, we are making a large scale/coarse structure argument,
where the large scale structure is dominated by $d(s, v)$, which is all that matters.

- For any node $n$ in the subtree hanging from $v$, we have $d(n, v) \leq d(v, e)$, since otherwise the path $s-v-n$ would become a path
  longer than the diameter, contradicting the maximality of the diameter.
- Hence, we have $d(n, v) \leq d(v, e) \leq d(v, s)$, where the second inequality comes from the assumption of $s$ and $e$.
  So $s$ is the node that is furthest from $v$ amongst all nodes in the graph.
- But now notice that $d(c, s) = d(c, v) + d(v, s)$, and this is the longest distance from $c$ to any other node. This implies that $d(c, s) > d(v, s)$ as $d(c, v) > 0$.
- This contradicts the minimality of the eccentricity of $c$: the longest distance from $c$ to


#### Claim: center is median of any diameter

We've already seen that center is on the diameter. Now if a center node is not on the median,
the distance to the furthest node (start/end) can be improved by moving the center node
closer to the median. So the best choice is to have the center be at (one of the) medians.



#### Claim: center does not change by removing all leaf vertices

We've shown that the center is the median of all diameters. Removing all leaves
removes two elements at the beginning and end of all diameters, leaving the
median (the center) invariant.



# Image unshredding as hamiltonian path

This was a cool use of [hamiltonian path](https://github.com/robinhouston/image-unshredding) that I saw on hacker news
recently.

- The problem is this: given an image where the columns are created by shuffling columns of an original image, we must recreate
  the original image.
- The reduction: treat each column as a vertex, connect columns that are close to each other in similarity.
- Hamiltonian path will visit each vertex exactly once (ie, pick each column exactly once).

I think this example is striking enough that I'll never forget that in a hamiltonian path, we can visit
vertices exactly one, (in contrast to an euler tour, we must visit each edge exactly once).


# Distance between lines in nD

- https://www.codechef.com/viewsolution/28723599

#### Subproblem: point-line distance in nD

- Intuitlvely, given a point $o$ and a line $L \equiv p + \alpha x$ (greek letters will be reals, all else vectors),
  we must have that the line that witnesses the shortest distance from $o$ to $L$ must be perpendicular to $L$.
- For if not, we would have some "slack" that we could spend to shorten the distance. Alternatively, using
  Lagrange multipliers intuition, the gradient must be perpendicular to the level surface of the constraint.
  In this case, we are tryng to find a point $o'$ that minimizes distance $oo'$ such that $o' \in L$. The ladder
  is a lagrange constraint, and hence defines a level surface to which the optimal solution must be perpendicular to.
- Some calculus to prove this Let $l \equiv p + \alpha x$ be a point on the line $L$. We extrmize the length $ol$
  as a parameter of $\alpha$:

$$
\begin{aligned}
&\partial_\alpha (ol \cdot ol) = 0 \\
&\partial_\alpha ((o - p - \alpha x) \cdot (o - p - \alpha x) = 0 \\
&\text{only terms with $\alpha$ survive $\partial_\alpha$: } \\
&\partial_\alpha - o \cdot \alpha x + p \cdot \alpha x  - \alpha x \cdot o - \alpha x \cdot (- p) - \alpha x \cdot (- \alpha x)  = 0\\
&\partial_\alpha - 2 \alpha o \cdot x + 2 p \cdot \alpha x  + \alpha^2 x \cdot x  = 0\\
&\partial_\alpha - 2 \alpha o \cdot x + 2\alpha p \cdot x + \alpha^2 x \cdot x  = 0 \\
&- 2 o \cdot x + 2 p \cdot x + 2 \alpha x \cdot x  = 0 \\
&2 (- o  + p + \alpha x)  \cdot x  = 0 \\
&2 (- o  + l)  \cdot x  = 0 \\
&2 (\vec{lo})  \cdot x  = 0 \\
&(\vec{lo}) \cdot x  = 0 \\
&\vec{lo} \bot x
\end{aligned}
$$

- This tells us that the line $ol$ is perpendicular to the direction $x$, which is the direction of the line $L$. Hence, the
  line $(ol)$ from the point $o$ to the line $L$ with minimum distance is orthogonal to the line $L$ itself.

#### Line-Line distance

- We can take two parametric points on two lines $L \equiv p + \alpha x$, and $M \equiv q + \beta y$, and build the line $lm$ which witnesses
  the shortest distance.
- From the above derivation, we see that the line $lm$ must be perpendicular to both $L$ and $M$, since we can view line-line-distance as two
  simultaneous point-line-distance problems: distance from point $l \in L$ to line $M$, and distance from point $m \in M$ to line $L$.
- This gives us the equations $lm \cdot x = 0$, and $lm \cdot y = 0$. We have two variables $\alpha, \beta$ and two equations, so we solve for $\alpha, beta$.
- This allows us to find the line $lm$ whose length is the shortest distance.

# `lower_bound` binary search with closed intervals

```cpp
// find rightmost ix such that ps[ix].b < t
ll max_earlier(ll t, vector<P> &ps) {
  assert(ps.size() > 0);
  // [l, r]
  ll l = 0, r = ps.size()-1;
  // closed interval.
  int ans = -1;
  while (l <= r) {
    ll mid = l + (r-l)/2;
    if (ps[mid].b < t) {
      // we have considered `mid`.
      // now move to the higher range to find other candidates.
      ans = max(ans, mid);
      l = mid+1;
    } else {
     // ps[mid] does not satisfy our invariant.
     // move to the lower range.
     r = mid-1;
    }
  }
  assert(ps[l].b < t);
  if (l + 1 < ps.size()) { assert(ps[l+1].b >= t); }
  return ans;
}
```


# Sliding window implementation style

I usually implement sliding window as:


```cpp
// [l, r)
int l = r = 0;
while (r < n) {
 assert(l <= r);
 if (extend_window) { r++; }
 else {
    l--; //contract window
 }
}
```

However, there are cases where we have complicated invariants on the sliding
window, such as a maximum length. An example is [codeforces 676c](https://codeforces.com/contest/676/problem/C),
where we must maintain a sliding window which contains at most `k >= 0` "illegal" elements.

My [flawed implementation](https://codeforces.com/contest/676/submission/121042148) using a `while` loop was:

```cpp
int best = 0;
for(int c = 'a'; c <= 'b'; ++c) {
    // window: [l, r)
    int l = 0, r = 0;
    // number of illegal letters changed. <= k
    int changed = 0;
    while(r < n) {
        assert(changed <= k);
        assert(l <= r);
        if (s[r] == c) { r++; } // legal, extend.
        else {
            // need to change a letter to extend, s[r] != c.
            if (changed == k) {
                // cannot extend, contract from left.
                if (s[l] != c) { changed--; }
                l++;
            } else {
                // extend, spending a change.
                r++;
                changed++;
            }
        }
        // keep track of best window size.
        best = max(best, r-l);
    }
}
```

Unfortunately, the above code is flawed. It does not work when the window size is zero. (TODO: explain)
on the other hand, the implementation where we always stride forward with the `r` value in a `for` loop,
and only deciding what happens with `l` does not suffer from this ([link to implementation](https://codeforces.com/contest/676/submission/121058022)):

```cpp
int best = 0;
for(int c = 'a'; c <= 'b'; ++c) {
    int l = 0;
    // number of illegal letters changed. <= k
    int changed = 0;
    // [l, r]
    for(int r = 0; r < n; ++r) {
        // change to 'a'.
        if (s[r] != c) { changed++; }
        // maintain invariants: must have changed <= k,
        // and at the end of a loop trip, we must have l <= r.
        while(changed > k && l < r) {
            if (s[l] != c) { changed--; }
            l++;
        }
        assert(l <= r);
        // keep track of best window size.
        best = max(best, r-l+1);
    }
}

```





# Kawaii implementation of `x = min(x, y)`


```cpp
template <typename T>
inline void Mn(T &x, T y) { x > y && (x = y); }
```

Wrapping the thing into a template allows one to write code such as `Mn(x, 10)`
to mean `x = min(x, 10)`. This a nice pattern!




# CSES: Counting Towers

- [Link to problem](https://cses.fi/problemset/task/2413/) I found the problem interesting, as I found the DP states un-obvious.
- I eventually performed a DP on the the number of possible towers in y-axis `[0, h)` where we keep track of whether
  the last layer has a `2x1` tile or two `1x1` tiles.
- Importantly, this means that the decision of "closing" a section to create a new section is left to the
  *next* DP state.
- This is weirdly reminisecent of some kind of topological phenomena, where we
  use intervals of the form `[l, l+1)` to cover a space.
- It seems to help me to look at this kind of DP as first creating the
  combinatorial objects, and then switching
  it over to counting the number of such objects created.

# Smallest positive natural which can't be represented as sum of any subset of a set of naturals

we're given a set of naturals $S \equiv \{ x_i \}$ and we want to find
$n \equiv \min \{ sum(T): T \subseteq S \}$, the smallest number that can't be written as a sum
of elements from $S$.

#### By observation


- Key observation: If we sort the set $S$ as $s[1] \leq s[2] \leq \dots \leq s[n]$,
  then we must have $s[1] = 1$. For if not, then $1$ is the smallest nmber which
  cannot be written as a sum of elements.
- Next, if we think about the second number, it must be $s[2] = 2$. If not, we return $2$ as the answer.
- The third number $s[3]$ can be $3$. Interestingly, it can also be $4$, since we can write $3 = 1 + 2$, so we can skip $3$
  as an input.
- What about $s[4]$? If we had $[1 \leq 2 \leq 3]$ so far, then see that we can represent all numbers upto $6$.
  If we have $[1 \leq 2 \leq 4]$ so far, then we can represent all numbers upto $7$. Is it always true that given a "satisfactory"
  sorted array $A$ (to be defined recursively), we can always build numbers upto $\sum A$?
- The answer is yes. Suppose the array $A$ can represent numbers upto $\sum A$. Let's now append $r \equiv sum(A)+1$ into $A$. ($r$ for result).
  Define `B := append(A, r)`. We claim we can represent numbers $[1 \dots (r+\sum A)]$ using numbers from $B$.
  By induction hypothesis on `A`. We can represent $[1 \dots \sum A ]$ from $A$. We've added $r = \sum A + 1$ to this array.
  Since we can build numbers $[1\dots \sum A]$ from $A$, we can add $r$ to this to build the range $[r+1 \dots r + \sum A]$.
  In total, by not choosing $r$, we build the segment $[1 \dots \sum A ]$ and by choosing $r$ we build the segment $[\sum A + 1 \dots \sum A + r]$
  giving us the full segment $[1 \dots \sum A + r]$.


#### Take 2: code

- Input processing:

```cpp
void main() {
  int n;
  cin >> n;
  vector<ll> xs(n);
  for (ll i = 0; i < n; ++i) {
    cin >> xs[i];
  }
```

- Sort to order array

```
  sort(xs.begin(), xs.end());
```

- Next define `r` as max sum seen so far.

```cpp
  ll r = 0; // Σ_i=0^n xs[i]
```

- We can represent number $[0\dots r]$ What can $xs[i]$ be? If it is greater than $(r+1)$, then we have found a hole. If $xs[i] = r+1$,
  then we can already represent $[0\dots r]$. We now have $(r+1)$. By using the previous numbers, we can represent the sums
  $(r+1) + [0 \dots r]$, which is equal to $[r+1 \dots 2r+1]$.
- More generally, if $xs[i] < r+1$, we can represent $[0 \dots r]; [xs[i]+0, xs[i]+r]$.
- The condition that this will not leave a gap between $r$ and $xs[i]$ is to say that $xs[i]+0 \leq (r+1)$.

```cpp
  for (ll i = 0; i < n; ++i) {
    if (xs[i] <= r+1) {
      // xs[i] can represent r+1.
      // We can already represent [0..r]
      // By adding, we can represent [0..r] + (xs[i]) = [xs[i]..r+xs[i]]
      // Since xs[i] <= r+1, [xs[i]..r+xs[i]] <= [r+1, 2r+1].
      // In total, we can represent [0..r] (not using xs[i]) and [<=r+1, <=2r+1]
      // (by using xs[i]) So we can can be sure we won't miss numbers when going
      // from [1..r] to [xs[i]<=r+1...] The largest number we can represent is
      // [xs[i]+r].
      r += xs[i]; // max number we can represent is previous max plus current
    } else {
      // xs[i] > r+1. We have a gap at r+1
      cout << r + 1 << "\n";
      return;
    }
  }
  cout << r + 1 << "\n";
}
```



# Example of RVs that are pairwise but not 3-way independent.

Define `X, Y` to be uniformly random `{0, 1}` variables. `Z = X xor Y`. Each of the pairs
are independent, but `X, Y` determine `Z` so it's not 3-way independent.


# Notes on Liam O Connor's thesis: Cogent

- `AutoCoress`: cool tool
- `sel4`: translate C to HOL using AutoCoress
- `cake`: verify subset of ML
- Cogent has no recursion, provide higher order iterators/recursion schemes to do stuff.
- We do this by using the ! operator. Converts linear, writeable type into read-only type.
  Function that takes value of type Buffer! is free to read, but not write to Buffer.
- Constraint based type inference: (1) generate constraints, (2) solve.
- refinement relation R between values in the value semantics
    and states in the update semantics, and show that any update semantics evaluation
    has a corresponding value semantics evaluation that preserves this relation. When each
    semantics is viewed as a binary relation from initial states to final states (outputs), this
    requirement can be succinctly expressed as a commutative diagram...
- "Translation is the art of failure.  Umberto Eco" --- nice.
-  For the most part, this is because these refinement stages
    involve shallow embeddings, which do not allow the kind of term inspection
    needed to directly model a compiler phase and prove it.
- Strange, refinement relation *goes upwards*? Not downwards?
- `State = (Set (a, state), bool)` seems weird to me. I would have expected `State = Set (a, state, bool)`.
  But I guess if some contol flow path leads to UB, you can blow everything out.
- Translation validation: for each output, produce proof of correctness.
  Different from proving a compiler correct. More like a proof certificate.
- The reasoning behind the decision to relate representations instead of Cogent
  types to C types is quite subtle: Unlike in C, for a Cogent value to be well-typed,
  all accessible pointers in the value must be valid (i.e. defined in the store μ) and
  the values those pointers reference must also, in turn, be well-typed. For taken
  fields of a record, however, no typing obligations are required for those values,
  as they may include invalid pointers (see the update semantics erasure of the
  rules in Figure 4.5). In C, however, taken fields [what is a taken field?] must still be well-typed, and
  values can be well-typed even if they contain invalid pointers. Therefore, it is
  impossible to determine from a Cogent value alone what C type it corresponds
  to, making the overloading used for these relations ambiguous
- Cogent is a total language and does not permit recursion, so we have, in principle,
  a well-ordering on function calls in any program. Therefore, our tactic proceeds by
  starting at the leaves of the call graph, proving corres theorems bottom-up until
  refinement is proven for the entire program. [amazing]
- With this state definition,
  it is not well-defined to take a pointer to a stack-allocated variable, nor
  to reinterpret stack memory as a different type. C code that performs such
  operations is rejected by the parser.
- At the moment, such
  processes are implemented in Cogent with a C shell, which awaits events in a
  loop and executes a Cogent function whenever an event occurs. These are
  clearly better speci ed as productive corecursive programs. Extending Cogent
  to support corecursion will likely be ultimately needed in order to support
  moving these particular C loops into Cogent. Fortunately, Isabelle also
  supports corecursive shallow embeddings, providing us with a direct
  translation target.
- Future work: Property based testing,
  Concurrency, Recursion+Non-termination+Coinduction, Richer type system
  (refinement types), Data layout /Data description




# C++ `lower_bound`, `upper_bound` API

I never remember what precisely `lower_bound` returns, so this is me collecting this information
in a way that makes sense to me. The API docs say

> Returns an iterator pointing to the first element in the range `[first,last)`
> which does not compare less than val.

- So `lower_bound(first, last, bound)` it finds the leftmost location `l` in `[first..last)` such that `as[l] >= bound`.
- See that it can be *equal* to the value `bound`.


In contrast, `upper_bound` says:
> Returns an iterator pointing to the first element in the range `[first,last)` which compares greater than val.

- So `upper_bound(first, last, bound)` it finds the leftmost location `l` in `[first..last)` such that `as[l] > bound`.


##### Pictorially

If we have a range:

```
<<<<<<< ======= >>>>>>>>
        |     |
        L     R
```

- The `<` values are less than bound, `=` values are equal to bound, and `>` values are greater than bound, then
  `lower_bound` and `upper_bound` return iterators to represent the `=` range `[L, R]` in half-open form.
- So we will have `[lower_bound, upper_bound) = [L, R]`. This matches the C++ API where everything uses half-open intervals.

```
<<<<<<< ======= >>>>>>>>
        L     R |
        lower   upper
```

##### Traversals

- $[L, H]$: loop as `for(auto it = lowerbound(l); it < upperbound(h); ++it) {}`.
  This works since `upperbound(h)` will find first index `> h`, so we include all `=h`.
- $[L, H)$: loop as `for(auto it = lowerbound(l); it <= lowerbound(h); ++it) {}`.
  This works `lowerbound(h)` first first index `>= h`, so we don't include any `=h`.
- $(L, H]$: use `for(auto it = upperbound(l); it <= upperbound(h); ++it) {}`.
  `upperbound(l)` finds first index `>l`, so we ignore values `=l`.
- $(L, H)$: use `for(auto it = upperbound(l); it < lowerbound(h); ++it) {}`.


How to think about which one we want? This about it as `lowerbound` shifts
iterators towards the left, and `upperbound` shifts iterators to right.


- For `[L`, we want to shift beginning leftwards, so `lowerbound(L)`.
- For `(L`, we want to shift  beginning rightwards, so `upperbound(L)`.
- For `H]`,  we want to shift ending rightwards, so `upperbound(H)`.
- For `H)`,  we want to shift ending leftwards, so `lowerbound(H)`.

##### `equal_range`

- To unify the above description, one can simply use `std::equal_range(fst, last, val)` which
  returns the half-open interval `[l, r)` where the array has value `val`. This is equivalent to
  returning a pair of `lower_bound`, `upper_bound`.

# Books that impart mental models

I love books that impart menetal models of how a domain expert thinks about their field. This was
something I loved in particular about [TiHKAL](https://en.wikipedia.org/wiki/TiHKAL) which describes
reaction mechanisms. I'd love references to other books that do the same.


# Subarrays ~= prefixes

To solve any problem about subarrays, we can reinterpret a subarray `[l..r]` as a prefix `[0..r] - [0..l]`.
For example, to find all subarrays `[l..r]` whose sum of elements divides `n`, we can think of this
as finding a subarray `[l..r]` where the sum of elements modulo `n` is zero.
This is CSES' [subarray divisibiity](https://cses.fi/problemset/task/1662/) problem:

```cpp

int main() {
    int n;
    cin >> n;
    vector<ll> xs(n);
    for (int i = 0; i < n; ++i) {
        cin >> xs[i]; xs[i] = xs[i] % n; if (xs[i] < 0) { xs[i] += n; }
    }

    ll count = 0; // number of subarrays with sum = 0 (mod n)
    ll cursum = 0; //  current sum [0..i]
    // number of subarrays [0..r] (for some r) such that Σa[i] = count.
    map<ll, ll> partial_sum_count;
    partial_sum_count[0] = 1;

    for (int i = 0; i < n; ++i) {
        // current sum [0..i]
        cursum = (cursum + xs[i]) % n;

        // for each [0..j] (for j < i) with sum cursum, we want:
        // sum([i..j]) = 0
        // => sum([0..i]) - sum([0..j)) = 0
        // => sum([0..i]) = sum([0..j))
        // for each such `j`, we get one subarray.
        auto it = partial_sum_count.find(cursum);
        if (it != partial_sum_count.end()) {
            count += it->second;
        }

        // partial sum [0..i] = cursum
        partial_sum_count[cursum]++;
    }

    cout << count << "\n";

    return 0;
}
```

# Operations with modular fractions

- Quick note on why it's legal to perform regular arithmetic operations  on fractions $a/b$ as operations on $ab^{-1}$ where $ab^{-1} \in \mathbb Z/pZ$.
- The idea is that we wish to show that the map $a/b \mapsto ab^{-1}$ is a ring homomorphism $\phi: \mathbb Q \to \mathbb Z/p \mathbb Z$.
- The proof: (i) the map $Z \rightarrow Z/pZ$ is a ring homormophism, (ii)  map from an integral domain to a field always factors through the field of fractions of the domain, we
  get a map $\phi: \mathbb Q \rightarrow \mathbb Z/ p \mathbb Z$. So from abstract nonsense, we see that $\phi$ will be a well defined ring.hom.
- More down to earth: let's check addition multiplication, and multiplicative inverse. All else should work automagically.
- For addition, we wish to show that $\phi(a/b + c/d) = \phi(a/b) + \phi(c/d)$. Perform the calculation:

\begin{aligned}
&\phi(a/b + c/d) \\
&=\phi((ad + bc)/bd) \\
&= (ad + bc)(bd)^{-1}\\
&= abb^{-1}d^{-1} + bcb^{-1}d^{-1} \\
&= ad^{-1} + cd^{-1} \\
&= \phi{a/d} + \phi{c/d} \\
\end{aligned}

- For multiplication, we wish to show that $\phi(a/b \cdot c/d) = \phi(a/b) \cdot \phi(c/d)$:


\begin{aligned}
&\phi(a/b \cdot c/d) \\
&=\phi{ac/bd}
&= ac(bd)^{-1} \\
&= acd^{-1}b^{-1} \\
&= ab^{-1} \cdot cd^{-1} \\
&= \phi{a/b} \cdot \phi{c/d} \\
\end{aligned}

- For inverse, we wish to show that $\phi(1/(a/b)) = \phi(a/b)^{-1}$:

\begin{aligned}
&\phi(1/(a/b))
&=\phi{b/a}
&= ba^{-1}
&= (ab^{-1})^{-1}
&= \phi(a/b)^{-1}
\end{aligned}

Thus, we can simply represent terms $a/b$ in terms of $ab^{-1}$ and perform arithmetic as usual.


# Modular inverse calculation

- Easy way to calculate $a^{-1}$ mod $p$ is to use $a^{p-2}$. We know that $a^{p - 1} \equiv 1$ from Lagrane's theorem,
  so $a^{p-2} \cdot a \equiv 1$, or $a^{-1} \equiv a^{p-2}$. This can be done fairly quickly with repeated exponentiation.

- Another way to do this is to use extended eucliean division. Suppose $ a \not \equiv 0$ (mod p).
  Then we can find numbers $\alpha, \beta$ such that $a \alpha + p \beta = gcd(a, p) = 1$.
  If we look at the whole equation (mod $p$), we find that $a \alpha \equiv 1$ (mod $p$), or $\alpha$ is the modular
  inverse of $a$.

```cpp
pair<int, int> euc(int x, int y) {
  if (x < y) { return euc(y, x); }
  // x > y
  if (x % y == 0) { return {0, 1}; }
  int a, b; std::tie(a, b) = euc(y, x%y);
  // ay + b(x%y) = gcd(y, x%y) = gcd(x, y)
  // ay + b(x - y(x//y)) = gcd(y, x%y) = gcd(x, y)
  // ay + bx - by(x//y)  = gcd(y, x%y) = gcd(x, y)
  // (a - b(x//y))y + bx = gcd(y, x%y) = gcd(x, y)
  // bx + (a - b(x//y))y = gcd(y, x%y) = gcd(x, y)
  // intuition?
  return {b, a - b*(x/y)};
}
```


# The number of pairs `(a,b)` such that `ab≤x` is `O(xlogx)`

Fix a given `a`. `ab ≤ x` implies that `b ≤ x/a`, or there are only `x/a` possible values for `b`.
If we now consider all possible values for `a` from `1` upto `x`, we get:

$$
\begin{aligned}
|{ (a, b) : ab <= x }|
= \sum_{a=1}^x |{ b: b <= x/a }|
\leq \sum_{a=1}^x |x/a|
\leq x \sum_{a=1}^x (1/a)
\leq x \log x
\end{aligned}
$$

To show that the harmonic numbers are upper bounded by $\log$,
can integrate: $\sum_{i=1}^n 1/i \leq \int_0^n 1/i = \log n$

#### Relationship to Euler Mascheroni constant

This is the limit $\gamma \equiv \lim_{n \to \infty} H_n - \log n$. That this is a constant
tells us that these functions grow at the same rate. To see that this si indeed a constant,
consider the two functions:

- $f(n) \equiv H_n - \log n$ which starts at $f(1) = 1$ and strictly decreases.
- $g(n) \equiv H_n - \log(n+1)$ start lower at $g(1) 1 - \log 2$ and strictly increases. [why?]
- Also, $\lim_n f(n) - g(n) = 0$. So these sandwhich something in between, which is the constant $\gamma$.


# DP as path independence

- Dp is about forgetting the past / path independence. Doesn't matter how we got to a state, only what the state is.
  For example, to DP on subsequences, we don't care about how we got to a given subsequence. We only care about
  the final result that we computed for that subsequence. This lets us "extend" knowledge about a subsequence.
  So we go from `2^n` (subsets), to `2` followed by `2` followed by `2` followed by `2`, since at each stage,
  we forget how we got there and collate information.

- In this light, the recursive sub-computation is the "path dependent" part since it tries a path. The path independence
  states that it's safe to cache the results of the sub-computation, since all that matters is the final state (inputs).


# Binary search to find rightmost index which does not possess some property

```cpp
// p for predicate/property
// precondition: p(0) = false
// precondition: p(1 << NBITS) = last ix we process.
// precondition: p is monotonic;
//   once it switches to true, does not switch back to false.

if (p(1 << NBITS) == 0) { return 1 << NBITS; }
else {
  assert(p(1<<NBITS) == 1);
  int ans = 0;
  for (int i = NBITS-1; i >= 0; i--) {
    int k = 1 << i;
    assert(p(ans + 2*k) == 1);
    if (p(ans + k) == 0) {
      ans = ans + k;
    }
  }
}
// postcondition:
// ans is largest index such that
// has_some_poperty(ans) = 0
```

- **Claim 1: (Correctness)** `p(ans[i]) = 0`. By precondition, this is true before the loop.
  See that it's a loop invariant, as we only update `ans[i]` to `ans[i]+k` if `p(ans[i]+k) = 0`.
  Thus, is is true after the loop.


- **Claim 2: (Maximality)**: At loop iteration `i`: `p(ans[i] + 2k[i]) = 1`. We cannot improve our solution
  by using previous jump lengths.

This implies optimality once the loop ends. At the end of the loop we have `i = -1`.
So:

```
2k[-1] = 2(1/2) = 1
finalans = ans[-1]
---
p(ans[-1] + 2k[-1]) = 1
=> p(finalans+1) = 1
```

- Proof of Claim 2: induction on `i`
- Suppose claim 2 is true till index `i`: `p(ans[i] + 2k[i]) = 1`.
- To prove: induction hypothesis holds at index `(i-1)`.
- Case analysis based on loop body at `i`: `p(ans[i] + k[i]) = 0 or 1`
- (a) `p(ans[i] + k[i]) = 0`. We update  `ans[i-1] = ans[i] + k[i]`.
- We wish to show that the loop invariant holds at `i-1`: `p(ans[i-1]+2k[i-1]) == 1`.

$$
\begin{aligned}
&\text{k value: }  k[i] = 2^i \\
&\text{(k-1) value: }  k[i-1] = 2^{i-1} = 2k[i] \\
&\text{Ind: } p(ans[i] + 2k[i]) = 0 \\
&\text{Case (a): }  p(ans[i] + k[i]) = 0 \\
&\text{Update: } ans[i-1] \equiv ans[i] + k[i] \\
&p(ans[i-1] + 2k[i-1]) \\
&= p((ans[i] + k[i]) + 2k[i-1])  \\
&= p(ans[i] + k[i] + k[i])\\
&= p(ans[i] + 2k[i]) \\
&= 1 ~\text{(By Induction Hyp.)}
\end{aligned}
$$

- We've shown that the induction hypothesis hold at index $(i-1)$ in case (a) where we update the value of $ans[i]$.

- (b) If `p(ans[i] + k[i]) = 1`, then we update `ans[i-1] = ans[i]`.
- We wish to show that the loop invariant holds at `i-1`: `p(ans[i-1]+2k[i-1]) ==1`.

$$
\begin{aligned}
&\text{k value: }  k[i] = 2^i \\
&\text{(k-1) value: }  k[i-1] = 2^{i-1} = 2k[i] \\
&\text{Ind: } p(ans[i] + 2k[i]) = 0 \\
&\text{Case (b): }  p(ans[i] + k[i]) = 1 \\
&\text{Update: } ans[i-1] \equiv ans[i] \\
&p(ans[i-1] + 2k[i-1]) \\
&= p(ans[i] + 2k[i-1])  \\
&= p(ans[i] + k[i] + k[i])\\
&= p(ans[i] + 2k[i]) \\
&= 1 ~\text{(By Induction Hyp.)}
\end{aligned}
$$

- We've shown that the induction hypothesis hold at index $(i-1)$ in case (b) where we don't change the value of $ans[i]$.

- In summary, the loop invariant is held at index $(i-1)$ assuming the loop invariant is satisfied at index $(i)$,
  for both updates of $ans[i]$.  Thus, by induction, the loop invariant holds for all iterations.

- **Elaborated proof of why `p(ans[0]+1) = 1` at the end of the loop**

See that we can insert a new invaraiant at the end of the loop which asserts  `p(ans[i]+k[i]) == 1`:

```cpp
if (p(1 << nbits) == 0) { return 1 << nbits; }
else {
  assert(p(1<<nbits) == 1);
  int ans = 0;
  for (int i = nbits-1; i >= 0; i--) {
    int k = 1 << i;
    assert(p(ans + 2*k) == 1);
    int ans2;
    if (p(ans + k) == 0) {
      ans2 = ans + k;
      // ans2 + k
      // = (ans + k) + k
      // = ans + 2k
      // = 1 (from assertion)
    } else {
       ans2 = ans;
      // ans2 + k
      // = ans + k
      // = 1 [from else branch]
    }
    // ## new loop end invariant ##
    // true from then, else branch.
    assert(p(ans2+k) == 1)
    ans = ans2;
  }
}
```

- We've proven the correctness of the loop invariant at the *end* of the loop, given the prior loop invariant at the *beginning*
  of the loop.
- So, At the end of the `(i=0)` iteration, we have `k=1`, and so `p(ans+1) == 1`, which is the "rightmost index" condition.
  that we originally wanted.

#### Fully elaborated proof

```cpp
if (p(1 << nbits) == 0) { return 1 << nbits; }
else {
  assert(p(1<<nbits) == 1);
  int ans = 0;
  // p(ans[nbits-1] + 2*(1<<nbits-1))
  // = p(0 + 1 << nbits)
  // = p(1 << nbits)
  // = 1 [from assert]
  for (int i = nbits-1; i >= 0; i--) {
    int k = 1 << i;
    // From previous loop iteratio (i+1):
    // ---------------------------------
    // p(ans[(i+1)-1] + k[i+1]) == true
    // => p(ans[i] + k[i+1]) == true
    // => p(ans[i] + 2k[i]) == true
    assert(p(ans + 2*k) == true);

    if (p(ans + k) == 0) {
      ans += ans + k;
      // ASSIGNMENT: ans[i-1] = ans[i] + k[i]
      // p(ans[i-1] + k[i])
      // = p(ans[i] + k[i] + k[i])
      // = p(ans[i] + 2k[i])
      // = p(ans[i] + k[i+1])
      // = 1 (from induction hyp)
    } else {
       ans = ans; // no-op
       // ASSIGNMENT: ans[i-1] = ans[i].
       // p(ans[i-1] + k[i])
       // = p(ans[i] + k[i])
       // = 1 (from else branch)
    }
    // ## new loop end invariant ##
    // p(ans[i-1] + k[i])== 1
    assert(p(ans+k) == 1)
  }
}
```


#### Simplified implementation

If we are willing to suffer some performance impact, we can change the loop
to become significantly easier to prove:

```cpp
if (p(1 << nbits) == 0) { return 1 << nbits; }
else {
  assert(p(1<<nbits) == 1);
  int ans = 0;
  int i = nbits-1;
  while(i >= 0) {
    assert (p(ans+2*k) == 1);
    int k = 1 << i;
    if (p(ans + k) == 0) {
      ans += ans + k;
    } else {
        i--;
    }
    assert(p(ans) == 0)
  }
}
```

In this version of the loop, we only decrement `i` when we are sure that `p(ans+k) == 0`.
We don't need to *prove* that decrementing `i` monotonically per loop trip maintains
the invariant; Rather, we can try "as many `i`s as necessary" and then decrement `i`
once it turns out to not be useful.

#### Relationship to LCA / binary lifting

This is very similar to LCA, where we find the lowest node that is *not* an ancestor. The ancestor
of such a node *must be* the ancestor.

```cpp
int lca(int u, int v) {
    if (is_ancestor(u, v)) return u;
    if (is_ancestor(v, u)) return v;

    // u is not an ancestor of v.
    // find lowest parent of u that is not an ancestor of v.
    for (int i = l; i >= 0; --i) {
        if (!is_ancestor(up[u][i], v))
            u = up[u][i];
    }
    return up[u][0];
}
```


# Correctness of `lower_bound` search with half-open intervals


```cpp
// precondition: `xs` is sorted.
// find rightmost i such that xs[i] <= y and dp[i+1] > y.
int tallest(vector<long> &xs, int y) {
    // [l, r)
    int l = 0, r = dp.size();
    // precondition: l < r
    while(1) {
        if (l + 1 == r) { return l; }
        // info gained from if: r > (l+1)
        int m = (l+r)/2;
        // should this be (xs[m] > y) or (xs[m] >= y)?
        if (xs[m] > y) {
            r = m; // will decrease interval floor division.
        } else {
            // r > (l+1)
            // so m := (l+r/2) > (2l+1)/2 > l.
            l = m;
        }
    }
}
```

- Firt see that if we can find such an `i`, then in the extreme case where the array does not have a
  greater element, we would like the find the *rightmost* `i` that fulfils the condition that `xs[i] <= y`.
  So in our imagination, we right pad the array with an infinitely large value.
- We wish to know whether the `if` condition should have `xs[m] > y` or `xs[m] >= y` before it decides to shrink the search range.
- Intuitively, we wish to move the search range rightwards. So if we have `xs[m] == y`, we must move `l` towards `m` to move the search range rightwards.
  For more clarity, let's write the above as:


```cpp
// precondition: `xs` is sorted.
// find i such that xs[i] <= y and dp[i+1] > y.
int tallest(vector<long> &xs, int y) {
    // [l, r)
    int l = 0, r = dp.size();
    // precondition: l < r
    while(1) {
        if (l + 1 == r) { return l; }
        // info gained from if: r > (l+1)
        int m = (l+r)/2;
        // should this be (xs[m] > y) or (xs[m] >= y)?
        if (xs[m] > y) {
            // move interval towards `l` for smaller values.
            r = m; // will decrease interval floor division.
        } else if (xs[m] < y) {
            // move interval towards `r` for larger values.
            // r > (l+1)
            // so m := (l+r/2) > (2l+1)/2 > l.
            l = m;
        } else {
            //xs[m] == y
            // we want rightmost index `l` where `xs[l] <= y`.
            // - this `xs[m]` is a legal index.
            // - we want rightmost `m`. Since `m > l`, move `l` rightward by setting `l = m`.
            l = m;
        }
    }
}
```

# Greedy Coin change: proof by probing

#### Probing the coin set `{1, 5, 10, 20, 100}`

- Let `O*` be optimal solution for this coin set. I'll write `copies x [coinval$]` notationally.
- `O*` will convert `5x[1$] → 1x[5$]` , because it's better to use less coins.
- `O*` will convert `2x[5$] → 1x[10$]`
- `O*` will convert `2x[10$] → 1x[20$]`
- `O*` will convert `5x[20$] → 1x[100$]`
- So we summarize: `O*` can have at most: `4x[1$]`, `1x[5$]`, `1x[10$]`, `4x[20$]`.
  If it has more than these, it can convert to one copy of a larger coin, losing optimality.

#### Optimal takes as many `100$` as greedy.


- Recall: `G` (the greedy solution) takes as many `100, 10, 5, 1` as possible, starting from `100`, working its way down to `1`.
- Let `G[100$]` be the number of copies of the `100$` coin the greedy solution uses to represent `n`.
- Claim: `O[100$] >= G[100$]`. Since `O` is optimal, it won't take *more* than greedy since that's wasteful, so as a Corollary `O[100$] = G[100$]`.
- Suppose for contradiction that `O[100$] < G[100$]`. Then there is a `100$` to be made up by `O`, which `G` fulfils by using a `[100$]` coin.
- We know by probing that if we stick to coins less than `[100$]`, `O` can have at most `4x[20$] + 1x[10$] + 1x[5$] + 4x[1$]` coins.
- See that we can't add any more of `[1$], [5$], [10$], [20$]`. For example, suppose we try and use another `[1$]` coin. This means we have
  `4x[20$] + 1x[10$] + 1x[5$] + 5x[1$]`. From probing, we know we should change `5x[1$] → 1x[5$]`. This changes the sum to
  `4x[20$] + 1x[10$] + 2x[5$]`. From probing, we know `2x[5$] → 1x[10$]`. The sum becomes `4x[20$] + 2x[10$]`. Again from probing,
  we know to be optimal and use less coins, we should change `2x[10$] → 1x[20$]`. This makes the sum `5x[20$]`.
  This too should be changed to `1x[100$]`, a fact we learnt from probing.
  But this contradicts the assumption that we want to use only coins smaller than `[100$]`.
  So if we are using coins smaller than `[100$]`, the maximum value we can represent is given by
 `4x[20$] + 1x[10$] + 1x[5$] + 4x[1$]` .
- The maximum value `4x[20$] + 1x[10$] + 1x[5$] + 4x[1$]`  adds up to `99$`, which is one shy of `100$`. So, it is impossible for us to represent a value of a 100 dollars
  using coins of value less than `[100$]` **in an optimal fashion**. Thus, `O[100$] = G[100$]`, as it is best to take as many coins as possible.
- Repeat the argument for smaller denominations.



# Clean way to write burnside lemma

Burnside lemma says that $|Orb(G)| \equiv 1/|G| \sum_{g \in G} fix(g)$. We prove this
as follows:

$$
\begin{aligned}
&\sum_{g \in G} fix(g) \\
&= \sum_{g \in G} |\{x : g(x) = x \}| \\
&= |\{(g, x) : g(x) = x \}| \\
&= \sum_{x \in X}|\{x : g(x) = x \}| \\
&= \sum_{x \in X} Stab(x)
\end{aligned}
$$

- From orbit stabilizer, we know that $|Orb(x)||Stab(x)| = |G|$.
- Since $|Orb(x)$ is the total cardinality of the orbit, each element in the orbit contributes $1/|Orb(x)|$ towards cardinality of the full orbit.
- Thus, the sum over an orbit $\sum_{x \in Orb(x)} 1/|Orb(x)|$ will be 1.
- Suppose a group action has two orbits, $O_1$ and $O_2$. I can write the sum $\sum_{x \in g} 1/|Orb(x)|$ as:
  $\sum_{x \in O_1} 1/|O_1| + \sum_{x \in O_2} 1/|O_2|$, which is equal to 2.
- I can equally write the sum as $\sum_{o \in Orbits} \sum_{x \in o} 1/|o|$. But this sum is equal to $\sum_{o \in Orbits} \sum_{x \in o} 1/|Orb(x)|$.
- This sum sums over the entire group, so it can be written as $\sum_{x \in G} 1/|Orb(x)|$.
- In general, the sum over the entire group $\sum_{x \in g} 1/|Orb(x)|$ will be the number of orbits, since the same argument holds _for each orbit_.


$$
\begin{aligned}
&= \sum_{x \in X} Stab(x) \\
&=  \sum_{x \in X}  |G|/|Orb(x)| \\
&=  |G| \sum_{o \in orbits} \sum_{x \in o} 1/|o| \\
&=  |G| \texttt{num.orbits} \\
\end{aligned}
$$

So we have derived:

$$
\begin{aligned}
&\sum_{g \in G} fix(g) = |G| \texttt{num.orbits} \\
&1/|G| (\sum_{g \in G} fix(g)) = \texttt{num.orbits} \\
\end{aligned}
$$

> If we have a transformation that fixes many things, ie, $fix(g)$ is large,
> then this $g$ is not helping "fuse" orbits of $x$ together, so the number of
> orbits will increase.

- [Reference](https://math.mit.edu/~apost/courses/18.204_2018/Jenny_Jin_paper.pdf)


# The groupoid interpretation of type theory

The monograph by  Martin Hofmann and Thomas Streicher is remarkably lucid. It
opens by stating that UIP (uniqueness of identity proofs) is false by providing
a model for the axioms of MLTT where UIP fails --- a groupoid!

# Mnemonics for free = left adjoint

> To free is a very liberal thought. Very left

> Left and free have the same number of letters (4)



# Where to scratch a cat

Scratch the sides of their rear legs - that's where they can't scratch themselves.
Found this useful to know, since we've recently adopted a stray.


# Mnemonic for Specht module actions

Consider the two extreme cases, of wide v/s narrow:
```
x = [* * *]
y = [#]
    [#]
    [#]
```


- Consider `x = [* * *]`. It's very wide/fat, so it doesn't like much exercise, which
  is why it's columns stabilizer $C_x =\{ e\}$ is trivial. Thus, the action $A_x \equiv id$.

- Consider `y = [*][*][*]`. It's very slim, and exercises quite a bit. So it's column stabilizer is $S_3$,
  and its action $A_y \equiv \dots$ has a lot of exercise.

- Anyone can participate in $x$'s exercise regime. In particular, $A_x(y) = id(y) = y$ since $y$ doesn't tire out from the exercise regime of $x$.
- On the other side, it's hard to take part in $y$'s exercise regime and not get TODOed out. If we consider $A_y(x)$, we're going to get zero
  because by tableaux, there are swaps in $A_y$ that leave $x$ invariant, which causes sign cancellations. But intuitively, $A_y(x)$ is asking $x$
  to participate in $y$'s exercise regmine, which it's not strong enough to do, and so it dies.

- In general, if $\lambda \triangleright \mu$, then $\lambda$ is wider/fatter than $\mu$. Thus we will have $A_\mu(\lambda) = 0$ since $A_\mu$ is a harder
  exercise regime that has more permutations.

- Extend this to arrive at specht module morphism: If we have a non-zero morphism $\phi: S^\lambda \rightarrow S^\mu$ then $\lambda \rightarrow \mu$ [Check this?? Unsure]

# Quotes from 'Braiding Sweetgrass'

> Listening in wild places, we are audience to conversations in a language not
> our own


> Puhpowee,  she explained, translates as “the force which causes mushrooms to
> push up from the earth overnight.” As a biologist, I was stunned that such a
> word existed. In all its technical vocabulary, Western science has no such
> term, no words to hold this mystery. You’d think that biologists, of all
> people, would have words for life. But in scientific language our terminology
> is used to define the boundaries of our knowing. What lies beyond our grasp
> remains unnamed.

> Only 30 percent of English words are verbs, but in Potawatomi that proportion
> is 70 percent. Which means that 70 percent of the words have to be
> conjugated, and 70 percent have different tenses and cases to be mastered..

> Our toddlers speak of plants and animals as if they were people, extending to
> them self and intention and compassion—until we teach them not to. We quickly
> retrain them and make them forget. When we tell them that the tree is not a
> who,  but an  it,  we make that maple an object;

> We don’t know their names or their faces, but our fingers rest right where
> theirs had been and we know what they too were doing one morning in April
> long ago. And we know what they had on their pancakes. Our stories are linked
> in this run of sap; our trees knew them as they know us today..

> I realize that those first homesteaders were not the beneficiaries of that
> shade, at least not as a young couple. They must have meant for their people
> to stay here. Surely those two were sleeping up on Cemetery Road long before
> the shade arched across the road. I am living today in the shady future they
> imagined, drinking sap from trees planted with their wedding vows. They could
> not have imagined me, many generations later, and yet I live in the gift of
> their care. Could they have imagined that when my daughter Linden was
> married, she would choose leaves of maple sugar for the wedding giveaway?

> You should not be able to walk on a pond. It should be an invitation to
> wildlife, not a snare. The likelihood of making the pond swimmable, even for
> geese, seemed remote at best. But I am an ecologist, so I was confident that
> I could at least improve the situation. The word  ecology  is derived from
> the Greek  oikos,  the word for home. I could use ecology to make a good home
> for goslings and girls.


> Our appetite for their fruits leads us to till, prune, irrigate, fertilize,
> and weed on their behalf. Perhaps they have domesticated us. Wild plants have
> changed to stand in well-behaved rows and wild humans have changed to settle
> alongside the fields and care for the plants—a kind of mutual taming.

> In that awareness, looking over the objects on my desk—the basket, the
> candle, the paper—I delight in following their origins back to the ground. I
> twirl a pencil—a magic wand lathed from incense cedar— between my fingers.
> The willow bark in the aspirin. Even the metal of my lamp asks me to consider
> its roots in the strata of the earth.


> I smile when I hear my colleagues say “I discovered X.” That’s kind of like
> Columbus claiming to have discovered America. It was here all along, it’s
> just that he didn’t know it. Experiments are not about discovery but about
> listening and translating the knowledge of other beings.


> It seems counterintuitive, but when a herd of buffalo grazes down a sward of
> fresh grass, it actually grows faster in response. This helps the plant
> recover, but also invites the buffalo back for dinner later in the season.
> It’s even been discovered that there is an enzyme in the saliva of grazing
> buffalo that actually stimulates grass growth. To say nothing of the
> fertilizer produced by a passing herd. Grass gives to buffalo and buffalo
> give to grass.




# Transfinite recursion: Proof
- Let $(J, <)$ be a well-ordered set.
- Denote by $[0, \alpha)$ the set $\{ j \in J : j < \alpha \}$ as suggestive notation. Similarly $[0, \alpha]$ is the set $\{ j \in J: j \leq \alpha \}$.
- Let $r: (\forall \alpha \in J, [0, \alpha) \rightarrow O) \rightarrow O$ be a recursion formula, which
  when given a function $f: [0, \alpha) \rightarrow O$ which is well defined on $J$ upto $\alpha$, produce a value $r(\alpha) \in O$
  that extends $f$ to be well defined at $\alpha$.
- We wish to find a function $f(j)$ such that for all $j \in J$, $f(j) = r([0, j))$. So this function $f$ is deterined
  by the recursion principle $r$. We construct such a function by transfinite induction.
- Let $J_0 \subseteq J$ be the set of $j \in J$ such that there exists a function $f_j: [0, j] \rightarrow O$  (see the closed interval!),
  which obeys the recursion formula upto $j$. That is, for all other $k \leq j$, we have that $f_j(k) = r(f_j|[0, k))$. Choose $k \leq j$ so that we check that
  $f_j(j) = r(f_j|[0, j))$.
- Claim: the set $J_0$ is inductive.
- Let $[0, j) \subseteq J_0$. Thus, for all $k < j$, there is a function $f_k: [0, k] \rightarrow O$ such that $f_k(l) = r(f_k|[0, l))$.
- We must show that $j \in J_0$. So we must construct a function $f_j: [0, j] \rightarrow O$ such that ... (reader: fill in the blanks).
- Handwavy: note that the set of functions $\{ f_k : k \in [0, j) \}$ all agree on their outputs since their outputs are determined by the recursion formula
  (Foraal: we can first prove that any function that satisfies the recursion scheme is uniquely defined).
- Thus, we can build the function $g_j: [0, j) \rightarrow O$ given by $g_j \equiv \cup_{k \in [0, j)} f_j$. That is, we literally take the "set union" of the functions
  as ordered pairs, as the functions are all compatible. This gives us a function defined upto $j$.
- The value of $f_j$ at $j$ must be $r(g_j)$. So we finally define $f_j \equiv g_j \cup \{ (j, r(g_j) \}$. This is a uniquely defined function as $r$ is a function:
  $r: [0, j) \rightarrow O$  thus produces a unique output for a unique input $g(j)$.
- We have a function $f_j$ that obeys the recursion schema: (1) at $j$, it is defined to obey the recursion schema; At $k < j$, it is written as union of prior $f_k$ which
  obey recursion schema by transfinite induction hypothesis.
- Thus, we have $j \in J_0$, witnessed by $f_j$.
- We have fulfilled the induction hypothesis. So $J_0 = J$, and we have a set of function $\{ f_j : j \in J \}$, all of which are compatible with each other and obey the recursion
  schema. We take their unions and define $f \equiv \cup_j f_j$ and we are done!

# Transfinite induction: Proof

- Let $(J, <)$ be a well-ordered set.
- Let $S(\alpha) \equiv J < \alpha$, or $S(\alpha) \equiv \{ j \in J: j < \alpha \}$.  This is called as the section of $J$ by $\alpha$.
- Let a $J_0 \subseteq J$ be *inductive* iff for all $\alpha \in J$, $S(\alpha) \subseteq J_0$ implies $\alpha \in J_0$. That is:

$$
\text{$J_0$ inductive} \equiv \forall \alpha \in J, S(\alpha) \subseteq J_0 \implies \alpha \in J_0
$$

- Then transfinite induction states that for any inductive set $J_0 \subseteq J$, we have $J_0 = J$.

- Proof by contradiction. Suppose that $J_0$ is an inductive set such that $J_0 \neq J$.
- Let $W$ (for wrong) be the set $J_0 - J$. That is, $W$ is elements that are not in $J_0$.
- $W$ is non-empty since $J_0 \neq J$. Thus, consider $w \equiv \min(W)$, which is possible since $J$ is well-ordered, thus the subset $W$ has a minimum element.
- $w$ is the smallest element that is not in $J_0$. So all elements smaller than $w$ are in $J_0$. This, $S(w) \subseteq J_0$. This implies $w \in J_0$ as $J_0$ is inductive.
- This is contradiction, as we start with $w$ is the smallest element not in $J_0$, and then concluded that $w$ is in $J_0$.
- Thus, the set $W \equiv J_0 - J$ must be empty, or $J_0 = J$.

# Thoughts on playing Em-Bm

I'm having some trouble playing Eminor followed by Bminor in quick succession.
The problem was a type of analysis-paralysis, where I wasn't sure in what order I should
barre the chord, and then place my other fingers.  I'm trying to change my
mental mode, where I keep in mind a "root finger", which for Bminor is the middle finger
which I first place on the correct string , and then place all other fingers in relation
to it. This seems to help, since the task becomes (a) place root finger (b) naturally place
other fingers after it.

# An explanation for why permutations and linear orders are not naturally isomorphic

the number of linear orders on a finite set is the same as the number of
bijections: the factorial of the cardinality.  Every linear order on a set is
isomorphic to any other, but a bijection is only isomorphic to another which
has the same size and number of cycles. Thus, we have two functors $Perm: Set \rightarrow Set$
which sends a set to its set of permutations, and $Ord: Set \rightarrow Set$
which sends a set to its set of linear orders, such that the
functors are equal on all objects (upto set isomorphism --- ie, produce outputs
of the same size) but the functors fail to be isomorphic, since they have
different criteria for "being equal".


# We can't define choice for finite sets in Haskell!

> If all you have is a decidable equality relation on the elements, then
> there seems to be no function which can implement choice. That is, you can’t
> write a function `choose :: Set a ->  Maybe (a, Set a)`


> Concretely, suppose we represent sets as lists of nonrepeated elements. Then,
> we can write an operation `choose :: Set a -> Maybe (a, Set a)`, which just
> returns a pair of the head and the tail if the list is nonempty, and returns
> Nothing if it is empty.


> However, this operation does not respect equality on sets. Note that any
> permutation of a list representing a given set also represents that same set,
> but the choose operation returns different answers for different permutations.
> As a result, this operation is not a function, since it does not behave
> extensionally on finite sets!


> I feel there should be an argument involving parametricity which makes this
> work for arbitrary datatype representations, since all we rely on is the fact
> that equality can’t distinguish permutations. But I haven’t found it yet.

- [nLab link](https://golem.ph.utexas.edu/category/2012/10/the_curious_dependence_of_set.html#c042358)



# Geomean is scale independent

`sqrt(ab)` is dimensionally meaningful even if `a` and `b` are dimensionally different. I found
this interesting, since it implies that Geomean is not "biased": arithmetic mean is more sensitive to large values (eg: `(1 + 999)/2 = 500`),
while harmonic mean is more sensitive to small values. Geomean is neither, so it's more "balanced".

# Thoughts on playing Em Bm.


# Induction on natural numbers cannot be derived from other axioms

The idea is to consider a model of the naturals that obeys all axioms other than induction,
and to then show how this model fails to be a model of induction. Thus, induction
does not follow from the peano aximos minus the induction axiom. We build a model of naturals as $M \equiv \mathbb N \cup \{ * \}$
where we define the successor on $M$ as
$succ(n \in \mathbb N) = n + 1$ and $succ(*) = *$. Now let's try to prove $P(m) \equiv succ(m) \neq m$ for all $m \in M$.
$P(0)$ holds as $succ(0) = 1 \neq 0$. It is also true that if $P(m)$, then $P(m+1)$. However,
it is NOT true that $\forall m \in M, P(m)$ since it does not hold for $* \in M$. So we really do need
induction as an axiom to rule out other things.

# Ordinals and cardinals


This a rough sketch of a part of set theory I know very little about, which I'm encountering as I solve
the "supplementary exercises" in Munkres, chapter 1.

#### Ordinals

- Two totally ordered sets have the same order type if there is a monotone isomorphism between them.
  That is, there's a function $f$ which is monotone, and has an inverse. The inverse is guaranteed
  to be motone (1), so we do not need to stipulate a _monotone_ inverse.
- Definition of **well ordered set**: totally ordered set where every subset has a least element.
- Theorem: The set of **well ordered sets** is itself well ordered.
- Definition **ordinals**: Consider equivalence classes of well ordered sets under order type.
  of well ordered sets with the same order type. The equivalence classes are **ordinals**.

##### (1) Inverse of a Monotone function is monotone.

- Let $f: A \rightarrow B$ be monotone: $a < a'$ implies $f(a) < f(a')$. Furthermore,
  there is a function $g: B \rightarrow A$ such that $g(f(a)) = a$ and $f(g(b)) = b$.
- Claim: if $b < b'$ then $g(b) < g(b')$.
- Let $b < b'$. We must have (a)  $g(b) < g(b')$, or (b) $g(b) = g(b')$, or (c) $g(b) > g(b')$.
- If $g(b) < g(b')$ we are done.
- Suppose for contradiction $g(b) \geq g(b')$ then we must have $f(g(b)) \geq f(g(b'))$ since $f$ is monotone. Since $f, g$ are inverses
  we get $b \geq b'$. This contradicts the assumption $b < b'$.
- This doesn't work for partial orders because we may get $b$ and $b'$ as _incomparable_.


#### Von Neumann Ordinals

- **Von neumann ordinals:** Representatives of equivalence classes of ordinals.
  Formally, each Von-Neumann ordinal is the well-ordered set of all smaller ordinals.
- Formal defn of  Von-Neumann ordinal $o$: (1) every element $x \in o$ will be a subset of $o$, since $x$
  is itself a set `{ ordinal < x }`, which is a subset of `{ ordinal < o }`. (2) the set $o$
  is well ordered by set membership, since two such ordinals will always be comparable, and one must
  contain the other.
- For example of Von Neumann ordinals, consider `0 = {}`, `1 = {0}`, `2 = {0, 1}`, `3 = {0, 1, 2}`.
  We can order `3` based on membership: `0 ∈ 1, 2` so `0 < 1, 2`. `1 ∈ 2` hence `1 < 2`. This totally orders `3`
  based on set membership. Next, also see that a **member** of `3`, such as `2`, is in face `2 = {0, 1}`, which is a subset of `3`.
  So every member of `3` is a subset of `3`. (Not vice versa: not every subset is a member! The subset `{1, 2}` is not a member of `3`).

#### Limit ordinals

- A **limit ordinal** is an ordinal that cannot be written as the successor of some other ordinal.
- **Theorem**: An ordinal must be either zero, or the successor of some other ordinal, or a limit ordinal (2)
- [References on ordinals](http://www-users.math.umn.edu/~garrett/m/algebra/notes/14.pdf)

#### Cardinality and cardinals
- We can define cardinality as equivalence classes of sets that are
  **equinumerous**: ie, sets with bijections between them.  This does not strictly speaking work
  due to set-theoretic issues, but let's go with it.
- In each such equivalence class of sets which are equinumerous, there will be many well ordered sets.
  The smallest such well ordered set (recall that the set of well ordered sets is itself totally ordered).
  This is called as the **cardinal** for that cardinality.
- So we redefine cardinality as the smallet ordinal $\alpha$ such that there is
  a bijection between $X$ and $\alpha$.
  This is motivated from the "equivalence class of all equinumerous sets", but
  sidesteps set theoretic issues. For this to work, we need well ordering. Otherwise,
  there could a set with no ordering that is in bijection with it.

#### Definition of Cardinal
- Said differently, an ordinal is a cardinal if it cannot be put in bijection with any smaller ordinal.
- Thus, all natural numbers are cardinals, $\omega$ is a cardinal, $\omega + 1$ is NOT a cardinal (can be put in bijection with $\omega$),
- We can think of $\aleph_0$ as a **countably infinite** queue where each person in the queue has to wait for **finitely** many people to exit.
- We can think of $\aleph_1$ as a **uncountably infinite** queue where each person in the queue has to wait for **countably** many people to exit.



#### Rank
- The **rank** of the empty set is zero. The rank of a set is recursively the smallest ordinal greater
  than the ranks of all the members of the set. Every ordinal has a rank equal to itself.
- $V_0$ is the empty set.
- $V_{n+1} \equiv 2^{V_n}$. This defines $V$ for successor ordinals.
- $V_\lambda \equiv \cup_{\beta < \lambda} V_\beta$. This defines $V$ for limit ordinals.
- The set $V_\alpha$ are also callled stages or ranks. We can define the rank of a set $S$ to be the smallest $\alpha$
  such that $S \subseteq V_\alpha$.


#### Inaccessible cardinal

A cardinal that cannot be created by adding cardinals, taking unions of cardinals, taking power sets
of cardinals. So the set of cardinals smaller than an inacessible cardinal give a model for ZFC.
if $\kappa$ is an inaccessible cardinal, then $V_\kappa$, collection of all sets of rank less than $\kappa$
acts as a place to do mathematics safely, while still having access to the "set of all sets" $V_\kappa$
(Grothendeick universes, apparently).



#### Alternative definition of cardinality using rank

- Recall that we wanted to define cardinality as the equivalence class of
  of equinumerous sets, but this ran into set theoretic issues.
- A fix [(by Dana Scott)](https://en.wikipedia.org/wiki/Scott%27s_trick) is for a set $A$, consider the least rank $\kappa$
  where some set in bijection with $A$ appears. Then we define the cardinality
  of $A$ to be the equivalence classes of sets in $V_\kappa$ that are in
  bijection with $A$. This gives us the cardinals without needing us to
  consider all sets. This works even without well ordering.
- I don't actually understand why this works. In my mind, the set `{0}` and `{{0}}` both have the same size, but `{0}` lives in `V1` while `{{0}}`
  lives in `V2`, so they won't have the same cardinality? Actually, I think I do understand: for the set `{{0}}`, the set `{0}` which is in bijection
  with `{{0}}` occurs at rank `1`, so the cardinality of `{{0}}` is given by the equivalence class in `V1`: `[{0}]`.
- The key part seems to be "find the **smallest** rank". I have no idea how one would formalize this.


#### Weak and strong limits

- A set $S$ is a strong limit if it cannot be obtained by taking powersets of sets smaller than it.
- In set theory, we as a rule of thumb replace powerset with successor to get some weaker statement.
- A set $S$ is a weak limit if it cannot be obtained by taking successor of sets smaller than it.



#### References
- [Large Sets 3](https://golem.ph.utexas.edu/category/2021/06/large_sets_3.html)

# Musing about Specht modules

If we generalize, to each point $x$, we are creating a group of orthogonal
matrices $O_x$ (like $C_t$), such that
- All points in the orbit have (the same/similar, unsure?) $C_t$
- For points outside the orbit, we evaluate to zero.

At least in dim=2, we can't take rotations (of finite order) as elements of $O_x$. These behave
like nth roots of unity on averaging, so we get $1 + \omega + \omega^2 + \dots + \omega^{n-1} = 0$,
leading to not giving any new points in $O_x$.

- The only way to get new points in dim=2 is by taking reflections. So, for example:

```
  y
  |
p | q
  |
```

- reflection of `p` about the `y` axis gives us `q`. So if we set $O_p = \{I, Y\}$, we get $O_p(p) = I - Y$.
- We need $O_p(q) = sgn(Y)O_p(p)$, which does indeed happen, as $O_p(p) = p - q$, with $O_p(q) = q - p = - (p-q)$.
- Let's add more points:

```
  y
  |
p | q
c | d
```

- The problem with the new points $c, d$ is that they are not in the orbit $O_p(p)$, but they also don't evaluate to zero!
- This tells us that after we pick the points $p, q$, any new points we pick *must lie on the axis of reflection* to be annhilated.
- Thus, one valid way of adding new points is:


```
  y
  |
  c
p | q
--+-----x
  |
  d
  |
```

- Here, $c, d$ have as group $O_c = O_d = \{I, X\}$, reflection about the $X$ axis. Check that all the axioms are satisfied: elements
  in the orbits $O_c, O_d, O_p, O_q$ evaluate to $\pm A_c c, \pm A_p p$. While elements not the orbit become zero.
- Thus, it seems like the Specht module attempts to construct "reflections" that somehow represent $S_n$. Is this why it is related
  to Coxeter theory?

- [What is a Coxeter diagram good for](https://math.stackexchange.com/questions/735679/what-is-the-coxeter-diagram-for)
- [What is a Coxeter group](https://math.stackexchange.com/questions/2895896/what-is-a-coxeter-group)


# Every continuous function on $[a, b]$ attains a maximum

The high-level machinery proof:
1. Continuous image of a compact set `[a, b]` under function $f$ is a compact set `f([a, b])` (1).
2. Compact set in $\mathbb R$ is closed (2) (Heine Borel).
3. $sup(f[a, b])$ is a limit point of $f([a, b])$. (4: `sup` is a limit point).
4. Thus $f([a, b])$ (closed) contains $sup(f([a, b])$ (limit point) (5: closed set contains all limit points).
5. Thus $f$ attains maxima $sup(f([a, b]))$ on $[a, b]$.


##### (1) Continuous image of compact set is compact

- Let $f: A \rightarrow B$ be a continuous function. Let $C \subseteq A$ be a compact set.
- Need to show $f(C)$ is compact.
- Take any open cover $\{ V_i \}$ of $f(C)$. Need finite subcover.
- Pullback $V_i$:  Let $U_i \equiv f^{-1}(V_i)$.  Each $U_i$ open as $f$ is continuous. $\{ U_i = f^{-1}(V_i) \}$ cover  $C$ since $\{ V_i \}$ cover $f(C)$.
- Extract finite subcover $\{ U_j : j \in J \}$ for finite set $J$.
- Push forward finite subcover: $\{ V_j : j \in J \}$ cover $f(C)$ as $U_j$ cover $C$.


# Invisible cities

> The city does not consist of this, but of relationships between the
> measurements of its space and the events of its past: the height of a lamppost
> and the distance from the ground of a hanged usurper’s swaying feet

> Perinthia’s astronomers are faced with a difficult choice. Either they must
> admit that all their calculations were wrong and their figures are unable to
> describe the heavens, or else they must reveal that the order of the gods is
> reflected exactly in the city of monsters.

> ... seek and learn to recognize who and what, in the midst of the inferno,
> are not inferno, then make them endure, give them space.



> Bear with me,’ that man answered. ‘I am a wandering herdsman. Sometimes my
> goats and I have to pass through cities; but we are unable to distinguish them.
> Ask me the names of the grazing lands: I know them all, the Meadow between the
> Cliffs, the Green Slope, the Shadowed Grass. Cities have no name for me: they
> are places without leaves, separating one pasture from another, and where the
> goats are frightened at street corners and scatter. The dog and I run to keep
> the flock together.’




> description of Zaira as it is today should contain all Zaira’s past. The city,
> however, does not tell its past, but contains it like the lines of a hand,
> written in the corners of the streets, the gratings of the windows, the
> banisters of the steps, the antennae of the lightning rods, the poles of the
> flags, every segment marked in turn with scratches, indentations, scrolls.



> The city’s gods, according to some people, live in the depths, in the black
> lake that feeds the underground streams. According to others, the gods live in
> the buckets that rise, suspended from a cable, as they appear over the edge of
> the wells, in the revolving pulleys, in the windlasses of the norias, in the
> pump handles, in the blades of the windmills that draw the water up from the
> drillings, in the trestles that support the twisting probes, in the reservoirs
> perched on stilts over the roofs, in the slender arches of the aqueducts, in
> all the columns of water, the vertical pipes, the plungers, the drains,

> the emperor is he who is a foreigner to each of his subjects, and only through
> foreign eyes and ears could the empire manifest its existence to Kublai. In
> languages incomprehensible to the Khan, the envoys related information heard in
> languages incomprehensible to them: from this opaque, dense stridor emerged the
> revenues received by the imperial treasury, the first and last names of
> officials dismissed and decapitated, the dimensions of the canals that the
> narrow rivers fed in times of drought.

> Perhaps, Kublai thought, the empire is nothing but a zodiac of the mind’s phantasms.



> Marco Polo imagined answering (or Kubiai Khan imagined his answer) that the
> more one was lost in unfamiliar quarters of distant cities, the more one
> understood the other cities he had crossed to arrive there; and he retraced the
> stages of his journeys, and he came to know the port from which he had set
> sail, and the familiar places of his youth, and the surroundings of home, and a
> little, square of Venice where he gambolled as a child. At this point Kublai
> Khan interrupted him or imagined interrupting him, or Marco Polo imagined
> himself interrupted, with a question such as: ‘You advance always with your
> head turned back?’ or ‘Is what you see always behind you?’ or rather, ‘Does
> your journey take place only in the past?’


> It is pointless to ask whether the new ones are better or worse than the old,
> since there is no connection between them, just as the old postcards do not
> depict Maurilia as it was, but a different city which, by chance, was called
> Maurilia, like this one.


> No one remembers what need or command or desire drove Zenobia’s founders to
> give their city this form, and so there is no telling whether it was satisfied
> by the city as we see it today, which has perhaps grown through successive
> superimpositions from the first, now undecipherable plan. But what is certain
> is that if you ask an inhabitant of Zenobia to describe his vision of a happy
> life, it is always a city like Zenobia that he imagines, with its pilings and
> its suspended stairways, a Zenobia perhaps quite different, a-flutter with
> banners and ribbons, but always derived by combining elements of that first
> model.



> the others tell, each one, his tale of wolves, sisters, treasures, scabies,
> lovers, battles. And you know that in the long journey ahead of you, when to
> keep awake against the camel’s swaying or the junk’s rocking, you start
> summoning up your memories one by one, your wolf will have become another wolf,
> your sister a different sister, your battle other battles, on your return from
> Euphemia, the city where memory is traded at every solstice and at every
> equinox.


> Kublai interrupted him: ‘From now I shall describe the cities and you will tell
> me if they exist and are as I have conceived them

> Abandoned before or after it was inhabited. Armilla cannot be called deserted

> A girl comes along, twirling a parasol on her shoulder, and twirling slightly
> also her rounded hips. A woman in black comes along, showing her full age, her
> eyes restless beneath her veil, her lips trembling. A tattooed giant comes
> along; a young man with white hair; a female dwarf; two girls, twins, dressed
> in coral. Something runs among them, an exchange of glances like lines that
> connect one figure with another and draw arrows, stars, triangles, until all
> combinations are used up in a moment, and other characters come on to the scene

> The ancients built Valdrada on the shores of a lake, with houses all verandas
> one above the other, and high streets whose railed parapets look out over the
> water. Thus the traveller, arriving, sees two cities: one erect above the lake,
> and the other reflected, upside-down



> Even when lovers twist their naked bodies, skin against skin, seeking the
> position that will give one the most pleasure in the other, even when murderers
> plunge the knife into the black veins of the neck and more clotted blood pours
> out the more they press the blade that slips between the tendons, it is not so
> much their copulating or murdering that matters as the copulating or murdering
> of the images, limpid and cold in the mirror.


> The city of Sophronia is made up of two half cities. In one there is the great
> roller-coaster with its steep humps, the carousel with its chain spokes,...The
> other half-city is of stone and marble and cement, with the bank, the
> factories, the palaces, the slaughterhouse, the school, and all the rest. One
> of the half-cities is permanent, the other is temporary, and when the period if
> its sojourn is over, they uproot it, dismantle it....And so every year the day
> comes when the workmen remove the marble pediments, lower the stone walls, the
> cement pylons, take down the Ministry, the monument, the docks, the petroleum
> refinery, the hospital, load them on trailers, to follow from stand to stand
> their annual itinerary. ..

> then the whole citizenry decides to move to the next city, which is there
> waiting for them, empty and good as new; there each will take up a new job, a
> different wife, will see another landscape on opening his window, and will
> spend his time with different pastimes, friends, gossip. So their life is
> renewed from move to move, among cities whose exposure or declivity or streams
> or winds make each site somehow different from the others.


> have constructed in my mind a model city from which all possible cities can be
> deduced,’ Kublai said. ‘It contains everything corresponding to the norm. Since
> the cities that exist diverge in varying degree from the norm, I need only
> foresee the exceptions to the norm and calculate the most probable
> combinations.’ ‘I have also thought of a model city from which I deduce all the
> others’ Marco answered, ‘It is a city made only of exceptions, exclusions,
> incongruities, contradictions. If such a city is the most improbable, by
> reducing the number of elements, we increase the probability that the city
> really exists. So I have only to subtract exceptions from my model, and in
> whatever direction I proceed, I will arrive at one of the cities which, always
> as an exception, exist. But I cannot force my operation beyond a certain limit:
> I would achieve cities too probable to be real.’


> This is the foundation of the city: a net which serves as passage and as
> support. All the rest, instead of rising up, is hung below...

> You reach a moment in life when, among the people you have known, the dead
> outnumber the living. And the mind refuses to accept more faces, more
> expressionsSuspended over the abyss, the life of Octavia’s inhabitants is
> less uncertain than in other cities. They know the net will last only so
> long.

> Besides, the more Leonia’s talent for making new materials excels, the more
> the rubbish improves in quality, resists time, the elements, fermentations,
> combustions. A fortress of indestructible leftovers surrounds Leonia,
> dominating it on every side, like a chain of mountains.


> 'Why is Thekla’s construction taking such a long time?’ the inhabitants
> continue hoisting sacks, lowering leaded strings, moving long brushes up and
> down, as they answer, ‘So that its destruction cannot begin.’ And if asked
> whether they fear that, once the scaffolding is removed, the city may begin to
> crumble and fall to pieces, they add hastily, in a whisper, ‘Not only the
> city.’

>  It is not the voice that commands the story: it is the ear.’

# Associativity of addition in cubicaltt

Let's first understand what we need to prove. we're trying to prove that addition is associative. addition is defined as follows:

```
data nat = zero | suc (n : nat)

-- recursive on right argument
add (m : nat) : nat -> nat = split
  zero -> m
  suc n -> suc (add m n)
```

Since `add` is recursive on the right, we can simplify (by computation) values such as `add x (S y)` to `S (add x y)`. This will be important when reasoning about induction later.

Now, we wish to prove that:



```
for all a b, c,
  a + (b + c) = (a + b) + c
```


we prove this by induction on `c`. Let's consider the base case and the inductive case:

```
-- BASE CASE:
-- a + (b + 0) = (a + b) + 0
-- [computation]: a + (b) = (a + b)
```

By computation on the base case, we simplify `(b+0)` to `b`, and we similary simplify `(a + b) + 0` to `(a + b)`. So we're really asked to prove `add a b  = add a b` which is trivial (by reflexivity).

Next, let's think of the inductive case, where we suppose `c = S n`
and then simplify what we have to prove to a normal form:

```
-- INDUCTIVE HYPOTHESIS: let c = S n:
-- a + (b + S n) = (a + b) + S n
-- =[computation]: a + (S (b + n)) = (a + b) + S n
-- =[computation]: S (a + (b + n)) = (a + b) + S n
-- =[computation]: S (a + (b + n)) = S ((a + b) + n)
```

We see that after simplification by computation, we need to prove that
`S (a + (b + n)) = S ((a + b) + n`. The core idea is to use associativity
to prove that `(a + (b + n)) = ((a + b) + n)` and to then stick a `S _` on it, giving `S (a + (b + n)) = S ((a + b) + n)`. In a cubical diagram, this looks like:

```
-- j=1
--  ^  S(a+(b+n)) - -- -- -- -- -- - S((a+b) + n)
--  |  ^                                 ^
--  |  |                            <j> suc (add (add a b) n)
--  |  |                                 |
--  |<j> suc(add a (add b n))            |
--  |  |                                 |
--  |  |                                 |
--  |  S(a+(b+n)) ---------------------> S((a+b)+n)
--  |           suc (add A a b n @ i)
-- j=0
-- i=0 -------------------------------> i=1
```

- The bottom horizontal line is the first to `comp`, given as `(suc (addA a b n @ i))`

And in cubical code, it's written as:

- The left and right vertical lines are the second inputs to comp.
- The left vertical line is given by `<j> suc (add a (add b n)`
- The right vertical line is given by ` <j> suc (add (add a b) n)`.

In total, the implementation is:

```
addA (a b: nat) :
  (c: nat) -> Path nat (add a (add b c))
                       (add (add a b) c) = split
  zero -> <i> add a  b
  suc n -> <i> comp (<i> nat) (suc (addA a b n @ i))
                [ (i = 0) -> <j> suc (add a (add b n))
		        , (i = 1) -> <j> suc (add (add a b) n)]

```

**EDIT:** I now realise that we do not need to use `comp` since both the left and right edges of the square are constant. We can implement the above as:

```
addA (a b: nat):
  (c: nat) -> Path nat (add a (add b c))
                       (add (add a b) c) = split
  zero -> <i> add a  b
  suc n -> <i> (suc (addA a b n @ i))
```


# Etymology of fiber bundle $F \rightarrow E \rightarrow B$


The $F$ stands for fibre, $E$ for ensemble (total space), and $B$ for base space,
as told in this [math.stackexchange answer](https://math.stackexchange.com/questions/4165418/etymology-of-mathbfbg-for-category-of-one-object-for-g/4165440#4165440)

# Galois correspondence, functorially

For a given group $G$, build the category of subgroups as follows:
The objects aren't exactly subgroups, but are isomorphic to them ---
for each coset $H$, the category has the object as the coset space $G/H$,
equipped with the left-action of $G$ on the coset space . The morphisms
between $G/H$ and $G/K$ are the intertwining maps $\phi: G/H \rightarrow G/K$
which commute with the action of $G$: $(g \times ) \circ \phi = \phi \circ (g \times )$.


We first work out what it means to have such an intertwining map. Suppose we pick
a coset of $H$, which is an element of the coset space $\alpha H \in G/H$ for some $\alpha \in G$.
Now the intertwining condition says that $\phi(g \alpha H) = g \phi(\alpha H)$. If we pick
$\alpha = e$, then we get $\phi(g H) = g \phi(H)$. Thus, the intertwining map
is entirely determined by where it sends $H$, ie, the image $\phi(H)$.


Now, let the image of $\phi(H)$ be some coset $\gamma K \in G/K$. Suppose
that the coset $gH = g'H$, since writing a coset as $gH$ is not unique. Apply $\phi$
to both sides and use that $\phi$ is intertwining. This gives
$\phi(gH) = g \phi(H) = g \gamma K$ and $\phi(g'H) = g'\phi(H) = g' \gamma K$.
For these to be equal, we need $\gamma^{-1} g'^{-1} g \gamma  \in K$. But since
$gH = g'H$, we know that this is equivalient to $g g'^{-1} \in H$. Thus, the above condition becomes
equivalent to $\forall h \in H, \gamma^{-1} h \gamma \in K$.

So we now have a category whose objects are coset spaces and whose morphisms are intertwining maps.
We now consider the category of a given field extension $L/F$, which has objects intermediate fields
between $L$ and $F$, and has morphisms as field morphisms which fix $F$.


# CubicalTT: sharpening thinking about indexed functions


```
-- | function from nat to nat defined by lambda abstraction
f1 : nat -> nat -> nat = \(b: nat) -> \(c : nat) ->  b
```

```
-- | function from nat, nat -> nat defined by case analaysis
f2 : nat -> nat -> nat =
  split
    zero -> split@(nat -> nat) with
                zero -> zero
                suc b' -> zero
    suc a' -> split@(nat -> nat) with
                zero -> a'
                suc b' -> b'
```

```
-- | parametrized family of nats, defined by definition.
g1 (b : nat) (c : nat) : nat = b
```



```
-- | Family of nat parameterized by `(x: nat), `(y: nat)
-- | cannot split on parameters, can only split on fn.
-- g2 (x : nat) (y : nat) : nat =
--   split
--     zero -> split@(nat -> nat) with
--                 zero -> zero
--                 suc b' -> zero
--     suc a' -> split@(nat -> nat) with
--                 zero -> a'
--                 suc b' -> b'
```

# Functors to motivate adjuntions

- Consider the category $Set^\partial$ of sets with partial functions
  as morphisms, and the category $Set^*$, the category of pointed sets and
  and basepoint-preserving functions as morphisms.
- The functor $F: Set^\partial \rightarrow Set^*$
  sends sets to set-with-basepoint. To be very precise about basepoint considerations,
  since this is where the non-inversion will lie, let us say that for a set $X$, we add a basepoint $\{X \}$.
  So, the functor $F$ sends a set $X$ to the set `a = {X} in (X U {a}, a)`, which
  expanded out is $(X \cup \{ \{ X \} \}, \{ X \})$. The functor $F$ sends a partial function
  $f: A \rightharpoonup B$ to based function by defining $F(f): F(A) \rightarrow F(B)$
  which sends undefined values $a$ to $\{B\} \in F(B)$, and is forced by definition sends the basepoint $\{ A \} \in F(A)$ to $\{ B \} \in F(B)$.
- The "inverse" functor $G: Set^* \rightarrow Set^\partial$ forgets the basepoints, and sends
  a function $h: (A, a) \rightarrow (B, b)$
  to the partial function $G(h): A \rightarrow B$ by not mapping those elements in the domain
  which were mapped to $b$ by $h$.
- Going from a partial function $f$ to a bottomed function $F(f)$ and then back again
  to partial function $G(F(f))$ forgets no information.
- On the other hand, going from a basepointed set $(A, \bot)$ for some arbitrary basepoint $\bot$
  will return a set with a _different_ basepoint, $(A/ \bot \cup \{ \{ A/\bot \} \}, \{ A/\bot \})$. Note that the sets
  $(A, \bot)$ and $A/\bot \cup \{ \{ A/\bot\} \}$ are isomorphic, but not equal!


```
G(F((A, a)))
= let x = remove A a in G(x)
= let x = remove A a;
      botnew = set([x]) in insert x botnew
-- | adds the set (A - a) as an element of (A - a)
= insert (remove A a) (remove A a)

```

Thus, we should come up with a weaker notion of equality : Adjoints!

# Madoka Magica: plot thoughts

- I wonder whether incubator ~ Kyubey ~ kyubii ~ nine-tails.
- Homura is such a tragic character.


# Chain rule functorially

- The first category is $Euc^*$, whose objects are pointed subsets of Euclidean space.
   So, the objects are of the form $(U \subseteq \mathbb R^n, a \in U)$. Morphisms
  are based smooth functions between these opens: smooth functions $f: U \rightarrow V$
  such that $f(a) = b$.
- The second category is $M$
 whose objects are natural numbers and morphisms $n \to m$ are matrices of
 dimension $n \times m$.
- Define a functor $d: Euc \to M$ which
  sends subsets to the dimension of the space they live in: $U \subseteq \mathbb R^n, a) \to n$,
  and sends smooth functions $f: (U, a) \rightarrow (V, b)$ to their Jacobian evaluated at the
  basepoint, $J_f|_a$.
- Functoriality asserts that the jacobian of the composition of the two functions is a matrix
  multiplication of the jacobians.

Let's think through the functoriality. It says that if we have two arrows which can be composed,
$(f, a)$ and $(g, f(a))$ -- note that it has to be $(g, f(a))$ because only compatible basepoint
functions can be composed.


I feel like we shouldn't use natural numbers for $M$, but we should rather use real vector spaces.
And as for $Euc$, we should replace this with $ManOpen$ where we use based
"charted" opens of a differentiable manifold.  This makes the diffgeo clear!

# Lagrange multipliers by algebra

#### Constrained optimisataion: the first stab

We want to maximize $z = f(x, y)$ given the constraint that $g(x, y) = 0$.
Let us arbitrarily say that $x$ is independent and $y$ is dependent on $x$, so there
is some function $t$ such that $y = t(x)$. This lets us compute $dy/dx$ using:

$$
\begin{aligned}
& g(x, y) = 0\\
&\frac{d g(x, y)}{dx}  = d0 = 0\\
&\frac{\partial g}{\partial x} + \frac{\partial g}{\partial y}\frac{dy}{dx} = 0 \\
&\frac{dy}{dx} = - \frac{\partial g/\partial x}{\partial g/\partial y}
\end{aligned}
$$

Next, since $z$ is a function of $x$ alone (as $y$ is dependent on $x$ via $t$), the condition
$dz/dx = 0$ guarantees a maxima for $z$:

$$
\begin{aligned}
&\frac{dz}{dx} = 0 \\
&\frac{\partial f}{\partial x} + \frac{\partial f}{\partial y}\frac{dy}{dx} = 0 \\
&\frac{\partial f}{\partial x} + \frac{\partial f}{\partial y} \frac{\partial g/\partial x}{\partial g/\partial y} = 0 \\
\end{aligned}
$$

Solving the above condition along with $g(x, y) = 0$ to recover the value of $y$ gives us the optima.

#### Constrained optimisataion: equal footing


$$
F(x, y, \lambda) = f(x,y) + \lambda g(x, y)
$$

If we consider the stationary value of $F$, we get:

$$
\begin{aligned}
&\frac{\partial F}{\partial x} = \frac{\partial f}{\partial x} + \lambda \frac{\partial g}{\partial x} = 0 \\
&\frac{\partial F}{\partial y} = \frac{\partial f}{\partial y} + \lambda \frac{\partial g}{\partial y} = 0 \\
&\frac{\partial F}{\partial \lambda} = \frac{\partial f}{\partial x} + \lambda \frac{\partial g}{\partial x}
\end{aligned}
$$

to eliminate $\lambda$ from the above equations, we rearrange:


$$
\begin{aligned}
&\frac{\partial f}{\partial x}/\frac{\partial g}{\partial x}  = \lambda\\
&\frac{\partial f}{\partial y}/\frac{\partial g}{\partial y}  = \lambda \\
\end{aligned}
$$

This $\lambda$ can be eliminated to recover the previous equation:

$$
\begin{aligned}
&\frac{\partial f}{\partial x}/\frac{\partial g}{\partial x}  = &\frac{\partial f}{\partial y}/\frac{\partial g}{\partial y} \\
&\frac{\partial f}{\partial x} =  \frac{\partial g}{\partial x} \frac{\partial f}{\partial y}/\frac{\partial g}{\partial y} \\
&\frac{\partial f}{\partial x} - \frac{\partial g}{\partial x} \frac{\partial f}{\partial y})/\frac{\partial g}{\partial y}  = 0 \\
\end{aligned}
$$


The langrange multipler procedure is nice since it does not break the symmetry between the two variables.


# Specht module construction

#### $A[\lambda][t]$, and its image

Define

$$
A[\lambda][t](x) \equiv \sum_{\pi \in C[t]} sgn(\pi) \pi(x).
$$

That is, $A[\lambda][t]$ creates a signed linear combination of $x$ by creating signed orbits of $x$ under the
column stablizier of $t$.


First consider

$$
A[\lambda][t](t) = \sum_{\pi \in C[t]} sgn(\pi) \pi(t).
$$

We claim that $A[\lambda][t]$ is
a projection operator which projects onto the subspace spanned by $A[\lambda][t](t)$. To show this,
let's consider the action of $A[\lambda][t]$ on some other tabloid $s$.


There is a predicate we are
interested in that determines whether $A[\lambda][t](x)$ is $0$ or $\pm t$: If $t$ has two elements $a, b$
that are in the same column of $t$, which are in the same row of $x$. If such elements $a, b$ exist, then
the action of $\texttt{swap}(a, b)$ is trivial on $x$, as tabloids are invariant under row permutations. Furthermore,
$\texttt{swap}(a, b)$ is in the column stabilizer $C[t]$, since $a, b$ are in the same column of $t$. Exploiting
this, we write the group $C[t]$ as cosets of the subgroup $H \equiv \{ id, \texttt{swap}(a, b) \}$. Now the magic
happens: the action on $x$ via $H$ turns out to be zero:

$$
\begin{aligned}
&\sum_{\pi \in H} sgn{\pi} \pi(x) \\
&= id(s) - \texttt{swap}(a, b)(x) \\
&= x - x = 0
\end{aligned}
$$

Since $C[t]$ partitions as cosets of $H$, the entire action of $C[t]$ on $x$ becomes zero:

$$
\begin{aligned}
&\sum_{\pi \in C[t]} sgn{\pi} \pi(x) \\
&= \sum_{\pi \in C[t]/H} (\pi \cdot id)(x) - (\pi \cdot \texttt{swap}(a, b))(x) \\
&= \sum_{\pi \in C[t]/H} (\pi  \cdot id) (x) - (\pi \cdot \texttt{swap}(a, b))(x) \\
&= \sum_{\pi \in C[t]/H} \pi  \cdot (id(x) - \texttt{swap}(a, b)(x)) \\
&= \sum_{\pi \in C[t]/H} \pi (id(x) - \texttt{swap}(a, b)(x)) \\
&= \sum_{\pi \in C[t]/H} \pi (x - x) \\
&= \sum_{\pi \in C[t]/H} \pi (0) = 0
\end{aligned}
$$


On the other hand, let us assume that elements in the same column of $t$ are always in different rows $x$ [
if they are in the same row, then the action is zero as we saw before.] Let us focus on the $c$th column of $t$:
say the elements in this column are $t[1][c], t[2][c], \dots, t[n][c]$. These elements will be in different rows of $x$.
Since we can freely permute rows, we can move these elements $t[:][c]$ to the $c$th column _of_ $x$. This makes column $x[:][c]$
of $x$ be a permutation of the $t[:][c]$ column of $t$. Now, there is a unique permutation which permutes every column of $x$
to be like the columns of $t$. Thus, there is a unique permutation $\pi \in C[x]$ such that $\pi(x) = t$. We can invert this,
to find a permutation $\pi' \equiv \pi^{-1} \in C[t]$ such that $\pi'(t) = x$. This will force the value of $A[\lambda][t](x)$ to be
equal to $\pm A[\lambda][t](t)$, since $x$ differs from $t$ by a permutation:

$$
\begin{aligned}
&A[\lambda][t](x) = \\
&= A[\lambda][t](\pi' t) \\
&= \sum_{\sigma \in C[t]} sgn(\sigma) \sigma(\pi' t) \\
&= \sum_{\sigma \in C[t]} sgn(\sigma) (\sigma \circ \pi') t) \\
&= \sum_{\sigma \circ \pi \in C[t]} sgn(\sigma) sgn(\pi') sgn(\pi') (\sigma \circ \pi') t) \\
&=  sgn(\pi') \sum_{\sigma \circ \pi \in C[t]} sgn(\sigma \circ \pi) (\sigma \circ \pi') t) \\
&= sgn(\pi') \sum_{\sigma' \in C[t]} sgn(\sigma') \sigma'(t) \\
&= sgn(\pi') A[\lambda][t](t)
\end{aligned}
$$

Thus, we find that when $A[\lambda][t]$ acts on a tableaux $x$, the result is either $0$ [when $x$ cannot be obtained by a column permutation of $t$],
or is $\pm A[\lambda][t](t)$ [when $x$ can be ontained by a column permutation of $t$]. Thus, the image of $A[\lambda][t]$
is a 1-dimensional subspace spanned by $A[\lambda][t](t)$. So the important property that we have uncovered is that $A[\lambda][t](x)$
is non-zero iff $t$'s columns can be permuted to produce $x$: written formally, we have:

$$
\begin{aligned}
&A[\lambda][t](x) \neq 0 \iff \exists \pi \in C[t], \pi(t) = x \\
&A[\lambda][t](x) = 0 \iff \not \exists \pi \in C[t], \pi(t) = x \\
\end{aligned}
$$

#### Inner product and $A[\lambda][t]$ is self adjoint

We impose the "canonical" inner product on the space of vectors spanned by tabloids, given
by making all non-equal basis tabloids orthogonal:

$$
\langle \{t\} | \{t'\} \rangle \equiv
\begin{cases}
1 & \{t \} \simeq \{ t' \} \\
0 & \text{otherwise}
\end{cases}
$$

Under this inner product, we claim that $A[\lambda][t]$ is self-adjoint:
we have that $\langle A[\lambda][t](x), y \rangle = \langle x, A[\lambda][t](y) \rangle$. The key idea is that $A[\lambda][t](y)$
is made up of permutations which are unitary, since they simply permute the orthogonal basis vectors,
and these permutations are arranged in $A[\lambda][t]$ such that the $A[\lambda][t]$ operator is self-adjoint:


$$
\begin{aligned}
&\langle A[\lambda][t](x) | y \rangle \\
&= \langle \sum_{\pi \in C[t]} sgn \pi  \pi(x) | y \rangle \\
&= \sum_{\pi \in C[t]} sgn \pi \langle  \pi(x) | y \rangle \\
&\text{($\pi^{-1}$ is a permutation of orthonormal basis, hence orthogonal)} \\
&\text{($\pi^{-1}$ preserves inner produce as orthogonal):} \\
&= \sum_{\pi \in C[t]} sgn \pi \langle \pi^{-1} \pi(x) | \pi^{-1} y \rangle \\
&= \sum_{\pi \in C[t]} sgn \pi \langle \pi^{-1} \pi(x) | \pi^{-1} y \rangle \\
&= \sum_{\pi \in C[t]} sgn \pi \langle x | \pi^{-1} y \rangle \\
&\text{(Sum over $\pi^{-1}$, is an automorphism:)} \\
&= \sum_{\pi^{-1} \in C[t]} sgn \pi^{-1} \langle x | \pi^{-1} y \rangle \\
&= \langle x | \sum_{\pi^{-1} \in C[t]} sgn \pi^{-1}   \pi^{-1} y \rangle \\
&= \langle x | A[\lambda][t](y) \rangle \\
\end{aligned}
$$


#### $S[\lambda]$ is a irreducible subspace of $M[\lambda]$

- Define the subspace spanned by $\{ A[\lambda][t] : t \in \texttt{tabloid}(\lambda) \}$ as $S[\lambda]$ (for Specht).
  Thus, the $A[\lambda][t]$ span $S[\lambda]$.
- $S[\lambda]$ is invariant under $S[n]$, since the action of $\pi \in S[n]$ on $A[\lambda][t]$
  sends $A[\lambda][t]$ to $A[\lambda][\pi(t)]$. Also, the full space $M[\lambda]$ is invariant under $S[n]$ by construction.
- The orbit of any $A[\lambda][t]$ under $S_n$ gives us the full set $\{ A[\lambda][t'] : t' \in \texttt{tabloid}$, since we can produce
   $A[t']$ from $A[t]$ by the action that permutes $t$ into $t'$.
- For all invariant subspace $U$, $U$ is either disjoint from $S[\lambda]$ or $U$ contains $S[\lambda]$. So it is impossible
  to reduce $S[\lambda]$ into a smaller invariant subspace $U$.
- Consider some invariant subsepace $U$. If it is disjoint from $S[\lambda]$, then we are done.
- Otherwise, assume there is some $x \in S[\lambda] \cap U$.
- As $x \in S[\lambda]$ and $S[\lambda]$ is spanned by $\{ A[\lambda][t](t) : t \in \texttt{tabloid} \}$, there must be some $t'$ along which $x$ has a component:
  $\langle x | A[\lambda][t'](t') \rangle \neq 0$.
- Since $A[\lambda][t']$ is symmetric, I can write the above as $\langle A[\lambda][t'](x) | t' \rangle \neq 0$.
  Now since the image of $A[\lambda][t']$ is the subspace spanned by $t'$, since $U$ is invariant under $A[\lambda][t']$,
  and since $\langle A[\lambda][t'](x) | t' \rangle \neq 0$, we can say that $A[\lambda][t'](x) = \alpha t' \in U$ for $\alpha \neq 0$.
  This tells us that we have the vector $t' \in U$.
- Once we have a _single_ $t' \in U$, we win, since all the other $t$'s are obtained as permutations of $t'$, and $U$ is an invariant
  subspace of these permutations.
- TLDR: if we havs some common vector $x \in S[\lambda] \cap U$, then $\langle x | A[\lambda][t](t) \rangle \neq 0$. By
  self-adjoint, we get $\langle  A[\lambda][t](x) | t \rangle \neq 0$. But $A[\lambda][t](x) = k_{t, x} A[\lambda][t](t)$, hence $k_{t, x} \neq 0$.
  Further, $A[\lambda][t](x) \in U$ since $U$ is invariant and $x \in U$, hence $k_{t, x} A[\lambda][t](t) \in U$ for $k_{t, x} \neq 0$ hence $A[\lambda][t](t) \in U$.
  This forces all of $S[\lambda] \in U$, since $U$ is invariant and $S[\lambda]$ is generated by the various $\{ A[\lambda][t](t) : t \texttt{tabloid} \}$,
  which are obtained by permutation of of $A[\lambda][t](t)$ for a given $t$.

#### The argument, in the abstract

Let $V$ be a finite dimensional real vector space with inner product $\langle \cdot | \cdot \rangle$.
Let $H: V \rightarrow V$ be a symmetric operator with rank 1 image, eigenvector $h \in V$.
For simplicity, say that the eigenvalue of $h$ is $1$, so $H h= h$.
($H$ Hermitian is defined as $\langle Hx | y \rangle = \langle x | H y \rangle$)
Let $\mathcal O$ be a group of orthogonal matrices.  Define a subspace $S$ of $V$ given
by the $\mathcal O$-span of the image of $H$: $S \equiv span(\{ O h : O \in \mathcal O\})$.

We wish to show that $S$ is an irreducible $\mathcal O, H$-invariant subspace. By construction, $S$ is $\mathcal O, H$-invariant,
since it takes the subspace spanned by $h$ and makes it invariant under $\mathcal O$.
To show that this is irreducible, suppose we have some $\mathcal O, H$ invariant subspace $W$. We wish to show
that if $W$ contains a single vector from $S$, then it contains all of $S$: $W \cap  S \neq \emptyset \implies S \subset W$.

- Suppose that $x \in W \cap S$. Since $S$ is spanned the various $\mathcal O h$, there must be some $O \in \mathcal O$
  such that $\langle x | O h \rangle \neq 0$.
- Since $O$ is orthogonal, we can shift the rotation towards $x$ by rotating the entire frame by $O^{-1}$,
  giving us $\langle O^{-1} x | h \rangle \neq 0$.
- Since $h$ is an eigenvector, we replace $h$ by $H h$ giving us $\langle O^{-1} x | H h \rangle \neq 0$.
- Since $H$ is hermitian, I rewrite the above as $\langle H O^{-1} x | h \rangle \neq 0$.
- Since $x \in W$ and $W$ is invariant under $\mathcal O$ and $H$, we have that $H O^{-1} x \in W$.
- Also, since the image of $H$ lies entirely along $h$, we have that $H O^{-1} x = \alpha_x h$.
  Combining with $\langle H O^{-1} x | h \rangle \neq 0$ gives us $\langle \alpha_x h | h \rangle \neq 0$,
  or $\alpha \neq 0$.
- Thus, the **non-zero** vector $\alpha_x h \in W$ (non-zero as $\alpha_x \neq 0$). Hence, the vector $h \in W$.
  Since $W$ is closed under $\mathcal O$ and $S$ is generated as $\mathcal O h$, we have that $S \subseteq W$.

##### Showing that $H$ as thesigned linear combination of $\mathcal O$ is Hermitian

In the abstract, we define $H \equiv \sum_{O \in \mathcal O} |O| O$, which specializes
to $H_t \equiv \sum_{\pi \in C_t } \pi sgn(\pi)$ in the tableaux theory. Now consider
$H^T = \sum_{O \in \mathcal O} |O| O^T$ Since $O$ is orthogonal, $O^T = O^{-1}$. Furthermore,
we have that $|O| = |O|^{-1}$ since:

$$
\begin{aligned}
&|O| = \pm 1 \\
|O^{-1}|  = |O|^{-1} \\
&= (\pm 1)^{-1} = \pm 1
\end{aligned}
$$

Combined, this tells us that $H^{T} = \sum_{O \in \mathcal O} |O|^{-1} O^{-1}$. Since $\mathcal O$
is a subgroup, the sum can be re-indexed to be written as $H^{T} = \sum_{O' \in \mathcal O} |O'| O'$,
which is equal to $H$. Hence, we find that $H^T = H$, or $H$ defined in this way is hermitian.


##### Showing that $H$ is rank 1

In the symmetric group case, we consider:

$$A_x \equiv \sum_{\sigma \in C_t} sgn(\sigma) \sigma$$

Now say we have some other $y$. The two cases are:

- $y \in Orb(x, C_x)$. We have $y = \pi x$ for $\pi \in C_x$ In this case, the expression for $A_x y$ can be written as $A_x (\pi x)$
  which is equal to $sgn(\pi) A_x(x)$. So this belongs to the subspace of $A_x(x)$.
- $y \not \in Orb(x, C_x)$. This means that we cannot rearrange the columns of tabloid $x$ to get tabloid $y$ (upto row permutation).
- That is, we have:

```
xa -> 1
xb -> 1
xc -> 2
```

- where two elements in the same column of $x$ `(xa, xb)` want to go to the same row of $y$. If all elements
  in the same column of $x$ `(xa, xb, xc)` wanted to go to different rows of $y$ `(3, 1, 2)`, we could have
  permuted $x$ in a *unique* way as `(xb, xc, xa)` to match the rows. This tells us how to convert $x$ into $y$,
  for this column. If we can do this for all columns, we are done.
- The only obstruction to the above process is that we have two elements in the same column of $x$ `(xa, xb)` that
  want to go to the same row of $y$. Said differently, there is a permutation $p$ that swaps `xa <-> xb` that is in
  $C_x$ (since `(xa, xb)` are in the same column), whose action leaves  $y$ unchanged (since $y$ a tabloid has
  these elements in the same row; tabloid invariant under row permutation).
- Thus, we can write $C_t$ as cosets of the subgroup $\{e, p\}$ whose action of $y$ will be:

$$
\begin{aligned}
&(sgn(e) e +sgn(p) p)(y) \\
&(e - p)(y) \\
&y - y = 0
\end{aligned}
$$

- Thus, the action of the full $C_t$, written as cosets of $\{ e, p\}$ cancels out entirely and becomes zero, since every coset
  is of the form $h\{e, p\}$, ie $\{h, hp\}$. And the action of this will be:

$$
\begin{aligned}
&(sgn(h)h + sgn(hp)hp)y \\
&=sgn(h) hy + sgn(h)(-1) hp y \\
&=sgn(h) hy - sgn(h) hp y \\
&=sgn(h) hy - sgn(h) hy \\
&=0
\end{aligned}
$$

- Thus, either an element $y$ is in the orbit $C_x$ or not. If it's in the orbit, we get answer $\pm A_x x$. If it's not, we get zero.


#### Have we found all the irreps?

Recall that the number of irreps is upper bounded by the number of conjugacy classes of the group. This follows
from character theory: (1) the characters of irreps are orthogonal in the space of class functions, and
(2) the dimension of the space of class functions is is equal to the number of conjugacy classes, since there
are those many degrees of freedom for a class function --- it must take on a different value per conjugacy class
[TODO: finish my character theory notes]. In our case, we have found one irrep per conjugacy class, since
conjugacy classes of $S_n$ is determined by cycle type, and the shape of a diagram encodes the cycle type of
a permutation. If we show that the irreps of different shapes/diagrams are inequivalent, we are done.


#### Characterizing Maps $S[\lambda]$ to $S[\mu]$



We wish to prove the key lemma, which is that if we have a non-zero map $f: M[\lambda] \rightarrow M[\mu]$,
then $\lambda \trianglerighteq \mu$. Let's consider the extreme cases with 3 elements:

```
λ = (1 1 1):
* * *
```

```
μ = 3:
#
#
#
```

- Let $l$ be a $\lambda$ tableau, $m$ be a $\mu$ tableau.
- Let's consider $A[l](m)$ and $A[m](l)$.
- For $A_l(m)$ to be non-zero, we need a way to send elements of $m$ in the same column (`#; #; #`) to correct rows in $l$ (`* * *`)But see that $l$
  has only one row, and $m$ has no choice: it must send all its elements in all columns to that single row of $l$. Thus, the $C_l$ [WRONG]
  don't hinder us from doing the only thing we possibly can.
- For $A_m(l)$ to be non-zero, we need a way to send elements of $l$ in the same column, of which there are three columns, `*`, `*`, `*`, to different rows of
  $m$. But if $l$ were feeling stubborn, it could say that it wants each of its `*`'s to end up in the first row of $m$. $m$ will be overcrowded, so this
  leads to the map becoming zero.
- In general, if $\lambda \triangleright \mu$, then the map $A[\lambda](\mu)$ can be nonzero, since we need to send elements in the same column of $\mu$ to different
  rows of $\lambda$, and $\lambda$ is "bigger", [WRONG?!]


Thus, we have found ALL irreps, since as argued before, there can be at most as many irreps as there are shapes/diagrams of $n$,
and we've shown that each irrep that corresponds to a shape is distinct.

#### All the $S[\lambda]$ are distinct irreps of $S_n$ by Schur's lemma

Suppose that $S[\lambda] \simeq S[\mu]$. Thus we have an invertible intertwining map $T: S[\lambda] \rightarrow S[\mu]$.
By Schur's lemma, since we know that $S[\lambda]$ and $S[\mu]$ are irreps,
we know that $T$ is a scalar multiple of the identity map. Let $m$ be a tabloid of shape $\mu$.
We know that $A[\mu][m](m) \in S[\mu]$. Now consider $T^{-1}(A[\mu][m](m))$. This must be
equal to $A[\mu][m](T^{-1}(m))$. This means that $T^{-1}(m)$ is not zero when acted upon
by $A[\mu][m](m)$, thus $T^{-1}(m)$, of shape $\lambda$ must dominate shape $\mu$
[Argue why this is the case by adapting the proof seen before about spaces].


Ruunning the argument is reverse, we get both directions of $\lambda \trianglerighteq \mu$ and $\mu \trianglerighteq \lambda$,
there by establishing $\lambda = \mu$.

#### Working it out for S3

##### `Tabloid(3)`

There's only one tabloid of shape `3`, which is `{1 2 3}`. Thus we get a 1D complex vector space with
basis vector `b{1, 2, 3}`. Every permutation maps `b{1, 2, 3}` onto itself, so we get the trivial
representation where each element of `S3` is the identity map.


##### `Tabloid(2, 1)`

There are three tabloids of shape `(2, 1)`, one for each unique value at the bottom. The top row can be
permuted freely, so the only choice is in how we choose the bottom. We get the tableaux
`{1 2}{3}` = `[1 2][3]` =  `[2 1][3]`, drawn as:

```
[1 2] = [2 1] = {1 2}
[3]     [3      {3}
```

And similarly we get `{1 3}{2}` and `{1 2}{3}`. So we have a three dimensional vector space.
Now let's look at the action of the `A` operator `A: Tableaux -> GL(V(Tabloid(mu))`. First of all,
we see that the `A` operator uses _tableaux_ and not _tabloids_ (because we
need to know which elements are in the same column).
Recall that the action of `A(t)` on a tabloid `x` is to sum up linear combinations of $sgn(\pi)\pi(x)$,
where $\pi$ is from the column stabilizer of `t`.

$$
A(t)(x) \equiv \sum_{\pi \in \texttt{col-stab}(t)} sgn(\pi) \pi(x)
$$

So let's find the action! The tableaux `[1 2][3]`, ie:

```
[1 2]
[3]
```

has as column stabilizers the identity permutation, and the
permutation `(1 3)` obtained by swapping the elements of the columns `[1..][3]`
Thus, the action of `A([1 2][3])` on a tabloid `{k l}{m}`
is the signed linear combination of the action
of the identity and the swap on `{k l}{m}`:

$$A([1 2][3])(\{ k l \}\{m \}) = 1 \cdot \{k l\}\{m\} + (-1) \cdot {m l}{k} $$


Recall that the basis of the Specht module is given by `A([t])({t})`, where we have the tableaux `t`
act on its own tabloid. In the case where `t = [1 2][3]` we get the output

```
A([1 2][3])({1 2}{3}) = {1 2}{3} - {3 1}{2}
```

Similarly, we tabulate all of the actions of `A(x)({x})` below, where we
pick the equivalence class representative of tabloids as the tabloid whose
row entries are in ascending order.


```
A([1 2][3])({1 2}{3})
  = (id - (1, 3))({1 2}{3})
  = {1 2}{3} - {3 1}{2}
  = {1 2}{3} - {1 3}{2}
```

```
A([2 1][3])({2 1}{3})
  = A([2 1][3])({2 1}{3})
  = A([2 1][3])({1 2}{3})
  = (id - (2, 3))({1 2}{3})
  = {1 2}{3} - {1 3}{2}
```


```
A([1 3][2])({1 3}{2})
  = (id - (1, 2))({1 3}{2})
  = {1 3}{2} - {2 3}{1}
```

```
A([3 1][2])({3 1}{2})
  = (id - (3, 2))({3 1}{2})
  = (id - (3, 2))({1 3}{2})
  = {1 3}{2} - {1 2}{3}
```

```
A([1 2][3])({1 2}{3})
  = (id - (1, 3))({1 2}{3})
  = {1 2}{3} - {3 2}{1}
  = {1 2}{3} - {2 3}{1}
```

```
A([2 1][3])({2 1}{3})
  = (id - (2, 3))({2 1}{3})
  = (id - (2, 3))({1, 2}{3})
  = {1 2}{3} - {1 3}{2}
```

If we now label the vector as `{2 3}{1} = a`, `{1 3}{2} = b`, `{1 2}{3} = c`, written
in ascending order of the element of their final row, we find that `A(x)(x)` gave us the vectors:

```
A([1 2][3])({1 2}{3})
  = {1 2}{3} - {1 3}{2} = c - b
A([2 1][3])({2 1}{3})
  = {1 2}{3} - {1 3}{2} = c - b
A([1 3][2])({1 3}{2})
  = {1 3}{2} - {2 3}{1} = b - a
A([3 1][2])({3 1}{2})
  = {1 3}{2} - {1 2}{3} = b - c = -(c-b)
A([1 2][3])({1 2}{3})
  = {1 2}{3} - {2 3}{1} = c - a
A([2 1][3])({2 1}{3})
  = {1 2}{3} - {1 3}{2} = c - b
```

where the subspace spanned by the vectors `(a-b)`, `(b-c)`, `(c-a)` is
two dimensional, because there a one-dimensional redundancy `(a-b) + (b-c) + (c-a) = 0`
between them. Furthermore, the basis vectors `(a - b)`, `(b - c)`, `(c - a)` are invariant
under all swaps, and are thus invariant under all permutations, since all permutations can be
written as a composition of swaps. So we have found a two-subspace of a three-dimensional
representation of `S3`. To see that this subspace is irreducible, notice that given any permutation
of the form `k - l`, we can swap the letters `k, l` and the third letter `m` to obtain the entire
basis. Hence, this subspace is indeed irreducible, and the representation of `Sn` that we have
is indeed an irreducible representation.


##### `Tabloid(1, 1, 1)`

There are 6 tabloids of shape `(1, 1, 1)`, given by the permutations of the numbers `{1, 2, 3}`.
If we write them down, they're going to be (a) `{1}{2}{3}`, (b) `{1}{3}{2}`, (c) `{2}{1}{3}`,
(d) `{2}{3}{1}`, (e) `{3}{1}{2}`, (f)`{3}{2}{1}`. This gives us a 6 dimensional vector
space spanned by these basis vectors.


Let's now find out the value of `A([1][2][3])({1}{2}{3})` recall that we need to act
on `{1}{2}{3}` with all column stabilizers of `A([1][2][3])`.






##### `A` on tabloid instead of tableaux

I claim that the different `A_t` and `A_s` for `{t} = {s}` differ only by sign [Why?
Because we can reorder the elments of `t` and `s` to suffer a sign]. Thus, we can
directly define `A_{t}` on the *tabloids*, by defining it as first sorting the rows of `t`
and then using `A_t`.


# Even and odd functions through representation theory

Consider the action of $\mathbb Z/ 2\mathbb Z$ on the space of functions $\mathbb R \to \mathbb R$.
given by $\phi(0)(f) = f$, and $phi(1)(f) = \lambda x. f(-x)$. How do we write this in terms of irreps?

- On the even functions, since $e(x) = e(-x)$ for $e$ even, we have that,
  $\phi(0)(e) = e$ and $\phi(1)(e) = e$ [since $e(-x) = e(x)$], or $\phi(x)(e) = id(e)$,   hence the action
  of $\phi$ is that of the trivial representation on the subspace spanned by even functions.

- On the odd functions, since $o(-x) = -o(x)$, we have that $\phi(1)(o)(x) = o(-x) = -o(x) = sgn(o)(x)$ hence $\phi(1)(o) = -o$, hence $\phi(x)(o) = sgn(x)(o)$ where $sgn$
  is the sign representation!

Since the even and odd functions span the space of all functions, as we can write any function $f$ as the
sum of an even part $e_f(x) \equiv [f(x) + f(-x)]/2$ and an odd part $o_f(x) \equiv [f(x) - f(-x)]/2$. So,
we have described the action of $\phi$ in terms of subspaces which span the space, so we've found the irrep decomposition.

# Greg egan: Orthogonal

I found the idea of writing a story about a universe with a closed loop of time fascinating.
Here are some of the sentences that really helped me "get" compatiblism as an idea thanks
to reading the book:

> Suppose we leave a piece of equipment behind on Esilio - say, a
> small spyglass. Over the eons, from our point of view, we'd expect it to become
> pitted by dust in the wind, and eventually break up completely and turn to
> sand. Our spyglass, our rules: that sounds fair, doesn't it? But if that sand
> stays on Esilio, what origin will it have from Esilio's point of view? Most
> likely, some ordinary Esilian rock will have broken down to make it - which to
> us, would look like erosion running backwards. But then, in Esilian time the
> remnants of that rock will eventually form themselves spontaneously into a
> spyglass, which lies on the ground until we come along to retrieve it.  So if
> you follow the history of the matter that makes up the spyglass far enough in
> both directions, it's clear that it's not committed to either side's rdes.'
>
> 'Swap the roles of Esilio and the Surveyor,' he replied, 'then tell the same
> story again. If something from Esilio takes the place of the spyglass, it must
> be with us already. We must have been carrying it, or the things that will
> become it, from the very start. Because according to Esilio's arrow of time
> we've already visited the planet, and it's almost certain that something
> remained with us when we departed.'


> 'Tell us one thing that you're sure won't happen,' he challenged her.  She
> said, 'Two objects in thermal contact will not maintain different
> temperatures over a long period of time.' 'Because ... ?' 'Because there are
> vastly more possibilities in which they share their thermal energy more
> equally. If you pick a possibility at random, it's likely to be one of those.
> Fundamental physics might make the entropy minimum necessary - but we still
> expect the cosmos to be as random as it can be.'


> There was fine red dust covering the grey hardstone walls of the airlock. He
> hadn't noticed it by the dimmer illumination of the safety light. He ran a
> gloved finger along the seal of the outer door, trying to find the point
> where it had been breached, but if there was a hole it wasn't apparent.  It
> hardly mattered now; however the dust had entered, he was about to let in a
> great deal more. But as he began to turn the crank, the realisation hit him:
> it hadn't corne from outside. They must have brought it with them all the way
> from the Peerless, scattered invisibly throughout the craft, with a little
> more accumulating inside the airlock each time the inner door was opened. Or
> in Esilio's terms: the Surveyor's visit had just ended, and this residue was
> something they would soon take away with them


> Twice, as she jumped out of some indentation in the sand, it vanished. She
> and Azelio hadn't actually made all the tracks that he'd attributed to them.
> Or not yet, they hadn't.  'Come and join us,' Azelio said. 'Some of these
> must be yours.'


> Each time Azelio lifted his feet, scattered sand unscattered itself, grains
> sliding in around the places where he'd stepped to settle more evenly -
> though not always smoothing the ground completely. After all, 197 Ramiro
> reasoned, it was possible to walk in someone else's footprints, or to step
> several times in your own. It would only be the last footfall on any given
> spot - prior to the next occasion on which the wind levelled everything -
> that would unmake the imprint completely.



> 'What happens if I try to walk on pristine ground?' he asked.  'Try it and
> see!' Agata taunted him.  Ramiro descended to the bottom of the ladder,
> intending to move quickly and get the ordeal over with, but then his resolve
> deserted him. When he willed his foot to land on unblemished sand, what
> exactly would intervene to stop him? A cramp in the muscle, diverting his leg
> to its proper, predestined target? A puppet-like manipulation of his body by
> some unseen force too strong to resist, or a trance-like suspension of his
> whole sense of self? He wasn't sure that he wanted to know the answer. And
> perhaps that was the simplest resolution: he would lack the courage to walk
> out across the surface of Esilio for the rest of the mission. He would cower
> in his room, leaving the work to the others, while he waited to return to the
> Peerless in disgrace.

> He'd scrutinised the ground beforehand, and he was sure there'd been no
> footprints at all where his feet now stood.  He lifted one foot and inspected
> the sand below. He had created an indentation that had not been there before.
> That was every bit as strange to Esilio as the erasures he'd witnessed were
> strange to him.


>'How?' he demanded, more confused than relieved.  'You
> really don't listen to me, do you?' Agata chided him. 'Did I ever tell you
> that the local arrow was inviolable? 'No.' What she'd stressed most of all
> was a loss of predictability but the sight of her and Azelio unmaking their
> footprints had crowded everything else out of his mind. Those disappearing
> marks 198 in the sand might be unsettling, but if he could ignore them and
> walk wherever he pleased then they were not the shackles he'd taken them to
> be.


> 'What happens if there are footprints that no one gets around to
> before the next dust storm?' he asked Agata. 'Ones that were there
> straight after the last storm?'
> She said, 'There can't be a footprint untouched by any foot. I don't
> understand the dynamics of wind and sand well enough to swear to
> you that there won't be hollows in the ground that come and go of
> their own accord - but if you're talking about a clear imprint, if we
> could keep our feet away from it, it simply wouldn't be there.'


> Esilio was a world where a certain amount of nOiSY, partial - and
> predominantly trivial - information about the future would be strewn across
> the landscape. There had always been plenty of trivial things that could be
> predicted with near-certainty back on the Peerless, and perhaps as many of
> them would be lost, here, as these eerie new portents would be gained

> Emboldened, he strode out across the illuminated ground, pausing
> every few steps to kick at the sand. Sometimes he simply pushed the
> dust aside; sometimes the dust applied pressure of its own, as it
> moved in to occupy the space his foot vacated. But that pressure
> never came out of nowhere: his feet moved as and when he'd willed
> them to move, followed by the dust but never forced to retreat. Nor
> were they thrust without warning into the air

> Each time there was a dust storm the record of future movements would be
> erased, but even in a prolonged period of calm the footprints would overlap,
> conveying very little information.

> 'You already dug twelve holes!' he observed.
> 'And I thought you were messing around with Agata all morning.'
> Azelio made a noncommittal sound.
> 'My plan is to dig up all these plants at the end of the trial and take
> them back to the Peerless for my colleagues to analyse,' Azelio mused.  'So I
> guess that's when I'll see the transition between cultivated and truly
> pristine ground. But right now, in Esilio's terms, we've just dug the plants
> up - so on our terms, we're about to do that. Backwards.' Ramiro said, 'You
> make it sound as if you've been practising timereversed agronomy all your
> life.' 'It's not that hard to see what's going on, if you think it through,'
> Azelio replied lightly.  'But you don't mind following markers like this?
> Evidence of acts you haven't performed yet?' 'It's a little disconcerting,'
> Azelio conceded. 'But I can't say that it fills me with claustrophobia to
> know that I'll carry out the experimental protocols I always planned to carry
> out.'


> He lowered the plant until its roots were in the hole, then
> he started adding soil from the surrounding mound. Some of the soil
> was scooped in with pressure from behind, in the ordinary manner.
> Some appeared to pursue the trowel, the way the dust sometimes
> pursued Ramiro's feet. What decided between the two? Azelio's own
> actions had to be consistent with the motion of the soil, but which
> determined which? Maybe there was no answer to that, short of the
> impossible act of solving in the finest detail the equations that Agata
> was yet to discover, revealing exactly which sequences of events
> were consistent with the laws of physics all the way around the
> cosmos.


> Ramiro's left arm had grown tired from holding the plant in place over the
> hole. He shifted it slightly to make himself more comfortable, but as he
> shifted it back he saw soil rising and adhering to the roots. He stared at
> this bizarre result for a moment, then decided to stop wasting time delaying
> an outcome he had no wish to oppose.  He held the trowel to the side of the
> mound nearest the hole, then drew it closer. The sand followed the blade -
> not adhering to it and needing to be brought along, but gently pushing it. He
> lowered the trowel into the hole then withdrew it; the sand parted from the
> blade and packed itself between the roots of the plant and the side of the
> hole.

> He hesitated, groping for a clearer sense of his role in the task. But
> what could he actually do wrong? So long as he was committed to
> making whatever movements with the trowel were necessary until
> the plant was securely in place, that state of mind and the strictures
> of the environment ought to work it out between themselves.
> He scooped some soil straight into the hole; like the last delivery, it
> clung to the roots. In Esilio's terms, this soil had spent at least a few
> stints packed tightly around the plant; if he could have seen the
> action in reverse, it would have involved nothing stranger than a
> clump of sand finally coming loose.

> But as she moved the broom across the floor, duly concentrating the dust
> ahead of it, other dust began to appear behind it - some of it falling from
> the air, some sliding over the stone to pile up against the bristles. Its
> entropy was decreasing too, as it accumulated from whatever scattered reaches
> of the Surveyor in which it had been lurking.  The net result was that the
> stretch of floor she'd swept remained as dusty as ever.

> But the plants' uptake of nutrients relied on interactions
> between their roots and the native soil at a microscopic level, and
> there was no guarantee that the two systems, left to themselves,
> would simply sort out their differences

> 'Because the test plots are failing,' Agata explained. 'So we need
> to take the explosive up into the hills, turn some rock into soil for
> ourselves - against the Esilian arrow - and see if that imbues the soil
> with the properties that it needs to support plant growth


> 'If we do set off this
> explosive,' he reasoned, 'shouldn't we be able to see some evidence of
> that already?'
> Agata said, 'You mean a crater?'
> 'Yes.'
> 'If we found a site like that, it would be useless to us. It would imply
> that after we set off the bomb, the crater would be gone and the sand
> around it would be rock again.'
> Ramiro scowled. 'Esilio doesn't care what's useful or useless, or it
> wouldn't have killed the plants, would it?'
> 'Esilio doesn't care,' Agata agreed, 'but why would we go ahead and
> set off the bomb there, knowing that it would do us no good?'
> 'Because the crater would prove that we did!' Ramiro replied heatedly.
> 'But as far as we know, there is no such crater.' Agata met his gaze
> openly, trying to reassure him of her Sincerity: she wasn't playing
> some verbal game just to annoy him. 'There is no crater, because if
> we saw it, we wouldn't choose to make it. Esilio can't force our hand;
> whatever happens has to be consistent with everything, including
> our motives. Ramiro said, 'It can't force our hand, but there could still be an
> accident.' 'That's true. But if we saw such a crater, we wouldn't even go near it
> with the explosive.'

> He ran a hand over his face. 'If the plants can't
> bring their arrow to Esilio, why should a bomb do any better?'
> 'The roots of a plant aren't entirely passive,' Azelio replied, 'but
> they do rely on the state of the soil. I don't think the bomb going off
> will rely on anything like that.'
> 'But in Esilian time,' Ramiro protested, 'all the soil we're supposedly going to make with this bomb has to mesh perfectly with a
> backwards explOSion in such a way that it forms a solid rock. How
> likely is that?'
> How likely are the alternatives?' Agata countered. 'How likely is
> it that the explOSive will fail to detonate? How likely is it that we'll
> allow it to explode in an existing crater instead - just to pander to
> Esilio's arrow?'



> She started swinging her pick into the rock face.
> Small chips of stone flew out from the point of impact, stinging her
> forearms, but the rush of power and freedom she felt at the sight of
> the growing excavation was more than enough to compensate.
> In Esilian time, the chips were rising from the ground, propelled into
> the air by conspiracies of time-reversed thermal diffusion, just to aid
> her as she rebuilt the rock. What stronger proof could there be that
> the cosmos had a place for her, with all her plans and choices? One
> day it would kill her, but until then the contract was clear: hardship
> and frustration and failure were all pOSSible, but she would never be
> robbed of her will entirely.


> the lines on the
> rock face formed symbols. The sides of the ridges appeared softened
> and eroded, as if a generation's worth of future dust storms had left
> their mark. But she could still make out most of the message.
> ' ... came here from the home world,' she read. 'To offer thanks
> and bring you ... courage.'
> Azelia said, 'Who thanks whom for what?'
> 'It's from the ancestors,' she said. 'They're going to come here and
> write this. They're going to come here to tell us that everything we've
> done and everything we've been through was worth it in the end.'


> But ever since he'd seen the writing for himself, he'd been unable to stop
> wondering if the message suited him too well. As far as he could recall, he'd
> never consciously planned to commit any kind of hoax.  What he didn't know was
> exactly what his lack of preparation meant. The words were there, nothing could
> change that now. But with every moment that passed it seemed more likely to him
> that the ancestors had nothing to do with it, and that he would find a way to
> write the message himself.


> To feel alive, he needed to feel himself struggling moment by
> moment to shape his own history. It was not enough to look down
> on events from above like a biologist watching a worm in a maze,
> content to note that this creature's actions had never actually gone
> against its wishes.

> nothing helped a plan run more smoothly than having a law of physics on its side


> How could he carve anything into the rock face, if the idea of doing
> it had only come to him after he'd seen the result? Even the choice
> of words hadn't sounded like his own. If he'd only selected them
> because he'd read them, who would have made the choice? No one.
> Agata had told him endlessly: a loop could never contain complexity
> with no antecedent but itself, because the probability would be far
> too low. There could be no words appearing on rocks for no other
> reason than the fact that they'd done so.


> 'We've all hit a dead patch,' Lila said sadly. 'Chemists, biologists,
> astronomers, engineers. Since they switched on the messaging
> system, there hasn't been a single new idea across the mountain.'
> 'You mean no one's been sending back new ideas?' Agata had
> predicted as much - but surely that self-censorship hadn't surprised
> anyone.
> 'Oh, the messages have contained no innovations,' Lila confirmed.
> 'But neither has the work itself.'
> 'I don't understand,' Agata admitted.
> Lila said, 'If people did innovate, the results would leak back to
> them one way or another. I know you believed that they'd be able
> to keep qUiet, so everything would go on as usual. But everything
> has not gone on as usual. We've had no new ideas since the system
> was turned on - because if we'd had them, we would have heard of
> them before we'd had a chance to think of them ourselves. The
> barriers to information flow are so porous now that the knowledge
> gradient has been flattened: the past contains everything the future
> contains ... which means the future contains nothing more than
> the past.'


> What would her own generation be famous for? Rendering
> the creation of new knowledge impossible.

> 'I'm where I need to be.' 'In the administrative sense, or the teleological?'


> Azelio hummed with frustration. 'What's all this talk of replacement? If a
> meteor is going to hit us, it's going to hit us! You can devise as many
> ingenious plans as you like to try to sabotage the system at the very same
> moment, but if there's a rock on its way, nothing you do is going to make it
> disappear.' 'If there's a rock on its way, that's true,' Ramiro conceded.
> 'But until we know that there is, why should we assume that? The history of
> the next twelve stints ends with the messaging system failing; we're about as
> certain of that as we can be. Some sequence of events has to fill the gap
> between that certainty and all the other things we know. So which snippets
> would you rather the cosmos had on hand to complete the story? Just one,
> where a meteor hits the Peerless? Just two: a meteor, or a bomb? Making our
> own preferred version possible won't rule out everything else - but if we
> don't even try, we'll rule out our own best hope entirely.'



> Azelio was looking disoriented. 'I want this to work,' he said
> haltingly. 'But every time I stop and think about it, it feels as if all
> we're doing is playing some kind of game.


> Azelio glanced down at the pile of notes on her desk. 'And doesn't
> everything that could happen, happen? Isn't that what your diagram
> calculus says?'
> 'No.' Agata nodded at the pile. 'Por a start, you can only add up
> diagrams that begin and end in exactly the same way: they all take
> different paths, but their end pOints have to be identical. Getting
> to the disruption with benign sabotage leaves the mountain intact;
> getting there with a meteor strike hardly brings you to the same state.
> And even when the end points are identical, all the alternatives you
> draw for a process just help you find the probability that the process
> takes place. Those alternatives don't all get to happen, themselves.'
> 'Then what makes the choice?' Azelio pressed her. 'When a luxagen
> could end up in either of two places, how does just one get picked?

> Just because
> we don't know the cause of the disruption, that doesn't mean that every cause
> we can imagine will coexist. If you want history to unfold a certain way,
> forget about wave mechanics. What matters now are the usual things: who we are,
> what we do, and a certain amount of dumb luck.'

> Azelio put the diagram down. 'So if there's a meteor coming, how
> do I stop it? Or avoid it?'
> 'You can't,' Agata replied. This was the sticking point they always
> reached. 'Not if the disruption is the proof that it hits us.'
> 'Then what difference does it make "who we are" and "what we
> do"?' Azelio asked bitterly. 'If I go through the motions of enacting
> something more benign ... how will that help? If there's a murderer
> trying to kill your family, you don't protect them by moving your
> own tympanum to match the threats being shouted through the
> door. Or do you really believe in safety through reverse ventriloquism?'
> Agata wrapped her arms around her head in frustration. 'We don't
> know that there's a murderer at the door! We don't know that there's a
> meteor on its way!'


> 'This is your pass,' the woman
> explained, handing her a red disc. 'Please don't lose it.'
> 'Do I lose it?' Agata asked.
> 'Of course you don't,' the guard replied. 'Because I asked you not
> to.' 'Right.' Agata suppressed a shiver.

> 'I didn't make the inscription,' Tarquinia declared. 'I went out there to try,
> but nothing happened: no shards of stone rose from the ground to meet the
> chisel. I tried different tools, different movements ... but I couldn't unwrite
> those symbols. If anything, when I left they were sharper than I'd found them -
> as if all I'd done was make the message less clear for Agata and Azelio than if
> I'd stayed away completely. I wasn't the author of those words. Someone else
> must be responsible for them.'

> I wish I could talk to them,' she said. 'I wish I could thank
> them. I wish I could tell them that it wasn't for nothing, that it ended
> well.' Clara said, 'If that's what you want, then I believe you'll find a
> way.'

# Simplicial approximation: maps can be approximated by simplicial maps (TODO)



# Limit is right adjoint to diagonal

Suppose a category `C` possesses all small limits. This means that for any index category `J`
and functor `F: J -> C`, the limit `lim F:C` exists in C. We wish to show that the functor
`const: C -> (J -> C)` given by `const(c) = \j. c` has a right adjoint `lim: (F -> C) -> C`
which produces the limit of a diagram. So we are saying that `const |- lim`.  So we need
to provide a morphism `(const c -> diag) -> (c -> lim diag)`. A morphism
`const c: J -> C -> diag: J -> C` is a natural transformation between the `const c` functor
and the `diag` functor. This is, by definition, a cone with apex `c`. However, every cone
factors through the limit cone of the diagram `diag`. Thus, we get a morphism `(c -> lim diag)`,
from the fact that the cone with apex `c` factors through the cone with apex `lim diag`, as `lim diag`
is the universal cone.

This establishes that limit is right adjoint to diag. From this, can we get a cheap proof
that right adjoints preserve limits ? Suppose `L: C -> D`, `R: D -> C` are adjoint `L |- R`.
Now, consider limits in `D`. This can be considered by taking the category `(J -> D)`.
We get an adjunction `const: D -> (J -> D) |- lim: (J -> D) -> C`.

```text
C<-g-D <-lim-   (J -> D)
C    D          (J -> D)
C-f->D -const-> (J -> D)
```

composing gives us:

```text
C <-g- D <-lim-   (J -> D) <-f._ -  (J -> C)
C      D          (J -> D)          (J -> C)
C -f-> D -const-> (J -> D)  -g._ -> (J -> C)
```

I'm not sure how to proceed further, but I feel that it must be possible to proceed! I lack
the technology, unfortunately, to make this go through.


# Working out why right adjoints preserve limits.

We have `L: C -> D` and `R: D -> C` adjoints functors,
so we have the condition:
1. Hom(L(a): D, b: D) ~= Hom(a: C, R(b): C)

We will also show that `Hom(A, -)` preserves limits:

```
Hom(a, lim (F: J -> C):C) : Set ~= lim ({Hom(a, -) . F}: J -> Set): Set
 Hom(a, lim (F: J -> C):C) : Set ~= lim (\j. Hom(a, F(j)): J -> Set): Set
```


The above statement, fully elaborated with all the types looks as follows:

```
lim :: (J -> K) -> K
Hom(a: C, {lim (F: J -> C)}:C ): Set ~=
lim (\j. Hom(a, F(j)): J -> Set): Set
```

Furthermore, we also know from the Yoneda embedding, that `x ~= Hom(x, -)` for all `x`.
Given these two facts, we can speedily derive that a right adjoint preserves limits:

```
Hom_C(a:C , R(lim F: J -> D)): Set
= Hom_D(L(a), lim F: J -> D) [Adjunction]
~= {lim (\j. Hom_D(L(a), F(j)): J -> Set}: Set [Hom lim = lim Hom]
~= {lim (\j. Hom_C(a, R(F(j)))): J -> Set}: Set [Adjunction inside lim]
~= Hom_C(a, {\j. R(F(j))}: J -> C): C [lim Hom = Hom lim]
~= Hom_C(a, R . F)
```



#### `Hom(a, -)` preserves limits:

We wish to show that the `Hom(a, -)` functor preserves limits. That is:

```
Hom(a, lim F: J -> C): Set ~= lim(\j. Hom(a, F(j)): J -> Set): Set
```

Let's start with `Hom(a, lim F: J -> C): Set`. An element of this
is a morhism `arr: a -> lim F` from `a` to the apex
of the limit cone `lim F`. We need to translate this into a `lim(\j. Hom(a, F(j)): J -> Set): Set`,
which is a family of morphisms from each `a` to each `{ F(j) : j in J}`. This is obtained
by composing the projection maps `pi(j): lim F -> F(j)` with `arr: a -> lim F` to
get `pi(j) . arr : a -> F(j)` which lives in `Hom(a, F(j))`. We get the limit by considering
the family of these maps, as the Limit in `Set` is just a product with coherence conditions,
and an element of the limit is a tuple/family with coherence conditions.

To go the other way around, suppose we have an element in the limit
`lim(\j. Hom(a, F(j)): J -> Set): Set`. This means that we have a family of maps from `a` to `F(j)`
which obeys the coherence conditions. This means that `a` is the apex of some valid cone. But we
know that `lim F` is the universal cone, thus the `a` cone must factor through `lim F`. This gives
us a factoring map `factor: a -> lim F`. The map `factor` lives in `Hom(a, lim F)`. This gives the other
way round.


Thus, the two sets are equivalent, and hence `Hom(a, -)` preserves limits (almost by definition).


# Limit/Colimit/Cone/Cocone: the arrows are consistent!

I sometimes wonder if a product is a limit or a colimit (not really, because
I remember that limits are product + equalizers, but it makes for a nice story
nonetheless). I realised that the arrows of a cone/co-cone are always consistent.
Since a cone has arrows _out_ of the apex, the universal cone is given by arrows _into_ the apex
to be able to compose arrows
Similarly, since a co-cone has arrows _into_ the apex, the universal co-cone must have arrows
_out_ of the apex into the apex of another co-cone. Thus a terminal object must be a limit/cone,
since we want arrows _into_ it (by universality), and that  is compatible if the cone itself has arrows
_out_ of the apex, ie, a limit, since a limit is a product and thus has projections out of it.



# Representable Functors

imagine image of functors $F: C \rightarrow D$, $G: C \rightarrow D'$ as lying in sheets.
Then a nautural transformation $\eta$ goes "perpendicular to these sheets. Often,
knowing the natural transformation at one point determines it at every other point, if the
category is rich-in-morphisms (eg. Set is very rich in morphisms). Now if we think of $[C, Set]$
(category of functors from $C$ to $Set$), we have all the Hom functors here, such as $Hom(x, -)$,
$Hom(y, -)$, $Hom(z, -)$ etc. We may have some other functor $F: C \rightarrow Set \in [C, Set]$.
If this functor $F$ is isomorphic to some Hom-functor $Hom(a, -)$, then the functor $F$ is said
to be a representable functor since it is represented by a single object $a$ through $Hom(a, -)$.
PArametric polymorphism in haskell, that forces us to write one formula for all types makes
these functions automatically natural transformations. So any implementation of a function
such as `foo :: Maybe a -> [a]` will automatically be a nautral transformation (?)


Let's try and check if the list functor is representable. If I pick `foo :: (Integer -> x) -> [x]`
this direction can be implemented as `foo f = fmap f [0,1..]`. On the other hand, the
other way round does not work: `foo:: [x] -> (Integer -> x)` can't always be implemented. It's
not representable (proof by haskell intuition).

```hs
{-# LANGUAGE ExplicitForAll #-}
{-# LANGUAGE RankNTypes #-}
{-# LANGUAGE TypeFamilies #-}
{-# LANGUAGE InstanceSigs #-}
type Hom a b = a -> b
type Nat f g = forall x. f x -> g x
class Representable f where
    type Rep f :: * -- the representing object o whose Hom(o, -) ~= f
    -- tabulate :: Nat (Hom (Rep f)) f
    -- tabulate :: forall x. Hom (Rep f) x -> f x
    tabulate :: forall x. ((Rep f ->  x)) -> f x
    -- index :: Nat f (Hom (Rep f))
    -- index ::  forall x. f x ->  (Hom (Rep f) x)
    index ::  forall x. f x ->  (Rep f -> x)


```

`Stream` is representable:

```hs
data Stream a = Cons a (Stream a)
instance Representable Stream where
   type Rep Stream = Integer
   tabulate i2x = go i2x 0 where
      go :: (Integer -> x) -> Integer -> Stream x
      go f i = Cons (f i) (go f (i+1))

   index :: Stream x -> Integer -> x
   index (Cons x xs) n = case n of 0 -> x; not0 -> index xs (n-1)
```

In general, things that are products tend to be representable, while things
that are sums tend not to.

#### Every presheaf is a colimit of representables

- Roughly, every presheaf $P: C \rightarrow Set$ can be written by "gluing" (union + equivalence relation/colimit)
  functors of the form $Hom(a_i, -)$.
- Let $P$ be the presheaf. To say that it
  can be written as a colimit of Hom-sets, this means that we have some (yet unknown)
  diagram $dgrm: J \rightarrow [C, Set]$ such that $P$ is the colimit of such a
  set.
- Unwrapping what this means, it means that we have a functor $dgrm: J \rightarrow [C, Set]$ such that
  the image of $J$ is always a hom-set. That is, $dgrm(j \in J) = Hom(c_j, -) \in [C, Set]$.
- Furthermore, since $P$ is a colimit, we have arrows of the form $dgrm(j) = Hom(c_j, -) \rightarrow P$.
- Recall that such an arrow is a natural transformation between $Hom(c_j, -)$ and $P$.
- Also recall that by the Yoneda lemma, such natural transformations $Hom(c_j, -) \rightarrow P$ are in natural bijection
  with elements in $P(c_j)$. So at some point, we'll probably need to pick elements $P(c_j)$. =
- We're not done yet, this is what one part of  what it means to be a colimit; we also need all the diagrams to commute!
- (1) the embedding natural transformations $Hom(c_j, -) \rightarrow P$ arrows
  commute with image of the arrows in $J$, of the form $Hom(c_j, -) \rightarrow Hom(c_{j'}, -)$.
- (2) that $P$ is the universal object in $[C, Set]$ such that
  this rats nest of hom-sets embeds perfectly into $P$.
- Now the problem boils down to designing a $dgrm: J \rightarrow [C, Set]$ which picks out enough
  hom-sets and relations between the hom-sets such that $P$ is the colimit of
  such a $dgrm$.
- The idea, once, again, goes back to (a) Yoneda, and (b) Grothendeick.
- It appears that to be able to pick out such embedding arrows for the co-cone
  $Hom(c_j, -) \rightarrow P$, we need elements $P(c_j)$.
- Soo let's build a category that does exactly that; This new category called as a _Grothendieck construction_.
- Given a category $C$ and a presheaf $P: C \rightarrow Set$, this new category called $el(P)$
  has as objects pairs of the form $(c \in C, u \in P(c))$.
- So we have a pair of an abstract object $c \in C$, and an element of its set $u \in P(c)$, as $P(c) \in Set$, as $P$ is a presheaf, thus has the type
  $P: C \rightarrow Set$.
- The arrows in this category $el(P)$ are derived from arrows in the original category $c \xrightarrow{a} d$.
  Such an arrow lifts to a set-function thanks to the presheaf, $P(c) \xrightarrow{P(a)} P(d)$.
- If we now have $u \in P(c)$, we can then build an arrow in $el(C)$ which takes $(c \in C, u \in P(c)) \xrightarrow{el(P)(a)} (d \in C, P(a)(u) \in P(d))$.


Picture speaks a thousand words:
```
C | c -a→ d
Set | P(c) -P(a)→ P(d)
Set | u ∈ P(c) -P(a)→ d ∋ P(a)(u)
el P | (c∈C, u∈P(c))
el P | (c∈C, u∈P(c)) -el a→ (d∈C, P(a)(u)∈P(d))
```

- So, this category gives us a way to "locate ourselves" within the set $P(c)$, which will be instrumental
  in creating the arrows (natural transformations) of the form $Hom(c_j, -) \rightarrow P(c_j)$, as asked of us by the cocone.
- This also hints at why we use colimis and not limits: because the yoneda goes from the $Hom(c_j, -)$ to $P$,
  we can only conjure arrows into $P$ via Yoneda, thereby forcing us to use a colimit.

- We claim that we should choose the diagram category as $J\equiv el(P)$, with the diagram functor $dgrm: el(P) \rightarrow [C, Set]$
  given by $dgrm(c \in C, u \in P(c)) : el(P) \equiv Hom(c, -) : [C, Set]$.
- This embeds $(c, u \in P(C))$ where $u$ is a way to locate $P$'s view of $C$ as a Hom-set $Hom(c -)$.
- To give the natural transformation from the image of the diagram to the apex of the cocone $P$,
  we use Yoneda: We need an arrow $Hom(c, -) \rightarrow P$, which we know is in bijection with elements of $P(c)$ through yoneda.
- Luckily, we have $u \in P(c))$ to invoke yoneda, so we build the arrows from $dgrm(c, u) = Hom(c, -)$ to $P$,
  given by applying Yoneda to $u \in P(c)$.
- Thus, we can at least form a cocone. Whether the arrows of the "base" of
  the cocone commute with the apex-pointing arrows, and whether this is universal is to be checked next.
- Given some other cocone $Q \in [C, Set]$, with co-cone morphisms $\sigma_j: Hom(c_j, -) \rightarrow Q$, we need to
  create a natural transformation $\theta: P \rightarrow Q$. Let's do this pointwise.
- For some $c \in C$, we need to build a map $\theta_c: P(c) \rightarrow Q(c)$. Since the domain and codomain are pointwise,
  let's pick some element $x \in P(c)$.
- See that this can be seen as an element $(c \in C, x \in P(c)$ which is an element of the category $el(P)$.
- But, recall that this was our index category $el(P)$.
  Thus, there is going to be an arrow $dgrm((c \in C, x \in P(c)) = Hom(c, -) \xrightarrow{q(c,x)} Q$ since $Q$ is a cocone.
- But since $q(c, x) \in [Hom(c, -), Q]$, it's an element of $Q(c)$. We have thus found a way to map $P(c)$ into $Q(c)$
  by "pulling back" into the index category and then "pushing forward" via Yoneda. [What the fuck is actually happening here?]

#### Simplified construction of $el(P)$

- Recall that $el(P)$ consisted of a pair $(c \in C, u \in P(c))$. We know from Yoneda that set elements of $P(c)$ are in bijection with natural
  transformations $eta_c: Hom(-, c) \to P$.
- Thus $el(P)$ consists of _all_ natural transformations $\eta_c: Hom(-, c) \Rightarrow P$ [for all objects $c$].
- The arrows in $el(P)$ between $\eta: Hom(-, x) \Rightarrow P$ and $\mu: Hom(-, y) \Rightarrow P$ are pushforwards of arrow
  $x \xrightarrow{f} y$ (given by $\lambda h. f \circ h$) which make the diagram commute:

```text
              η
Hom(-, x) >------->P
   v               ^
   |arrow:        /
   | \h -> f.h   / μ
   v            /
Hom(-, y)>-----*
```

- Consider the functor $J: el(P) \to [C^{op}, Set]$ which sends each natural transformation $\eta:Hom(-, x) \Rightarrow P$ to
  just $J(\eta: Hom(-, x) \Rightarrow P) \equiv Hom(-, x)$ (ie, forget the mapping, just keep the domain of the natural transformation.
- We claim that $P$ is the cocone of the functor $J$. So we must have mappings from each $Hom(c, -)$ into $P$.
- These mappings from $Hom(c, -)$ into $P$ are given by "un-forgetting" the data we forgot when mapping $\eta:Hom(-, c) \Rightarrow P \mapsto Hom(-, c)$.
  These commute by the construction of $el(P)$.
- (Are these the only choices of maps? Maybe there are others, not just the ones we "un-forgot"!)
- Next we need to check that $P$ is universal. Consider some other $Q: C^{op} \Rightarrow Set$. We must show a map $\alpha: P \Rightarrow Q$
  (ie, the cocone $Q$ factorizes through $P$, or $P$ is initial cocone.).
- Let's do this pointwise. So we want to define a family $\alpha_k: P(k) \Rightarrow Q(k)$.
- Pick some element $e \in P(k)$.
  This corresponds to some natural transformation $\eta_e: Hom(-, k) \rightarrow P$.
  We know that we have a corresponding
  $\eta_e': Hom(-, k) \rightarrow Q$. this is some element $e' \in Q(k)$. So we are forced to set $e \mapsto e'$ when we try to map $P(k)$ to $Q(k)$.
-  This works for arbitrary $k, e$, so the entire map is determined. This proves that $P$ is terminal cocone.


- [Reference](https://mysite.science.uottawa.ca/phofstra/MAT5147/presheaves.pdf)
- [Density theorem proof](https://en.wikipedia.org/wiki/Density_theorem_(category_theory)#Proof)


# Why terminal object is a limit

1. Thinking in Set, the terminal object is `{*}`, which is the empty product of
   sets. Hence, the terminal is a type of product, which is a limit.
2. What does the terminal `{*}` project onto? It should project onto its
   components, since its a limit. But recall that it was the limit of ZERO
   objects. `{*}` vacuously projects into zero objects [ie, we're not obliged to
   construct a projection]
3. Think about products again. the product is universal such that any other
   "candidate for the product" must factor through a projection onto the
   product. Similarly, the terminal is universal such that any other "candidate
   for the terminal" (literally all other objects) must factor through the
   terminal [ie, must map into the terminal].



# Excluded middle is not false in intuitionistic logic

```hs
{-# LANGUAGE EmptyCase #-}

data Void
absurd :: Void -> a
absurd v = case v of
type NOT x = x -> Void
type FALSE x = x -> Void
type LEM x = Either x (NOT x)

type NOTFALSE a = NOT (FALSE a)
lemNotFalse :: NOTFALSE (LEM a)
-- lemNotFalse :: (LEM a -> Void) -> Void
-- lemNotFalse :: (Either a (a -> Void) -> Void) -> Void
lemNotFalse f = f $ Right $ \a -> f (Left a)

lemFalseExplodes :: FALSE (LEM a) -> anything
-- lemFalseExplodes :: LEM a -> Void
lemFalseExplodes lem = absurd (lemNotFalse lem)
```

# Yoneda Lemma and embedding

```hs
type Hom a b = (a -> b)
type Nat f g = forall x. f x -> g x
```
Yoneda, which states that $[C, Set](F(-), Hom(a, -)) \simeq F(a)$:

```
type YonedaLHS f a = Nat (Hom a) f
```


```
rhs2lhs :: Functor g => g a -> YonedaLHS g a
-- rhs2lhs :: g a -> (Nat (Hom a) g)
-- rhs2lhs :: g a -> (forall x. (Hom a) x ->  g x)
-- rhs2lhs :: g a -> (forall x. (a -> x) -> g x)
rhs2lhs ga = (\a2x -> fmap a2x ga) :: g x
```

`rhs2lhs` is a lot like an enriched continuation, where
we are given a value `(g a)`, and we need to produce
an "enriched" continuation handler, which when given
a use `(a -> x)` produces not an `x`, but a `g x`.


```hs
lhs2rhs :: Functor g => YonedaLHS g a -> g a
-- lhs2rhs :: Nat (Hom a) g -> g a
-- lhs2rhs :: (forall x. (Hom a x) -> g x) -> g a
-- lhs2rhs :: (forall x. (a -> x) -> g x) -> g a
-- set x = a
-- lhs2rhs :: ((a -> a) -> g a) -> g a
lhs2rhs cont = (cont (id :: Hom a a)) :: g a
```

in `lhs2rhs`, given an enriched continuation handler
`forall x. (a -> x) -> g x`, and we need to produce a `g a`.
As with regular continuations, we feed in the `id` function
to recover the trapped continuation value.

```hs
type List a = [a]
type Nat f g = forall x. f x -> g x
listyo :: (Nat (Hom a) List) -> [a]
-- listyo :: (forall x. (Hom a x) -> List x) -> [a]
-- listyo :: (f: forall x. (g: a -> x) -> [x]) -> [a]
-- implement f, is to use g multiple times
-- f g = [g a1, g a2, ... g an] = fmap g [a1, a2, ... an]
-- f id = [id a1, id a2, ... id an] = [a1, a2, ... an]
listyo f = f id

-- F = [.]
listyo' ::  [a] -> (forall x. (a-> x) -> [x])
listyo' as = \f -> fmap f as
```

When we specialize Yoneda to lists, we are led to the idea
that a continuation of the form `(a -> x) -> [x]` must contain
`[a]`s which it uses to produce multiple `x`s.



```
-- F = (b -> .)
-- pick x = a
-- ((a -> a) -> (b -> a) -> (b -> a)
-- Nat(Hom(a, -), F) ~= F a
-- type Hom a b = (a -> b)
-- c -> Hom (c, -)
-- a, b. arrows ∈ Hom (a, b)
-- Hom (a, -), Hom(b, -). arrows ∈ Nat Hom (a, -) Hom(b, -)
--
-- a, b. arrows ∈ Hom (a, b)
-- Hom (-, a), Hom(-, b). arrows ∈ Nat Hom (-, a) Hom(-, b)
contrayo :: Nat (Hom a) (Hom b) -> Hom b a
contrayo :: (forall x. (a -> x) -> (b -> x)) -> (b -> a)
contrayo f = f id

contrayo' ::   (b -> a) -> (forall x. (a -> x) -> (b -> x))
contrayo' b2a = \a2x -> a2x . b2a
```

When we specialize Yoneda to `b -> -`, we are led to the idea
that a continuation of the form `(a -> x) -> (b -> x)` must contain
plumbing to turn `b`s into `a`s: ie, it must contain a function `b -> a` .

```
-- F = id .
type Id x = x
-- Nat(Hom(a, -), Id - ) ~= Id a
-- Nat(forall x. (a -> x), Id x) ~= Id a
-- Nat(forall x. (a -> x) -> x) ~= a
idyo :: (forall x. (a -> x) -> x) -> a
idyo k = k id

idyo' ::  a -> (forall x. (a -> x) -> x)
idyo' a = \k -> k a
```

specializing to `id` recovers usual continuations.

In total, Yoneda tells us that from every enriched continuation
`ContF a g = Nat (Hom a) g = forall x. (a -> x) -> g x`,
we can recover a `g a`. Hence, there is a bijection between `g a` and
`ContF a g`

#### Yoneda embedding

The yoneda embedding follows from the lemma. The lemma tells us that `Nat(Hom(a, -), F) ~= F(a)`.
Pick `F = Hom(b, -)`. This gives `Nat(Hom(b, -), Hom(a, -)) ~= Hom(b,  a)` Thus, if
we consider the mapping `C -> [C, Set]` given by sending `a` to `F(a)`,
we also preseve the `Hom` sets as natural transformations, since `Hom(b, a)` is isomorphic
to `Nat(Hom(b, -), Hom(a, -))`. Thus, we get a full and faithful embedding of the original category
into the `Hom` category.


# GHCID

- [ghcid](https://hackage.haskell.org/package/ghcid) + tmux is a nice way to get a REPL/IDE
  like experience for haskell with minimal fuss.

# Character theory

I jot down the rough proof sketches of character theoretic facts for quick reference.
Fix a group $G$. A group representation of $G$ is a group homomorphism from the group
to the automorphism group of a complex vector space $V$: Formally,
$f: G \rightarrow Aut(V)$. A direct sum of representations $f: G \rightarrow Aut(V)$, $f': G \rightarrow Aut(W)$
is the obvious extension of the maps $f \oplus f': G \rightarrow Aut(V \oplus W)$,
given by $(f \oplus f')(g) = \lambda v. f(g)(v) \oplus f'(g)(v)$.
A representation is said to be irreducible if it cannot be written as the
direct sum of two non-trivial representations. A character is the trace of
a representation. An irreducible character is the trace of an irreducible representation.

#### All finite group representations are unitary representations

Given a representation $f: G \rightarrow Aut(V)$, we construct
an _invariant_ inner  product, that is, one where $\langle f(g)(v) | f(g)(w) \rangle = \langle v | w \rangle$.
This maps the representation unitary, since it preserves this special inner product.
The idea is to begin with some _arbitrary_ inner product $[v, w]$ which we can always
induce on $V$ (pick a basis). Then, we build an "averaged" inner product
given by $\langle v | w \rangle \equiv \sum_{h \in G} [ f(h)(v) | f(h)(w) ]$.
Intuitively, this inner product is invariant because on considering $\langle f(g)(v) | f(g)(w) \rangle$,
the definition will contain $[f(h)(f(g)(v)) | f(h)(f(g) w)] = [f(hg)(v) | f(hg)(w)]$,
which is a re-indexing of the original sum.
Hence, the representation $f$ preserves this inner product,
and we can thus study only unitary representations (which are much simpler).
From now on, we assume all representations are unitary.

#### Representation has same value for the entire conjugacy classe

Since all representations are unitary, the image of $f(ghg^{-1}) = f(g) f(h) f(g)^{-1}$
is going to be a change-of-basis of $f(h)$, and thus does not
actually change the automorphism given by $f(h)$. Hence, representations are
the same for an entire conjugacy class. Such functions which are constant
on a conjugacy class is called as a _class function_.


#### Morphism between representations / intertwining

A map between two representations, $f: G \rightarrow V$, $f': G \rightarrow W$
is given by $\eta: V \rightarrow W$ if the natural diagram commutes:

```
V --f--→ V
|        |
η        η
↓        ↓
W --f'-→ W
```
such a map $\eta$ is called called as an intertwining map or an equivariant map.


#### Schur's lemma

The only equivariant maps between irreducible representations is either the
zero map or a **scalar multiple** of the identity map. This is stronger than
saying that the equivariant map is a diagonal matrix; scalar multiple of
identity implies that all dimensions are scaled uniformly.

The main idea of the proof is to show that the kernel and image of the
intertwining map is an irreducible subspace of $f, f'$ retrospectively. Since
the maps are irreducible, we must have the the intertwining is either the zero
map, or a map into the full group. This forces the map to be zero or a scalar
multiple of the identity.

One way to look at this is that for irreps $f: G \rightarrow V$ and
$f': G \rightarrow W$, the dimension of $Hom(V, W)$ is either 0 or 1 (scalings of identity).



#### Schur orthogonality relations


We consider representations "one matrix index" at a time, and show that
the matrix entries of irreducible representations is going to be orthogonal
The proof is to consider representations $\alpha: G \rightarrow \mathbb GL(V)$
$\beta: G \rightarrow \mathbb GL(W)$, and an intertwining map $T: V \rightarrow W$.

How do we involve all of $\alpha, \beta, T$ at once? Recall that since $T$ is an intertwining, we must have:

$$
T(\alpha(g)(v)) = \beta(g)(T(v))
$$

Now, since $\beta$ is invertible (it must be since it's a member of $GL(W)$), I can rewrite
the above as:

$$
\beta^{-1}(g)(T(\alpha (g)(v)) = T(v)
$$

This needs that $T: V \rightarrow W$ is an intertwining map. Can we generalize this
to any **linear map**? Suppose that $L: V \rightarrow W$ is a **linear map**, not
necessary intertwining. Let's induce an intertwining map from $L$:

$$
\begin{aligned}
&\overline{L}: V \rightarrow W \\
&\overline{L}(v) \equiv 1/|G|\sum_{g \in G} \beta(g)^{-1} T \alpha(g) v
\end{aligned}
$$

We average the intertwining condition of $T(v)$ to produce an appropriate $\overline{L}(v)$.
Is this an intertwining? Yes, because when we compute $\beta(h)^{-1} \overline L \alpha(h)$,
the averaging trick winds up shifting the index, exactly as it does for the inner product:

$$
\begin{aligned}
&\beta(h)^{-1} \overline L \alpha(h) \\
&=\beta(h)^{-1} \left( \sum_{g \in G} \beta(g)^{-1} L \alpha(g) \right) \alpha(h) \\
&=\sum_{g \in G} \beta(gh)^{-1} L \alpha(gh) \\
&=\sum_{g \in G} \beta(gh)^{-1} L \alpha(gh) \\
&=\sum_{kh^{-1} \in G} \beta(kh^{-1}h)^{-1} L \alpha(kh^{-1}h) \\
&=\sum_{kh^{-1} \in G} \beta(k)^{-1} L \alpha(k) \\
&= \overline{L}
\end{aligned}
$$

Thus, for every linear map $L: V \rightarrow W$, if the representation $\alpha$ is not
isomorphic to the representation $\beta$, then $\overline{L} = 0$, or:

$$
\begin{aligned}
&\sum_{g \in G} \beta(g)^{-1} L \alpha(g) = 0 \\
&\left( \sum_{g \in G} \beta(g)^{-1} L \alpha(g) \right)[i][j] = 0[i][j] \\
&\sum_{g \in G} \beta(g)^{-1}[i][p] L[p][q] \alpha(g)[q][j] = 0[i][j] \\
&\text{($\beta$ is unitary)} \\
&\sum_{g \in G} \beta(g)*[p][i] L[p][q] \alpha(g)[q][j] = 0[i][j] \\
\end{aligned}
$$

The above equality holds **for all** indexes $i, j$ and **for all** choices
of $L[p][q]$ (since $L$ can be **any linear map**). In particular,
we can choose $L[p][q] = \delta[p][r] \delta[q][s]$ for **arbitrary** $r, s$.
This gives us the equation:

$$
\begin{aligned}
&\sum_{g \in G} \beta(g)*[p][i] L[p][q] \alpha(g)[q][j] = 0[i][j] \\
&\sum_{g \in G} \beta(g)*[p][i] \delta[p][r] \delta[q][c] \alpha(g)[q][j] = 0[i][j] \\
&\sum_{g \in G} \beta(g)*[r][i] \alpha(g)[s][j] = 0[i][j] = 0\\
\end{aligned}
$$

This tells that we can choose any index $[r, i]$ and index $[i, j]$ and these will be orthogonal,
when viewed as vectors "along" the set of matrices.

<img src="./static/repr-theory/schur-orthogonality.png">

If the representation is a one-dimensional representation/character, then we have no freedom
in indexing, and the above becomes:


$$
\begin{aligned}
&\sum_{g \in G} \beta(g)* \alpha(g) = 0[i][j] = 0
\end{aligned}
$$

Thus, different characters are all orthogonal.

#### Inner product of class functions

we impose an inner product relation on the space of class functions (complex valued functions
constant on conjugacy classes) $G \rightarrow \mathbb C^\times$, given by
$\langle f | f' \rangle \equiv 1/|G| \sum_{g \in G} f(g) \overline{f'(g)}$
where $\overline{f'(g)}$ is the complex conjugate.

Using the Schur orthogonality relations, we immediately deduce that the inner product
of two irreducible characters can be viewed as the schur orthogonality applied to their
(only) matrix entry at location (1, 1). Thus, irreducible characters will be orthogonal,
and equal characters will have inner product 1.


#### Regular representation

The "Cayley-style" representation one would naturally dream up. For a group $G$,
build a vector space $V$ whose basis is given by elements of $G$. Have $g \in G$
act on $V$ by seding $v_h$ to $v_{gh}$. Ie, act with $g$ as a permutation on $V$.
This gives us a "large" representation. For example, the permutation group of $n$
letters will have a regular representation of $n!$ basis vectors.

This representation contains every irrep. The idea is to show that the dot
product of the trace of the regular representation with every other irrep is
nonzero.  Furthermore, since the regular representation has finite dimension,
this tells us that there are only finitely many irreps: the irreps correspond
to subrepresentations, and a finite representation only has finitely many
subrepresentations. This makes the idea of classifying irreps a reasonable task.


##### Character of the regular representation

**Theorem:** The character $r_G$ of the regular representation is given by $r_G(1) = |G|$,
$r_G(s) = 0$ for $s \neq 1$.

- The matrix for the identity element is the identity matrix, and the size
  of the matrix is the size of the vector space, which is $|G|$ since
  there's a basis vector for each element of $G$. Thus, $r_G(1) = |G|$.
- For any other element $g \in G$, the regular representation will be a permutation matrix
  with no fixed points. Thus, the diagonal of the matrix is all zeros, and hence $r_G(g) = 0$.

##### Regular representation contains all other irreps

The inner product of the character of the regular representation with any other
irrep $\alpha$ is going to be:

$$
\begin{aligned}
& \langle r_G | \chi_\alpha \rangle  = 1/|G| \sum_{g \in G} r_G(g)* \chi_\alpha(g) \\
&= 1/|G| (r_G(1) \cdot \chi_\alpha(1)) \\
&= 1/|G| (|G| \cdot 1) \\
&= 1
\end{aligned}
$$

Thus, the regular rep contains the other irreps, since the character of the regular rep has non-zero
inner product with irrep, and irrep characters are all orthogonal.

#### Abelian groups are controlled by characters

Since abelian groups map to automorphism that all commute with each other, we can
simultaneously diagonalize these matrices. Thus, we only need to consider
the data along each diagonal, which is independent. This reduces the representation
to a direct sum of scalars / 1D representations / characters.

#### Number of irreducible representations

Recall that the characters of irreducible representations are orthogonal. Also,
the dimension of the space of class functions is equal to the number of
conjugacy classes of the group $G$, since a class function takes on a distinct
value over each conjugacy class, so there are those many degrees of freedom.
This tells us that the number of irreducible representations is at most
the number of conjugacy classes of the group.


# Cofibration

```
A --gA[t]--> X
|           ^
i           |
|           |
v           |
B >-gB[0]---*
```

The data $(A, B, i)$ is said to be a cofibration  ($i$ like an inclusion $A \rightarrow B$)
iff given any homotopy $gA[t]: [0, 1] \times A \rightarrow X$, and a map
downstairs $gB[0]: B \rightarrow X$ such that $gB[0] \circ i = gA[t](0)$,
we can extend $gB[0]$ into $gB[t]$. We see that this is simply
the HEP (homotopy extension property), where we have a homotopy of subspace
$A$, and a starting homotopy of $B$, which can be extended to a full homotopy.



#### Lemma: Cofibration is always inclusion (Hatcher)

#### Pushouts

```
A <-i- P -β-> B
```

The pushout intuitively glues $B$ to $A$ along $A$'s subspace $P$. For this
interpretation, let us say that $P$ is a subspace of $A$ (ie, $i$ is an
injection). Then the result of the pushout is a space where we identify
$\beta(p) \in B$ with $p \in A$.  The pushout in Set is  $A \cup B/ \sim$
where we generate an equivalence relation from $i(p) \sim \beta(p)$. In
groups, the pushout is amalgamated free product.

```hs
-- | HoTT defn
f :: C -> A
g :: C -> B
inl :: Pushout A  B C f g
inr ::  Pushout A B C f g
glue :: Π(c: C) inl (f(c)) = inr(g(c))
```

Suspension:

```
1 <- A -> 1
```

Suspension can "add homotopies". Example, `S1 = Susp(2)`.

```
A --f--> P
|       |
|i      |i'
v       v
B -----> B Uf P
```

We want to show that $P \xrightarrow{i'} B \cup_f X$
is a cofibration if $A \xrightarrow{i} B$ is a cofibration.



Reference: [F. Faviona, more on HITs](https://www.youtube.com/watch?v=zn0nAXtoMtU)

# Emily Riehl Contrability as uniqueness

- untyped lambda calc/simply typed is topology of computation.
- dependent lambda calc/topos theoretic interpretation gives extensional mltt. Diagonal is identity type.
- challenge: intensional in topological setting. Path space is the identity type.

# Cofactor as derivative of determinant

I saw this at [math.se](https://math.stackexchange.com/questions/4128999/does-taking-derivative-of-determinant-of-a-matrix-with-respect-to-an-entry-give),
that one can define the cofactor of index $A[i][j]$ of a matrix $A$ as $\frac{\partial A}{\partial A[i][j]}$ which I think is quite cool.




# Homology, the big picture

First, there was nothing. Then, we decided we want homology. We start out by baby-stepping with
simplicial homology. We rapidly abandon this in favour of singular homology, since it's easier to define
notions of chain morphisms with singular homology. We want to know when spaces have the same homology/chain complex.
A reasonable idea is to prove that when the map between spaces is homotopic to identity, the chain complex
is identical. During the course of the proof, we feel the need for a notion of "chain equivalence", and thus we
we are led to define the notion of [chain homotopy](https://en.wikipedia.org/wiki/Homotopy_category_of_chain_complexes), and
more generally, the homotopy category of chain complexes.

Next, we want the long exact sequence of homology connecting a space to its
quotient. To get here, we first consider relative homology, connecting a space
to a subspace. Next, we are led to build the
machinery of excision which tells us that relative homlogy is unchanged on
removing a subspace. Finally, we craft "good pairs", which are spaces for whom
the relative homology sequence will be equivalent to the quotient long exact sequence.
Excision lets us prove that relative homology is equal to quotient homology for good pairs.

Once we have excision, we use it to show that show that (1) simplicial and singular
homology agree, and (2) construct the Mayer Viteoris sequence (the Kunneth of homology).


#### Chain equivalence

Two chains $C, D$ are chain equivalent if there's a prism operator betwen them `:)` More seriously,

#### Relative homology

Build sequence $C_n(X) \rightarrow C_n(A) \rightarrow C_n(X)/C_n(A)$. Snake lemma gives us
long exact sequence of relative homology.

#### Good pair

$(X, A)$ is a good pair if (1) $A$ is closed in $X$ (contains all its boundaries), (2) there is an open nbhd $U$ of $A$
($A \subseteq U \subseteq X$) such that $U$ deformation retracts onto $A$.

For example, $(D^2, S^1)$ is a good pair, because the subspace $U = D^2 - (0, 0)$ (annulus)
deformation retracts onto the boundary $S^1$. The subspace $U$ is open since
it is the complement of a closed set, the point. More generally,
given an attaching map $f: \partial D^2 \rightarrow X$ to attach a $D^2$ into a
space $X$, if we build $Y \equiv X \cup_f D^2$, then $(Y, X)$ is a good pair,
since we have an open $U$ which is $Y$ minus the origin of the disk that conatins $X$. That is,
set $U \equiv X \cup_f (D^2 - (0, 0))$. $U$ contains $X$, and deformation retracts onto $X$, since we can "deform" the
ball minus the origin $D^2 - (0, 0)$ back into the original space $X$. This, cellular attachments create a "chain of good spaces".



Also see this answer on [HEP versus good pair](https://math.stackexchange.com/questions/74528/homotopy-extension-property-vs-good-pairs?rq=1)


#### good pair + Excision => relative equals quotient homology

Let $(X, A)$ be a good pair. Consider the projection map which kills $A$,
the map $\pi: (X, A) \rightarrow (X/A, [A])$ as a map of good pairs.
(Note that $(X/A, [A])$ is also a good pair). We claim this induces isomorphisms
$\pi^*: H_n(X, A) \rightarrow H_n(X/A, [A])$.




# Legal Systems very different from ours

# Shrinking wedge of circles / Hawaiian earring (TODO)

I've been trying to make peace with the fact that countably infinite wedge of circles
is so different from the hawaiian earring. Here are some thoughts:

- Topology on the hawaiian earring is very different. Eg: small opens around the center of infinite
  wedge is contractible, while no small open around the origin of the hawaiian earring is contractible.
- We can take infinite products of group elements in the hawaiian earring, since the radii decrease.
  For example, we can take a loop at *each* circle of radius $1/n$ by making it traverse the circle
  of radius $1/n$ in the interval $t \in [(n-1)/n, n/(n+1)]$, and stay at $(0, 0)$ at $t=1$.

# Simplicial approxmation of maps (TODO)

#### What we want:

> every map $f: K \rightarrow L$ is homotopic to a simplicial map $f_\triangle: K \rightarrow L$:
> ie, a map that sends vertices to vertices,
> and sends other points through an extension of linearity.
> such that $f(st(v)) \subseteq st(f_\triangle(v))$ where $f_\triangle$ is the simplicial
> approximation of $f$.

Recall that $st(v)$ is the intersection of interiors of all simplices that
contain the vertex $v$. So on a graph, it's going to be a "star shaped" region
around the vertex of all the edges around the vertex.

#### Why this can't happpen

Consider a triangle as a simplex of a circle. We want to represent rotations of
the circle.  I can rotate around a circle once, twice, thrice, ... As many
times as I want. However, if all I have is a triangle, I can represent rotating
once as the map $1 \mapsto 2, 2 \mapsto 3, 3 \mapsto 1$ and rotating twice as
maybe $1 \mapsto 3, 3 \mapsto 2, 2 \mapsto 1$, but that's it. I've run out of
room! So I need to *subdivide* the simplex to get "more points" to represent
this map.

#### The correct statement

# Lebesgue number lemma (TODO)

for a compact space $X$ and an open cover $\{ U_\alpha \}$, there is a radius
$r > 0$ such that any ball of such a radius will be in some open cover: For all
$x \in X$, for all such balls $B(x, r)$, there exists a $U_x \in \{ U_\alpha \}$ such that
$B(x, r) \subseteq U_x$.  Intuitively, pick a point $x$. for
each open $U$, we have a ball $B(x, r)$ that sits inside it since $U$ is open.
Find the largest such radius, we can do so since $\{x\}$ is the closed subset of a compact set.
This gives us a function $f$ that maps a point $x$ to the largest radius of ball
that can fit in _some_ open cover around it. This function $f$ is a continuous function (why?)
on a compact set, and thus has a minimum. So, for all points $x \in X$, if you give a
ball of radius $\min f$, I can find some open cover around it.

#### Lebesgue number lemma, Version 2:

for a compact space $X$ and an open cover $\{ U_\alpha \}$, there is a diameter $d > 0$ such that
set of smaller radius will be in some open cover: For all $x \in X$, for all
opens $x \in O$ such that $diam(O) < d$, there exists a $U_x \in \{ U_\alpha \}$ such that  $O \subseteq U_x$.

If we can find radius $B(x, r)$ that satisfies this, then if we are given a set of diameter less than $2r$,
there will be a ball $B(x, r)$ that contains the set $O$ of diameter at most $d = 2r$,
and this ball will be contained in some $U_x$.  So we will have the
containments $O \subseteq B(x, r) \subseteq U_x$.


#### Lebesgue number lemma, proof from Hatcher

TODO


# Lean internals Cheat Sheet

- [CIC page in Coq](https://web.mit.edu/jgross/Public/tmp/doc/sphinx/_build/html/language/cic.html)
- [`bollu/cubicaltt`](https://bollu.github.io/cubicaltt/Main.html): an annotated version of the cubicaltt sources.
- [CPDT (certified programming with dependent types) chapter on equality](http://adam.chlipala.net/cpdt/html/Cpdt.Equality.html)
  to learn about the various reduction rules.
- [Data structures to verify acyclicity of a graph on updates](https://dl.acm.org/doi/10.1145/2756553): A New Approach to
  Incremental Cycle Detection and Related Problems
- [Coq Coq correct](https://dl.acm.org/doi/pdf/10.1145/3371076): Paper on
  formally verifying the type checker for Coq, contains information about data structures used in the kernel.


# MicroUI

I love the implementation of [`microui`](https://github.com/rxi/microui), so I wrote
a [code walkthrough here](https://bollu.github.io/microui/microui-source.html). I feel I learnt
a nice design pattern for writing such an immediate-mode GUI library in the future.


# Proof of tree having (V-1) edges

I'm more comfortable with the proof where we link the vertex to the incoming
edge "all at once".  The proof of induction feels weird.  So sahiti suggested:
impose an ordering that makes the time feel better. So if I imagine the tree
losing leaves from the bottom up left to right, it feels a lot smoother.  So
sahiti also suggested: shake the tree! This feels better as well. In general, I think
I prefer thinking of it in terms of "applicative", instead of "monad, where the choices
are statically determined, and I am not forced to make an arbitrary choice at each step, since
the arbitrariness of the choice breaks my "flow".


# Creating PDFs to read code

1. Use [`vim-bruin`](https://git.sr.ht/~romainl/vim-bruin) for black and white printing
2. Use `more *.cpp *.h > consolidated.cpp` to create a single file. `ClangFormat` this file.
3. Open in vim, use `:toHTML` in vim to dump out an HTML.
4. Open HTML page in firefox, use `save as PDF` to generate a PDF.
5. Print!


# Bias and gain

Bias changes the "central tendency"/"hinge point" of the curve.

```cpp
float GetBias(float t, float b) {
  return (t / ((((1/b) - 2)*(1 - t))+1.0));
}
```

Gain changes how rapidly we reach the bias point.

```cpp
function GetGain(t,g) {
  if(t < 0.5)
    return GetBias(t * 2.0,g)/2.0;
  else
    return GetBias(t * 2.0 - 1.0,1.0 - g)/2.0 + 0.5;
}
```


# Barycentric subdivision: edge length decreases

For a edge $E$, subdiving the edges into two at the center produces two edges
both $1/2$ the original length.  Given a triangle $T$, we wish to prove that
subdividing the triangle by joining the barycenter to the vertices reduces edge
length by $2/3$ of the maximum length. More generally, we wish to show that the
edge length decreases to $n/(n+1)$ of the largest length for an $n$ dimensional
figure.

The barycenter is at the location $b \equiv 1/n \sum_i v_i$. The distance
from a vertex $v_k$ is $||v_j - b|| = ||v_k - (1/n \sum_i v_i)|| = ||1/n(\sum_i v_k - v_i)||$.
By Cauchy Schwarz, we have that $||v_j - b|| \leq 1/n ||\sum_i v_k - v_i||$. One of the terms,
where $k = i$ will be zero, and the other (n-1) terms are at most $l$, the length of the longest edge.
This gives $||v_j - b|| \leq (n-1)l/n$, hence the edge length decreases by a factor of $(n-1)/n$.


# Homotopic maps produce same singular homology: Intuition

Take two maps $f, g: X \rightarrow Y$ which are homotopic. We wish
to show that if $f$ is homotopic to $g$, then we will get the same
induced singular homology groups from $f$ and $g$. The idea is to take a chain
$c[n] \in C[n]$, then study the image $f\sharp(c[n])$ and $g\sharp(c[n])$. Since $f$
and $g$ are homotopic, we can build a "prism" that connects $f\sharp(c[n])$ and $g\sharp(c[n])$
by means of a prism operator, that sends a chain $c \in C[n]$
to the prism $p(c)$ produced by the chain which lives in $D[n+1]$. Next, we compute the
boundary of this prism, $\partial p(c)$. This boundary will contain a top portion,
which is $f\sharp(c)$, a bottom portion which is $g\sharp(c)$, and the boundary edges
of the prism itself, which is the same as taking the prism of the boundary edges
$p(\partial c)$.  This gives the equation $\partial(p(c)) = p(\partial c) + g\sharp(c) - f\sharp(c)$.
Rearranging, this gives $g\sharp(c) - f\sharp(c) = \partial p(c) - p(\partial c)$. To inspect
homology, we wish to check that $f\sharp, g\sharp$ agree on elements of $\ker(\partial[n])/im(\partial[n+1])$.
So, we set $c \in \ker(\partial[n])$. This kills of $p(\partial c)$. Further, since we
quotient by $\partial[n+1]$, the $\partial(p[c])$ also dies off. This means that
$g\sharp(c) - f\sharp(c) = 0$ when interpreted as an element of $H[Y][n]$. Philosophically,
living in $\ker(\partial[n])$ kills $- \circ \partial$, and quotienting
by $im(\partial[n+1])$ kills $\partial \circ -$. Thus, we get that $g\sharp$ and $f\sharp$ produce the same
homology element. Intuitively, we are saying that these can be connected by a prism in the space,
and thus produce the same element. Think of the 0D case in a path-connected
space, where all points become equivalent since we can connect them by paths.

To compute the boundary of the prism, we break the prism into an interplation from
$f\sharp$ into $g\sharp$ by raising $f\sharp$ into $g\sharp$ one vertex at a time. This then allows us
to induce cancellations and show that $\partial(p(c))$ contains the terms
$p(\partial(c))$, $f\sharp(c)$ and $g\sharp(c)$.


Let's consider a 1D line $l: \Delta^1 \rightarrow X$ in $X$, with vertices
$l[0], l[1]$. The image of this line under $f$ is $m \equiv f \circ l$  with $m[0], m[1]$ as vertices,
and under $g$ is $n$ with $n[0], n[1]$ as vertices. Let $H: [0, 1] \times [0, 1] \rightarrow X$
be the homotopy between $H(0) f$ and $H(1) = g$.  The prism is image of the function $p: [0, 1] \times \Delta^1$, defined
as $p(t, i) \equiv H(t, l(i))$. We see that $p(0, i) = H(0, l(i)) = f(l(i)) = m$, and $p(1, i) = g(l(i)) = n$.
So, we get a "prism" whose endpoints are $m = f \circ l$ and $n = g \circ l$.


# Singular homology: induced homomorphism

The space of chains $C[i]$ of a topological space $X$
is defined as all functions $\Delta^i \rightarrow X$.
The boundary map is defined as:

$$
\begin{aligned}
&\partial[n]: C[n] \rightarrow C[n-1] \\
&\partial[n](\sigma) \equiv \sum_i (-1)^i \sigma|[v[0], v[1], \dots, \hat{v[i]}, \dots, v[n]]
\end{aligned}
$$

where $\hat{v[i]}$ means that we exlude this vertex, and $v[0], v[1], \dots$ are the vertices
of the domain $\Delta^i$.

Now, say we have a function $f: X \rightarrow Y$, and a singular chain complex $D[n]$ for $Y$.
In this case, we can induce a chain map $f\sharp: C[n] \rightarrow D[n]$, given by:

$$
\begin{aligned}
&f\sharp: C[n] \rightarrow D[n] \\
&f\sharp: (\Delta^n \rightarrow X) \rightarrow (\Delta^n \rightarrow Y) \\
&f\sharp(\sigma) = f \circ \sigma
\end{aligned}
$$

We wish to show that this produces a homomorphism from $H[n](X) \equiv \ker \partial[n]/ im \partial[n+1]$
to $H[n](Y) \equiv \ker \partial[D][n] / im \partial[D][n+1]$. To do this, we already have a map from  $C[n]$ to $D[n]$.
We need to show that it sends $\ker \partial[n] \mapsto \ker \partial[D][n]$ and.

The core idea is that if we have abelian groups $G, H$ with subgroups $M, N$, and a homomorphism
$f: G \rightarrow H$, then this descends to a homomorphism $f': G/M \rightarrow H/N$ iff
$f(M) \subseteq N$. That is, if whatever is identified in $G$ is identified in $H$, then our
morphism will be valid. To prove this, we need to show that if two cosets $g + M$, $h + M$
are equal, then their images under $f'$ will be equal. We compute $f(g+M) = f(g) + f(M) = f(g) + 0$,
and $f(h + M) = f(h) + f(M) = f(h) + 0$. Since $g + M = h+M$, we get $f(g) = f(h)$. Thus, the morphism
is well-defined.



# Demoscene tools

- [Leviathan](https://github.com/bollu/Leviathan-2.0): framework for 4k demos.
- [WaveSabre](https://github.com/bollu/WaveSabre). [Talk at DemoBit](https://youtu.be/JjFyHI1b_Tw?t=7246)
- [aDDIct](https://conspiracy.hu/release/tool/) --- This not helpful as it contains no sources.
- [bonzomatic](https://github.com/bollu/Bonzomatic) --- useful for livecoding shaders.
- [Buzz DAW](https://en.wikipedia.org/wiki/Jeskola_Buzz)
- [Supercollider](https://supercollider.github.io/)
- [sointu / 4klang: minimal synth](https://github.com/vsariola/sointu)


# Binaural Beat

> The beating effect happens when sound waves physically mix together.  Believe
> it or not though, there is a part of your brain where it mixes (adds) the
> sounds from each ear together as well.  That means that if you play similar
> frequencies to different ears, they will mix INSIDE YOUR BRAIN, and you will
> perceive a different kind of beating effect.


# Low pass filter by delaying

 I don't understand this.  Full text with context:

> For example, at a sample rate of 10kHz, one sample delay is equal to the
> sample time of 0.0001 seconds. ... A signal at 1000Hz has a period of 0.001
> seconds and a one sample time delay is 1/10 of the period, or 36°.

I understand the math upto this point. 0.001 seconds -> 360 degrees, so 0.0001
seconds -> 36 degrees. Thus, a sample delay of 0.0001 seconds corresponds to 36
degrees of phase shift.

What's the next bit? I don't understand this:

>  The larger phase difference results in a lower amplitude and the higher
>  frequency signal is attenuated more than the lower frequency signal. The
>  effect is that of a low-pass filter.

1. Why does a large phase shift result in a lower amplitude?
2. Why is the higher frequence signal attenuated (= weakened, as far as I understand) more?


Wiki claims that this discrete process is the "same as" the low pass filter:

```cpp
function lowpass(real[0..n] x, real dt, real RC)
    var real[0..n] y
    var real α := dt / (RC + dt)
    y[0] := α * x[0]
    for i from 1 to n
        y[i] := α * x[i] + (1-α) * y[i-1]
    return y
```

One proof strategy that I can think of:
1. Split signal into fourier components
2. Notice that if the frequency is higher than some threshold, we will start introducing phase deltas larger
   than $\pi$. This will cause cancellation of a $\sin$ wave.
3. See that this makes sure that only low frequency signals live.

I'm now trying to understand why this doesn't "wrap around". I would naively
expect: (1) low frequency = minimal destructive interference (2) high frequency
(phase difference 180 degrees) = maximal destructive interference (3) EVEN
HIGHER frequency (phase difference greater than 180 degrees) = non-maximal
destructive interference?

I believe the resolution is to remember that we only build signals upto what
Niquist lets us, so we build at max a sin wave of frequency `fs/2` where the same
period is `fs`. Thus, when we phase shift, we will get a phase of at max 180 degrees.


As to why the Niquist ratio is `1/2`, imagine a circle. a `1/2` is how much
"ambiguity" we have in the phase. In that, if we jump by more that `pi`, (ie,
more than `1/2` of the circle), we will  ????


# Octaves are double frequency apart (TODO)

As I am reading `BasicSynth`, I learnt that:

> Each half-step between notes in the
> musical scale represents a frequency ratio of $2^{1/12} \simeq 1.059$.

The $(\cdot)^{1/12}$ is reasonable, because an octave contains 12 semitones.
The base $2$ is quite mysterious! I wanted to know why this is.


a multiple oCochlea and why frequencies are 1:2

> https://physics.stackexchange.com/questions/44469/octave-equivalence-biological-or-more

# Bias and gain

- Bias lets us move the "mean" of the  plot.
- Gain lets us move "how quickly" we get to the mean.

# Show, don't tell

Think of effects, not causes.

- It was autumn -> the leaves crunched under her feet.
- She was blind -> She felt for the chair with her white cane.

- https://www.youtube.com/watch?v=YAKcbvioxFk

# Try and think of natural transformations as intertwinings

I'm comfrotable with elementary representation theory, but I feel far less at home manipulating
natural transformations. I should try and simply think of them as the intertwinig operators
in representation theory, since they do have the same diagram. Then the functors become
two representations of the same category (group), and the natural transformation is an
intertwining operator.

If one does this, then Yoneda sort of begins to look like Schur's lemma. Schur's
lemma tells us that intertwinings between irreducible representations are either zero
or a scaling of the identity matrix. That is, they are one-dimensional, and the space
of all intertwinings is morally isomorphic to the field $\mathbb C$. If we specialize
to character theory of cyclic groups $Z/nZ$, let's pick one representation to be
the "standard representation" $\sigma: x \mapsto e^{i 2 \pi x/n}$. Then, given some other
representation $\rho: Z/nZ \rightarrow \mathbb C^\times$, the intertwining between
$\sigma$ and $\rho$ is determined by where $\rho$ sends $1$. If $\rho(1) = k \sigma(1)$
for $k \in \mathbb R$, then the intertwining is scaling by $k$. Otherwise, the intertwining
is zero. This is quite a lot like Yoneda, where the natural transformation is fixed
by wherever the functor sends the identity element.


# Subobject classifier measures how much we need to pay to access fact

- Truths are free. We don't pay any of the monoid (given $A \rightarrow B$,
  subobj assigns full monoid to image of $A$ in $B$).
- We go bankrupt trying to prove really false things (subobj assigns emptyset)
- To things that are truth adjacent, we spend some of our monoid (by dividing the filter)
  to get to the element. So we "spend money" to "fix the lie" of the element in $B$ not being truthful,
  but close enough to the truth.


# Spectral norm of Hermitian matrix equals largest eigenvalue (TODO)

Define $||A|| \equiv \max \{ ||Ax|| : ||x|| = 1 \}$. Let $A$ be
hermitian. We wish to show that $||A||$ is equal to the largest eigenvalue.
The proof idea is to consider the eigenvectors $v[i]$ with eigenvalue $\lambda[i]$
with largest eigenvalue $v^\star$ of eigenvalue $\lambda^*$ and claim that
$||Av^\star|| = \lambda^*$ is maximal.

# Penrose cohomology [TODO]

<img src="./static/penrose-triangle.png"/>

- [I should just reach Cech Cohomology for this!](https://en.wikipedia.org/wiki/%C4%8Cech_cohomology)

# Weingarten map

- Let $S \subseteq \mathbb R^3$ be an extrinsic manifold
- Let $U \subseteq \mathbb R^2$ be the domain for a parametrization $x: U \to S$.
- The gauss map $N$ is the map which sets each point $p \in S$ to the normal plane at $p$.
- The weingarten map is the map $dN$ which can be identified with


# When maps cannot be lifted to the universal cover

-  https://math.stackexchange.com/questions/1734540/existence-of-a-lifting

# Nets from Munkres (TODO)

#### Directed set
A direct set is a partial order $J$ which has "weak joins".
That is, for every $a, b \in J$, there exists a $u \in J$ such that $a \leq u$ and $b \leq u$.
It's not a join since we don't need $u$ to be UNIQUE.

#### Cofinal subset

A subset $K$ of a partial order $J$ is said to be cofinal if loosely, $\forall J \leq \exists K$.
That is, for all $j \in J$, there is a $k \in K$ such that $j \leq k$. So intuitively, $K$
is some sort of portion of $J$ that leaves out a finite part of the bottom of $J$.

#### Cofinal subset is directed

#### Nets

Let $X$ be a topological space. a net is a function $f$ from a directed set $J$ into $X$.
We usually write this as $(x_j)$.

#### Net eventually in a subset $A$

A net $(x_j)$ is eventually in a subset $A$ if there exists an $i \in I$ such that for all
$j \geq i$, $x_j \in A$.  This is an $\exists \forall$ formula.

#### Net cofinally/frequently in a subset $A$

The net $x[:]$ is cofinally in a subset $A$ if the set $\{ i \in I : x_i \in A \}$
is cofinal in $I$. This means that for all $j \in J$, there exists a $k$ such that
$j \leq k$ and $x_k \in A$. This is a $\forall \exists$ formula. So intuitively,
the net could "flirt" with the set $A$, by exiting and entering with elements in $A$.


#### Eventually in $A$ is stronger than frequently in $A$

Let $x[:]$ be a net that is eventually in $A$. We will show that such a net is also
frequently in $A$. As the net is eventually in $A$, there exists an $e \in I$ (for eventually), such that
for all $i$, $e \leq i \implies x[i] \in A$. Now, given an index $f$ (for frequently),
we must establish an index which $u$ such that $f \leq u \land x[u] \in A$.
Pick $u$ as the upper bound of $e$ and $f$ which exists as the set $I$ is directed.
Hence, $e \leq u \land f \leq u$. We have that $e \leq u \implies x[u] \in A$.
Thus we have an index $u$ such that $f \leq u \land x[u] \in A$.

#### Not Cofinal/frequently in $A$ iff eventually in $X - A$

##### Not Frequently in $A$ implies eventually in $X - A$

Let the net be $x[:]$ with index set $I$. Since we are not frequently in $A$,
this means that there is an index $f$ at which we are no longer frequent.
That is, that there does not exist elements
$u$ such that $f \leq u \land x[u] \in A$. This means that for all elements
$u$ such that $f \leq u$, we have $x[u] \not \in A$, or $x[u] \in X - A$.
Hence, we can choose $f$ as the "eventual index", since all elements above $f$
are not in $A$.

##### Eventually in $X - A$ implies not frequently in $A$

Let the net be $x[:]$ with index set $I$.
Since the net is eventually in $X - A$, this means that
there is an index $e$ (for eventually) such that for all $i$ such that $e \leq i$ we have
$x[i] \in X - A$, or $x[i] \not \in A$.  Thus, if we pick $e$ as the
frequent index, we can have no index $u$ such that $e \leq u \land x[u] \in A$,
since all indexes above $e$ are not in $A$.


#### Convergence of a net

We say a net $(x_j)$ converges to a limit $l\in X$, written as $(x_j) \rightarrow l$ iff
for each neighbourhood $U$ of $l$, there is a lower bound $j_U \in J$ such that for all $k$,
$j_U \leq k \implies x_k \in U$. That is, the image of the net after $j_U$ lies in $U$. In other words,
the net $(x_j)$ is eventually in every neighbourhood of $l$. This is a $\forall \exists \forall$
formula (for all nbhd, exists cuttoff, for all terms above cutoff, we are in the nbhd)

#### Limit point of a net

We say that a point $l$ is a **limit point** of a net if $x$ is
cofinally/frequently in every neighbourhood of $A$. That is,
for all neighbourhoods $U$ of $A$, for all indexes $j \in J$, there
exists an index $k[U, j]$ such that $j \leq k[U, j] \land x[j] \in U$.
This ia $\forall \forall \exists$ formula (for all nbhd, for all
indexes, there exists a higher index that is in the nbhd).

#### Converge of a net with net as $\mathbb N$


#### Product of nets

#### Convergenge of product nets iff component nets converge

#### Nets in Hausdorff spaces converge to at most one point

#### Point $p$ is in closure of $A$ iff net in $A$ converges to point $p$


#### Function is continuous iff it preserves convergence of nets

#### Subnets


#### Subnets of a net converge

#### Accumulation point of a net

#### Subnets converge iff point is accumulation point

#### Compact implies every net has convergent subnet

#### Compact implies every net has convergent subnet

#### Universal Net

#### Every net has universal subnet

#### Universal net converges in compact space

#### pushforward of universal net is universal


#### Tychonoff's theorem

Let $\{ X_\alpha : \alpha \in \Lambda \}$ is a collection of compact
topological spaces. Let $X \equiv \prod_{\alpha \in \Lambda} X_\alpha$ be the
product space. Let $\Phi: D \rightarrow X$ be a universal net for $X$.
For each $\lambda \in \Lambda$, the push forward net $\pi_\lambda \circ \Phi: D \rightarrow X_\lambda$
is a universal net. Thus, it converges to some $x_\lambda \in X_\lambda$.
Since products of nets converge iff their components converge, and here all the components
converge, the original net also converges in $X$. But this means that $X$ is compact
as the universal net converges.

- [Pete Clark's notes on point set topology](http://alpha.math.uga.edu/~pete/pointset.pdf)
- [Tanuj Gupta: Tychonoff theorem](https://www.math.tamu.edu/~tanujgupta17/tychonoff.pdf)


# Limit point compactness from Munkres

Munkres calls "Bolzano Weirstrass" as limit point compactness. He defines a
space $X$ to be **limit point compact** if every infinite subset of $X$ has a
limit point.

#### Compact implies limit compact

We will prove the contrapositive. That is, let $X$ be a compact set.
If $A \subseteq X$, does not have any limit point, then $A$ is finite.
If $A$ does not have any limit point, then $A$ vacuously contains all of its limit
points. Thus, $A$ is closed. Since $A$ is a closed subset of a compact set $X$, $A$ itself
is compact. Next, see that for each $a \in A$, we can find an open $U_a$ such that $U_a \cap A = \{ a \}$.
If we can't find such a $U_a$, then it means that $a$ is a limit point!
(Since all nbhd of $a$ intersect $A$ non-trivially). Clearly, these "isolating" $U_a$ cover $A$.
Since $A$ is compact, we have a finite subcover $U_{a_i}$. See that $A = \{ a_i \}$.
To show this, since the $U_i$ cover $A$, we have $A \subseteq \cup_i U_{a_i}$. Hence,
$A = (\cup_i U_{a_i}) \cap A$, which is equal to $\cup (U_{a_i} \cap A)$ which is $\cup_i a_i$.
Hence, $A$ has finitely many points, exactly the $a_i$.


#### Classical Proof Using Bisection

Let's prove this in $\mathbb R$.
Let $C$ be a compact set containing an infinite number of points. We know from
Heine Borel that $C$ is closed and bounded. Let the interval containing $C$ be $I[0] \equiv [l, r]$.
Bisect the interval into two sub-intervals: $J[0][0] \equiv [l, m]$ and $J[0][1] \equiv [m, r]$ for $m = (l+r)/2$.
One of these must contain an infinite number of points (suppose both contain a  finite number of points, then $I[0]$
itself must contain a finite number of points, contradiction). We can thus recurse, setting $I[1]$ to be the sub-interval
that has an infinite number of points. This gives us a nested sequence of intevals $I[0] \supset I[1] \supset \dots$.
The interval $J \equiv \cap_i I[i]$ is closed as it is the intersection of closed intervals. Also, $J$ has length zero
since we bisect the interval each time. Hence, $J$ is a single point, ie $J = \{ j \}$. We claim that $j$ is an accumulation
point of the original subsequence. Any open set around $O$ will contain some interval $I[o]$

# Proof of Heine Borel from Munkres (compact iff closed, bounded)

We wish to show that compact iff closed and bounded in $\mathbb R$.

- Let $S$ be closed and bounded. We wish to show that $S$ is compact. Since $S$ is bounded,
  $S$ is contained in some large closed interval $I$. (1) Closed intervals are compact in the order topology of a
  complete total order, and thus $I$ is compact ($\mathbb R$ is a complete total order).
  Then (2) $S$ is a closed subset of a compact set $I$, and is thus compact.
  Hence closed and bounded implies compact.
- Let $S$ be compact. We wish to show that $S$ is closed and bounded. Cover $S$ with open balls of increasing
  radii. This is an open cover; Extract a finite subcover. From the finite subcover, pick the largest open ball
  $I$. $S$ is entirely contained in $I$, and is thus bounded. (3) $S$ is closed, as it is a compact subset of a
  Haussdorff space. Hence, we are done.

#### (1) Closed intervals are compact in the topology of a complete total order.

Let us work with a complete total order $T$ (in our case $T = \mathbb R$). We equip $T$
with the order topology (which matches the usual topology on $\mathbb R$).
Let $[l, r]$ be a closed interval. Let $\{ U_i \}$ be an open cover of $[l, r]$.
Let $M$ (for middle) be the set of points $m$ such that $[l, m]$ has a finite cover using $\{ U_i \}$
That is,

$$
M \equiv \{ m \in [l, r] : [l, m] \text{ has finite cover} \}
$$

- **CLAIM 1:** $lub(M) \in M$.
- Pick an open $lub(M) \in V \in \{ U_i \}$.
- As $V$ is open, there is some $(c \in V) < (lub(M) \in V)$.
- if $c \in M$: the finite cover of $[l, c]$ along with $V$ give a finite cover for $lub(M)$. Thus $lub(M) \in M$.
- if $c \not \in M$, then $c < lub(M)$ and $c$ is an upper bound for $M$, which is absurd.
- Thus, $lub(M) \in M$.
- **CLAIM 2:** $lub(M) = r$. This implies that $r \in M$, and $[l, r]$ has a finite subcover using $U_i$.
- For contradiction of Claim 2, assume that $lub(M) \neq r$.
- Pick some open set $O$ in the cover that contains $lub(M)$: $lub(M) \in O \in \{ U_i \}_i$.
- As $O$ is open, $O$ contains some point $c$ (for contradiction) that is after $lub(M)$: $lub(M) < c$.
- Rewriting: $c \in O \land c > lub(M)$. So, the interval $[l, c]$ has the same cover as $[l, lub(M)]$.
- Hence, $[l, c]$ has a finite cover, thus $c \in M$.
- **CONTRADICTION:** $c \in M \land c > lub(M)$, which is absurd. We would have $c = lub(M)$.
- Thus, this means that $lub(M) = r$, and thus the entire interval $[l, r]$ has finite subcover.

<img src="./static/closed-intervals-compact-in-order-topology.png" />

#### (2) Closed subset of a compact set is compact

Let $B$ be a closed subset of a compact space $K$. Take an open cover $\{ U_i \}$ of $B$.
See that $\{ B^c, U_i \}$ is a cover of the full space $K$, and hence has a finite subcover.
This subcover will be of the form $\{B^c, U_j\}$. The $\{U_j\}$ are a finite subcover of $B$.
Thus, $B$ is compact as we have extracted a finite subcover of an open cover.


#### (3) Compact subset of Haussdorf space is closed

Morally, this is true because in a Haussdorff space, single point subsets are closed.
Compactness pushes this local property to a global property --- The entire compact set
itself becomes closed.

- Let $S$ be a compact subset of a haussdorf space $X$.
- For any point $q \not \in S$, we need to show the existence of an open set $q \in Q$ such that $S \cap Q = \emptyset$.
- For each point $s \in S$, use Haussdorf to find separating sets $s \in O(s; q)$, $q \in O(q; s)$ such that $O(s; q) \cap Q(q; s) = \emptyset$.
- See that the sets $\{ O(s; q) : s \in S \}$ are a cover of $S$.
- Extract a finite subcover of this, say $\{ O(s_i; q) : s \in S \}$.
- Use this finite subcover to separate $q$ from $S$.
- Now, pick the open set $Q \equiv \cap \{ O(q; s_i) \}$, which is open since it's a finite intersection.
- See that this $Q$ separates $q$ from $S$.
- We have that $Q \cap O(s_i, q) = \emptyset$ for each $O(s_i, q)$.
- Thus,$Q \cap (\cup O(s_i; q)) = \emptyset$, and thus $Q \cap S = \emptyset$ as $S \subseteq \cup O(s_i; q)$.
- if $q \not \in S$, we have an open $Q$ that separates $q$ from $S$,
  thus $q$ is NOT A LIMIT --- not every open nbhd of $Q$ has non-empty intersection with $S$.
- Contrapositive: All limit points of $S$ are in $S$. Thus, $S$ is closed. (4)

<img src="./static/compact-subset-of-haussdorf-is-closed.png"/>

#### (4) A set with all limit points is closed (complement of open)

Let $S$ be a set that has all its limit points. Consider the complement set $T$. We will
show that $T$ is open.

- all points in $T$: have open that separates them from $S$. Union of all of these opens is $T$.
  $T$ open: infinite union of opens. $S$: the complement of an open set, closed.

More elaborately:

- for all all $t \in T$, $t \not in S$ (by defn).
- $t$ is not a limit point of $S$ ($S$ has all limit points).
- Thus, there is an open $U_t$ such that $t \in U_t$ and $U_t \cap S  = \emptyset$.
- Define: $T' \equiv \cup_{t \in T} U_t$. Claim: $T' = T$.
- As $U_t$ contains no elements of $S$, $T'$ contains no element of $S$.
- As $U_t$ contains $t$, $T'$ contains all $t$.
- Thus $T'$ contains all $t \in T$, and no element of $S$. So $T'$ is a complement of $S$. $T' = T$.
- $T$ is a infinite union of opens. Thus $T$ is open.
- $S$ is complement of open set $T$. $S$ is closed.

# Alexandrov topology

These are the best generalizations of finite topological spaces.
I should study them for better intuition + comptutability properties.
This is a topology where the intersection of all families of open sets
is open, not just finite intersections. The minimal neighbourhood of a point $V(x)$
is the intersection of all opens containing $x$.

- [Alexandrov Topology](https://en.wikipedia.org/wiki/Alexandrov_topology)
- [Paper on the systematic study of Alexandrov spaces](http://emis.impa.br/EMIS/journals/AMUC/_vol-68/_no_1/_arenas/arenas.pdf)



# Zeroth singular homology group: Intuition

We wish to show that for a path connected space $X$, the zeroth singular homology group is just $\mathbb Z$.
The intuition is that the zeroth homology group is given by consider $C[1] \xrightarrow{\partial_1} C[0]$,
$C[0] \xrightarrow{\partial_0} 0$, and then taking $H[0] \equiv ker(\partial_0) / im(\partial_1) = C[0] / im(\partial_1)$.
Recall that $C[0]$ is the abelian group generated by the direct sum of generators
$\{ \Delta^0 \rightarrow X \}$, where $\Delta^0$ is the $0$-simplex, that is,
a single point. So $C[0]$ is an abelian group generated by all points in $X$. Now, $C[1]$ contains all paths
between all points $p, q \in X$. Thus the boundary of $C[1]$ will be of the form $q - p$. Quotienting by $C[1]$
identifies all points with each other in $C[0]$. That is, we get $H[0] \equiv \langle x \in X | y = z \forall y, z \in X \rangle$,
which is isomorphic to $\mathbb Z$. Thus, the zeroth singular homology group is $\mathbb Z$.


# Examples of fiber products / pullbacks

#### Fiber products of sets

If we have a set $S$, we can form a category of bundles over $S$. These are pairs
$(X, \pi: X \rightarrow S)$. The morphisms between such objects $(X, \pi: X \rightarrow S)$
and $(X', \pi': X' \rightarrow S)$ are arrows $h: X \rightarrow X'$ that
make the obvious diagram commute:


```
X ---h--> X'
 \       /
 pi     pi'
   \   /
    v v
     S
```

The product of these objects is given by the fiber product or pullback:

$$
X \times_S Y \equiv \{ (x, y)  \in X \times Y: \pi_X(x) = \pi_Y(y) \}
$$

along with the map $\pi_{X \times Y}: X \times_Y \rightarrow S; \pi((x, y)) \equiv \pi_X(x)$.
See that for consistenty, we could also have defined this as $\pi((x, y)) \equiv \pi_Y(y)$.
Since our condition is that $\pi_X(x) = \pi_Y(y)$, it all works out.
Said differently, we consider the product of fibers over the same base-point.


###### Fiber products of arbitrary bundle over a single-point base space

If $S \equiv \{ * \}$, then the projections are always $\pi(-) \equiv *$, and the fiber
product is the usual product.


###### Fiber products of singleton bundle over arbitrary base space

If $S$ is arbitrary while $P \equiv \{ p \}$ (for Point),
then this bundle $P$ will lie over some point in $S$, given
by $\pi: P \rightarrow S$, where the special point
is chosen by $\pi(p) = s_p$. If we now consider some other bundle $X$ over $S$,
Then $P \times_S X$  will pick the element $(p \in P, \pi_X^{-1}(s_p) \subseteq X)$.
That is $P \times_S X \simeq \pi_X^{-1}(s_*)$, which is the fibre of $X$ over
the special point $s_p = \pi(p)$. This explains the name.


- [Notes on scheme theory](https://www.math.purdue.edu/~arapura/preprints/schemesgalois4.pdf)



#### Fiber products of vector bundles

Consider a fiber bundle $E \xrightarrow{\pi} B$. Now consider a new base space $B'$
with a map $f: B' \rightarrow B$. So we have the data:

```
       E
     pi|
       v
B'-f-> B
```

Given this, we would like to pullback the bundle $E$ along $f$ to get a new
bundle over $B'$.This is defined by:

$$
E'_f \equiv \{ (b', e) : f(b') = \pi(e) \} \subseteq B' \times E
$$

This is equipped with the subspace topology. We have the projection map
$pi': E'_f \rightarrow B$, $\pi'((b', e)) \equiv b'$. The projection into
the second factor gives a map $h: E'_f \rightarrow E$, $h((b', e)) \equiv e$.
This makes the obvious diagram commute:

```
E' -h-> E
|pi'    |pi
B' -f-> B
```

Any section $\sigma: B \rightarrow E$ of $E$ induces a section of $E'$
$\sigma': B' \rightarrow E'$, by producing the function (given as a relation):

$$
\begin{aligned}
\sigma': B' \rightarrow E' \\
\sigma(b') \equiv  (b', \sigma(f(b')) \in_? E'  \simeq B' \times E
\end{aligned}
$$

This has codomain $E'$. To check, if  $(b', \sigma(f(b'))$ is in $E'$,
we need $f(b') = \pi(\sigma(f(b'))$. But this is true since $\sigma$
is a section, and thus $\pi(\sigma(f(b')) = f(b')$.

Moreover, we need to check that $\sigma'$ is indeed a section of $B'$. For this,
we need to check that $\pi'(\sigma'(b')) = b'$. Chasing definitions, we find
that this is:

$$
\begin{aligned}
&\pi'(\sigma'(b'))
&= \pi'(b', \sigma(f(b')))
&= b'
\end{aligned}
$$

Hence we are done, we have indeed produced a legitimate section.

#### Fiber products of Spec of affine scheme

Let $R, A, B$ be rings. consider $A \otimes_R B$. What is $Spec(A \otimes_R B)$, in terms of
$Spec(A)$, $Spec(B)$, and whatever data you like about $R$? (Say I give you both $R$ and $Spec(R)$).

The answer is that apparently, it's exactly $Spec(A) \times_{Spec(R)} Spec(B)$.



# Covariant derivative

If $x_p \equiv a \partial_x + b \partial_y + c \partial_z$ is a vector at $p \in \mathbb R^3$ and $Y$ is a vector field,
then the covariant derivative of $Y$ in the direction $X$ is given by taking the directional derivative
of each component of $Y$ along $X$:

$$
x_p |- Y \equiv (x_p \cdot Y[1], x_p \cdot Y[2], x_p \cdot Y[3])
$$

The notation `|-` is meant to suggest that $X_p$ is acting on $Y$.
For a concrete example, if $X_p \equiv (a, b, c)$ and $Y \equiv (xy^2 + 4z, y^2 - x, x + z^3)$,
then the computation yields:

$$
\begin{aligned}
&x_p |- Y \equiv (x_p \cdot Y[1], x_p \cdot Y_2, x_p \cdot Y_3) \\
& ((a \partial_x + b \partial_y+ c \partial_z ) \cdot (xy^2 + 4z),
   (a \partial_x+ b \partial_y+ c \partial_z) \cdot (y^2 - x),
   (a \partial_x+ b \partial_y+ c \partial_z) \cdot (x + z^3))
&= (ay^2 + 2bxy + 4, -a + 2by, a + 3cz^2)
\end{aligned}
$$

#### Property 1: Linearity in RHS

We have that $x_p |- (Y + Z) = x_p |- Y + x_p |- Z$.  This is proven by the linearity of the partial derivative.

#### Property 2: Linearity in LHS: $(x_p + x'_p)|- Y = (x_p |- Y) + (x'_p |- Y)$.

This follows as vector addition is linear, and the action of the directional derivative is linear.

#### Property 3: Scaling of LHS

$(f(p) x_p) |- Y = f(p) (x_p |- y)$

#### Property 3: Scaling of RHS

$x_p |- (fY) = (x_p f(p)) Y + f (x_p |- Y)$


$$
\begin{aligned}
&x_p |- (fY) \equiv (x_p \cdot fY[1], x_p \cdot fY_2, x_p \cdot fY_3) \\
&= ((a \partial_x|_{p_x} + b \partial_y|_{p_y} + c \partial_z|_{p_z} ) \cdot (fY[1]), \dots, \dots)
&= ((a Y[1] \partial_x|_{p_x} f + af \partial_x|_{p_x} Y[1] +
     b Y[1] \partial_y|_{p_y} f + b f \partial_y|_{p_y} Y[1]
     c Y[2] \partial_z|_{p_z} f + c f \partial_y|_{p_z} Y[2], \dots, \dots) \\
&= ((fa \partial_x Y[1] + fb\partial_y Y[2] + fc \partial_z Y[3]) Y +  (Y[1] a \partial_x + Y[2] b \partial_y + Y[3] c \partial_z) \cdot f,
    \dots, \dots) \\
&= (fx_p) |- Y + (Y(p)
\end{aligned}
$$

#### Computing $x_p |- Y$

We can compute $x_p |- Y$ once we have a curve $\sigma$ that is compatible with $x_p$.  So if
we have a curve $\sigma(0) = p$, and $\sigma'(0) = x_p$, and we know $Y$, we can then compute
$x_p |- Y$ as:

$$
\begin{aligned}
\frac{d (Y \circ \sigma(t))}{dt}|_{t = 0} \\
&Y'(\sigma(t))|_{t=0} \cdot \sigma'(t)|_{t = 0} \\
&Y'(\sigma(0)) \cdot \sigma'(0) \\
&Y'(p) \cdot x_p \\
&x_p[1] \partial_x Y[1] + x_p[2] \partial_y Y[2] + x_p[3] \partial_y Y[3] \\
&x_p |- Y
\end{aligned}
$$

Realy, we only need to  know $Y$ **along** $\sigma$  to compute the derivative, no more.
So it's enough to have (1) a curve $\sigma$ that is compatible with $x_p$, and (2)
knowledge of the vector field $Y$ along $\sigma$.


#### Parallel vector fields

Say that a curve $\sigma$ is tangent to a vector $t_p$ if $\sigma(0) = p$ and $\sigma'(0) = t$.
Then a vector field $Y$ defined a along $\sigma$ is **parallel along** $t$ iff $t_p |- Y = 0$.
Intuitively, this means that the vector field does not change in the direction of $t_p$, so it keeps
its value constant along $t_p$. It is as if the values of $Y(0)$ have been transported "parallely"/
"with no distortion" along the tangent $t_p$.

#### Parallel vector fields

Let $\sigma$ be a $C^\infty$ curve.


# Clackety sounds: `bucklespring`

I've taken to running [`bucklespring`](https://github.com/zevv/bucklespring) in the background when I code,
because it makes the experience of programming so much more tactile. Having left my mechanical keyboard
in college in the time of the plague, I feel like I was sorely missing this sort of auditory feedback!


# Submersions and immersions

Who in the world decided their names? I remember which is which based on the sound. "Submersion"
is "surjective", "immersion" is "injective". But really, the naming makes no sense. I can intuitively
submerge a ring (a 1D object) into the ocean (a 3D object). so if anything, I'd expect submersions
to be locally injective. You can only submerge $X$ into $Y$ if $Y$ is "larger" than $X$. The definition
asks for the precise opposite!

# Ehrsmann connection

Here's my current understanding of how the Ehrsmann connection works.


We have a  $G$-bundle $G \xleftarrow{\triangleleft G} P \xrightarrow{\pi} M$.
Let's first think of it as globally trivial so $P \simeq M \times G$. Now at each point
$m \in M$, we have the fiber $\{ m \} \times G$ over $m$. We now consider the kernel
of the map $\pi^*: T_{m, g} M \times G \rightarrow T_m M$. What are the elements here?
We know that $T(M \times G) \simeq TM \oplus TG \simeq TM \oplus \mathfrak g$ where $\mathfrak g$
is the Lie algebra of the lie group $G$. So we know that $\pi^*$ maps $T_p M \oplus \mathfrak g \mapsto T_p M$.
Thus the kernel of $\pi^*$ is going to be $\mathfrak g$.
This is called as the "vertical subspace" $V_p P \equiv ker(\pi^*) \subseteq T_p P$.

Now, we have a choice in how we pick $H_p P$ for each point $p \in P$ such that $H_p P \oplus V_p P = T_p P$.
This choice of $H_p P$ is the connection. We claim that this choice is equally well encoded by a lie-algebra
valued one form, $\omega : TP \rightarrow \mathfrak g$. That is, $\omega: TM \times TG \rightarrow \mathfrak g$,
which is $\omega: TM \times \mathfrak g \rightarrow \mathfrak g$. Intuitively, this tells us how much of the component
along $\mathfrak g$ is not covered by the $H_p P$.


The idea is that since $V_p P \oplus H_p p = T_p P$, given any vector $t_p \in T_p P$, I can compute
$t^v_p \equiv t_p - H_p(t_p)$. Then I will have $v^p \in V_p P$ since I've killed the component in $H_p P$.
However, I know that $V_p P$ is the same as $\mathfrak g$. Thus, I spit out the value $t^v_p$, treated as an
element of $\mathfrak g$. This tells me how much of $V_p$ is *not* stolen away by $H_p P$ in the decomposition.

So we have the map $\pi_h: T_p P \rightarrow V_p P$ given by $pi_h(t_p) \equiv t_p - H_p(t_p)$. The kernel
of this map is $H_p P = ker(\pi_h)$.

#### Accessing the tangent space from the Ehrsmann Connection

- https://mathoverflow.net/a/94139/123769

#### Generalizing to Non-trivial bundles

If we have a non-trivial bundle, then I need some way to link $\mathfrak g$ with $V_p P$ without splitting the bundle
as I did here. The idea is that element of $T_p P$ are basically curves  $c_p: I \rightarrow P$. We use the curves
to build derivations. For each lie algebra element $a \in \mathfrak g$, I can build the curve
$c^a_p: I \rightarrow P$ given by $c^a_p(t) \equiv p \triangleleft \exp(at)$. That is, the curve I get by pushing
the point $p$ along $a \in \mathfrak g$.  Note that all the points in the curve $a^p$ lie on the same point
in the base manifold, because the group only moves within fibers. So we have that $\pi(p) = \pi(c^a_p(t))$ for all $t$.
This means that when we push forward the curve $c^a_p(t)$, it represents the constant curve, which has zero derivative!
Thus, we have that all these curves are in the kernel $c^a_p(t) \in ker(\pi^*)$, and hence $\mathfrak g \subseteq V_p P$.
To show the other inclusion, pick some element $v_p \in V_p P \subseteq T_p P$. The group $G$ must be non-trivial,
otherwise the bundle will also be trivial. Let $p \in \pi^{-1}(m)$ for some $m$. Note that since the bundle is a principal
bundle, we have that the fiber $\pi^{-1}(m)$ is a $G$-torsor. I guess this is ismorphic as a group to $G$. Now, the
tangent space $T_p P$ is the tangent space the group $G$, which has the same dimension as the lie algebra $\mathfrak g$.
Hence, the function we defined above must be surjective.

NOTE TO SELF: there should be a more direct proof that uses the fact that the fiber is $G$-torsor!

# Quotes from the culture

> “Empathize with stupidity and you’re halfway to thinking like an idiot,”

> 'Absolutely not.  Common misconception that; that fun is relaxing.  If it is,
> you're not doing it right.  That's what the Hole's for; fun.  Fun and games.
> Cools down a bit during the day, but it can get pretty wild, too.  The drink
> festivals are usually the worst.  Shouldn't be any trouble tonight though.
> Fairly quiet.'


> Excuse me, rector,' Gurgeh said, rising.  The old apex's gaze followed him.
> 'Duty calls.' 'Obey,' Hamin said.

> The drums are made from human skin; you can see why each set is called a
> family.

> 'Absolutely not.  Common misconception that; that fun is relaxing.

> As the adage said; falling never killed anybody; it was when you stopped…


> This is not a heroic age,' he told the drone, staring at the fire.  'The
> individual is obsolete.  That's why life is so comfortable for us. We don't
> matter, so we're safe

> Genetechnologically, it's been within their grasp for hundreds of years, but
> it's forbidden.  Illegal, if you remember what that means.' Gurgeh nodded



> As with all sentient Culture constructs, its precise character had not been
> fully mapped out before its construction, but allowed to develop as the
> drone's mind was put together.  The Culture regarded this unpredictable
> factor in its production of conscious machines as the price to be paid for
> individuality, but the result was that not every drone so brought into being
> was entirely suitable for the tasks it had initially been designed for.


> So it's false.' 'What isn't?' 'Intellectual achievement.  The exercise of
> skill.  Human feeling.'


> Just another belch in the darkness. Sound but not a word, noise without
> meaning.

> There seemed little point in telling the creature when; the Dra’Azon called
> every time “now” even though their language used tenses.


> We are water falling, itinerant and vague, ever seeking the lowest level,
> trying to collect and connect. We are vapor, raised against our own devices,
> made nebulous, blown on whatever wind arises. To start again, glacial or not.

> the urge not to feel useless. The Culture’s sole justification for the
> relatively unworried, hedonistic life its population enjoyed was its good
> works; the secular evangelism of the Contact Section, not simply finding,
> cataloguing, investigating and analyzing other, less advanced civilizations
> but—where the circumstances appeared to Contact to justify so doing—actually
> interfering (overtly or covertly) in the historical processes of those other
> cultures.


> And if we tamper with our inheritance, so what? What is more ours to tamper with?

> It was a young, unstable sort of bitterness, a kind of fake, something she
> assumed for a while, like a child trying on adult clothes. She luxuriated in
> the feeling of being old and disillusioned for a moment, then let it drop.

> Idir was never attacked, and technically never surrendered. Its computer
> network was taken over by effector weapons, and—freed of designed-in
> limitations—upgraded itself to sentience, to become a Culture Mind in all but
> name.


> The voice sounded like congealing fat being poured into a jug;

> It would have helped if the Culture had used some sort of emblem or logo;
> but, pointlessly unhelpful and unrealistic to the last, the Culture refused
> to place its trust in symbols. It maintained that it was what it was and had
> no need for such outward representation.


> Just as it could not imprison itself with laws, impoverish itself with money
> or misguide itself with leaders, so it would not misrepresent itself with
> signs.

> There was something too about the inexactitude of it all that the Mind found
> almost frightening. It could look at some carefully machined piece of metal
> or some delicately molded bit of plastic, and know that to the people who had
> built the Command System—to their eyes—these things were exact and precise,
> constructed to fine tolerances with dead straight lines, perfect edges,
> smooth surfaces, immaculate right angles… and so on. But the Mind, even with
> its damaged sensors, could see the rough edges, the crudity of the parts and
> the components involved. They had been good enough for the people at the
> time, and no doubt they had fulfilled the most important criterion of all;
> they worked


> So it had effectively frozen its primary memory and cognitive functions,
> wrapping them in fields which prevented both decay and use. It was working
> instead on back-up picocircuitry, in real space, and using real-space light
> to think with (how humiliating).


> the most select group of rich psychotics in the human galaxy, here to play
> the game that is to real life what soap opera is to high tragedy.

> Originally Damage was played on such occasions because only during the
> breakdown of law and morality, and the confusion and chaos normally
> surrounding Final Events, could the game be carried out in anything remotely
> resembling part of the civilized galaxy; which, believe it or not, the
> Players like to think they’re part of.




# Lie bracket commutator as infinitesimal conjugation


- Consider the map $c(g, h) = ghg^{-1}$. Say we want to study the map near the identity in the first argument.
- So we replace $g$ by $e + \epsilon k$ for identity $e$ and $k$ arbitrary group element.
- This now makes conjugation $(e + \epsilon k) h (e + \epsilon k)^{-1}$.
- Since $(1+x)^{-1} \simeq 1 - x$ by taylor expansion, the above becomes: $(e + \epsilon k) h (e - \epsilon k)$.
- Algebra time:

$$
\begin{aligned}
&(e + \epsilon k) h (e - \epsilon k) \\
&= ehe + e h (- \epsilon k) + \epsilon k) h e - \epsilon k h (-\epsilon k) \\
&= h - \epsilon hk + \epsilon kh - \epsilon^2 khk \\
&\simeq h + \epsilon [k, h] + O(\epsilon^2)
\end{aligned}
$$

- Thus, the linear part/gradient of the conjugation is given by $\epsilon [k, h] = kh - hk$.
- So, the lie bracket corresonds to infinitesimal conjugation.

# Thoughts on proof of fundamental group of unit circle

#### Definition of covering space

It's important that when we say that $p^{-1}(U) = U \times F$, that the local
homeomorphisms of $U \times {i} \rightarrow U$ is given by $p|_{U \times \{ i \}}$:
it is not **some other map** that gives us the homeomorphism, but $p$ itself.
This makes $p$ locally bijective on a nbhd.


#### Path lifting

> A time varying embedding can be lifted for all time given a lift of initial conditions.
> A smoothly varying family of embeddings can be filted given an initial lift.

The fact that we work with intervals are of paramount importance. They are compact,
and we can thus use induction to path lift.

- [Kan extension condition](https://www.imsc.res.in/~kapil/geometry/topol/kan.html)


# Pasting lemma

Let $f: X \rightarrow Y$ be a function.
Let $A, B$ are closed subets of $X$ such that $X = A \cup V$. Then $f$ is continuous iff
$f|_A$ and $f|_B$ are continous.

#### Forward: $f$ continuous implies restriction continuous

This is clear from how restrictions work. Pick $i: A \rightarrow X$ to be the
function that embeds $A$ with the subspace topology into $X$. This is continuous by
the definition of the subspace topology. Now define $f|_A : A \rightarrow Y \equiv f \circ i$.
which is continous since it is the composition of continuous functions.

#### Backward: restrictions continuous implies $f$ continuous.

Let $V \subseteq Y$ be closed. Then $f_A^{-1}(V)$ is closed in $A$ by the continuity of $f_A$
Now see that $f_A^{-1}(V)$ is closed in the subspace topology of $A$  means that
there is some closed $P \subseteq X$ such that $f|_A^{-1}(V) = A \cap P$.
Since both $A$ and $P$ are closed in $X$, this means that $f^{-1}(V)$ is closed
in $X$ (see that we have filted "closed in $A$" to "closed in $X$).
Similarly, we will have that $f|_B^{-1}(V) = B \cap Q$ for some closed $B$ and $Q$.
Then we can write:

$$
\begin{aligned}
&f^{-1}(V) \\
&= f|_A^{-1}(V) \cup f|_B^{-1}(B) \\
&= (A \cap P) \cup (B \cap Q) \\
&= \texttt{finite union of closed sets} \\
&= \texttt{closed} \\
\end{aligned}
$$

# Tensoring with base ring has no effect

If $0 \rightarrow M' \rightarrow M \rightarrow M''$ is an exact sequence of $A$ modules,
then so is $0 \rightarrow A \otimes M' \rightarrow A \otimes M \rightarrow A \otimes M''$.
(As an aside, the order is $M', M, M''$ since the middle term $M$ is somehow
put together from the other two. So $M$ is the primary. Then by human
convention, we choose the single prime on the left and the double prime on the
right).


# Seeing the semidirect product of the dihedral group.

Think of rigid motions of a hexagon. Let's focus on a single edge.
See that the movement of this edge determines everything else.
So let's see where this edge can go to. There are six different
locations it can go to, by "rotating". Not only that, but we can
also "flip" the edge (by flipping the entire hexagon!) This means
we have two types of transformations we can perform on this single
edge, that determines everything else: (1) rotating it, moving it to another
location, and (2) flipping the edge. We might naively decide to mathematically
encode the different moves we can make as `(angle, flip)`, which represents
(a) rotating by an angle, and (b) flipping the hexagon. The next question
one asks is how to write the result of performing one move after another?
- If we have two rotations, we can compose them into another rotation.
- If we have two flips, they compose to become no flip at all.
- What happens if we have `(angle1, flip=true)` followed by `(angle2, flip=False)`?

In fact, there is a subtlety here. What do we mean by "rotate by an angle"? How do
we determine "clockwise" and "anti-clockwise"? There are two choices:
- 1. Define these "from the top view", as viewing the hexagon as the face of a clock.
- 2. Define this "from the view of the edge", as rotating in the direction of the edge.


# Animating rotations with quaternion curves

- [Reference: classic paper](http://graphics.cs.cmu.edu/nsp/course/15-464/Fall05/assignments/p245-shoemake.pdf)
- [Comp.graphics usenet FAQ](http://www.faqs.org/faqs/graphics/algorithms-faq/)

# Mnemonic for hom-tensor and left-right adjoints

- Remember the phrase `tensor-hom` adjunction, thus tensor is left adjoint.
- Remember that the type of an adjunction is `(f x -> y) -> (x -> g y)` and here,
  `f` is left adjoint, `g` is right adjoint. Then see that currying is
  `((p, x) -> y) ->(x -> (p -> y))`. Thus tensor is left adjoint, hom is right
  adjoint.
- Remember that RAPL (right adjoints preserve limits); Then recall that
  tensoring a direct limit (a colimit) preserves the tensor, as a colimit retains
  torsion (example: prufer group has torsion, its components also have torsion; tensor can detect this by
  tensoring with $\mathbb Q$).
  On the other hand, tensoring of an inverse-limit (a limit) is not preserved:
  think of p-adics. Each of the components have torsion, but the p-adics do not.
  Thus, tensor DOES NOT preserve limits (inverse limits). And so, tensor CANNOT
  be right adjoint; tensor must be left adjoint.
- Since tensor is right exact, because it kills stuff, and could this destroy
  injectivity, it is left adjoint.


# Construction of tensor product: Atiyah macdonald

I've only seen two ways of seeing the tensor product: (1) for vector
spaces, where one uses a basis, and (2) the universal property, that
describes the point of the tensor product.
This is the first hands-on-but-not-basis construction
of the tensor product I've seen, and so I record it here.
Let $R$ be the base ring. We are tensoring the modules $M$ and $N$.

- Create the free $R$ module $F \equiv R^{M \times N}$ whose elements are
  free linear combinations of tuples from $M$ and $N$.
- Let $K$ (for kill) be the submodule generated by the equations:
  (1) $(x + x', y) - (x, y) - (x', y)$,
  (2) $(x, y + y') - (x, y) - (x, y')$,
  (3) $(rx, y) - r \cdot (x, y)$
  (4) $(x, ry) - r \cdot (x, y)$
- Let $T \equiv F/K$. Denote the element of each $(x, y) \in F$ in the
  quotient $F/K$ as $x \otimes y$. Then $T$ is generated by such elements.
- From our quotients, we have the equation $(ax) \otimes y = a (x \otimes y) = x \otimes (ay)$,
  and $(x + x') \otimes y = x \otimes y + x' \otimes y$, and finally
  $x \otimes (y + y') = x \otimes y + x \otimes y'$.

Any $R$-module map map $f: M \times N \rightarrow O$ where $O$ is an $R$-module extends by
linearity into   $f_F: F \rightarrow O$ as $f_F(\sum_i r_i (x, y)) \equiv r_i f(x, y)$.
We also have a map $-/\sim : F \rightarrow T$

```
 F=R^{MxN} →fF→ MxN →f→ O
 ↓               ↑
 F/~             fT
 ↓               ↑
 T=M(x)N →→fT→→→→*
```

For this diagram to commute, we need the fibers of $(f \circ f_F): R^{MxN} \rightarrow O$ to take constant values for each $o \in O$.
Unwrapping that condition implies that $f$ is bilinear. So, the condition
$f_T(x \otimes y) = f(x, y)$ uniquely determines $f_T(x \otimes y)$ if $f(x, y)$ is bilinear.
If not, the map $f_T$ is ill-defined, as we cannot "kan extend" $f_F$ along $f_T$.



# Recovering topology from sheaf of functions: Proof from Atiyah Macdonald

Let $X$ be a compact Haussdorff space. Such a space is normal (T4), so we can separate closed subsets
by open neighbourhoods. This also means that the space obeys the Urhyson lemma, so we can construct
continuous functions that take value $0$ at some point and $1$ at some other point. We will use this
to argue about zero sets of functions.

- We will first show a strong nullstellensatz like theorem, showing that every maximal ideal $m$ of
   the ring of continuous functions $C(x)$ is in bijection with the set of functions that vanish at a point, $V(x)$.

- Let $C(X)$ be the ring of all continuous real valued functions on $X$. For each $x \in X$, define
  $I(x) \subseteq C(X)$ to be the set of functions that vanish at $x$.
  This is a maximal ideal, because it is the kernel of the evaluation map $f \mapsto f(x)$.

- Given some maximal ideal $m \subseteq C(X)$, we will show that there is some point $p \in X$ such that
  $m = I(p)$. To show this, first consider the common zeros of functions in $m$, $V(m) \equiv \{ x \in X : f(x) = 0 \forall f \in m \}$.
  We first show that $V(m)$ is non-empty, and we then show that $V(m)$ contains exactly one point.

- To show $V(m)$ is non-empty, suppose for contradiction that $V(m)$ is empty. Thus, for each point $x \in X$,
   not all functions in $m$ vanish at $x$ (otherwise $x \in V(m)$).
   So, there is a function $f_x \in m$ that does not vanish at $x$, hence $f_x(x) \neq 0$. Since $f_x$
   is continuous, there is some open neighbourhood $x \in U_x$ where $f(U_x) \neq 0$. (A continuous function
   that does not vanish at a point cannot "suddenly" decay to zero. It will be non-zero over an open nbhd).
   Since the space $X$ is compact, we have a finite number of $U_{x_i}$ that cover $X$. Hence, we build a function
  $c \equiv \sum_i f_{x_i}^2$ ($c$ for contradiction) that vanishes nowhere. This means $c$ is a unit.
  But we must have $c \in m$ as $c$ is built out of functions  $f_{x_i} \in m$. This is a contradiction as a unit
  cannot belong to a maximal ideal. Thus, $V(m)$ contains at least one point.

- To show that $V(m)$ contains exactly one point, suppose that $V(m)$ contains a single point $x$.
   This means that all functions in $m$ vanish at $x$. Thus, $m \subseteq I(x)$, since $I(x)$ contains all functions
   (not just ones in $m$) that vanish at $x$. But $m$ is maximal, and hence $m = I(x)$. This tells us that
   every maximal ideal $m$ corresponds to some vanishing set $I(x)$.

- We will next show that every vanishing set $I(x)$ is distinct. We already know that it is maximal. This gives us an
   injection. Let $I(p), I(q)$ be two vanishing sets for distinct points. Let $z_p$ be the function constructed from
   Urhyson's lemma that is zero at $p$ at nonzero at $q$. Thus, we have $z_p \in I(p)$ and $z_p \not \in I(q)$. Hence,
   $I(p) \neq I(q)$. This shows that the maximal ideals $I(p), I(q)$ will be distinct.

- We have thus established a **bijection** / **nullstellensatz** between zero sets maximal ideals $V(m)$ and
   functions that vanish at a point $I(p)$.


- We will next show that this provides a homeomorphism. It suffices to consider basic open sets. We know that the
   sets $D_{spec}(f) = \{ m \in C(X) : f \not \in m \}$ is a basis for the maximal spectrum of the ring under zariski.
   We will show that $D_{top}(f) \equiv \{ x \in X: f(x) \neq 0 \}$ is a basis for the topology of $X$. Then the function
   that takes points to maximal ideals of functions that vanish at that point will provide a topological homeomorphism.
   Thus, we have shown that the maximal spectrum of the ring allows us to recover the topology of the underlying space!


- We wish to show that the open set $D_{top}(f)$ form a base for the topology on $X$. So consider an open set
   $U \subseteq X$. Now think of $U^c$ which is closed. We build the function $d(x, U)$ such that $d(x, U)(x) = 1$
   and $d(x, U)(U^c) = 0$ by invoking Urhyson. Therefore, $x \in D_{top}(d(x, U)) \subseteq U$. So the set $U$ can be
   covered with $\{ D_{top}(d(x, U)): x \in U \}$, which means the sets $D(d(x, U))$ form a base of the topology on $X$.

- We wish to show that the open sets $D_{spec}(f)$ form a base for the topology on $maxSpec(C(X))$. Let $U$ be a
   closed  set in $maxSpec(C(X))$.

-  We wish to show that the open set $D_{spec}(f)$ have homeomorphisms $D_{top}(f)$. This completes the isomorphism into a
   homeomorphism, and we have thus completed the proof that we can recover the topology from the spectrum.

- Consider the function $zero: X \rightarrow mSpec(C(X))$  sending the point $x$ to the kernel of the evaluation map at $x$.
   Let $D_{spec}(f) \subseteq mSpec(C(X))$ be a basic open of $mSpec(C(X))$. Consider $zero^{-1}(D_{spec}(f))$.
   This will contain all those points $x \in X$ such that $zero(x) \in D_{spec}(f)$. This means that it will contain
   point $x \in X$ such that $f$ does not vanish at those points, as (1) $zero(x) \in D_{spec}(f)$ implies
   (2) $f \not \in zero(x)$ which implies $f(x) \neq 0$. Clearly, this is an open subset of $X$, as it is the
   complement of the closed set $f(x) = 0$ [zero sets are always closed]. Furthermore, the set $zero^{-1}(D_{spec}(f))$
   maps to what we would expect; it trades the algebraic definition of "does not vanish" to the geometric one,
   while describing the exact same phenomena.

# Urhyson's lemma

We don't know any continuous functions on compact Haussdorf spaces; Let $X$ be a topological space. What functions
$X \rightarrow \mathbb R$ are continuous? We only have the constant functions!
If $X$ is a metric space, can we get more continuous functions? We can probably do something
like $f_p(x) \equiv d(p, x)$. But the compact Haussdorf spaces are very nice, we should know
*something* about them!

we often asumme we have an embedding (a homeomorphism) of a compact Haussdorff space $X$ into $\mathbb R^n$,
I then get so many continuous functions! I can take the polynomials on $\mathbb R^n$ and restrict to $X$.
Polynomials are dense in the compact-open topology! (Stone-Weirstrass)

### Normal space (T4)

A space where points are closed, and two disjoint closed subsets can be separated by open neighbourhoods. It's
stronger than haussdorf, because we can separate subsets, not just points.

### Urhyson lemma

If $X$ is normal and $A, B$ are closed disjoint subsets of $X$, there exists a continuous
function $f: X \rightarrow [0, 1]$ such that $f(A) = 0$ and $f(B) = 1$. This gives us
"interesting continuous function" on an arbitrary topological space.

We ask for normal, because compact Hausfdorff spaces are normal. So "good smooth manifolds"
for example, are normal.

### Lemma: Re-characterization of normality

If $X$ is normal and $C \subseteq O \subseteq X$ with $C$ closed, $O$ open, then there
exists a set $U \subseteq X$ that is open such that $C \subseteq U \subseteq \overline{U} \subseteq O$.
(In fact, this is iff!) See that we "reverse the direction"; We started with closed-open, we end with
closed-(open-closed)-open.

- Consider $C$ and $O^c$. These are two closed sets. Since $C$ is contained in $O$,
  $C$ does not meet $O^c$ ($C \subseteq O$, we have $C \cap O^c = \emptyset$).
- By normality, we have two opens $P, Q$ such that $C \subseteq P$, $O^c \subseteq Q$, and $P \cap Q = \emptyset$.
- So we have $C \subseteq P$, and $P \subseteq Q^c$. This gives us $C \subseteq P \subseteq Q^c \subseteq O$.
- We have $\overline{P} \subseteq Q^c$ as $P \subseteq Q^c$ and $Q^c$ is closed, and thus contains all of its limit points.
- This together gives $C \subseteq P \subseteq \overline{P} \subseteq Q^c \subseteq O$.

### Proof: Intuition

- Suppse we succeeded. Then the only thing we know is that the space is normal, so it is
  rich in open sets. We're going to convert the existence of a continuous function into properties
  of open pre-images. We will then show that we have "enough opens" in $X$ to build the continuous
  function using the pre-image characterization.
- Suppose we succeeded. Then $[0, p) \subseteq [0, 1]$ is open in the subspace topology.
- Define $U_p \equiv f^{-1}([0, p)) \subseteq X$. Each of these $U_p$ are included in one another as we make $p$
  larger.
- In fact, we have

$$U_p = f^{-1}([0, p)) \subseteq f^{-1}([0, p]) \subseteq f^{-1}([0, q)) \subseteq f^{-1}([0, q]])$$

- We have that $\overline{U_p} = f^{-1}([0, p]) \subseteq U_q = f^{-1}([0, q))$ for $p < q$.
- If we now think of the original sets, we needed $f(A) = 0$, $f(B) = 1$. So we must have that $A \subseteq f^{-1}([0, p))$
  for all $p > 0$.
- Similarly, we have that $U_p \subseteq B^c$ for $p < 1$, as till $p$ reache $1$, we cannot get to $B$.
- This gives us $A \subseteq U_p \subseteq B^c$.
- This is the only properties we will use to reconstruct $f$!
- Really, I only need a dense subset of $U_p$. So let's say I pick $\{ U_p : p \in \mathbb Q \}$.
- I can reconstruct $f(x)$ by first thinking of $f(x)$. There are sets $U_p$ that reach towards $f(x)$.
  Consider the closest such
- So take $y = sup(\{ p \in \mathbb Q : p \leq f(x) \} \cup \{ 0 \})$. Because $\mathbb Q$
  is dense in $\mathbb R$, this works out and we get $y = f(x)$
- But if $p \leq f(x)$, this means $x \not \in U_p$ since $U_p$ covers $[0, p)$. So we write this as:
  $y = sup(\{ p \in \mathbb Q : x \not \in U_p \} \cup \{ 0 \})$. Because $\mathbb Q$
  is dense in $\mathbb R$, this works out and reconstructs for us us $y = f(x)$
  (see that we did not use $f$ in the definition of $y$).


### Claim 1

Claim: If $P \subseteq (0, 1)$ is dense, and $\{ U_p \}_{p \in P}$ is a collection of open subsets of $X$
indexed by $p$, such that:

1. $A \subseteq U_p \subseteq B^c$.
2. $\overline{U_p} \subseteq U_q$ whenever $p < q$

Then $f(x) = sup(\{ p \in P : x \not \in U_p \} \cup \{ 0 \})$ is continuous and $f(A) = 0$, $f(B) = 1$.
See that we don't even need normality! (Time: 29:30 in video)

- **Proof:** It's clearly well defined based on $sup$. If it's continuous, then it obeys the properties
  based on the containment assumptions (1) and (2).
- For $p \in P$, We claim $x \not \in U_p \implies f(x) \geq p$. If $x \not \in U_p$,
  then $p$ is in the set of points we take a $sup$ over. Hence, we have that $f(x) \geq p$
  since $f(x)$ is the $sup$.
- The contrapositive is that $f(x) < p \implies x \in U_p$.
- To show $f: X \rightarrow [0, 1]$ is continuous, it suffices to show that preimages of open
  sets are open for a basis. We know a basis consisting of intervals $\{ (p, q) : p, q \in P \}$.
  We need to show that $f^{-1}((r_0, s_0))$ is open for $r_0, s_0 \in P$ with $0 < r_0 < s_0 < 1$.
  [The cases where $r_0 = 0$ or $s_0 = 1$ are easy modifications].
- Choose a $x \in f^{-1}((r_0, s_0))$. Since $P$ is dense, we can find $r_x, s_x$ such that
  $r_0 < r_x < x < s_x < s_0$.
- We claim that $x \in \overline{U_{r_x}}^c \cap U_{s_x}$. $\overline{U_{r_x}}^c$ is open as it is
  the complement of a closed set. Hence, we have shown that $x$ is in this open nbhd.
- Since $f(x) < U_s$, we must have $x \in U_s$ by our contrapositive.
- We claim that $x \not \in \overline{U_r}$. Proof by contradiction; suppose $x \in \overline{U_r}$,
  hence $r < f(x)$.
  Then, for any $r' \in P$ such that $r < r' < f(x)$, we would have $x \in U_r'$ (by 2).
  We claim that this is A CONTRADICTION.
- Since $f(x) = sup(\cdot)$, and $r < f(x)$ we have something in the $sup$ that is bigger than $r$.
  Let this thing be $r'$ such that $x \not \in U_{r'}$. But this is a contradiction to $x \in \overline{U_r}$.
- TODO: there is more to proof!

#### Claim: $P \equiv \mathbb Q \cap (0, 1)$

With $P \equiv \mathbb Q \cap (0, 1)$ there exists a collection $\{ U_p \}_{p \in P}$ as we need.

We will prove this by induction. Choose an bijection $\mathbb Q \cap (0, 1) \equiv \{ p_1, p_2, \dots \}$.
Let $P_n \equiv \{ p_1, p_2, \dots, p_n \}$. To define $U_{p_i}$ choose an open set such
that:

$$A \subseteq U_{p_1} \subseteq U_{p_1}^c \subseteq B^c$$

Such a set exists by our characterization of normality.
Now suppose $U_{p_1}, \dots U_{p_n}$ have been constructed such that $\{ U_p \}$
satisfies the claims (i), (ii). To construct $U_{p_{n+1}}$. Recall that the $p_i$
can be in arbitrary order, since we choose an arbitrary bijection. So let
$r$ be the index such that $p_r$ comes right before $p_{n+1}$, and $s$ comes
right after $p_{n+1}$. This gives us $r = \max \{ p_i | 1 \leq i \leq n \land p_i < p_{r+1} \}$,
$s = \min \{ p_i | 1 \leq i \leq n \land p_i < p_{r+1} \}$. Then $r \leq s$ and $\overline U_r \subseteq U_s$.
Thus by our characterization of normality, there exists an open $V$ such that:

$$
\overline U_r \subseteq V \subset \overline V \subseteq U_s
$$


#### Tietze Extension theorem


If $X$ is normal, $A \subseteq X$ is closed, given a continuous bounded function $f: A \subseteq \mathbb R$
then there exists and continuous and bounded function $F: X \rightarrow \mathbb R$ such that $F|A = f$.

#### Urhyson's Metrization theorem

A normal space with a countable basis is metrizable. We know that metrizable is normal. This says
that normal is not so far away from metrizable.

#### Embedding of topological manifolds

If $X$ is a compact topological $n$-manifold, then there exists an embedding into some $\mathbb R^m$.
That's saying that there are "m" very interesting continuous functions, the coordinate functions! So it
makes sense Urhyson's is involved.




#### References
- [Urhyson's Lemma video](https://www.youtube.com/watch?v=UQas4Cu89D0)
- [Urhyson's Lemma lecture notes](http://therisingsea.org/notes/mast30026/lecture22.pdf)

# Compact Hausdorff spaces are normal


Let $C, D$ be two disjoint closed subsets. We wish to exhibit disjoint opens
$U, V$ which separate $C, D$. Formally, we want $C \subseteq U, D \subseteq V, U \cap V = \emptyset$.


The crucial idea is to take all pairs of points in $C \times D$, and use
Hausdorffness to find opens $\{ (U_{cd}, V_{cd}) : (c, d) \in C \times D \}$
such that $c \in U_{cd}, d \in V_{cd}, U_{cd} \cap V_{cd} = \emptyset$.  which
separate all pairs $c$ and $d$, and then to use compactness to escalate this
into a real separating cover.

Now that we have the pairs, for a fixed $c_0 \in C$, consider the cover
$\cup_{d} V_{cd} $. This covers the set $D$, hence there is a finite subcover
$D \subseteq V_{cD} \equiv \cup_{d_i} V_{c {d_i}}$. Now, we go back, and build the set
$c \in U_{cD} \equiv \cap_{d_i} U_{c {d_i}}$. This is the intersection of a finite
number of opens, and is hence open. So we now have two sets $U_{cD}$ and $V_{cD}$
which separate $c$ from $D$. We can build such a pair $U_{cD}, V_{cD}$ that separates
each $c$ from all of $D$. Then, using compactness again, we find a finite subcover of
sets $U_{c_i D}, V_{c_i D}$ such that the $U_{CD} \equiv \cup_{i=0}^n U_{c_i D}$ cover $C$, each of the
$V_{c_i D}$ cover $D$ (so $V_{CD} \equiv \cap_{i=0}^n V_{c_i} D$ covers $D$). This gives
us our final opens $U_{CD}$ and $V_{CD}$. that separate $C$ and $D$.

# Stone representation theorem: Proof from Atiyah Macdonald

A boolean ring is one where for every element $r \in R$, we have $r^2 = r$. We first
study boolean rings abstactly and collect their properties. Secondly,
we show an isomorphism between complete lattices and boolean rings.
Thirdly, we use the topology from $Spec$ to import a topology on complete lattices,
which will be Haussdorf and completely disconnected.

#### In a boolean ring, all prime ideals are maximal.

Let $p$ be a prime ideal, and let $x \in p$. One is tempted to use jacobson like arguments,
and thus one considers the element $(1 - x)$. Since in this ring, we have $x^2 = x$,
this means that $x(1 - x) = 0$. Hence, we have $x(1 - x) \in p$. This is not so
useful, until we notice that we never used the fact that $x \in p$!. So pick some **arbitrary**
element $y \in R$. To show $p$ a prime ideal is maximal, let $y \not \in p$. Then we know
that $1 - y \in p$. Thus, if $y$ we were added to $p$ (ie, we try to create a larger ideal $m = (y, p)$),
we get $1 - y + y = 1 \in p$. Thus, the ideal $m = (y, p) = 1$ when $y \not \in p$. Thus, $y$
is maximal.

#### In a boolean ring, $2 = 1 + 1 = 0$. More generally, $2x = 0$ for all $x$.

Showing $2x = 0$ is the same as showing $x = -x$. We know that $(-x) = (-x)^2 = x^2 = x$
as in this ring $x^2 = x$ for all $x$. Hence, we have that $x = -x$ or $1 = -1$ or $2 = 0$.


#### In the spectrum of a boolean ring, $D(f)$ for $f \in R$ is clopen

That is, the basic open sets of the prime spectrum of the ring are all clopen. The basic
open sets $D(f)$ (where $D$ stands for doesn't vanish on the prime spectrum)
are open by definition. To show that $D(f)$ is open, we need to find
an ideal $I$ such that $D(f) = V(I)$. Consider $g \equiv 1 - f$. We know
that $f(1 - f) = 0$ for all $f$ and we are considering the prime spectrum.
Thus, either $f$ or $(1 - f)$ must vanish at each point because $f(1 - f)$ vanishes
at each point: so $f(1 - f) = 0 \in p$ implies $f \in p$ or $(1 - f) \in p$.

- To see that $V(1 - f) \subset D(f)$, let $p \in V(1 - f)$. Hence, $1 - f \in p$. Thus, we have
  $f \not \in p$: if $f$ and $(1 - f)$ are both in $p$, then $1 \in p$ which is absurd as $p$ is a proper ideal.
  Hence, $p \in D(f)$. Thus, $V(1 - f) \subset D(f)$.
- To see that $D(f) \subset V(1 - f)$, let $p \in D(f)$, hence $f \not \in p$. But $f(1 - f) = 0 \in p$ since
  the ring is boolean. Hence $(1 - f) \in p$ by the primality of $p$ and since $f(1 - f) \in p$.
  Thus, $p \in V(1 - f)$. Hence, $D(f) \subset V(1 - f)$.

This shows us that each basic open set is clopen, as each basic open is both open and closed.

#### for all rings, The space $Spec(R)$ is quasi-compact: every open cover of $Spec(R)$ has a finite subcover of $Spec(R)$.

We generally only call Haussdorf spaces "compact". The covering property is called "quasi-compact"

Consider an open covering $C_i$ such that $\cup C_i = Spec(R)$. Since the base of the topology
is the doesn't vanish sets, we can write each $C_i$ as $C_i = \cup_j D(f_{ij})$. Hence we have that
$Spec(R) = \cup_{i, j} D(f_{i, j})$. This is the same as saying:

$$
\begin{aligned}
&\emptyset = Spec(R)^c \\
&= (\cup_{i, j} D(f_{i, j}))^c  \\
&= \cap_{i, j} D(f_{i, j})^c \\
&= \cap_{i, j} V(f_{i, j})^c \\
\end{aligned}
$$

Recall that intersecting vanishing sets is the same as building an ideal containing all those functions.
So we have an ideal $I \equiv (f_{11}, f_{12}, \dots, f_{21}, \dots, f_{ij})$.
Saying that the intersection of all $V(f_{ij})$ is empty is saying that $I = R$.
This is by strong nullstellensatz, which states that every maximal ideal (and hence, every ideal which is contained in some maximal ideal)
must have some solution. The only way to not have a solution (ie, to vanish nowhere) is to generate the entire ring.
Thus, we must have that $I \equiv (f_{ij}) = R$, and hence $1 \in R$ implies $1 \in I = (f_{ij})$.
In an ideal, we only ever take **finite sums**. So $1$ is a **finite** linear combination of some $f_{ij}$. So we have
the equation:

$$
1 = g_1 f_{i_1 j_1}  + g_2 f_{i_2 j_2} + \dots + g_n f_{1_n j_n}
$$

Thus we have that $1 \in (f_{i_1 j_1}, f_{i_2 j_2}, \dots f_{i_n j_n}$, and hence $\cap_{k=1}^n V(f_{i_k j_k}) = \emptyset$.
Complementing both sides, we get that $\cup_{k=1}^n D(f_{i_k j_k}) = Spec(R)$. We know that $D(f_{i_k j_k}) \subseteq C_{i_k}$, as
the basic open set $D(f_{i_k j_k})$ was used to cover $C_{i_k}$. Hence, we can "expand out" the finite covering by basic opens
to a finite overing by the covering given to us. So we get $Spec(R) = \cup_{k=1}^n C_{i_k}$.

#### for all rings, each $D(f)$ is quasi-compact

This is a generalization of the fact that $Spec(R)$ is quasi-compact, as $Spec(R) = D(1)$. Localize at $f$, so
build the ring $R_{(f)}$. Intuitively, $Spec(R_f) = D(f)$, as $Spec(R_f)$ only has ideals where $f$ does not vanish.
If $f$ vanishes at a prime $p$, then $f \in p$. But we localize at $f$, hence $f$ becomes a unit, so we get $1 \in p_{(f)}$,
and thus the ideal is no longer an ideal.

#### Topology: Closed subset $S$ of a quasi-compact space $T$ is quasi-compact

Let $S \subseteq T$ be closed. We wish to show that $S$ is quasi-compact; that is,
any cover of $S$ has a finite subcover. Let $C_i$ be an arbtirary cover of $S$.
Create a new cover $C'_i$ which is $C_i$ with $S^c$ added. We add $S^c$ so that
we can cover $T$ with $C'_i$, and from this extract a cover for $S$. This works
since $S^c$ covers no element of $S$; The subcover we get of $C'_i$ will have
to create a covering for $S$ using the sets of $C_i$. Ask for a finite subcover
$F_i$ of $C'_i$. The finite covering of $S$ is $F_i - S^c$.

#### In $Spec(B)$, a boolean ring, the sets $D(f)$ are closed under finite union

We want to show that for each family $D(f_i)$, we have a $g$ such that $D(g) = \cup_i D(f_i)$.
We will show it for two functions; recurse in general. The idea is that if we have $f, g$,
we want to build a function that does not vanish when either $f$ or $g$ vanish. Let's
pretend they are boolean functions. Then we are looking for $f \lor g$. We can realise
or in terms of and (multiplication) and xor(addition) as $h \equiv f \lor g \equiv f + g + fg$.
To re-ring-theory this, write $h = f + g + fg = f + g(1 - f)$. See that (1) if $f$ vanishes ($f = 0$)
then $h = g$, (2) if $g$ vanishes ($g = 0$) then $h = f$ which is as expected. If neither
$f$ nor $g$ vanish at $p$, then in this case, we must have $(1 - f)$ vanishes at $p$, since $f(1 - f) = f - f^2 = 0 \in p$.
Hence $f$ or $f^2$ belong to the prime ideal, and hence one of them must vanish. If $f$
does not vanish, then $(1 - f)$ vanishes, and hence $h = f$ does not vanish. So,
$h$ does not vanish when either $f$ or $g$ do not vanish, which means that $D(f) \cup D(g) = D(h) = D(f + g + fg)$.
Iterate for $n$.

#### In $Spec(B)$, for a boolean ring, the sets $D(f)$ are the **only** subsets that are clopen.

We know that all the $D(f)$ are clopen. We need to show that these are the only ones.
So pick some clopen set $A$ (for "ajar", a pun on clopen). Since $A$ is open, we must that $A$
is a (possibly infinite) union of basic opens $D(f_i)$.
Since $A$ is closed and $Spec(B)$ is quasi-compact, $A$ is also quasi-compact.
Thus, we can extract a finite subcover of $A$ to write $A = \cup_{k=1}^n D(f_{i_k})$.
The sets $D(f)$ are closed under finite union. So there exists some $g$ such that $A = D(g)$.
Thus, any clopen set $A$ can be written as $D(g)$ for some $g$.


#### $Spec(B)$, for a boolean ring, is Haussdorf

Intuitively, since every prime ideal is maximal, given two distint prime ideals $p, q$, we can find
functions $f, g$ such that $f$ vanishes only on $p$ and $g$ vanishes only on $q$. Since the
basic opens are clopen, we can then build opens that separate $p$ from $q$ by complementing
the vanishing sets of $f, g$.

Pick two points $p, q \in Spec(B)$, $p \neq q$.  These are maximal ideals (all prime ideals in $B$ are maximal).
Thus, neither contain the other; So we must have elements $f \in p - q$, and $g \in q - p$. So
we have that $V(f) = \{ p \}$ and $V(g) = \{ q \}$. Since $Spec(B)$ is clopen, we know that
$V(f)^c$ and $V(g)^c$ are also open. So we get neighbourhoods $N_p \equiv V(f) \cap V(g)^c$
and $N_q \equiv V(g) \cap V(f)^c$ such that $N_p \cap N_q = \emptyset$ and $p \in N_p$, and $q \in N_q$.
Thus we are able to separate the space.

#### $Spec(B)$, for a boolean ring, is compact

Compact is just a definition that asks for (1) Haussdorf, and (2) quasi-compact,
both of which we have shown above. Thus, $Spec(B)$ for a boolean ring is compact.

#### A boolean lattice $L$ can be converted into a boolean ring.

Take a boolean lattice $L$ define the zero of the ring to be bottom, so $0 \equiv \bot$,
and the one of the ring to be the top, so $1 \equiv \top$. The addition operation
is XOR, and the multiplication is intersection; So we define $a + b \equiv (a \land \lnot b) \lor (\lnot a \land b)$,
and multiplication as $a \cdot b \equiv a \land b$. It's easy to check that this does obey the
axioms of a commutative ring, and is boolean because $a^2 = a \land a = a$.

#### Boolean rings $B$ are boolean lattices of the clopen sets of the spectra $BRing(Clopen(Spec(B)))$

Take a boolean ring $B$, build its spectra $Spec(B)$. Take the set of all clopens. We have
seen that this is exactly the sets $D(f)$. Let us show that $D(fg) = D(f) \cap D(g)$ and
$D(f + g) = D(f) \oplus D(g)$ where $\oplus$ is the exclusive or of the sets. This induces
a map from the ring operations to the lattice operations.


### Boolean lattices $L$ are the clopen sets of spectra of boolean rings $Clopen(Spec(R(L)))$.

Take a lattice $L$, treat it as a ring, and consider the clopens generated from the ring.
We know that for two elements $l, m$ we have that $lm = l \land m$. From the previous
argument, we know that $D(lm) = D(l) \cap D(m)$. This gies $D(l \land m) =  D(lm) = D(l) \cap D(m)$,
a lattie homomorphism. we get $D(l \lor m) = D(l) \cup D(m)$ by complementing; Since
every set is clopen, we can complement a clopen set $D(l)$ to get some clopen set $D(l)^c$.
But every clopen set can be written as $D(l')$ for some $l'$.




#### Bonus: quotient ring $R/p$ for prime ideal $p$ is $F_2$


# Covariant Hom is left exact

Let's say we have the exact sequence:

$$
0 \rightarrow A \xrightarrow{i} B \xrightarrow{\pi} C \rightarrow 0
$$

Where the first arrow is $i$ for inclusion and the third is $\pi$ for projection.
We now want to consider what happens when we have $Hom(X, -)$ for some target space $X$.

The induced arrows are induced from composition; I will write $(f; g)(x) \equiv g(f(x))$
to mean "first do $f$, then do $g$". Hence, my arrows linking $Hom(X, A)$ to $Hom(X, B)$ will be
$-;i$: To first go from $X$ to $A$, and then apply $i$ to go from $A$ to $B$.

This gives us the sequence (which we are to check if it is exact, and which of the left
and right arrow exist):


$$
0 \xrightarrow{?} Hom(X, A) \xrightarrow{-;i} Hom(X, B) \xrightarrow{;-\pi} Hom(X, C) \xrightarrow{?} 0
$$


#### A particular example


As usual, we go to the classic exact sequence:


$$
0 \xrightarrow 2Z \rightarrow{\pi} Z \rightarrow{\pi} Z/2Z \rightarrow 0
$$

We now have three interesting choices for our $X$ in relation to the above sequence:
(a) $Z$, (b) $2Z$, (c) $Z/2Z$. Since $Z$ and $2Z$ are isomorphic as modules, let's study
the case with $Z$ and $Z/2Z$


#### $Hom(-; Z)$
#### $Hom(-; Z/2Z)$

# Internal versus External semidirect products

Say we have an inner semidirect product. This means we have subgroups $N, K$ such that $NK = G$,
$N$ normal in $G$ and $N \cap K = \{ e \}$. Given such conditions, we can realize $N$ and $K$
as a semidirect product, where the action of $K$ on $N$ is given by conjugation in $G$.
So, concretely, let's think of $N$ (as an abstract group) and $K$ (as an abstract group)
with $K$ acting on $N$ (by conjugation inside $G$). We write the action of $k$ on $n$
as $n^k \equiv knk^{-1}$.  We then have a homomorphism $\phi: N \ltimes K \rightarrow G$
given by $\phi((n, k)) = nk$. To check this is well-defined, let's take $s, s' \in N \ltimes K$, with
$s \equiv (n, k)$ and $s' \equiv (n', k')$. Then we get:

$$
\begin{aligned}
&\phi(ss') = \\
&=\phi((n, k) \cdot (n', k')) \\
&\text{definition of semidirect product via conjugation:} \\
&= \phi((n {n'}^k, kk')) \\
&\text{definition of $\phi$:} \\
&= n n'^{k} kk' \\
&\text{definition of $n'^k = k n' k^{-1}$:} \\
&= n k n'k^{-1} k k'  \\
&= n k n' k'  \\
&= \phi(s) \phi(s')
\end{aligned}
$$

So, $\phi$ really is a homomorphism from the external description (given in terms of the conjugation)
and the internal description (given in terms of the multiplication).

We can also go the other direction, to start from the internal definition and get to the conjugation.
Let $g \equiv nk$ and $g' \equiv n'k'$. We want to multiply them, and show that the multiplication
gives us some other term of the form $NK$:

$$
\begin{aligned}
gg' \\
&= (n k) (n' k')  \\
&= n k n' k'  \\
&= \text{insert $k^{-1}k$: } \\
&= n k n' k^{-1} k k' \\
&= n (k n' k^{-1}) k k' \\
&= \text{$N$ is normal, so $k n' k^{-1}$ is some other element $n'' \in N$:} \\
&= n n'' k k' \\
&= N K
\end{aligned}
$$

So, the collection of elements of the form $NK$ in $G$ is closed. We can check that the other properties
hold as well.


# Splitting of semidirect products in terms of projections

Say we have an exact sequence that splits:

$$
0 \rightarrow N \xrightarrow{i} G \xrightarrow{\pi} K \rightarrow 0
$$

with the section given by $s: K \rightarrow G$ such that $\forall k \in K, \pi(s(k)) = k$.
Then we can consider the map $\pi_k \equiv s \circ pi: G \rightarrow G$. See that this firsts
projects down to $K$, and then re-embeds the value in $G$. The cool thing is that
this is in fact *idempotent* (so it's a projection!) Compute:

$$
\begin{aligned}
&\pi_k \circ \pi_k \\
&= (s \circ \pi) \circ (s \circ \pi ) \\
&= s \circ (\pi \circ s) \circ \pi ) \\
&= s \circ id \circ \pi \\
&= s \circ \pi = \pi_k \\
\end{aligned}
$$

So this "projects onto the $k$ value". We can then extract out the $N$ component as
$\pi_n: G \rightarrow G; \pi_n(g) \equiv g \cdot \pi(k)^{-1}$.



# Tensor is right exact

Consider an exact sequence

$$
0 \rightarrow A \xrightarrow{f} B \xrightarrow{g} C \rightarrow 0
$$

We wish to consider the operation of tensoring with some ring $R$.
For a given ring morphism $h: P \rightarrow Q$ this induces a new
morphism $R \otimes h: R \otimes A \rightarrow R \otimes B$ defined
by $h(r \otimes a) \equiv r \otimes h(a)$.

So we wish to contemplate the sequence:


$$
R \otimes A \xrightarrow{R \otimes f} R \otimes B \xrightarrow{R \otimes g} R \otimes C
$$


To see if it is left exact, right exact, or both. Consider the classic sequence of
modules over $\mathbb Z$:

#### A detailed example


$$
0 \rightarrow 2\mathbb Z \xrightarrow{i} \mathbb Z \xrightarrow{\pi} \mathbb Z / \mathbb 2Z \rightarrow 0
$$

Where $i$ is for inclusion, $\pi$ is for projection. This is an exact sequence, since it's of the form
kernel-ring-quotient. We have three natural choices to tensor with: $\mathbb Z, \mathbb 2Z, \mathbb Z/\mathbb 2Z$.
By analogy with fields, tensoring with the base ring $\mathbb Z$ is unlikely to produce anything of interest.
$\mathbb 2Z$ maybe more interesting, but see that the map $1 \in \mathbb Z \mapsto 2 \in 2 \mathbb Z$ gives us an
isomorphism between the two rings. That leaves us with the final and most interesting element (the one with torsion),
$\mathbb Z / \mathbb 2Z$. So let's tensor by this element:

$$
\mathbb Z/2\mathbb Z \otimes  2\mathbb Z \xrightarrow{i'}
\mathbb Z/2\mathbb Z \otimes  \mathbb Z \xrightarrow{\pi'}
\mathbb Z/2\mathbb Z \otimes  \mathbb Z / \mathbb 2Z
$$

- See that $\mathbb Z/2\mathbb Z \otimes 2 \mathbb Z$ has elements of the form $(0, *) = 0$,
  We might imagine that the full ring collapses since
  $1 \otimes 2k) = 2(1 \otimes k) = 2 \otimes k = 0$ (since $2 = 0$ in $\mathbb Z/2\mathbb Z$). But this in fact
  incorrect! Think of the element $1 \otimes 2$. We *cannot* factorize this as $2(1 \otimes 1)$ since $1 \not \in 2 \mathbb Z$.
  So we have the element $1 \otimes 2 \in \mathbb Z/2\mathbb Z / \times 2 \mathbb Z$.
- See that $\mathbb Z/2\mathbb Z \otimes \mathbb Z \simeq \mathbb Z/2\mathbb Z$:
  Factorize $(k, l) = l(k, 1) = (kl, 1) \simeq \mathbb Z/2 \mathbb Z$.
- Similarly, see that $\mathbb Z/2\mathbb Z \otimes \mathbb Z/2\mathbb Z  \simeq \mathbb Z/2\mathbb Z$.
  Elements $0 \otimes 0, 0 \otimes 1, 1 \otimes 0 \simeq 0$ and $1 \otimes 1 \simeq 1$.
- In general, Let's investigate elements $a \otimes b \in \mathbb Z/n\mathbb Z \otimes \mathbb Z/m\mathbb mZ$ .
  We can write this as $ab 1 \otimes 1$. The $1 \otimes 1$ gives us a "machine" to reduce the number by $n$ and by $m$.
  So if we first reduce by $n$, we are left with $r$ (for remained) for some $ab = \alpha n + r$. We can then reduce
  $r$ by $m$ to get $ab = \alpha n + \beta m + r'$. So if $r' = 0$, then we get $ab = \alpha n + \beta m$. But see that
  all elements of the form $\alpha n + \beta m$ is divisible by $gcd(n, m)$. Hence, all multiples of $gcd(n, m)$ are sent
  to zero, and the rest of the action follows from this. So we effectively map into $\mathbb Z/ gcd(m, n) \mathbb Z$
- In fact, we can use the above along with (1) write finitely generated abelian groups as direct sum of cyclic groups,
  (2) tensor distributes over direct sum. This lets us decompose tensor products of all finitely generated
  abelian groups into cyclics.
- This gives us another heuristic argument for why $\mathbb Z \times \mathbb Z/2\mathbb Z \simeq \mathbb Z/2 \mathbb Z$.
  We should think of $\mathbb Z$ as $\mathbb Z/\mathbb \infty Z$, since we have "no torsion" or "torsion at infinity".
  So we get the tensor product should have $gcd(2, \infty) = 2$.
- Now see that the first two components of the tensor give us a map from
  $\mathbb Z/2\mathbb Z \otimes \mathbb 2Z \xrightarrow{i} \mathbb Z/2\mathbb Z \otimes \mathbb Z$ which sends:

$$
\begin{aligned}
&x \otimes 2k \mapsto x \otimes 2k \in \mathbb Z/2\mathbb Z \otimes \mathbb Z \\
&= 2 (x \otimes k) \\
&= (2x \otimes k) \\
&=0 \otimes k = 0
\end{aligned}
$$

- This map is not injective, since this map kills everything! Intuitively, the "doubling" that is latent
  in $2\mathbb Z$ is "freed" when injecting into $\mathbb Z$. This latent energy explodes on contant
  with $\mathbb Z/2 \mathbb Z$ giving zero. So, the sequence is no longer left-exact, since the map is
  not injective!



- So the induced map is identically zero! Great, let's continue, and inspect the tail end
  $ \mathbb Z/2\mathbb Z \otimes  \mathbb Z \xrightarrow{\pi} \mathbb Z/2\mathbb Z \otimes  \mathbb Z / \mathbb 2Z$.
  Here, we sent the element $(x, y) \mapsto (x, y \mod 2)$. This clearly gives us all the elements: For example,
  we get $0 \otimes 0$ as the preimage of $0 \times 2k$ and we get $1 \otimes 1$ as the preimage of (predictably)
  $1 \otimes (2k+1)$. Hence, the map is surjective.

So finally, we have the exact sequence:

$$
\mathbb Z/2\mathbb Z \otimes  2\mathbb Z \xrightarrow{i'}
\mathbb Z/2\mathbb Z \otimes  \mathbb Z \xrightarrow{\pi'}
\mathbb Z/2\mathbb Z \otimes  \mathbb Z / \mathbb 2Z \rightarrow 0
$$

We do NOT have the initial $(0 \rightarrow \dots)$ since $i'$ is no longer injective.
It fails injectivity as badly as possible, since $i'(x) = 0$. Thus, tensoring is
RIGHT EXACT. It takes right exact sequences to right exact sequences!


#### The general proof

Given the sequence:

$$
A \xrightarrow{i} B \xrightarrow{\pi} C \rightarrow 0
$$

We need to show that the following sequence is exact:

$$
R \otimes A \xrightarrow{i'} R \otimes B \xrightarrow{\pi'} R \otimes C \rightarrow 0
$$

- First, to see that $\pi'$ is surjective, consider the basis element $r \otimes c \in R \otimes C$.
  Since $\pi$ is surjective, there is some element $b \in B$ such that $\pi(b) = c$. So the element
  $r \otimes b \in B$ maps to $r \otimes c$ by $\pi'$; $\pi'(r \otimes b) = r \otimes \pi(b) = r \otimes c$
  (by definition of $\pi$, and choice of $b$). This proves that $B \xrightarrow{\pi'} R \otimes C \rightarrow 0$
  is exact.

- Next, we need to show that $im(i') = ker(\pi')$.
- To show that $im(i') \subseteq ker(\pi')$, consider an arbitrary $r \otimes a$. Now compute:

$$
\begin{aligned}
&\pi'(i'(r \otimes a))  \\
&= \pi'(r \otimes i(a)) \\
&= r \otimes \pi(i(a))
& \text{By exactness of $A \xrightarrow{i} B \xrightarrow{\pi} C$, $\pi(i(a)) = 0$:} \\
&= r \otimes 0  \\
&= 0
\end{aligned}
$$
So we have that any element in $i'(r \otimes a) \in im(i')$ is in the kernel of $\pi'$.

Next, let's show $ker(\pi') \subseteq im(i')$. This is the "hard part" of the proof. So let's
try a different route. I claim that if $im(i') = ker(\pi')$ iff $coker(i') = R \otimes C$. This
follows because:

$$
\begin{aligned}
&coker(i) = (R \otimes B)/ im(i') \\
& \text{Since } im(i') = ker(\pi')
&= (R \otimes B)/ker(\pi') \\
& \text{Isomorphism theorem: } \\
&= im(\pi') \\
& \text{$\pi'$ is surjective: } \\
&= R \otimes C
\end{aligned}
$$

Since each line was an equality, if I show that $coker(i) = R \otimes C$, then I have that $im(i') = ker(\pi')$.
So let's prove this:


$$
\begin{aligned}
&coker(i) = (R \otimes B)/ im(i') \\
&= (R \otimes B)/i'(R \otimes A) \\
& \text{Definition of $i'$: } \\
&= (R \otimes B)/(R \otimes i(A)) \\
\end{aligned}
$$

I claim that the $(R \otimes B)/( R \otimes i(A)) \simeq R \otimes (B/i(A))$ (informally, "take $R$ common").
Define the quotient map $q: B \rightarrow B/i(A)$. This is a legal quotient map because $i(A) = im(i) \simeq ker(\pi)$
is a submodule of $B$.

$$
\begin{aligned}
q : B \rightarrow B/i(A) \\
f: R \otimes B \rightarrow  \rightarrow R \otimes (B / i(A)) \\
f(r \otimes b) = r \otimes  q(b) \\
r \otimes b  \in R \otimes B \xrightarrow{f = R \otimes q } r \otimes q(b) \in R \otimes B/i(A)
\end{aligned}
$$

Let's now study $ker(f)$. It contains all those elements such that $r \otimes q(b) = 0$.
But this is only possible if $q(b) = 0$. This means that $b \in i(A) = im(i) = ker(\pi)$.
Also see that for every element $r \otimes (b + i(A)) \in R \otimes (B/i(A))$, there is an inverse
element $r \otimes b \in R \otimes B$. So, the map $f$ is *surjective*. Hence, $im(f) \simeq R \otimes (B/i(A))$.
Combining the two facts, we get:

$$
\begin{aligned}
&domain(f)/ker(f) \simeq im(f) \\
&(R \otimes B)/(R \otimes (B/i(A))) \simeq R \otimes (B/i(A))
&coker(i) = (R \otimes B)/(R \otimes (B/i(A))) \simeq R \otimes (B/i(A)) = R \otimes C
\end{aligned}
$$

Hence, $coker(i) \simeq R \otimes C$.


- [Reference: Kyle Miller's notes on the exactness of the tensor product](https://math.berkeley.edu/~kmill/notes/tensor.pdf)



# Semidirect product as commuting conditions

Recall that in $N \ltimes K = G$, $N$ is normal. This is from the mnemonic
that it looks like $N \triangleleft G$, or from the fact that the acting/twisting subgroup
$K$ is a fish that wants to "eat"/act on the normal subgroup $N$.


So, we have $knk^{-1} \in N$ as $N$ is normal, thus $knk^{-1} = n'$. This can be
written as $kn = n'k$. So:

- When commuting, the element that *gets changed/twisted* in the normal subgroup.
  This is because the normal subgroup has the requisite constraint on it to be
  twistable.
- The element that remains invariant is the actor.

In the case of translations and rotations, it's the translations that are normal.
This can be seen either by noticing that they are abelian, and are thus normal, while
rotations don't "look normal". Alternatively, one can try to consider translate-rotate
versus rotate-translate.


<img src="./static/semidirect-product/rotate-translate.png"/>
- First rotating by $r$ and then translating by $t$ along the x-axis
  has the same effect as first translating by $t'$ at 45 degrees to the x-axis,
  and then rotating by the **same** r.

- This begs the question, is there some other
  translation `t''` and some other rotation `r''` such that `t''; r''` (`t''` first, `r''` next)
  has the same effect as `r;t` (`r` first, `t` next)?

<img src="./static/semidirect-product/translate-rotate.png"/>

- First let's translate by $t$ along the x-axis and then rotating by $r$.
  Now let's think, if we wanted to rotate and then translate, what rotation would
  we start with? it would HAVE TO BE $r$, since there's no other way to get the axis
  in such an angle in the final state. But if we rotate by $r$, then NO translation
  can get us to the final state we want. So, it's impossible to find a `rotation;translation`
  pair that mimics our starting `translation;rotation`.


# Exact sequences for semidirect products; fiber bundles

#### Fiber bundles

In the case of a bundle, we have a sequence of maps $F \rightarrow E \rightarrow B$ where
$F$ is the fiber space (like the tangent space at the identity $T_eM$). $E$ is the total space (the bundle $TM$),
and $B$ is the base space (the manifold $M$). We require that the inverse of the projection
$\pi^{-1}: B \rightarrow E$ locally splits as product $\pi^{-1}(U) \simeq U \times F$.

#### Semidirect products

In a semidirect product $N \ltimes K$, we have that $N$ is normal (because the fish wants to eat
the normal subgroup $N$ / the symbol looks like $N \triangleleft G$ which is how we denote normality).
Thus, we can only quotient by $N$, leaving us with $K$. This is captured by the SES:

$$
0 \rightarrow N \rightarrow  N \ltimes K \xrightarrow{\pi} K \rightarrow 0
$$

- We imagine this as a bundle, with base space $M=K$, bundle $TM=N \ltimes K$,
  and fiber space (like, tangent space at the identity, say) $T_e M =  N$.

- Furthermore, this exact sequence splits; So there is a map $s: K \rightarrow N \ltimes K$
  ($s$ for "section/split") such that $\forall k, \pi(s(k)) = k$. To see that this is true,
  define $s(k) \equiv (e, k)$. Since all actions of $K$  fix the identity $e \in N$, we have
  $s(k)s(k') = (e, k) (e, k') = (e, kk') = s(kk')$ so this is a valid map. To see that $\pi$
  is its inverse, just act $\pi$; $\pi(s(k)) = \pi(e, k) = k$.


#### Viewing the semidirect product space as a G-bundle

Consider the space $E \equiv N \ltimes K$ as a bundle over $K$
given by the projection $E \equiv N \ltimes K \xrightarrow{\pi} K$. We can have $N$ act on the fibers
by a left and a right action. Let's consider both:

- $N$ acting on right: $(n, k) \triangleleft (n', e) \equiv (n n'^k, ke) \equiv (n n'^k, k)$
- $N$ acting on left: $(n', e) \triangleright (n, k) \equiv (n' n^e, k) = (n' n, k)$
   This is the "easier action" to interpret;
  it permutes fibers, keeping the base space the same. So this gives a principal bundle action.
- $K$ acting on right: $(n, k) \triangleleft (e, 'k) \equiv (n e^k, kk') = (ne, kk') = (n, kk')$.
  This action is easy, it permutes fibers.
- $K$ acting on left: $(e, k') \triangleright (n, k) \equiv (e n^{k'}, k'k) \equiv (n^{k'}, kk')$.


So we see that $N$ acting on the left gives us an action that permutes inside fibers,
and $K$ acting on the right gives us an action that permutes the fibers themselves.
So we can write this as $N \triangleright N \ltimes K \triangleleft K$ to capture
the base-space bundle-space relationship, perhaps.

Also, see that if we quotient $N \ltimes K$ by the action of $G\equiv N$ acting on
the left, with the quotient map called $[\cdot]$ for orbit equivalence classes,
we get $N\ltimes K \xrightarrow{[\cdot]} (N \ltimes K)/N = K$, which is isomorphic
to our starting picture $N \ltimes K \xrightarrow{\pi} K$. Hence, it is indeed true
that this bundle is a principal $G$-bundle.

- [Ref: Geometrical anatomy of theoretical physics, lecture 19, principal bundles](https://www.youtube.com/watch?v=vYAXjTGr_eM&list=PLPH7f_7ZlzxTi6kS4vCmv4ZKm9u8g5yic&index=19)


#### Relationship to gauges

**NOTE**: this was written before I knew what a G-bundle is. This is perhaps
easier to read, but less useful in hindsight.

Let $X$ be the space of *all* states. Let $O$ be a group action whose orbits identify
equivalent states. So the space of "physical states" or "states that describe the same
physical scenario" is the orbit of $X$ under $O$, or $X/O$.
Now, the physical space $X/O$ is acted upon by some
group $G$.  If we want to "undo the quotienting" to have $G$ act on all of $X$, then we need to construct $G \ltimes O$.
$G$ is normal here because $O$ already knows how to act on the whole space; $G$ does not, so $O$ needs to "guide" the action of
$G$ by acting on it.  The data needed to construct $G \ltimes O$ is a *connection*.
Topologically, we have $X \rightarrow X/O$ and $G \curvearrowright X/O$. We want to extend
this to $(G \ltimes O) \curvearrowright X$. We imagine this as:

```
*1| #1 | @1  X
*2| #2 | @2
*3| #3 | @3
  | |  |
  | v  |
* | #  | @ X/H
```

where the action of $H$ permutes amongst the fibers of `*, #, @`. Next, we have an action of $G$ on $X/H$:


```
*1| #1 | @1  X
*2| #2 | @2
*3| #3 | @3
  | |  |
  | v  |
* | #  | @ [X/H] --G--> # | @ | *
```

We need to lift this action of `H` the `H`-orbits. This is precisely the data a
connection gives us (why?) I guess the intuition is that the orbits of $X$ are like
the tangent spaces where $X \rightarrow X/O$ is the projection from the bundle
into the base space, and the $G$ is a curve that tells us what the "next point" we want to
travel to from the current point. The connection allows us to "lift" this to
"next tangent vector". That's quite beautiful.

We want the final picture to be:

```
*1| #1 | @1  X          #2| @2|
*2| #2 | @2    --G-->   #1|   |
*3| #3 | @3             #3|   |
  | |  |                  |   |
  | v  |                  |   |
* | #  | @ [X/H] --G--> # | @ | *
```


#  Semidirect product is equivalent to splitting of exact sequence

Consider the exact sequence

$$
0 \rightarrow N \xrightarrow{\alpha} G \xrightarrow{\pi} H \rightarrow 0
$$

- We want to show that if there exists a map $s: H \rightarrow G$ such that
  $\forall h, \pi(s(h)) = h$ (ie, $\pi \circ s = id$), then G$ \simeq N \ltimes H$.
  So the splitting of the exact sequence decomposes $G$ into a semidirect product.
- The idea is that elements of $G$ have an $N$ part and a $K$ part. We can get the $K$
  part by first pushing into $K$ using $\pi$ and then pulling back using $s$. So define
  $k: G \rightarrow G; k(g) \equiv s(\pi(g))$. This gives us the "K" part. To get the $N$
  part, invert the "k part" to annihiliate it from $G$. So define a map
  $n: G \rightarrow G; n(g) \equiv g k(g)^{-1} = g k(g^{-1})$.
- See that the image of $n$ lies entirely in the kernel of $\pi$, or the image of $n$
  indeed lies in $N$. This is a check:

$$
\begin{aligned}
&\pi(n(g)) \\
= \pi(g k(g^{-1})) \\
= \pi(g) \pi(k(g^{-1})) \\
= \pi(g) \pi(s(\pi(g^{-1}))) \\
= \text{$\pi(s(x)) = x$:}\\
= \pi(g) \pi(g^{-1}) = e
\end{aligned}
$$

- Hence, the image of $n$ is entirely in the kernel of $\pi$. But the kernel of $\pi$ is isomorphic to $N$,
  and hence the image of $n$ is isomorphic to $N$. So we've managed to decompose an element of $G$ into a $K$
  part and an $N$ part.
- Write $G$ as $N \ltimes K$, by the map $\phi: G \rightarrow N \ltimes K; \phi(g) = (n(g), k(g))$.
  Let's discover the composition law.

$$
\begin{aligned}
&\phi(gh) =^? \phi(g) \phi(h) \\
&(n(gh), k(gh)) =^? (n(g), k(g)) (n(h), k(h)) \\
&(ghk((gh)^{-1}), k(gh)) =^? (gk(g^{-1}), k(g)) (hk(h^{-1}), k(h)) \\
\end{aligned}
$$

We need the second to be $k(gh) = k(g) k(h)$, so that composes in an
entirely straightforward fashion. For the other component, we need:


$$
\begin{aligned}
&ghk((gh)^{-1})  =^? gk(g^{-1}) \cdot hk(h^{-1}) \\
&ghk((gh)^{-1})  =^? gk(g^{-1}) k(g) \cdot hk(h^{-1}) k(g^{-1}) \\
&ghk((gh)^{-1})  =^? g [k(g^{-1}) k(g)] \cdot h [k(h^{-1}) k(g^{-1})] \\
&ghk((gh)^{-1})  =^? g \cdot h k((gh)^{-1}) \\
&ghk((gh)^{-1})  = gh k((gh)^{-1}) \\
\end{aligned}
$$

So we need the $n$ of $h$ to be twisted by the $k$ component of $g$ by a conjugation. So we define the semidirect
structure as:

$$
\begin{aligned}
(n(g), k(g)) \cdot (n(h), k(h)) \equiv (n(g) k(g) n(h) k(g)^{-1}, k(g) k(h)) \\
&= (n(g) n(h)^{k(g)}, k(g) k(h))
\end{aligned}
$$

We've checked that this works with the group structure. So we now have a morphism $\phi: G \rightarrow N \ltimes K$.
we need to check that it's an isomorphism, so we need to make sure that this has full image and trivial kernel.

- Full image: Let $(n, k) \in N \ltimes K$. Create the element $g = \alpha(n) s(k) \in G$.
  We get $\pi(g) = \pi(\alpha(n)s(k)) = \pi(\alpha(n)) \pi(s(k)) = e k = k$.
  We get $n(g) = g k$

- [physics.se](https://physics.stackexchange.com/questions/13153/discrete-gauge-theories/13171#13171)





# Intro to topological quantum field theory

- Once again, watching a videos for shits and giggles.
- Geometrically, we cut and paste topological indices / defects.
- QFT in dimensions n+1 (n space, 1 time)
- Manifold: $X^n$. Can associate a hilbert space of states $H_x$.
- Space of wave functions on field space.
- Axioms of hilbert space: (1) if there is no space, the hilbert space $H_\emptyset$ for it is the complex numbers.
  (2) If we re-orient the space, the hilbert space becomes the dual $H_{-X} = H_X^\star$.
  (3) Hilbert space over different parts  is the tensor product: $H_{X \cup Y} = H_X \otimes H_Y$.
- We want arbitrary spacetime topology. We start at space $X$, and we end at a space $Y$.
  The space $X$ is given positive orientation to mark "beginning" and $Y$ is given negative orientation
  to mark "end". We will have a time-evolution operator $\Phi: H_X \rightarrow H_Y$.
- We have a composition law of gluing: Going from $X$ to $Y$ and then from $Y$ to $Z$ is the same as going from
  $X$ to $Z$. $\phi_{N \circ M} = \phi_N \circ \phi_M$.
- If we start and end at empty space, then we get a linear map $\Phi: H_\emptyset \rightarrow H_\emptyset$ which is a linear map
  $\Phi: \mathbb C \rightarrow \mathbb C$, which is a fancy way to talk about a complex number (scaling)
- If we start with an empty set and end at $Y$, then we get a function $\Phi: H_\emptyset \rightarrow H_Y \simeq \mathbb C \rightarrow \mathbb Y$. But this is the same as picking a state, for example, $\Phi(1) \in H_Y$ [everything else is determined by this choice].
- If a manifold has two sections $X$ and $-X$, we can glue $X$ to $-X$ to get the trace.
- Quantum mechanics is `0 + 1` TQFT (!)
- TQFT of 1+1 dimensions.
- Take a circle: $S^1 \rightarrow H$.  Let $H$ be finite dimensional.
- A half-sphere has a circle as boundary. So it's like $H_\emptyset \rightarrow H_{S^1}$. This is the ket $|0\rangle$.
- This is quite a lot like a string diagram...
- [Frobenius algebra](https://en.wikipedia.org/wiki/Frobenius_algebra)
- [Video: IAS PiTP 2015](https://www.youtube.com/watch?v=jEEQO-tcyHc)



# Non examples of algebraic varieties

It's always good to have a stock of non-examples.

#### Line with hole: Algebraic proof

The set of points $V \equiv \{ (t, t) : t \neq 42, t \in \mathbb R \} \subseteq mathbb R^2$ is not
a variety. To prove this, assume it is a variety defined by equations $I(V)$.
Let $f(x, y) \in I(V) \subseteq \mathbb R[x, y]$. Since $f$ vanishes on $V$, we must
have $f(a, a) = 0$ for all $a \neq 42$ (since $(a, a) \in V$ for all $a \neq 42$).
So create a new function $g(a) \equiv (a, a)$. Now $f \circ g: \mathbb R \rightarrow \mathbb R = f(g(a)) = f(a, a) = 0$.
This polynomial (it is a composition of polynomial, and is thus a polynomial)
has infinitely many zeroes, and is thus identically zero. So, $f(g(a)) = 0$, So $f(a, a) = 0$ for all
$a$. In particular, $f(42, 42) = 0$ for all equations that define $V$, hence $(42, 42) \in I(V)$. But this
does not give us the variety $V$. Hence $V$ is not a variety.

#### Line with hole: Analytic proof

The set of points $V \equiv \{ (t, t) : t \neq 42, t \in \mathbb R \} \subseteq mathbb R^2$ is not
a variety. To prove this, assume it is a variety defined by equations $I(V)$.
Let $f(x, y) \in I(V) \subseteq \mathbb R[x, y]$. Since $f$ vanishes on $V$, we must
have $f(a, a) = 0$ for all $a \neq 42$ (since $(a, a) \in V$ for all $a \neq 42$).
Since $f$ is continuous, $f$ preserves limits. Thus, $\lim_{x \to 42} f(x, x) = f(\lim_{x \to 42} (x, x))$.
The left hand side is zero, hence the right hand size must be zero. Thus, $f(42, 42) = 0$.
But this can't be, because $(42, 42) \not \in V$.

#### $\mathbb Z$

The set $\mathbb Z$ is not an algebraic variety. Suppose it is, and is the zero set
of a collection of polynomials $\{ f_i \}$. Then for some $f_i$, they must vanish on at least
all of $\mathbb Z$, and maybe more. This means that $f_i(z) = 0$ for all $z \in \mathbb Z$. But a
degree $n$ polynomial can have at most $n$ roots, unless it is the zero polynomial.
Since $f_i$ does not have a finite number of roots, $f_i = 0$. Thus, all the polynomials
are identically zero, and so their zero set is not $\mathbb Z$; it is all of $\mathbb R$.


#### The general story

In general, we are using a *combinatorial* fact that a $n$ degree polynomial has at most $n$ roots.
In some cases, we could have used *analytic* facts about continuity of polynomials, but it suffices
to simply use *combiantorial* data which I find interesting.

# Nilradical is intersection of all prime ideals

#### Nilradical is contained in intersection of all prime ideals

Let $x \in \sqrt 0$. We must show that it is contained in all prime ideals.
Since $x$ is in the nilradical, $x$ is nilpotent, hence $x^n = 0$ for some $n$. Let $p$ be an
arbitrary prime ideal. Since $0 \in p$ for all prime ideals, we have
$x^n = 0 \in p$ for $x$. This means that $x^n = x \cdot x^{n-1} \in p$,
and hence $x \in p \lor x^{n-1} \in p$.  If $x \in p$ we are done.
If $x^{n-1} \in p$, recurse to get $x \in p$ eventually.


#### Proof 1: Intersection of all prime ideals is contained in the Nilradical

Let $f$ be in the intersection of all prime ideals. We wish to show that $f$
is contained in the nilradical (that is, $f$ is nilpotent). We know that $R_f$ ($R$
localized at $f$) collapses to the zero ring iff $f$ is nilpotent. So we wish to
show that the sequence:

$$
\begin{aligned}
0 \rightarrow R_f \rightarrow 0
\end{aligned}
$$

is exact. But exactness is a local property, so it suffices to check against each $(R_f)_m$ for
all maximal ideals $m$. Since $(R_f)_m = (R_m)_f$ (localizations commute), let's reason about $(R_m)_f$.
We know that $R_m$ is a local ring as $m$ is prime (it is maximal), and thus $R_m$ has only a single
ideal $m$. Since $f \in m$ for all maximal ideal $m$ (since $f$ lives in the intersection of all prime
ideals), localizing at $f$ in $R_m$ blows up the only remaining ideal, collapsing us the ring to give
us the zero ring. Thus, for each maximal ideal $m$, we have that:


$$
\begin{aligned}
0 \rightarrow (R_f)_m \rightarrow 0
\end{aligned}
$$

is exact. Thus, $0 \rightarrow R_f \rightarrow 0$ is exact. Hence, $f$ is nilpotent, or $f$ belongs to the
nilradical.

#### Proof 2: Intersection of all prime ideals is contained in the Nilradical

- Quotient the ring $R$ by the nilradical $N$.
- The statement in $R/N$ becomes
  "in a ring with no ninpotents, intersection of all primes is zero".
- This means that every non-zero element is **not** contained in  **some** prime ideal. Pick
  some arbitrary element $f \neq 0 \in R/N$. We know $f$ is not nilpotent, so we naturally consider
  $S_f \equiv \{ f^i : i \in \mathbb N \}$.
- The only thing one can do with a  multiplicative subset
  like that is to localize. So we localize the ring $R/N$ at $S$.
- If all prime ideals contain the function $f$,
  then localizing at $f$ destroys all prime ideals, thus blows up all maximal ideals,
  thereby collapsing the ring into the zero ring (the ring has no maximal ideals, so the ring is the zero ring).
- Since $S^{-1} R/N = 0$, we have that $0 \in S$. So some $f^i = 0$. This contradicts the assumption that no element of $R/N$
  is nilpotent. Thus we are done.

#### Lemma: $S$ contains zero  iff  $S^{-1} R = 0$

- (Forward): Let $S$ contain zero. Then we must show that $S^{-1} R = 0$. Consider some element $x/s \in S^{-1} R$.
  We claim that $x = 0/1$.  To show this, we need to show that there exists an $s' \in S$ such that $xs'/s = 0s'/1$.
  That is, $s'(x \cdot 1 - 0 \cdot s) = 0$. Choose $s' = 0$ and we are done. Thus every element is $S^{-1}R$ is zero if $S$
  contains zero.

- (Backward): Let $S^{-1} R = 0$. We need to show that $S$ contains zero. Consider $1/1 \in S^{-1} R$. We have that $1/1 = 0/1$.
  This means that there is an $s' \in S$ such that $s'1/1 = s'0/1$. Rearranging, this means that
  $s'(1 \cdot 1 - 1 \cdot 0) = 0$. That is, $s'1 = 0$, or $s' = 0$. Thus, the element $s'$ must be zero for $1$ to be
  equal to zero.  Hence, for the ring to collapse, we must have $0 = s' \in S$. So, if $S^{-1}R = 0$, then $S$ contains zero.


# Exactness of modules is local


We wish to show that for some ring $R$ and modules $K, L, M$
a sequence $K \rightarrow L \rightarrow M$ is exact iff $K_m \rightarrow L_m \rightarrow M_m$
is exact for every maximal ideal $m \subset R$. This tells us that exactness is local.




# Quotient by maximal ideal gives a field

#### Quick proof

Use correspondence theorem. $R/m$ only has the images of $m, R$ as ideals which
is the zero ideal and the full field.

#### Element based proof

Let $x + m \neq 0$ be an element in $R/m$. Since $x + m \neq 0$, we have $x \not in m$.
Consider $(x, m)$. By maximality of $m$, $(x, m) = R$. Hence there exist elements $a, b \in R$
such that $xa + mb = 1$. Modulo $m$, this read $xa \equiv 1 (\text{mod}~$m$)$. Thus $a$
is an inverse to $x$, hence every nonzero element is invertible.


# Ring of power series with infinite positive and negative terms

If we allow a ring with elements $x^i$ for all $-\infty < x < \infty$, for notation's
sake, let's call it $R[[[x]]]$. Unfortunately, this is a badly behaved ring.
Define $S \equiv \sum_{i = -\infty}^\infty x^i$. See that $xS = S$, since
multiplying  by $x$ shifts powers by 1. Since we are summing over all of $\mathbb Z$,
$+1$ is an isomorphism. Rearranging gives $(x - 1)S = 0$. If we want our ring
to be an integral domain, we are forced to accept that $S = 0$. In the Barvinok
theory of polyhedral point counting, we accept that $S = 0$ and exploit this
in our theory.

# Mean value theorem and Taylor's theorem. (TODO)

I realise that there are many theorems that I learnt during my preparation for JEE
that I simply don't know how to prove. This is one of them. Here I exhibit
the proof of Taylor's theorem from Tu's introduction to smooth manifolds.

> Taylor's theorem: Let $f: \mathbb R \rightarrow \mathbb R$ be a smooth function,
> and let $n \in \mathbb N$ be an "approximation cutoff". Then there exists
> for all $x_0 \in \mathbb R$ a smooth function $r \in C^{\infty} \mathbb R$
> such that:
> f(x) = f(x_0) + (x - x_0) f'(x_0)/1! + (x - x_0)^2 f'(x_0)/2! + \dots + (x - x_0)^n f^{(n)'}(x_0)/n! + (x - x_0)^{n+1} r

We prove this by induction on $n$. For $n = 0$, we need to show that there exists an $r$ such that
$f(x) = f(x_0) + r$. We begin by parametrising the path from $x_0$ to $x$ as $p(t) \equiv (1 - t) x_0 + tx$.
Then we consider $(f \circ p)'$:

$$
\begin{aligned}
&\frac{f(p(t))}{dt} = \frac{df((1 - t) x_0) + tx)}{dt} \\
&= (x - x_0) \frac{df((1 - t)x_0) + tx)}{dx}
\end{aligned}
$$

Integrating on both sides with limits $t=0, t=1$ yields:

$$
\begin{aligned}
&\int_0^1 \frac{df(p(t))}{dt} dt = \int_0^1 (x - x_0) \frac{df((1 - t)x_0) + tx)}{dx} dt \\
f(p(1)) - f(p(0)) =  (x - x_0) \int_0^1 \frac{df((1 - t)x_0) + tx)}{dx} dt \\
f(x) - f(x_0) =  (x - x_0) g[1](x) \\
\end{aligned}
$$

where we define $g[1](x) \equiv \int_0^1 \frac{df((1 - t)x_0) + tx)}{dx} dt $ where the $g[1](x)$ witnesses
that we have the first derivative of $f$ in its expression. By rearranging, we get:

$$
\begin{aligned}
f(x) - f(x_0) =  (x - x_0) g[1](x) \\
f(x)  =  f(x_0) + (x - x_0) g[1](x) \\
\end{aligned}
$$

If we want higher derivatives, then we simply notice that $g[1](x)$ is of the form:

$$
\begin{aligned}
g[1](x) \equiv \int_0^1 f'((1 - t)x_0) + tx) dt \\
g[1](x) \equiv \int_0^1 f'((1 - t)x_0) + tx) dt \\
\end{aligned}
$$


# Cayley Hamilton

I find the theorem spectacular, because while naively the vector space $M_n(F)$
has dimension $n^2$, Cayley-Hamilton tells us that there's only $n$ of $M^0, M^1, \dots$
are enough to get linear dependence.  However, I've never known a
proof of Cayley Hamilton that sticks with me; I think I've found one now.

For any matrix $A$, the adjugate has the property:

$$
A adj(A) = det(A) I
$$

Using this, Consider the matrix $P_A \equiv xI - A$ which lives in $End(V)[x]$,
and its corresponding determinant $p_A(x) \equiv det(P_A) = det(xI - A)$.

We have that

$$
P_A adj(P_A) = det(P_A) I \\
(xI  - A) adj(xI - A) = det(xI - A) I = p_A(x) I \\
$$

If we view this as an equation in $End(V)[x]$, it says that $p_A$ has a factor $xI - A$. This means that
$x = A$ is a zero of $p_A(X)$. Thus, we know that $A$ satisfies $p_A(x)$, hence $A$ satisfies
its own characteristic polynomial!

The key is of course the  adjugate matrix equation that relates the adjugate matrix
to the determinant of $A$.


#### Adjugate matrix equation

- Let $A'(i, j)$ be the matrix $A$ with the $i$ th row and $j$ column removed.
- Let $C[i, j] \equiv (-1)^{i+j} det(A'(i, j))$ be the determinant of the $A'(i, j)$ matrix.
- Let define $adj(A) \equiv C^T$ to be the transpose of the cofactor matrix.
  That is, $adj(A)[i, j] = C[j, i] = det(A'(j, i))$.
- Call $D \equiv A adj(A)$. We will now compute the entries of $Z$ when $i = j$ and when $i \neq j$.
  We call it $D$ for diagonal since we will show that $D$ is a diagonal matrix with entry $det(A)$
  on the diagonal.
- First, compute $D[i, i]$ (I use einstein summation convention where repeated indices are implicitly
  summed over):

$$
\begin{aligned}
= D[i, i] = (A adj(A))[i, i] \\
&= A[i, k] adj(A) [k, i] \\
&= A[i, k] (-1)^{i+k} det(A'[k, i]) \\
&= det(A)
\end{aligned}
$$

The expression $A[i, k] det(A'[k, i])$ is the determinant of $A$ when expanded along the row $i$ using
the [Laplace expansion](https://en.wikipedia.org/wiki/Laplace_expansion).

Next, let's compute $D[i, j]$ when $i \neq j$:

$$
\begin{aligned}
D[i, j] = (A adj(A))[i, j] \\
&= A[i, k] adj (A)[k, j] \\
& = A[i, k] (-1)^{k+j} det(A'[k, j]) \\
& = A[i, k] (-1)^{j+k} det(A'[k, j]) \\
& = det(Z)
\end{aligned}
$$

This is the determinant of a new matrix $Z$ (for zero), such that the $j$th row of $Z$ is the $i$th
row of $A$. More explicitly:

$$
\begin{aligned}
Z[l, :] \equiv
\begin{cases}
A[l, :] & l \neq j \\
A[i, :] & l = j \\
\end{cases}
\end{aligned}
$$

Since $Z$ differs from $A$ only in the $j$th row, we must have that
$Z'[k, j] = A'[k, j]$, since $Z'[k, j]$ depends on what happens on all
rows and columns **outside** of $j$.

If we compute $det(Z)$ by expanding along the $j$ row, we get:

$$
\begin{aligned}
&det(Z) = (-1)^{j+k} Z[j, k] det(Z'[k, j]) \\
&det(Z) = (-1)^{j+k} A[j, k] det(Z'[k, j]) \\
&det(Z) = (-1)^{j+k} A[j, k] det(A'[k, j]) \\
&= D[i, j]
\end{aligned}
$$

But $Z$ has a repeated row: $A[j, :] = A[i, :]$ and $i \neq j$. Hence, $det(Z) = 0$.
So, $D[i, j] = 0$ when $i \neq j$.

Hence, this means that $A adj(A) = det(A) I$.

- We can rapidly derive other properties from this reuation. For example, $det(A adj(A)) = det(det(A) I) = det(A)^n$,
  and hence $det(A) det(adj(A)) = det(A)^n$, or $det(adj(A)) = det(A)^{n-1}$.
- Also, by rearranging, if $det(A) \neq 0$, we get $A adj(A) = det(A) I$, hence $A (adj(A)/det(A)) = I$,
  or $adj(A)/det(A) = A^{-1}$.


#### Determinant in terms of exterior algebra

For a vector space $V$ of dimension $n$, Given a linear map $T: V \rightarrow V$, define
a map $\Lambda T: \Lambda^n  V \rightarrow \Lambda^n V$ such that
$\Lambda T(v_1 \wedge v_2 \dots \wedge v_n) \equiv T v_1 \wedge T v_2 \dots \wedge T v_n$.
Since the space $\Lambda^n V$ is one dimension, we will need one scalar $k$ to define
$T$: $T(v_1 \wedge \dots \wedge v_n) = k v_1 \wedge \dots \wedge v_n$. It is either a theorem
or a definition (depending on how one starts this process) that $k = det(T)$.


If we choose this as a definition, then let's try to compute the value. Pick orthonormal
basis $v[i]$. Let $w[i] \equiv T v[i]$ (to write $T$ as a matrix). Define the $T$ matrix to be defined
by the equation $w[i] = T[i][j] v[j]$. If we now evaluate $\Lambda_T$, we get:

$$
\begin{aligned}
\Lambda T(v_1 \wedge \dots v_n) \\
&= T(v_1) \wedge T(v_2) \dots \wedge T(v_n) \\
&= w_1 \wedge w_2 \dots w_n \\
&= (T[1][j_1] v[j_1]) \wedge (T[1][j_2] v[j_2]) \wedge (T[1][j_n] v[j_n]) \\
&=  (\sum_{\sigma \in S_n} (\prod_i T[i][\sigma(i)] sgn(\sigma))  v[1] \wedge v[2] \dots \wedge v_n
\end{aligned}
$$

Where the last equality is because:
- (1) Repeated vectors get cancelled, so we must have unique $v[1], v[2], \dots v[n]$ in the terms we collect.
  So all the $j_k$ must be distinct in a given term.
- A wedge of the form $T[1][j_1] v[j_1] \wedge T[2][j_2] v[j_2] \dots T[n][j_n] v[j_n]$, where all the
  $j_i$ are distinct (see (1)) can be rearranged by a permutation that sends $v_{j_i} \mapsto v_i$.
  Formally, apply the permutation $\tau(j_i) \equiv i$. This will reorganize
  the wedge into $T[1][j_1] T[2][j_2] \dots T[n][j_n] v[1] \wedge v[2] \wedge v[3] \dots v[n] (-1)^{sgn(\tau)}$,
  where the sign term is picked up by the rearrangement.
- Now, write the indexing into $T[i][j_i]$ in terms
  of a permutation $\sigma(i) \equiv j_i$. This becomes $\prod_i T[i][\sigma(i)] (-1)^{sgn(\tau)} v[1] \wedge v[2] \dots \wedge v[n]$.
- We have two permutations $\sigma, \tau$ in the formula. But we notice that $\sigma = \tau^{-1}$, and hence
  $sgn(\sigma) = sgn(\tau)$, so we can write the above as $\prod_i T[i][\sigma(i)] (-1)^{sgn(\sigma)} v[1] \wedge v[2] \dots \wedge v[n]$.
- Thus, we have recovered the "classical determinant formula".

#### Laplace expansion of determinant


From the above algebraic encoding of the determinant of $T[i][j]$ as $\sum_{\sigma \in S_n}sgn(\sigma)\prod_i T[i][\sigma(i)]$,
we can recover the "laplace expansion" rule, that asks to pick a row $r$, and then compute the expression:
as

$$
L_r(T) \equiv \sum_c T[r, c] (-1)^{r+c} det(T'(r, c))
$$

Where $T'(r, c)$ is the matrix $T$ with row $r$ and column $c$ deleted.
I'll derive this concretely using the determinant definition for the 3 by 3 case. The general
case follows immediately. I prefer being explicit in a small case as it lets me see what's going on.

Let's pick a basis for $V$, called $b[1], b[2], b[3]$. We have the relationship
$v[i] \equiv Tb[i]$. We want to evaluate the coefficient of $v[1] \wedge v[2] \wedge v[3]$.
First grab a basis expansion of $v[i]$ as $v[i] = c[i][j] b[j]$. These uniquely define
the coefficients $c[i][j]$. Next, expand the wedge:

$$
\begin{aligned}
& v[1] \wedge v[2] \wedge v[3] \\
&= (c[1][1]b[1] + c[1][2]b[2] + c[1][3]b[3]) \wedge
   (c[2][1]b[1] + c[2][2]b[2] + c[2][3]b[3]) \wedge
   (c[3][1]b[1] + c[3][2]b[2] + c[3][3]b[3])
\end{aligned}
$$

I now expand out only the first wedge, leaving terms of the form $c[1][1]b[1] (\cdot) + c[1][2]b[2](\cdot) c[1][3]b[3] (\cdot)$.
(This corresponds to "expanding along and deleting the row" in a laplace expansion when finding the determinant)
Let's identify the $(\cdot)$ and see what remains:


$$
\begin{aligned}
& v[1] \wedge v[2] \wedge v[3] \\
&= c[1][1]b[1] \wedge (c[2][1]b[1] + c[2][2]b[2] + c[2][3]b[3]) \wedge (c[3][1]b[1] + c[3][2]b[2] + c[3][3]b[3])
 + c[1][2]b[2] \wedge(c[2][1]b[1] + c[2][2]b[2] + c[2][3]b[3])  \wedge(c[3][1]b[1] + c[3][2]b[2] + c[3][3]b[3])
 + c[1][3]b[2] \wedge(c[2][1]b[1] + c[2][2]b[2] + c[2][3]b[3])  \wedge(c[3][1]b[1] + c[3][2]b[2] + c[3][3]b[3])
\end{aligned}
$$

Now, for example, in the first term $c[1][1]b[1] \wedge (\cdot)$, we lose anything inside that contains a $b[1]$,
as the wedge will give us $b[1] \wedge b[1] = 0$ (this corresponds to "deleting the column" when considering the submatrix).
Similar considerations have us remove all terms that contain $b[2]$ in the brackets of $c[1][2]b[2]$, and terms that
contain $b[3]$ in the brackets of $c[1][3]b[3]$. This leaves us with:

$$
\begin{aligned}
& v[1] \wedge v[2] \wedge v[3] \\
&= c[1][1]b[1] \wedge (c[2][2]b[2] + c[2][3]b[3]) \wedge (c[3][2]b[2] + c[3][3]b[3])
 + c[1][2]b[2] \wedge(c[2][1]b[1] + c[2][3]b[3])  \wedge(c[3][1]b[1] +  c[3][3]b[3])
 + c[1][3]b[2] \wedge(c[2][1]b[1] + c[2][2]b[2] )  \wedge(c[3][1]b[1] + c[3][2]b[2])
\end{aligned}
$$

We are now left with calculating terms like $(c[2][2]b[2] + c[2][3]b[3]) \wedge (c[3][2]b[2] + c[3][3]b[3])$ which
we can solve by recursion (that is the determinant of the 2x2 submatrix). So if we now write the "by recursion" terms
down, we will get something like:

$$
\begin{aligned}
& v[1] \wedge v[2] \wedge v[3] \\
&= c[1][1]b[1] \wedge (k[1] b[2] \wedge b[3])
 + c[1][2]b[2] \wedge(k[2] b[1] \wedge b[3])
 + c[1][3]b[2] \wedge(k[3] b[1] \wedge b[2])
\end{aligned}
$$




Where the $k[i]$ are the values produced by the recursion, and we assume that the recursion will give
us the coefficients of the wedges "in order": so we always have $b[2] \wedge b[3]$ for example, not $b[3] \wedge b[2]$.
So, we need to ensure that the final answer we spit out corresponds to $b[1] \wedge b[2] \wedge b[3]$. If we simplify
the current step we are at, we will get:

$$
\begin{aligned}
& v[1] \wedge v[2] \wedge v[3] \\
&= k[1] c[1][1]b[1] \wedge b[2] \wedge b[3]
 + k[2] c[1][2]b[2] \wedge b[1] \wedge b[3]
 + k[3] c[1][3]b[2] \wedge b[1] \wedge b[2]
\end{aligned}
$$


We need to rearrange our terms to get $b[1] \wedge b[2] \wedge b[3]$ times some constant.
On rearranging each term into the standard form $b[1] \wedge b[2] \wedge b[3]$, we are forced to pick up the correct sign factors:

$$
\begin{aligned}
& v[1] \wedge v[2] \wedge v[3] \\
&= k[1] c[1][1]b[1] \wedge b[2] \wedge b[3]
  -k[2] c[1][2]b[1] \wedge b[2] \wedge b[3]
 + k[3] c[1][3]b[1] \wedge b[2] \wedge b[3] \\
&= (c[1][1]k[1] - c[1][2]k[2] + c[1][3]k[3])(b[1] \wedge b[2] \wedge b[3])
\end{aligned}
$$

We clearly see that for each $c[i]$, the factor is $(-1)^i k[i]$ where $k[i]$ is the answer
gotten by computing the determinant of the sub-expression where we delete the vector $b[i]$ (ignore the column)
and also ignore the entire "row", by not thinking about $c[j](\cdot)$ where $j \neq i$.
So, this proves the laplace expansion by exterior algebra.


#### Deriving Cayley Hamilton for rings from $\mathbb Z$

I'll show the idea of how to prove Cayley Hamilton for an arbitrary commutative ring $R$
given we know Cayley Hamilton for $\mathbb Z$. I describe it for 2x2 matrices.
The general version is immediate from this. Pick a variable matrix
and write down the expression for the characteristic polynomial So if:

```
M = [a b]
    [c d]
```

then the characteristic polynomial is:

```
ch
= |M - xI|
=
|a-x b|
|c   d-x|
```

that's $ch(a, b, c, d, x) \equiv (a-x)(d-x) - bc = x^2 +x (a + d) + ad - bc$. This equation has $a, b, c, d, x \in R$
for some commutative ring $R$. Now, we know that if we set $x = M$, this equation will be satisfied. But what does
it mean to set $x = A$? Well, we need to let $x$ be an arbitrary matrix:

```
x = [p q]
    [r s]
```

And thus we compute `x^2` to be:

```
x^2
= [p q][p q]
  [r s][r s]
= [p^2 + qr; pq + qs]
  [rp + sr; rq + s^2]
```

So now expanding out $ch(a, b, c, d, x)$ in terms of $x$ on substituting for $x$ the matrix
we get the system:


```
[p^2 + qr; pq + qs] + (a + d) [p q] + (ad - bc)[1 0] = [0 0]
[rp + sr; rq + s^2]           [r s]            [0 1]   [0 0]
```

We know that these equations hold when $x = M$, because the Cayley-Hamilton theorem
tells us that $ch(M) = 0$! So we get a different system with `p = a, q = b, r = c, s = d`,
still with four equations, that we know is equal to zero! This means we have four
intederminates `a, b, c, d` and four equations, and we know that these equations are true
for all $\mathbb Z$. But if a polynomial vanishes on infinitely many points, it must
identically be zero. Thus, this means that `ch(A)` is the zero polynomial, or `ch(A) = 0`
for *all* `R`. This seems to depend on the fact that the ring is infinite, because otherwise
imagine we send $\mathbb Z$ to $Z/10Z$.  Since we don't have an infinite number
of $\mathbb Z$ elements, why should the polynomial be zero? I imagine that this
needs zariski like arguments to be handled.


#### Cramer's rules

We can get cramer's rule using some handwavy manipulation
[or rigorizing the manipulation using geometric algebra](https://arxiv.org/pdf/1205.5935.pdf).

Say we have a system of equations:

$$
\begin{aligned}
a[1] x + b[1] y = c[1] \\
a[2] x + b[2] y = c[2]
\end{aligned}
$$

We can write this as:

$$
\vec a x + \vec b y = \vec c
$$

where $\vec a \equiv (a_1, a_2)$ and so on. To solve the system, we wedge with $\vec a$ and $\vec b$:

$$
\begin{aligned}
\vec a \wedge (\vec a x + \vec b y) = \vec a \wedge \vec c \\
\vec a \wedge \vec b y = \vec a \wedge \vec c \\
y = \frac{\vec a \wedge \vec c}{\vec a \wedge \vec b} \\
y =
\frac{\begin{vmatrix}
a[1] & a[2] \\
c[1] & c[2]
\end{vmatrix}}{
\begin{vmatrix}
a[1] & b[1] \\
a[2] & b[2]
\end{vmatrix}
}
\end{aligned}
$$

Which is exactly cramer's rule.


#### The formula for the adjugate matrix from Cramer's rule (TODO)


#### References

- [More abstract proof of Cayley Hamilton](https://math.stackexchange.com/questions/605590/is-there-a-simpler-more-abstract-proof-of-the-cayley-hamilton-theorem-for-matri)
- [PlanetMath: proof of Cayley Hamilton for commutative rings](https://planetmath.org/proofofcayleyhamiltontheoreminacommutativering)


# Nakayama's lemma

I read the statement as $IM = M \implies M = 0$, when $I$ is in the jacobson radical.
1. Essentially, it tells us that if a module $M$ "lives by the $I$", then it also "dies by the $I$".
2. Alternatively, we factor the equation as $M(I - 1) = 0$. Since our ideal $I$
   is a member of the jacobson radical, $(1 - I)$ is "morally" a unit and thus $M = 0$.
   This is of course completely bogus, but cute nontheless.
3. We can think of a graded ring, say $R[x]$ acting on some graded module $M$ (say, a subideal, $M = (x^2)$). When we compute $IM$,
   this will bump up the grading of $M$. If $IM = M$, then $M$ could not have had non-trivial elements in the first place, since the
   vector of, say, "non-zero elements in each grade" which used to look like $(v_0, v_1, v_2, \dots)$ will now look like $(0, v_0, v_1, \dots)$.
   Equating the two, we get $v_0 = 0, v_1 = v_0 = 0, v_2 = v_1 = 0$ and so on, collapsing the entire ring.

# Vector fields over the 2 sphere

We assume that we already know the hairy ball theorem, which states that
no continuous vector field on $S^2$ exists that is nowhere vanishing. Using
this, we wish to deduce (1) that the module of vector fields over $S^2$ is
not free, and an *explicit* version of what the
[Serre Swan theorem](https://en.wikipedia.org/wiki/Serre%E2%80%93Swan_theorem)
tells us, that this module is *projective*

#### 1. Vector fields over the 2-sphere is projective

Embed the 2-sphere as a subset of $\mathbb R^3$. So at each point, we have
a tangent plane, and a normal vector that is perpendicular to the sphere:
for the point $p \in S^2$, we have the vector $p$ as being normal to $T_p S^2$ at $p$.
So the normal bundle is of the form:

$$
\mathfrak N \equiv \{ \{ s \} \times \{ \lambda s : \lambda in \mathbb R \}  : s \in \mathbb S^2 \}
$$
- If we think of the trivial bundle, that is of the form $Tr \equiv \{ s \} \times \mathbb R : s \in \mathbb S^2 \}$.
- We want to show an isomorphism between $N$ and $T$.
- Consider a map $f: N \rightarrow Tr$ such that $f((s, n)) \equiv (s, ||n||)$. The inverse
  is $g: Tr \rightarrow N$ given by $g((s, r)) \equiv (s, r \cdot s)$. It's easy to check that these
  are inverses, so we at least have a bijection.
- To show that it's a vector bundle morphism, TODO.
- (This is  hopelessly broken, I can't treat the bundle as a product. I can locally I guess by taking charts;
   I'm not sure how I ought to treat it globally!)



#### 1. Vector fields over the sphere is not free

- 1. Given two bundles $E, F$ over any manifold $M$, a module isomorphism
  $f: \mathfrak X(E) \rightarrow \mathfrak X(F)$ of vector fields as
  $C^\infty(M)$ modules is induced by a smooth isomorphism of vector bundles $F: E \rightarrow F$.
- 2. The module $\mathfrak X(M)$ is finitely generated as a $C^\infty$ module over $M$.
- Now, assume that $\mathfrak X(S^2)$ is a free module, so we get that
  $\mathfrak X(S^2) \simeq \oplus_i C^\infty(S^2)$.
- By (2), we know that this
  must be a finite direct sum for some finite $N$: $mathfrak X(S^2) = \oplus_i=1^N C^\infty(S^n)$.
- But having $N$ different independent non-vanishing functions on $\mathbb S^2$ is the same as
  clubbing them all together into a vector of $N$ values at each point at $S^2$.
- So we get a smooth
  function $S^2 \rightarrow \mathbb R^n$, AKA a section of the trivial bundle
  $\underline{\mathbb R^n} \equiv S^2 \times \mathbb R^n$.
- This means that we have managed to trivialize the vector bundle over the sphere if vector fields over $S^2$ were a free module.
- Now, pick the element $S^2 \times \{ (1, 1, 1, 1, \dots) \} \in S^2 \times \mathbb R^n$. This is a nowhere
  vanishing vector field over $S^2$. But such an object cannot exist, and hence vector fields over the
  sphere cannot be free.



#### References

- [Smooth vector fields over $S^2$ is not a free module](https://math.stackexchange.com/questions/4052994/smooth-vector-fields-over-the-2-sphere-is-not-a-free-module/)
- [Smooth vector fields over $S^2$ is a projective module](https://math.stackexchange.com/questions/4053091/explicitly-exhibit-that-vector-fields-over-the-2-sphere-is-a-projective-module)


# Learning to talk with your hands

I was intruged by [this HN thread](https://news.ycombinator.com/item?id=26382528)
about learning to talk with your hands. I guess I'm going to try and do this more often now.

# Lovecraftisms

I recently binged a lot of Lovecraftian horror to get a sense of
his writing style. Here's a big list of my favourite quotes:

> His madness held no affinity to any sort recorded in even the latest and most
> exhaustive of treatises, and was conjoined to a mental force which would have
> made him a genius or a leader had it not been twisted into strange and
> grotesque forms.


> seething vortex of time

> Snatches of what I read and wrote would linger in my memory. There were
> horrible annals of other worlds and other universes, and of stirrings of
> formless life outside of all universes

> clinging pathetically to the cold planet and burrowing to its horror-filled
> core, before the utter end.

> appalled at the measureless age of the fragments

> fitted darkly into certain Papuan and Polynesian legends of infinite
> antiquity

> The condition and scattering of the blocks told mutely of vertiginous cycles
> of time and geologic upheavals of cosmic savagery.

> uttermost horrors of the aeon-old legendry

> The moon, slightly past full, shone from a clear sky, and drenched the
> ancient sands with a white, leprous radiance which seemed to me somehow
> infinitely evil.

> with the bloated, fungoid moon sinking in the west

> how preserved through aeons of geologic convulsion I could not then
> and cannot now even attempt to guess.

> gently bred families of the town

> could not escape the sensation of being watched from ambush on every hand by
> sly, staring eyes that never shut.

> and there was that constant, terrifying impression of other sounds--perhaps
> from regions beyond life--trembling on the very brink of audibility.

> little garden oasis of village-like antiquity where huge, friendly cats
> sunned themselves atop a convenient shed.


> Better it be left alone for the years to topple, lest things be stirred that ought to rest forevrr in the black abyss

> It clearly belonged to some settled technique of infinite maturity and
> perfection, yet that technique was utterly remote from any--Eastern or
> Western, ancient or modern--which I had ever heard of or seen exemplified. It
> was as if the workmanship were that of another planet.


> intricate arabesques roused into a kind of ophidian animation.

> never was an organic brain nearer to utter annihilation in the chaos that
> transcends form and force and symmetry.


> away outside the galaxy and possibly beyond the last curved rim of
> space.


> It was like the drone of some loathsome, gigantic insect ponderously shaped
> into the articulate speech of an alien species

> In time the ruts of custom and economic interest became so deeply cut in
> approved places that there was no longer any reason for going outside them,
> and the haunted hills were left deserted by accident rather than by design


> There were, too, certain caves of problematical depth in the sides of the
> hills; with mouths closed by boulders in a manner scarcely accidental, and
> with more than an average quota of the queer prints leading both toward and
> away from them

> he fortified himself with the mass lore of cryptography

> As before, the sides of the road showed a bruising indicative of the
> blasphemously stupendous bulk of the horror

> The dogs slavered and crouched close to the feet of the fear-numbed family.

> an added element of furtiveness in the clouded brain which subtly transformed
> him from an object to a subject of fear


> fireflies come out in abnormal profusion to dance to the raucous, creepily
> insistent rhythms of stridently piping bull-frogs.

> a seemingly limitless legion of whippoorwills that cried their endless
> message in repetitions timed diabolically to the wheezing gasps of the dying
> man

> pandemoniac cachinnation which filled all the countryside

> the left-hand one of which, in the Latin version, contained such monstrous
> threats to the peace and sanity of the world

> Their arrangement was odd, and seemed to follow the symmetries of some cosmic
> geometry unknown to earth or the solar system

> faint miasmal odour which clings about houses that have stood too long

> I do not believe I would like to visit that country by night--at least not when the sinister stars are out

> there was much breathless talk of new elements, bizarre optical properties,
> and other things which puzzled men of science are wont to say when faced by
> the unknown..

> stealthy bitterness and sickishness, so that even the smallest bites induced a lasting disgust

> plants of that kind ought never to sprout in a healthy world.


>  everywhere were those hectic and prismatic variants of some diseased,
>  underlying primary tone without a place among the known tints of earth.
>
> In her raving there was not a single specific noun, but only verbs and
> pronouns..


> great bare trees clawing up at the grey November sky with a studied malevolence

> There are things which cannot be mentioned, and what is done in common
> humanity is sometimes cruelly judged by the law.


> monstrous constellation of unnatural light, like a glutted swarm of corpse-fed
> fireflies dancing hellish sarabands over an accursed marsh,


> No traveler has ever escaped a sense of strangeness in those deep ravines, and
> artists shiver as they paint thick woods whose mystery is as much of the
> spirits as of the eye.


> We live on a placid island of ignorance in the midst of black seas of infinity,
> and it was not meant that we should voyage far. The sciences, each straining in
> its own direction, have hitherto harmed us little; but some day the piecing
> together of dissociated knowledge will open up such terrifying vistas of
> reality, and of our frightful position therein, that we shall either go mad
> from the revelation...



> form which only a diseased fancy could conceive

> ... dreams are older than brooding Tyre, or the contemplative Sphinx, or
> garden-girdled Babylon

> iridescent flecks and striations resembled nothing familiar to geology or
> mineralogy.



> miserable huddle of hut

> Only poetry or madness could do justice to the noises heard by Legrasse's men
> as they ploughed on through the black morass.

> In his house at R'lyeh dead Cthulhu waits dreaming

> all the earth would flame with a holocaust of ecstasy and freedom.

> The aperture was black with a darkness almost material.

# Hairy ball theorem from Sperner's Lemma (TODO)

- Let $\Delta$ be an n-dimensional simplex with vertices $v_0, v_1, \dots, v_n$.
- Let $\Delta_i$ be the face opposite to vertex $v_i$. That is, $\Delta_i$ is the face with all vertices except $v_i$.
- The boundary $\partial \Delta$ is the union of all the $n+1$ faces of $\Delta_i$ (i is from $0$ to $n$).
- Let $\Delta$ be subdivided into smaller simplicies forming a simplciial complex $S$.
- **Sperner's lemma**: Let the vertices of $S$ be labelled by $\phi: S \rightarrow \Delta$ (that is,
   it maps all vertices of the simplicial complex $S$ to one of the vertices of the simplex $\Delta$),
   such that $v \in \Delta_i  \implies \phi(v) \neq i$. Then there is at least one $n$-dimensional simplices
   of $S$ whose image is $\Delta$ (That is, there is at least one n-dimensional-sub-simplex $T \subseteq S$
   such that vertices of $T$ are mapped to $\{0, 1, \dots, n\}$). More strongly, the number of such
   sub-simplices is *odd*.
- We can see that the map $\phi$ looks like some sort of retract that maps the complex $S$ to its boundary $\Delta$.
  Then Sperner's lemma tells us that there is one "region" $T \subseteq S$ that gets mapped onto $\Delta$.

#### 1D proof of Sperner's: Proof by cohomology

- For 1D, assume we have a line with vertex set $V$ and edges $E$. Let the vertex at the
  beginning be $v_0$ and the vertx at the end be $v_1$. That is, $\Delta \equiv \{v_0, v_1\}$
  and $S \equiv (V, E)$ is a subcomplex of $\Delta$ --- that is, it subdivides the line $\Delta$
  into smaller portions. Let $\phi: S \rightarrow \Delta$ be the labelling function.
- create a function $f: \Delta \rightarrow \mathbb F_2$ that assigns $0$ to
  $v_0$ and $+1$  to $v_1$: $f(v_0) \equiv 0; f(v_1) \equiv 1$. Use this to generate a
  function on the full complex $F: S \rightarrow F_2; F(v) \equiv F(\phi(v))$.

- From $F$, generate a function on the edges
  $dF: E \rightarrow F_2; dF(\overline{vw}) = F(w) + F(v)$. See that this scores such that
  $dF(AB) = +1$, $dF(BA) = +1$, $dF(AA) = dF(BB) = 0$. (Recall that the arithmetic is over $F_2$)
  So, $dF$ adds a one every time we switch from $A$ to $B$ or from $B$ to $A$.
- However, we also see that $dF$ is generated from a "potential function "f". Hence we
  have the identity $\sum_{e \in E} dF(e) = f(v_1) - f(v_0) = 1 - 0 = 1$. Hence,
  we must have switched signs an odd number of times.
- Since we start from $A$, that means we must have switched from $A$ to $B$ an odd number of times.


#### 2D proof of Sperner's: Proof by search

- Start from an edge in the bottom $ef$ labeled $BC$. We are looking for a simplex labeled $ABC$.
- To start: Pick some vertex above $ef$, say $g$. If this is labeled $A$, we are done. If not, say this is
  labeled $B$. So we get triangle $efg=ABB$. Launch our search procedure from this triangle $efb$.
- Find the triangle adjacent to $efg$ along the edge $eg=AB$ (the other $AB$ edge, not the one we started with).
  If this adjacent triangle $egh$ has $h=A$ we are done. If not, move to the triangle $egh$.
- See that we will either find a triangle labeled $ABC$, or we will keep running into triangles labeled $ABB$.
- We cannot ever *repeat* a triangle in our path; to repeat a triangle is to start with some edge $xy$
  and then to pick a vertex $z$ such that $xyz=efg$ where $efg$ was already picked. This must mean that the
  edge $ef$ was already picked. [TODO]

#### Proof of hairy ball by sperner's lemma [TODO]


#### Why hairy ball is interesting: Projective modules

The reason I care about the hairy ball theorem has to do with vector fields.
The idea is to first think of smooth vector fields over a smooth manifold.
What algebraic structure do they have? Indeed, they are a vector space over $\mathbb R$.
However, it is difficult to exhibit a basis. Naively, for each point $p \in M$, we would
need a basis $T_p B \subset T_p M$ as a basis. This brings in issues of smoothness, etc.
Regardless, it would be uncountable in dimension.

On the other hand, let's say we allow ourselves to consider vector fields as *modules*
over the ring of smooth functions on a manifold. That is, we can scale the vector
field by a different value at each point.

We can hope the ""dimension"" of the module is much smaller.
So, for example, if we think of $\mathbb R^2$, given some vector field $V \equiv v_x \hat x + v_y \hat y$,
the functions $v_x$ and $v_y$ allow us to write  basis! Create the vector fields $V_x \equiv \hat x$
and $V_y \equiv \hat y$. Then any vector field $V$ can be written as $V = v_x V_x + v_y V_y$
for functions $v_x, v_y$ in a unique way!


However, as we know, **not all modules are free**. A *geometric* example of such
a phenomenon is the module of vector fields on the _sphere_. By the hairy ball theorem,
any vector field must vanish at at least a single point. So if we try to build a vector
field pointing "rightwards" (analogous to $\hat x$) and "upwards" (analogous $\hat y$),
these *will not be valid smooth vector fields*, because they don't vanish! So,
we will be forced to take more than two vector fields. But when we do that,
we will lose uniqueness of representation. However, all is not lost.
The [Serre Swan theorem](https://en.wikipedia.org/wiki/Serre%E2%80%93Swan_theorem)
tells us that any such module of vector fields will be a *projective* module.
The sphere gives us a module that is not free. I'm not sure how to show that it's projective.

#### Simple example of projective module that is not free.

- Let $K$ be a field. Consider $R \equiv K \times K$ as a ring, and let $M \equiv K$
  be a module on top of $R$.
- $M$ is a projective module because $M \oplus K \simeq R$
  (that is, we can direct sum something onto it to get the some $\oplus_i R$)
- On the other hand, $M$ itself is not free because $M \neq \oplus_i R$ for any $i$. Intuitively,
  $M$ is "half an $R$" as $M \simeq K$ while $R \simeq K\times K$.
- The geometric picture is that we have a space with two points $\{p, q\}$. We have a bundle
  on top of it, with $M$ sitting on $p$ and $0$ (the trivial module) sitting on top of $q$.
  When we restrict to $p$, we have a good bundle $M$.
- But in total over thr space, we can't write the bundle as $M \times \{p, q\}$ because the
  **fibers have different dimensions**! The dimension over $p$ is $dim(M) = 1$ while over $q$
   is $dim(0) = 0$.
- What we can do is to "complete" the bundle by adding a copy of $M$ over $q$, so that we can
  then trivialise the bundle to write $M \times \{p, q\}$.
- So, a projective module corresponds to a vector bundle because it locally is like a vector space,
  but may not be trivialisable due to a difference in dimension, or compatibility, or some such.


# CS and type theory: Talks by vovodesky

- [Talk 1: Computer Science and Homotopy Theory](https://www.youtube.com/watch?v=UvDeVqzcw4k)
- Think of ZFC sets as rooted trees. Have two axioms:
- (1) all branches of all vertices are non-isomorphic (otherwise a set would have two copies of the same element)
- (2) Each leaf must be at finite depth from the root.
- This is horrible to work with, so type theory!
- [Talk 2: What if foundations of math is inconsistent?](https://www.youtube.com/watch?v=O45LaFsaqMA)
- We "know" that first order math is consistent. We can prove that it is impossible
  to prove that first order math is consistent!
- Choice 1: If we "know" FOL is consistent, then we should be able to transform
  this knowledge into a proof, then 2nd incompleteness is false.
- Choice 2: Admit "transcendental" part of math, write dubious philosophy.
- Choice 3: Admit that our sensation that FOL +arithmetic is consistent is an illusion
  and admit that FOL arithmetic is inconsistent.
- Time to consider Choice 3 seriously?

#### First order arithmetic

Mathematical object which belongs to class of objects called  formal theories.
Has four pieces of data:

1. Special symbols, names of variables.
2. Syntactic rules.
3. Deduction rules: Construct new closed formulas from old closed formula.
4. Axioms: collection of closed formulas.

Anything that is obtainable from these deduction rules is called a theorem.
First order logic have symbols: `∀, ∃, ⇒, !(not)` and so on. First order theory is
inconsistent if there a closed formula $A$ such that both $A$ and $!A$ is a
theorem.

- Free variables describe subsets.
  Eg: `∃ n: n^2 = m` describes the set `{ m : ∃ n: n^2 = m }`.
- It's possible to construct subsets (formulae with one free variable) whose
  membership is undedicable. So you can prove that it is impossible to say
  anything whatsoever about these subsets.


#### Gentzen's proof and problems with it

Tries to reason about trees of deduction. Show that proofs correspond to
combinatorial objects. Show that inconsistency corresponds to an infinite
decreasing sequence that never terminates. Then he says that it is
"self evident" that this cannot happen. But it is not self evident!

#### What would inconsistency of FOL mean for mathematicians?

- Inconsistency of FOL implies inconsistency of many other systems
  (eg. set theory).
- Inconsistency of FOL implies inconsistency of *constructive* (intuitionistic)
  mathematics! (WTF?) shown by Godel in 1933. Takes a proof of contradiction
  in classical and strips off LEM.
- We need foundations that can create *reliable proofs* **despite** being
  inconsistent!
- Have systems that react to inconsistency in less drastic ways.
  One possible candidate is constructive type theories.
  A proof of a formula in such a system is itself a formula in the system.
  There are no deduction rules, only syntactic rules. So a proof is an object
  that can be studied in the system. If one has a proof of contradiction,
  then such a proof can be detected --- they have certain properties that can
  be detected by an algorithm (what properties?)

#### New workflow

- Formalize a problem.
- Construct creative solution.
- Submit proof to a "reliable" verifier. If the verifier terminates, we are
  done. If the verifier does not terminate, we need to look for other proofs that
  can terminate.
- our abstract thinking cancels out by normalisation :P


#### Summary
- Correct interpretation of 2nd incompleteness is a step of proof of inconsistency
  of FOL (Conjecture).
- In math, we need to learn how to use inconsistent theories to obtain reliable
  proofs. Can lead to more freedom in mathematical workflow.

#### Univalent Foundations: New Foundations of Mathematics
- [Talk 3: Univalent foundations --- New Foundations of Mathematics](https://www.youtube.com/watch?v=E9RiR9AcXeE)


- Was uncertain about future when working on 2-categories and higher
  math. No way to ground oneself by doing "computations" (numerical experiments).
  To make it worse, the existing foundations of set theory is bad for these
  types of objects.
- Selected papers on Automath.
- Overcoming category theory as new foundations was very difficult for vovodesky.
- Categories are "higher dimensional sets"? NO! Categories are "posets in the next dimension".
  Correct version of "sets in the next dimension" are groupoids (WHY?)
  [MathOverflow question](https://mathoverflow.net/questions/309515/why-did-voevodsky-consider-categories-posets-in-the-next-dimension-and-groupo)
- Grothendeick went from isomorphisms to all morphisms, this prevented him from
  gravitating towards groupoids.
- Univalent foundations is a complete foundational system.
- [Sets are groupoids on the next dimension](https://mathoverflow.net/questions/309515/why-did-voevodsky-consider-categories-posets-in-the-next-dimension-and-groupo)




#### Vovodesky's univalence principle --- Joyal

- [Talk 5: Vovodesky's univalence principle --- Joyal](https://www.youtube.com/watch?v=HRBShaxIblI)

- Univanent type theory is arrived at by adding univalence to MLTT.
- Goal of univalent foundations is to apply UTT to foundations.
- Univalence is to type theory what induction principle is to peano arithmetic
- Univalence implies descent. Descent implies Blakers Massey-theorem, which
  implies Goodwille calculus.

- The syntactic system of type theory is a **tribe**.
- A clan is a category equipped with a class of _carrable maps_ called fibrations.
  A map is carrable if we can pull it back along any other map.
- A clan is a category along with maps called "fibrations", such that (1) every
  isomorphism is a fibration, (1) closed under composition, (3) fibrations are
  carrable, (4) base change of fibration is a fibration, (4) Category has a terminal
  object, and map into the terminal object is a fibration.
- A map $u: A \rightarrow B$ is **anodyne** if it does something good with respect
  to fibrations.
- A **tribe** is a clan such that (1) base chnge of anodyne along fibration is anodyne,
  (2) every map factorizes as anodyne followed by fibration.
- Kan complexes form a tribe. A fibration is a Kan fibration. A map is anodyne
  here if it is a monomorphism and a homotopy equivalence.
- Given a tribe $E$, can build a new tribe by slicing $E/A$ (this is apparently
  very similar to things people do in Quillen Model categories).
- A tribe is like a commutative ring. We can extend by adding new variables to get
  polynomial rings. An elementary extension is extending the tribe by adding a new
  element.
- If $E$ is a tribe, an object of $E$ is a type. We write `E |- A : Type`.
- If we have a map $a: 1 -> A$, we regard this as an element of A: `E |- a : A`.
- A fibration is a family of objects. This is a dependent type `x : A |- E(x): Type`.
  `E(x)` is the fiber  of `p: E -> A` at a variable element `x : A`.
- A section of a fibration gives an element of the fibration. We write this as
  `x : A |- s(x) : E(x)`. `s(x)` denotes the value of `s: A -> E` of a variable
   element `x : A`. (Inhabitance is being able to take the section of a fiber bundle?!)
- change of parameters / homomorphism is substitution.

```
y : B |- E(y) : Type
--------------------
x : A |- E(f(x)) : Type
```

This is pulling back along fibrations.

- Elementary extension `E -> E(A)` are called as context extensions.

```
|- B : Type
-----------
x : A |- B : Type
```

- A map between types is a variable element `f(x) : B` indexed by `x : A`

```
x : A |- f(x) : B
```

- Sigma formation rule: The total space of the union is the sum of all fibers(?)

```
x: A |- E(x): Type
------------------
|- \sum{x : A}E(x): Type
```


```
x: A |- E(x): Type
------------------
y : B |- \sum{x : f^{-1}(y)}E(x): Type
```

- Path object for $A$ is obtained by factorial diagonal map `diag: a -> (a, a)` as an anodyne
  map `r: A -> PA` followed by a fibration `(s, t) : PA -> A x A`.

- A homotopy `h: f ~ g` between two maps `f, g : A -> B` is a map`h: A -> PB`
  such that `sh = f` and `th = g`. homotopy is a congruence.
- `x: A, y : A |- Id_A(x, y) : Type` called the identity type of A.
- An element `p: Id_A(x, y)` is a proof that `x =A y`.
- Reflexivity term `x : A |- r(x) : Id_A(x, x)` which proves `x =A x`.
- The identity type is a path object
- $\gamma(x, y): Id_A(x, y) -> Eq(E(x), E(y))$. $\gamma$ is some kind of
  connection: given a path from $x$ to $y$, it lets us transport $E(x)$ to $E(y)$,
  where the $Eq$ is the distortion from the curvature?

# Hilbert basis theorem for polynomial rings over fields (TODO)

**Theorem:** Every ideal $I$ of $k[x_1, \dots, x_n]$ is finitely generated.

First we need a lemma:

## Monomial ideals

- Monomial ideals are ideals generated by monomials. in $K[x, y]$, these monomials are of the form $x^ay^b$.
- Lemma: Let $I = (\vec x^\alpha : \alpha \in A)$ be a monomial ideal generated by exponent vectors $A$.
  The monomial $\vec x^\beta$ lies in $I$ iff $x^\beta$ is divisible by some $\alpha \in A$.
- Suppose $\vec x^\beta$ lies in $I$. Thus, $x^\beta \equiv \sum_\alpha z_\alpha \vec x^\alpha$ for polynomials $z_\alpha \in k[x, y]$.
- Suppose each $z[\alpha] \equiv \sum_j c[\alpha][j] x^{\alpha[j]}$
  for monomials $x^{[\alpha][j]} \in k[x, y]$ and coefficients $c[\alpha][j] \in K$.
- This makes the equation look like:

\begin{aligned}
&x^\beta \equiv \sum_\alpha (\sum_j c[\alpha][j] x^{\alpha[j]}) \cdot x^{\alpha} \\
&x^\beta \equiv \sum_\alpha \sum_j c[\alpha][j] x^{\alpha[j] + \alpha}
\end{aligned}

- But since $x^{\beta}$ occurs on the right hand side, there must a term on the left hand side which is $x^{\beta}$ with non-zero
  coefficient. So we must have some $\alpha_*, j_*$ such that $x^{\alpha_*[j_*] + \alpha_*} \sim x^\beta$, or
  $\alpha_* + \alpha_*[j_*] = \beta$, or $\alpha_* \leq \beta$, which means that $x^\beta$ lies in the ideal as it can be generated
  by scaling $x^\alpha_* \in I$.

#### Polynomial in  monomial ideal is linear combination of ideal elements

- If $f \in I$, then this means that $f = \sum_i x^{\alpha} c_i$ for polynomials $c_i \in K[x, y]$.
- Expanding $c_i$ into monomials $c_{ij}$, we see that each of the terms on the RHS is some monomial $x^{\alpha_i}c_{ij}$ which is
  a multiple of $x^{\alpha_i}$, and thus lives in the ideal $I$.
- So, $f$ is a linear combination of $x^{\alpha_i} c_{ij}$ which live in the ideal.
- **MORAL**: A monomial ideal is determined by its monomials. Any polynomial in
  the monomial ideal is generated by monomials in the ideal.

#### Dickson's Lemma: monomial ideals are finitely generated

- Induction on the number of variables. $n = 1$ is done since $k[x]$ is a PID, needs only a single generator.
- Let's have $n+1$ variables, which we write as $K[x_1, \dots, x_n, y]$ with $y$ being the new variable we add (for induction).
- Suppose $I \subseteq K[x_1, \dots, x_n, y]$ is a monomial ideal. We must find a generating set for $I$.
- Let $J$ be the ideal generated by the ideal $I$ where we set $y$ to $1$. One way to think about this is to write $J \simeq I/(y-1)$.
- Alternatively, being very explcit, we define $J \equiv \{ x^\alpha : \exists k, x^\alpha y^k \in I\}$. That is,
  $J$ consists of all $x^\alpha$ such that for some $k$, $x^\alpha y^k \in I$.
- Philosophically, $J$ is the projection of $I$ onto the $\{ x_i \}$.
- Our inductive hypothesis says that $I$ is finite generated by $I \equiv \langle x^{\alpha(1)}, \dots, x^{\alpha(n)} \rangle$.
- For each $i \in [1, n]$, we know that we have $x^{\alpha(i)}y^{m(i)} \in I$ for some $m(i)$. Let $M \equiv \max_i m(i)$ be the largest
  of all $m_i$.
- Now consider the slices of $J$ at $y^k$. That is, we wish to generate $y^k \cdot I$ for all $k \in [0, m]$.
  Define $J_k \equiv \langle y^k x^{\alpha(i)} \rangle$.
- By our induction hypothesis, each of the $J_k$ is finitely generated.
- Thus, the full $J$ is generated by the  collection of all generators for each $J_k$ for $0 \leq k \leq M$. To compute $M$,
  we finitely generated $I$.
- See that every monomial in $I$ is divisible by the generator of some $J_k$ for some $k$. Suppose some $x^\beta y^b \in I$.
  If $b \geq M$, then we find some $x^\alpha(i)|x^\beta$ in $J$. Then, we consider $x^\alpha(i) y^{m(i)}$ which
  will definitely divide $x^\beta y^b$ since $m(i) \leq M \leq b$, and then $y^{m(i)}|y^b$.
- If we have $b < M$, then we consider the ideal $J_b$. Then the monomial $x^\beta y^b$ will be generated by monomials in $J_k$.
- Thus, since (1) every monomial in $I$ lies in some $J_k$, and vice versa, (2) monomial ideals are determined by their monomials,
  and (3) The $J_k$ are finitely generated, we have shown that $I$ is finitely generated by the union of generators
  of the $J_k$, $\cup \texttt{gen}(J_k)$


#### Ideal of leading terms

- For any ideal $I$, define the ideal of leading terms $LT(I)$ to be the ideal conisting of elements as the leading term of elements
 of $I$. So, $LT(I) \equiv \{ LT(f) : f \in I \}$. Check that this is an ideal. ($0 = LT(0)$, $1 = LT(1)$, $LT(f+g) = LT(f)+LT(g)$,
  and $LT(fg) = LT(f) LT(g)$).
- Suppose we have an ideal $I \equiv \langle f_1, f_2, \dots, f_n \rangle$. Now we have two ideals that we wish to compare:
  $LT(I)$, the ideal of leading terms, and $\langle LT(f_1), \dots, LT(f_n) \rangle$, the ideal _generated_ by the leading terms of the
  generators of $I$.
- We must always have $\langle LT(f_1), \dots LT(f_s) \rangle \subseteq LT(I)$
  by the definition of $LT(I)$ which contains _all_ leading   terms.
- However, $LT(I)$ can be larger.
- A generating set for $I$ given by $I \equiv \langle f_1, f_2, \dots, f_s \rangle$
  is a Grober basis iff it is true that $LT(I)$ equals  $\langle LT(f_1), LT(f_2), \dots, LT(f_s) \rangle$.

#### Proof of hilbert basis theorem

- We wish to show that every ideal $I$ of $k[x_1, \dots, x_n]$ is finitely generated.
- If $I = \{ 0 \}$ then take $I = (0)$ and we are done.
- Pick polynomials $g_i$ such that $(LT(I)) = (LT(g_1), LT(g_2), \dots, LT(g_t))$.
  This is always possible since $(LT(I))$ is a monomial ideal, which is finitely generated by Dickinson's Lemma.
- We claim that $I = (g_1, g_2, \dots, g_t)$.
- Since each $g_i \in I$, it is clear that $(g_1, \dots, g_t) \subseteq I$.
- Conversely, let $f \in I$ be a polynomial.
- Divide $f$ by $g_1, \dots, g_t$ to get $f = \sum_i a_i g_i + r$ where no term
  of $r \in K[x_1, \dots, x_n]$ is divisible by any of $LT(g_1), \dots, LT(g_t)$. We claim that $r = 0$.
- See that $r = f - \sum_i a_i g_i$. We have $r \in I$, since $f \in I$ and the $g_i$ live in $I$.
- Thus, we must have $LT(r) \in LT(I)$ (by the definition of $LT(I)$).
- If $LT(r)$ is nonzero, then since (1) $LT(I) = \langle LT(g_1), \dots, LT(g_n) \rangle$, and (2) $LT(I)$ is a monomial ideal,
   $LT(r)$ must be divisible by one of the generators!
- This contradicts the assumpion that $r$ is a reminader --- a remainder is by definition not divisible by any $LT(g_i)$.
- Thus, we have shown that if $f \in I$, then $f \in (g_1, \dots, g_n)$.


#### References

- Cox, Little, O'Shea: computational AG.


# Covering spaces

#### Covering spaces: Intuition

- Consider the map $p(z) = z^2 : \mathbb C^\times \rightarrow \mathbb C^\times$. This is a
  2-to-1 map. We can try to define an inverse regardless.
- We do define a "square root" if we want. Cut out a half-line $[0, -infty)$
  called $B$ for branch cuts. We get two functions on
  $q_+, q_-: \mathbb C - B  \rightarrow \mathbb C^\times$, such that $p(q_+(z)) = z$.
  Here, we have $q_- = - q_+$.
- The point of taking the branch cut is to preserve simply connectedness. $\mathbb C^\times$
  is not simply connected, while $\mathbb C/B$ is simply connected!
  (This seems so crucial, why has no one told me this before?!)
- Eg 2: exponential. Pick $exp: \mathbb C \rightarrow \mathbb C^\times$. This is
  surjective, and infinite to 1. $e^{z + 2 \pi n} = e^{iz}$.
- Again, on $\mathbb C / B$, we have $q_n \equiv \log + 2 \pi i n$, such that
  $exp(q_n(z)) = z$.
- A covering map is, roughly speaking, something like the above. It's a map that's
  n-to-1, which has n local inverse defined on simply connected subsets of
  the target.
- So if we have $p: Y \rightarrow X$, we have $q: U \rightarrow Y$ (for $U \subseteq X$)
  such that $p(q(z)) = z, \forall z \in U$.


#### Covering spaces: Definition

- A subset $U \subset X$ is a called as an **elementary neighbourhood**
  if there is a discrete set $F$ and a homeomorphism $h: p^{-1}(U) \rightarrow U \times F$
  such that $p|_{p^{-1}(U)}(y) = fst(h)$ or $p|_{p^{-1}(U)} = pr_1 \circ h$.
- [Alternative definition](https://www.math.wisc.edu/~maxim/751f14w6.pdf)
  A subset $U \subset X$ is called as **evenly covered/elementary nbhd** if
  $p^{-1}(U) = \sqcup \alpha V_\alpha$ where the $V_\alpha$ are disjoint and open, and
  $p|_{V_\alpha} : V_\alpha \rightarrow U$ is a homeomorphism for all $\alpha$.
- An elementary neighbourhood is the region where we have the local inverses
  (the complement of a branch cut).
- We get for each $i \in F$ , a map $q_i : U \rightarrow U \times F; q_i(x) = (x, i)$
  and then along $h^{-1}$ sending $h^{-1}(x, i) \in p^{-1}(U)$.
- We say $p$ is a covering map if $X$ is covered by elementary neighbourhoods.
- We say $V \subseteq Y$ is an elementary sheet if it is path connected and $p(V)$
  is an elementary neighbourhood.
- So, consider $p(x) = e^{ix}: \mathbb R \rightarrow S^1$.  If we cut the space
  at $(0, 0)$, then we will have elementary neighbourhood $S^1 - \{(0, 0)\}$
  and elementary sheets $(2 \pi k,  2 \pi+1)$.
- The point is that the inverse projection $p^{-1}$ takes $U$ to some object of the form $U \times F$:
  a local product! So even though the global covering space $\mathbb R$ does not look
  like a product of circles, it locally does. So it's some sort of fiber bundle?


> Slogan: Covering space is locally disjoint copies of the original space.


#### Path lifting and Monodromy

- Monodromy is behaviour that's induced in the covering space, on moving in a loop in a base.
- Etymology: Mono --- single, drome --- running. So running in a single loop /
  running around a single time.
- Holonomy is a type of monodromy that occurs due to parallel transport in a loop, **to detect curvature**
- Loop on the base is an element of $\pi_1(X)$.
- Pick some point $x \in X$. Consider $F \equiv \pi^{-1}(x)$ ($F$ for fiber).
- Now move in a small loop on the base, $\gamma$. The local movement will cause
  movement of the elements of the fiber.
- Since $\gamma(1) = \gamma(0)$, the elements of the fiber at the end of the movement
  are equal to the original set $F$.
- So moving in a loop induces a permutation of the elements of the fiber $F$.
- Every element of $\pi_1(X)$ induces a permutation of elements of the fiber $F$.
- This lets us **detect non-triviality** of $\pi_1(X)$. The action of $\pi_1(X)$ on the fiber
  lets us "detect" what $\pi_1(X)$ is.
- We will define what is means to "move the fiber along the path".


#### Path lifting lemma

**Theorem**:Suppose $p: y \rightarrow X$ is a covering map. Let $\delta: [0, 1] \rightarrow X$
be a path such that $\delta(0) = x$, and let $y \in p^{-1}(x)$ [$y$ is in the fiber of $x$].
Then there is a **unique** path $\gamma: [0,1] \rightarrow Y$ which "lifts" $\delta$.
That is, $\delta(p(y)) = \gamma(y)$, such that $\gamma(0) = Y$.


> Slogan: Paths can be lifted. Given how to begin the lift, can be extended all the way.

- Let $N$ be a collection of **elementary neighbourhoods** of $X$.
- $\{ \delta^{-1}(U) : U \in N \}$ is an open cover (in the compactness sense) of $[0, 1]$.
- By compactness, find a finite subcover. Divide interval into subintervals $0 = t_0 < t_1 < \dots t_n = 1$
  such that $\delta|k = \delta|_{[t_k, t_{k+1}]}$ lands in $U_k$, an elementary neighbourhood.
- Build $\gamma$ by induction on $k$.
- We know that $\gamma(0)$ should be $y$.
- Since we have an elementary neighbourhood, it means that there are a elementary
  sheets living over $U_0$, indexed by some discrete set $F$. $y$ lives in one
  of thse sheets. We have local inverses $q_m$. One of them lands on the sheet
  of $y$, call it $q$.  So we get a map $q: U_0 \rightarrow Y$ such that $q(x) = y$.
- Define $\gamma(0) \equiv q(\delta(0)) = q(x) = y$.
- Extend $\gamma$ upto $t_1$.
- Continue all the way upto $t_k$.
- To get $\gamma$ from $(t_k, t_{k+1}$, there exists a $q_k: U_k \rightarrow Y$
  such that $q_k(\delta(t_k)) = \gamma(t_k)$.
  Define $\gamma(t_k \leq t \leq t_{k_1}) \equiv q_k(\delta(t_k))$.
- This is continuous because $\delta$ continuous by definition, $q_k$ continuous
  by neighbourhood, $\gamma$ is pieced together such that endpoints fit,
  and is thus continuous.
- Can check this is a lift! We get $p \circ \gamma = p \circ q_k \circ \delta_k$.
  Since $q_k$ is a local inverse of $p$, we get $p \circ \gamma = \delta_k$
  in the region.

#### 7.03: Path lifting: uniqueness

If we have a space $X$ and a covering space $Y$, for a path $gamma$ that
starts at $x$, we can find a path $\gamma'$ which starts at $y \in p^{-1}(x)$
and projects down to $\gamma$: $\gamma(t) = p(\gamma'(t))$. We want to show
that this path lift is **unique**

##### Lemma

Let $p: Y \rightarrow X$ be a covering space. Let $T$ be a connected space
Let $F: T \rightarrow X$ be a continuous map (for us, $T \simeq [0, 1]$).
Let $F_1, F_2: T \rightarrow Y$ be lifts of $F$ ($p \circ F_1 = F$, $p \circ F_2 = F$).
We will show that $F_1 = F_2$ iff the lifts are equal for some $t \in $T.


> Slogan: Lifts of paths are unique: if they agree at one point, they agree at all points!

<img src="./static/cw/path-lifting-uniqueness-setup.png"/>

- We just need to show that if $F_1$ and $F_2$ agree somewhere in $Y$, they agree
  everywhere. It is clear that if they agree everywhere, they must agree somewhere.
- To show this, pick the set $S$ where $F_1, F_2$ agree in $Y$: $S \equiv \{ t \in T : F_1(t) = F_2(t) \}$.
- We will show that $S$ is open and closed. Since $T$ is connected, $S$ must
  be either the full space or the empty set. Since $S$ is assumed to be non-empty,
  $S = T$ and the two functions agree everywhere.
- (Intuition: if both $S$ and $S^c$ are open, then we can build a function that colors $T = S \cup S^c$
  in two colors continuously; ie, we can partition it continuously; ie the spaces
  must be disconnected. Since $T$ is connected, we cannot allow that to happen,
  hence $S = \emptyset$ or $S = T$.)
- Let $t \ in T$. Let $U$ be an evenly covered neighbourhood/elementary neighbourhood of $F(t)$ downstairs (in $X$).
  Then we have $p^{-1}(U) = \sqcup_\alpha V_\alpha$ such that $p|_V{\alpha}: V_\alpha \rightarrow U$
  is a local homeomorphism.
- Since $F_1, F_2$ are continuous, we will have opens
  $V_1, V_2$ in $V_\alpha$, which contain $F_1(t), F_2(t)$ upstairs
  (mirrroring $U$ containing $F(t)$ downstairs).
- The pre-images of $V_1$, $V_2$ along $F_1, F_2$ give us open sets $t \in T_1, T_2 \subseteq T$.
- Define $T* = T_1 \cap T_2$.  If $F_1(t) \neq F_2(t)$, then $V_1 \neq V_2$
  and thus $F_1 \neq F_2$ on all of $T*$. So, $S^c = T*$ is open.
- If $F_1(t) = F_2(t)$, then $V_1 = V_2$ and thus $F_1 = F_2$ on $T*$
  (since $p \circ F_1 = F = p \circ F_2$, and $p$
  is injective within $U$, ie within $V_1, V_2$). So $S$ is open.
- Hence we are done, as $S$ is non-empty and clopen and is thus equal to $T$.
  Thus, the two functions agree on all of $T$.

#### Homotopy lifting, Monodromy

- Given a loop $\gamma$ in $X$ based at $x$ ,
  the **monodromy around $\gamma$** is a permutation
  $\sigma_\gamma : p^{-1}(x) \rightarrow p^{-1}(x)$,
  where $\sigma_{\gamma}(y) \equiv \gamma^y(1)$
  where $\gamma^y$ is the unique lift of $\gamma$ staring at $y$.
  We have that $\sigma_{\gamma} \in Perm(p^{-1}(x))$.
- Claim: if $\gamma_1 \simeq \gamma_2$ then $\sigma_{\gamma_1} = \sigma_{\gamma_2}$.
- We need a tool: homotopy lifting lemma.


> Slogan: permutation of monodromy depends only on homotopy type

#### Homotopy lifting lemma/property of covering spaces

Suppose $p: Y \rightarrow X$ is a covering map and $\gamma_s$ is a homotopy
of paths rel. endpoints ($\gamma_s(0)$ and $\gamma_s(1)$ are independent of $s$ /
endpoints are fixed throughout the homotopy). Then there exists for each
lift $\gamma'_0 : [0, 1] \rightarrow Y$ of $\gamma_0:[0,1] \rightarrow X$
(ie, $p \circ \gamma'_0 = gamma_0$), a completion
of the lifted homotopy $\gamma'_s: [0, 1] \rightarrow Y$ (ie, $p \circ gamma'_s = gamma_s$).
Moreover, this lifted homotopy is rel endpoints: ie, the endpoints of $gamma'$ are
independent of $s$.

> Slogan: homotopy lifted at 0 can be lifted for all time

- Let $H: [0, 1] \times [0, 1] \rightarrow X$ be the homotopy in $X$ such that
  $H(s, t) = \gamma_s(t)$. Subdivide the square into rectangles $R_{ij}$  such that
  $H(R_{ij})$ is contained in $U_{ij}$ for some elementary neighbourhood $U_{ij}$.
  We build $H': [0, 1] \times [0, 1] \rightarrow Y$ by building local inverses
  $q_{ij} : U_{ij} \rightarrow Y$ such that $p \circ q_{ij}  = R_{ij}$.
  We then set $H'|_{R_{ij}}  = q_{ij} \circ H$.


- [Reference video](https://www.youtube.com/watch?v=3CuQ3yfh0eA&list=PLN_4R2IuNuuTWD00k9BAB1fo0UldBHnME&index=31)
- [Notes for uniqueness of path lifting](https://www.math.wisc.edu/~maxim/751f14w6.pdf)




# Wedge Sum and Smash Product

I sometimes forget which is which. I now remember this as folows:

- First, these work on based spaces so we always need to think of based points.
- Wedge is a sum, so it's going to be some type of union. It needs to identify
  things, so it better be $A \cup B / \sim$ where $\sim$ identifies based points.
- Smash is a product, so it's going to be some type of product. It needs to
  identify things, so it better be $A \times B / \sim$, where $\sim$ crushes together
  anything that has a based point. So $(*, a), (a, *), (*, *)$ are all crushed.
- If we don't remember the "sum" and "product" bit, and only remember "wedge"
  and "smash", then "wedge" starts with a "w" which looks like `\/`so it should
  be a union.

# Quotient topology

I watched this for shits and giggles. I don't know enough topology at all, but it's
fun to watch arbitrary math videos.

#### Quotient topology: Defn, examples
- Intended to formalise identifications.

Given space $X$ and equivalence relation $\sim$ on $X$, the quotient set
$X/\sim$ inherits a topology. Let $q : X \rightarrow X/\sim$ send point to
equivalence class.  Quotient topology is the most **refined** topology
on $X/\sim$ such that $q$ is continuous. That is, it has the most open sets
for which this map is continuous.

- More explicitly, a set $U \subset X/\sim$ (which is a collection of equivalence
  classes) is open iff $q^{-1}(U)$ is open in $X$.
- Even more explicitly, $V \subseteq X/\sim$ is open iff $U_V \equiv \{ x \in U : [x] \in V \}$
  is open in $X$.
- Even more explicitly, we can write $U \equiv \cup_{v \in V} v$, because the elements of
  $v$ are equivalence classes.

#### Claim: quotient topology is a topology

- The preimage of the empty set is the empty set, and thus is open.
- The preimage of all equivalence classes is the full space, and thus open.
- Preimage of union is union of preimages: $\cup_i q^{-1}(V_i)$ extend $h$ to get a new homotopy $H$: $H_0 = id_X$ and $H_t|A = h_t$.


#### $(X, A)$ have HEP and $A$ is contractible, then $X \simeq X/A$
- Pick $q: X \rightarrow X/A$. We need another map such that their compositions are
  homotopic to the identities of $X$ and $X/A$.
- Define $s: X/A \rightarrow X$ as a section of $q$, given by $s([a]) \equiv a, s([x]) \equiv x$.
  This is a section of $q$ since $q \circ s = id_{X/A}$ (That is, $s$ maps entirely within the fibers of $q$).
- Consider $s_t : H_t \circ s : X/A \rightarrow X$. That is, lift from $X/A$ to $X$ using $s$ and then perform $H_t$ on $X$.
  We claim that The map $(H_1 \circ s)$ is the homotopy inverse of $q$.
- (1a) $(H_1 \circ s) \circ q : X \rightarrow X$ is equal to $H_1$, as $H_1(s(q(A))) = H_1(s([a])) = H_1(a) = a  = H_1(A)$, and $H_1(s(q(x))) = H_1(s([x])) = H_1(x)$.
- (1b) So we have $(H_1 \circ s) \circ q = H_1 \simeq H_0 = id_X$, as $H_0 = id_X$ is from defn, and $H_1 \simeq H_0$ is from homotopy. So we are done
  in this direction.
- (2a) Consider $q \circ (H_1 \circ s) : X \rightarrow X/A$. We wish to show that this is continuous. Let's show that it lifs to a continous
  map upstairs. So consider $q \circ (H_t \circ s) \circ q : X \rightarrow X/A$. We claim that this is equal to $q \circ H_t$,
  which is continuous as it is a composition of continuous maps.
- This relationship is hopefully intuitive:
  $q \circ (H_t \circ s) \circ q$ asks us to treat all of $A$ as if it were $a$ before applying $H_t$.
  Since $q$ kills whatever $H_t$ does after, and $H_t$ guarantees to keep $A$ within $A$, it's fine if we treat all of $A$ as just $a$.
  $q \circ H_t$ asks us to treat $A$ as $A$ itself, and not $a$. Since $q$ kills stuff anyway, we don't really care.
  The real crux of the argument is that $q \circ stab_A = q \circ stab_A \circ s \circ q$ where $stab_A$ is a map that stabilizes $A$.
- (2b) Consider $(q \circ (H_t \circ s) \circ q)(A) = (q \circ H_t \circ s)([a]) = (q \circ H_t)(a)$  --- Since $H_t(a) = h_t(a) = a' \in A$,
  we crush all data regardless of what happens. This is the same as the value $(q \circ H_t)(A) = [a]$ as $H_t(A) \subseteq A$ and $q(A) = [a]$.
  For the other set, we get $(q \circ (H_t \circ s) \circ q)(x) = q \circ H_t \circ s([x]) = q \circ H_t(x)$ and hence we are done.
- (2c) Now since $q \circ (H_t \circ s))$ is continuous, and that $q \circ (H_0 \circ s) : X/A \rightarrow X/A = id_{X/A}$, we are done
  since we can homotope from $q \circ H_1 \circ s \simeq q \circ H_0 \circ s = id_{X/A}$.


> Slogan: Use HEP to find homotopy $H$. Use $H_1 \circ s$ as inverse
> to quotient.


# CW Complexes and HEP

If $X$ is a CW complex and $A$ is a closed subcomplex, then it has the HEP.
A closed subcomplex is a union of closed cells of $X$ such that $X$ is obtained
by adding more cells to $A$.


##### Lemma

If $e$ is a disk, then there is a continuous map from $e \times [0, 1]$ to
$\partial e \times [0, 1] \cup (e \times \{ 0 \})$.

<img src="./static/cw/hep-project-disk.png"/>

##### Lemma

If $X$ is obtained from $A$ by attaching one $k$-cell, then $(X, A)$ has HEP.


Given a homotopy $h_t: A \times [0, 1] \rightarrow Y$ and a new homotopy
$F_0: X \rightarrow Y$ such that $F_0|A = h_t$, we want to complete $F$
such that $F_t|A = h_t$.

The only part I don't know where to define $F$ on is the new added $e$ portion.
So I need to construct $H$ on $e \times [0, 1]$. Use the previous map to get to
$e \times [0, 1] \cup (e \times \{0\})$. This is in the domain of $F_0$ or $h_t$,
and thus we are done.

##### CW Complexes have HEP

Induction on lemma. base case is empty set.

##### Connected 1D CW Complex

**Theorem:** any connected 1D CW complex is homotopic to wedge of circles.

- Find a contractible subcomplex $A$ of $X$ that passes through all $0$ cells.
- By HEP, $X \simeq X/A$. $X/A$ has only one zero-cell and other one cells.
  One cells are only attached to zero cells. Hence, is a wedge of circles.
- The idea to find a contractible subcomplex is to put a partial order on the
  set of *all* contractible cell complexes by inclusion.
- Pick a maximal element with respect to this partial order.
- Claim: maximal element must contain all zero cells. Suppose not. Then I
  can add the new zero cell into the maximal element (why does it remain contractible? Fishy!)


# Stable homotopy theory

We like stable homotopy groups
because of the [Freudenthal suspension theorem](https://en.wikipedia.org/wiki/Freudenthal_suspension_theorem)
which tells us that homotopy groups stabilise after many suspensions.

The basic idea seems to be something like a tensor-hom adjunction. We have
the loop spaces which are like $S^1 \rightarrow X$ and the suspension which
is like $S^1 \wedge X$. The theory begins by considering the tensor-hom-adjunction
between these objects as fundamental.  So curry stuff around to write things as
`(S^1, A) -> B` and `A -> (S^1 -> B)`, which is `Suspension(A) -> B` and `A -> Loop(B)`.
This gives us the adjunction between suspension and looping.


- We then try to ask: how can one invert the suspension formally? One tries
  to do some sort of formal nonsense, by declaring that maps between $\Sigma^{-n}X$
  and $\Sigma^{-m} Y$ , but this doesn't work due to some sort of grading issue.
- Instead, one repaces a single object $X$ with a family of objects $\{ X_i \}$
  called  as the spectrum. Then, we can invert the suspension by trying to invert
  maps between objects of the same index.

#### References

- [Homotopy Extension](http://www.homepages.ucl.ac.uk/~ucahjde/tg/html/cw-02.html)
- [CW complexes](https://www.youtube.com/watch?v=XWg4LVbmm3M&list=PLN_4R2IuNuuTWD00k9BAB1fo0UldBHnME&index=21)
- [Stable homotopy theory 1](https://www.youtube.com/watch?v=neC3HUyqlV0)


# Simply connected spaces

- A space is simply connected iff fundamental group at all points is trivial.
- We usually don't want to talk about basepoint, so we assume that the space
  is path-connected. This means we can move the basepoint around, or not
  take about the basepoint.
- So, a path-connected space is simply connected iff the fundamental group is
  trivial.

#### Simply connected => all paths between two points are homotopic.

If $x, y$ are two points, then there is a single unique homotopy class of
points from $x$ to $y$. Consider two paths from $x$ to $y$ called $\alpha, \beta$.
Since $\beta^{-1} \circ \alpha \in \pi_1(x, x) = 1$, we have that
$\beta^{-1} \circ \alpha \simeq \epsilon_x$. [ie, path is homotopic to trivial
path]. compose by $\beta$ on the left: This becomes $\alpha \simeq \beta$.

- This is pretty cool to be, because it shows that a simply connected space is forced
  to be path connected. Moreover, we can imagine a simply connected space as one we can
  "continuously crush into a single point".


# Finitely generated as vector space v/s algebra:

- To be finitely generated as a vector space over $K$ from a generating
  set $S$ means that we take elements of the form $\sum_i k_i s_i$, or abbreviated,
  elements of the form $\sum KS$
- To be finitely generated as a $K$ algebra from a generating set $S$,
  we take elements of the form
  $\sum_i k_i s_i + \sum_{ij} k_{ij} s_i s_j + \dots$. To abbreviate, elements
  of the form $\sum C + CS + CS^2 + CS^3 \dots = C/(1-S)$.

As a trivial example, consider $K[X]$. This is not finitely generated as a
vector space since it doesn't have a finite basis: the obvious choice of
generating set $\{ 1, X, X^2, \dots \}$ is not finite. It *is* finitely
generated as a $K$-algebra with generating set $\{ X \}$.

# Weak and Strong Nullstllensatz


#### Weak Nulstellensatz: On the tin

For every maximal ideal $m \subset k[T_1, \dots, T_n]$ there is a unique
$a \in k^n$ such that $ m = I(\{ a \})$. This says that any maximal ideal
is the ideal of some point.

#### Weak Nullstellensatz: implication 1 (Solutions)
every ideal, since it is contained in a maximal ideal, will have zeroes.
Zeroes will always exist in all ideas upto the maximal ideal.

- It simply says that for all ideals $J$ in $\mathbb C[X_1, \dots, X_n]$, we have $I(V(J)) = sqrt J$
- Corollary: $I$ and $V$ are mutual inverses of inclusions between algebraic sets and radical ideals.


#### Weak Nullstellensatz: Implication 2 (Non-solutions)

If an ideal does not have zeroes, then it must be the full ring. Hence, 1 must
be in this ideal. So if $I = (f_1, f_2, \dots, f_n)$ and the system has
no solutions, then $I$ cannot be included in any maximal ideal, hence $I = \mathbb C[X_1, \dots, X_n]$.
Thus, $1 \in I$, and there exist $c_i \in \mathbb C[X_1, \dots, X_n]$ such that
$1 = sum_i f_i c_i$.


#### Strong Nullstellensatz: On the Tin


For every ideal $J$, we have that $I(V(J)) = |_0^\infty\sqrt J$. I am adopting
the radical (heh) notation $|_0^\infty \sqrt x$ for the radical, because this matches
my intuition of what the radical is doing: it's taking *all roots*, not just *square roots*.
For example, $\sqrt{(8)} = (2)$ in $\mathbb Z$.


#### Strong Nullstellensatz: Implication 1 (solutions)

Let $J = (f_1, \dots, f_m)$. If $g$ is zero on $V(J)$ , then $g \in \sqrt J$.
Unwrapping this, $\exist r \in \mathbb N, \exists c_i \in \mathbb C[X_1, \dots,  X_n], \sum_i f_i c_i = g^r$.



#### Weak Nullstellensatz: Proof

- Let $m$ be a maximal ideal.
- Let $K$ be the quotient ring  $K \equiv \mathbb C[X_1, \dots, X_n] / m$.
- See that $K$ is a field because it is a ring quotiented by a maximal ideal.
- Consider the map $\alpha: \mathbb C[X_1, \dots, X_n] \rightarrow K$, or $\alpha : \mathbb C [X_1, \dots, X_n] \rightarrow \mathbb C[X_1, \dots, X_n] / m$ by sending
  elements into the quotient.
- We will show that $\alpha$ is an evaluation map, and $K = \mathbb C$. So we will get a function
  that evaluates polynomials at a given point, which will have a single point as a solution.
- Core idea: See that $\alpha(\mathbb C) = \mathbb C \subset K$. Hence $K$ is a field that contains
  $\mathbb C$. But $\mathbb C$ is algebraically closed, hence $K = C$.
- First see that $\mathbb C \subset K$, or that $\alpha$ preserves $\mathbb C$ [ie, $\alpha(\mathbb C) = \mathbb C$].
  note that no complex number can be in $m$.
  If we had a complex number $z$ in $m$, then we would need to have $1 = 1/z \cdot z$ in $m$
  (since an ideal is closed under multiplication by the full ring), which means $1 \in m$, due to which
  we get $m$ is the full ring. This can't be the case because $m$ is a proper maximal ideal.
- Hence, we have $\mathbb C \subseteq K$ or $K = \mathbb C$.
- Thus the map we have is $\alpha: \mathbb C[X_1, X_2, \dots, X_n] \rightarrow \mathbb C$.
- Define $z_i = \alpha(X_i)$. Now we get that $\alpha(\sum_{ij} a_{ij} X_i^j) = \sum_{ij} a_{ij} z_i^j$. That is,
   we have an evaluation map that sends $X_i \mapsto z_i$.
- CLAIM: The kernel of an evaluation map $\alpha$ is of the form $(X_1 - z_1, \dots, X_n - z_n)$.
- PROOF OF CLAIM:TODO
- The kernel is also $m$. Hence, $m = (X_1 - z_1, \dots, X_n - z_n)$, and point that corresponds to the
  maximal ideal is $(z_1, z_2, \dots, z_n)$.


#### Strong Nullstellensatz: Proof

We use the [Rabinowitsch trick](https://en.wikipedia.org/wiki/Rabinowitsch_trick).
- Suppose that wherever $f_1, \dots, f_m$ simultaneously vanish, then so does $g$. [that is, $g \in I(V(J))$
  where $J = (f_1, \dots, f_m)$].
- Then the polynomials $f_1, \dots, f_m, 1 - Yg$ have no common zeros where $Y$ is a new
  variable into the ring.
- Core idea of why they can't have common zeros: Contradiction. assume that $1 - Yg$, and all the $f_i$
  vanish at some point.
  Then we need $1 - Yg = 0$ which mean $Y = 1/g$, so $g$ cannot vanish, so $g \neq 0$.
  However, since all the $f_i$ vanish, $g$ also vanishes as $g \in (V(J))$. This is contradiction.
- Now by weak Nullstellensatz, the ideal $J = (f_1, \dots, f_m, (1-Y)g)$ cannot be contained
  in a maximal ideal (for then they would simultaneously vanish). Thus, $J = R$ and $1 \in J$.
- This means there are coefficients $c_i(Y, \vec x) \mathbb C[X_1, \dots , X_n, Y]$ such that

$$
1 = c_0(Y, \vec x) (1 - Yg(\vec x)) \sum_{i=1}^m c_i(Y, \vec x) f_i(\vec x)
$$

Since this holds when $\vec x, Y$ are arbitrary variables, it continues to hold
on substituting $Y = 1/g$, the coefficient $c_0(1-Yg) = c_0(1 - g/g) = c_0(1 - 1) = 0$ disappears. This gives:
$1 = \sum_{i=1}^m c_i (Y, \vec x) f_i(\vec x) $

since $Y = 1/g$, we can write $c_i(Y=1/g, \vec x) = n_i(\vec x)/g^r_i(\vec x)$.  By clearing denominators, we get:

$$
1 = \sum{i=1}^m n_i(\vec x) f_i(\vec x)/ g^R(\vec x)
$$

This means that $ g^R(\vec x) = \sum_{i=1}^m n_i(\vec x) f_i(\vec x)$

#### Strong Nullstellensatz: algebraic proof

- We have $g \in I(V(J))$.
- We want to show that $g \in \sqrt{J}$ in $R$.
- This is the  same as showing that $g \in \sqrt{0}$ in $R/J$. ($J \mapsto 0$ in the quotient ring).
- If $g$ is nilpotent in $R/J$, then the $(R/J)_g$ becomes the trivial ring $\{ 0 \}$.
  [Intuitively, if $g$ is nilpotent and a unit, then we will have $g^n = 0$, that is  unit raised to some
   power is 0, from which we can derive $1 = 0$].
- Localising at $g$ is the same as computing $R[Y]/(1 - Yg, J)$.
- But we have that $V(1 - Yg, J) = \emptyset$. Weak Nullstellensatz implies that $(1 - Yg, J) = (1)$.
- This means that $R[Y]/(1 - Yg,J) = R[Y]/(1) = \{ 0 \}$. Thus, $(R/J)_g$ has $g$ as nilpotent,
  or $g \in \sqrt J$ in $R$.

#### Relationship between strong and weak

Strong lets us establish what functions vanish on a *variety*. Weak let us establish
what functions vanish at a *point*.

#### Strong Nullstellensatz in scheme theory

- Same statement: $I(V(J)) = \sqrt J$.
- $V(J)$ is the set of points on which $J$ vanihes. Evaluation is quotienting. So it's going to be
  set of prime ideals $p$ such that $J \xrightarrow{R/p} 0$. So $J \subset p$. This means that
  $V(J) = \{ p \text{prime ideal in } R, J \subseteq p \}$.
- $I(V(J))$ is the set of functions that vanish over every point in $V(J)$. The functions that vanish
  at $p \in V(J)$ are the elements of $p$. So the functions that vanish over all points is
  $I(V(J)) = \cap V(J)$.
- Unwrapping, this means that $I(V(J))$ is the intersection of all ideals in $V(J)$, which is the intersection
  of all primes that contains $J$, which is the radical of $J$.

Holy shit, scheme theory really does convert Nullstellensatz-the-proof into
Nullstellensatz-the-definition! I'd never realised this before, but this.. is crazy.

Not only do we get easier proofs, we also get more power! We can reason about generic
points such as $(x)$ or $(y)$ which don't exist in variety-land. This is really really cool.

- [Reference video](https://www.youtube.com/watch?v=GyWiyR0vULE)

# Screen recording for kakoune pull request

I wanted to show what keys I was pressing to demonstate the change I was
proposing. So I used:
- `SimpleScreenRecorder` to record my screen.
- `screenkey` to show the keystrokes I press.

This was used the create the PR that
[improves the page up/page down to mimic vim behaviour](https://github.com/mawww/kakoune/pull/4074)

# Intuition for why finitely presented abelian groups are isomorphic to product of cyclics

- If we have a finitely presented group, we can write any element as a product
  of the generators.. Say we have two genetors $g, h$ and some relations between
  them, we can have elements $gh$, $ghgh$, $gghh$, $ghg^{-1}$, and so on.
- If the group is abelian, we can rearrange the strings to write them as $g^a h^b$.
  For example, $ghgh = g^2h^2$, and $ghg^{-1} = g^0h^1$ and so on.
- Then, the only information about the element is carried by the powers of $g, h$.
- If $g$ has order $n$ and $h$ has order $m$, then the powers live in $Z/nZ, Z/mZ$.
- Thus, the group above is isomorphic to $Z/nZ \times Z/mZ$ by rearranging and
  collecting powers.
- The same argument works for any finitely generated abelian group.


# Euler characteristic of sphere

Pick two antipodal points and connect them into a great circle. We have two points.
To connect them, we need two edges. The great circle divdies the spere into two
faces. This gives $2-2+2=2$.


# John Conway: The symmetries of things

Original way to classify wallpaper groups: think of geometric transforms
that fix the pattern. Thurston's orbifold solution: think of quotients of $\mathbb R^2$
by groups --- this gives you an *orbifold* (orbit manifold).


Take a chair, surround it around by a sphere.  The symmetries of a physical
object fixes the center of gravity. So we pick the center of the sphere  to
be the center of gravity. The "celestial sphere" (the sphere around the chair)
is a nice manifold (We only have the surface of the sphere). The vertical
line that divides the chair also divides the sphere into two parts.

- The points of the orbifold are orbits of the group.
- So now the orbifold gives us a hemisphere in this case.
- The topology of the orbifold determines the group.
- This is astonishing, because the group is a metrical object: elements of the group
  preserve the inner product of the space.
- And yet, geometrical groups are determined by the *topology* of their orbifolds!
- Thurston's metrization conjecture: certain topological problems reduce to geometrical ones.

Conway came up with his notation for wallpaper groups/orbifolds. There are only
four types of features.

-  The hemisphere orbifold is `*`. (group of order 2). `*` denotes the effect on
   the orbifold. `*` really means: what is left out of a sphere when I cut out a
   hemispherical hole. `*` is the name for a disk, because a hemisphere is a disk
   topologically. It has metrical information as well, but we're not going to
   speak about it, because all we need is the topological information.
-  One-fourth of a sphere (symmetry group of rectangular table)
   is denoted by `* 2 2`. The `*` for the hemisphere, and `2, 2`
   for the angles of `pi/2`.
-  If the table is a sphere, then we have diagonal symmetry as well. In this case,
   the orbifold has angle `pi/4`. So the table is `* 4 4`.
-  If we take a cube, then we have an even more complicated orbifold. The "fundamental region"
   of the cube has 2, 3, and 4 mirrors going through them. So in the orbifold, we get
   triangles of angles `pi/2, pi/3, pi/4`. This would be `* 4 3 2`.
-  Draw a swastika. This has no reflection
   symmetry. This has a *gyration*: a point about which the figure can be rotated,
   but the point is NOT on a line of reflection. We can tear the paper and make
   it into a cone. This gives us a *cone point*. The angle around the cone point
   is `2pi/4`. This is the orbifold of the original square with a swastika on it.

An orbifol can be made to carry some amount of metrical information. The cone
point only has 90 degrees, so it is in some sense, "a quarter of a point".

-  Draw a cube with swastikas marked on each face. This has no reflection
   symmetry. Once again, we have a gyration, and again, only the gyration/singularities
   matter. This group is again `4, 3, 2` , but in **blue**. In this notation,
   **red** is reflection, **blue** is "true motion" (?).

Let us try to work out the euler characteristic of the rectangular table
orbifold by using $V - E + F$. The orbifold as one face.
The **wrong thing** to say is that the orbifold has two edges and two vertices.
It is untrue because the edge of the orbifold is only half an edge --- let's
say that lines have thickness. In this case, we will have $V = 2/4$, $E = 2/2$,
and $F = 1$.  The euler characteristic works out to be a half. This is appropriate,
because the orbifold is a type of divided manifold.

- If we work this out for a cube, we get $2/48$. This is because the sphere gets
  divided into 48 pieces, and the sphere has an euler characteristic of 2!
- Alternatively, we can think that we started out with 2 dollars, and we are then
  buying the various features of our orbifold. `*` costs `1$`, a blue number
  after a star, for example: `2` costs `1/2` a dollar. `3` costs `2/3` of a dollar,
  `4` costs `3/4` of a dollar. In general, `n` costs `1 - 1/n`.
  The red numbers are children, so they cost half an much: `n` consts `1/2(1 - 1/n) = (n-1)/2n`.


Now, see that we started with positive euler characteristic (2), and we divide
it by some `n` (the order of the group). So we end up with a positive euler characteric.
By a sort of limiting argument, the euler characteristic of the wallpaper groups,
which are infinite, is zero. However, see that we must get to the zero by starting
with two dollars and buying things off the menu! If we try and figure out what
all the possible ways are to start with 2 dollars and buy things till we are
left with exactly 0 dollars, we get that there are 17 possible ways of buying
things on the menu! Thus, this the reason for there being 17 wallpaper groups.


- To buy more than two dollars, you are buying symmetries from the hyperbolic
  plane!

Because we can completely enumerate 2-manifolds, we can completely enumerate
2-orbifolds, which are essentially the same thing as symmetry groups. The real
power is in the 3D case. We don't have a full classification of 3-manifolds. But
we maybe able to go the other way. This is the metrization theorem.

- [Video lecture](https://www.youtube.com/watch?v=8z6T-7ovA5Q)

# Semidirect product mnemonic

I just learnt that when we write the semidirect product $N \ltimes K$, the
$\ltimes$ is to look like a combination of $N \triangleleft G$ ($N$ is normal in $G$)
and the $\times$ operator; This tells us that it is the $N$ part that is normal.
in $N \ltimes K$.

- A good example to remember is $\mathbb R^3 \ltimes SO(3)$, where we define
  a group element $(t, r)$ by the action: $(t, r) v = rv + t$ [$t$ for translation and $r$ for rotation].

- Let's compose these. We find that:

$$
\begin{aligned}
&(t2, r2)((t1, r1)(v))  \\
&= (t2, r2)(r1v + t1) \\
&= r2(r1v + t1) + t2\\
&= (r2 r1) v + (r2 t1 + t2) \\
&= (r2 t1 + t2, r2 21) v
\end{aligned}
$$

- Here, we have the rotation $r_2$ act non-trivially on the translation $t_1$.
- We need the translation to be normal, since we are messing with the translation
  by a rotation.
- We want the translations to be closed under this messing about by the rotation action;
  The action of a rotation on a translation should give us another translation.
  Thus, the translations $(t_1, id)$ ought to be normal in the full group $(t_2, r_2)$.

Another mnemonic for the semidirect product:

> my thesis adviser told me that the acting group (the non-normal subgroup)
> opens its mouth and tries to swallow / "act on" the group it acts upon (the normal subgroup).
> The group that is acted on must be normal, because we act "by conjugation". Alternatively,
> being normal is "tasty", and thus needs to be eaten.


# Non orthogonal projections

Consider the matrix

$$
P = \begin{bmatrix} 1 & 1 \\ 0 & 0 \end{bmatrix}
$$
- $P^2 = P$, so it's a projection. It projects the vector `[x;y]` to the
  vector `[x+y;0]`. Clearly, applying it twice will result in 0. `[x; y]`,
  1. `[x+y; 0]`, 2. `[x+y; 0]`.
- It projects the value `(x+y)`onto the `x` axis,and kills the `y` axis.
- It's **not** a projection onto the coordinate axis.


# Why did maxwell choose his EM wave to be light?

- We Knew gravity as fields
- dalton/thompson atomic model that had particles: protons, neutrons, electron
- Knew electricity and magnetism as fields
- Maxwell wrote down laws, said that the wave solution to his laws was light. (why?)
- Michaelson morly proved speed of light was constant, matched maxwell prediction
- Einstein found photo electric effect. Posited “light particle” (photon). [why light?]
- De Broglie
- [who connected photon to EM wave through gauge?]
- Weyl created U(1) symmetry for Maxwell’s equations / photon
- Yang-mills wrote down how photon occurs as particle associated to EM field
- what is the field that electron corresponds to?  Electron field? Why no wiki page? Dirac spinor field! Dirac spinor
- How do we get fermi/bose statistics out of the field equation?  In QM, when
  we perform second quantization, ie, solve for single particle and claim that
  multi particle is the tensoring of single particle, we “choose the
  statistics” arbitrarily.


# Fast string concatenation in python3

Apparently, the correct way to do this, in a way that's not `O(n^2)` is to
use the `io.StringIO` module. The API is:

- `x = io.StringIO()`: create a string buffer
- `x.write(stuff_to_append)`: append into string buffer with correct `realloc()`
   doubling semantics for `O(1)` amortized per character
- `out = x.getvalue()`: pull data out of `StringIO`.
- `x.close()`: tell the `StringIO` that we are done and it can free its buffer.

It took quite a bit of trawling the API docs to find this while I was
helping a friend speed up some data munging.

# Split infinitive

```
to safely remove %v
```

The infinite "to remove" has been split by "safely".

```
to remove %v safely.
```

# Yoneda from string concatenation

I'm trying to build intuition for Yoneda (again) this time from the perspective
of strings and concatenation. The idea is that the identity function behaves
like the empty string, and "free arrow composition" behaves like string
concatenation. So can we understand yoneda from this model?

- First, let's think of `Hom(X, X)`. What are the elements here? Well, for one,
  we need the identity arrow `idX` in `Hom(X, X)`. Maybe we have other elements
  called `a, b, c` in `Hom(X, X)`. So our picture of `Hom(X, X)` looks like this:


<img src="./static/yoneda/hom-x-x-1.png"/>

- what does it *mean* to have an element `a` in `Hom(X, X)`? It means that there's
  an arrow from `X` to `X` in the category. But this also means that we have
  a map from `Hom(X, X)` *to* `Hom(X, X)`, given by composing with `a`! That is,
  we have a map `- . a :: Hom(X, X) -> Hom(X, X)`.

<img src="./static/yoneda/hom-x-x-2.png"/>

- If we have such a map of "composition with a", then we need to know where this
  map `-.a` maps all the elements of `Hom(X, X).` Thinking about this,
  we see that we need to add new elements to `Hom(X, X)`, which are the
  composition of the current elements (`idX`, `a`, `b`, `c`) with `a`. This
  gives us the elements
  `idX.a = a, a.a = aa, b.a = ba, c.a = ca`.

<img src="./static/yoneda/hom-x-x-3.png"/>

- Similarly, we need to know where *these* new elements `aa`, `ba`, `ca` map to,
  but let's hold off on that for now, for that simply demands an extrapolation of
  imagination. Let's imagine having another object `Y` and an arrow `g: X -> Y`.
  This will give us a new hom-set `Hom(X, Y) = Hom(X, X) . g`

<img src="./static/yoneda/hom-x-y-1.png"/>

- In `Hom(X, Y)` we will have as elements all the arrows from `X` to `Y`.
  Let's say there's some arrow `h: X -> Y`. Then, we will find this arrow `h` in `Hom(X, Y)`
  as the image of `idX` under `-.h` . So really, for *any* arrow, we can find
  what element it maps to as long as know (a) `idX` and (b) `-.h`.


 Now that we understand the "internal" structure, let's imagine we're representing
 this collection of objects and arrows by some other collection of objects
 and arrows. So we have a functor `F` that takes these sets to other sets,
 and takes these objects to other objects.


# Right Kan extensions as extending the domain of a functor

#### First over functions (fake category fluff)

Given a function $g: C \rightarrow E$ and an embedding $j: C \rightarrow D$,
then the Right Kan extension of $g$ along $j$, denoted $g/j$ is a new function
$g/j: D \rightarrow E$.
So we are extending the *domain* of $g$, along the extender $j$. Informally,
we write the new function as $g/j$ because:

```
C---
|   \-g---*
j         |
|         |
v         v
D--g/j--->E
```
```
foo(j(c)) = g(c)
foo = (g/j)(c)
g/j(j(c)) = g(c)
```

#### Next over preorders (real category stuff)

The kan extension provides us a bijection, for
any function `f: D -> E`

```
C---
|   \-g---*
j         |
|         |
v         v
D--g/j--->E
D------f->E

hom(f.j, g) ~= hom(f, g/j)
```

That is, if we have some way to make congruent `f.j` with `g`, then we can
"split" the congruence to have `f.j` congruent with `(g/j).j`. Cancelling `j`,
we can have `f` congruent with `g/j`.

Consider a preorder with a ordering `≤`. Equip with a monoidal structure `<>`,
which is  a monotone map with a neutral element. (For example, integers with
multiplication and `≤`).

The bijection of hom-sets is equivalent to saying

```
m*k <= n iff m <= n/k
```

(how? I have no idea; I gotta work this out!)


#### Question: What happens in the context of vector spaces?

Since linear algebra is probably the nicest thing we have in math, I really
want to understand what happens in the linear algebra case. I don't really
understand how to make the correct version of a kan extension inside $Vect$,
though. A kan extension seems to fundamentally be a 2 categorical construct,
than a 1 categorical construct.


- [Art and dan explain an old trick](https://www.cs.ox.ac.uk/ralf.hinze/Kan.pdf)

# Non standard inner products and unitarity of representations


I stumbled across [this questions about non-standard inner products](https://math.stackexchange.com/questions/4021023/visualization-of-length-and-orthogonality-under-non-standard-inner-product). Can I use this to visualize the weyl
averaging trick in represention theory?

# take at most 4 letters from 15 letters.

Trivial: use $\binom{15}{0} + \binom{15}{1} + \binom{15}{3} + \binom{15}{4}$.
Combinatorially, we know that $\binom{n}{r} + \binom{n}{r-1} = \binom{n+1}{r}$.
We can apply the same here, to get $\binom{15}{0} + \binom{15}{1} = \binom{16}{1}$.
But what does this *mean*, combinatorially? We are adding a dummy letter, say $d_1$,
which if chosen is ignored. This lets us model taking at most 4 letters by adding
4 dummy letters $d_1, d_2, d_3, d_4$ and then ignoring these if we pick them up; we
pick 4 letters from 15 + 4 dummy = 19 letters.


I find it nice how I used to never look for the combinatorial meaning behind
massaging the algebra, but I do now.

# Flat functions

Define

$$
f(x) \equiv
\begin{cases}
0 & x <= 0 \\
e^{-1/x} & x > 0
\end{cases}
$$

This is smooth, but is badly non-analytic. Any taylor expansion around $x=0$
is going to be identically zero. So we're going to prove that it possesses
all derivatives. This implies that the derivative at zero is equal to zero,
because the left derivative is always equal to zero.

- $f(x) \equiv e^{-1/x}$. Differentiate to get $f'(x) = e^{-1/x}/x^2$. Change
  $y \equiv 1/x$ to get $y^2 e^{-y}$. As $y \mapsto \infty$, $e^{-y}$
  decays more rapidly than $y^2$ increases, thus the limit is zero.
  Hence, $f'(x) = 0$.
- For higher derivatives, let $f^{(n)}(x) \equiv p_n(1/x) e^{-1/x}$ for some polynomial $p_n$.
  See that $f^{(n+1)}(x) = d/dx [p_n(1/x) e^{-1/x})]$. To compute this, set $y \equiv 1/x$
  and compute $d/dy [p_n(y) e^{-y}] dy/dx$ which is:

$$
\begin{aligned}
& = d/dy [p_n(y) e^{-y}] dy/dx \\
& = p_n'(y) e^{-y} + p_n(y) (- e^{-y}) \cdot 1/x^2 \\
& = e^{-1/x} (p_n'(1/x) - p_n(1/x)) 1/x^2 \\
& = e^{-1/x} (q_n'(1/x) - q_n(1/x)) \\
& \text{let $r_{n+1}(x) (\equiv q_n'(t) - q_n(t))t^2$} \\
& = r_{n+1}(1/x) e^{-1/x}
\end{aligned}
$$

- So we can write higher derivatives too as $poly(1/x)$ times $exp(-1/x)$ which also decays
  rapidly to $0$.

- Philosophically, what's going on is that a non-zero polynomial can only have a finite number of zeroes.
  Since this function has an infinite number of zeroes around it's neighbourhood at $(x = 0)$,
  any polynomial that agrees with this function in any neighbourhood must be identically zero everywhere.

- [Flat functions on wikipedia](https://en.wikipedia.org/wiki/Flat_function)

# Hopf Algebras and combinatorics

> Started from algebraic topology in the 40s. In late 70s, Rota
> figured out that many combinatorial objects have the structure of a Hopf
> algebra.

A hopf algebra is a vector space $H$ over a field $K$. together with $K$ linear
maps $m: A \rightarrow A \otimes A$ (multiplication),
$U: A \rightarrow K$ (unit), $\Delta: H \rightarrow H \otimes H$ (comultiplication)
$S: A \rightarrow A$ (co-inverse/antipode). Best explained by examples!


- [Hopf algebra and combinatorics](https://www.youtube.com/watch?v=FzVhjCRuXus&list=PL-XzhVrXIVeRLeezwY9h4M68k6yB3yOo-)
- [Hopf algebras and rooted trees](http://www.math.ubc.ca/~thomas/TeXthings/HopfAlgebras-1.1.pdf)


- [Hopf algebra 1](https://www.youtube.com/watch?v=fqirLhXLoXM)

> The idea is that groups act by symmetries. Hopf algebras also act,
> we can think of as providing quantum symmetries.


#### Eg 1: Group algebra: $A = kG$

$G$ is a group, $kG$ is a group algebra. $\delta(g) \equiv g \otimes g$,
$\epsilon(g) = 1$, $s(g) = g^{-1}$.




# Butcher group

I really want to read the math about the [butcher group](https://en.wikipedia.org/wiki/Butcher_group),
which was introduced to study numerical solutions of ODEs using RK, and
then had far-reaching theoretical applications. Connes remarked:

> We regard Butcher’s work on the classification of numerical integration
> methods as an impressive example that concrete problem-oriented work can lead
> to far-reaching conceptual results.



# Neovim frontends

- [veonim](https://glitchtron.org/veonim/): Rendered an utterly glitched UI.
- [uivonum](https://github.com/smolck/uivonim): NPM based, so wasn't my thing.
- [neovide](https://github.com/Kethku/neovide): rust based, feels very fluid,
  has cool cursor animations that make it "fun" to type with!
- [goneovim](https://github.com/akiyosi/goneovim)

# A semidirect product worked on in great detail

We work out the semidirect product structure of the collection of real 2x2 matrices

$$
\begin{bmatrix}
1 & a \\ 0 & b
\end{bmatrix}
$$

We first see that the multiplication rule is:


$$
\begin{bmatrix}
1 & a \\
0 & b
\end{bmatrix}
\begin{bmatrix}
1 & p \\
0 & q
\end{bmatrix}
=
\begin{bmatrix}
1 &  p + bq \\
0 & bq
\end{bmatrix}
$$

so  these are closed under matrix multiplication. The identity matrix
is one among these matrices and thus we have the identity. The inverse
of such a matrix  can also be seen to be of such a kind.

##### Diagonal transforms



We have two subgroups of matrices in this set of 2x2 matrices.
The first of these I shall call _diagonal_ and denote with $D$:

$$
\begin{bmatrix}
1 & 0 \\
0 & b
\end{bmatrix}
\begin{bmatrix}
1 & 0 \\
0 & q
\end{bmatrix}
=
\begin{bmatrix}
1 & 0 \\
0 & bq
\end{bmatrix}
$$

<img src="./static/semidirect-product/diagonal.png"/>

Hopefully clearly, this is isomorphic
to $\mathbb R^*$ since the only degree of freedom is the bottom right entry,
which gets multiplied during matrix multiplication. These transform
a vector $(x, y)$ into the vector $(x, \delta y)$.
Informally, the $D$ matrices are responsible for scaling the $y$-axis.

<img src="./static/semidirect-product/diagonal-composition.png"/>

##### Shear transforms

Next, we have the other subgroup of matrices, which I shall call _shear_
and denote by $S$:

$$
\begin{bmatrix}
1 & a \\
0 & 1
\end{bmatrix}
\begin{bmatrix}
1 & p \\
0 & 1
\end{bmatrix}
=
\begin{bmatrix}
1 & (a+p) \\
0 & 1
\end{bmatrix}
$$


<img src="./static/semidirect-product/shear.png"/>

These are isomorphic to $\mathbb R^+$, since the only degree of freedom is
their top-right entry, which gets added on matrix multiplication. These
matrices transform a vector $(x, y)$ into $(x + \delta y, y)$.

<img src="./static/semidirect-product/shear-composition.png"/>


#### Generating all transforms with diagonal and shear transforms

we can write any transform of the form

$$
T \equiv
\begin{bmatrix}
1 & a \\
0 & b
\end{bmatrix}
$$


#### Semidirect product: Conjugations

We need to check whether the subgroup $D$ or the subgroup $S$ is normal.
For this, take two arbitrary elements:

$$
[d] \equiv
\begin{bmatrix}
1 & 0 \\
0 & d
\end{bmatrix}; ~~~
[s] \equiv
\begin{bmatrix}
1 & s \\
0 & 1
\end{bmatrix}
$$


##### Conjugating $D$ by $S$:

Let's to conjugate a diagonal with a shear:

$$
\begin{aligned}
&[s^{-1}][d][s](x, y) \\
&= [s^{-1}][d] (x+sy, y) \\
&= [s^{-1}](x+sy, dy) \\
&= (x+sy-sdy, dy) \\
\end{aligned}
$$

This doesn't leave us with another diagonal transform.

<img src="./static/semidirect-product/sinv-d-s.png" />

#####  Conjugating $S$ with $D$

Now let's compute the action of $dsd^{-1}$, and $sds^{-1}$ on some general $(x, y)$:

$$
\begin{aligned}
&[d^{-1}][s][d](x, y) \\
&= [d^{-1}][s] (x, dy) \\
&= [d^{-1}](x + dy, dy) \\
&= [d^{-1}](x + dy, dy \times 1/d \\
&= (x + dy, y)
\end{aligned}
$$

See that the final result we end up with is a shear transform which
shears by $y/d$. So, we can write the equation $DSD^{-1} = S$: conjugating
a shear by scaling leaves us with a shear.

<img src="./static/semidirect-product/dinv-s-d.png" />

##### The connnection to partial  fractions

Recall that any matrix of the form `[a b; c d]` can be viewed as taking
the fraction `x/y` to `(ax+by)/(cx+dy)`. In our case, we have:


- Diagonal: `[1 0; 0 b]` which take `x/y` to `x/by`.
- Shear: `[1 a 0 1]` which take `x/y` to `(x + ay)/y`.

It's clear that diagonals and shears compose. What is unclear is how they
interact. A little thought shows us:

```
x/y -diagonal->
x/dy -shear->
(x+sdy)/dy
(x+sy')/y'
```

```
x/y -shear->
(x+sy)/y -diagonal->
(x+sy)/dy
= (x+(s/d)y')/y'
```

So, when we compse shears with diagonals, we are left with "twisted shears".
The "main objects" are the shears (which are normal), and the "twists" are
provided by the diagonal.

The intuition for why the twisted obect (shears) should be normal
is that the twisting (by conjugation) should continue to give us twisted
objects (shears). The "only way" this can resonably happen is if the twisted
subgroup is normal: ie, invariant under all twistings/conjugations.


##### How the semidirect product forms

From the above computations, we can see that it is the shear transform $S$ that
are normal in the collection of matrices we started out with, since
$D^{-1}SD = S$. Intuitively, this tells us that it is the diagonal
part of the transform composes normally, and the shear part of the transform is
"twisted" by the diagonal/scaling part. This is why composing a shear
with a diagonal (in either order --- shear followed by diagonal or vice versa)
leaves us with a twisted shear. This should give a visceral sense of "direct
product with a twist".

##### Where to go from here

In some sense, one can view
[all semidirect products as notationally the same as this example](http://bollu.github.io/the-cutest-way-to-write-semidirect-products.html)
so this example provides good intuition for the general case.

# Direct and Inverse limits

#### Direct limit: definition

A direct limit consists of _injections_ $A_1 \rightarrow A_2 \rightarrow \dots$.
It leads to a limit object $L$, which as a set is equal to the union of all
the $A_i$. It is equipped with an equivalence relation. We can push data "towards"
the limit object, hence it's a "direct" limit.

So each element in $A_i$ has an equivalence class representative in $L$.


#### Direct limit: prototypical example


###### $S_n$

We can inject the symmetric groups $S_1 \rightarrow S_2 \rightarrow \dots$.
However, we cannot project back some permutation of $S_2$ (say) to $S_1$:
if I have $(2, 1)$ (swap 2 and 1), then I can't project this back into $S_1$.

This is prototypical; in general, we will only have injections into the limit,
not projections out of the limit.


##### Prufer group

Here, the idea is to build a group consisting of all the $p^n$th roots
of unity. We can directly """define""" the group as:

$$
P(q)^\infty \equiv \{ \texttt{exp}(2\pi k /q^n) : \forall n, k \in \mathbb N, ~ 0 \leq k \leq q^n \}
$$

That is, we take $q^1$th roots of unity, $q^2$th roots of unity, and so
on for all $n \in \mathbb N$.

To build this as a direct limit, we embed the group $Z/q^n Z$ in $Z/q^{n+1}Z$ by sending:
the $q^n$ th roots of unity to $q^{n+1}$th roots of unity raised to the power $q$.
An example works well here.

- To embed $Z/9Z$ in $Z/27Z$, we send:
- $2 \pi 1 /9$ to $2 \pi 1/9 \times (3/3) = 2 \pi 3 / 27$.
- $2 \pi 2 /9$ to $2 \pi 6/27$
- $2 \pi 3 /9$ to $2 \pi 9 / 27$
- $2 \pi k / 9$ to $2 \pi (3k)/27$
- This gives us a full embedding.


The direct limit of this gives us the prufer group. We can see that the prufer group
is "different" from its components, since for one it has cardinality $\mathbb N$.
For another, all subgroups of the prufer group are themselves infinite. The idea
is to see that:
- Every subgroup of the prufer group is finite.
- By Lagrange, `|prufer|/|subgroup| = |quotient|`. But this gives us something like
  `infinite/finite = infinite`.

To see that every subgroup $H$ of the prufer group is finite, pick an element $o$ outside of
the subgroup $H$. This element $o$ will belong to some $Z/q^kZ$ for some $k \in \mathbb Z$
(since the direct limit has an elements the union of all the original elements modulo
some equivalence). If the subgroup $H$ does not have $o$ (and thus does not contain $Z/q^kZ$),
then we claim that it cannot contain any of the larger $Z/q^{k+\delta}Z$. If it did
contain the larger $Z/q^{k + \delta}$, then it would also contain $Z/q^k$ since we inject
$Z/q^k$ into $Z/q^{k+\delta}$ when building the prufer group. Thus, at MAXIMUM,
the subgroup $H$ can be $Z/q^{k-1}Z$, or smaller, which is finite in size.  Pictorially:

```
...         < NOT in H
Z/q^{k+1}Z  < NOT IN H
Z/q^kZ      < NOT IN H
---------
...         < MAYBE IN H, FINITE
Z/q^2Z      < MAYBE IN H, FINITE
Z/qZ        < MAYBE IN H, FINITE
```

The finite union of finite pieces is finite. This $H$ is finite.

##### Stalks

Given a topological space $(X, T)$ and functions to the reals
on open sets $F \equiv \{ U \rightarrow \R \}$, we define the restricted
function spaces $F|_U \equiv \{ F_U : U \rightarrow \mathbb R : f \in F \}$.


Given two open sets $U \subseteq W$, we can restrict functions on $W$
(a larger set) to functions on $U$ (a smaller set). So we get maps
$F|_W \rightarrow F|_U$.

So given a function on a larger set $W$, we can inject into a smaller set $U$.
But given a function on a smaller set, it's impossible to uniquely extend
the function back into a larger set. These maps really are "one way".

The reason it's a union of all functions is because we want to "identify"
equivalent functions. We don't want to "take the product" of all germs of
functions; We want to "take the union under equivalence".

###### Finite strings / `A*`

Given an alphabet set $A$, we can construct a finite limit of strings of length
$0$, strings of length $1$, and so on for strings of any given length
$n \in \mathbb N$.  Here, the "problem" is that we can also find projection maps that
allow us to "chop off" a given string, which makes this example not-so-great.
However, this example is useful as it lets us **contrast** the finite and infinite
string case. Here, we see that in the final limit $A*$, we will have all
strings of _finite_ length.  (In the infinite strings case, which is an
inverse limit, we will have all strings of _infinite_ length)

##### Vector Spaces over $\mathbb R$

consider a sequence of vector spaces of dimension $n$: $V_1 \rightarrow V_2 \dots V_n$.
Here, we can also find projection maps that allows us to go down from $V_n$
to $V_{n-1}$, and thus this has much the same flavour as that of finite strings.
In the limiting object $V_\infty$, we get vectors that have a finite number of
nonzero components. This is because any vector in $V_{\infty}$ must have come
from some $V_N$ for some $N$. Here, it can have at most $N$ nonzero components.
Further, on emedding, it's going to set all the other components to zero.

###### Categorically

Categorically speaking, this is like some sort of union / sum (coproduct).
This, cateogrically speaking, a **direct limit** is a **colimit**.

#### Inverse limit: definition

An inverse limit consists of _projections_ $A_1 \leftarrow A_2 \leftarrow \dots$.
It leads to a limit object $L$, which as a set is equal to a subset of the
product of all the $A_i$, where we only allow elements that "agree downwards"
.Formally, we write this as:

$$
L \equiv \{ a[:] \in \prod_i A_i : \texttt{proj}(\alpha \leftarrow \omega)(a[\omega]) = a[\alpha] ~ \forall \alpha \leq \omega \}
$$

So from each element in $L$, we get the projection maps that give us the component $a[\alpha]$.


> These 'feel like' cauchy sequences, where we are refining information at each
> step to get to the final object.

#### Inverse limit: prototypical example

##### infinite strings

We can consider the set of infinite strings. Given an infinite string,
we can always find a finite prefix as a projection. However, it is impossible
to *canonically* inject a finite prefix of a string into an infinite string!
Given the finite string `xxx`, how do we make it into an infinite string?
do we choose `xxxa*`, `xxxb*`, `xxxc*`, and so on? There's no canonical choice!
Hence, we only have *projections*, but no *injections*.

##### P-adics

Consider the 7-adics written as infinite strings of digits in $\{0, 1, \dots, 6\}$.
Formally, we start by:

1. Having solutions to some equation in $\mathbb{Z}/7\mathbb{Z}$
2. Finding a solution in $\mathbb{Z}/49\mathbb{Z}$ that restricts to the same solution in
   $\mathbb{Z}/7\mathbb{Z}$
3. Keep going.


The point is that we define the $7$-adics by projecting back solutions
from $\mathbb{Z}/49\mathbb{Z}$. It's impossible to correctly _embed_
$\mathbb{Z}/7\mathbb{Z}$ into $\mathbb{Z}/49\mathbb{Z}$: The naive map
that sends the "digit i" to the "digit i" fails, because:

- in $\mathbb{Z}/7\mathbb{Z}$ we have that $2 \times 4 \equiv 1$.
- in $\mathbb{Z}/49\mathbb{Z}$ $2 \times 4 \equiv 8$.

So $\phi(2) \times \phi(7) \neq \phi(2 \times 7) = \phi(4)$. Hece, we
**don't have injections**, we **only have projections**.

##### Partitions

Let $S$ be some infinite set. Let $\{ \Pi_n \}$ be a sequence of partitions
such that $\Pi_{n+1}$ is finer than $\Pi_n$. That is, every element of $\Pi_n$
is the union of some elements of $\Pi_{n+1}$. Now, given a finer partition,
we can clearly "coarsen" it as desired, by mapping a cell in the "finer space"
to the cell containing it in the "coarser space". The reverse has no canonical
way of being performed; Once again, we only **have projections**, we have
**no injections**.


The inverse limit is:

$$
\{ (P_0, P_1, P_2, \dots) \in \prod_{i=0}^n \Pi_n : P_a = \texttt{proj}_{a \leftarrow z}(P_z) \forall a \leq z  \}.
$$

But we only care about "adjacent consistency", since that generates the other
consistency conditions; So we are left with:


$$
\{ (P_0, P_1, P_2, \dots) \in \prod_{i=0}^n \Pi_n : P_a = \texttt{proj}_{a \leftarrow b}(P_b) \forall a +1 = b  \}.
$$

But unravelling the definition of $\texttt{proj}$, we get:

$$
\{ (P_0, P_1, P_2, \dots) \in \prod_{i=0}^n \Pi_n : P_a \supseteq P_b) \forall a +1 = b  \}.
$$

So the inverse limit is the "path" in the "tree of partitions".

##### Vector Spaces

I can project back from the vector space $V_n$ to the vector space
$V_{n-1}$. This is consistent, and I can keep doing this for all $n$. The thing
that's interesting (and I believe this is true), is that the final object we get,
$V^\omega$, can contain vectors that have an infinite number of non-zero components!
This is because we can build the vectors:

$$
\begin{aligned}
&(1) \in V_1 \\
&(1, 1) \in V_2 \\
&(1, 1, 1) \in V_3 \\
&(1, 1, 1, 1) \in V_4 \\
&\dots
\end{aligned}
$$

Is there something here, about how when we build $V_\infty$, we build it as a
direct limit. Then when we dualize it, all the arrows "flip", giving us $V^\omega$?
This is why the dual space can be larger than the original space for infinite
dimensional vector spaces?



###### Categorically

Categorically speaking, this is like some sort of product along with equating
elements.  This, cateogrically speaking, a **inverse limit** is a **limit**
(recall that categorical limits exist iff products and equalizers exist).

### Poetically, in terms of book-writing.

- The direct limit is like writing a book one chapter after another. Once we
  finish a chapter, we can't go back, the full book will contain the chapter,
  and what we write next must jive with the first chapter. But we only control
  the *first chapter* (existential).

- The inverse limit is like writing a book from a very rough outline to a more
  detailed outline. The first outline will be very vague, but it controls the
  *entire narrative* (universal). But this can be refined by the later drafts
  we perform, and can thus be "refined" / "cauchy sequence'd" into something
  finer.

### Differences

- The direct limit consists of taking unions, and we can assert that any element in $D_i$
  belongs in $\cup_i D_i$. So this lets us assert that $d_i \in D_i$ means that $d_i \in L$,
  or $\exists d_i \in L$, which gives us some sort of existential quantification.
- The inverses limit consists of taking $\prod_i D_i$. So given some element $d_i \in D_i$,
  we can say that elements in $L$ will be of the form $\{d_1\} \times D_2 \times D_3 \dots$.
  This lets us say $\forall d_1 \in D_1, \{d_1\} \times D_2 \dots \in L$. This is
  some sort of universal quantification.


<!-- - [Grab me a coffee](https://ko-fi.com/bollu) -->
# LEAN 4 overfrom from LEAN together 2021
- add `unsafe` keyword.
- allow people to provide unsafe version of any opaque function if the
  type is inhabited. Type inhabited => proofs are fine. (Do we need to assume UIP for this to work?)
- mimalloc, custom allocator.
- counting immutable beans for optimising refcounting. (related work: Perceus: Grabage free refcounting with reuse.)
- hash tables and arrays are back (thanks to linearity?)
- Tabled typeclass resolution for allowing diamonds in typeclass resolution
  (typeclasses no longer need to form a semilattice for resolution).
- Discrminiation trees.
- LEAN4 elaborator for adding custom syntax related to monads, tactics.
- Beyond notation: hygenic macro expansion for theorem proving languages.
- Kernel can have external type checker.

> during wartime, you do not study the mating ritual of butterflies

- Collaboration: Optimising tensor computations.
- Collaboration: Rust integration.
- Collaboration: DSLs for LEAN.
- Collaboration: SAT/SMT integration

#### Metaprogramming in LEAN4

- macro expansion, elaboration. First expand all macros, elaborate, repeat.

#### Verified decompilation

- We want assured decompilation.
- Check equivalence of BBs using solvers; compcert approach is too complex.

- [Lean together 2021](https://www.youtube.com/watch?v=UeGvhfW1v9M&list=PLlF-CfQhukNnO8z3TcFcoKozif9gbl7Yt&index=5)

# BLM master thesis

- [link here](https://tspace.library.utoronto.ca/bitstream/1807/101595/3/Khogali_Yusra_201806_MA_thesis.pdf)

# RSK correspondence for permutations

##### Tableaux

Tableaux of size $n$ first needs a partition of size $n$ in decreasing
order. Write it as $\lambda$, such that $\lambda[i] \geq 0$ and $\sum_i \lambda[i] = n$
and $\lambda[i]$ is weakly decreasing: $\lambda[1] \geq lambda[2] \geq lambda[n]$.
For example, a partition of $9$ is $4, 2, 2, 1$. This is drawn as:

```
* * * *
* *
* *
*
```

Next, we fill the tableau with numbers from $[n] \equiv \{1,\dots,n\}$ such
that the rows are weakly increasing and columns are strictly increasing
(gravity acts downwards, and we always want to get bigger). These
are called **Standard tableay** For example,
a valid Standard tableau corresponding to the partition above is:

```
1 3 4 6
2 5
7 9
8
```

(Sidenote: here both rows and columns are strictly increasing because we have
unique numbers. If we did not, then by convention, the rows will be weakly
increasing and columns strictly increasing. I always repeat the chant
"rows weakly, columns strictly" to burn it into my brain).

##### Insertion

Say we start with some tableau $T$. Can we add an element $x$ into it such that
$T' = ins(T, x)$ is a valid tableau? Yes, and this process is called insertion.

##### Deletion


This is the reverse of insertion. Say we start with a tableau $T$. Can we delete
a location $(i, j)$, such that we get a smaller tableau $T'$, and an element $x$
such that $ins(T', x) = T$? Yes we can, and this process is called deletion.

##### Misoncentions about deletion

Deletion does not mean that we lose the _value_ at $(i, j)$. Rather, we
_change the shape_ of the tableau to lose the _cell_ $(i, j)$. consider
the tableau:

```
1
2
3
```

If we ask to delete the cell $(r=1,c=3)$ (that is, the cell containing $3$),
we will be left with the tableau:

```
2
3
```

and the element $1$. So, when we insert $1$ into $[2; 3]$ we get $[1; 2; 3]$.

We **did not get**

```
1
2
```

and the element $3$. This is because if we insert $3$ into $[1;2]$, then we
get the tableau $[1,3;2]$:

```
1 3
2
```

##### Bijection between permutations and pairs of standard tableau

Given a permutation $p: [n] \rightarrow [n]$, we define two tableau
corresponding to it: the insertion tableau $P$ and the recording tableau $Q$.
Informally, the insertion tableau is obtained by inserting $p[1], p[2], \dots, p[n]$
in sequence into an empty tableau. The recording tableau at step $i$ records
where the number $i$ was stored in the tableau. So the recording tableau
at step $i$, $Q_i$ has the same shape as the insertion tableau at step $i$,
$P_i$, and contains the value $i$ at the cell where $i$ was stored in $P$.
That is, $P_i[Q_i[i]] = i$.

##### Properties of the insertion and recording tableau

We consider the set of points $(i, p(i))$. This is called as the
[Viennot's geometric construction](https://en.wikipedia.org/wiki/Viennot%27s_geometric_construction),
where we reason about the graph. We will reason about the graph here, but couch
the formal arguments in terms of partial orders to be precise.

At each point $(i, p(i))$, imagine a rectangle with $(i, p(i))$ as the lower left
corner. Next, shine a flashlight from the point $(0, 0)$ towards the upper right
quadrant; the boundary that is cast by the rectangles are called as the
shadow lines.

Formally, we consider a dominance relationship where $(x, y) \lhd (p, q) \equiv x \leq p \land y \leq q$.
Then, we get the "points on the shadow lines" by considering the Hasse diagram
of the points $(i, p(i))$ under the relationship $\lhd$. Each level of
the hasse diagram becomes one of the shadow lines.  The collection of all of
these shadow lines is called as the _first order shadow lines_.

Next, for each anti-chain, pick the element with the smallest $x$-coordinate.
These points _will form a chain_. This chain will be first row of
the permutation tableau $P$.

Funnily enough, it is also one of the longest increasing subsequences of the
sequence $i \mapsto p(i)$ because the length of the longest chain (the longest increasing
subsequence) is equal to the number of antichains (the number of shadow lines)

##### Duality theory of $\lhd$

<!-- lhd = left hand delta -->

Note that $\lhd$ as a relation is symmetric in $x$ and $y$. Thus, any order
theoretic result we prove for $x$ will hold for $y$. But note that $(i, p(i))$
is the permutation $p$, while $(p(i), i)$ is the inverse permutation $(p^{-1})$.
Thus, we should expect a "duality" between the order theoretic properties of
$P$ and $p^{-1}$.





# Djikstra's using a segtree

> keep min segtree of distances. Now just have to run n-1 interations.
> You like segtrees right :P


# Markov and chebyshev from a measure theoretic lens

I've been idly watching [Probability and Stochastics for finance: NPTEL](https://www.youtube.com/watch?v=qTg0mqxuGeA&list=PLEYrMI37wMbplhGJmqhlYv0VUSwC6zMsU&index=8), and I came across this nice way to
think about the markov and chebyshev inequality. I wonder whether Chernoff
bounds also fall to this viewpoint.

#### Markov's inequality

In markov's inequality, we want to bound $P(X \geq A)$. Since we're in measure land,
we have no way to directly access $P(\cdot)$. The best we can do is to integreate
the constant function $1$, since the probability is "hidden inside" the measure.
This makes us compute:

$$
P(X \geq A) \equiv = \int_{\{X \geq A\}} 1 d \mu
$$

Hm, how to proceed? We can only attempt to replace the $1$ with the $X$ to get
some non-trivial bound on $X$. But we know that $X \geq A$. so we should perhaps
first introduce the $A$:


$$
P(X \geq A) \equiv = \int_{\{X \geq A\}} 1 d \mu = 1/A \int_{\{X \geq A\}} A d \mu
$$

Now we are naturally led to see that this is always less than $X$:

$$
\begin{aligned}
&P(X \geq A) \equiv = \int_{\{X \geq A\}} 1 d \mu = \\
& 1/A \int{\{X \geq A\}} A d \mu < 1/A \int_{\{X \geq A\}} X d \mu = 1/A \mathbb{E}[X]
\end{aligned}
$$

This completes marov's inequality:

$$
P(X \geq A) \leq \mathbb{E}[X]/A
$$

So we are "smearing" the indicator $1$ over the domain $\{X \geq A\}$ and attempting
to get a bound.



# Among any 51 integers, that are 2 with squares having equal value modulo 100
# $1^n + 2^n + \dots + (n-1)^n$ is divisible by $n$ for odd $n$
# $10^{3n+1}$ cannot be written as sum of two cubes

https://hackage.haskell.org/package/contravariant-1.5.3/docs/Data-Functor-Contravariant-Divisible.html



# Coq-club: the meaning of a specification

> When I was doing my PhD, I faced questions similar to yours. It emerged from my
> encounter of HOL4 for completing a project after having used Coq for another.
>
> Given your question is on the meaning of a word, I would like to refer to a
> philosophical doctrine on how words acquire their meaning in a system of signs.
> Using that doctrine, I put forward  how I came to an answer for myself!
>
> So turns out that a text can be perceived as a construct made around elemental
> "oppositions". Accordingly, textual constructs only produce meaning through
> their interplay of DIFFERENCES (mostly emergingin in form of binary contrasts)
> inside a system of distinct signs. This doctrine was first introduced by
> Ferdinand Saussure on which J. Derrida drew for introducing his notion of
> difference.
>
> Considering the above explanation, instead of hard wiring the words
> "specification" and "implementation" to predetermined functionality or
> referents, we can perceive them in a contrasting interplay whose connection is
> established via the proof game. The "specification" is something used by a
> "proof" to demonstrate "the correctness " of an "implementation ".
>
> Now going for the Saussurian doctrine, there is no problem for an _expression_
> to be specification for an implementation,  but itself being an implementation
> for something else. Therefore, I would definitely hesitate to say it is
> meaningless (or even misguiding) to use the word specification in the context
> of formal verification.
>
> Hopefully that was useful!


- [Link to coq-club discussion](https://sympa.inria.fr/sympa/arc/coq-club/2021-01/msg00103.html)

# SQLite opening

```
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
```


# Old school fonts

I've been rolling with the  `Px437 ToshibaSat 8x14` font as my daily driver purely for nostalgia reasons; It is to be honest quite a good font! Otherwise, I use `Iosevka Fixed Expanded`, or the "agda font", `mononoki`.

- [I love the old school fonts website](https://int10h.org/oldschool-pc-fonts/fontlist/?2#toshiba)

# Stalking `syzigies` on hackernews

He's the author of Macaulay; I learnt quite a bit by [stalking him on hackernews](https://news.ycombinator.com/threads?id=Syzygies)

- Schreier–Sims algorithm for computing with permutations.

- Our phones should learn a private language with us. My dog learns after one
  repetition; Zoom should learn to arrange my windows as I like, at least after
  47 repetitions.

- [The bayer filter](https://en.wikipedia.org/wiki/Bayer_filter)

- Our extrapolations always take the form of moving along a tangent vector out
  from prior experience. Prior to relativity, Newtonian physics was the belief
  that we actually lived in that tangent space. Surprises come when the
  deviations are large enough for reality to curve away from our models

- Like flipping through for the soft porn in a friend's "romance" novel, I must
  confess I searched straight for this guideline.

 - Lisp's signature 17 car pileup at the end of every expression.

- I look for the `$` or equivalent in any proposal out there, to see if the
  author has written lots of code or is just talking. It's like looking for
  bone marrow in beef stew, evaluating a cookbook. Marrow is central to the
  story of Lisp; we got our start being able to wield tools to crack open bones
  after lions and jackals had left a kill. The added nutrition allowed our
  brains to increase in size. Soon we mastered fire, then Lisp.

-  I spent the first few months outside doing woodworking; I've been struggling
   with an overwhelming urge to center my consciousness in my hands. This is of
   course the history of our species, a biological urge as profound as our sex
   drive. We figured out how to make very sharp hunting tools from unruly
   rocks, or we died.

- [spider webs on drugs](http://thirdmonk.net/high-culture/spiders-drugs-affect-webs.html)

-  The first chapter of Berstel and Reutenauer's "Noncommutative Rational
   Series with Applications" presents Schützenberger's theorem that every
   noncommuting rational power series is representable, and conversely. The
   idea is NOT painfully abstract, but makes twenty minutes work of a semester
   of undergraduate automata theory (an assertion I've tested multiple times in
   my math office hours).

- You don't want sync software going off and "thinking" about what a symlink
  really means, anymore than you'd want sync software going off and "thinking"
  after finding porn on your computer

- Luckily, I was trained far enough down the street from MIT to escape their
  Lisp world view, so we coded our computer algebra system in C, and it was
  fast enough to succeed and bring us tenure. Today, we'd choose Haskell.


His LISP language with inferred parens:

```
define | edge? g e
  let
    $ es | edges g
      e2 | reverse e
    or (member e es) (member e2 es)
```

```
(define (edge? g e)
  (let
    ( (es (edges g))
      (e2 (reverse e)))
    (or (member e es) (member e2 es))))
```


# Conditional probability is neither causal nor temporal

I found this insightful:

> `P(A|B)` means the probability of A happening given B already
> happened. Not so! `P(A|B)` doesn’t specify the time ordering of A and B. It
> specifies the order in which YOU learn about them happening. So P(A|B) is the
> probability of A given you know what happened with B.

This makes sense from the information theoretic perspective; I'd never meditated
on this difference, though.

I'd seen things like:

> `P(sunrise | rooster-crow) = large` even though rooster crowing does not *cause*
> the sunrise to happen.

but I'd never seen/actively contemplated an example of `P(A|B)` where they
are temporally reversed/ambiguous.

# Hook length formula

Truly remarkable formula that tells us the number of standard young tableaux
for a given partition $\lambda$ of $n$. Recall the definitions:
- A partition $\lambda$ of the number $n$.
- An assignment of numbers $\{1, 2, \dots n\}$ onto the diagram of the partition
  such that the assignment is (a) weakly increasing in the rows, and
  (b) strictly increasing in the columns. It is strictly increasing in the columns
  because gravity acts downwards.
- Formally, a partition is written as $\lambda \equiv [\lambda_1, \lambda_2, \dots, \lambda_m]$,
  where $\lambda_i \geq 0$ and $\sum_i \lambda_i = n$, and that they
  are weakly decreasing ($\lambda_1 \geq \lambda_2 \geq \dots$).
- Formally, to define the tableaux, we first define the diagram $dg(\lambda) \equiv \{ (i, j) : 1 \leq j \leq \lambda[i] \}$
  which are the "locations" of the cells when visualizing $\lambda$ as a Ferrers diagram.
- Finally, the actual assignment of the numbers to the tableaux is given by a bijection
  $asgn: dg(\lambda) \rightarrow [n]$ such that $f$ is weakly increasing in the rows
  and strictly increasing in the columns.


#### The formula
Now, we want to count the number of young tableaux (formally, the data $n, \lambda, asgn$)
for a given partition $\lambda$. The formula is:

$$
n!/\left(\prod_{\texttt{cell} \in \lambda} hooklen(\texttt{cell})\right)
$$

where $hooklen$ is the largest "hook shape":

```
* * *
*
*
...
```

at the cell $(i, j)$ that is in the partition $\lambda$.

#### The structure of hooks

say we have a hook shape


```
a b c d
e
f
```

And the numbers $\{1, 2, 3, 4, 5, 6\}$. How many ways can we assign the numbers
to the above hook shape such that its a legal young tableaux?

- First, see that $a = 1$ is a must. Proof by contradiction. Assume $1$
  is not placed at $a$. Whenever it is placed, it will be less than the number
  placed at $1$. But this is wrong, because a young tableaux must be weakly
  increasing in the rows and strictly increasing in the columns.
- Next, see that after placing $a = 1$, the other numbers can be placed "freely":
  If we take a subset of $\{2, 3, 4, 5, 6\}$ of the size of the leftover row,
  ie, $|b~c~d| = 3$, then there is only one way to place them such that they are
  in ascending order. Similarly, the leftover numbers go to the column where there
  is only one way to place them.
- Hence, after $a = 1$ is fixed, for every $5C3$ subset, we get a legal hook.
- In general, if we have $n=r+c+1$ nodes, with $r+1$ nodes in the row, and $c+1$
  nodes in the column (the top-left node is counted twice), then we have $\binom{r+c}{r}$
  number of legal hooks; Once we pick the lowest number for the top left node,
  every $r$-subset will give us a hook.

- This result matches the hook-length formula. According to the hook length
  formula, we need to fill in for each node the length of the hook, and divide
  the full product by $n!$. So for
  the hook:

```
a b c d
e
f
```

This becomes:

```
6 3 2 1
2
1
```

$$
6!/(6\times 3!\times 2!) = 5!/(3! 2!) = 5C3 = \binom{r+c}{r}
$$

where $r=3, c=2$.


#### Knuth's heuristic

- Consider the hook shape. The only constraint we have is that the top-left
  number ought to be the smallest. For the hook $H$ to be legal, if we distribute
  numbers into it uniformly at random, then there is a
  $1/(\texttt{hook-length}(H))$ probability that the hook will be legal.


- The tableaux will be legal iff **all the hooks in the tableaux are legal**


- Thus, the probability of getting a legal tableaux is:

$$
\begin{aligned}
&\texttt{num}(\lambda)/n! =  \prod_\{h \in \texttt{hook}(\lambda) 1/\texttt{hook-length}(h) \\
&\texttt{num}(\lambda) =  n!/\prod_\{h \in \texttt{hook}(\lambda)\texttt{hook-length}(h) \\
\end{aligned}
$$


#### The relationship to representation theory

The RSK correspondence gives us a bijection between the permutation group $S_n$
and pairs of standard young tableaux:

$$
RSK \equiv \bigcup_{\lambda \in \texttt{partition}(n)} SYT(\lambda) \times SYT(\lambda)
$$

given by the pair of insertion tableaux and the recording tableaux for each partition
$\lambda$ of $n$.

If we look at this in terms of set sizes, then it tells us that:

$$
\begin{aligned}
&|S_n| = |\bigcup_{\lambda \in \texttt{partition}(n)} SYT(\lambda) \times SYT(\lambda) \\
&n! = \sum_{\lambda \in \texttt{partition}(n)} |SYT(\lambda)|^2 \\
&n! = \sum_{\lambda \in \texttt{partition}(n)} |\texttt{hook-length-formula}(\lambda)|^2 \\
\end{aligned}
$$

This looks very suspicious, almost like the representation theoretic formula of:

$$
\texttt{group-size} = \sum_{\texttt{irrep} \in Repr(G)} dim(\texttt{irrep})^2
$$

and it is indeed true that $\texttt{hook-length-formula}(\lambda)$ corresponds
to the dimension of an irreducible representation of $S_n$, and each $\lambda$
corresponds to an irrep of $S_n$.



# The tyranny of light

> More information may
> lead to less understanding; more information may undermine trust; and more
> information may make society less rationally governable.

# Muirhead's inequality

We denote by $\sum_! F(x[1], \dots, x[n])$ the sum ov $F$ evaluated over all
permutations. Formally:

$$
\sum_! F(x[1], \dots, x[n]) \equiv \sum_{\sigma \in S_n} F(x[\sigma[1]], \dots, x[\sigma[n]])
$$


We write

$$
[a[1], \dots a[n]] \equiv 1/n! \sum_! x_1^{a[1]} \dots x[n]^{a[n]} = \sum_{\sigma \in S_n} \prod_{j} x[\sigma[j]]^{a[j]}
$$

For example,we have:
- $[1, 1] = 1/2! (xy + yx) = xy$
- $[1, 1, 1] = xyz$
- $[2, 1, 0] = 1/3! (x^2y + x^2z + y^2z + y^2x + z^2x + z^2 y)$
- $[1, 0, 0] = 1/3! (x^{[1, 0, 0']} + x^{[1, 0', 0]} + x^{[0, 1, 0']} + x^{[0', 1, 0]} + x^{[0, 0', 1]} + x^{[0', 0, 1]})$.
  This is equal to $2!(x + y + z)/3! = (x + y + z)/3$.
- In general, $[1, 0, 0, 0, \dots, 0]$ ($n$ zeroes) is $(n-1)!/n!(\sum_i x_i)$ which is the AM.
- Also, $[1/2, 1/2] = 1/2!(x^{1/2}y^{1/2} + y^{1/2}x^{1/2}) = \sqrt{xy}$.
- In general, $[1/n, 1/n, \dots, 1/n]$ is the GM $\sqrt{n}{x[1] x[2] \dots x[n]}$.

#### Majorization

Let $(a), (b) \in \mathbb R^n$ be two non-decreasing sequences: $a[1] \geq a[2] \dots \geq a[n]$,
and $b[1] \geq b[2] \dots \geq b[n]$.  We will say that $(b)$ is majorized by
$(a)$  (written as $(b) \prec (a)$) when we have that:

1. $a[1] \geq a[2] \geq \dots a[n]$, $b[1] \geq b[2] \geq \dots b[n]$.
2. $\sum_i b[i] = \sum_i a[i]$.
3. $\sum_{i=1}^u b[i] \leq \sum_{i=1}^u a[i]$ for $1 \leq i \leq n$.

It is clear that this is a partial order. The below figure shows majorization
in terms of partitions. For two sequences $f, g$, define $F$ to be their "integral"
(partial sums) and $f', g'$ to be their "derivatives" (finite differences).
Then the condition that $f \prec g$ states that $F$ is upper bounded by $G$,
and that $F, G$ are concave functions.

<img src='./static/majorization-partitions.png'>


The other lens of viewing majorization is to think of a number as some sort
of fixed length $l$, and we are allowed to make some progress to reach the goal
($f(x) > 0$) as long as we progress less at each each timestep ($f''(x) < 0$).
In this viewpoint, the majorization condition asserts that $f \prec g$ is that
$g$ will always be ahead of/not fall behind $f$.


<img src='./static/majorization-fixed-length.png'>

#### Majorization and step

We can show that if $(b) \prec (a)$ , then we can get from $(b)$ to $(a)$
in a finite number of discrete steps, that "borrow" from higherlocations in $b$
and "give" to lower locations. Formally, define a step operator $S(l, r)$ where
$l < r$ such that:

$$
S(l, r)(b)[k] =
\begin{cases}
 b[l]+1 & k = l \\
 b[r]-1 & k = r \\
 b[k] & \texttt{otherwise}
\end{cases}
$$

That is, this borrows a single value from $b[j]$ and gives it to $b[i]$. We can see
that $(b) \prec S(l, r)(b)$.

For a given $(b) \prec (a)$, we can find a sequence of step operations
$S(l[i], r[i])$ such that we transform $(b)$ into $(a)$; That is, it is possible
to "single-step" the translation from $(b)$ to $(a)$.

#### Muirhead's theorem statement

for non negative numbers $x[]$, we have:

$$[b] \leq [a] \iff (b) \prec (a)$$

Expanding it out, this means that:

$$
1/n! \sum_! x^{[b]} \leq 1/n! \sum_! x^{[a]} \iff (b) \prec (a) \\
\sum_! x^{[b]} \leq \sum_! x^{[a]} \iff (b) \prec (a) \\
$$



# Rearrangement inequality

If $a[i]$ is a non-decreasing sequence: $a[1] \leq a[2] \leq \dots a[n]$, and
similarly $b[i]$ is a non-decreasing sequence: $b[1] \leq b[2] \leq b[n]$ then
we have that:

$$
\sum_i a[i] b[i] \geq \sum_i a[\sigma[i] b[i]
$$

for any permutation $\sigma \in S_n$.

> insight: the greedy strategy is the best. Think of $b[n]$ as the max. number of times
> we are allowed to pick some $a[i]$.
> It is best to be greedy and pick the value $\max_i a[i]$  $b[n]$ number of times.
> $\max_i a[i] = a[n]$. Thus having $a[n]b[n]$ will beat all others.

#### Proof

The proof strategy is to: show what happens for a transposition. Every
permutation can be broken down into transpositions and thus we are done.

Let $S = \sum_i a[i] b[i]$. Let $T$ be $S$ with us picking the value $a[r]$ $b[s]$ times,
and picking the value $a[s]$ $b[r]$ times. This gives

$$
T = \sum_{i \neq r, s} a[i] b[i] + a[r]b[s] + a[s]b[r]
$$


Since we wish to show $S > T$, let's consider $S - T$:

$$
\begin{aligned}
&S - T = \sum_i a[i]b[i] - (\sum_{i \neq r, s} a[i]b[i] + a[r]b[s] + a[s]b[r]) \\
&=\sum_{i \neq r, s} a[i]b[i] + a[r]b[r] + a[s]b[s]  - (\sum_{i \neq r, s} a[i]b[i] + a[r]b[s] + a[s]b[r]) \\
&= a[r]b[r] + a[s]b[s] - a[r]b[s] - a[s]b[r] \\
&= a[r](b[r] - b[s]) + a[s](b[s] - b[r]) \\
&= a[r](b[r] - b[s]) - a[s](b[r] - b[s]) \\
&= (a[r] - a[s])(b[r] - b[s])
\end{aligned}
$$

Since $r < s$ we have $b[r] \leq b[s]$, hence $b[r] \leq b[s] < 0$. For the product
to be greater than zero, we need $a[r] \leq a[s]$, or $a[s] \geq a[r]$ when $s > r$.

Hence, for a transposition, we are done. Thus we are immediately done
for any permutation:

#### Application: AM-GM

Say we wish to show $(p + q)/2 \geq \sqrt{pq}$. Let WLOG $p \leq q$.
Pick the sequences:

$$
a = [p, q]; a' = [q, p]; b = [p, q]
$$

Then the rearrangement inequality gives us:

$$
\begin{aligned}
&a[1]b[1] + a[2]b[2] \geq a'[1]b[1] + a'[2]b[2] \\
&p^2 + q^2 \geq qp + pq \\
&(p^2 + q^2)/2 \geq pq
\end{aligned}
$$

Pick $p = \sqrt{r}, q = \sqrt{s}$ to arrive at:

$$
(r + s)/2 \geq \sqrt{rs}
$$

and thus we are done.

#### References
- Inequalities: a mathematical olympiad approach

# Triangle inequality

We can write this as:

```
   *A
 b/ |
C*  |
 a\ | c
   *B
```

The classical version one learns in school:
$$
c \leq a + b
$$

The lower bound version:

$$
|a - b| \leq c
$$

This is intuitive because the large value for $a - b$ is attained when $b = 0$.
(since lengths are non-negative, we have $b \geq 0$. if $b = 0$, then the point $A = C$
and thus $a = CB = AB = c$.

```
A/C (b=0)
|
| a=c
|
B
```

Otherwise, $b$ will have some length that will cover $a$ (at worst), or cancel $a$ (at best).
The two cases are something like:

```
 A
 ||b
 ||
c|*C
 ||a
 ||
 ||
 B
```

In this case, it's clear that $a - b < c$ (since $a < c$) and
$a + b = c$. In the other case, we will have:

```
 C
b||
 ||
 A|
 ||
 ||a
c||
 ||
 ||
 ||
 B
```

Where we get $a - b = c$, and $c < a + b$. These are the extremes when the triangle has
zero thickness. In general, because the points are spread out, when we
project everything on the $AB=c$ line, we will get less-than(`<=`)
instead of equals (`=`).

# The Heather subculture
- And finally, [the sweater's perspective](https://www.youtube.com/watch?v=c_PT91SqVX8)

# Frobenius Kernel

#### Some facts about conjugates of a subgroup

Let $H$ be a subgroup of $G$. Define $H_g \equiv \{ g h g^{-1} : h \in H \}$.

- We will always have $e \in H_g$ since $geg^{-1} = e \in H_g$.
- Pick $k_1 k_2 \in H_g$. This gives us $k_i = gh_ig^{-1}$. So,
  $k_1 k_2 = g h_1 g^{-1} g h_2 g^{-1} = g (h_1 h_2) g^{-1} \in H_g$.
- Thus, the conjugates of a subgroup is going to be another subgroup
  that has nontrivial intersection with the original subgroup.
- For inverse, send $k = ghg^{-1}$ to $k^{-1} = g h^{-1} g^{-1}$.


#### Frobenius groups



# Galois theory by "Abel's theorem in problems and solutions"

I found the ideas in the book fascinating. The rough idea was:

- Show that the $n$th root operation allows for some "winding behaviour"
  on the complex plane.
- This winding behaviour of the $n$th root is controlled by $S_n$, since we are
  controlling how the different sheets of the riemann surface can be permuted.
- Show that by taking an $n$th root, we are only creating solvable groups.
- Show tha $S_5$ is not solvable.



# Galois theory perspective of the quadratic equation

I found this quite delightful the first time I saw it, so I wanted to record
it ever since.

Let $x^2 + bx + c$ be a quadratic. Now to apply galois theory, we first
equate it to the roots:

$$
\begin{aligned}
&x^2 + bx + c = (x - p)(x-q)
&x^2 + bx + c = x^2 - x(p + q) + pq
&-(p + q) = b; pq = c
\end{aligned}
$$

We want to extract the values of $b$ and $c$ from this. To do so, consider
the symmetric functions:

$$
(p + q)^2 = b^2
(p - q)^2 = (p + q)^2 - 4pq = b^2 - 4c
$$

Hence we get that

$$
p - q = \pm\sqrt{b^2 - 4c}
$$

From this, we can solve for $p, q$, giving us:

$$
p = ((p + q) + (p - q))/2 = (-b \pm \sqrt{b^2 - 4c})/2
$$

#### Galois theory for cubics
#### Galois theory for bi-quadratics
#### Galois theory for quintics

#### References
- [Abel and the insolubility of the quintic](http://www.math.caltech.edu/~jimlb/abel.pdf)

# Burnside lemma by representation theory.

Recall that burnside asks us to show that given a group $G$
acting on a set $S$, we have that the average
of the local fixed points $1/|G|(\sum_{g \in G} |\texttt{Fix}(g)|)$ is
equal to the number of orbits (global fixed points) of $S$, $|S/G|$.

Let us write elements of $g$ as acting on the vector space $V_S$, which is
a complex vector space spanned by basis vector $\{ v_s : s \in S \}$. Let
this representation of $G$ be called $\rho$.

Now see that the right hand side is equal to

$$
\begin{aligned}
&1/|G| (\sum_g \in G Tr(\rho(g))) \\
&= 1/|G| (\sum_g \in G \chi_\rho(g) ) \\
&\chi \rho \cdot \chi_1
\end{aligned}
$$

Where we have:
- $\chi_1$ is the charcter of the trivial representation $g \mapsto 1$
- The inner product $\langle \cdot , \cdot \rangle$ is the $G$-average inner
   product over $G$-functions $G \rightarrow \mathbb C$:

$$
\langle f , f' \rangle \equiv \sum_{g \in G} f(g) \overline{f'(g)}
$$

So, we need to show that the number of orbits $|S/G|$ is equal to the
multiplicity of the trivial representation $1$ in the  current representation
$\rho$, given by the inner product of their characters $\chi_1 \cdot \chi_\rho$.



let $s* in S$ whose orbit we wish to inspect. Build
the subspace spanned by the vector $v[s*] \equiv \sum_{g \in G} \rho(g) v[s]$.
This is invariant under $G$ and is 1-dimensional. Hence, it corresponds
to a 1D subrepresentation for all the elements in the orbit of $s*$.
(TODO: why is it the **trivial** representation?)


# Contributing to SAGEmath


#### Development

- The first time, run `make build`. DO NOT RUN `make`, as this performs a `make doc`
  as well which burns cycles building docs for no reason.
- Normally, if you just change Python code in the library, it suffices to run `./sage -br`
  to update Python.
- Only if you changed docs, and want to test that they still work,
  you'd need to run `make`, or `make doc-html`
- To run doctests, can run `./sage -t <filepath>`. [More info on the sage doctesting page](https://doc.sagemath.org/html/en/developer/doctesting.html)
- `make build && ./sage -n=jupyter ./test-ddg-notebook.ipynb` is reasonably fast.

- [SAGE developer index](https://doc.sagemath.org/html/en/developer/index.html)
- [Baby's first Trac ticket: #31248 --- Make tableaux error messages more precise](https://trac.sagemath.org/ticket/31248#comment:1)

#### Git the hard way for SAGE

- [Git the hard way](https://doc.sagemath.org/html/en/developer/manual_git.html)

git with SAGE uses different URLs for fetch and push.

```
[user@localhost sage]$ git remote add trac git://trac.sagemath.org/sage.git -t master
[user@localhost sage]$ git remote set-url --push trac git@trac.sagemath.org:sage.git
trac        git://trac.sagemath.org/sage.git (fetch)
trac        git@trac.sagemath.org:sage.git (push)
```

- I use my github account to develop for SAGE.
- [Linking your SSH key with sage-trac](https://doc.sagemath.org/html/en/developer/trac.html#linking-your-public-key-to-your-trac-account)

#### Getting the commit merged

The release manager (Volker Braun) takes care of it.
A number of people can close tickets for invalidity/duplicate etc,
but the actual merging is done by one person only (and a number of
bots/scripts that help).

A positively reviewed ticket with green bots and all fields filled in will
usually be merged in a week or two or rejected (merge conflict, issues
with specific architectures, failing bots). But it might take longer (too
many positively review tickets waiting, end of release cycle).


#### Tending to the garden

- Fix typos
- Fix `pep8`, `pyflakes`, lint warnings. Try to simplify code that's
  marked very compliated by `radon`.
- Fix code that's marked by [lgtm](https://lgtm.com/query)

# Shadow puppet analogy for entanglement

I found [this answer on quantumcomputing.stackexchange](https://quantumcomputing.stackexchange.com/a/15525/14471)
to be a visceral example of "something like entanglement":

Imagine making shadow puppets. However in this setup, instead of one you have
two screens and two torches  pointing 90 degrees apart so
that the image formed by torch 1 is projected onto screen 2 and the image
formed by torch 2 is simultaneously projected onto screen 1.

```
 screen 1       screen 2
   /               \
  /                 \
 /                   \
          mm              <-  hand
      \         /
   torch 1   torch 2
```

Now any movement of your hand changes both images in a correlated way. In a
sense, the images are entangled - if you observe image 1 to have a certain
configuration, then only a small subset of possibilities in the total
configuration space of image 2 are valid, and vice versa.



# Books for contest math

A personal list of books I wish to study this year, to get better at
"problem solving". This is ranked in order of difficulty
I wish to spend this year learning nuts and bolts type things.

- Inequalities: an olympid approach --- Nice book, has an axiomatic/algebraic bent.
- Mathematical circles: Russian experience
- The art and craft of problem solving
- Basics of Olympiad Inequalities: Samin Riasat --- quickly covers the big 12.
- [Evan chen: A Brief Introduction to Olympiad Inequalities ](https://web.evanchen.cc/handouts/Ineq/en.pdf)
- Pham Kim Hung: Secrets in Inequalities
- Edwin Beckenback: Introduction to Inequalities
- Nicholas D. Kazarinoff : Geometric inequalities
- Introduction to Functional Equations: Theory and problem-solving strategies for mathematical competitions and beyond
- [Combinatorics: Introduction to counting and probability](https://artofproblemsolving.com/store/item/intro-counting)
- [Combinatorics: Intermediate counting and probability](https://artofproblemsolving.com/store/item/intermediate-counting?gtmlist=Bookstore_AoPS_Side)
- Algebra: 101 Problems in Algebra by Titu Andreescu
- Number Theory Structures, Examples and Problems
- Combinatorics: 102 Combinatorial problems
- Combinatorics: Pablo Soberon’s Problem Solving Methods in Combinatorics
- Geometry: [Yufi Zhao: handouts](https://yufeizhao.com/olympiad/)
- Geometry: Trig bashing / Barycentric bashing (evan cheng)
- Problem-solving Strategies In Mathematics: From Common Approaches To Exemplary Strategies
- Problems from the Book
- Straight From the Book
- [AoPS list of past problems](https://artofproblemsolving.com/community/c13_contests)
- [AoPS list of books](https://artofproblemsolving.com/wiki/index.php?title=Math_books)
- [Mathematical problem solving: MIT course](https://yufeizhao.com/a34/)

# Analysing simple games

I found the clear articulation of these ideas quite nice.

1. In a game with symmetry, a symmetric move can be blocked or prevented **only**
   by the previous move an opponent has **just made**.
2. The symmetry in many games can be written as some kind of equality, where
   at each turn, one first player breaks the symmetry, and the other player
   (who has the winning strategy) restores it.

#### Example game

Consider a game where two players take turns placing bishops on a chessboard,
so that the pieces cannot capture each other. The player who cannot win
loses.

#### Winning strategy

place the bishop symmetrically about the line passing between the fourth and
fifth column (file). Note that the only way this bishop could be blocked is
if the move just made by the other player can block it.



#### References
- [Mathematical circles: Russian experience](https://bookstore.ams.org/mawrld-7)

# Linear algebraic proof of the handshaking lemma

We wish to show that the number odd vertices is even. Let $A$ be the adjacency
matrix of the undirected graph $G$. Since $G$ is undirected, $A = A^T$. Now
move everything to $F_2$, including $A$. This means that $A$ has entries $\{0, 1\}$.
Now, denote the vector of all ones by $o \equiv (1, 1, \dots 1)$. See that
$Ao$ counts the partities of the degrees of each vertex, and $o^T(Ao)$ counts the
sum of parities of the degrees of each vertex.


Note that the vertices of even degree with add $0$ to the sum $o^TAo$, while
odd vertices will add a $1$. Thus, $o^TAo$ will equal the parity of
the number of odd vertices. As we wish to show that the number of odd vertices
is even, we want to prove that $o^TAo = 0$.


We will now algebraically simplify $o^TAo$ (does anyone have a cleaner proof?)
giving us:


$$
\begin{aligned}
&o^TAo = \sum_{ij} o_i A_{ij} o_j \\
&= \sum_{i=j} o_i A_{ij} o_j + \sum_{i < j} o_i A_{ij} o_j + o_j A_{ji} o_i \\
&\text{($A$ is symmetric; $A_{ji} = A_{ij}$)} \\
&= \sum_{i=j} o_i A_{ij} o_j + \sum_{i < j} o_i A_{ij} o_j + o_j A_{ij} o_i \\
&= \sum_{i=j} o_i A_{ij} o_j + \sum_{i < j} 2 \cdot o_i A_{ij} o_j  \\
&\text{($F_2$ has characteristic zero, so $2 = 0$)} \\
&= \sum_{i=j} o_i A_{ij} o_j + 0 \\
&\text{(replace $i = j$ with $k$)} \\
&= \sum_{k} o_k A_{kk} o_k  \\
&\text{($A_{kk} = 0$ since graph has no self loops)} \\
&= \sum_{k} 0 \cdot o_k^2  = 0
\end{aligned}
$$

So, the number of vertices of odd degree is even.


I want to avoid this computation with respect to the basis, but I'm not
sure how to do that.

#### A simplification from arjun

Since $A_{kk} = 0$, we have that $A = B + B^T$ for $B$ lower triangular.
This allows us to simplify:

$$
\begin{aligned}
& o^T A o = o^T (B + B^T) o = \\
& =o^T B o + o^T B^T o = \langle o, Bo \rangle + \langle Bo, o \rangle \\
& = 2 \cdot \langle o, Bo \rangle = 0
\end{aligned}
$$




# Historical contemporaries

I continue to be delighted at how connected arbitrary parts of history are.
Here's a list of contemporaries I would not have guessed:

- Rembrandt sketched Shah jahan
- Greek ambassador in the Ashoka court
- "Bhaeatha's kingdom" for Bharat as known by the Chinese
- Aurangzeb had rockets when fighting his brother
- Aurangzeb had a French physician (Francois bernier)
- Picasso was against the Korean war (1950) and painted about it.

# Rota's twelvefold way

- Count functions from $I \rightarrow O$.
- See that any such function is a subset of $O^I$.
- We can write such a function as $(o_1, o_2, \dots, o_{|I|}) \in O^I$
- if we have $S_I \circ f$, this means that we can permute images.
- If we have $f \circ S_O$, this means that we can permute fibers.

#### f any function

- we count $O^I$

#### f injective

- We count $O^{(I)} = O(O-1)\dots(O-I+1)$ as given by the falling factorial.

#### f surjective, with equivalence $S_I \circ f$.

- For each element $o \in O$, pick some subset $I_o \subseteq I$. We need the
  subsets $I_o$ to be disjoint, and all $I_o$ to be non-empty.
- We can permute the fibers $I_o$, so we can place them by weakly decreasing order of size.
- Then this is the same as counting partitions of $I$ into $O$ subsets, given by
  $S(n, x)$/${n\brace m}$ (stirling numbers of the second kind).


#### f surjective

- For each element $o \in O$, pick some subset $I_o \subseteq I$. We need the subsets $I_o$ to be disjoint,
  and all $I_o$ to be non-empty.
- We get partway there by counting **compositions** of $I$: the number of ways to
  split $|I|$ into $(a_1, a_2, \dots, a_k)$ such that each $(a_i > 0)$ and $\sum_i a_i = |I|$.
  Note that ordering matters here, since we write a **tuple** $(a_1, a_2, \dots a_k)$.
- For example, the compositions of $3$ are $(1, 1, 1)$, $(1, 2)$ and $(2, 1)$.
  See that we have both $(1, 2)$ and $(2, 1)$.
- Contrast this with partitions, which I write in weakly decreasing: $(1, 1, 1)$, $(2, 1)$.
- This can be counted by the stars and bars method:

```
1 _ 2 _ 3 _ 4 _ ... _  |I|
```

- We want to fill the $|I|-1$ blanks (`_`) with $k$ bars if we want a $k$-composition (remember that compositions
  can't have zeros). So we can count this by $\binom{|I|-1}{k}$.

#### f surjective, with equivalence $S_I \circ f \circ S_O$:






# Counting necklackes with unique elements

Count number of ways to form a necklace with $\{1, 2, \dots, n\}$

- Method 1: This is equivalent to counting $|S_5|$ modulo the subgroup generated by
  $(12\dots)$. That subgroup has size $5$. So the size is $S_5/5$.
- Method 2: A cycle is an equivalence class of elements $(a,b,c,d,e)$ along with
 all of its cyclic shifts ($(b,c,d,e,a)$, $(c,d,e,a,b)$, $(d,e,a,b,c)$, $(e,a,b,c,d)$).
  We are to count the number of equivalence classes. First pick a canonical element
  of each equivalence class of the form $(1, p, q, r, s)$.


# Decomposition of projective space

Projective space $\mathbb P^{n+1} = \mathbb P^n \cup \mathbb R^n$. The
current way I think about this is as follows (specialize to $n=3$)

- Consider a generic point $[x : y : z]$. Either $x = 0$ or $x \neq 0$.
- If $x = 0$, then we have $[0 : y : z]$ which can be rescaled freely:
  $[0: y: z] = (0, y, z, 1) = (0, \lambda y, \lambda z, \lambda) = [0: y: z]$.
  So, we get a component of $\mathbb P^2$ from the $[y: z]$.
- If $x \neq 1$, we have $[x : y : z]$. Spend the projectivity to get $(1:y:z) = (x, y, z, x)$.
  Now we have two free parameters, $(y, z) \in \mathbb{R^2}$. This gives us the $\mathbb R^2$.

There's something awkward about this whole thing, notationally speaking. Is there
a more natural way to show that we have spent the projectivity to renormalize
$[x: y: z]$ to $(1, y, z)$ ?


#### Projective plane in terms of incidence

We can _define_ $\mathbb P^2$ to be an object such that:
1. Any two lines are incident at a single point.
2. Two distinct points must be incident to a single line. (dual of (1))


#### The points at infinity
This will give us a copy of $\mathbb R^2$, along with "extra points" for parallel
lines.

- Consider two parallel lines $y = mx + 0$ and $y = mx + 1$. These don't traditionally
  meet, so let's create a point at infinty for them, called $P_m(0, 1)$.
- Now consider two more parallel lines, $y = mx + 0$ and $y = mx + 2$. These don't
  traditionally meet either, so let's create a point at infinite for them, called
  $P_m(0, 2)$.
- Finally, create another point $P_m(0, 3)$ as the point of intersection between
   $y = mx + 0$ and $y = mx + 3$.

- Now, consider $P_m(0, 1), P_m(0, 2), P_m(0, 3), dots$. We claim that they must all be equivalent.
  Assume not. Say that $P_m(0, 1) \neq P_m(0, 2)$.
- Then there must a line that joins $P_m(0, 1)$ an $P_m(0, 2)$. Call it $L_m(0, 1, 2)$.
  Now, what is the intersection between $L_m(0, 1, 2)$ and the line $y = mx + 0$?
  The points $P_m(0, 1)$ and $P_m(0, 2)$ *both* lie on the line $L_m(0, 1, 2)$.
  But this is a contradiction: two lines must be incident at a single unique point.
- So we must have $P_m(0, 1) = P_m(0, 2) = P_m$. So, for each direction, we must
  have a unique point where all lines in that direction meet.

We can make a definition: the **point at infinity for a given direction** is the
equivalence class of all lines in that direction.

<img src='./static/projective-plane-incidence-points.png'/>

#### The line at infinity

This now begs the question: what lines to different points at infinity lie on?
Let's consider $P_q, P_r, P_s, P_t$ as four points at infinity for four different
slopes.

- Consider the lines $L(q, r)$ that is incident on $P_q$ and $P_r$, and then
  the line $L(s, t)$ that is incident on the lines $P_s$ and $P_t$.
- This begs the question: where do these lines meet? If we say that the meet at _more new_
  points of intersection, like $P(q, r, s, t)$ this process will never end.
- So we demand that _all points at infinity_ lie on a _unique_ line at infinity.



# Childhood: Playing pokemon gold in japanese

I just recalled this very off memory of how back when I was a kid, somehow the
only version of pokemon (gold) that was circulating amongst folks was the one
in _japanese_. So we freaking played gold in _japanese_. I can't believe I got
through so many levels with no clue of what in the actual fuck I was doing. I
remember being stuck at the point where you need to use cut to cross a barrier
or something, and figuring it out by accident.

Pretty sure I got blocked someplace because I lost the surf HM.

This memory just resurfaced, and I spent a solid five minutes thinking about
just how _insane_ the whole thing is. A kid's determination to play a game
knows no bounds, indeed.

# Tensor is a thing that transforms like a tensor

There are two ways of using linear maps in the context of physics. One is
as a thing that acts on the _space_. The other is a thing that acts on the
_coordinates_.

So when we talk about transformations in tensor analysis, we're talking
about _coordinate transformatios_, not _space transformations_.

Suppose I implement a double ended queue using two pointers:

```
struct Queue {int *memory, *start, *end; }
void queue_init(int size) {
  memory = malloc(sizeof(int) * size);
  start = end = memory + (size - 1) / 2;
}
void queue_push_start(int x) { *start = x; start--; }
void queue_push_end(int x) { end++; *end = x; }
int queue_head() { return *start; }
int queue_tail() { return *end; }
void queue_deque_head() { start++; }
void queue_deque_tail() { tail--; }
```

See that the state of the queue is technically three numbers, `{ memory, start, end }` (Pointers are just numbers after all). But this is *coordinate dependent*, as `start` and `end` are relative to the location of `memory`. Now suppose I have a procedure to reallocate the queue size:

```
void queue_realloc(Queue *q, int new_size) {
   int start_offset = q->memory - q->start; 
   int end_offset = q->memory - q->end;
   int *oldmem = q->memory;
   q->memory = realloc(q->memory, new_size);
   memcpy(q->memory, oldmem + q->start, sizeof(int) * (end_offset - start_offset);
   q->start = q->memory + start_offset;
   q->end = q->memory - end_offset;
}
```
Notice that when I do this, the values of `start` and `end` can be completely different!

However, see that the *length* of the queue, given by `(end - start)` is *invariant*: It hasn't changed!

----

In the exact same way, a "tensor" is a collection of numbers that describes something physical with respect to a particular coordinate system (the pointers `start` and `end` with respect to the `memory` coordinate system). "tensor calculus" is a bunch of rules that tell you how the numbers change when one changes coordinate systems (ie, how the pointers `start` and `end` change when the pointer `memory` changes). Some quantities that are computed from tensors are "physical", like the length of the queue, as they are *invariant* under transformations. 

Tensor calculus gives a principled way to make sure that the final answers we calculate are "invariant" / "physical" / "real". The actual locations of `start` and `end` don't matter, as `(end - start)` will always be the length of the list!

----

Physicists (and people who write memory allocators) need such elaborate tracking, to keep track of what is "real" and what is "coordinate dependent", since a lot of physics involves [crazy coordinate systems](https://en.wikipedia.org/wiki/Schwarzschild_metric#History), and having ways to know what things are real and what are artefacts of one's coordinate system is invaluable. For a real example, consider the case of singularities of the Schwarzschild  solution to GR, where we initially thought there were two singularities, but it later turned out there was only one "real" singularity, and the other singularity was due to a poor choice of coordinate system:

> Although there was general consensus that the singularity at r = 0 was a 'genuine' physical singularity, the nature of
> the singularity at r = rs remained unclear. 
> In 1921 Paul Painlevé and in 1922 Allvar Gullstrand independently produced a metric, a spherically symmetric solution of Einstein's equations, which we now know is coordinate transformation of the Schwarzschild metric, Gullstrand–Painlevé coordinates, in which there was no singularity at r = rs. They, however, did not recognize that their solutions were just coordinate transform

# Tensor Hom adjunction

- `(- X A)` witnesses `A` as an output, while `Hom(A, -)` witness A as input.
- Similarly, we know that we can contract `A` with `A*` so it makes sense that the
  "dual" of multiplying by `A` (ie, how to divide out `A`) is to invert it by
  allowing a contraction with `A*`.


# Schur's lemma

#### Statement

if $r_v : G \rightarrow GL(V), r_w: G \rightarrow GL(W)$ are two irreducible
representations of the group $G$, and $f: V \rightarrow W$ is an equivariant map
(that is, $f\forall g \in G, \forall v \in V, (r_v(g)(v)) = r_w(g)(f(v))$),
then we have that either $f = 0$ or $f$ is an isomorphism.

- Said differently, this implies that either $r_v$ and $r_w$ are equivalent, and $f$
  witnesses this isomorphism, or $V$ and $W$ are not isomorphic and $f$ is the zero map.

#### Proof

- First, note that $ker(f)$ and $im(f)$ are invariant subspaces of $G$.
- Let $k \in ker(f)$. hence:

$$
\begin{aligned}
&r_w(g)(f(k)) = 0 \\
&f(r_v(g)(k) =  r_w(g)(f(k)) = 0 \\
&r_v(g)(k) \in ker(f) \\
\end{aligned}
$$
So if $k \in ker(f)$ then so does $r_v(g)(k)$ for all $g$. Hence, the kernel
is an invariant subspace.

- Next, let $w \in im(f)$, such that $w = f(v)$ hence:

$$
\begin{aligned}
&f(v) = w \\
&r_w(g)(w) = r_w(g)(f(v)) = f(r_v(g)(v)) \\
&r_w(g)(w) \in im(f) \\
\end{aligned}
$$

So if $w \in im(f)$ then $r_w(g)(w) \in im(f)$ for all $g$. Hence, image
is an invariant subspace.


- Since $V$ is irreducible, we must have that either $ker(f) = 0$ or $ker(f) = V$.
  If this were not the case, then we could write $V = ker(f) \oplus ker(f)^\perp$
  non-trivially. This contradicts the irreducible nature of $V$. Thus, either $f$
  sends all of $V$ to $0$ (ie, $f$ is the zero map), or $f$ has trivial kernel
  (ie, $f$ is injective).
- Since $W$ is irreducible, we must have that either $im(f) = 0$ or $im(f) = W$
  by the exact same argument; $im(f)$ is an invariant subspace, and $W$ is
  irreducible thus has non non-trivial invariant subspaces. Thus either $im(f) = 0$
  ($f$ is the zero map), or $im(f) = W$ ($f$ is surjective).
- Thus, either $f$ is the zero map, or $f$ is both injective and surjective; that is,
  it is bijective.
- The real star of the show is that (1) we choose irreducible representations,
  and (2) kernel and image are invariant subspaces for the chosen representations,
  thus we are forced to get trivial/full kernel/image.


#### Strengthing the theorem: what is $f$?

We can additionally show that if $f$ is not the zero map, then $f$ is
constant times the identity. That is, there exists a $\lambda$ such that $f = \lambda I$.

- $f$ cannot have two eigenvalues. If it did, the eigenspaces of $\lambda_1$ and
  $lambda_2$ would be different subspaces that are stabilized by $f$. This can't
  happen because $V$ is irreducible. So, $f$ has a single eigenvalue $\lambda$.
- Thus, if $f$ has full spectrum, it's going to be $f = \lambda I$.
- $f$ has full spectrum since we tacitly assume the underlying field is $\mathbb C$
  and $f$ has full rank.



# Daughters of destiny

Captures the microcosm of what it means to live in India.

- [Shanti Bhavan](https://www.shantibhavanchildren.org/)

# Stuff I learnt in 2020

- MLIR
- unification
- GRIN
- demand analysis
- tabled typeclass resolution
- ZX
- pwn.college
- semantics of general relativity
- mathemagic
- oripa and FOLD
- tensegrity
- uncivilization
- CSES
- USACO
- rete
- number theory / amalgam
- sampleraytracer
- bijective combinatorics
- [Why do people stay poor?](https://news.ycombinator.com/item?id=25568800)
- Talk: p-adics
- Talk: smallpt-hs


# Line bundles, a high level view as I understand them today

- What is a line bundle?
- What does it mean to tensor two line bundles?
- Why are line bundles invertible?
- Can we draw pictures?

#### Why are bundles invertible?

Because locally, they're locally modules. This leads us to


#### Why are modules invertible?

All modules are invertible when tensored with their dual.


To simplify further, let's move to linear algbera from ring theory; consider the field $\mathbb R$.
Over this, we have a vector space of dimension $1$, $\mathbb R$. Now, if we consider $\mathbb R \otimes \mathbb R^*$,
this is isomorphic to $\mathbb R$ since we can replace $(r, f) \mapsto f(r)$. This
amounts to the fact that we can contract tensors.

So, $\mathbb R \otimes \mathbb  R^* \simeq \mathbb R$. Generalize to bundles.

#### References

- [Fiber bundles at physics travel guide](https://physicstravelguide.com/advanced_tools/fiber_bundles#tab__concrete)

# Conversations with a wood carver

There's a wood carver who lives close to home, whose name is Harish.
I went to speak to him, asking if he would be willing to teach me woodcarving.
It was a very interesting converstaion.

- He argued that wood carving was his caste, and it was impossible for him
  to teach me this, since he learnt it "by practice from birth".
- He also mentioned that his skills were learnt by practice, and not through
  training and were thus un-teachable.
- He felt that it was impossible to pick up the skill anymore since I ddn't
  learn it as a kid.
- His feeling is that the art of wood carving is not respected, and it makes
  much more sense to go learn how to use a CNC .
- We spoke about how the traditional style of woodcarving provided more
  control, and led to better construction. He said that consumers don't care,
  and resent him for the extra time.
- He oft repeated how he was poor; He wakes up in the morning, takes care
  of his cows, then begins carving. He might stay up late if there's an urgent
  order.
- None of his children learnt woodcarving either. They seem to be learning
  things like commerce and graphic design. It seems likely that woodcarving
  will die with him.
- He also mentioned how he no longer carves for the local temples, who one would
  expect would be his largest customer base since he specializes in carving
  paraphranelia for idols. It turns out that temples only provide "blessings",
  and no payment.
- When carving beds for gods, one must arrange the bed to be along the natural
  direction of the tree. The feed of the god must be in the direction of the
  roots, and the head must be towards the sky. Otherwise, the god will not
  accept the tree.
- Towards this, there are many interesting principles of how to learn the
  direction of wood.
- For one, one can use knots in the wood to identify the
  direction of growth.  See the knot in the front and back of a block of wood.
  There will be a directionality to this knot. See that branches grow from low
  to high; So the knot indicates the direction of growth of the tree.
- For another, we can cut a think horizontal slice from the block of wood.
  In the two halves, the splinters will "point upwards" in the slice.

In general, this conversation left me quite dejected about the state of arts
in India. It seems like traditional carpentry in India is dead, and the
"replacements" are of terrible quality. I was also saddened that he so adamantly
believes that it is fundamentally impossible for people to learn carpentry.


# Discrete Riemann Roch

#### Divisors
Function $V \rightarrow \mathbb Z$. We think of this as formal linear combination
of vertices.


#### Degree of a divisor

$deg(D) \equiv \sum_{v \in V} D(v)$.

#### Borrowing and lending at a vertex $v_\star$

- Lending: $v$ gives 1 unit of money to all its neighbours

$$
f' = f + \sum_{vw \in E} -v + w
$$

- Borrowing: $v$ takes 1 unit of money from all its neighbours

$$
f' = f + \sum_{vw \in E} + v - w
$$

#### Borrowing and lending on a set $S$:

- Lending on a set $S$: every vertex $v \in S$ gives 1 unit of money to all its neighbours

$$
f' = f + \sum_{v \in S}\sum_{vw \in E} -v + w
$$

- Borrowing defined similarly.
- See that borrowing at a vertex $v$ is the same as lending from $V / v$.
  The reason being, the lending between vertices of $V/v$ will cancel, and only
  lends into $v$ will be counted. This is the same as $v$ borrowing.


#### Linear equvivalence

Two divisors $D_1, D_2$ are linearly equivalent iff there is a sequence of
borrowing or lending moves that leads from $D_1$ to $D_2$. This is an
equivalence relation on the space of divisors.  Equivalence class of $D_1$
is represented by $[D_1]$.

#### Partial ordering of divisors

We say that $D_1 < D_2$ if for all $v$, $D_1(v) < D_2(v)$.

#### Effective divisors

A divisor such that $\forall v, D(v) \geq  0$ is called as an effective divisor. Sometimes written
as $D \geq 0$.

Our goal is given a divisor $D$, to check if it is linearly equivalent to
a divisor $D'$ such that $D \geq 0$. If we can do so, then no one is in debt,
and we have won the game.


#### Addition of divisors

We add divisors pointwise: $(f + g)(v) \equiv f(v) + g(v)$.
This respects linear equivalence. Hence, $[D_1] + [D_2] \equiv [D_1 + D_2]$.
This makes divisors, and their equivalence classes an abelian group

#### The Picard Class Group (group of divisor classes)

The group of equivalence classes of divisors  under pointwise addition is
the picard group.

#### Jacobian Class group (divisor classes of degree 0).

- Subgroup of picard group of degree 0.
- That is, all equivalence class elements of degree 0.
- This is well defined because all linearly equivalent divisors (divisors that can be
  gotten by lending/borrowing) all have the same degree (total money). This is because
  lending/borrowing does not change the total amount of money in the market,
  only redistributes it.


#### Picard group decomposition in terms of Jacobian group

For each $q \in V$, there is an isomorphism of groups $\phi_q: Pic(G) \rightarrow \mathbb Z \times Jac(G)$,
where we send a divisor class $[D]$ to $\phi_q([D]) \equiv (deg(D), [D - deg(D)q]$.

- Clearly, the new divisor $[D - deg(D)q]$ has total degree $0$, since $deg(D)$
  has been subtracted off at $q$.
- We can recover the original divisor since we know $deg(D)$.



#### Complete linear system $[D]_{\geq 0}|$

The complete linear system of $D$ is the set of all winning configurations from $D$.
That is:

$$
[D]_{\geq 0} \equiv \{ E \in [D] : E \geq 0 \}
$$

We win the game if $[D]_{\geq 0}$ is nonempty.


#### The discrete laplacian

The laplacian is the map $L: (V \rightarrow \mathbb Z) \rightarrow (V \rightarrow \mathbb Z)$
defined by:

$$
L(f)(v) \equiv \sum_{vw \in E} (f(v) - f(w))
$$

That is, $L(f)(v)$ is the total **deviation** of $v$ from all of its neighbours $w$.

#### Firing script

A firing script is a function $s: V \rightarrow \mathbb Z$ ($s$ for script) that
tells us how many times $v$ lends money to its neighbours).


- The collection of all firing scripts form an abelian group, and is denoted
  by $M(G)$. [TODO: why $M$?]


- Set lending by a subset $W \subset V$ is denoted by $\chi_W$, where $\chi_W(v) \equiv 1$ if $v \in W$
 and $\chi_W(v) \equiv 0$ otherwise. Written in iverson notation, we have $\chi_W(v) \equiv [v \in_? W]$.


- The effect of running a firing script $s$ on a divisor $D$ to get a divisor $D'$ is:


$$
\begin{aligned}
D' \equiv D + \sum_{v \in V} s(v) (-v+ w) \\
\end{aligned}
$$


if $s: V \rightarrow \mathbb Z$ is a firing script, then the divisor of the
firing script $s$ is:

$$
div(s) \equiv  \sum_{v \in V} s(v) (-v+ w)
$$

- The effect of running a firing script is to replace a divisor $D$ by a new
  divisor $D' = D + div(s)$. We denote this by $D \xrightarrow{s} D'$ and call
  this as **script-firing**

#### `div` is a group homomorphism

We see that `div` is a function from $M(G) =  V \rightarrow \Z$ to  $Div(G) = V \rightarrow \Z$
under the map:

$$
div(s) \equiv  \sum_{v \in V} s(v) (-v+ w)
$$

We show that $div(s_1 - s_2) = div(s_1) - div(s_2)$ thereby checking the homomorphism
property.

$$
\begin{aligned}
&div(s_1 - s_2) =  \sum_{v \in V} (s_1 - s_2)(v) (-v+ w) \\
&= \sum_{v \in V} (s_1(v) - s_2(v)) (-v+ w)  \\
&= \sum_{v \in V} s_1(v) (-v+ w)  - \sum_{v \in V} s_2(v) (-v+ w)  \\
&= div(s_1) - div(s_2)
\end{aligned}
$$

and is hence a group homomorphism.


#### `div` produces divisors of degree 0: `deg(div(s)) = 0`.

See that $div$ is balanced, in that for every $-v$ we have a $+w$. This makes
the total degree zero.

#### Principal divisors: $Prin(G) \equiv div(M(G))$.

- Divisors of the form `div(s)` are called as **Principal divisors**. They are a
  subgroup of the degree 0 divisors.

- Moreover, if $D'$ is obtainable from $D$ by a series of lending and borrowing
  moves, then $D' - D \in Prin(G)$.
- This means that linear equivalence is a coset of the principal divisors: $[D] = D + Prin(G)$.

#### Picard, Jacobian Class group  as quotients

- $Pic(G) = Div(G)/Prin(G)$.
- $Jac(G) = Div^0(G)/Prin(G)$.
- $Pic(G), Jac(G)$ are class groups because we get equivalence classes of divisors,
  equivalent upto principal divisors.


#### `div` is same as laplacian

<img src='./static/discrete-riemann-roch/laplacian-lending.png'>

#### Picard group is cokernel of L

Recall that `Pic(G) = Div(G)/Prin(G)`, where `Prin(G)` was the collection of
divisors that could be realised from a firing script.  That is,

$$
Prin(G) \equiv \{ div(s) : s \in V \rightarrow \mathbb Z \}
$$

```
M(G) -div→ Div(G) -quotient→ Pic(G) → 0
|          |
f          g
|          |
v          v
Z^n  -L→   Z^n   -quotient'→ cok(L) ~= Z^n/Im L → 0
```

- The quotient map `quotient` is surjective.
- The map `quotient'` is also surjective

#### Dollar game in terms of laplacian

given a divisor $D$, does there exist a vector $x \in \mathbb Z^V$
such that $D + Lx \geq 0$?

Clearly, this is some sort of linear inequality. So, we expect polytopes
to show up! Since $x$ is an integer point, we want integer points in polytopes.

#### Kernel of laplacian in connected graph: all 1s vector

- first of all, see that lending by everyone in $V$ has no effect:
  everyone lends to all their neighbours, and all their neighbours lend to them,
  having zero net effect.

- Stated in terms of the firing script, this means that $s_1 + s_2 + \dots s_n$
  is in the kernel of $div$: the firing script creates a zero divisor. If we
  choose a basis, this is the all 1s vector.

- In terms of the laplacian, this is stating that the all ones vector is in
  the kernel of the laplacian.


#### Kernel of laplacian in connected graph: constant functions (TODO)

Suppose we have a script $s: V \rightarrow \mathbb Z$ such that $div(s) = 0$.

**TODO **


> This feels sheafy to me, in terms of "locally constant".


#### Reduced laplacian: Configurations on $G$

We build reduced laplacians to relate the jacobian (degree zero elements of divisor class group)
and the laplacian.

Fix a vertex $q \in V$. Define $\tilde{V} \equiv V /\{q\}$. A configuration
on $G$ with respect to $q$ is an element of the subgroup

$$
Config(G, q) \equiv \mathbb Z \tilde{V} \subseteq ZV = Div(G)
$$

so we simply forget the value at $q$. Alternatively, we set the value of $q$
to zero and continue will our divisor definitions.

We can perform lending and borrowing on a configuration divisor, by simply
not tracking data at $q$.

#### 3: Winning

#### q-reduced configurations

We wish to solve the game by benelovence: have vertices lend to adjacent vertices.
Here are the steps to convert such an intuition to a real algorithm:

1. Start with a divisor $D$ we want to find an effective divisor $E \geq 0$
   that $D$ is linearly equivalent to (ie, there exists a series of moves to convert $D$ to $E$).
2. Pick some benelovent vertex $q \in V$. Call $q$ the source. Let $V' = V/q$ be the non
   source vertices.
3. Let $q$ lend so much money to the non-source-vertices, such that the non-source-vertices,
   sharing amongst themselves, are out of debt.
4. Now only $q$ is in debt from this giving. $q$ makes no lending or borrowing moves.
   The non-source-vertices must get $q$ out of debt. Find a $S \subseteq V'$ such that if
   everyone in $S$ lends, then no one in $S$ go into debt. Make the corresponding set-lending
   move. Repeat until no such $S$ remains. The resulting divisor is said to be $q$-reduced.

In the end, if $q$ is no longer in debt, we win. Otherwise, $D$ is unwinnable.



#### Superstable configuration

Let $c \in Config(G, q)$. It is called superstable if $c \geq 0$ and has
no legal non-empty set firings. That is, for each non-empty $S \subseteq V/q$,
we have some $v \in S$ such that firing $v$ would cause $v$ to go into debt;
that is, $c(v) < outdeg_S(v)$.

#### Decomposition of divisor into superstable configuration

Every divisor can be written as $D = c + kq$ where $c \in Config(G, q) \geq 0$.
In this form, $D$ is $q$-reduced iff $c$ is superstable! This follows
from the definition of $q$-reduced: there is no subset $S$ which can be fired such
that $S$ stays out of debt. Now, if $q \geq 0$, then we win, from what we know
of $q$-reduced configurations.



#### 4: Acylic orientations
#### Orientations

An orientation of a graph makes each edge directed. We think of edges now as
tuples $e \equiv (u, v)$ as an edge from $u$ to $v$. We denote $e^- = u$ and
$e^+ = v$ to be the source and sink vertices of the orientation.


#### Acylic orientations

An orientation is acyclic if there are no cycles. Every acylic orientation
must have at least one sink and a source. It must have **at least one source**.
Assume the acyclic orientation does not have any sources.

#### Acylic orientation has at least one source

Pick any vertex . If it is a source, done. If it is not a source, it has a parent.
Go to parent that has NOT BEEN PICKED YET, repeat check. We will eventually:

- Find a source  vertex (vertex with no parent)
- All parents of current vertex have been picked  (ie, we find a cycle). Can't
  happen.

Thus all acyclic orientations have at least one source.


#### Indegree sequence of an acyclic orientation.

If $O$ is an orientation, define

$$
indeg_O(u) \equiv |\{ e \in O : e^+ = u \}|
$$

That is, to each $u$, associate the number of edges whose end is at $u$.

#### WRONG: Acylic orientation determined by indegree sequence?

The book claims that acyclic orientation is determined by the indegree sequence.
I don't believe this. Consider the graph $G$:

```
--a--
|   |
v   v
b   c
```

- This has indegrees  $(a=0, b=1,c=1)$.

Now consider $H$:

```
a
|
v
b
|
v
c
```

- This has indegrees  $(a=0, b=1, c=1)$ but the graphs are not equal!

#### Acylic orientation determined by indegree sequence

OK, the above is not what the book claims. The book claims that two orientations
$O_G$, $O'_G$ **of the same graph** are equal if their indegree sequences
are equal.

This is believeable, because if the orientations point differently, their
indegrees will change.

- Proof strategy: induction on number of vertices + forcing sources to be the same + creating new  sources
  by removing current sources.

- Theorem is immediate with only one vertex. Assume holds for $n$. Now we have
  a graph with $(n+1)$ vertices. Find source in acyclic orientation $O_G$. This has
  no incoming edges, so has indegree zero. This must be the same in $O'_G$ since
  $O_G$ and $O'_G$ have the same indegree sequence.

- Now remove the sources that are structurally equal. We get a graph of $H$ of
  (n-1) vertices, and we get $O_H$ and $O'_H$ by removing the sources
  from $O_G, O_G'$. Since $O_G = O_G'$ we must have that $O_H = O_H'$ since removing
  the same source from both graphs modifes the orientations the same way. Recurse
  into $O_H, O_H'$.

#### Divisor for an orientation

For an orientation $O$ we define a divisor $D(O)$ as:

$$
D(O) \equiv \sum_{v \in V}(indeg_O(v) - 1) v
$$

#### 5: Riemann roch

#### The rank function

In one sense, the “degree of winnability” of the dollar game is measured by the size
of complete linear systems: $D$ is “more winnable” than $D'$ if
$[D]_{\geq 0} > [D']_{\geq 0}$. Instead of measuring $[D]_{\geq 0}$, we choose to
define another function, the rank, that measures "stability/robustness of winnability"

- Fist, $r(D) \equiv -1$ if $D$ is unwinnable: $r(D) \equiv 0$ iff $[D]_{\geq 0} = \emptyset$
- Next, $r(D) = 1$ if $D$ is barely winnable.  That is, $D$ is winnable, but
  there is *some* vertex $v$ such that $D - v$ is unwinnable. That is, $r(D)$
  is barely winnable if the ability to win at $D$ can be destroyed by a single
  vertex losing a dollar.

- In general, for $k \geq 0$, define that $r$ is at least $k$ winnable if the dollar
  game is winnable strating from all divisors obtained from $D$ by removing $k$
  dollars. Formally, this becomes:

$$
r(D) \geq k \iff |D - E| \neq \emptyset \text{for all $E \geq 0$ ($E$ effective) of degree $k$}
$$

This means that $r(D) = l$ if there is some divisor $E$ of degree $l+1$ such that $D - E$ is
not winnable.

#### $r(D)$ is upper bounded by degree: $r(D) \leq deg(D)$
#### if $D$ is of degree 0, then rank is 0 iff $D$ is principal
#### $r(D) \leq r(D + v) \leq r(D) + 1$: adding a dollar can increase rank by at most 1
#### $r(D + D') \geq r(D) + r(D')$: rank is super-linear.
#### Lower bound on rank: $r(D) \geq deg(D) - g$

Won't prove this here, depends on other results (if $deg(D) \geq g$, then $D$ is winnable)




#### Canonical divisor

For any orientation $O$, define $O_{rev}$ to be the reversed orientation. Now
define the canonical divisor $K$ to be $K \equiv D(O) + D(O_{rev})$. See that
for every $v \in V$:

$$
\begin{aligned}
K(V) = indeg_O(v) + outdeg_O(v) = deg_G(v)
\end{aligned}
$$

#### References

- [This answer on mathoverflow that asks about how to understand divisors of elliptic curves](https://mathoverflow.net/a/322850/123769)
- [Specialization of linear systems from groups to graphs](https://arxiv.org/pdf/math/0701075.pdf)
- [riemann-roch and abel-jacobi theory on a finite graph](https://arxiv.org/pdf/math/0608360v3.pdf)
- [Divisors and Sandpiles: An Introduction to Chip-Firing](https://bookstore.ams.org/mbk-114/)


# Conversation with Olaf Klinke

> do you have reading you'd recommend to gain your viewpoint of
> computation-as-topology-as-computation?

I am a topologist, a domain theorist to be more precise. I had the
privilege to meet many founders of this relatively young field of
mathematics. Domain theory is a denotational semantics (there are
others) of lambda calculus. For reading, there is the old testament and
the new testament, as I call it. The old testament is
"A compendium of continuous lattices"
ISBN 3-540-10111-X
ISBN 0-387-10111-X
The new testament is
"Continuous lattices and domains"
ISBN 0-521-80338-1

Domain theory makes sense once one stops disregarding bottom _|_, or
undefined. Think of domains as triangular objects, e.g. the type Bool

```
False   True
    \   /
     _|_
```

How does one compute a real number? Think of a horizontal real
interval, and draw a triangle underneath:

```
---[---]---
\   \ /   /
 \   .   /
  \     /
   \   /
    _|_
```

Every point in the triangle represents a closed interval. At the top is
a copy of the real numbers in the form of singleton intervals, the
"total" elements. Every point underneath is a proper interval,
representing everything reachable by "fanning out" upward from that
point. This may be a model for e.g. interval arithmetic, where
computing a more precise result means moving up in the triangular
domain of intervals. Directed suprema (results of recursive
computations) in this domain are nested intersections of intervals.
Existence of these directed suprema is equivalent to the uniqueness and
non-emptyness of the nested intersections, which again is guaranteed by
the two topological properties "Hausfdorff" and "compactness" of the
closed real interval.

A treasure trove of smart little Haskell programs is
[Martín Escardó's so-called Barbados notes, number 46 in `https://www.cs.bham.ac.uk/~mhe/papers/index.html`](https://www.cs.bham.ac.uk/~mhe/papers/index.html)


# Topological groups and languages

[MonoidNull](http://hackage.haskell.org/package/monoid-subclasses/docs/Data-Monoid-Null.html) is a monoid
that allow us to test for `mempty`. So it obeys the law:

```hs
class Monoid m => MonoidNull m where
    null :: Monoid m => m -> Bool
    -- null x == x == mempty
```

There are `MonoidNull`s that don't have an `Eq` instance. For example, consider
`Maybe (Int -> Int)`, where the monoid over `(Int -> Int)` adds them pointwise.
Clearly, we can't tell when two functions are equal, so there's no way we can
give an `Eq` instance to `Maybe (Int -> Int)`. But we can definitely tell
when it's `Nothing`! So we have a `MonoidNull` instance without an `Eq`
instance.


Now the interesting thing is that if we have a group that has `MonoidNull`,
then it automatically has `Eq`! Witness:

```hs
instance (Group g, MonoidNull g) => Eq g where
   x == y = null (x <> inv y)
```

See that this is a transport principle: we're able to transport the test
of equality at the origin/`mempty` provided by `null` to any point in the
group.


Olaf Klinke remarked:

> A beautiful example of topological groups: Their topology is completely
> determined by the neighbourhoods of the identity element. If the
> identity element is isolated, the entire group is discrete.

I found this very interesting, because he's vieweing this from the
"topology of computation" lens, where the existence of `null` means that
the identity element is isolated. Now since it is a topological group (group
operations are continuous since everything is computable!),
the isolatedness of the identity transports to all points, giving us a discrete
object where equality is decidable! Below is an illustration of how I imagine
the situation.


<img src='./static/olaf-topological-groups.png' />



#### References
- [Post on haskell-cafe by Olaf Klinke](https://mail.haskell.org/pipermail/haskell-cafe/2020-December/133264.html)


# The mnemonica stack (TODO)

```
4  c♣
2  h♡
7  d♢
3  c♣
4  h♡
6  d♢
A  s♠
5  h♡
9  s♠
2  s♠
Q  h♡
3  d♢
Q  c♣
8  h♡
6  s♠
5  s♠
9  h♡
K  c♣
2  d♢
J  h♡
3  s♠
8  s♠
6  h♡
10 c♣
5  d♢
K  c♣
2  s♠
3  h♡
8  d♢
5  c♣
K  s♠
J  d♢
8  c♣
10 s♠
K  h♡
J  c♣
7  s♠
10 h♡
A  d♢
4  s♠
7  h♡
4  d♢
A  c♣
9  c♣
J  s♠
Q  d♢
7  c♣
Q  s♠
10 d♢
6  c♣
A  h♡
9  d♢
```


- [YouTubevideo with chant](https://www.youtube.com/watch?v=-QXy489NocE)



# Conversation with Alok about how I read

Alok Debnath, a friend of mine claims he understood "how I read" based on
reading infinite jest and setting me experiments that allowed him to observe
how I read.

In his words:

> Alok: I have seen you spasm on your cursor trying to read text (TODO: get a longer
> quote form alok about what this means)


He said that he never understood what the fuck I was doing until he read
Infinite Jest by David Foster Wallace (a phenomenal book, I loved it and recommended it to him,
which were enough recommendations to get him to read it, it seems).

#### Infinite jest

> Alok: It took me reading that book twice to understand how you process text.
> Let's deep dive.  You don't read sentences, from what I remember. You have a
> different model of chunking text.  For what it's worth, I tried to remember
> what you spasm between when skimming vs when reading. There does not seem to
> be much difference between those modes for you, which was interesting. So I
> tried to note why you would sometimes go BACK rather than read sentence to
> sentence. I figured it was one of three things:


The three things are:

> 1. You went from verb to verb or action to action, or event to event, and
>   then determined the significance of that event. You would move backwards
>   only if the verb was significant enough to warrant its arguments being
>   understood
> 2. You went from topic to topic, and would only go BACK if you think you
>    missed a timestep in the movement between topics.
> 3. You read from line to line, regardless of the sentence, phrase, clause or
>    syntactic structure, and would only go back if an item caught your
>    attention.

According to him, I do a combination of 1 and 2, in contrast to others who
might do (3).

#### Why this works for me

> you are uniquely adaptive to reading style, based on very little information.
> This is a good thing when there is a unique, singular style to the entire
> article, it is easy to templatize and then retrofit into how you want to get
> that information.

#### His take on my take on why SEP is trash

> I ran a series of experiments to figure this out. I'd ask you to read a
> paper, a textbook chapter or something in front of me, and after you'd read a
> paragraph, ask you to explain it. Some times you were already reading
> something (mostly philosophy related) and that's ambush.  Lastly, I used SEP as
> bait .SEP has not been written for people like you. And I was thoroughly
> surprised at your vehement disapproval to some of the articles
> (for their content ofc), but your veiled stylistic inputs as well.

> you mentioned that the text [of the SEP article on Derrida]() was malformed,
> which is a stylistic input, rather than a content issue.

He figured out that the SEP entry has been written in two merged styles - one is
a list of topics that Derrida talks about The other is a list of events which
weave together how those topics became tenets of his philosophy.  The style of
writing generally based on the modern notion of "set-inductive" introductions
to topics Which doesn't work well with you. Because I then noticed how you read
code And I figured that you need to have a trace of the topics talked about in
case they appear again in the code, and you parse blocks, retrieve need, GC,
and move on to the next block. So order of arguments and the state of these
topics remains in your mind, along with significant events.
debnatak: You read text in a similar way, which is why set inductive writing is
the worst way to write for you.



##### Inductive writing
 Apparently, this is a common philosophy of teaching where one is exposed
to a topic by "forewarning" them of all the subtopics, then a narrative is
weaved exploring the relationship between each subtopic, explaining them as
they come.  It's the style in which school textbooks are written.  So it is
neither ordered by event, nor ordered by topic. It's the job of the teacher to
guide the student across the text.


> Now, the Derrida SEP article is written in a very similar manner, albeit a
> bit more well formed in narrative The text is not written in a manner where
> you can parse things by topic(i.e.  first deconstructionism, then
> universality, then sovereignty) or by event (publishing book1 , then 2, then
> 3 or whatever). Therefore, this writing style is completely adverserial to
> your reading style!


##### Why I enjoy DFW and infinite jest

> Infinite Jest, and DFW in general, clearly does not write like this. It is the antithesis, almost
> Your insane experience in garbage collection works when there are a large
> number of interconnected stories, people and threads being referenced in the
> same sentence.Given that you chunk differently, parse differently, and
> organise mental notes on what you have read differently than I do, it is not
> surprising that you understood DFW fairly well.
> DFWs writing style almost wholeheartedly abandons prescriptivist notions of
> punctuation and syntactic structure beyond the meager subject verb agreement,
> Which I think is also abandoned in some monologues.
> That would not be a large issue for someone who does not use punctuation as a
> mechanism of parsing sentence information, or even as an anchor of "begin
> here" and "end here".

##### Inference from me reading code?

According to him, this is similar to how I read code:

> I saw you read word2vec.c in front of me And I was mindfucked at how you
> abstract information on the go Like you read bracket to bracket (I think),
> and keep track of "important" variables, especially function arguments and
> return values, and just summarize the rest debnatak: Not every operation
> needs to be understood, of course. But it is noted regardless. Functions are
> skipped over if not called, variables are ignored if not used.  debnatak: You
> were never confused about the program flow debnatak: Idk, it seemed clean for
> code, and math ofc because representations


##### eye tracking data


# KMP (Knuth, Morris, Pratt) (TODO)

#### References
- [KMP in haskell](https://chaoxuprime.com/posts/2014-04-11-the-kmp-algorithm-in-haskell.html)
- [String algorithms: Borders, KMP: video](https://www.youtube.com/watch?v=-YdOWEpZEfc)
- [Geometric point pattern matching](http://www.jucs.org/jucs_16_14/geometric_point_pattern_matching/jucs_16_14_1902_1911_ukkonen.pdf)

# Reading C declarations

> The real rule turns out to be simple (although non-obvious): "Declaration
> matches usage." So, for example, if you want a pointer to a function
> returning a pointer to an array of 3 integers, you'd want

```
(*(*f)())[3 - 1]
```

> to evaluate to an int, so the declaration would be

```cpp
int (*(*f)())[3];
```



# Make mnemonics

- `$@`: target, since it looks like a target.
- `$<`: the 1st prereq, since `<` points to the left.
- `$^`: all prereqs, since `^` looks like an "upward grouping flower bracket".
- `$?`: prereqs that are *newer* than the target, since `?` is stuff you don't know / haven't looked at.
- `$*`: target with *suffix deleted*, since we generally grep for `*.c|h|`, we want the `*` part of `$@`.
   Alternatively, `*` is also like a target, but only the bull's eye with the extra stuff like the suffix
   stripped out.

- [The POSIX makefile page which is WAY more readable](https://pubs.opengroup.org/onlinepubs/9699919799/utilities/make.html)
- [notes for new make users](http://gromnitsky.users.sourceforge.net/articles/notes-for-new-make-users/#4b6d995-automatic-variables)

# Vandermonde and FFT


FFT lets you do the following:

You are given two sequences: `a0,...,an` and `b0,...,bm` Compute sequence `c0,…,c[n+m]` such that
$$c[i]=a[0]b[i]+a[1]b[i−1]+ \dots +a[i−1]b[1]+a[i]b[0]$$

This is exactly what I needed here, where $a[i]= \binom{n}{i}$ and $b[i]= \binom{m}{i}$.
If I thought for a little longer I would realize that $c[i]=\binom{n+m}{i}$
instead of computing it using FFT.

#### References

- [Codeforces contest comment by Swistakk)[https://codeforces.com/blog/entry/85348?#comment-730898]

# Thoughts on blitz chess: 950 ELO

I plan on summarizing my current thoughts on chess at different stages of ELO
on Lichess.  This should be fun to look back on. Currently, I found that the
thing that helps me the *most* when it comes to winning is this simple kernel:

> Attack.

With the somewhat useful addendum:

> With a plan.

That's it. That's literally all I need to do. I generally try to focus on the
weak `f` pawn, get my Queen out early (people at my ELO rating don't really know
how to punish an early roaming queen. I don't know either!), at just attack.

If there's an attack on your pieces, *don't defend, counter-attack*. Of course,
there are situations where one _must_ defend. Only defend then.

Getting into this frame of reference stopped me from languishing at ~800 ELO.
I used to
- get anxious about the *game* and the prospect of conflict.
- get anxious about the clock.
- get anxious about leaving pieces hanging.

It seems that "getting over" these anxieties took ~20 games, after which I could
focus on the mechanics. This is a good reference point, since I have the same
problem with competitive programming --- the exact same anxieties, in fact.

# Periodic tables and make illegal states unrepresentable

The periodic table of elements succeeded because the "gaps" in the table
consisted of only legal atoms --- thus, by making illegal states unrepresentable,
a table of the current state of knowledge becomes valuable because all the
*gaps* are legal states. The exact same thing happened with juggling and
juggling notattion.


# questions on the structure of graphs

I've been trying to get more of a feeling for graphs lately, so I'm collecting
sources of "structural" questions of graphs and answers for these questions.

> Q. Is it possible in an unweighted graph, there is exactly one unique shortest
> path tree for a node u but more than one such shortest path tree for some
> other node v ?

> Q. Can I orient the edges of a bridge-less undirected bipartite graph with even
> no. of nodes such that all the nodes are in a cycle ?


# Combinations notation in bijective combinatorics

They explicitly write $nCr$ as $[n]C[r, n-r]$. This makes it better for
"future uses", where it explicitly allows us to think of $[n]C[x, y]$ as
breaking $n$ into $x$ things we choose and $y$ things we don't choose.

This makes the recurrence:

$$
[n]C[r] = [n-1]C[r-1] + [n-1]C[r]
$$

look as:

$$
[n]C[r,n-r] = [n-1]C[r-1,n-r] + [n-1]C[r, n-r-1]
$$

That is, we are reducing on either the first component ($r-1$) or on the
second component ($n-r-1$), in the smaller set ($n-1$).



# Arguments for little endian
Say we wish to store `<MSB> 100 200 300 400 <LSB>`. In little endian, this would be
stored as:

```
ix:   0   1   2   3
val:  400 300 200 100
```

An interesting theory for why this is good is if we want to treat this 4-bit
data as 1-bit data, we want the subarray `[400]`. It's easier to *directly*
acess in little endian as just `data[0]`, instead of in big endian where
it would be `data[3]`. So, storing stuff backwards makes it easier to chop off
the LSBs data, since that's the _suffix_.

# Expectiles


Mean is a minimiser of $L_2$ norm: it minimizes the loss of penalizing your
'prediction' of (many instances of) a random quantity. You can assume that the
instances will be revealed after you have made the prediction.

If your prediction is over/larger by $e$ you will be penalized by $e^2$.
If your prediction is lower by $e$
then also the penalty is $e^2$. This makes mean symmetric. It punishes
overestimates the same way as underestimates.


Now, if you were to be punished by absolute value $|e|$ as opposed to $e^2$ then median would be your best
prediction.

Lets denote the error by $e_+$ if the error is an over-estimate and
$e_-$ if its under. Both $e++$ and $e_-$ are non-negative. Now if the penalties were to
be $e_+ + a e+-$ that would have led to the different quantiles depending on
the values of $a > 0$. Note $a \neq 1$ introduces the asymmetry.

If you were to do introduce a similar asymmetric treatment of $e_+^2$ and
$e_-^2$ that would have given rise to expectiles.



# Depth first search through linear algebra (TODO)


#### References
- [Talk Video](https://www.youtube.com/watch?v=fKim6IKdr8U)
- [Link to paper](https://dl.acm.org/doi/pdf/10.1145/3315454.3329962)

# 2-SAT

First break into SCC's. Each SCC represents equivalence: since there is a
path from every variable to every other variable, they must take on the
exact same value. Hence if $x$ and $\lnot x$ are in the same SCC, we don't
have a solution, because this means that $\texttt{true} = \texttt{false}$
or $\texttt{false} = \texttt{true}$.

Let's say we find SCC's where this does not happen. Now, zoom out and think of
the condensation DAG. We want to assign true/false to each node in the SCC DAG.
How should we assign true/false? Say that $x$ and $\lnot x$ are in two
different components. So this means that we have the possible orderings
- $x \implies \lnot x$: $\texttt{true} \implies \texttt{false}$ (Inconsistent!)
- $x \implies \lnot x$: $\texttt{false} \implies \texttt{true}$ (Consistent, principle of explosion)

Hence, if $x$ implies $\lnot x$, we should set $x$ to $\texttt{false}$. The other
assignment is _inconsistent_.

# Longest increasing subsequence, step by step (TODO)
- [The science of Programming by Gries](https://www.cs.cornell.edu/gries/July2016/The-Science-Of-Programming-Gries-038790641X.pdf)

# On reading how to rule (TODO)
#### The prince

#### Arthashastra

#### The book of lord shang


# Strongly Connected Components via Kosaraju's algorithm

We know that a directed graph can be written as two-levels, a top-level dag,
with each node in the DAG being a condensation of the original graph. So
we wish to discover the DAG, and then each condensation. We wish to
view Kosaraju's algorithm as a "stronger topological sort" that works
for general graphs, and not just DAGs.

#### Step 1: Discover the tree/DAG

Run a bog standard DFS on the graph and record entry and exit times,
because that tell us everything we need to know about the DFS. Let's decide
what to keep and throw away next.

#### Step 2: Think

If we had a DAG, then we would be done; We sort the nodes according
to descending order of exit times, and we get the topological order
of the DAG. However, this is incorrect for our purposes, as this
only gives us the components if we don't have cycles.

#### Step 3: Mix in cycle detection/single SSC


Pick the first node according the topological sort heurstic --- the node
that's earliest according to exit time. We now need to discover cycles.
Recall that we built the DAG according to DFS order, so if we run a DFS
again, we'll get the entire subtree in the DAG! Rather, we want the
"anti DFS": whatever can reach the 'root' of the 'DAG'. To find this,
we reverse the DAG and find the component reachable from here.

#### SCC's as adjunction
I learnt this from Benjamin Pierce's  "Category theory for computer scientists":

> The strong components of a graph themselves form an acyclic graph
> that is a quotient of the original graph-that is, each node corresponds
> to an equivalence class of strongly connected nodes in the original. The
> mapping taking a graph to the acyclic graph of its strongly connected
> components may be expressed as a left adjoint to the inclusion functor
> from AcyclicGraph to Graph


#### References
- [CS Cornell lecture notes](https://www.cs.cornell.edu/courses/cs410/1998su/Lectures/lect24.txt)


# Articulation points

I find DFS fascinating, and honestly insane for how much structral
information of the graph it manages to retain.

> A vertex $v$ is an articulation point of a graph $G$ if the removal
> of $v$ disconnects the induced subgraph.

#### Tactic 1 - Inductively

We first solve the super easy case with the root, and then try to see
if we can treat other cases like the root node case, then we're good.
Here, we are given an graph $G$, and we are thinking about a DFS tree
$T_G$ of the graph $G$.

#### Thinking about the root

When is the root an articulation point? If the root has multiple children,
then it is an articulation point; If we remove the root, then it disconnects
the children. This is because we have an undirected graph, where we only have
back edges, and no cross edges. A back edge can only go from a node to its
ancestor. If we remove the root, the back edges cannot save us, for there is
no ancestor _higher than the root_ to act as an alternate path

#### Non root vertex

When is a non root vertex $v$ an articulation point? When there is *some* child
$w$ of $v$ such that the subtree of $w$ cannot escape the subtree of $v$.
That is, all back edges from $w$ do not go above $v$. If we were to now
remove $v$, then $w$ would be disconnected from the rest of the graph.

> Alternate phrasing: When all cycles in the subtree of $w$ are within the
> subtree of $v$. This means that the backedges cannot go above $v$.
> If $w$ could build a cycle that goes above $v$, then $v$ would not be an
> articulation point, because it'll be involved in some cycle
> $v \mapsto  w \mapsto \mapsto p \mapsto v$, which gives us an alternative path
> to reach $w$ even if $v$ is removed.


One way to imagine this maybe to imagine $v$ as the new root, and the other
stuff that's above $v$ to be to the left of $w$. That way, if we could go to $w$,
we get a cross edge from the "new root"(v) and the "other section" (the part
that's connected by a cross edge). If we prevent the existence of these
"fake cross edges", we're golden, and $v$ is then an articulation point.

#### Tactic 2 - Structurally / Characterization

Next we follow a "mathematical" development, where we build theorems
to characterize k-connectedness and use this to guide our algorithm design

#### Menger's theorem

Let $G$ be a connected undirected graph. Let $u, v$ be two non-adjacent
vertices.  The minimum number of vertices whose removal from $G$ disconnects
$u$ and $v$ is equal to the **maximal number of vertex disjoint paths** from $v$
to $u$.

#### Whitney's theorem (corollary)

An undirected graph is $k$ connected iff $k$ vertices must be removed to
disconnect the graph.

#### Biconnected components

Menger's theorem tells us that a graph is not biconnected **iff** we can find a vertex
whose removal disconnected the graph. Such a vertex is an articulation vertex.

> A biconnected component is a maximal subset of edges, such that the induced
> subgraph is biconnected. Vertices can belong to many components;
> Indeeed, articulation vertices are those that belong to more than one component.

<img src="./static/structure-of-non-biconnected-graph.png"/>


#### Lemma: Characterization of biconnected components

> Two edges belong to the same biconnected component iff there is a cycle
> containing both of them.
> [This lemma is silent about biconnected components of single edges]

We show that a cycle is always contained in a single binconnected component.
If a cycle contains edges from more than one biconnected component, then we can
"fuse" the biconnected components together into a single, larger, biconnected
component.


#### Lemma: Each edge belongs to exactly one biconnected component


#### Tactic 3 - 'Intuitively'

We look at pictures and try to figure out how to do this.

#### DFS for articulation vertices - undirected:

<img src="./static/articulation-vertex-undirected.png"/>

- The connectivity of a graph is the smallest number of vertices that need to
  be deleted to disconnect the graph.
- If the graph has an articulation vertex, the connectivity is 1. More robust
  graphs that don't have a single point of failure/articulation vertex are
  said to be *binconnected*.
- To test for an articulation vertex by brute force, delete each vertex,
  and check if the graph has disconnected into components. this is $O(V(V+E))$ time.

> Joke: an articulate vertex is one that speaks very well, and is thus important
> to the functioning of the graph. If it is killed, it will disconnect society,
> as there is no one to fulfil its ability to cross barriers with its eloquent
> speech.

#### Articulation vertices on the DFS tree - undirected

- If we think of only the DFS tree for a moment of an undirected graph
  and ignore all other edges, then
  all interneal non-leaf vertices become articulation vertices, because they
  disconnect the graph into two parts: the part below them (for concreteness,
  think of a child leaf), and the root component.

- Blowing up a leaf has no effect, since it does not connect two *components*,
  a leaf only connects itself to the main tree.


- The root of the tree is special; If it has only one child, then it acts like
  a leaf, since the root connects itself to the only component. On the other
  hand, if there are multiple components, then the root acts like an internal
  node, holding these different components together, making the root an
  articulation vertex.

#### Articulation vertices on the DFS graph - undireced

- DFS of a general undirected graph also contains *back edges*. These act as
  security cables that link a vertex back to its ancestor. The security
  cable from `x` to `y` ensures that none of the nodes on the path `[x..y]`
  can be articulation vertices.

- So, to find articulation vertices, we need to see how far back
  the security cables go.

```cpp
int anc[V]; int dfs_outdeg[V];
void processs_vertex_early(int v) { anc[v] = v; }
void process_edge(int x, int y) {
  if (dfsedge[x][y].type == TREE) { dfs_outdeg[x]++; }
  // y <-*
  //     |
  //     BACK
  //     |
  // x --*
  if (dfsedge[x][y].type == BACK && (parent[y] != x)) {
     if(entry_time[y] < entry_time[anc[x]]) {
       anc[x] = y;
     }
  }
}
```


<img src="./static/articulation-vertices-undirected-3-cases.png"/>

> In a DFS tree, a vertex v (other than the root) is an articulation
> vertex iff v is not a leaf and some subtree of v has no back edge incident
> until a proper ancestor of v.

#### References

- Udi Manber: Introduction to algorithms: A creative approach.
- Steven Skeina: The algorithm design manual.
- [Codeforces: problems to solve](https://codeforces.com/blog/entry/23617)
- [A2OJ articulation point problems](https://a2oj.com/category?ID=64)
- [INOI advanced graph algorithms](https://www.iarcs.org.in/inoi/online-study-material/topics/articulation-points.php)

# Disjoint set union

#### intuition for correctness of `rank`:

Assume that we had to re-point pointers of all our children to the
new root when we decide to make another node the root. That is,
we would have:

```
void mkroot(int newroot, int prevroot) {
   for (int child : children[prevroot] {
        parent[child] = newroot;
   }
   parent[prevroot] = newroot];
   children[prevroot] = {}; // this has no children anymore
}
```

- In this setting, we ought to make the *smaller* subtree the `prevroot`
  and the *larger* subtree the `newroot`: It is better to loop over
  fewer children.

- When we perform the `rank` based union, we are using the *same heuristic*,
  even though we don't actually loop over all our children.


# Making GDB usable

- Use [GEF](https://github.com/hugsy/gef)

# Bouncing light clock is an hourglass

I've always disliked the "clocks" that are used in special relativity,
because a clock attempts to measure something absolute, rather than something
relative. So, we should rather use hour glasses. In an hour glass, we can
only measure *intervals* of time.

<br/>

Now, when we have such an hourglass, we should fill the hourglass with
*photons*, because their speed of falling is invariant for all reference frames.
So, what we need is the ability to create an hourglass worth of photons which
we keep dripping down, once the photon at the funnel has reached the bottom.

<br/>

This is *exactly* what the two mirror photon clock does --- it bounces a photon
between two mirrors. We can look at this as us "flipping" the hourglass
once the photon reaches the bottom of the hourglass.

# Euler tours

#### Tucker's proof: undirected graph with all even degree has an euler tour

I find this proof much more intuitive because it's extremely clear where
the even condition is used.

1. For each vertex $v$, arbitrarily pair edges incident at $v$ to get
   chains `u --- v --- w`.
2. Connect chains to get cycles.
3. Find a spanning tree of cycles to get an euler tour, where we have an
   edge between two cycles if they share a common vertex.

It's super clear why we need all vertices to be even degree; You can't pair
up vertices otherwise!

#### References
- [Video on euler tour](https://www.youtube.com/watch?v=8MpoO2zA2l4)
- [Notes from Emory course on graph theory](http://www.mathcs.emory.edu/~rg/book/chap5.pdf)
- [CSTheory.stackexchange question on euler tours](https://cstheory.stackexchange.com/questions/31538/runtime-of-tuckers-algorithm-for-generating-a-eulerian-circuit)


# Representation theory of the symmetric group (TODO)

- [Video lectures: Representation theory, a combinatorial viewpoint](https://www.youtube.com/watch?v=QqJIOnTDbLM&list=PLFE2F2CDA55A9EBB6)

# Maximum matchings in bipartite graphs

It turns out that the best way to do this is to simply implement Dinic's with
scaling. That seems to meet the desired Hopcroft-Karp complexity. I was quite
disappointed to learn this, since I was hoping that Hopcroft-Karp would have
new ideas.



#### References

- [Bipartite Graphs/Matching (Intro)-Tutorial 12 D1 Edexcel](https://www.youtube.com/watch?v=JpapV5DrBek)
- [Maximum Matching Algorithm - Tutorial 13 D1 Edexcel A-Level](https://www.youtube.com/watch?v=gbasc4F-7hk)
- [Slides on matroid intersection](http://swoh.web.engr.illinois.edu/courses/ie512/handout/matching.pdf)


# p-adics, 2's complement, intuition for bit fiddling

Consider the equation $x \& (-x)$ which enables us to find the largest
power of 2 that divides $x$. One can prove this relatively easily from the
definitions:

$$
\begin{aligned}
&a = \langle x 1 0^r \rangle \\
&-a = \lnot a + 1 = x01^r + 1 = \overline{x}10^r \\
&a \& (-a) = a \& (\lnot a + 1) = (x 10^r) \& (\overline{x}10^r) = 0^{|\alpha|}10^r = 2^r
\end{aligned}
$$

That is, if we state that $a = \langle x 1 0^r \rangle$ for some arbitrary $r$,
we then find that $a \& (-a) = 2^r = \langle 1 0^r \rangle$, which is precisely what we need to subtract
from $a$ to remove the rightmost/trailing $1$. However, I don't find
this insightful. So I'm going to spend some time dwelling on $2$-adics, to find
a more intuitive way to think about this.

#### 2-adics and negative numbers

In the 2-adic system, we have that:

$$
\begin{aligned}
&-1 = \dots 1 1 1 1 \\
&-2 = -1 + -1 = \dots 1 1 1 1 + \dots 1 1 1 1 = \dots 1 1 1 0 \\
&-4 = -2 + -2 = \dots 1 1 1 0 + \dots 1 1 1 0 = \dots 1 1 0 0 \\
&-8 = -2 + -2 = \dots 1 1 0 0 + \dots 1 1 0 0 = \dots 1 0 0 0 \\
\end{aligned}
$$

Of course, these agree with the 2's complement representation, because the 2's
complement representation simply truncates the 2-adic representation. At any
rate, the point of interest is that if we now want to know how
to write $-3$, we start with the "lower" number $-4$ and then add $1$ to it,
giving us:

$$
-3 = -4 + 1 = \dots 1 1 0 0 + \dots 0 0 0 1 = \dots 1 1 0 1
$$

Which once again agrees with the 2's complement definition.

#### $x \& (-x)$ for powers of 2:

If we now think strictly about powers of 2, we know that, for example,
$8 = \langle \dots 0 0 1 0 0 \rangle$ while $-8 = \langle \dots 1 1 1 0 0 \rangle$.
Hence, $x \& (-x) = \langle 0 0 1 0 0 \rangle$.  This will hold for any power of 2,
so our claim that $x \& (-x)$ gives us the location of the LSB will work for
any power of 2.

#### Alternative explanation for 2's complement

Start with the fact that we choose a single representation for zero:

```
0 ~= b0000000
```

Now, when we subtract 1, ask "are we in signed world or unsigned world"? If
in signed world, we want the answer to be `-1`. If in unsigned world
we want the answer to be 255.

```
0 - 1
= b0000000 - b00000001
= b11111111
=unsigned= 255
```

If we wanted to interpret the answer as *signed*, then we are free to do so.
This *automatically tell us that*

```
0 - 1
=unsigned= b11111111
=signed= -1
```

So, the advantage is that our operations don't care about whether the
number is signed/unsigned.



# Diameter of a tree


## Key property of the diameter

- Let $p$ be a path of maximum diameter, which starts at $p$ and ends at $q$.
 Consider a tree where the diameter is shown in golden:

<img src='./static/diameter/tree-diam-spread.png' />

- We claim that a node at distance $d$ from the left can have a subtree of
  height at most $d$:

<img src='./static/diameter/tree-diam-straight-example.png' />

- Suppose this were not the case. Then, we can build a *longer* diameter (in pink)
  that is longer than the "supposed diameter" (in gold):

<img src='.static/diameter/tree-diam-straight-counterexample.png' />

## Algorithm to find the diameter:

First perform DFS to find a vertex "on the edge", say $v$. Then perform DFS again
starting from this vertex $v$. The farthest vertex from  $v$, say $w$ gives
us the diameter (the distance from $v$ to $w$)

#### Proof by intuition/picture:

- first imagine the tree lying flat on the table.

<img src="./static/diameter/tree.png" />

- Hold the tree up at node $c$. It's going to fall by gravity and arrange as
  shown below. This is the same as performing a DFS.

<img src="./static/diameter/tree-dfs-1.png" />

- Pick one of the lowest nodes (we pick $g$). Now hold the entire tree from
  this lowest node, and once again allow gravity to act.

<img src="./static/diameter/tree-dfs-2.png" />

- This will give us new lowest nodes such as $b$. This node $b$ is going to be
  diameter, "because" it's the distance from a lowest node to another lowest
  node.

# Catalan numbers as popular candidate votes (TODO)

- Usually, folks define catalan numbers as paths that go up or right from $(1, 1)$
  to $(n, n)$ in a way that never goes below the line $y = x$.

- The catalan numbers can be thought to model two candidates $A$ and $B$ such
  that during voting, the votes for $A$ never dip below the votes for $B$.

I quite like the latter interpretation, because we really are counting
two different things (votes for $A$ and $B$) and then expressing a relationship
between them. It also allows us to directly prove that `catalan(n)` is equal
to $1/(n+1) \binom{2n}{n}$ by reasoning about seqences of votes, called as
*ballot sequences*

#### Ballot sequences

#### References
- [Richard Stanley's slides](https://math.mit.edu/~rstan/transparencies/china.pdf)

# The chromatic polynomial (TODO)

I've been on a combinatorics binge lately, so I'm collecting cool facts about
the chromatic polynomial. We first define the chromatic function of a graph,
which is a generating function:

$$
f[G](x) \equiv \texttt{number of ways to color $G$ with $x$ colors} \cdot x^n
$$

If we have a single vertex $K_1$, then $f[K_1](x) =  n x^n$, since we can color
the single vertex with the $n$ colors we have.

#### Composition of chromatic funcions of smaller graphs


#### The chromatic function is a polynomial



# Structure theory of finite endo-functions

We study functions $f: V \rightarrow V$ and their properties by thinking of them as a
graph with vertex set $V$ and directed edges $(v, f(v))$. This gives us insight into
permutations, rooted trees, and a bunch of counting principles. Such a structure is
called as *functional digraph*

#### Principle 1: Structure theory

every functional digraph uniquely decomposes into disjont rooted trees which feed into
one or more disjoint cycles. We think of nodes as pointing from the leaves towards the
root. The root of the tree lies in a cycle.

#### Existence of tree implies not bijection

If we have a tree, we can keep walking backwards using edges from the root towards
the leaves. Now this leaf does not have an incoming edge. This means that this leaf
is not in the image of $f$. Hence $f$ cannot be surjective.

#### Rooted Trees: a single cycle

in a rooted tree, only the root node $r$ is such that $f(r) = r$. All other nodes point to
other nodes without cycles.

#### Permutations: no rooted tree, only cycle

In a permutation, all we have are cycles. There are no trees that hang from the cycles.

#### Counting number of rooted trees: $n^{n-2}$: (TODO)

Say we have a function $f: V \rightarrow V$ where $|V| = n$ and $f(1) = 1$, $f(n) = n$.


#### References
- [USACO: functional graphs](https://usaco.guide/silver/func-graphs)

# Number of paths in a DAG

Given the adjacency matrix $A$ of a DAG, this  must be nilpotent. This is because
$A^k[i][j]$ will tell us the number of paths from $i$ to $j$ with $k$ edges in the path.
In a DAG, since there are no cycles, there is an upper bound on the number of edges
a path can have: the longest path is $|V| - 1$, when the DAG is a straight line. Thus,
we must have that $A^|V| = 0$.

- Let $A^n = 0$.
- Now, we know that $(I - A)^{-1} = I + A + A^2 + \dots$
  which will terminate as a finite sum, with $(I - A)^{-1} = I + A + A^2 + \dots + A^{n-1}$.
- But note that $(I + A + A^2 + \dots A^{n-1})[i][j]$ will count number of paths from
  $i$ to $j$ with $0$ edges, $1$ edge, $2$ edges, etc. so we will get the _total_ number of
  paths from $i$ to $j$!.


# Set partitions

Let $X$ be a set. A breakup of $X$ into pairwise disjoint sets $A[i]$ such that $\cup_i A[i] = X$
is called a partition $P$ of the set $X$.

#### Stirling numbers of the second kind: $S(n, k)$

These count the number of ways to break an $n$ element set into $k$ partitions/equivalence classes.


The recurrence is:

$$
S(n, k) \equiv S(n-1, k-1) + kS(n-1, k)
$$

- For the $n$th element, I either build a new equivalence class $\{ n \}$
  and then make $k-1$ equivalence classes from $\{1\dots (n-1)\}$.
- Alternatively, I have $k$ equivalence classes from $\{1 \dots (n-1)\}$, say $P[1], P[2], \dots, P[k]$
  I decide into which $P[i]$ the $n$ should go, which gives me $k$ choices.
- Initial conditions: $S(0, 0) = 1$, $S(0, k \neq 0) = S(n \neq 0, 0) = 0$.

#### Stirling numbers and surjections

> Interesting interpretation: The number of ways to surject an $n$ element set into a $k$
> element set, since a surjection breaks a set up into a known number of fibers (in this case, $k$ fibers).

This is not entirely true, because we only get $k$ equivalence classes of the set $\{1, \dots, n\}$. We need to
decide where to map each equivalence class. So the correct count of $\{ [n] \xrightarrow{onto} [k] \}$
is $k!S(n, k)$: there are $k!$ ways to map equivalence classes of $n$ to elements of $k$


#### Rook theory(!)

Turns out we can provide a crazy relationship betweeen ferrers diagrams, and rooks (as in the chess piece)
and stirling numbers of the second kind.

We define $\Delta(n)$ to be the board consisting of the integer partition
$[n-1, n-2, \dots, 1]$. For example, we think of $\Delta(4)$ as:

```
Delta(4):
+--+
|  |
+--+--+
|  |  |
+--+--+--+
|  |  |  |
+--+--+--+--+
```

Hopefully, this looks like a staircase with 4 stairs starting from the ground.
We have filled in squares of $[3, 2, 1]$ blocks stacked above one another.


We define $r(n, k)$ to be the number of legal rook placements on a board $\Delta(n)$
with $k$ free rows. That is, we have $(n-k)$ rooks to place on the board $\Delta(n)$,
with one on each row, such that no rook attacks another rook.

- Boundary condition: $r(0, 0) = 0$ 0 free rows on a $\Delta(0)$ board counts as
  one configuration.
- Recurrence: $r(n, k) \equiv r(n-1, k-1) + k r(n-1, k)$

-  $r(n-1, k-1)$ term:
   We don't place a rook on the bottom row. This means we have used up a free row,
   and need to place rooks with $(k-1)$ free rows on an $(n-1)$ board:

```
+--+
|  |
+--+--+
|  |  |  r(n-1, k-1)
+--+--+--+

+--+--+--+
|  |  |  |  BLANK
+--+--+--+--+
```

- $k r(n-1, k)$: We fill out $\Delta(n-1)$ with rooks such that we have
  $k$ free rows. Then, we add the final row. Note that since we have rooks,
  $k$ free rows is equivalent to $k$ free columns! Now, we can't leave the final row
  free, since we have already exhausted our $k$ free rows in the recursion. We have $k$
  free columns for the rook in the final row to inhabit. So we get $k r(n-1, k)$.


#### Bijection between rooks and Stirling numbers of the second kind

Finally, note that $S(n, k) = r(n-k, k)$, as $S(n, k) = S(n-1, k-1) + k S(n-1, k)$
which is equivalent to asking:

$$
\begin{aligned}
&S(n, k) = S(n-1, k-1) + k S(n-1, k) \\
&r(n-k, k) =_? r(n-1 - (k-1), k-1) + k r(n-1 - k, k) \\
&r(n-k, k) =_? r(n-k, k-1) + k r(n-k-1, k) \\
&\text{set $m = n-k$: } \\
&r(m, k) = r(m, k-1) + k r(m, k) \\
\end{aligned}
$$

#### Directly reading off the bijection between set partitions and rook placements

I found this very cool. The idea is to treat each rook as a "bouncer" that bounces light
rays. All elements hit by a light ray belong to an equivalence class.

<img src="./static/rooks-equivalence-classes.png"/>


#### Wrooks and signless stirling numbers

Similar to the rooks, we define a _wrook_ (a weak rook) as one that only attacks
on its row. Here $w(n, k)$ denotes a placement of wrooks on $\Delta(n)$ with $k$
free rows.

$$
\begin{aligned}
&w(n, k) \equiv \\
&~ w(n-1, k-1)~ \text{Leave bottom row free: uses up a free row} + \\
&~n w(n-1, k)~ \text{Place a wrook on bottom row: $n$ possible positions}
\end{aligned}
$$

The corresponding "counting" object is called as the signless stirling numbers:

TODO


# Integer partitions: Recurrence

An integer partition of an integer $n$ is a sequence of numbers $p[1], p[2], \dots p[n]$ which
is weakly decreasing: so we have $p[1] \geq p[2] \dots \geq p[n]$. For example, these
are the integer partitions of $5$:

- [5]
- [4, 1]
- [3, 2]
- [3, 1, 1]
- [2, 2, 1]
- [2, 1, 1, 1]
- [1, 1, 1, 1, 1]

Thus, $P(5) = 7$. We denote by $P(n, k)$ the number of partitions of $n$ into $k$ parts.
So we have $P(5, 1) = 1$, $P(5, 2) = 2$, $P(5, 3) = 2$, $P(5, 4) = 1$, $P(5, 5) = 1$.

The recurrence for partitions is:

$$P(n, k) = P(n-1, k-1) + P(n-k, k)$$

The idea is to consider a partition $p[1], p[2], \dots, p[k]$ of $n$ based on the final element:
- if $p[k] = 1$, then we get a smaller partition by removing the $k$th part, giving us a partition of $(n-1)$
  as $[p[1], p[2], \dots, p[k-1]]$. Here the number decreases from $n \mapsto (n-1)$ and the number of parts
  decreases from $k \mapsto (k-1)$.
- if $p[k] \neq 1$ (that is, $p[k] > 1$), then we get a partition of $n-k$ by knocking off a $1$ from *each* partition, giving us
  $[p[1] - 1, p[2] - 1, \dots, p[k]-1]$. Here we decrement on the number $n \mapsto n - k$ while still keeping
  the same number of parts.

#### References

- Bijective Combinatorics
- [Slides by Brian Miceli](http://ramanujan.math.trinity.edu/bmiceli/research/TXState04-09-10.pdf)

# Stars and bars by direct bijection

We know that the number of $k$ element multisets using letters from $\{1, \dots, n\}$
is $\binom{k+n-1}{k}$.  That is, we are allowed to pick elements from $\{1, \dots, n\}$
repeatedly, and we want $k$ such elements.

#### The usual proof: stars and bars

The usual proof involves creating $k$ "stars" ($\star$) which need to be placed in $n$
buckets. These buckets are created by having $(n-1)$ "bars" ($|$). For example, if we
wish to consider all $k=3$ element multisets of the letter $n=4$: $\{w, x, y, z\}$:

$$
\begin{aligned}
&[w, w, w] \mapsto \star \star \star \vert \vert \vert  \\
&[w, x, y] \mapsto \star \vert \star \vert \star \vert \\
&[x, x, x] \mapsto \vert \star \star \star \vert \vert  \\
&[x, z, z] \mapsto \star \vert \vert \star \star \\
\end{aligned}
$$

#### Direct bijection.

To build a direct bijection, map a $k$ multiset of $n$ into a $k$ **subset** of $n+k-1$, which
is counted by $\binom{n+k-1}{k}$.


- We are first given a $k=6$ multiset of $n=3$, say $m = \{3, 1, 2, 1, 3, 3\}$ ($m$ for multiset).
- We make the representation unique by imposing an ascending order,  so we write $M = [1, 1, 2, 3, 3]$, where each $M[i] \leq M[i+1]$.
- Now, we map the above sequence to a set of  *unique* values, by mapping $N[i] = M[i] + i$. Since $M[i] \leq M[i+1]$ we have that
  $M[i] + i < M[i+1] + (i+1)$.
- This gives us the set $M' = \{ 1+0, 1+1, 2+2, 3+3, 3+4 \} = \{ 1, 2, 3, 6, 7 \}$.
- See that this process is reversible. Given some set, say $N = \{ 4, 3, 2, 6, 7, 8 \}$, order in ascending order to get
  $N' = [2, 3, 4, 6, 8]$ and then subtract $i$ from $N'[i]$ to get $[2-0, 3-1, 4-2, 6-3, 7-4, 8-5] = [2, 2, 2, 3, 3, 3]$.


I found this very elegant, because it "de-multisets" the multiset by adding just enough to make each element unique,
and then simply counts the unique subset. Very slick! We need to add $k-1$ to the final index, and the largest number
we can have is $n$ so we need $n + (k-1)$ values. We need a size $k$ multiset, making us need $\binom{n+(k-1)}{k}$.

- Reference: Bijective Combinatorics

# DFS and topological sorting

The proper way to solve a maze is to keep breadcrumbs! Use recursion.
Recursively explore the graph, backtracking as necessary.

#### DFS on a component:

```py
parent = { s: None}
dfs-visit(adj, s):
  for v in adj[s]:
    if v not in parent:
      parent[v] = s
      dfs-visit(adj, v)
```

#### visit all vertices:

```py
dfs(vs, adj):
  parent = {}
  for s in vs:
    if s not in parent:
    parent[s] = None
    dfs-visit(adj, s)
```

#### Complexity

We call `dfs-visit` once per vertex $V$. Per vertex, we pay `adj(v)` per
vertex `v`. In total, we visit `|E|`.

#### Shortest paths?

DFS **does not take the shortest path** to get to a node. If you want shortest
paths (in an unweighted graph), use BFS.

#### Edge classification

1. **Tree edges**: visit a new vertex via that edge. Parent pointers track
                   tree edges.
2. **forward edges**: goes from node `n` to descendant of node `n`.
3. **backward edges**: goes from a node `n` to an ancestor of node `n`.
4. **cross edges**: all other edges. Between two non-ancestor-related nodes.


How do we know forward, back, cross edges?

#### Computing edge classifications

- **backward edges**: mark nodes being processed. if we see an edge towards a
                      node still being processed, it's a backward edge.
- **forward edges**/**cross edges**: use time.

#### Which of these can exist in an undirected graph?

- Tree edges do exist. They better! That's how we visit new nodes.
- Forward edges: can't happen, because we will always traverse "backwards".

```
A ----> B
  ----> C
```

`A -> C` is a forward edge!
If we made the above undirected, then we will have `A -> B` tree edge and `B -> C`
back-edge.

- Back-edges: can exist in an undirected graph as shown above; `B -> C` is a back edge.
- Cross-edges: once again, cross edges can only come up from "wrongly directed"
  edges. But we don't have directions in an undirected graph.

#### Cycle detection

$G$ has a cycle iff $G$'s DFS has a back-edge.

##### Proof: DFS has a back edge => $G$ has a cycle

```
  tree
A -...-> X
^         |
---back---*
```

By definition, `A -> X` is connected using tree edges, and a back edge
`X -> A`. gives us the cycle.

#### Proof: $G$ has a cycle => DFS has a back edge

Say we have a cycle made of `k` vertices `x, y, z, ...`.
assume `v[0]` is the first vertex in the cycle visited by the DFS.
Keep labeling based on how DFS visits then as `v[1], v[2], ... v[k]`.
The we claim the edge `v[k] -> v[0]` will be a backedge.

- We know that when we're recursing on `v[0]`, we will visit `v[1]` before we
  finish `v[0]`.
- Similarly, `v[i]` will be visited before `v[i-1]`.
- Chaining, we will finish `v[k]` before we finish `v[0]`.
- In terms of balanced parens, it's like `{0 (k; k) 0}`.
- So, when we look at the edge `v[k] -> v[0]`, we have not yet finished `v[0]`.
  Thus, we get a backedge.

#### Topological sort

Given a DAG, order vertices so that all edges point from lower order to
higher order. The algorithm is to run DFS and output the reverse order of
finishing time of vertices. Why does this work?

#### Proof that topological sort works

We want to show that for an edge $(u, v)$ that $v$ finishes before $u$, so that $v$
is ordered _after_ $u$.
Remember that we sort based on _reverse_ of finishing order.

##### Case 1: `u` starts before `v`

We will eventually visit `v` in the recursion for `u` because `u -> v`
is an edge.  So, we will have
the bracketing `{u (v; v) u}` so we're good: we finish `v` before we finish `u`.

##### Case 2: `v` starts before `u`

We have the bracketing `(v ... {u`. If we were to finish `u` before finishing `v`, then
`v` is an ancestor of `u`, and this gives the bracketing
`(v .. {u .. u} .. v)` and thus the edge $(u, v)$ is a back-edge. But this is
impossible because the graph cannot have cycles! Thus, we will still have that
`v` finishes beofre `u`, giving the bracketing `(v v) .. {u u}`.


- [MIT introduction to algorithms: Lecture 14, DFS and topological sorting](https://www.youtube.com/watch?v=AfSk24UTFS8)


# Tournaments

- Tournament graph: either $U$ beats $V$, so we have $U \rightarrow V$ or we have $V$ beats $U$ so we
  have the edges $V \rightarrow U$ for every $U, V$

[image at 49:00 from video math for comp sci lecture 10]

- Example:  `A -> B -> D -> E -> C`. Wait, `C -> A`. It's unclear how to talk about
  the best player!

#### directed Hamiltonian path

A directed walk that visits every vertex exactly once.

#### Theorem: every tournament graph contains a directed hamiltonian path

Induction on the number of nodes. When we start thinking of the problem,
we have both nodes and edges as parameters. But edges are directly related to nodes,
so it makes sense we induct on nodes.

##### Induction
If $n=1$ we are done.  In the inductive step, assume it holds for $n=n$.  For
$n=n+1$, let's take out one node $v$ and see what happens. In the remaining
graph, we still have a tournament graph on $n$ nodes. By the induction
hypothesis we have a directed hamiltonian path $v_1 v_2 \dots v_n$. We want to
create a bigger path that includes $v$.

##### Case 1
If $v \rightarrow v_1$ then we will get a path $v v_1 \dots v_n$.

##### Case 2
If $v_1 \rightarrow v$, then it is harder! Now what do we do?
Ideally we want to plug $v$ somewhere in the sequence $v_1 v_2 \dots v_n$.
Let's consider the smallest $i$ such that $v \rightarrow v_i$. We know that $i \neq 1$
as we are in case 2.

```
v1 -> ...v[i-1] -> v[i] -> ... vn
                   ^
                   v
```

If we have $v[i-1] \rightarrow v$ we are done because we get to insert $v$
into the path as $v[i-1] \rightarrow v \rightarrow v[i]$. Because $v[i]$ is the
smallest index that $v$ beats, we must that $v[i-1]$ beats $v$ --- otherwise $i$
is no longer the smallest index!


#### Chicken tournament

Either a chicken $u$ pecks a chicken $v$ then $u \rightarrow v$ or the other
direction, $v \rightarrow u$. We say that $u$ *virtually* pecks $v$ if there's
a patch of pecking for $u$ to peck $v$.

> The chicken king is the chicken that virtually pecks all other chickens.

We can have multiple king chickens. We want to find at least one chicken king.
We may want to show that the vertex with the most number of outgoing edges
is going to be a king.

#### Theorem: chicken with highest out degree is the king

Proof by contradiction: assume $u$ has highest out degree and is not the king.
So there is some vertex $v$ such that $\not u \rightarrow v$. Hence we have
that $v \rightarrow u$. In the other case, we have that $\not u \rightarrow w \xrightarrow{\star} v$.

- [Reference: Math for computer science, lecture 10](https://www.youtube.com/watch?v=DOIp5D7VMS4)

# Matching problems (TODO)

Given a graph $G = (V, E)$ a matching is a collection of edges of $G$ where every
node has degree 1.

#### Perfect matching

A matching is perfect if it has size $|V|/2$, or no vertex is left
isolated. That is, everyone is matched with someone.

#### Weighted (Perfect) Matching

Some matchings maybe more preferable than orders, by giving weights.Usually,
lower weights are more desirable. We may want to find the minimum weight matching.                                                          n
The weight of a matching is the sum of the weights on the edges of $M$. In this
context, we usually always ask for a **perfect matching**. Otherwise, one can
trivially *not match anyone* to get a min-weight matching of weight 0.
So the definition of a min-weight matching for the graph $G$ is a perfect
matching with minimum weight.

We don't see these in `6.042`. Will have to read flows/hungarian to study this.

#### Preference matching

Given a matching, $(x, y)$ form a **rogue couple** if they both prefer each
other over their matched mates. Ie, they both wish to defect from their
'matched mates'. A matching is **stable** if there aren't any rogue couples.
The goal is to find a perfect stable matching. That is, get everyone married
up, and make it stable!


The point is, not everyone has to become happy! It's just that we don't allow
rogue couples who can mutually get a benefit.

#### Bad situation for preference matching

If boys can love boys as well as girls, then we can get preference orderings
where no stable marriage is possible. The idea is to create a love triangle.

- Alex prefers Bobby over Robin
- Bobby prefers Robin over Alex
- Robin prefers Alex over Bobby.
- And then there is mergatoid, who is the third choice for everyone.
  mergatoid's preferences don't matter

##### Theorem: there does not exist a stable matching for this graph

Proof: assume there does exist a stable matching, call it $M$. Mergatoid
must be matched with someone. WLOG, assume mergatoid is matched to Alex by
symmetry. If mergatoid is matched to alex, then we must have Robin matched
to Bobby

- Alex and Bobby are not rogue, because Bobby  likes Robin more than Alex.
- Alex and Robin are the rogue, because (1) Robin prefers Alex over Bobby, and
  (2) Alex prefers Robin over Mergatoid.

Hence, we found a rogue couple. So $M$ was not stable.

#### Stable Marriage Problem: success in some cases!

We have $N$ boys and $N$ girls [need the same number of each]. Each boy
has his own ranked preference list of all the girls. Each gil has her own
ranked preference list of all the boys. The lists are complete and there
are no ties. We have to find a perfect matching with no rogue couples.

#### Mating algorithm / Mating ritual

The ritual takes place over several days.
- In the morning, the girl comes out to the balcony.
- Each boy goes to his favourite girl who hasn't been crossed off in his list
  and serenades her.
- In the afternoon, if a girl has suitors, she tells her favourite suitor
  "maybe I'll marry you, come back tomrrow". Girls don't make it too easy. For
  all the lower priority boys, she says "now way I'm marrying you".
- In the night, all the boys who heard a no cross that girl off from their list.
  If the boy heard a maybe, he will serenade her.
- If we encounter a day where every girl has at **most** one suitor, the algorithm
  terminates. So we don't have two or more boys under one balcony.


#### Things to prove

- Show that the algorithm terminates.
- Show that everyone gets married.
- Show that there are no rogue couples.
- We may want to show it runs quickly.
- Fairness? is this good for girls, or for boys?

#### Termination, terminates quickly: N^2 + 1 days

Proof by contradiction. suppose TMA does not terminate in $N^2+1$ days.

**Claim** If we don't  terminate on a day, then that's because a girl had
two or more boys under her balcony. Thus, at least one boy crosses the girl
off of his list. We measure progress by the cross-out. In $N^2$ days, all boys
would have crossed out all girls.

#### Invariant

- `P` is that if a girl $G$ every rejected a boy $B$ then she has a suitor who
  she prefers to $B$.

- To prove that this is indeed an invariant, induction on time.
  At the beginning, no girl has rejected any boy, so it's vacuously true.

- Assume `P` holds at the end of day $d$. At the end of day $d+1$, there's two cases.
- If $G$ rejects $B$ on day $d+1$, there must be a better boy, hence `P` is true.
- If $G$ rejected $B$ on day less than $d+1$, then $G$ must have had a better suitor $B'$
  on day $d$ by the induction hypothesis. Now on day $d+1$, she either has $B'$
  or someone even better, $B''$ came along.

#### Everyone is married

Proof by contradiction. Assume not everyone was married. Assume that some boy $B$ is
not married. (If there is no boy who is not married then everyone is married).
- If we was not married at the end, then he must be rejected by *everyone*.
- If he were not rejected by everyone, then he would be under someone's balcony
  trying to serenade them. That he is unmatched means that all the girls have
  rejected him.
- This means that every girl has somebody better than $B$, which is not possible,
  because that would mean that every girl was married. That's not possible as there
  are an equal number of boys and girls.

> Sid note: I don't buy this! we need to show that in the course of the algorithm,
> it's impossible for a girl to end up empty handed. I'd prove this by noticing that
> at each round, a girl acts like some kind of "gated compare and swap" where only
> the highest value is allowed to be put into the mutex, and all of the others
> are rejected. Thus, if there is a girl who has multiple writes, she will
> only allow one of the writes to happen, and permanently disallow the other writes.
> Thus, the other writes have to move to other girls.

#### No rogue couples

Contradiction: assume that there is a pair that are not married, call them bob and gail.
We need to show that they will not go rogue. Since bob and gail are not
married, either (1) gail rejected bob, or (2) gail did not reject bob because
bob never serenaded her. If bob had serenaded her *and* was not rejected, then they
would have been married!.


- (1) If gail rejected bob, then gail has marries someone she likes better than bob
  since she's rejected bob. Thus, gail and bob can't be a rogue couple because she
  likes her spouse more than bob.

- (2) bob never serenaded gail. This means that he married someone who he prefers
  more than gail, cause he never reached gail.

#### Fairness

- The girls get to pick the best ones who come to them.
- The boys get to go out and try their first choice though. A girl may wait
  for her Mr. Right who will never come along, and thus satisfice.
- Which is better? proposors or acceptors? Sociological question! Here it turns
  out that **boys have all the power**.
- Let $S$ be the set of all stable matchings. We know that $S$ is not empty
  because the algorithm is able to produce at least one stable matching.
- For each person $P$, we define the **realm of possibility** for $P$ to be the
  set $Q$ of people that they can be matched to in a stable matching. So
  $Q_p \equiv \{ q : (p, q) \in M, M \in S \}$. That is, there's a stable marriage
  where you're married to them.
- A person's **optimal mate** is their most favourite in the realm of possibility. Their
  **pessimal mate** is their least favourite in the realm of possibility.

#### Theorem: No two boys can have the same optimal mate.

Assume two boys do have the same optimal mate. Say $(b^\star, g)$ and $(b, g)$. WLOG
let $g$ prefer $b^\star$ over $b$. Now, there exists some "stable matching" where
$g$ is matched with $b$, because $g$ is the optimal mate, hence in the realm
of possibility of $b$. However, this matching is unstable because $(b^\star, g)$
is a rogue couple: $g$ likes $b^\star$ more than $b$, and $b^\star$ likes $g$ best!

#### Theorem: No two girls can have the same optimal mate

Redo previous proof by switching girl and boy. It's not a proof about the *algorithm*,
but about the *structure of stable matches* themselves.


#### Theorem: The algorithm matches every boy with his optimal mate

Proof by contradiction.  Assume that Nicole is optimal for Keith, but Keith winds
up not marrying Nicole. This means he must have crossed off Nicole in some day (bad day).

Note that he must have **gotten to Nicole**, because no girls he prefers over nicole
would have led to a stable marriage, and would thus not be an output generated
by the algorithm. This, all girls he prefers above nicole must reject him
at *some* step of the algorithm till he reaches Nicole.

We assume that in this instance of the algorithm, he does not get Nicole, thus
Nicole too must have rejected him.

Let us assume that Keith gets rejected by Nicole on the **earliest bad day**.

When Nicole rejects Keith, this means that Nicole had a suitor she likes better
than Keith. Call him Tom. `Tom >Nicole Keith`. Furthermore, since this is the
earliest bad day, tom has not crossed off his optimal girl, and thus nicole
must be the "best girl" for tom --- either out of his league, or the optimal
feasible math. Thus, `Nicole >Tom optimal-feasible-mate-for-tom`.


But this means that in a stable marriage with `(Nicole, Keith)`, we would have
`(Nicole, Tom)` be a rogue couple! This contradicts the fact that nicole is optimal
for keith.



- Proof from Optimal Stable Matching Video, MIT 6.042J Mathematics for Computer Science, Spring 2015.

#### We match every girl with her pessimal mate

TODO

#### Theorem: matchings form a lattice

Let $M = ((b_1, g_1), (b_2, g_2), \dots (b_n, g_n))$  and $M' = ((b_1, g'_1), (b_2, g'_2), \dots, (b_n, g'_n))$
be two stable matchings. Then.

$$
M \lor M' \equiv ((b_1, \max_{b_1}(g_1, g_1'), \dots, (b_n, \max_{b_n}(g_n, g_n')))
$$

is a stable matching.

##### Step 1: This is  a matching
First we show that it is indeed a matching: the marriages are all monogamous.
Assume that we had $g_1 = \max_{b_1}(g_1, g_1') = \max_{b_2}(g_2, g_2') = g_2'$.


Since $(b_2, g_2')$ is the match in $M'$ and $g_1 = g_2'$, we have that $(b_2, g_1)$
is the match in $M'$. We also know that $g_1 >_{b_1} g_1'$ from the assumption.
Since the matching $M'$ is stable, we need to ensure that $(g_1, b_1)$ is not a
rogue couple; $b_1$ prefers $g_1$ over $g_1'$. Thus, we must have that $b_2 >_{g_1} b_1$
to ensure that $(b_2, g_1)$ is stable.

However $M$ is stable, and $(b_1, g_1) \in M$.  Since we have that $b_2 >_{g_1} b_1$,
for $(b_1, g_1)$ to be stable, we must ensure that $(b_2, g_1)$ is not
a rogue couple, since $g_1$ prefers $b_2$ over $b_1$. This we must have
that $g'_1 >_{b_2} g_1$.

But this contradicts the equation $\max{b_2}(g_2, g_2') = g_2' = g_1$ (?)

#### Sid musings

> the girls are monotonic filters, where they only allow themselves to match higher.
> The propogate (in the kmett/propogators sense of the word) information to all
> lower requests that they will not match. The boys are in some kind of atomic
> write framework with conflict resolution, where a girl allows a boy to "write"
> into her 'consider this boy' state if the boy is accepted by her filter.

#### References

- [MIT OCW Math for comp sci: lecture 7 --- matching](https://www.youtube.com/watch?v=5RSMLgy06Ew)
- [SPOJ problem](https://www.spoj.com/problems/STABLEMP)
- [Knuth: Stable matching and its relation to other combinatorial problems](https://www-cs-faculty.stanford.edu/~knuth/ms.html)
- [Math for Comp Sci: Optimal stable matching](https://www.youtube.com/watch?v=n4KKgKpp--0)

# Four fundamental subspaces

- Column space / Image: $C(A)$, since it corresponds to $C(A) \equiv \{ y : \exists x, y = Ax \}$
- Null space $N(A) \equiv \{ k : Ak = 0 \}$.
- Row space: row spans the row space, so it's all linear combinations of the rows
    of $A$. This is the same as all combinations of the columns of $A^T$.
  Row space is denoted by $C(A^T)$.
- Null space of $A^T$: $N(A^T)$, also called as the "left null-space of $A$".

Let $A$ be $m \times n$. The Null space of $A$ is in $\mathbb R^n$. The column
space is in $\mathbb R^m$. The rows of $A$  are in $\mathbb R^n$. The nullspace
of $A^T$ is in $\mathbb R^m$.


We want a basis for each of those spaces, and what are their dimensions?
- The dimension of the column space is the rank $r$.
- The dimension of the row space is also the rank $r$.
- The dimension of the nullspace is $n - r$.
- Similarly, the left nullspace must be $m - r$.


#### Basis for the column space

The basis is the pivot columns, and the rank is $r$.

#### Basis for the row space

$C(R) \neq C(A)$. Row operations do not preserve the column space, though
they have the same row space. The basis for the row space of $A$ and $R$
since they both have the space row space, we just read off the first $r$
rows of $R$.

#### Basis for null space

The basis will be the special solutions. Lives in $\mathbb R^n$


#### Basis for left null space

It has vectors $y$ such that $A^T y = 0$. We can equally write this as
$y^T A = 0$. Can we infer what the basis for the left null space is
from the process that took us from $A$ to $R$? If we perform gauss-jordan,
so we compute the reduced row echelon form of $[A_{m\times n} I_{m \times m}]$,
we're going to get $[R E]$ where $E$ is whatever the identity matrix became.

Since the row reduction steps is equivalent to multiplying by some matrix $M$,
we must have that:

$$
\begin{aligned}
&M [AI] = [RE] \\
&MA = R; MI = E \implies M = E
\end{aligned}
$$

So the matrix that takes $A$ to $R$ is $E$! We can find the basis for the left
nullspace by lookinag at $E$, because $E$ gives us $EA = R$.

#### Reference
- [Gilbert strang, lecture 10: four fundamental subspaces](https://www.youtube.com/watch?v=nHlE7EgJFds)


# WHO list of essential medicines (TODO)
- [Wikipedia reference](https://en.wikipedia.org/wiki/WHO_Model_List_of_Essential_Medicines)

# why is `int i = i` allowed in C++?

This bizarre program:

```cpp
struct Foo { explicit Foo() {}; }
int main() { Foo foo = foo; cout << "works!"; return 0; }
```

actually works! Why is this allowed? The only real use-case I know for this is
to write:

```cpp
const int ARRSIZE = 200;
int *ptr = malloc(sizeof(ptr) * ARRSIZE);
```

Still, this seems awfully dodgy. It feels like the C speficiation could allow
the use of the left-hand-side name in expression that only need *type* information
while emitting compile time errors for expressions that use the left-hand-side-name
as a *value*.


# Kakoune cheatsheet

- `/`: search for some text. `n`: go to next occurence. `Shift-n`: goto next occurence with a multi cursor.
- `Shift-X`: select multiple lines in sequence. `s`: make a multi-cursor a word in the current selection
- `space`: remove multiple cursors
- `Alt+i <key>`: select `<object>` of some type. Example: `Alt+i w`: select word.  `Alt+i s`: select sentence.
- `Shift-c`: create multiple cursor in line below
- `X`: select line.


# Assembly IDE

I've wanted to "learn assembly" properly, in the sense of write small to
medium programs to feel like a native. Scouting around for IDE's, I couldn't
find much. However, it seems like `emacs` has a rich ecosystem for
assembly! I had no idea if it's a *good* ecosystem --- my experience with
`emacs` has been hit and miss. I decided to take the dive.

- [`http://ref.x86asm.net/`](http://ref.x86asm.net/)
- [`nasmshell`](https://github.com/fishstiqz/nasmshell)
- [`nasm-mode`](https://nullprogram.com/blog/2015/04/19/)
- [`x86-lookup`](https://nullprogram.com/blog/2015/11/21/)
- [blog post](https://vishnudevtj.github.io/notes/assembly-in-emacs)
- [link to volume 2](/https://software.intel.com/content/www/us/en/develop/download/intel-64-and-ia-32-architectures-sdm-combined-volumes-2a-2b-2c-and-2d-instruction-set-reference-a-z.html)
- [Link](https://software.intel.com/content/www/us/en/develop/articles/intel-sdm.html)
  to general page with download link called as Intel 64 and IA-32 architectures software
  developer's manual combined volumes 2A, 2B, 2C, and 2D: Instruction set reference, A-Z.
- [`cgasm`](https://github.com/bnagy/cgasm) to quickly lookup assembly.

# Cohomology is like holism

A shower thought, but Cohomology is indeed like holism. It describes precisely
how the whole is greater than the sum of its parts, in terms of capturing a
"global defect" that is oftentimes "locally trivial".

# Flows (TODO)

- [Srinivas Devdas: Flows](https://www.youtube.com/watch?v=VYZGlgzr_As)

#### Canonical Transformation

- No self loops.
- No loops of the form `s -> u -> s`. (ie, no 2-vertex loops).
- This allows us to conflate "positive flow" and "net flow".

#### Notation: Net flow / flow

- A flow on $G$ is a function $f: V \times V \rightarrow \mathbb R$ such that
  $f(u, v) \leq c(u, v)$ for all vertices $u, v$.
- **Flow conservation**: for all vertices $u$, $\sum_v f(u, v) = 0$.
- **anti-symmetry**: $f(u, v) = -f(v, u)$.

#### Implicit summation notation

The value of a flow $f$ denoted as $|f|$ (cardinality of $f$), is denoted as:

$$
|f| \equiv f(s, V) = \sum_v f(s, v)
$$

#### Properties of flow

- $f(X, X) = 0$. $f(a, a) = 0$ because self loops are not allowed. for two
 different vertices, we're going to get $f(a, b) + f(b, a) = 0$ by skew symmetry.
 In general, $f(X, Y) = -f(Y, X)$.
- $f(X \cup Y, Z) = f(X, Z) \cup f(Y, Z)$ if $X \cap Y = \emptyset$.

#### Theorem: $|f| equiv f(s, V) = f(V, t)$

Recall that $|f| = f(s, V)$. We want to show that $|f| = f(s, V) = f(V, t)$.
So whatever gets pushed out gets pushed in.

$$
\begin{aligned}
&|f| \equiv f(s, V) \\
& f(s, V) + f(V - s, V) = f(V, V) = 0 \\
&  f(s, V) = f(V - s, V) \\
&  f(s, V) = f(V - s - t, V) + f(t, V) \\
&  f(s, V) = f(t, V) - f(V - s - t, V)\\
& [\text{any vertex in $V - s - t$ is an intermediate vertex, which has 0 net flow}] \\
&  f(s, V) = f(t, V) - 0 \\
&  f(s, V) = f(t, V) \\
\end{aligned}
$$

#### Cut:

A partition of the network into two parts, such that the source is in one
part and sink in the other. $(S, T)$ is a cut of a flow network $G$ is
a partition of $V$ such that $s \in S, t \in T$. If $f$ is a flow on $G$
then the flow across the cut is $f(S, T)$.


#### Capacity of a cut and its relationship to flow

$$c(S, T) = \sum_{s \in S, t \in T} c(s, t)$$
See that we only get
**positive coefficents** here. There is no "negative capacity", only "negative flow".

#### Theorem: upper bound flow across a cut

Value of _any_ flow is upeer bounded by the capacity of _any_ cut. We need
more tools to prove this, as this is basically max-flow-min-cut

#### A different characterization of flow value

Lemma: for any flow $f$ and any cut $(S, T)$ we have that $|f| = f(S, T)$.
It's because we have the source on one side, and the sink on the other side.
That gives us the flow! Everything else cancels by conservation.

$$
\begin{aligned}
&f(S, T) = f(S, V) - f(S, S) \\
&f(S, T) = f(S, V) - 0 \\
&f(S, T) = f(s, V) + f(S - s, V) \\
\end{aligned}
$$

As $S - s$ does not contain $t$, by flow conservation, we must have that $f(S - s, V) = 0$.
Thus we get:

$$
\begin{aligned}
f(S, T) = f(s, V) = |f|
\end{aligned}
$$

So, I can know the capacity of any cut $(S, T)$ bounds the flow of the network!
So if I go look at the min-cut, then I can bound the max flow. We don't know
how to find these min-cuts. That's what we'll need to figure out.

#### Residual network

Network that points us to locations with leftover capacity where we can
push flow. $G_f(V, E_f)$ contains all those edges that have positive (greater than zero)
residual capacity. Edges in $E_f$ admit more flow. If $(v, u) \not \in E$, then
$c(v, u) = 0$, but $f(v, u) = -f(u, v)$. So we will have extra edges in the
residual network that don't exist in the original network.

If I have a flow $-1$ due to a back-edge with capacity $0$, I can in fact
send more flow to make it $0$! So I can have "back edges" in the residual network
for edges whose flow has to shrink.

#### Augmenting path in $G_f$

> **Sid question:** A path from $s$ to $t$ in $G_f$. Why does the existence of
> an augmenting path in $G_f$ actually mean that we can increase the flow? even
> when we have "back edges"? **Sid answer**: Because at the end of the day,
> we are picking a path from $s$ to $t$ which tells us how to change our flow
> in a way that we still respect capacity constraints.


# Amortized analysis

- [Erik Demaine: amortization --- amortized analysis](https://www.youtube.com/watch?v=3MpzavN3Mco)

#### Table doubling
- Expected cost of hash lookup: $O(1 + n/m)$ where $n$ items in table of size $m$
  ($n/m$ is the load factor)
- Total cost for $n$ insertions: $2^0 + 2^1 + \dots + 2^{\log n} \simeq O(n)$.
- Amortized cost per operation is $O(1)$.

#### Aggregate method

We do some sequence of $k$ operations. Measure the total cost of the $k$
operations and divide by $k$. This **defines the amortized cost** (Weak definition).

#### Generalized definition (amortized cost)

- assign **some cost** for each operation, called the amortized cost, such that it
  "preserves the sum" of the cost for all operation sequences `op[i]`.

$$
\begin{aligned}
\sum \texttt{amortized-cost}(op[i]) \geq \sum \texttt{real-cost}(op[i])
\end{aligned}
$$

-  The cost that obeys this inequality is called as the **amortized cost**.


#### 2/3 trees:

- `O(1)` to create
- `O(log n)` to insert  (amortized)
- `O(0)` to delete? (amortized) We can bound the deletion cost by the insertion cost,
  because we can't delete more items than we have inserted! We can bound the
  **delete cost** by the **insert cost**.

- `c` creation time, `i` insertions, `d` deletions.
- Let $n^\star$ be the largest size of the tree we've encountered in this
  sequence of operations. This way, we are really bounding the worst case.
- The real cost is $(c  + i \log n^\star + d \log n^\star)$. Let's try to show
  an amortized bound with `O(0)` to delete!.

$$
\begin{aligned}
&O(c  + i \log n^\star + d \log n^\star) \\
&= O(c + (i + d) \log n^\star) \\
&[\text{$d \leq i$ since we can delete at most number of items}] \\
&\leq O(c + 2i \log n^\star) \\
&\leq O(c + i \log n^\star)
&\leq O(c + i \log n^\star + 0d)
\end{aligned}
$$

#### Accounting method

Define a time bank account. An operation can store time credit in that bank account.
Bank account must always have **non-negative** time balance. Performing operations
costs time. So we can either directly pay for operations, or we can pull money
from the time bank account. We can pay for time using the stored credit in the
bank.


##### Sid note

On the whole I always find this confusing; Why would I have a bank account
if I can also simultaneously pay with an infinite amount of money? So I prefer
to think of it as me having (1) an infinitely large, slow, reservoir of gold, (2)
a quick cache of gold [which replaces the "bank"]. To pay for an operation,
I can only access money from my quick cache, because pulling money from my slow
reservoir is slow. I can transfer money from my infinitely large reservoir
to my quick cache of gold. The amortized method calculates the total amount of
gold that was pulled from the reservoir and stored into the cache.
We might have leftover gold in the quick cache (upper bound).
We can't have "negative gold" in the cache.
We define the **amortized cost** to be the total number of gold coins
**pulled out of infinite reservoir** by an operation.


#### Accounting example: 2/3 trees

When we insert, I pull $2 \log(n^\star)$ from my reservoir. I use $1 \log(n^\star)$
to pay for the insertion, and keep a reserve of $\log(n^\star)$ in the bank.
Then when we delete an element, we use the $\log(n^\star)$ extra we had kept
in the cache from the insert.

##### Better bounds: removing the star

We want to say that we pay $\log(n)$ for insert and delete
where $n$ is the size of the tree when we perform the insert or delete.

Per insert, we pull in two gold coins worth $\log(n)$ from the reservoir
into the cache. When we delete, we use the $\log(n)$ in the cache from
the money that was withdrawn when we created that element. See that the $n$
changes as the size of the data structure changes.

#### Table doubling via accounting

- When we insert a item into a table, withdraw $c + O(1)$ value from the reservoir.
  Keep gold coin worth $c$ that was in the cache _on the item that was inserted_.
  So imagine a real gold coin worth $c$ floating above the item.

- When we double the size of the table, use up as many old coins as possible,
  and then withdraw the rest of the cost from the infinite gold reservoir. Also
  withdraw to keep coins on the newly inserted items.

- So by the time we double, half of the elements have coins, other half don't.
  At the end, I'm going to have $n/2$ coins. The amortized cost of **doubling**
  is going to be $O(n) - cn/2$ which is going to be zero if $c$ is large. since I
  will have $cn/2$ coins in my cache of gold.

- Insert costs $O(1 + c) = O(c)$ since we need to pull out those many coins from
  the infinite gold reservoir.


#### Charging method

Time travel/blame the past for your mistakes. We allow operations to charge
their cost retroactively to their past (not to their future!). An operation
can withdraw more value that it immediately needs from the infinite reservoir
into the gold cache, and it keeps it "for itself" for future-itself.

- amortized cost = total gold pulled out of infinite reservoir.


#### Charging example: Table doubling

After we double the table, the table is half-full, we need to perform $n/2$
insertions to get the table to be full. When we double the array next time,
we charge the doubling to the insertions since the last doubling!
There are $n/2$ items since the last doubling (I had `2` items, I doubled to `4` items,
so there are `n/2` new items. Now I want to double and add `4` more items).
I have a cost of `O(n)` for the doubling. So I can charge `O(1)` cost to
all the new items since the last doubling. Note that I only charge once; after
I've charged items, I've doubled the array, so they are now "old".


#### Potential method (Most powerful) / Defining karma:

We define a potential function $\phi$ mapping a **data-structure-configuration**
to an natural number pile of gold coins. It tries to measure how bad the datastructure
is right now. We can pull money out of the pile of money in the potential.
Amortized cost is the actual cost plus the change in the amount of money in the
data structure configuration after and before:

$$
\texttt{amortized(op)} = \texttt{real(op)} + \phi(\texttt{after(op)})  - \phi(\texttt{before(op)})
$$

Adding up all the amortized costs, the sum telescopes, giving us

$$
\texttt{amortized(total)} = \texttt{real(total)} + \phi(\texttt{end}) - \phi(\texttt{begin})
$$

- We really like to have $\phi(\texttt{begin}) = 0$.



#### Potential example: binary counter

flipping a bit is $O(1)$. How much will increment cost? An increment is going
to cost 1 + the number of trailing ones. We want to make this **constant**.


- What is making this bad? the number of trailing ones? Consider `11110` which has
  zero trailing ones.  If I increment it I get `11111`, which has 5 trailing ones.
  So I need to pull on 5 gold coins, which is `O(n)`. No good, I want `O(1)`.
  Though this is the natural thing to try, it doesn't quite work.

- Rather, we can define $\phi$ to be the total number of 1 bits. Whenever I increment,
  at maximum, I can add one `1`. If a number has `t` trailing bits, then on incrementing,
  I destroy `t` one bits, and add a single one-bit. eg: `0110 + 1 = 1000`.

- The amortized cost is: `1 + t` (actual cost). The change
  in potential is: `t - 1` [lost `t` 1s, gained `1` one]. So the amortized cost is
  total cost - change in potential, which is `1 + t - (t - 1) = 2`, a constant.



# Shelly Kegan: death --- Suicide and rationality (TODO)

How does the fact that we will die affect the way we live? previous
chapter! The fact our mortality raises the question of whether or not
we should put an end to our life. It's the extra feature --- the variability
of death, the fact that we can control how long we live, and thus we face
the possibility of ending our life earlier than it would otherwise. Under what
circumstances is it a good thing to do?

You must be either crazy or immoral is the knee jerk. The very first thing
to do is to distinguish questions of rationality from morality.

#### Rationality of suicide

1. When if ever would it be true that you are better off dead?
2. Assume that the answer to the first question is "under circumstance X,

   you would be better off dead", can you trust your judgement that this is one
   of those cases X?

In those circumstances that life is terrible, you can't think clearly. So perhaps
you ought not attempt to make "rational decisions" under duress. Non existence
is not a state because it depends on existence.

Dying would be bad because it would deprive us of the good things in life ---
the deprivation requirement.  If we believe in the two state requirement, how
can we say this?  The two state argument can't even tell us that it's
better off to be alive for the happiest person! So the two state requirement
**is not a genuine requirement**. We simply have to say that the life you would
have had is a great life; I don't need to say anything about how death is going
to be inferior. The "loss of a good state" is enough, without needing to know
what we are transitioning _into_.

But if so, we can flip the argument by symmetry. If a person's life was full
of suffering and misery and disappointment, then for their life to go
longer would be bad.

What goes into making someone's life worthwhile? people disagree about the
ingredients of the best kind of life. Going back to hedonism (add all pleasure,
subtract all pain), if this number comes out negative, then your life is not
worth living. The longer you live, the more the balance shifts to the negative
(say).

Is life itself worth having? Neural container theory: life is a container
in which good/bad is filled up. Valuable container theories: the very fact
that you are alive gave you some positive value. Fantastic continer theories:
doesn't matter how bad the contents get, even so the grand total is still
positive. What's so incredible about life itself? They argue that being
alive itself is valuable. But most people don't really mean life, they mean
life as a person. For example, they would not agree that being alive as a
blade of grass is a "good life".


What about a life where the person's functioning has decayed, but they can still
feel pain? In that case perhaps, their life's quality can degrade.

We can probably find sympathy with the perspective that here on out, their
life is going to be net negative; someone who has terminal cancer and is in
great pain.

There could be a person where they're suffering from a degenerative diesease,
but are still able to think and have a life worth living while slowly losing
motor control. One day there comes a time when their life is not worth living,
but by that point, they don't have control over their body.

It's easy to mistake a low point with a global minima; Even if life is
*less worth living* than you hope it would be, it might feel terrible in
the position.

#### Deciding under uncertainty



##### Could it ever be true that you're better off dead?

The very claim that "jones would be better off dead" can't make any sense. In
order to make comparisons we need to be able to talk about states before
and after. Call this the two state requirement.

#### Morality of suicide

- [Shelly Kegan: death, 24. Suicide, Part 1](https://www.youtube.com/watch?v=MajfZIyHP8U&list=PLEA18FAF1AD9047B0&index=24)

# Sam harris and jordan peterson: Vancouver 1 (TODO)

> Is there a difference between religious and non-religious totalitarian states?
> Yes, dogma is the commonality. In the case of stalin / north korea, they
> are almost religions that are not branded as "religions". ~ Sam

> the problem with dogmas is that they do not allow revision. The moment someone
> has a better idea you have to shut it down. ~ Sam

> Free speech elevates error correction of dogmas above dogmas. So
> Free speech must be on the pinnacle in the hierarchy of values ~ Peterson

> The only problem with the religion is the dogmatism. I've got no problem
> with the buildings and the music and ... ~ Sam Harris.

> What is the phenomenology of spiritual experience? That phenomenology is
> real! This phenomenology seems to confirm the dogma.

> The core element of tribal alliance is independent of the religious
> substrate? Religion can allow clearly good people who are not captured
> by tribalism are able to perform atrocities. This suffering is not from a
> "ape like" urge. If you buy the claim that quran is the perfect word, then
> human rationality is bounded pathologically  which leads to worrying
> outcomes.

> Christians were the ones in egland who were against slavery ~ Petersen
> Yes, because they were the only ones around, so they must have done everything
> then ~ Sam
> Don't forget that the christians *used their christian faith* as an argument
> against slavery ~Petersen
> Well then it's unfortunate that they were on the losing side of an argument.
> If only the bible had said "don't keep slaves" imagine how much easier their
> movement would have been ~Sam.

> Rise of postmodern interpretations of literature. Take a complex narrative,
> there are many ways of interpreting it. For example, consider a movie with
> a twist at the end. The twist changes the emaning of the entire movie. So while
> the bible may contain, sentence by sentence, things that are "just wrong"
> from a modern lens, perhaps it's not so when viewed holistically.
> Everything in a narraitve is conditioned on the entire text. While you
> may argue that some sentences in the bible are so horrific that it's impossible
> to use context to massage them, you have to give the devil his due. The
> Christian bible is a narrative.

> OK, what does this do to Moses' laws of war and doctrines?


> the notion of revelation and prophecy destroys a whole bunch of
> soceity. I've read to the end of the book, it's scary to the end as well!

> there is an idea in the bible, that things are always going to be falling
> apart, there is an apocalyptic crux to everything touched by humanity.
> Hero is born in the darkest point in the journey. When things fall apart,
> that is the time of the hero.

> You can read into any story psychological insights ~ Sam. But you can do that
> with any set of facts too ~ Peterson. This why fundamentalim has an edge
> over modern theology. Modern theology concedes that we can't read it literally.
> But the more you get away from the literal you can broadcast whatever you want.

> This notion that redemption is to be found in truthful speech is embodied
> as a person. you want to ground values in something that is true. But the
> problem is that i can't see how you can inerpret the world of facts without
> an a priori structure.

> Kant identified time and space as a priori intuitions. I claim that stories
> are another kind of a priori intuition. You can write down stories of utpoia
> and dystopia; When you do, you're already two thirds your way to heaven and
> hell. Why not go all the way?

> Literal versus metaphorical truth. There are some truths that are literally
> false but if you behave as if they were true you come out ahead.

> Imagine a universe where every possible mind is tuned to the worst possible
> experience that they can. If anything is bad, that's bad. If the word bad
> is going to mean anything, it's bad. I claim that this is a "factual claim".
> Every claim we make about anything, turtles all the way down, gets us to
> something that's bedrocked on intuition [Perhaps even math, in terms of
> the axioms _we choose_? Mh, I'm not very convinced, but sure]. If we are
> going to use the word bad and good, there will be an implicit acknowledgement
> that the worse possible misery for everyone is *bad*. It's *built in*. ~ Sam
> Jordan disagrees that this is a factual claim.


> Why did people do the worst things

- [Sam harris and jordan peterson: Vancouver 1](https://www.youtube.com/watch?v=jey_CzIOfYE)

# Correctness of binary search


#### Closed-closed intervals


```cpp
// search index i in interval [l, r] for value `val`.
// returns i such that xs[i] = val.
// return -1 otherwise.
int binsearch(int l, int r, int val, int *xs) {
  while(l <= r) {
  int mid = (l+r)/2;
  // l <= mid < r
  if (xs[mid] == val) {
    return mid;
  } else if (xs[mid] < val) {
    // go to higher range, this is too small.
    // have already considered mid.
    // l <= mid => l < mid+1
    l = mid+1; // [l, r] -> [mid+1, r]
  } else {
    // go to lower range, this is too larger.
    // have already considered mid, so go to mid-1.
    // mid < r => mid-1 < r
    // [l, r] -> [l, mid-1]
    r = mid -1;
  }
  return -1;
}
```



#### Closed-open / half-open intervals

```cpp
// search in interval [l, r) for value `val`
int binsearch(int l, int r, int val, int *xs) {
  // [l, l+1) = { l }
  if (r == l + 1) { return l; }
  int mid = (l+r)/2;
  if (xs[mid] <= val) {
    return binsearch(l, mid, val, xs);
  } else {
    return binsearch(mid, r, val, xs);
  }
}
```

- We have `(l <= mid < r)` since floor division of the form `(l+r)/2` will pull values "downward".
- Furthermore, if `r = l + 1` we end the recursion.
- Thus, we are guaranteed that we will have that `r >= l + 2`.
- Hence, `mid = (l+r)/2` will be larger than `l` as `r >= l + 1`. We see this from the algebra `m = (l + r) >= (l + l + 2)/2 >= l + 1`.
- So we have `l < l+1 <= mid < r`. This establishes a "gap" `l < mid < r`, which is possible since all the smallest non-trivial interval `[l, r)` we
  consider will be `[l, l+1, l+2)` (recall that `r=l+1` is the base case).
- Thus, we have that: `l` is to the left of `mid=l+1` is to the left of `r>=l+2`.
- So, the intervals `[l, mid)` and `[mid, r)` will be smaller, as we cleanly "separate" out `l`, `mid`, and `r`.

# `readlink -f <path>` to access file path

To get the full path of a file, use

```
$ readline -f file
/path/to/file
```

This is useful to `scp`/`rsync` stuff.

# rank/select as compress/decompress

I haven't found a good naming convention so far for describing order
statistics. I'm taking about the common implementation:

```cpp
vector<int> xs(n);
vector<int> order2ix(n);
for(int i = 0; i < n; ++i) { order2ix[i] = i; }

sort(order2ix.begin(), order2ix.end(),
     [](int i, int j) {
        return make_pair(xs[i], i) < make_pair(xs[j], j);
     };
```

where `order2ix[o]` gives us the element with that order statistic. So,
`order2ix[0]` contains the smallest element, `order2ix[n-1]` contains the
largest element, etc. I've previously tried the naming conventions:

#### rank/select

`rank: ix -> order`, `select: order -> ix`. The pro of this is that it
uses the [rank/select](http://bitmagic.io/rank-select.html) naming convention.
This leads into the Galois connection aspect of it, but is otherwise not so
useful.
#### order2ix/ix2order

The signatures are `order2ix: order -> ix`, `ix2order: ix -> order`. This uses
the [order statistic](https://en.wikipedia.org/wiki/Order_statistic) naming
convention, and thereby makes it clear what the query is: you tell me the
kth order, I give you the index in the array in `order2ix(k)`. Alternatively,
you tell me the index `i`, and I'll tell you its order statistic in `ix2order(k).`


However, I found implementing this kind of odd. In particular, I need to
pause for a second and think about what maps to what in the `ix2order[order2ix[o]] = o;`.

```cpp
vector<int> xs(n);
vector<int> order2ix(n);
for(int i = 0; i < n; ++i) { order2ix[i] = i; }

sort(order2ix.begin(), order2ix.end(),
     [](int i, int j) {
        return make_pair(xs[i], i) < make_pair(xs[j], j);
     };

// REVERSE BIJECTION
vector<int> ix2order(n);
for(int o = 0; o < n; ++o) { ix2order[order2ix[o]] = i; }
```

For me, the major source of disconnect is that this "order" feels somewhat
disconnected from the original array `xs`. So I feel like I'm trying to reason
about these three

- The indexes `0, 1,..,n`
- The orders `0th,1st,2nd,..(n-1)th`
- The array values `xs[0],xs[1],xs[2],..xs[n]`

and it's unlclear to me how the two arrays `order2ix` and `ix2order`
relate to each other.

#### `compressed`/`decompressed`:

Now for the new convention that I hope works better: `compressed`/`decompressed`:

The idea is that `compressed` maps the original numbers to their compressed variants.
So it's going to have a signature `compressed: ix -> smalluniv`, where it
compresses the element `xs[i]` into `[0..n-1]`. `decompressed` is the inverse
function, which takes a number in the smaller universe, and returns its
index in the original array. So we have `decompressed: smalluniv -> ix`.


##### Why I like this better

I feel this convention is superior, because it's intuitive to me at a glance
as to what `compressed`/`decompressed` do and why they should be inverses.  I feel
it also matches **the deep reason** for why kth order statistic exists: it
lets us perform universe reduction, to go from a large space of a total order
to a small space `[0..(n-1)]`.

Furthermore, the very **name** implies that
`compressed` is the compressed version of _something_ (the original array `xs`)
and that `decompressed` is the decompressed version of _something_
(the compressed universe `[0..(n-1)]`). This makes it clear how they're reated
to the original array linguistically, which I quite like.


# Remembering Eulerian and Hamiltonian cycles

I used to keep forgetting the difference. Here's how I remember it now.
We know that an _euler tour_ always exists for a tree. Indeed, it's
a [handy data structure](https://en.wikipedia.org/wiki/Euler_tour_technique)
that can be used to convet LCA (lowest common ancestor) into RMQ(range minimum query).

So, the "Euler tour" must exist for a tree. See that when we perform a tour
on the tree, we **definitely** walk a vertex twice (once when entering, once when
exiting). It seems like we walk the (undirected) edges twice as well.
However, if we consider the edges as **directed edges**, then we're only walking
the edges once.

- So an euler tour must correspond to a tour where we walk over each edge
  exactly once.
- A hamiltonian tour must (by complementarity) correspond to a tour where we
  over each vertex exactly once.

# Nice way to loop over an array in reverse

```cpp
const double n = sizeof(spheres) / sizeof(Sphere), inf = t = 1e20;
for (int i = int(n); i--; ) { } //chad
for (int i = n-1; i >= 0; i--) { // simp
```


# Dynamic Programming: Erik Demaine's lectures

I realized I'd never bothered to ever formally learn dynamic programming,
so I'm watching Erik Demaine's lectures and taking down notes here.

## DP 1: Fibonacci, shortest paths

- [Video lecture here](https://www.youtube.com/watch?v=OQ5jsbhAv_M&list=PLcDimPvbmfT8qAxD6JH_kmXiQwTNcoK78)

1. DP ~= careful brute force.
2. DP ~= subproblems + "recurse"


#### Fibonacci

```
F(1) = F(2) = 1; F(n) = F(n-1) + F(n-2)
```

##### Naive:

```py
fib(n):
  if n <= 2: f = 1
  else f = fib(n-1) + fib(n-2)
  return f
```

EXPONENTIAL time! `T(n) = T(n-1) + T(n-2) + O(1)`. Since it's the fibonacci
recurrence, the solution is rougly $\phi^n$ where $\phi$ is the golden
ratio. Alternate, `T(n) >= 2T(n-2) ~ 2^(n/2)`

##### Memoized DP:

```py
memo = {}
fib(n):
  # vvv
  if n in memo: return memo[n]
  if n <= 2: f = 1
  else f = fib(n-1) + fib(n-2)
  # ^^^
  memo[n] = f
  return f
```

- We can think about it in terms of the recursion tree, where this allows
  us to not have to recompute some of the data.
- The alternative way of thinking about it is that there are **two ways**
  of calling `fib`: the first time, it's non-memoized, which recurses. Every
  other time, we're doing **memoized calls** that are constant time.
- The number of non memoized calls in `n`. These we have to pay for. The non
  recursive work per call is constant.
- Therefore, the running time is linear! Linear because there are `n` non
  memoized calls, and each of them cost **constant time**.
- In general, in DP, we _memoize_  (remember) solutions to **subproblems** that
  help us solve the actual problem. So, `DP = recursion + memo`.
- `Running time = number of different subproblems x time per subproblem`.
  When we measure **time per subproblem**, we ignore recursive calls!
  (don't count recursions).

##### Bottom up DP algorithm

```py
fib = {}
 -- | some thought for the loop
for k in range(1, n+1):
  if k <= 2: f = 1
  else: f = fib[k-1] + fib[k-2]
  fib[k] = f
```

Order based on any topo sort of dependency DAG. From the bottom up perspective,
we can decide how much we need to store based on how much state we need.

```
  *------------*
  |            v
f(n-2) f(n-1) f(n)
          |    ^
          *----*
```


#### Single Source Shortest paths (`s-v` path)

- Tool to find answers: *guessing*. Suppose you don't know it. how do you find the
  answer? guess! Don't try any guess, try *all* guesses! (then take the best one).
- DP = recursion + memoization + guessing.


There is some hypothetical path from `s` to `v`. We don't know what the first
edge of this hypothetical path is, so we guess. We try all of the paths from
`s->s'`. This changes `s`, but we really care about **single source** shortest
path. So rather, we choose to guess `v`. We guess the last edge `u? -> v`.
Recursively compute the path from `s` to `u?`, and then add the path to `v`.

```
\delta(s, v) = \min_{(u,v) \in E} \delta(s, u) + w(u, v)
```

Subpaths of shortest paths are shortest paths! Memoize to make it fast? Why
is it faster on memoization?


```
*---a----*
v   ^    v
s   |    w
|   |    |
*-->b<---*
```

```
δ(s, w)
  δ(s, a)
     δ(s, b)
       δ(s, s)
       δ(s, w) <- INFINITE
```

- Infinite time on graphs with cycles.
- For a DAG, it runs on V+E. Number of subproblems = `V`. Time we spend per
  subproblem at a vertex is the number of incoming edges.
  we can't take product, because the time per subproblem can vary wildly. So we restate our "time formula" as

```
total time = sum over times of all subproblems (modulo recursion)
```


This gives us:


```
total time = sum indeg(v) + O(1) = O(E) + O(1)
```

- **LESSON LEARNT: subproblem dependencies should be acyclic!**

- Claim: can use same approach for graphs! Explode a cycle over time. This makes
  any graph acyclic.

> **Sid question**: Can we derive Djikstras using the same "cycle explosion"
> trick?

We define $\delta_k(s, v)$ to be weight of shortest path that uses at most `k` edges.


```
\delta_k(s, v) = \min_{(u, v) \in E} \delta_{k-1}(s, u) + w(u, v)
```

We've increased the number of subproblems. We know that the longest path
possible can have $|V| - 1$ edges. So the `k` parameter goes from `[0..|V|-1]`
while the vertex `v` can be any vertex. Per vertex `v` we spend `indeg(v)` time.
So we get the total recurrence as:

$$
\begin{aligned}
&\sum_{(k \in [|V|-1], v \in V)} T(k, v) =  \\
&\sum_{k \in [|V|-1]} \sum_v indeg(v) = \sum_{k \in [|V|-1]} E = VE
\end{aligned}
$$

##  DP 2: Text Justification, Blackjack

- [Video Lecture](https://www.youtube.com/watch?v=ENyox7kNKeY&list=PLcDimPvbmfT8qAxD6JH_kmXiQwTNcoK78&index=2)

#### 5 "easy" steps to a DP

1. Define subproblems; analysis - number of subproblems
2. Guess (part of solution); analysis - number of choices for the guess
3. Relate subproblem solutions [with a recurrence]; analysis - time per subproblem (ignoring recursion)
4. Build an algorithm: [recursion/memo, or tabling]; check recurrence is acyclic
5. solve original problem;  total time: total time across all subproblems (ignoring recursion).
   In simple cases, total time = number of subproblems x time per subproblem.
6. Check that the original problem actually gets solved!


#### Recap: Fibonacci
1. subproblems: `F(1)...F(n)`
2. guess: nothing
3. relate: `F(n) = F(n-1) + F(n-2)`; `O(1)` time
4. F(n). constant time to find

#### Recap: Shortest path
1. subproblems: $\delta_k(s, v)$. $V^2$ subproblems.
2. guess: last edge; edge into $v$.
3. relate: $\delta_k(s, v) = \min_u \delta_{k-1}(s, u) + w(u, v)$; `indegree(v)` time
4. <blank>
5. $\delta_{v-1}(s, v)$ for all $v$. This takes $\Theta(V)$.

#### Text Justification

split text into "good lines". can only cut between word boundaries. Text is
a list of words. `badness(i, j)`: how bad is it to use `words[i:j]` in a line.
They may fit, or they may not fit. If they don't fit, then badness is `∞`.
Otherwise, it's going to be `(pagewidth - total width)^3`.
We want to minimize the sum of badnesses of the lines.

1. subproblems: the hard part! exponential: Guess for every word, whether a line
   begins or not. What is the natural thing to guess? guess how long the first
   line is / guess where the second line begins. After I guess where the second line
   is, I now have the remaining words to text justify. So the subproblems are
   going to be suffixes of the array: `words[i:]`. If we have `n` words, we have
   `n` suffixes. We're going to only remember *one line* [forget the past!],
   not *all the lines!* [this is exponential!]
2. Guess: where to start the second line. If we are at location `i`, there are `n-i`
   choices which we will think of as `O(n)`.
3. Recurrence: $dp[i] = \min{i+1 \leq j \leq n} \texttt{badness}(\texttt{words[i:j]}) + dp[j]$.
   Time per subproblem is `constant x [i+1..n]` which is `O(n)`.
4. Check recurrence is acyclic/topo order: `n, n-1, ... 1`
5. Total time: `number of subproblems x time per subproblem = O(n^2)`
6. Original problem: `dp[0]`.


#### Parent pointers

Remember which guess was best. Find actual solution, not just the cost of the

##### fiat

> fiat lux.

Let there be light
solution.


n suffixes | exp many sybsets. dont need to know history!





#### Blackjack

> whatever, I don't particularly care about the game

## DP 3: Paranthesization, Edit distance,  knapsack

#### Sequences

Good choices of objects to perform DP on:

- Suffixes: `x[i:]` for all `i`. `O(n)`.
- Prefixes: `x[:j]` for all `j`. `O(n)`.
- Substrings: `x[i:j]` for all `i` and `j`. `O(n^2)`.

#### Parenthesiztion

optimal order of associative expression.: `A[0] . A[1] ... A[n-1]`. Order
matters for matmul!
- What should we guess? There are exponentially many parenthesizations!
  Guess the outermost/last multiplication. Ie, we want to know:

```
(A[0] ... A[k-1]) * (A[k] ... A[n-1])`
```

- We can't just use prefixes and suffies, because when we recurse into
  `A[0]...A[k-1]`, we're going to get splits of the form `A[0]...A[k']`
  and `A[k']...A[k-1]`. In general, if we feel we need *both* prefixes AND suffixes, we likely
  need the full power of substrings.
- So our choice of subproblem is: `dp[i][j]` is the optimal outermost split for
  `A[i]...A[j-1]` The number of choices is `O(j-i+1) = O(n)`.

```py
dp[i][j] = min{
  for k in range(i+1, j):
    dp[i][k] + dp[k][j] + cost of (A[i:k] * A[k:j])
}
```
- Time is polynomial. `O(n)` time for subproblem ignoring recursions.
  We have `O(n^2)` subproblems (substrings). So the running time is `O(n^3)`.
- Topological order: in general, if we have prefixes, we go left to right.
  have suffixes, we go right to left. If we have substrings, we
  evaluate based on **increasing substring lengths**, since when we split,
  we get substrings with smaller lengths.

#### Edit distance
Given two strngs `x` and `y`. Find the cheapest way to convert `x` into `y`.
We allow _character edits_ to turn `x` into `y`: We can (1) insert a character
anywhere in `x`, (2) delete a character anywhere in `x`, (3) edit any character in `x`.
We have custom costs for each insert and delete.

- Can also solve longest common subsequence. `HIEROGLYPOHOLOGY`, `MICHAELANGELO`.
  Drop any set of letters from x and y, we want them to be equal. Model it as
  edit distance. Cost of insert/delete is `1`, cost of replacement is `0` if
  characters are equal, `∞` otherwise.
- We will look at suffixes of `x` and `y` at the subproblem. Subproblem is
  edit distance on `x[i:]` AND `y[j:]`. Number of subproblems is $O(|x| |y|)$.
- We need to guess! Not so obvious. Look at the first characters. What can I
  do with the first character of `x`? (1) I can replace the first characters.
  (2) I can insert the character `y[j]` into `x`.
  (3) I can delete the character `x[i]`. So we have:

1. Replace `x[i]` with `y[j]`.
2. Insert `y[j]`.
3. Delete `x[i]`.


```py
dp[i][j] = min{
  cost of replace x[i] with y[j] + dp[i+1, j+1],
  cost of insert y[j] + dp[i][j+1],
  cost of delete x[i] + dp[i+1][j],
}
```

The topological order is going to have smaller to larger suffixes.


> What I found really interesting is the offhand remark that longest common
> substring is **just edit distance** where we are allowed to only delete
> or keep characters.

#### Knapsack

List of items, each of size `s[i]` and a desire/value `v[i]`.  The sizes
are integers. We have a backpack of total size `S`. We want to choose a subset
of the items which maximize the value, and also fit into the backpack: $\sum s[i] \leq S$.


- Even though it seems like we don't have a sequence, we have a set of items
  we can put in *any* sequence. We can look at sequences of items.  At the item
  `i`, we should guess if item `i` is included or not.

```py
# v WRONG
dp[i] = ... max(dp[i+1], dp[i+1] + v[i])`
```

We don't keep track of the sizes! Rather, we choose our subproblem to be the suffix
AND the remaining capacity $x \leq S$. We have $O(n S)$ subproblems

```py
# v correct
dp[i][s] = max(dp[i+1][s], dp[i+1][s-s[i]] + v[i])
```

To be polynomial in the input, it would have to be $\theta(n \log S)$ because
$S$ is given as a number. It would not be $nS$; $S$ is exponential in the
input encoding $\log S$.


## R21: DP: Knapsack

We have `n` decisions: `d[i]` is do I take item `i`. What do we need to keep
track of? I need to know how much weight I have left. This is equivalent to
knowing the sum of the items. The edge is an arbitrary item, the weight is `-v[i]`
since we're trying to phrase the problem in terms of shortest path. The state
in the node is item I'm looking at, and weight of the items I've taken so far.


$$
\begin{matrix}
\end{matrix}
$$


#### DP4: Guitar fingering, tetris, super mario bros

A second kind of guessing. Guessing usually which subproblem to use to solve
a bigger subproblem. Another way of guessing is to add more subproblems to guess
or remember more features of the solution.

##### Mapping to knapsack

obvious solution was suffix in knapsack. So we needed to know how many units
of the knapsack we've used up; we're remembering something about the *prefix*
(but not the full prefix itself). On the other hand, in the forward direction,
we were solving more _types_ of subproblems, for varying sizes of knapsacks.

#### Piano and guitar fingering: Take 1

Given some musical piece to play: a sequence of `n` notes we want to play.
We want to find a fingering for each note. We have fingers `1` upto `f`. We want
to assign a finger to each note. We have a difficulty measure `d(p, f, p', f')`:
how hard is to transition from note `p` (p for pitch) with finger `f` to note
`p'` with finger `f'`?

- Subproblems: prefixes? suffixes? substrings? Suffixes are kind of fine. How to
  play notes `n[i:]`.
- Guess: Which finger to put on note `i`?
- Recurrence:

```py
dp[i] = min({
   for f in fingers:
      dp[i+1] + d(i, f, i+1, ?) # WRONG: don't know ?
})
```

- Add more subproblems! how to play `notes[i:]` when using finger `f` for `notes[i]`.
- What to guess? finger `g` for note `(i+1)`

```py
dp[i][f] = min({
  for g in fingers:
      dp[i+1][g] + d[notes[i], f, notes[i+1], g]
}
```

- Topological order:

```py
for i reversed(range(n)):
   for f in range(F): ...
```

- Original problem: we don't know what finger to use for `dp[0]`. So we can take
  a `min` over all fingers. `min([ dp[0][f] for f in range(F)])`


#### guitar chords:

Generalize the notion of "finger" to "finger(F) + string(S)". This gives
us $O(N((F+S)^2)) = O(NF^2S^2)$.  Multiple notes: `notes[i] = list of F notes` for
a piano.

- state: we need to know about the assignment of fingers to notes (or no note).
  So that's $(N+1)^F$. Generalize the rest.

#### Tetris

We know the entire sequence of pieces that's going to fall. For each, we must
drop the piece from the top. Also, full rows don't clear.
The width of the board is small. The board is initially emoty.
Can you survive?


The subproblems are how to play suffixes of `pieces[i:]`. We need to know
what the board looks like. If the board doesn't clear and we always drop from
the top, then all we need to know is the skyline.

```


1| ###
2| #
3|####
4|####
5|####
```

- So we also store the board skyline. We have `h` different choices for each
  column. There are `w` columns. So we have `(h+1)^w` number of choices for
  skylines. Total number of subproblems is `n.(h+1)^w`.
- Guess: what do I do with piece `i`? I can rotate it `0, 1, 2, 3` times, and the
  where to drop it. I can guess where to drop the piece. This is `4w` choices ---
  `4` for rotation, `w` for where we drop.

- Here the answer is a boolean: survive (1) or not (0). we want to survive, so
  we can just use `max` on a boolean.

#### Super Mario Bros

Recall that in the original super mario bros, if something moves out of the
screen it's lost forever; We can't move back in the old mario. We're given
the level, and a small $w\times h$ screen. The configuration of the game is
everything on the screen! Total info is going to be $c^{wh}$ where `c` is some
constant. We also need Mario's velocity, the score, and time. score can be S
big, time can be T big. The number of configurations is the product of all of
these. We also need to know how far to the right we have gone, which is another
`W`. Draw a graph of all configurations, and then use DP

## Lecture 10: Advanced DP by Srinivas

- [Video](https://www.youtube.com/watch?v=Tw1k46ywN6E&list=PLcDimPvbmfT8qAxD6JH_kmXiQwTNcoK78&index=10)

#### Longest palindromic sequence

Find palindrome inside longer word. Given a string `X[1..n]`. Find longest
palindrome that is a subsequence.

```
character
c arac
```

answer will be greater than or equal to 1 in length because a single letter
is a palindrome.

```
turboventilator
  r o   t  ator
```

- `L[i, j]`: length of longest palindromic subsequence in string `xs[i:j]` where `i<=j`.

```py
def L(i, j): # closed interval
  if i > j: return 0 # no letters
  if i == j: return 1 # single letter palindrome
  if x[i] == x[j]:
    return 2 + l(i+1, j-1)
  return max(L(i+1, j), L(i, j-1))
```
- number of subpbroblems: $O(n^2)$. Time per subproblem assuming recursion is free: $O(1)$.
  Hence, total time is $O(n^2)$.

#### Optimal binary search trees

Find most balanced BST for a set of keys. We have weights for the keys, which
are search probabilities. Find a BST T (there are exponential number of BSTs)
that minimizes $\sum_i w_i (depth_T(k_i) + 1)$. Depth of root is 0. Depth
of a node is distance from the root. This minimizes expected search cost.

##### Enumeration


We have exponentially many trees.

##### Greedy soltution / Why doesn't greedy work?

Assume the keys are sorted.
Pick `K[i]` in some greedy fashion (max.weight).
This immediately splits the set of keys into the left and right.
If we define `e(i, j)` to be the cost of the optimal BST on keys `k[i], ..., k[j]` .

```
greedy:
-------
        2|w=10
1|w=1           4|w=9
           3|w=8
```


```
optimal:
-------
         3|w=8
    2|w=10    4|w=9
1|w=1
```

##### DP

- Guess all possible root nodes. The greedy algorithm doesn't try to guess the
  root node, that's the only difference.

```py
-- e(i, j): cost of tree with keys k: i <= k <= j
def e(i, j):
  if i == j: return w[i]
  # | WRONG
  return min([e(i, r-1) + e(r+1, j) + w[r]
              for k in range(i, j+1)])
```

The weights are going to change when we increase depth, so we actually need
to add all the weights from `i` to `j`! So we write:

```py
-- e(i, j): cost of tree with keys k: i <= k <= j
def e(i, j):
  if i == j: return w[i]
  # | WRONG
  return min([e(i, r-1) + e(r+1, j) + weight(i, j)
                 for k in range(i, j+1)])
```

##### Alternating coins
Have a list of coins. We have an even number of coins.
Can only pick coins from the outside.

First player can always not lose in the game.  What the first player does
is compute `v[1] + v[3] + ... v[n-1]` versus `v[2] + v[4] + ...` which is even.
If the odd values win, the he picks `v[1]`. P2 can pick `v[2]` or `v[n]`.
P1 can pick either `v[3]` or `v[n-1]` depending on if P2 picked `v[2]` or `v[n]`.

- We now want to **maximize** the amount of money.

```py
v(i, j) = max([ range is(i+1, j) with P2 + v[i],
                range is (i, j-1) with P2 + v[j] ])
```

If we have `v(i+1, j)` subproblem with the opponent picking, we are guaranteed
that the opponent plays `min(v(i+1, j-1), v(i+2, j))`. So we can unfold this,
to get the full DP:


```py
v(i, j) = max([  min(v(i+1, j-1), v(i+2, j)) + v[i],
                  min(v(i, j-1), v(i+1, j)) + v[j],
```

##### DP: All pairs shortest paths.



# Accuracy vs precision

<img src="./static/accuracy-vs-precision.png"/>

I had a hard time remembering which is which, so here's how I do it now.
First, I think of it from a probabilistic lens, where one of them is the
mean, and the other is variance of a gaussian distribution as shown above.
We don't yet know whether accuracy is the mean or the variance.

Next, recall that it's linguistically correct to say:

> you're precisely wrong

but not

> you're accurately wrong.

Thus, we can be precise about something wrong. That is, we can
be very "precise" about "hitting the wrong target". So, precision ought
not care about the *true value*, just about *how well we hit something*.
This is exactly what the variance attempts to capture: how "spread out"
we are, or "how well we hit the mean".


The accuracy itself is the distance between the mean of our distribution and
the true reference value we want to hit.

# Why is the gradient covariant?

- [expanation of gradient being covariant in terms of the integral version](https://physics.stackexchange.com/a/127534/129278)

# Politicization of science

- [Reference](https://en.wikipedia.org/wiki/Politicization_of_science)

# Multi ꙮ cular O: ꙮ / Eye of cthulu

- [Multiocular O](https://en.wikipedia.org/wiki/Multiocular_O)

# You can't measure the one way speed of light

- [Veritasium video](https://www.youtube.com/watch?v=pTn6Ewhb27k)

# Show me the hand strategy

So, how do you surface covert-aggressions and covert-criticism?  Enter the:
Show Me The Hand Strategy The "show me the hand strategy" can be applied with
several techniques, including: Pretend you don't understand: if you don't
understand and they did want to make their point across, they will be forced to
be more direct in their aggression / offense Ask them what exactly do they
mean: you can use the broken record technique here, where you keep repeating
"what do you mean by that", "OK, but it does sound like you were trying to
criticize my work. It's OK if you do", "then, if you didn't want to criticize,
what did you mean" Go meta: explain them what they were doing, and tell them
that you prefer direct talk because "you can take it" (invite criticism into
the open), because you "expect better from them" (big judge power move), or
because "it's so much better for both" (leader-like win-win approach) Reframe
their aggression as support: nice power move and you will possibly get under
their skin when they wanted to get under yours. They wanted to hurt you, or to
harm your status, so when you reframe their attack as support, they will feel
compelled to come out in the open and be more direct


# Words that can be distinguished from letters if we know the sign of the permutation

```py
#!/usr/bin/env python3
with open("google-10000-english.txt", "r") as f:
    words = [w.strip() for w in f.readlines()]


sorted = {}
for w in words:
    wsort = list(w)
    wsort.sort()
    wsort = "".join(wsort)
    if wsort in sorted:
        sorted[wsort].append(w)
    else:
        sorted[wsort] = [w]

collisions = 0
for wk in sorted:
    if len(sorted[wk]) == 1: continue
    collisions += 1
    print(sorted[wk])
    print("---")

print(collisions, len(words), 100.0 * float(collisions) / len(words))


collisions = 0
for wk in sorted:
    collidews = sorted[wk]
    for i in range(len(collidews):
            for j in range(i+1, len(collidews))
    collisions += 1
    print(sorted[wk])
    print("---")
```

# Easy times don't create weak people, they just allow weak people to survive.

Easy times doesn't weaken the _generator_ side of things, it simply weakens
the _adverserial_ side of things allowing weak people to survive.

# Multiplicative weights algorithm (TODO)

# How to fairly compare groups

> Why is this a key argument? It’s really quite simple. Let’s say I have two
> groups, A and B. Group A has 10 people, group B has 2. Each of the 12 people
> gets randomly assigned a number between 1 and 100 (with replacement). Then I
> use the highest number in Group A as the score for Group A and the highest
> number in Group B as the score for Group B. On average, Group A will score
> 91.4 and Group B 67.2. The only difference between Groups A  and B is the
> number of people. The larger group has more shots at a high score, so will on
> average get a higher score. The fair way to compare these unequally sized
> groups is by comparing their means (averages), not their top values. Of
> course, in this example, that would be 50 for both groups – no difference!


- [Chessbase article about men v/s women in chess](https://en.chessbase.com/post/what-gender-gap-in-chess)


# Bijection from `(0, 1)` to `[0, 1]`

<img src="./static/bijection-between-closed-01-open-01.png">

# Rene Girard

- [Link where I first heard of him](https://alexdanco.com/2019/04/28/secrets-about-people-a-short-and-dangerous-introduction-to-rene-girard/)

# Noam Chomsky on anarchism (TODO)

- [Video of interview](https://www.youtube.com/watch?v=totmHrIJzK8)
- Emma Goldman Archives

#### Interview


What do we do with people who don't want to work or those with crimimal tendencies?
What do we do with people's interests, do they deserve to interchange jobs?

There would a general agreement between people who call themselves anarchists
should maximise people's abilities to fulfil their potential.

Another problem is that at any point in human history, people have not understood
what is opression. Chomsky's grandmother didn't think she was opressed while
being in a patriarchial family.

#### What is anarchism

- [What is anarchism](https://www.youtube.com/watch?v=yccBBzSHFAM)

Start with Rudolf Rocker.

> Anarchism is not a fixed social system with fixed answers, but a trend
> in mankind that drives for free unhindered unfolding

These derive from the Enlightenment. Thus institutions that constrain
such development are illegitimate unless they can justify themselves. Adam
Smith extolls the wonder of division of labour. Deeper into the book,
he argues that in any civilized society, the government must not allow division of labour
for it makes a human as stupid as they can be.

Anarchism seeks to identify structures of domination, authority, etc that constrain
human development. It then challenges them to justify themselves. If you
cannot meet the challenge, the structure should be dismantled and reconstructed
from below.

Anarchism is basically 'truism', which has the merit, at least, of being true.
It's an interesting category of principles that are universal and doubly
universal: universally accepted, and universally rejected in practice!



# Slavoj Zizek: Violence

- [Video talk at google](https://www.youtube.com/watch?v=_x0eyNkNpL0)

What does violence react to? What is the everyday texture of our lives? Ideology
in the sense of complicated networks of social, political prejudices determines
the way we functions and structures our life. What is ideology?

Donald Rumsfield, gulf war, spoke about known knows (saddam is a dictator),
known unknowns ('WMD that saddam surely had'), and unknown unknowns
('even worse WMD that saddam may have').

What about unknown knowns? Things we don't know that we know? This is ideology.
The texture into which we are embedded.

European trinity: France (revolutionary, political),
German (conservative, poets, thinkers),
Anglo saxon (liberal, economy).

Bohr had a horsheshoe above his house. 'Do you believe in it? Aren't you a scientist?'
'Of course I don't believe in it! But I was told that it works regardless of my belief in it!'.


What is ideology today? It seems very shallow, things of the form 'go achieve',
and whatnot. However, there is a lot more that is tacit.

'Interpassivity': we transpose onto the other our passive reaction. Others are
passive for us. Canned laughter on TV. Literally, the TV set laughs for you.
You feel relief as if you have laughed.

Similarly it's not that we believe. We need someone else to believe for us.
For example, santa Claus. The parent's don't believe, they do it to not let down
the kids. The kids don't believe, they pretend for presents and to not let
down the parents. The whole system of belief functions.

The first person to do this politically is the isareli prime minister
Golda Meir. When asked 'do you believe in god'. Her answer was 'no. I believe in
jewish people, and they believe in God'. But atheism is ~70% of israel.


When different cultures are thrown together (globalism) we should break the
spell of liberalism: we cannot understand each other, we don't even
understand ourselves. I don't want to understand all cultures. We need a code
of discretion. How do we sincerely politely ignore each other? We need proper
distance to treat others in a non-racist, kind manner.

He upholds that we don't even miss anything deep in this way. Do I really understand
you? Do I really understand myself?

> We are the stories we are telling ourselves about ourselves. The basic
> freedom is to tell your side of the story.

The motto of tolerance:

> An enemy is someone whose story I have not yet heard.

Living libraries, people can visit minorities and talk to them. It works at a
certain level. But it stops working at some level. Because we would not say
the same of Hitler.  'The X files insight'. Truth is _out there_. It's not
in what you are telling yourself about yourself. The story you are telling
yourself is a lie.

Two extreme examples. One from Europe, one from far east.
- Grey Eminence
- Zen at War


Corruption is prohibited officially, and it is exactly codified in a communist
country. Holidays in Japan. You are given 40 days. It's very impolite to take
more than 20 days. This creates a link between people, the link of politeness.
This is ideology. Prohibition is is prohibited to be stated publicly.

Nazi germany without glasses is 'sacrifice your country'. With glasses, it is
'do this, pretend to do this, we can have some fun, beat the jews'. Ideology
always offers you some bribery.


When hitler finishes giving a talk, the people clap. In a communist speech,
at the end of the speech, the speaker claps with the people. This is a
crystallization of the difference between fascism and communism.


'Nice to meet you, how are you?' is a sincere lie. From the very beginning
we entered into language, we enter into requiring one for whom we can
create appearances.

- [Zizek interview at BBC](https://www.youtube.com/watch?v=xN2ZGSX0cIE)

> The light at the end of the tunnel is an oncoming train

Embracing hopelessness means to accept that there are no easy solutions. We should
accept the hopelessness and start a paradigm shift.  Our tragedy is death.
Something will have to change fundamentally. We do not yet have the formula of
what to do. We can now only get ready for a global crisis.



> The problem with Hitler was that he wasn't violent enough. In the same way
> that Gandhi was more violent than Hitler, in terms of 'systemic change'.
> Hitler killed millions to save the system. Gandhi killed no one to setup
> a radical change. Change will hurt.

We tend to forget the violence of keeping things the same, and we only consider
the violence of change. Sometimes the gratest violence is to not participate.

Modi, China, Russia: Global market, Cultural narrowness.


> Polyamory is instrumental.
> True love is where you cannot be without someone else.


It is a sign of progress that some things are considered ideology. For example,
''is it right to kill?'' will be laughed at. The problem with current societies
is that we are eroding the set of things we can laugh at due to dangerous
ideas of relativism.

- [Zizek v/s Petersen](https://www.youtube.com/watch?v=lsWndfzuOc4)

Petersen: truths of the communist manifesto:

- History is to be viewed as an economic class struggle.
- Hierarchical structure is not attributable to capitalism.
- We're also in odds with nature, which never shows up in Marx.
- Hierarchical structures are necessary to solve complicated problems.
- Human hierarchy is not based on power. Power is a very unstable means of
  exploiting people.
- History comes off as a 'binary' class struggle in Marx.
- 'Dictatorship  of the proleteriat': Race to bottom of wages. The fact that we
  assume that all the evil could be attributed to the bourgouise itself
  setup the seeds for revolution.
- How will the replacement of the bourgouise happen? Why wouldn't the proleteriat
  become as or more corrupt than the capitalists?
- What makes you believe that you can take a complicated system like the free
  market and then centralize this?
- A capitalist who is running a business as a manager does add value.
- The criticism of profit. What's wrong with profit? Profit is theft is the
  marxist principle. If the capitalist adds value to the corporation, then they
  do deserve profit. Profit sets a constraint on wasted labour. There are forms
  of stupidity you cannot engage in because the market will punish you for it.
- 'The dictatorship of the proleteriat' would become hyper-productive. How?
  The theory seems to be that once we eradicate the profit motive and the
  bourgouise allows them to become hyper productive.
- We need hyper productivity for the dictatorship of the proleteriat to create
  enough goods for everyone. When this happens, everyone will engage in meaningful
  creative labour, which they had been alienated from in capitalism. Then this
  will create a utopia.
- Does this utopia really be the right utopia for everyone?
- The Dostovyeskian observation: what shallow take on people do you need to believe
  that if you hand people everything they need, they'll be happy? We were built
  for trouble. Hanging out on the beach is a vacation, not a job. We would
  destroy things just so something can happen just so we can have the adventure
  of our lives.
- Marx and Engels admit that there has not been a system that's capable to produce
  materials in excess as capitalism.

Zizek:
- The irony of how Petersen and him are both marginalized by the academic
  community.
- China today: strong authoritarian state, wild capitalist dynamics. It's managed
  to uplift hundreds of millions of people out of poverty. They want the
  Cofuscian ideal of harmonious society.
- Happiness as goal of life is problematic. Humans are creative in sabotaging
  pursuit of happiness. We have to find a meaningful cause beyond the mere
  struggle for pleasurable survival. Modernity means that we should carry the
  burden of freedom of choice.
- Never presume that your sufferring is in itself a proof of authenticity.
  Renunciation of pleasure can turn into the pleasure of renunciation.
-

# Poverty: Who's to blame?

- [Video](https://www.youtube.com/watch?v=jAaCpyuwRIw)

#### First blame countries
- Third world countries have terrible economic policies
- Administrations in third world countries are dysfunctional.
- First world countries *block* workers from immigrating for which we can blame
  first world countries.

#### Secondly blame individuals: The trifecta
- work at a stable job even if the job is not fun
- don't have kids if you can't afford it

#### Blame matters
- Blame affects wheher something is a social issue. For example, is the opioid
  epidemid a social behaviour? or should we just blame individuals?
- Blame affects who should be shamed for failing to change their
  behaviour.


#### Books to read
- Doing the best I can
- Promises I can keep

# Learn Zig in Y minutes


- imports:

```
const std = @import("std");
```


- globals:

```
// global variables.
const x = 1234;
```


- comments:

```
//! Top level comments are setup using //!
//! This module provides functions for retrieving the current date and
//! time with varying degrees of precision and accuracy. It does not
//! depend on libc, but will use functions from it if available.
```

- main:

```
pub fn main() !void {
    const stdout = std.io.getStdOut().writer();
    try stdout.print("Hello, {}!\n", .{"world"});
    // Comments in Zig start with "//" and end at the next LF byte (end of line).
    // The below line is a comment, and won't be executed.
```

- ints:

```
    // integers
    const one_plus_one: i32 = 1 + 1;
    print("1 + 1 = {}\n", .{one_plus_one});
```
- floats:

```
    // floats
    const seven_div_three: f32 = 7.0 / 3.0;
    print("7.0 / 3.0 = {}\n", .{seven_div_three});
```

- bools:


```
    // boolean
    print("{}\n{}\n{}\n", .{
        true and false,
        true or false,
        !true,
    });
```

- optionals:


```
    // optional
    var optional_value: ?[]const u8 = null;
    assert(optional_value == null);

    print("\noptional 1\ntype: {}\nvalue: {}\n", .{
        @typeName(@TypeOf(optional_value)),
        optional_value,
    });

    optional_value = "hi";
    assert(optional_value != null);

    print("\noptional 2\ntype: {}\nvalue: {}\n", .{
        @typeName(@TypeOf(optional_value)),
        optional_value,
    });
```

- errors:

```
    // error union
    var number_or_error: anyerror!i32 = error.ArgNotFound;
    print("\nerror union 1\ntype: {}\nvalue: {}\n", .{
        @typeName(@TypeOf(number_or_error)),
        number_or_error,
    });
    number_or_error = 1234;
    print("\nerror union 2\ntype: {}\nvalue: {}\n", .{
        @typeName(@TypeOf(number_or_error)),
        number_or_error,
    });
    // It works at global scope as well as inside functions.
    const y = 5678;
}

```



- Top level ordering:

```
// Top-level declarations are order-independent:
pub fn g() { f(); }
pub fn f() {}
```

- strings:

```
test "string literals" {
    const bytes = "hello";
    assert(@TypeOf(bytes) == *const [5:0]u8);
    assert(bytes.len == 5);
    assert(bytes[1] == 'e');
    assert(bytes[5] == 0);
    assert('e' == '\x65');
    assert('\u{1f4a9}' == 128169);
    assert('💯' == 128175);
    assert(mem.eql(u8, "hello", "h\x65llo"));
}
```


# The algebraic structure of the 'nearest smaller number' question

The [nearest smaller number](https://cses.fi/problemset/task/1645) problem
can be solved by using a stack along with an observation of monotonicity.
This is explained in the [USACO guide to stacks in the Gold section](https://usaco-guide.netlify.app/gold/stacks).

What I find interesting is that we need a *stack*. Why does a stack show up?
Stacks are usually related to a DFS on some appropriate object. What's that object?
And can we gain insight into when we need to use a stack based on this?


The idea is that we are trying to construct the Hasse diagram of the
original array, treated as a poset with ground set $P \equiv \{ (val, ix) : \texttt{arr}[ix] = val \}$
with the ordering $(a_1, a_2) < (b_1, b_2) \iff a_1 < b_1 \land a_2 < b_2$.

So we have this hasse diagram, which interestingly is going to be a tree.
this need not always be the case! consider the divisiblity poset with the
elements $3, 5, 15$.

Then the answer is to print the parent of each node in the tree as the parent
in the Hasse diagram is going to be closest number that is smaller than it.


Why does this Hasse diagram show up? What is the relationship between this problem,
and that of [Graham Scan](https://en.wikipedia.org/wiki/Graham_scan) which also
uses a similar technique of maintaining a stack. Does this also have a hasse
diagram associated to it? or a DFS tree?

<img src="./static/nearest-smaller-number.png">



# Why loss of information is terrifying: Checking that a context-free language is regular is undecidable

This comes from applying [Greibach's theorem](https://en.wikipedia.org/wiki/Greibach%27s_theorem#Applications).
I find myself thinking about this theorem once in a while, and its repercussions.
If we once had access to God who tabulated for all all regular languages
described as context free grammars, and we lost this tablet, we're screwed.
There's no way to recover this information decidably.

It shows that moving to higher models of computation (From regular to context free)
can sometimes be irreversably damaging.



# Sciences of the artificial

> A bridge under its usual conditions of service, behaves simply as a
> relatively smooth level surface. Only when it has been overloaded do we
> learn the physical properties of the  materials from which it is built.

> Ohm's law was suggested to its discovered by its analogy with some simple
> hydraulic phenomena.

Why simulation is useful:

- 1. (obvious): while the axioms maybe obvious, their raminifactions may not.

> A NASA launched satellite is surely an artificial object, but we usually
> do not think of it as simulating the moon; It simply obeys the same laws.

- 2. (subtle) Each layer only depends on an abstraction of the previous. Airplanes
  don't need the correctness of the Eightfold Way.

> Babbage introduced the words "Mill" and "Store"

> The focal concern of Economics is allocation of scarce resources.

> We can use a theory (say a theory of profit-loss) either positively,
> as an explaiation, or normatively, as a way to guide how we should run a
> firm.



# Numbering nodes in a tree

If we consider a tree such as:

```
      a
b         c
        d   e
```

The "standard way" of numbering,  by starting with a `0` and then appending a `0`
on going to the left, appending a `1` on going to the right doesn't make a great
deal of sense. On the other hand, we can choose to number them as follows:

- Consider the root to have value `1`
- Every time we go right, we add `1/2^{height}`. When we go left, we subtract `1/2^{height}`.
- This gives us the numbers:

```
      1
0.5       1.5
       1.25     1.75
```

- This also makes intuitive why to find the node to replace `1.5` when we delete
  it is to go to the left child `1.25` and then travel as much to the right as
  possible. That path corresponds to:

$$
\begin{aligned}
&1 + 1/2 - 1/4 + 1/8 + 1/16 + \dots \\
&=  1 + 1/2 - 1/4 + 1/4 \\
&= 1.5
\end{aligned}
$$

- So in the limit, the rightmost leaf of the left child of the parent
  *has the same value* as the parent itself. In the non-limit, we get as close as
  possible.

- This also may help intuit hyperbolic space? Distances as we go down in the
  three shrink. Thus, it's easier to "escape" away to the fringes of the space,
  rather than retrace your step. Recall that random walks in hyperbolic space
  almost surely move away from the point of origin. It feels to me like this
  explains why. If going towards the root / decreasing heighttakes distance
  $d$, going deeper into the tree / increasing the height
  needs distance $d/2$. So a particle would "tend to" travel the shorter distance.

# Number of vertices in a rooted tree

Make sure the edges of the tree are ordered to point away from the root $r$.
So, for all edges $(u, v) \in E$, make sure that $d(r, v) = d(r, u) + 1$.

Create a function $terminal$ which maps every outward arc
to its target. $terminal: E \rightarrow V$, $terminal((u, v)) = v$.

This map gives us an almost bijection from edges to all vertices other than
the root. So we have that $|E| + 1 = |V|$. Each of the edges cover one non-root
vertex, and we then $+1$ to count the root node.

I found this much more intuitive than the inductive argument. I feel like I
should attempt to "parallelize" inductive arguments so you can see the entire
counting "at once".

# Median minimizes L1 norm

Consider the meadian of $xs[1..N]$. We want to show that the median minimizes
the L1 norm $L_1(y) = \sum_i |xs[i] - y|$. If we differentiate $L_1(y)$ with
respect to $y$, we get:

$$
d L_1(y)/y = \sum_i - \texttt{sign}(xs[i] - y)
$$


Recall that $d(|x|)/dx = \texttt{sign}(x)$

Hence, the best $y$ to minimize the $L_1$ norm is the value that makes the sum
of the signs $\sum_i \texttt{sign}(xs[i] - y)$ minimal. The median is perfect
for this optimization problem.

1. When the list has an odd number of elements, say, $2k + 1$, $k$ elements
  will have sign $-1$, the middle element will have sign $0$, and the $k$ elements
  after will have sign $+1$. The sum will be $0$ since half of the $-1$ and the $+1$
  cancel each other out.
2. Similar things happen for even, except that we can get a best total sign distance of $+1$
  using either of the middle elements.


#### Proof 2:
Math.se has a nice picture proof abot walking from left to right.

#### Proof 3:
Consider the case where $xs$ has only two elements, with $xs[0] < xs[1]$.
Then the objective function to minimize the L1 norm, ie, to minimize
$|xs[1] - y| + |xs[2] - y|$. This is satisfied by any point in
between $xs[1]$ and $xs[2]$.

In the general case, assume that $xs[1] < xs[2] \dots < xs[N]$. Pick the smallest
number $xs[1]$ and the largest number $xs[N]$. We have that any $y$ between $xs[1]$
and $xs[N]$ satisfies the condition. Now, drop off $xs[1]$ and $xs[N]$, knowing
that we must have $y \in [xs[1], xs[N]]$. Recurse.


At the end, we maybe left with a single element $xs[k]$. In such a case, we need
to minimize $|xs[k] - y|$. That is, we set $xs[k] = y$.

On the other hand, we maybe left with two elements. In this case, any point between
the two elements is a legal element.


We may think of this process as gradually "trapping" the median between the
extremes, using the fact that that any point $y \in [l, r]$ minimizes
$|y - l| + |y - r|$!



- [Taken from `math.se`](https://math.stackexchange.com/questions/113270/the-median-minimizes-the-sum-of-absolute-deviations-the-ell-1-norm)




# LISP quine

I learnt how to synthesize a LISP quine using MiniKanren. It's quite magical,
I don't understand it yet.

```lisp
((lambda (x)
   `(,x (quote ,x)))
 (quote
   (lambda (x)
     `(,x (quote ,x)))))

```

# A slew of order theoretic and graph theoretic results

I've been trying to abstract out the [activity selection problem](https://en.wikipedia.org/wiki/Activity_selection_problem)
from the lens of order theory. For this, I plan on studying the following
theorems/algebraic structures:

- Intransitive indifference with unequal indifference intervals
- Mirsky's theorem
- Dilworth's theorem
- Gallai–Hasse–Roy–Vitaver theorem
- Dirac's theorem
- Ore's theorem
- [Course on discrete math](https://www.coursera.org/learn/discrete-mathematics#syllabus)
- [`cs.stackexchange`: Finding longest chain in poset in sub-quadratic time](https://cs.stackexchange.com/questions/67847/finding-longest-chain-in-poset-in-subquadratic-time)


Naively, the solution goes as follows, which can be tested against
[CSES' movie festival question](https://cses.fi/problemset/task/1629)

```cpp
// https://cses.fi/problemset/task/1629
int main() {
    int n;
    cin >> n;
    vector<pair<int, int>> ms(n);
    for (int i = 0; i < n; ++i) {
        cin >> ms[i].first >> ms[i].second;
    }

    std::sort(ms.begin(), ms.end(), [](pair<int, int> p1, pair<int, int> p2) {
        return (p1.second < p2.second) ||
               (p1.second == p2.second && p1.first < p2.first);
    });

    int njobs = 0;
    int cur_end = -1;
    for (int i = 0; i < n; ++i) {
        if (cur_end <= ms[i].first) {
            cur_end = ms[i].second;
            njobs++;
        }
    }
    cout << njobs << "\n";
    return 0;
}
```

#### Explanation 1: exchange argument

- The idea is to pick jobs *greedily*, based on *quickest finishing time*.
- The argument of optimality is strategy stealing. Think of the first job
  in our ordering `O` versus the optimal ordering `O*`.
- If we both use the same job, ie, `O[1] = O*[1]`, recurse into the second job.
- If we use different jobs then `O[1] != O*[1]`.
- Since  `O[1]` ends *quickest* [acc to our algorithm],
  we will have that `end(O[1]) < end(all other jobs)`, hence
  `end(O[1]) < end(O*[1])`.
- Since `O*` is a *correct* job schedule, we have that `end(O*[1]) < start(O*[2])`.
- Chaining inequalities, we get that `end(O[1]) < end(O*[1]) < start(O*[2])`.
- Thus, we can create `O~` which has `O~[1] = O[1]` and `O~[rest] = O*[rest]`.
  (`~` for "modified").
- Now recurse into `O~` to continue aligning `O*` with `O`. We continue to have the
  same length between `O~`, `O` and `O*`.

#### Explanation 2: posets and interval orders


# Neko to follow your cursor around

```
$ oneko -idle 0 -speed 100 -time 5120 -bg blue -fg orange -position +20+20
```

This is useful for screen sharing tools that can't display the mouse
pointer, [like Microsoft Teams](https://docs.microsoft.com/en-us/answers/questions/3222/mouse-pointer-not-visible-when-sharing-screen.html)

# Non commuting observables: Light polarization

- [physics.se](https://physics.stackexchange.com/questions/240543/is-there-something-behind-non-commuting-observables)


# Statement expressions and other GCC C extensions

This seems really handy. I've always loved that I could write

```
let x = if y == 0 { 1 } else { 42}
```

in Rust. It's awesome to know that the C equivalent is

```cpp
const int x =  ({ if (y == 0) { return 1; } else { return 42; });
```

#### [Conditions (`?:`) with omitted operands](https://gcc.gnu.org/onlinedocs/gcc/Conditionals.html#Conditionals)

```c
x ?: y =defn= x ? x : y
```

#### [variable length arrays](https://gcc.gnu.org/onlinedocs/gcc/Variable-Length.html#Variable-Length)

```c
FILE *
concat_fopen (char *s1, char *s2, char *mode)
{
  char str[strlen (s1) + strlen (s2) + 1];
  strcpy (str, s1);
  strcat (str, s2);
  return fopen (str, mode);
  // str is freed here.
}

```

#### [Designated array initializers: A better way to initialize arrays](https://gcc.gnu.org/onlinedocs/gcc/Designated-Inits.html#Designated-Inits)

- initialize specific indexes

```c
// initialize specific indexes
int a[6] = { [4] = 29, [2] = 15 };
// a[4] = 29; a[2] = 15; a[rest] = 0
```


- initialize ranges:

```c
// initialize ranges
int widths[] = { [0 ... 9] = 1, [10 ... 99] = 2, [100] = 3 };
```

- initialize struct fields:

```
//initialize struct fields
struct point { int x, y; };
struct point p = { .y = yvalue, .x = xvalue };
```


- initialize union variant:

```c
//initialize union variant
union foo { int i; double d; };
union foo f = { .d = 4 };
```

- Neat trick: lookup for whitespace in ASCII:

```c
int whitespace[256]
  = { [' '] = 1, ['\t'] = 1, ['\h'] = 1,
      ['\f'] = 1, ['\n'] = 1, ['\r'] = 1 };
```

#### [Cast to union](https://gcc.gnu.org/onlinedocs/gcc/Cast-to-Union.html#Cast-to-Union)

```c
union foo { int i; double d; };
int x = 42; z = (union foo) x;
double y = 1.0; z = (union foo) y;
```

#### [Dollar signs in identifier names]( https://gcc.gnu.org/onlinedocs/gcc/Dollar-Signs.html#Dollar-Signs)

```c
int x$;
int $z;
```


#### [Unnamed union fields](https://gcc.gnu.org/onlinedocs/gcc/Unnamed-Fields.html#Unnamed-Fields)

```c
struct {
  int a;
  union { int b; float c; };
  int d;
} foo

// foo.b has type int
// foo.c has type float, occupies same storage as `foo.b`.
```

- [GCC manual: statement expressions](https://gcc.gnu.org/onlinedocs/gcc/Statement-Exprs.html)
- [GCC manual: C extensions](https://gcc.gnu.org/onlinedocs/gcc/C-Extensions.html#C-Extensions)



# A quick look at impredicativity

I found this video very helpful, since I was indeed confused about the two
meanings of impredicativity that I had seen floating around. One used by haskellers,
which was that you can't instantiate a type variable `a` with a  (`forall t`).
Impredicative in Coq means having `(Type : Type)`.

- polymorphic types:

```hs
forall p. [p] -> [p] -- LEGAL
Int -> (forall p. [p] -> [p])  -- ILLEGAL
(forall p. [p] -> [p])  -> Int -- ILLEGAL
[forall a. a -> a] -- ILLEGAL
```

- Higher rank types: `forall` at the outermost level of a let-bound function,
  and to the left and right of arrows!

```hs
Int -> (forall p. [p] -> [p])  -- LEGAL
(forall p. [p] -> [p])  -> Int -- LEGAL
runST :: (forall s. ST s a) -> a -- LEGAL
[forall a. a -> a] -- ILLEGAL
```

- Impredicative type:

```hs
[forall a. a -> a]
```

- We can't type `runST` because of impredicativity:

```hs
($) :: forall a, forall b, (a -> b) -> a -> b
runST :: forall a, (forall s, ST s a) -> a -- LEGAL
st :: forall s. ST s Int
runST st -- YES
runST $ st -- NO
```

- Expanding out the example:

```hs
($) runST st
($) @ (forall s. ST s Int) @Int  (runST @ Int) st
```

- Data structures of higher kinded things. For example. we might want to have `[∀ a, a -> a]`
- We have `ids :: [∀ a, a -> a]`. I also have the function `id :: ∀ a, a -> a`. I want
  to build `ids' = (:) id ids`. That is, I want to cons an `id` onto my list `ids`.
- How do we type infer this?

#### How does ordinary type inference work?

```hs
reverse :: ∀ a. [a] -> [a]
and :: [Bool] -> Bool
foo = \xs -> (reverse xs, and xs)
```

- Start with `xs :: α` where `α` is a type variable.
- Typecheck `reverse xs`. We need to instantiate `reverse`. With what type?
  **that's what we need to figure out!**
- (1) Instantiate: Use variable `β`. So we have that our occurence of `reverse` has type
  `reverse :: [β] -> [β]`.
- (2) Constrain: We know that `xs :: α` and `reverse` expects an input argument of
   type `[β]`, so we set `α ~ [β]` due to the call `reverse xs`.
- We now need to do `and xs`. (1) `and` doesn't have any type variables, so we don't need
  to perform instantiation. (2) We can constrain the type, because `and :: [Bool] -> Bool`,
  we can infer from `and xs` that `α ~ [Bool]`
- We solve using [**Robinson unification**](https://en.wikipedia.org/wiki/Robinson%27s_unification_algorithm).
  We get `[β] ~ α ~ [Bool]` or `β = Bool`

#### Where does this fail for polytypes?

- The above works because `α` and `Β` only stand for **monotypes**.
- Our constraints are **equality constraints**, which can be solved by
  **Robinson unification**
- And we have only **one solution** (principal solution)
- When trying to instantiate reverse, how do we instantiate it?
- Constraints become subsumption constraints
- Solving is harder
- No principal solution
- Consider `incs :: [Int -> Int]`, and `(:) id incs` versus `(:) id ids`.

#### But it looks so easy!

- We want to infer `(:) id ids`
- We know that the second argument `ids` had type `[∀ a, a -> a]`
- we need a type `[p]` for the second argument, because `(:) :: p -> [p] -> [p]`
- Thus we must have `p ~ (∀ a, a -> a)`
- We got this information **from the second argument**
- So let's try to treat an application `(f e1 e2 ... en)` as a whole.

#### New plan

- Assume we want to figure out `filter g ids`.
- start with `filter :: ∀ p, (p -> Bool) -> [p] -> Bool`
- Instatiate `filter` with **instantiation variables** `κ` to get
  `(κ -> Bool) -> [κ] -> Bool`
- Take a "quick look" at `e1, e2` to see if we know that `κ` should be
- We get from `filter g ids` that `κ := (∀ a, a -> a)`.
- Substitute for `κ`  (1) the type that "quick look" learnt, if any, and
  (2) A **monomorphic** unification variable otherwise.
- Typecheck against the type. In this case, we learnt that `κ := (∀ a, a -> a)`,
  so we replace `κ` with `(∀ a, a -> a)`.
- Note that this happens at each **call site**!

#### The big picture

Replace the idea of:
- instantate function with unficiation variables, with the idea.
- instantiate function with a quick look at the calling context.
- We don't need fully saturated calls. We take a look at whatever we can see!
- Everything else is completely unchanged.

#### What can QuickLook learn?

- [Video](https://www.youtube.com/watch?v=ZuNMo136QqI)


# Data oriented programming in C++

- Calcuating entropy to find out if a variable is worth it! Fucking amazing.
- [Video](https://www.youtube.com/watch?v=rX0ItVEVjHc)


# Retro glitch

<img src=static/retro-glitch.jpg />

- There's something great about the juxtaposition of the classic Christian scene
  with the glitch aesthetic. I'm unable to articulate _what_ it is that I so
  thoroughly enjoy about this image.

- Fuck me, it turns out this is fascist art, goes by the genre of `fashwave`.
  Pretty much everything else in this genre is trash, this is the sole 'cool looking'
  picture of the lot.


# SSA as linear typed language

- Control flow is linear in a basic block: ie, we can have a sea of nodes
  representation, where each terminator instruction produces _linear_ control
  flow tokens: `br: token[-1] --> token[1]`. `brcond: token[-1] -> -> (token[1], token[1])`,
  `return: token[-1] -> ()`. This ensures that each branching only happens once,
  thereby "sealing their fate. On the other hand, reguar instructions also
  take a "control token", but don't _consume it_. so for example, `add: token[0] -> (name, name) -> name`.

- Next question: is dominance also somehow 'linear'?
- Answer: yes. We need quantitative types. When we branch from basic block `A`
  into blocks `B, C`, attach `1/2A` to the control tokens from `(%tokb, %tokc) = br cond %cond0 B, C`.
  Now, if someone builds a token that's at a basic block `D` that is merged
  into by both `B, C`, they will receive a "full" `A` that they can use.
  Pictorially:

```
       A
       ...

   B        C
[1/2A]     [1/2A]
       D
       1A
```

# Nix weirdness on small machines

```
floobits@pixel-druid:~$ nix-env -iA nixpkgs.hello
+ nix-env -iA nixpkgs.hello
installing 'hello-2.10'
these paths will be fetched (0.04 MiB download, 0.20 MiB unpacked):
  /nix/store/w9yy7v61ipb5rx6i35zq1mvc2iqfmps1-hello-2.10
copying path '/nix/store/w9yy7v61ipb5rx6i35zq1mvc2iqfmps1-hello-2.10' from 'https://cache.nixos.org'...
error: unable to fork: Cannot allocate memory
floobits@pixel-druid:~$ gdb --args nix-env -iA nixpkgs.hello
+ gdb --args nix-env -iA nixpkgs.hello
GNU gdb (Ubuntu 7.11.1-0ubuntu1~16.5) 7.11.1
Copyright (C) 2016 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
and "show warranty" for details.
This GDB was configured as "x86_64-linux-gnu".
Type "show configuration" for configuration details.
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>.
Find the GDB manual and other documentation resources online at:
<http://www.gnu.org/software/gdb/documentation/>.
For help, type "help".
Type "apropos word" to search for commands related to "word"...
Reading symbols from nix-env...(no debugging symbols found)...done.
(gdb) run
Starting program: /nix/store/d6axkgf0jq41jb537fnsg44080c4rd52-user-environment/bin/nix-env -iA nixpkgs.hello
warning: File "/nix/store/danv012gh0aakh8xnk2b35vahklz72mk-gcc-9.2.0-lib/lib/libstdc++.so.6.0.27-gdb.py" auto-loading has been declin
ed by your `auto-load safe-path' set to "$debugdir:$datadir/auto-load".
To enable execution of this file add
        add-auto-load-safe-path /nix/store/danv012gh0aakh8xnk2b35vahklz72mk-gcc-9.2.0-lib/lib/libstdc++.so.6.0.27-gdb.py
line to your configuration file "/home/floobits/.gdbinit".
To completely disable this security protection add
        set auto-load safe-path /
line to your configuration file "/home/floobits/.gdbinit".
For more information about this security protection see the
"Auto-loading safe path" section in the GDB manual.  E.g., run from the shell:
        info "(gdb)Auto-loading safe path"
warning: File "/nix/store/xg6ilb9g9zhi2zg1dpi4zcp288rhnvns-glibc-2.30/lib/libthread_db-1.0.so" auto-loading has been declined by your
 `auto-load safe-path' set to "$debugdir:$datadir/auto-load".
warning: Unable to find libthread_db matching inferior's thread library, thread debugging will not be available.
^[[A[New LWP 21466]
GC Warning: Failed to expand heap by 128045056 bytes
installing 'hello-2.10'
building '/nix/store/k3kz3cwyqdwi5bmwcbl1fzv2b2wkqrl6-user-environment.drv'...
created 43 symlinks in user environment
[LWP 21466 exited]
[Inferior 1 (process 21462) exited normally]
(gdb) run
```

### All nix subcommands are just symlinks

```
floobits@pixel-druid:~/idfk/nix-master$ ls -al /nix/store/4vz8sh9ngx34ivi0bw5hlycxdhvy5hvz-nix-2.3.7/bin/
total 1784
dr-xr-xr-x 2 floobits bollu    4096 Jan  1  1970 .
dr-xr-xr-x 9 floobits bollu    4096 Jan  1  1970 ..
-r-xr-xr-x 1 floobits bollu 1816768 Jan  1  1970 nix
lrwxrwxrwx 1 floobits bollu       3 Jan  1  1970 nix-build -> nix
lrwxrwxrwx 1 floobits bollu       3 Jan  1  1970 nix-channel -> nix
lrwxrwxrwx 1 floobits bollu       3 Jan  1  1970 nix-collect-garbage -> nix
lrwxrwxrwx 1 floobits bollu       3 Jan  1  1970 nix-copy-closure -> nix
lrwxrwxrwx 1 floobits bollu       3 Jan  1  1970 nix-daemon -> nix
lrwxrwxrwx 1 floobits bollu       3 Jan  1  1970 nix-env -> nix
lrwxrwxrwx 1 floobits bollu       3 Jan  1  1970 nix-hash -> nix
lrwxrwxrwx 1 floobits bollu       3 Jan  1  1970 nix-instantiate -> nix
lrwxrwxrwx 1 floobits bollu       3 Jan  1  1970 nix-prefetch-url -> nix
lrwxrwxrwx 1 floobits bollu       3 Jan  1  1970 nix-shell -> nix
lrwxrwxrwx 1 floobits bollu       3 Jan  1  1970 nix-store -> nix
```

It seems the way this works is that the `nix` tool figures out from what
_symlink_ it's being invoked to decide what to do. God, that's ugly? brilliant?
I don't even know.

### How does `writeFile` work?

- `cowsay` in nixpkgs
- `writeFile` in nixpkgs
- `runCommand'` in nixpkgs
- `mkDerivation` in nixpkgs
- `derivation` in nixpkgs
- `src/libexpr/primops/derivation.nix` in nixos
- `prim_derivationStrict` in nixos c++
- `derivationArg` in nixos c++
- `writeDerivation` in nixos c++

# Autodiff over derivative of integrals

- [Reynolds transport theorem](https://en.wikipedia.org/wiki/Reynolds_transport_theorem)
- [Physics based differential rendering](https://shuangz.com/courses/pbdr-course-sg20/)

# Proof of projective duality

In projective geometry, we can interchange any statement with "points" and
"lines" and continue to get a true statement. For example, we have the
dual statements:

- Two non-equal lines intersect in a unique point (including a point at infinty
  for a parallel line).
- Two non-equal points define a unique line.

The proof of the duality principle is simple. Recall that any point in
projective geometry is of the from $[a : b : c] \simeq (b/a, c/a)$. A projective
equation is of the form $px + qy + rz = 0$ for coefficients $p, q, r \in \mathbb C$.

- if we have a fixed point $[a : b : c]$, we can trade this to get a
  line $ax + by + cz = 0$.
- If we have a line $ax + by + cz = 0$, we can trade this to get a point $[a:b:c]$.
- The reason we need projectivity is because this correspondence is only well
  defined upto scaling: the line $x + 2y + 3$ is the same as the line $2x + 3y + 6$.
- In using our dictionary, we would get $[1:2:3]$, $[2:4:6]$. Luckily for us,
  projectivity, these two points are the same! $(2/1, 3/1) = (4/2, 6/2)$.
- The "projective" condition allows us to set points and lines on equal footing:
  lines can be scaled, as can points in this setting.

# Preventing the collapse of civilization

- [video by Jonathan Blow](https://www.youtube.com/watch?v=ZSRHeXYDLko)
- [The year civilization collapsed](https://www.youtube.com/watch?v=bRcu-ysocX4)
- [The thirty million line problem](https://caseymuratori.com/blog_0031#:~:text=The%20Thirty%2DMillion%2DLine%20Problem%20(2015))
- [Civilizations: Institutions, Knowledge, and future](https://www.youtube.com/watch?v=OiNmTVThNEY)
- [Dark mountain](https://dark-mountain.net/)

I am very sympathetic to the perspective that software has gotten far
less reliable than it used to be.

# Violent deaths in ancient societies (TODO)

### Kanun in albania

### Honor societies and Revence

### Law codes: Code of Hammurabi

#### References

- [Ethnographic and Archaeological Evidence on Violent Deaths](https://ourworldindata.org/ethnographic-and-archaeological-evidence-on-violent-deaths)
- [Kanun](https://en.wikipedia.org/wiki/Kanun_(Albania))

# An elementary example of a thing that is not a vector

Consider the tripe (temperature, pressure, humidity) at a point. If we rotate
the picture by 60 degrees, the triple _does not change_.


Now consider the direction of wind at a point. If we rotate the picture by
60 degrees, the components of the wind vector _change_ with our rotation.

Thus:

> a vector is something that transforms like a vector.

To be more precise, I can phrase it as:

> A vector iss (is and only is) something that transforms like a vector.

Generalization to tensors is left as an exercise for the reader.

# Elementary probability theory (TODO)

I've never learnt elementary probability theory "correctly". This is me
attempting to fix it.

#### Defn: Sample space

set of all possible outcomes / things that could happen.

#### Defn: Outcome / Sample point / atomic event

An outcome consists of all the information about the experiment
*after it has been performed* including the values of all random choices.

##### NOTE: Keeping straight event v/s outcome

It's easy to get confused between 'event' and 'outcome' (linguistically). I
personally remember that one of them is the element of the sample space and
another the subsets, but I can't remember which is which. Here's how I
recall which is which:

> every experiment has an *outcome*. We write an outcome section when we
> write a lab manual/lab record for a given experiment.


Now, we when perform an expriment, or something random happens, sometimes,
the result (ie, the outcome) can be _eventful_; it's not linguistically
right to say that some events can be _outcomeful_.

So, an event is a predicate over the set of outcomes; `event: outcome -> bool`.
This is the same as being a subset of outcomes (the event is identified
with the set of outcomes it considers eventful), so we have `event ~= 2^outcomes`.



## Example: Monty hall

An outcome of the monty hall game **when the the contestant switches** consists of:
- the box with the prize.
- the box chosen by the contestant.
- the box that was revealed.

Once we know the three things, we know everything that happened.

For example, the sample point $(2, 1, 3)$:
- the prize is in box 2
- the player first picks box 1
- the assistant, Carol, reveals box 3.
- The contestant wins, because we're assuming the player switches. Hnce, they
  will switch from their initial choice of (1) to (2).

Note that not all 3-tuples correspond to sample points. For example,
- $(1, 2, 1)$ is not a sample point, because we can't reveal the box with the prize.
- $(2, 1, 1)$ is not a sample point, because we can't reveal the box the player chose.
- $(1, 1, 2), (1, 1, 3)$ is OK. The player chooses the correct box, carol reveals some box,
  and then the player switches.

## Constructing the sample space: tree method

We build a decision tree.

#### where is the prize?

```
(prize 1)
(prize 2)
(prize 3)
```

#### player's choice


```
(prize 1
   (choice 1)
   (choice 2)
   (choice 3))
(prize 2
   (choice 1)
   (choice 2)
   (choice 3))
(prize 3
   (choice 1)
   (choice 2)
   (choice 3))

```

#### Which box is revealed


```
(prize 1
   (choice 1
      (reveal 2)
      (reveal 3))
   (choice 2
      (reveal 3))
   (choice 3)
      (reveal 2))
(prize 2
   (choice 1
     (reveal 3)
   (choice 2
     (reveal 1)
      (reveal 3))
   (choice 3)
     (reveal 1))
(prize 3
   (choice 1
     (reveal 2))
   (choice 2
     (reveal 1))
   (choice 3)
     (reveal 1)
     (reveal 2))
```


#### Win/Loss

```
(prize 1
   (choice 1
loss  (reveal 2)
loss  (reveal 3))
   (choice 2
win   (reveal 3))
   (choice 3)
win   (reveal 2))
(prize 2
   (choice 1
win  (reveal 3)
   (choice 2
loss (reveal 1)
loss  (reveal 3))
   (choice 3)
win  (reveal 1))
(prize 3
   (choice 1
win  (reveal 2))
   (choice 2
win  (reveal 1))
   (choice 3)
loss (reveal 1)
loss (reveal 2))
```

This seems like it's 50/50! But what we're missing is the *likelihood* of an
outcome.

#### Defn: Probability space

A probability space consists of a sample space (space of al outcomes) and a
probability function $P$ that maps the sample space to the real numbers, such that:
- For every outcome, the probability is between zero and one.
- The sum of all the probabilities is one.

**Interpretation**: For every outcome, the $P(outcome)$ is the probability of
that outcome happening in an experiment.


#### Assumptions for monty hall

- Carol put the prize uniformly randomly. Probability 1/3.
- No matter where the prize is, the player picks each box with probability 1/3.
- No matter where the prize is, the box that carol reveals will be picked
  uniformly randomly. Probability 1/2.

#### Assigning probabilities to each edge

```
(prize 1 [1/3]
   (choice 1 [1/3]
l  (reveal 2)   [1/2]
l  (reveal 3))  [1/2]
   (choice 2 [1/3]
w   (reveal 3)) [1]
   (choice 3) [1/3]
w   (reveal 2)) [1]
(prize 2 [1/3]
   (choice 1
w  (reveal 3)
   (choice 2
l (reveal 1)
l  (reveal 3))
   (choice 3)
w  (reveal 1))
(prize 3  [1/3]
   (choice 1
w  (reveal 2))
   (choice 2
w  (reveal 1))
   (choice 3)
l (reveal 1)
l (reveal 2))
```

#### Assigning probabilities to each outcome

- Probability for a sample point is the product of probabilities leading
  to the outcome

```
(prize 1 [1/3]
   (choice 1 [1/3]
l  (reveal 2)   [1/2]: 1/18
l  (reveal 3))  [1/2]: 1/18
   (choice 2 [1/3]
w   (reveal 3)) [1]: 1/9
   (choice 3) [1/3]
w   (reveal 2)) [1]: 1/9
...
```

So the probability of winning is going to be $6 \times 1/9 = \frac{2}{3}$.

#### Defn: Event

An event is a *subset* of the sample space.

- For example, $E_l$ is the event that the person loses in Monty Hall.

#### Probability of an event

The probability that an event $E$ occurs is the sum of the probabilities of the
sample points of the event: $P(E) \equiv \sum_{e \in E} P(e)$.



#### What about staying?

I win $2/3$rds of the time when I _switch_. If I don't switch, I must have lost.
So if I choose to stay, then I _lose_ $2/3$rds of the time. We're using that

- $P(\texttt{win with switch}) = P(\texttt{lose with stick})$.

#### Gambing game

- Dice $A$: $\{2, 6, 7\}$.

```
\ 2  /
 \  /
6 \/ 7
  ||
```
it's the same on the reverse side. It's a fair dice. So the probability of
getting $2$ is a third. Similarly for $6, 7$.

- Dice $B$: $\{1, 5, 9 \}$.
- Dice $C$: $\{3, 4, 8 \}$.

- We both dice. The higher dice wins. Loser pays the winner a dollar.

#### Analysis: Dice A v/s Dice C

- Dice $A$ followed by dice $C$:

```
(2
  (3
   4
   8))
(6
  (3
   4
   8))
(7
  (3
   4
   8))
```

- Assign winning

```
(2
  (3    C
   4    C
   8))  C
(6
  (3    A
   4    A
   8))  C
(7
  (3    A
   4    A
   8))  C
```

Each of the outcomes has a probability $1/9$, so dice $C$ wins.

#### Lecture 19: Conditional probability


`P(A|B)` where both `A` and `B` are events, read as probability of `A`
given `B`.

$$
P(A|B) \equiv \frac{P(A \cap B)}{P(B)}
$$

We know $B$ happens so we normalize by $B$. We then intersect $A$ with $B$
because we want both $A$ and $B$ to have happened, so we consider all outcomes
that both $A$ and $B$ consider eventful, and then reweigh the probability such
that our definition of "all possible outcomes" is simply "outcomes in $B$".

- A quick calculation shows us that $P(B|B) = P(B \cap B)/Pr(B) =1$.

#### Product Rule

$$
P(A \cap B) = P(B) P(A|B)
$$

follows from the definition by rearranging.

#### General Product Rule

$$
P(A_1 \cap A_2 \dots A_n) = P(A_1) P(A_2 | A_1) P(A_3 | A_2 \cap A_1) P(A_4 | A_3 \cap A_2 \cap A_1) \dots P(A_n | A_1 \cap \dots \cap A_{n-1})
$$

#### Example 1:

In a best two out of three series, the probability of winning the first
game is $1/2$. The probability of winning a game immediately after a victory is $2/3$.
Probability of winning after a loss is $1/3$. What is the probability of winning
given that we win in the first game?

Tree method:

```
(W1
  (W2)
   (L2
      (W3
      L3)))
(L1
  (W2)
   (L2
      (W3
      L3)))
(L1)
```

The product rule sneakily uses conditional probability! $P(W_1W_2) = P(W_1) P(W_2|W_1)$.
Etc, solve the problem.

#### Definition: Independence

events $A$, $B$ are independent if $P(A|B) = P(A)$ or $P(B) = 0$.

#### Disjointness and independence

Disjoint events are never independent, because $P(A|B) = 0$ while $P(A)$ need not
be zero.

#### What do indepdent events look like?

We know that we need $P(A|B) = P(A)$. We know that $P(A|B)$ is how much of $A$
is within $B$. So we will have $P(A|B) = P(A)$ if the space that $A$ occupies
in the sample space is the same proprtion of $A$ that occupies $B$. Euphimistically,
$A/S = (A \cap B)/B$.

#### Independence and intersection

If $A$ is independent of $B$ then $P(A\cap B) = P(A) P(B)$.

$$
\begin{aligned}
P(A) = P(A|B) \text{(given)} \\
P(A) = P(A \cap B) / P(B) \text{(defn of computing $P(A|B)$)} \\
P(A) P(B) = P(A \cap B) \text{(rearrange)} \\
\end{aligned}
$$

#### Are these two independent?

- A = event coins match
- B = event that the first coin is heads.

Intuitively it seems that these should be dependent because knowing something
about the first coin should tells us if the coins match.
$P(A|B)$ is the probability that (second coin is heads) which is  $1/2$.
$P(A) = 1/2$.

But our intuition tells us that these should be different!

#### Be suspect! Try general coins

Let prob. of heads is $p$ and tails is $(1-p)$ for both coins.

$P(A|B) = p$, while $P(A) = p^2 + (1-p)^2$.

#### Mutual independence

Events $A_1, A_2, \dots A_n$ are mutually independent if any knowledge
about any of the rest of the events tells us anything about the $i$th event.


#### Random variables

A random variable $R$ is a function from the sample space $S$ to $\mathbb R$. We can
create equivalence classes of the fibers of $R$. Each of this is an event,
since it's a subset of the sample space. Thus, $P(R = x)$ = $P(R^{-1}(x)) = \sum_{w: R(w) = x} P(w)$

#### Independence of random variables

$$
\forall x_1, x_2 \in \mathbb R, P(R_1 = x_1 | R_2 = x_2) = P(R_1 = x_1)
$$

> Slogan: No value of $R_2$ can influence any value of $R_1$.

####  Equivalent definition of independence:

$$
P(R_1 = x_1 \land R_2 = x_2) = P(R_1 = x_1) P(R_2 = x_2)
$$


#### References

- [Lec 18: math for computer science; elementary probability](https://www.youtube.com/watch?v=SmFwFdESMHI)
- [Lec 19: math for computer science; elementary probability](https://www.youtube.com/watch?v=SmFwFdESMHI)
- [Lec 21: math for computer science; random variables](https://www.youtube.com/watch?v=MOfhhFaQdjw)
- [Problem set 10](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-042j-mathematics-for-computer-science-fall-2010/assignments/MIT6_042JF10_assn10.pdf)
- [Problem set 11](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-042j-mathematics-for-computer-science-fall-2010/assignments/MIT6_042JF10_assn11.pdf)
- [Problem set 12](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-042j-mathematics-for-computer-science-fall-2010/assignments/MIT6_042JF10_assn12.pdf)

# The handshaking lemma

### Concrete situation:

Let's take a graph $G \equiv (V, E)$. We can imagine that each edge has a potential
of $2$. We can redistribute this potential, by providing a potential of $1$
to each of the vertices incident on the edge. This gives us the calculation
that the total potential is $2|E|$. But each vertex is assigned a potential of $1$
for each edge incident on it. Thus, the total potential is $\sum_v \texttt{degree}(v)$.
This gives the equality $\sum_i \texttt{degree}(v) = 2|E|$.

Thus, if each of the degrees are odd, considering modulo 2, the LHS becomes
$\sum_v 1 = |V|$ and the RHS becomes $0$. Thus we have that $|V| = 0$ (mod 2), or
the number of vertices remains even.

I learnt of this nice way of thinking about it in terms of potentials when
reading a generalization to simplicial
complexes.

#### References
- [The amazing world of simplicial complexes](https://arxiv.org/pdf/1804.08211.pdf)


# Git for pure mathematicians

What is `git`? It's not a version control system. It's an interface to work
with _torsors_. We have a space of files. We can manipulate "differences of
files", which are represented by patches/diffs. `git`'s model provides us tools
to work with this space of files.

We have two spaces, and a rooted DAG that connects to two spaces:

- A space of *files*.
- A space of *diffs* which forms a monoid with a monoid action on the space of files.
- A DAG where each node is a diff. The root note in the DAG is the empty diff.

# Mutorch

Minimal reverse mode AD implementation.

```py
#!/usr/bin/env python3

# x2, w1, w2 are Leaf variables
# x1 = f(w1, w2)
# y = g(x1, x2)
# loss = h(y)


# BACKPROP [reverse mode AD]
# ==========================
# t is a hallucinated variable.
# y = f(x)
# GIVEN: dt/dy
# TO FIND: dt/dx
# dt/dx = dt/dy * dy/dx
# dt/dloss
# t = loss
# dt/dloss = dloss/dloss = 1


# y1 = f(x1, x2, x3)
# y2 = g(x1, x2, x3)

# FORWARD MODE: [Tangent space] ---- objects of the does nothing at all :$\texttt{form (partial f/partial x)
# total gradient of x1: df/dx1 + dg/dx1
# total gradient of x2: df/dx2 + dg/dx2
# total gradient of x3: df/dx3 + dg/dx3

# l = r cos(theta)
# dl = dr cos(theta) + rsin(theta) dtheta
# dl/dtheta = dr/dtheta cos(theta) + rsin(theta) dtheta/dtheta
# dl/dtheta =   0       * .......  + rsin(theta) * 1

# dl/dr = dr/dr cos(theta) + rsin(theta) dtheta/dr
# dl/dr = cos(theta) +      .............*0

# REVERSE MODE: [CoTangent space] --- objects of the form df
# total gradient of y1: dy1 = (df/dx1)dx1 + (df/dx2)dx2  + (df/dx3)dx3
# total gradient of y2: dy2 = (dg/dx1)dx1 + (dg/dx2)dx2  + (dg/dx3)dx3
# HALLUCINATED T:
#    y1 = f(x1, x2, x3)
#    GIVEN:   dt/dy1 [output]
#    TO FIND: dt/dx1, dt/dx2, dt/dx3 [inputs]
#    SOLN:    dt/dxi = dt/dy * dy/dxi
#                    = dt/dy * df/dxi
import pudb

class Expr:
    def __mul__(self, other):
        return Mul(self, other)
    def __add__(self, other):
        return Add(self, other)

    def clear_grad(self):
        pass

class Var(Expr):
    def __init__(self, name, val):
        self.name = name
        self.val = val
        self._grad = 0
    def __str__(self):
        return "(var-%s | %s)" % (self.name, self.val)
    def __repr__(self):
        return self.__str__()

    def clear_grad(self):
        self._grad = 0

    def backprop(self, dt_doutput):
        self._grad += dt_doutput

    def grad(self):
        return self._grad

class Mul(Expr):
    def __init__(self, lhs, rhs):
        self.lhs = lhs
        self.rhs = rhs
        self.val = self.lhs.val * self.rhs.val
    def __str__(self):
        return "(* %s %s | %s)" % (self.lhs, self.rhs, self.val)
    def __repr__(self):
        return self.__str__()

    #         -------- input1
    #   S    /
    #  ---> v
    #  <--output *
    #      ^
    #       \_________ input2
    # think in terms of sensitivity.
    # - output has S sensitivity to something,
    # - output = input1 + input2
    # - how much sensitivity does input1 have to S?
    # - the same (S), because "sensitivity" is linear [a conjecture/axiom]
    # output = f(input1, input2); f(input1, input2) = input1 + input2
    def backprop(self, dt_output):
        # dt/dinput1 = dt/doutput * ddoutput/dinput1 =
        #            = dt/doutput * d(f(input1, input2))/dinput1
        #            = dt/doutput * d(input1 * input2)/dinput1
        #            = dt/doutput * input2
        self.lhs.backprop(dt_output * self.rhs.val)
        self.rhs.backprop(dt_output * self.lhs.val)

# a = ...   ^
# b = ...   ^
# c = a + b ^
#
class Add(Expr):
    def __init__(self, lhs, rhs):
        self.lhs = lhs
        self.rhs = rhs
        self.val = self.lhs.val + self.rhs.val
    def __str__(self):
        return "(+ %s %s | %s)" % (self.lhs, self.rhs, self.val)
    def __repr__(self):
        return self.__str__()

    #         -------- input1
    #   S    /
    #  ---> v
    #  <--output
    #      ^
    #       \_________ input2
    # think in terms of sensitivity.
    # - output has S sensitivity to something,
    # - output = input1 + input2
    # - how much sensitivity does input1 have to S?
    # - the same (S), because "sensitivity" is linear [a conjecture/axiom]
    # output = f(input1, input2); f(input1, input2) = input1 + input2
    def backprop(self, dt_output):
        # dt/dinput1 = dt/doutput * ddoutput/dinput1 =
        #            = dt/doutput * d(f(input1, input2))/dinput1
        #            = dt/doutput * d(input1 + input2)/dinput1
        #            = dt/doutput * 1
        self.lhs.backprop(dt_output * 1)
        self.rhs.backprop(dt_output * 1)

class Max(Expr):
    def __init__(self, lhs, rhs):
        self.lhs = lhs
        self.rhs = rhs
        self.val = max(self.lhs.val, self.rhs.val)
    def __str__(self):
        return "(max %s %s | %s)" % (self.lhs, self.rhs, self.val)
    def __repr__(self):
        return self.__str__()

    def backprop(self, dt_output):
        # dt/dinput1 = dt/doutput * doutput/dinput 1
        #            = dt/doutput *d max(input1, input2)/dinput1
        #            = |dt/doutput *d input1/dinput1 [if input1 > input2] = 1
        #            = |dt/doutput *d input2/dinput1 [if input2 > input1] = 0
        if self.val == self.lhs.val:
            self.lhs.backprop(dt_output * 1)
        else:
            self.rhs.backprop(dt_output * 1)

x = Var("x", 10)
print("x: %s" % x)
y = Var("y", 20)
p = Var("p", 30)
print("y: %s" % y)
z0 = Mul(x, x)
print("z0: %s" % z0)
z1 = Add(z0, y)
print("z1: %s" % z1)

# z1 = x*x+y
# dz1/dx = 2x
# dz1/dy = 1
# dz1/dp = 0
# z1.clear_grad()
z1.backprop(1) #t = z1
print("dz/dx: %s" % x.grad())
print("dz/dy: %s" % y.grad())
print("dz/dp: %s" % p.grad())

x.clear_grad()
y.clear_grad()
z1.backprop(1) #t = z1
print("dz/dx: %s" % x.grad())
print("dz/dy: %s" % y.grad())
```

# Computing the smith normal form


```py
#!/usr/bin/env python3.6
# Smith normal form
import numpy as np
from numpy import *
import math

def row_for_var(xs, vi: int):
    NEQNS, NVARS = xs.shape
    for r in range(vi, NVARS):
        if xs[r][vi] != 0: return r
# return numbers (ax, ay) such that ax*x - ay*y = 0
def elim_scale_factor(x: int, y: int): return (y, x)

def smith_normal_form(xs, ys):
    NEQNS, NVARS = xs.shape
    assert(NEQNS == ys.shape[0])


    # eliminate variable 'vi' by finding a row 'r' and then using the row
    # to eliminate.
    for vi in range(NVARS):
        ri = row_for_var(xs, vi)
        if ri is None:
            return (f"unable to find non-zero row for variable: {vi}")
        print(f"-eliminating variable({vi}) using row ({ri}:{xs[ri]})")
        # eliminate all other rows using this row
        for r2 in range(NEQNS):
            # skip the eqn ri.
            if r2 == ri: continue
            # eliminate.
            (scale_ri, scale_r2) = elim_scale_factor(xs[ri][vi], xs[r2][vi])

            print(f"-computing xs[{r2}] = {scale_r2}*xs[{r2}]:{xs[r2]} - {scale_ri}*xs[{ri}]:{xs[ri]}")
            xs[r2] = scale_r2 * xs[r2] - scale_ri * xs[ri]
            ys[r2] = scale_r2 * ys[r2] - scale_ri * ys[ri]
        print(f"-state after eliminating variable({vi})")
        print(f"xs:\n{xs}\n\nys:{ys}")

    sols = [None for _ in range(NVARS)]
    for vi in range(NVARS):
        r = row_for_var(xs, vi)
        if r is None:
            print(f"unable to find row for variable {vi}")
            return None
        assert(xs[r][vi] != 0)
        if ys[r] % xs[r][vi] != 0:
            print(f"unable to solve eqn for variable {vi}: xs:{xs[r]} = y:{ys[r]}")
            return None
        else:
            sols[vi] = ys[r] // xs[r][vi]

    # now check solutions if we have more equations than solutions
    for r in range(NEQNS):
        lhs = 0
        for i in range(NVARS): lhs += xs[r][i] * sols[i]
        if lhs != ys[r]:
            print(f"-solution vector sols:{sols} cannot satisfy row xs[{r}] = ys[{r}]:{xs[r]} = {ys[i]}")
            return None


    return sols

# consistent system
# x = 6, y = 4
# x + y = 10
# x - y = 2
xs = np.asarray([[1, 1], [1, -1]])
ys = np.asarray([10, 2])
print("## CONSISTENT ##")
out = smith_normal_form(xs,ys)
print("xs:\n%s\n\nys:\n%s\n\nsoln:\n%s" % (xs, ys, out,))


# consistent, over-determined system
# x = 6, y = 4
# x + y = 10
# x - y = 2
# x + 2y = 14
xs = np.asarray([[1, 1], [1, -1], [1, 2]])
ys = np.asarray([10, 2, 14])
print("## CONSISTENT OVER DETERMINED ##")
out = smith_normal_form(xs,ys)
print("xs:\n%s\n\nys:\n%s\n\nsoln:\n%s" % (xs, ys, out,))

# consistent, under-determined system
# x = 6, y = 4, z = 1
# x + y + z = 11
# x - y + z = 3
xs = np.asarray([[1, 1], [1, -1], [1, 2]])
ys = np.asarray([10, 2, 14])
print("## CONSISTENT UNDER DETERMINED ##")
out = smith_normal_form(xs,ys)
print("xs:\n%s\n\nys:\n%s\n\nsoln:\n%s" % (xs, ys, out,))


# inconsistent system
# x = 6, y = 4
# x + y = 10
# x - y = 2
# x + 2y = 1 <- INCONSTENT
xs = np.asarray([[1, 1], [1, -1], [1, 2]])
ys = np.asarray([10, 2, 1])
print("## INCONSISTENT (OVER DETERMINED) ##")
out = smith_normal_form(xs,ys)

# inconsistent system
# x + y = 10
# x - y = 2
xs = np.asarray([[1, -1], [1, 2], [1, 1]])
ys = np.asarray([10, 2, 1])
print("## INCONSISTENT (OVER DETERMINED) ##")
out = smith_normal_form(xs,ys)


# consistent system over Q, not Z
# x = y = 0.5
# x + y = 1
# x - y = 0
xs = np.asarray([[1, 1], [1, -1]])
ys = np.asarray([1, 0])
print("## INCONSISTENT (SOLVABLE OVER Q NOT Z) ##")
out = smith_normal_form(xs,ys)
```

# Laziness for C programmers

#### Side node: nonsrict versus lazy (This section can be skipped)

I will use the word `non-strict` throughout, and not `lazy`.
Roughly speaking, `lazy` is more of an implementation detail that guarantees
that a value that is once computed is cached. (operational semantics)

`non-strict` is a evaluation order detail that guarantees that values are
not evaluated until there are truly required. (denotational semantics).

`lazy` is one way to _implement_ `non-strict`.

This is pure pedantry, but I'd like to keep it straight, since there seems to be
a lot of confusion involving the two words in general.

#### Showing off non-strictness:
We first need a toy example to work with to explain the fundamentals of
non-strict evaluation, so let's consider the example below. I'll explain the `case` construct which is explained below. Don't worry if ato lazy evaluation "looks weird", it feels that way to everyone till one plays around with it for a while!

We will interpret this example as both a strict program and a non-strict program.
This will show us that we obtain different outputs on applying different
interpretations.

We distinguish between primitive values (integers such as `1`, `2`, `3`) and boxed values
(functions, data structures). Boxed values can be evaluated non-stricly. Primitive values
do not need evaluation: they are primitive.

##### Code

```hs
-- Lines starting with a `--` are comments.
-- K is a function that takes two arguments, `x` and `y`, that are both boxed values.
-- K returns the first argument, `x`, ignoring the second argument, `y`.
-- Fun fact: K comes for the K combinator in lambda calculus.
kCombinator :: Boxed -> Boxed -> Boxed
kCombinator x y = x

-- one is a function that returns the value 1# (primitive 1)
one :: PrimInt
one = 1

-- Loopy is a function that takes zero arguments, and tries to return a boxed value.
-- Loopy invokes itself, resulting in an infinite loop, so it does not actually return.
loopy :: Boxed
loopy = loopy

-- main is our program entry point.
-- main takes no arguments, and returns nothing
main :: Void
main = case kCombinator one loopy of -- force K to be evaluated with a `case`
            kret -> case kret of  -- Force evaluation
                    i -> printPrimInt i -- Call the forced value of `kret` as `i` and then print it.
```

#### A quick explanation about `case`:
`case` is a language construct that *forces* evaluation. In general, no value
is evaluated unless it is *forced* by a case.

#### Analysing the example: The strict interpretation

If we were coming from a strict world, we would have assumed that the expression
`K one loopy` would first try to evaluate the arguments, `one` and `loopy`.
Evaluating `one` would return the primitive value `1`, so this has no problem.

On trying to evaluate `loopy`, we would need to re-evaluate `loopy`, and so on
ad infitum, which would cause this program to never halt.

This is because, as programmers coming from a strict world, we assume that
*values are evaluated as soon as possible*.

So, the output of this program is to have the program infinite-loop for ever,
under the strict interpretation.

#### Analysing the example: The non-strict interpretation:

In the non-strict world, we try to evaluate `K(1, loopy)` since we are asked the result
of it by the `case` expression. However, we do not try to evaluate `loopy`, since
no one has asked what it's value is!

Now, we know that

```hs
kCombinator x y = x
```

Therefore,

```hs
kCombinator one loopy = one
```

regardless of what value `loopy` held.

So, at the case expression:
```hs
main = case K(one, loopy) of -- force K to be evaluated with a `case`
>>>         kret -> ...
```

`kret = one`, we can continue with the computation.

```hs
main :: () -> Void
main = case kCombinator one loopy of -- force K to be evaluated with a `case`
            kret -> case kret of  -- Call the return value of K as `x`, and force evaluation.
                       i -> printPrimInt i -- Call the vreturn value of `x` as `primx` and then print it.
```

Here, we force `kret` (which has value `one`) to be evaluated with `case kret of...`.
since `one = 1`, `i` is bound to the value `1`.
Once `i` is returned, we print it out with `printPrimInt(primx)`.

The output of the program under non-strict interpretation is for it to print out `1`.

#### Where does the difference come from?

Clearly, there is a divide: strict evaluation tells us that this program should
never halt. Non-strict evaluation tells us that this program will print an output!

To formalize a notion of strictness, we need a notion of `bottom` (`_|_`).

A value is said to be `bottom` if in trying to evaluate it, we reach an
undefined state.

Now, if a function is *strict*, it would first evaluate its arguments and then
compute the result. So, if a strict function is given a value that is `bottom`,
the function will try to evaluate the argument, resulting in the computation
screwing up, causing the output of the whole function to be `bottom`.

Formally, a function `f` is strict iff (if and only if) `f(bottom) = bottom`.

Conversely, a *non-strict* function does not need to evaluate its arguments if it
does not use them, as in the case of `K 1 loopy`. In this case, `f(bottom)` need
not be equal to bottom.

Formally, a function `f` is non-strict iff (if and only if) `f(bottom) /= bottom`.

As Paul Halmos says

> "A good stack of examples, as large as possible, is indispensable for a
> thorough understanding of any concept, and when I want to learn something
> new, I make it my first job to build one.". Let us consider some examples.

- `id`

```hs
id x = x

id (3) = 1
id (bottom) = bottom
```

`id` is strict, since `id(bottom) = bottom`.


- `const`


```hs
const_one x = 1

const_one(bottom) = 1
const_one(3) = 1
```

`const_one` is not strict, as `const_one(bottom) /= bottom`.

- `K`

```hs
K x y = x

K 1 2 = 1
K 1 bottom = 1
K bottom 2 = bottom
```

Note that `K(bottom, y) = bottom`, so K is *strict in its first argument*, and
`K(x, bottom) /= bottom`, so K is *non-strict in its second argument*.

This is a neat example showing how a function can be strict and lazy in different
arguments of the function.


### Compiling non-strictness, v1:

#### How does GHC compile non-strictness?

`GHC` (the Glasgow haskell compiler) internally uses multiple intermediate
representations, in order of original, to what is finally produced:

- Haskell (the source language)
- Core (a minimal set of constructs to represent the source language)
- STG (Spineless tagless G-machine, a low-level intermediate representation that accurately captures non-strict evaluation)
- C-- (A C-like language with GHC-specific customization to support platform
  independent code generation).
- Assembly


Here, I will show how to lower simple non-strict programs from a **fictitous** `Core` like language down to `C` , while skipping `STG`, since it doesn't
really add anything to the high-level discussion at this point.

#### Our example of compiling non-strictness

Now, we need a *strategy* to compile the non-strict version of our program.
Clearly, `C` cannot express laziness directly, so we need some other
mechanism to implement this. I will first code-dump, and then explain as we go along.


###### Executable `repl.it`:
<iframe height="400px" width="100%" src="https://repl.it/@bollu/Compiling-non-strict-programs-on-the-call-stack?lite=true" scrolling="no" frameborder="no" allowtransparency="true" allowfullscreen="true" sandbox="allow-forms allow-pointer-lock allow-popups allow-same-origin allow-scripts allow-modals"></iframe>

###### Source code
```
#include <assert.h>
#include <stdio.h>

/* a boxed value is a function that can be executed to compute something.
* We make the return value `void` on purpose. This needs to be typecast to a concrete
* Boxed type to get a value out of it: eg, typecast to BoxedInt.
*/
typedef void (*Boxed)();

/* A boxed int, that on evaluation yields an int*/
typedef int (*BoxedInt)();

/* one = 1# */
int one() {
    return 1;
}

/* bottom = bottom */
void bottom() {
    printf("in function: %s\n", __FUNCTION__);
    bottom();
}

/* K x y = x */
Boxed K(Boxed x, Boxed y) {
  return x;
}

/*
main :: () -> Void
main = case K(one, loopy) of -- force K to be evaluated with a `case`
            kret -> case kret of  -- Call the return value of K as `x`, and force evaluation.
                    i -> printPrimInt(i) -- Call the vreturn value of `x` as `primx` and then print it.
*/
int main() {
    Boxed kret = K((Boxed)one, (Boxed)bottom);
    int i = (*(BoxedInt)kret)();
    printf("%d", i);
    return 1;
}

```

We convert every possibly lazy value into a `Boxed` value, which is a function pointer that knows how to compute the
underlying value. When the lazy value is forced by a `case`, we call the `Boxed` function to compute the output.

This is a straightforward way to encode non-strictness in C. However, do note that this is not *lazy*, because a value could get
recomputed many times. *Laziness* guarantees that a value is only computed once and is later memoized.


#### Compiling with a custom call stack / continuations

As one may notice, we currenly use the native call stack every time we *force*
a lazy value. However, in doing  so, we might actually run out of stack space,
which is undesirable. Haskell programs like to have "deep" chains of values
being forced, so we would quite likely run out of stack space.

Therefore, GHC opts to manage its own call stack on the heap. The generated
code looks as you would imagine: we maintain a stack of function pointers +
auxiliary data ( stack saved values), and we push and pop over this "stack".
When we run out of space, we `<find correct way to use mmap>` to increase our
"stack" size.

I've played around with this value a little bit, and have found that the modern
stack size is quite large: IIRC, It allowed me to allocate ~`26 GB`. I believe
that the amount it lets you allocate is tied directly to the amount of physical
memory + swap you have. I'm not too sure, however. So, [for my haskell compiler, `sxhc`](https://github.com/bollu/simplexhc-cpp.git), I am considering
cheating and just using the stack directly.

Code for the same example (with the K combinator) is provided here.

##### Executable `repl.it`:
<iframe height="1000px" width="100%" src="https://repl.it/@bollu/Compiling-programs-with-continuations?lite=true" scrolling="no" frameborder="no" allowtransparency="true" allowfullscreen="true" sandbox="allow-forms allow-pointer-lock allow-popups allow-same-origin allow-scripts allow-modals"></iframe>


##### Source code

```c
#include <assert.h>
#include <stdio.h>
#define STACK_SIZE 50000

/* a boxed value is a function that can be executed to compute something. */
typedef void (*Boxed)();

/* a return continuation that receives a boxed value. */
typedef void (*BoxedContinuation)(Boxed);

/* A return continuation that receives an int value. */
typedef void (*IntContinuation)(int);

/* Custom stack allocated on the .data section*/
void *stack[STACK_SIZE];

/* Stack pointer */
int sp = 0;

/* Push a continuation `cont` */
void pushContinuation(void *cont) {
    assert(sp >= 0);
    assert(sp < STACK_SIZE);
    stack[sp] = cont;
    sp++;
}

/* Pop a continuation frame. */
void *popContinuation() {
    assert(sp < STACK_SIZE);
    assert(sp >= 0);
    sp--;
    void *cont = stack[sp];
    return cont;
}

/* one = 1# */
void one() {
    printf("in function: %s\n", __FUNCTION__);
    void *f = popContinuation();
    (*(IntContinuation)(f))(1);
}

/* bottom = bottom */
void bottom() {
    printf("in function: %s\n", __FUNCTION__);
    bottom();
}

/* K x y = x */
void K(Boxed x, Boxed y) {
    printf("in function: %s\n", __FUNCTION__);
    void *f = popContinuation();
    (*(BoxedContinuation)(f))(x);
}

void XForceContinuation(int i) {
    printf("in function: %s\n", __FUNCTION__);
    printf("%d", i);
}

void KContinuation(Boxed x) {
    printf("in function: %s\n", __FUNCTION__);
    pushContinuation((void *)XForceContinuation);
    x();
}

int main() {
    printf("in function: %s\n", __FUNCTION__);
    pushContinuation((void *)KContinuation);
    K(one, bottom);
    return 0;
}
```

we maintain our own "call stack" of continuations. These continuations are precisely the
parts of the code that deal with the return value of a case. ever

```hs
case x of
    xeval -> expr
```

compiles to:

```c
pushContinuation(XEvalContinuation);
x()
```

That is, push a continuation, and then "enter" into `x`.

One might have a question: does this still not use the call stack? There is a
function call at the end of most functions in the source code, so in theory, we
_are_ using the call stack, right? The answer is no. It's thanks to a neat
optimisation technique called _tail call elimination_. The observation is that
_after the call_, there is no more code to execute in the caller. So, by
playing some stack tricks, one can convert a _call_ to a _jump_.

Remember, a _`call`_ instruction uses the stack to setup a stack frame, under
the assumption that we will _`ret`_ at some point.  But, clearly, under our
compilation model, we will never `ret`, simply call more functions. So, we
don't *need* the state maintained by a `call`. We can simply `jmp`.

#### Wrapping up

I hope I've managed to convey the _essence_ of how to compile Haskell. I skipped a couple of things:
- haskell data types: sum and product types. These are straightforward, they just compiled to tagged structs.
- `let` bindings: These too are straightforward, but come with certain retrictions in STG. It's nothing groundbreaking,and
   is well written in the paper.
- Black holes: Currently, we are not truly _lazy_, in that we do not update values once they are computed.
- GC: how to weave the GC through the computation is somewhat non-trivial.

All of this is documented in the excellent paper:
[Implementing lazy languages on stock hardware](https://www.dcc.fc.up.pt/~pbv/aulas/linguagens/peytonjones92implementing.pdf).


I am considering extending this blog post that expands on these ideas. If there
is interest, please do e-mail me at `siddu.druid@gmail.com`.

# Exact sequence of pointed sets

This was a shower thought. I don't even if these form an abelian category.
Let's assume we have pointed sets, where every set has a distinguished
element $*$. $p$ will be analogous to the zero of an abelian
group. We will also allow multi-functions, where a function can have
multiple outputs. Now let's consider two sets, $A, B$ along with their
'smash union' $A \vee B$ where we take the disjoint union of $A, B$ with a
smashed $*$. To be very formal:

$$
A \vee B = \{0\} \times (A - \{ * \}) \cup \{1\}\times (B - \{ * \}) \cup \{ * \}
$$

We now consider the exact sequence:

$$
(A \cap B, *) \xrightarrow{\Delta} (A \vee B, *) \xrightarrow{\pi} (A \cup B, *)
$$

with the maps as:
$$
\begin{aligned}
&ab \in A \cap B \xmapsto{\Delta} (0, ab), (1, ab) \in A \vee B \\
&(0, a) \in A \vee B \xmapsto{\pi}
\begin{cases}
 * & \text{if } a \in B \\
 a  &\text{otherwise} \\
\end{cases} \\
&(1, b) \in A \vee B \xmapsto{\pi}
\begin{cases}
 * & \text{if } b \in A \\
 b  &\text{otherwise} \\
\end{cases} \\
\end{aligned}
$$

- We note that $\Delta$ is a multi-function, because it produces as output both
  $(0, ab)$ and $(1, ab)$.
- $\ker(\pi) = \pi^{-1}(*) = \{ (0, a) : a \in B \} \cup \{ (1, b) : b \in A \}$
- Since it's tagged $(0, a)$, we know that $a \in A$. Similarly, we know that $b \in B$.
- Hence, write $\ker(\pi) = \{ (0, ab), (1, ab) : ab \in A \cap B \} = im(\Delta)$

This exact sequence also naturally motivates one to consider
$A \cup B - A \cap B = A \Delta B$, the symmetric difference. It also gives
the nice counting formula $|A \vee B| = |A \cap B| + |A \cup B|$, also known
as inclusion-exclusion.

I wonder if it's possible to recover incidence algebraic derivations from this
formuation?

#### Variation on the theme: direct product

This version seems wrong to me, but I can't tell what's wrong. Writing it down:

$$
\begin{aligned}
(A \cap B, *) \xrightarrow{\Delta} (A \times B, (*, *)) \xrightarrow{\pi} (A \cup B, *)
\end{aligned}
$$

with the maps as:

$$
\begin{aligned}
&ab \in A \cap B \xmapsto{\Delta} (ab, ab) \in A \times B \\
&(a, b) \in A \times B \xmapsto{\pi}
\begin{cases}
 * & \text{if } a = b \\
 a, b  &\text{otherwise} \\
\end{cases} \\
\end{aligned}
$$

One can see that:
- $A \cap B \xrightarrow{\Delta} A \times B$ is injective
- $A \cap B \xrightarrow{\pi} A \cup B$ is surjective
- $ker(\pi) = \pi^{-1}(*) = \{ (a, b) : a \in A, b \in B, a = b \} = im(\Delta)$

Note that to get the last equivalence, we do not consider elements like
$\pi(a, *) = a, *$ to be a pre-image of $*$, because they don't _exact_ ly map
into $*$ [pun intended].



# What is a syzygy?

Word comes from greek word for "yoke" . If we have two oxen pulling, we yoke
them together to make it easier for them to pull.

#### The ring of invariants

Rotations of $\mathbb R^3$: We have a group $SO(3)$ which is acting on a vector space
$\mathbb R^3$. This  preserves the length, so it preserves the
polynomial $x^2 + y^2 + z^2$. This polynomial $x^2 + y^2 + z^2$ is said to be
the invariant polynomial of the group $SO(3)$ acting on the vector space
$\mathbb R^3$.

- But what does $x, y, z$ even mean? well, they are linear function $x, y, z: \mathbb R^3 \rightarrow \mathbb R$.
  So $x^2 + y^2 + z^2$ is a "polynomial" of these linear functions.

#### How does a group act on polynomials?

- If $G$ acts on $V$, how does $G$ act on the polynomial functions $V \rightarrow \mathbb R$?
- In general, if we have a function $f: X \rightarrow Y$ where $g$ acts on $X$ and $Y$
  (in our case, $G$ acts trivially on $Y=\mathbb R$), what is $g(f)$?
- We define $(gf)(x) \equiv g (f(g^{-1}(x)))$.
- What is the $g^{-1}$? We should write
  $(gf)(gx) = g(fx)$. This is like $g(ab) = g(a) g(b)$. We want to get
  $(gf)(x) = (gf)(g(g^{-1}x) = g(f(g^{-1}x))$.
- If we miss out $g^{-1}$ we get a mess. Let's temporarily define $(gf)(x) = f(g(x))$. Consider
   $(gh)f(x) = f(ghx)$. But we
  can also take this as $(gh)(f(x)) = g((hf)(x)) = (hf)(gx) = f(hgx)$. This is
  absurd as it gives $f(ghx) = f(hgx)$.

#### Determinants

We have $SL_n(k)$ acting on $k^n$, it acts transitively, so there's no interesting non-constant
invariants. On the other hand, we can have $SL_n(k)$ act on $\oplus_{i=1}^n k^n$. So if $n=2$
we have:

$$
\begin{bmatrix}
a & b \\ c & d
\end{bmatrix}
$$

acting on:

$$
\begin{bmatrix}
x_1 & y_1 \\ x_2 & y_2
\end{bmatrix}
$$

This action preserves the polynomial $x_1 y_2 - x_2 y_1$, aka the determinant. anything that
ends with an "-ant" tends to be an "invari-ant" (resultant, discriminant)

#### $S_n$ acting on $\mathbb C^n$ by permuting coordinates.

Polynomials are functions $\mathbb C[x_1, \dots, x_n]$. Symmetric group
acts on polynomials by permuting $x_1, \dots, x_n$. What are the invariant
polynomials?

- $e_1 \equiv x_1 + x_2 + \dots x_n$
- $e_2 \equiv x_1 x_2 + x_1 x_3 + \dots + x_{n-1} x_n$.
- $e_n \equiv x_1 x_2 \dots x_n$.

These are the famous elementary symmetric functions. If we think of
$(y - x_1) (y - x_2) \dots (y - x_n) = y^n - e_1 y^{n-1} + \dots e_n$.

- The **basic theory of symmetric functions** says that every invariant polynomial
  in $x_1, \dots x_n$ is a polynomial in $e_1, \dots, e_n$.

#### Proof of elementary theorem

Define an ordering on the monomials; order by lex order.
Define $x_1^{m_1} x_2^{m_2} > x_1^{n_1} x_2^{n_2} \dots$ iff either
$m_1 > n_1$ or $m_1 = n_1 \land m_2 > n_2$ or $m_1 = n_1 \land m_2 = n_2 \land m_3 > n_3$ and so on.

Suppose $f \in \mathbb C[x_1, \dots, x_n]$ is invariant. Look at the biggest monomial in $f$.
Suppose it is $x_1^{n_1} x_2^{n_2} \dots$. We subtract:

$$
\begin{aligned}
P \equiv
&(x_1 + x_2 \dots)^{n_1 - n_2} \\
&\times  (x_1 x_2 + x_1 x_2 \dots)^{n_2 - n_3} \\
&\times  (x_1 x_2 x_3 + x_1 x_2 x_4 \dots)^{n_3 - n_4} \\
\end{aligned}
$$

This kills of the biggest monomial in $f$. If $f$ is symmetric,
Then we can order the term we choose such that $n_1 \geq n_2 \geq n_3 \dots$.
We need this to keep the terms $(n_1 - n_2), (n_2 - n_3), \dots$ to be positive.
So we have now killed off the largest term of $f$.  Keep doing this to kill of $f$ completely.

This means that the invariants of $S_n$ acting on $\mathbb C^n$ are a finitely generated
algebra over $\mathbb C$. So we have a finite number of generating invariants such that every invariant
can be written as a polynomial of the generating invariants with coefficients in $\mathbb C$. This is
the first non-trivial example of invariants being finitely generated.


The algebra of invariants is a **polynomial ring** over $e_1, \dots, e_n$. This means that there
are no **non-trivial-relations** between $e_1, e_2, \dots, e_n$. This is unusual; usually
the ring of generators will be complicated.  This simiplicity tends to happen if $G$ is
a reflection group. We haven't seen what a syzygy is yet; We'll come to that.

#### Complicated ring of invariants

Let $A_n$ (even permutations). Consider the polynomial $\Delta \equiv \prod_{i < j} (x_i - x_j)$
This is called as the discriminant.
This looks like $(x_1 - x_2)$, $(x_1 - x_2)(x_1 - x_3)(x_2 - x_3)$, etc. When $S_n$ acts on $\Delta$,
it either keeps the sign the same or changes the sign. $A_n$ is the subgroup of $S_n$ that
keeps the sign fixed.

What are the invariants of $A_n$? It's going to be all the invariants of $S_n$, $e_1, \dots, e_n$,
plus $\Delta$ (because we defined $A_n$ to stabilize $\Delta$). There are no relations between
$e_1, \dots, e_n$. But there are relations between $\Delta^2$ and $e_1, \dots, e_n$ because $\Delta^2$
is a symmetric polynomial.

Working this out for $n=2$,we get $\Delta^2 = (x_1 - x_2)^2 = (x_1 + x_2)^2 - 4 x_1 x_2 = e_1^2 - 4 e_1 e_2$.
When $n$ gets larger, we can still express $\Delta^2$ in terms of the symmetric polynomials,
but it's frightfully complicated.

This phenomenon is an example of a Syzygy. For $A_n$, the ring of invariants is finitely generated
by $(e_1, \dots, e_n, \Delta)$. There is a non-trivial relation where $\Delta^2 - poly(e_1, \dots, e_n) = 0$.
So this ring is not a polynomial ring. This is a first-order Syzygy. Things can get more complicated!


#### Second order Syzygy

Take $Z/3Z$ act on $\mathbb C^2$. Let $s$ be the generator of $Z/3Z$. We define
the action as $s(x, y) = (\omega x, \omega y)$ where $\omega$ is the cube root of unity.
We have $x^ay^b$ is invariant if $(a + b)$ is divisible by $3$, since we will just get $\omega^3 = 1$.

So the ring is generated by the monomials $(z_0, z_1, z_2, z_3) \equiv (x^3, x^2y, xy^2, y^3)$.
Clearly, these have relations between them. For example:
- $z_0 z_2 =  x^4y^2 = z_1^2$. So $z_0 z_2 - z_1^2 = 0$.
- $z_1 z_3   x^2y^4 = z_2^2$. So $z_1 z_3 - z_2^2 = 0$.
- $z_0 z_3 = x^3y^3 = z_1 z_2$. So $z_0 z_3 - z_1 z_2 = 0$.

We have 3 first-order syzygies as written above. Things are more complicated than that. We can
write the syzygies as:

- $p_1 \equiv z_0 z_2 - z_1^2$.
- $p_2 \equiv z_1 z_3 - z_2^2$.
- $p_3 \equiv z_0 z_3 - z_1 z_2$.

We have $z_0 z_2$ in $p_1$. Let's try to cancel it with the $z_2^2$ in $p_2$. So we consider:

$$
\begin{aligned}
& z_2 p_1 + z_0 p_2 \\
&= z_2 (z_0 z_2 - z_1^2) + z_0 (z_1 z_3 - z_2^2) \\
&= (z_0 z_2^2 - z_2 z_1^2) + (z_0  z_1 z_3 - z_0 z_2^2) \\
&= z_0 z_1 z_3 - z_2 z_1^2 \\
&= z_1(z_0 z_3 - z_1 z_2) \\
&= z_1 p_3
\end{aligned}
$$

So we have non-trivial relations between $p_1, p_2, p_3$! This is a second order syzygy, a sygyzy between syzygies.


We have a ring $R \equiv k[z_0, z_1, z_2, z_3]$. We have a map $R \rightarrow \texttt{invariants}$.
This has a nontrivial kernel, and this kernel is spanned by $(p_1, p_2, p_3) \simeq R^3$. But this itself
has a kernel $q = z_1 p_1 + z_2 p_2 + z_3 p_3$. So there's an exact sequence:

$$
\begin{aligned}
0 \rightarrow R^1 \rightarrow R^3 \rightarrow R=k[z_0, z_1, z_2, z_3] \rightarrow \texttt{invariants}
\end{aligned}
$$

In general, we get an invariant ring of linear maps that are invariant under the group action.
We have polynomials $R \equiv k[z_0, z_1, \dots]$ that map onto the invariant ring. We have
relationships between the $z_0, \dots, z_n$. This gives us a sequence of syzygies. We have many
questions:

1. Is $R$ finitely generated as a $k$ algebra? Can we find a finite number of generators?
2. Is $R^m$ finitely generated (the syzygies as an $R$-MODULE)? To recall the difference, see that $k[x]$
   is finitely generated as an ALGEBRA  by $(k, x)$ since we can multiply the $x$s. It's not finitely generated as a
   MODULE as we need to take all powers of $x$: $(x^0, x^1, \dots)$.
3. Is this SEQUENCE of sygyzy modulues FINITE?
4. Hilbert showed that the answer is YES if $G$ is reductive and $k$ has characteristic zero. We will
   do a special case of $G$ finite group.

We can see why a syzygy is called such; The second order sygyzy "yokes" the first order sygyzy. It ties together
the polynomials in the first order syzygy the same way oxen are yoked by a syzygy.



#### Is inclusion/exclusion a syzygy?

I feel it is, since each level of the inclusion/exclusion arises as a "yoke" on the previous level.
I wonder how to make this precise.


#### References
- [Richard E Borcherds: Commutative Algebra, lecture 3](https://www.youtube.com/watch?v=RYPt7kGdo7s&list=PL8yHsr3EFj53rSexSz7vsYt-3rpHPR3HB&index=3)



# Under the spell of Leibniz's dream

- [Link to the article by djikstra](http://www.cs.utexas.edu/users/EWD/transcriptions/EWD12xx/EWD1298.html)
- [`monochrom`'s favourite work on djikstra](http://www.vex.net/~trebla/ewd.html)

I found it very quotable. I'm posting some quotes below.

- On applied versus pure mathematics:

> An important side-effect of the hard times was the creation of a spiritual
> climate in which the distinction between pure and applied science had
> vanished: of all the things you could do, you just did the most urgent one,
> and the development of some urgently needed theory was often the most
> practical thing to do.

- On 'applied institutes':

> The worst thing with institutes explicitly devoted to applied science is that
> they tend to become institutes of second-rate theory.

- On the artificial divide between theory and applied sections of university:

> These days there is so much obsession with application that, if the
> University is not careful, external forces, which do make the distinction,
> will drive a wedge between "theory" and "practice" and may try to banish the
> "theorists" to a ghetto of separate departments and separate buildings. A
> simple extrapolation will tell us that in due time the isolated practitioners
> will have little to apply; this is well-known, but has never prevented the
> financial mind from killing the goose that lays the golden eggs.

- On programming as typing:

> Needless to say, this confusion between the score and the composition led to
> an underestimation of the intellectual challenges programming presents

- On hilbert and axiomatics:

>  Hilbert's revolution was in any case to redefine "proof" to become a
>  completely rigorous notion, totally different from the psycho/sociological
>  "A proof is something that convinces other mathematicians."





# Normal operators: Decomposition into Hermitian operators

Given a normal operator $A$, we can always decompose it $A = B + iC$
where $B = B^{\dagger}$, $C = C^\dagger$, and $[B, C] = 0$.


This means that we can define 'complex measurements' using a normal operator,
because a normal operator has full complex spectrum. Since we can always
decompose such an operator $A$ into two hermitian operators $B, C$
that commute, we can diagonalize $B, C$ simultaneously and thereby measure
$B, C$ simultaneously.

So extending to "complex measurements" gives us no more power than staying
at "real measurements"

### Decomposing a normal operator

Assume we have a normal operator $A$. Write the operator in its eigenbasis $\{ |a_k \rangle \}$.
This will allow us to write $A = \sum_k |a_k \rangle \langle a_k|$.
with each $a_k = b_k + i c_k$. Now write this as:

$$
\begin{aligned}
& A = \sum_k (b_k + i c_k)|a_k \rangle \langle a_k| \\
& A = \sum_k b_k  |a_k \rangle \langle a_k| + i c_k |a_k \rangle \langle a_k|  \\
& A = B + iC \\
\end{aligned}
$$

$B, C$ are simultaneously diagonalizable in the eigenbasis $\{ |a_k \rangle \}$
and hence $[B, C] = 0$.


# Readable pointers

I recently had to debug a whole bunch of code that manipuates pointers, so I
need to stare at random things like `0x7f7d6ab2c0c0`, like so:

```
mkClosure_capture0_args0 (0x7f079ae2a0c0:) -> 0x556b95a23350:
mkClosure_capture0_args0 (0x7f079ae2a0e0:) -> 0x556b95a3f3e0:
mkClosure_capture0_args2 (0x7f079ae2a000:,
  0x556b95a23350:, 0x556b95a3f3e0:) -> 0x556b95a232e0:
evalClosure (0x556b95a232e0:)
  ⋮evalClosure (0x556b95a23350:)
  ⋮  ⋮mkConstructor1 (MkSimpleInt, 0x1) -> 0x556b9596c0b0:
  ⋮=>0x556b9596c0b0:
  ⋮isConstructorTagEq (0x556b9596c0b0:MkSimpleInt, MkSimpleInt) -> 1
  ⋮extractConstructorArg  0 -> 0x1:
  ⋮evalClosure (0x556b95a3f3e0:)
  ⋮  ⋮mkConstructor1 (MkSimpleInt, 0x2) -> 0x556b95a23190:
  ⋮=>0x556b95a23190:
  ⋮isConstructorTagEq (0x556b95a23190:MkSimpleInt, MkSimpleInt) -> 1
  ⋮extractConstructorArg  0 -> 0x2:
  ⋮mkConstructor1 (MkSimpleInt, 0x3) -> 0x556b95902a30:
=>0x556b95902a30:
```

 I got annoyed because it's hard to spot differences across numbers. So I wrote
 a small '''algorithm''' that converts this into something pronounceable:

```cpp
char *getPronouncableNum(size_t N) {
     const char *cs = "bcdfghjklmnpqrstvwxzy";
     const char *vs = "aeiou";

     size_t ncs = strlen(cs); size_t nvs = strlen(vs);

     char buf[1024]; char *out = buf;
     int i = 0;
     while(N > 0) {
         const size_t icur = N % (ncs * nvs);
         *out++ = cs[icur%ncs]; *out++ = vs[(icur/ncs) % nvs];
         N /= ncs*nvs;
         if (N > 0 && !(++i % 2)) { *out++ = '-'; }
     }
     *out = 0;
     return strdup(buf);
};
```

which gives me the much more pleasant output:

```
mkClosure_capture0_args0 (0x7fbf49b6d0c0:cisi-jece-xecu-yu)
  -> 0x561c5f11f9d0:suje-zoni-ciho-ko
mkClosure_capture0_args0 (0x7fbf49b6d0e0:qosi-jece-xecu-yu)
  -> 0x561c5f12f1b0:leda-guni-ciho-ko
mkClosure_capture0_args2 (0x7fbf49b6d000:ziqi-jece-xecu-yu,
  0x561c5f11f9d0:suje-zoni-ciho-ko,
  0x561c5f12f1b0:leda-guni-ciho-ko)
    -> 0x561c5f11f960:kuhe-zoni-ciho-ko
evalClosure (0x561c5f11f960:kuhe-zoni-ciho-ko)
  ⋮evalClosure (0x561c5f11f9d0:suje-zoni-ciho-ko)
  ⋮  ⋮mkConstructor1 (MkSimpleInt, 0x1) -> 0x561c5f129c10:qifa-duni-ciho-ko
  ⋮=>0x561c5f129c10:qifa-duni-ciho-ko
  ⋮isConstructorTagEq (0x561c5f129c10:MkSimpleInt, MkSimpleInt) -> 1
  ⋮extractConstructorArg  0 -> 0x1:ca
  ⋮evalClosure (0x561c5f12f1b0:leda-guni-ciho-ko)
  ⋮  ⋮mkConstructor1 (MkSimpleInt, 0x2) -> 0x561c5f120200:nuhi-zoni-ciho-ko
  ⋮=>0x561c5f120200:nuhi-zoni-ciho-ko
  ⋮isConstructorTagEq (0x561c5f120200:MkSimpleInt, MkSimpleInt) -> 1
  ⋮extractConstructorArg  0 -> 0x2:da
  ⋮mkConstructor1 (MkSimpleInt, 0x3) -> 0x561c5f100010:kuqi-koni-ciho-ko
=>0x561c5f100010:kuqi-koni-ciho-ko
```

The strings of the form `ziqi-jece-xecu-yu` makes it way easier to see control flow.
I can also see if two pointers are close, based on shared suffixes: ciho-ko is
shared, which means the numbers are themselves close.

- It turns out there's a system called [proquints](https://arxiv.org/html/0901.4016)
  that allows for such a thing already!


<!-- - [Support me in making more visualizations!](https://www.patreon.com/bollu) -->
# The grassmanian, handwavily

The grassmanian is a manifold consisting of, roughly, $k$ dimensional subspaces
of an $n$ dimensional vector space.

Here, I'll record derivations of how we represent grassmanians, the exponential
map, logarithm map, and the parallel transport with "physicist style"
reasoning. Really, one needs to be careful because the grassmanian is a
quotient of the non-compact steifel manifold, so we need to be careful about
choosing representatives and whatnot. However, nothing beats physicist
reasoning for intuition, so I'm going to do all the derivations in that style.

[TODO]


# Lie bracket as linearization of conjugation

Let us have $Y = GXG^{-1}$ with all of these as matrices. Let's say that $G$
is very close to the identity: $G = I + E$ with $E^2 = 0$ ($E$ for epsilon).
Note that now, $G^{-1} = (I + E)^{-1}$, which by abuse of notation
can be written as $1/(I + E)$, which by taylor expansion is equal to
$I - E + E^2 - E^3 + \dots$. Since $E$ is nilpotent, we truncate at $E^2$
leaving us with $(I - E)$ as the inverse of $(I+E)$. We can check that this is correct, by computing:

$$
\begin{aligned}
&(I+E)(I - E) = \\
&= I - E + E - E^2 \\
&= I - E^2 = \\
&= I - 0 = I
\end{aligned}
$$

This lets us expand out $Y$ as:

$$
\begin{aligned}
&Y = GXG^{-1} \\
&Y = (I + E)X(I + E)^{-1} \\
&Y = (I + E)X(I - E) \\
&Y = IXI -IXE + EXI - EXE \\
&Y = X - XE + EX - EXE
\end{aligned}
$$

Now we assert that because $E$ is small, $EXE$ is of order $E^2$ and will therefore
vanish. This leaves us with:

$$ GXG^{-1} = Y = X + [E, X] $$

and so the lie bracket is the Lie algebra's way of recording the effect of the
group's conjugacy structure.

# Computational Origami

- [RabbitEar: library for building origami visualizations in the browser](https://rabbitear.org/docs/)
- [ORIPA: tool for visualizing flat folded origami](https://github.com/oripa/oripa)
- [TreeMaker:]()
- [Origami Simulator: Tool to simulate origami, going from flat shaped to folded shaped](https://origamisimulator.org/)

# Katex in duktape

Here's some code to use `duktape`, a lightweight JavaScript interpreter
to run `katex` when implementing a custom static site generator [as I
am doing for this website]. This seems to be *way more lightweight*
than relying on Node, since we don't need to pay for inter-procedure-calls.


I haven't benchmarked my static site generator against others, but I would
be surprised if it is much faster, since it is written entirely in C, and
avoids anything 'expensive'.

```c
#include "duktape.h"
#include <stdio.h>
#include <assert.h>
typedef long long ll;

void vduk_print_stack(duk_context *ctx, const char *fmt, va_list args){
    char *outstr = nullptr;
    vasprintf(&outstr, fmt, args);
    assert(outstr);

    printf("\nvvv%svvv\n", outstr);
    printf("[TOP OF STACK]\n");
    const int len = duk_get_top(ctx);
    for(int i = 1; i <= len; ++i) {
        duk_dup(ctx, -i);
        printf("stk[-%2d] = %20s\n", i, duk_to_string(ctx, -1));
        duk_pop(ctx);
    }
    printf("^^^^^^^\n");
}


void duk_print_stack(duk_context *ctx, const char *fmt, ...) {
    va_list args;
    va_start(args, fmt);
    vduk_print_stack(ctx, fmt, args);
    va_end(args);
}
int main() {
    const char *latex_to_compile = "\\int_0^\\infty f(x) dx";
    const char *broken_latex_to_compile = "\\int_0^\\infty \\foobar f(x) dx";


    // FILE *fkatex = fopen("/home/bollu/blog/katex/katex.min.js", "rb");
    FILE *fkatex = fopen("/home/bollu/blog/katex/katex.min.js", "rb");
    if (fkatex == nullptr) { assert(false && "unable to open katex.min.js"); }

    fseek(fkatex, 0, SEEK_END);
    const ll len = ftell(fkatex); fseek(fkatex, 0, SEEK_SET);
    char *js = (char *)calloc(sizeof(char), len + 10);

    const ll nread = fread(js, 1, len, fkatex);
    assert(nread == len);
    duk_context *ctx = duk_create_heap_default();
    duk_push_string(ctx, "katex.min.js"); // for error message
    if (duk_pcompile_string_filename(ctx, 0, js) != 0) {
        fprintf(stderr, "===katex.min.js compliation failed===\n%s\n===\n",
                duk_safe_to_string(ctx, -1));
        assert(false && "unable to compile katex.min.js");
    } else {
        fprintf(stderr, "===katex.min.js successfully complied===\n");

        duk_print_stack(ctx, "Stack afer compilation", __LINE__);
        duk_call(ctx, 0);
        printf("program result: %s\n", duk_safe_to_string(ctx, -1));

    }



    // https://wiki.duktape.org/howtofunctioncalls
    duk_print_stack(ctx, "%d", __LINE__);
    if(duk_peval_string(ctx, "katex") != 0) {
        printf("eval failed: %s\n", duk_safe_to_string(ctx, -1));
        assert(0 && "unable to find the katex object");
    }  else {
        duk_print_stack(ctx, "%d", __LINE__);
    }

    duk_print_stack(ctx, "%d", __LINE__);
    duk_push_string(ctx, "renderToString");
    duk_push_string(ctx, latex_to_compile);

    duk_print_stack(ctx, "%d", __LINE__);
    if(duk_pcall_prop(ctx, -3, 1) == DUK_EXEC_SUCCESS) {
        printf("===katexed output:===\n%s\n", duk_to_string(ctx, -1));
    } else {
        printf("unable to katex: %s\n", duk_to_string(ctx, -1));
        assert(false && "unable to katex input");
    }

    return 0;
}
```

# Kebab case

[I learnt from the Nu shell blog](https://www.nushell.sh/blog/2020/08/23/year_of_nushell.html)
that `this-style-of-writing` variables is called as `kebab-case`. Very
evocative.

# Localization: Introducing epsilons (TODO)

We can think of localization at a zero divisors
as going from a regime of having divisors of zero into a
regime of having $\epsilon$. I'll explore this perspective by consider
$R = \mathbb Z/12 \mathbb Z$.


# NaN punning: Storing integers in doubles in JavaScript

This is a technique that allows us to store data inside a `double` by
punning the value of a `NaN`. This is used inside javascript engines
to represent all possible user types as a single NaN.
[This is well explained at the SpiderMonkey internals page](https://developer.mozilla.org/en-US/docs/Mozilla/Projects/SpiderMonkey/Internals)

```cpp
#include <assert.h>
#include <iostream>
#include <limits>
using namespace std;
// https://en.wikipedia.org/wiki/NaN
union PunDouble {
    double d;
    struct {
        uint64_t m      : 51;
        uint32_t qnan: 1;
        uint32_t e      : 11;
        uint32_t s      : 1;
    } bits;
    PunDouble(double d) : d(d) {};
    PunDouble(uint32_t s, uint32_t e, uint64_t m) {
        bits.s = s;
        bits.e = e;
        bits.qnan = 1;
        bits.m = m;
    }
};

union PunInt {
    int32_t i;
    uint32_t bits;
    PunInt(int32_t i): i(i) {};
};

using namespace std;
struct Box {

    inline bool is_int() const {
        auto pd = PunDouble(d);
        return pd.bits.e == 0b11111111111 && pd.bits.qnan == 1;
    }
    inline bool isdouble() const {
        auto pd = PunDouble(d);
        return (pd.bits.e != 0b11111111111) || (pd.bits.qnan == 0);
    }
    int32_t get_int() const {
        assert(is_int());
        uint64_t m = PunDouble(d).bits.m; return PunInt(m).i;
    }
    double get_double() const { assert(isdouble()); return d; }
    Box operator +(const Box &other) const;

    static Box mk_int(int32_t i) {
        return Box(PunDouble(1, 0b11111111111, PunInt(i).bits).d);
    }
    static Box mk_double(double d) { return Box(d); }
    double rawdouble() const { return d; }
    private:
    double d; Box(double d) : d(d) {}
};

// = 64 bits
Box Box::operator + (const Box &other) const {
    if (isdouble()) {
        assert(other.isdouble());
        return Box::mk_double(d + other.d);
    }
    else {
        assert(is_int());
        assert(other.is_int());
        return Box::mk_int(get_int() + other.get_int());
    }
}

ostream &operator << (ostream &o, const Box &b) {
    if (b.isdouble()) { return o << "[" << b.get_double() << "]"; }
    else { return o << "[" << b.get_int() << "]"; }
}

int32_t randint() { return (rand() %2?1:-1) * (rand() % 100); }

int32_t main() {

    // generate random integers, check that addition checks out
    srand(7);
    for(int32_t i = 0; i < 1000; ++i) {
        const int32_t i1 = randint(), i2 = randint();
        const Box b1 = Box::mk_int(i1), b2 = Box::mk_int(i2);
        cout << "i1:" << i1 << "  b1:" << b1 << "  b1.double:" << b1.rawdouble() << "  b1.get_int:" << b1.get_int() << "\n";
        cout << "i2:" << i2 << "  b2:" << b2 << "  b2.double:" << b2.rawdouble() << "  b2.get_int:" << b2.get_int() << "\n";
        assert(b1.is_int());
        assert(b2.is_int());
        assert(b1.get_int() == i1);
        assert(b2.get_int() == i2);
        Box b3 = b1 + b2;
        assert(b3.is_int());
        assert(b3.get_int() == i1 + i2);
    }

    for(int32_t i = 0; i < 1000; ++i) {
        const int32_t p1 = randint(), q1=randint(), p2 = randint(), q2=randint();
        const double d1 = (double)p1/(double)q1;
        const double d2 = (double)p2/(double)q2;
        const Box b1 = Box::mk_double(d1);
        const Box b2 = Box::mk_double(d2);
        cout << "d1: " << d1 << " | b1: " << b1 << "\n";
        cout << "d2 " << d2 << " | b2: " << b2 << "\n";
        assert(b1.isdouble());
        assert(b2.isdouble());

        assert(b1.get_double() == d1);
        assert(b2.get_double() == d2);;
        Box b3 = b1 + b2;
        assert(b3.isdouble());
        assert(b3.get_double() == d1 + d2);
    }
    return 0;
}
```



# Offline Documentation

I'm collecting sources of offline documentation, because my internet
has been quite unstable lately due to the monsoon. I realized that when it
came to C, I would always `man malloc`, or `apropos exit` to recall
the `calloc` API, or to learn about `atexit`. I wanted to get offline docs
for all the languages I use, so I'm building a list:

- C: man pages
- [C++: cppman](https://github.com/aitjcize/cppman)
- [C++: synth](https://github.com/Oberon00/synth)
- [python: pydoc](https://docs.python.org/3/library/pydoc.html)
- haskell: haddock


# Using Gurobi

I've been trying to learn how to use Gurobi, the industrial strength
solver for linear and quadratic equation systems.

- [compile the C+ bindings](https://stackoverflow.com/questions/46779850/cannot-compile-gurobi-examples-in-version-7-5-1)

```text
$ cd /path/to/gurobi90/linux64/src/build/ && make
```

# [osqp: convex optimizer in 6000 LoC](osqp-an-industrial-strength-convex-optimizer-in-6000-loc)

- [Here's the github link to their repo](https://github.com/oxfordcontrol/osqp)

It's written by heavyweights like Boyd himself, the author of the famous
convex optmization textbook and course.


```
╰─$ cloc .
     343 text files.
     329 unique files.
     163 files ignored.
---------------------
Language         code
---------------------
C                6483
C/C++ Header     3215
CMake            1930
make             1506
Python            701
C++               496
JSON              232
Markdown          213
Bourne Shell      186
DOS Batch         140
CSS               121
YAML              105
HTML               19
---------------------
SUM:            15347
---------------------
```


I find it amazing that all of the code lives in around 6500 lines. They're
supposedly industrial strength, and can handle large problems. Reading this
code should provide a lot of insight into how to write good convex optimizers!
I would love to take a course which explains the source code.


# stars and bars by generating functions

Say I have `C` colors of objects, and `S` slots to put these objects in. In
how manys can I put objects into slots, without regard to order? For example,
say we have 4 colors `c, m, y, k` and `2` slots `_ _`. The number of colorings
that I want to count is:

```
cc cm cy ck
mc mm my mk
yc ym yy yk
kc km ky kk
```

Everything coloring on the lower diagonal (say, `mc`) is equivalent to one on
the upper diagonal (`cm`). So in total, there are 10 colorings:

```
cc cm cy ck
*  mm my mk
*  *  yy yk
*  *  *  kk
```

One can solve this using stars-and-bars. Take the number of slots `S` to be the
number of stars. Take the number of colors `C` to be the number of bars. The
answer to the stars-and-basrs is the same as the coloring question.

I don't like stars and bars for this, because it seems to force an ordering of
the colors `c1 < c2 < .. < cn`. [which bar cooresponds to which color]. Is
there some way to not have to do this?

Is there some other way to show the `(n + k - 1)Ck` without imposing this
ordering, or some other way to count this quantity?

One other way you can look at this is using multinomial expansion, but its
computation is slightly more involved. Its advantage is that it ignores
ordering of the objects, which is what you desire.

In this case, we represent each color as the polynomial 1 + x + x^2, here the
power of x represents the number of instances you are taking of that color.

So, if you take (1 + x + x^2)^4, you have found the number of ways to arrange
four colors, for different numbers of slots. If you take coefficient of x^2
from that polynomial, you get the answer to your question

Why does this set of shady manipulations not work?


```
answer = coeff. of x^2 in (1 + x + x^2)^4
[We can add higher powers, won't change coeff of x^2]
answer = coeff. of x^2 in (1 + x + x^2 + x^3)^4
answer = coeff. of x^2 in (1 + x + x^2 + ...)^4
answer = coeff. of x^2 in (1/(1-x))^4

Call f(x) = (1/(1-x))^4
f(x) =taylor= f(0) + f'(x) x + f''(0) x^2/2 + f'''(0) x^3 / 6 + ...

1/(1-x)^4 =taylor= ... + (1/(1-x)^4)''(0) x^2/2 + ...

so:

answer = coeff. of x^2 in ... + (1/(1-x)^4)''(0) x^2/2 + ...
```

Now compute `(1/(1-x)^4)''` evaluated at `0` and divide
by `2`. This gives:


```
(1/(1-x)^4)'' (0)
= (-4/(1-x)^5)' (0)
= (20/(1-x)^6) (0)
= (20/(1-0)^6)
= (20)
```

so we get the answer as `answer = 20/2! = 10`.

# This is not a place of honor

- [Long term nuclear waste](https://en.wikipedia.org/wiki/Long-time_nuclear_waste_warning_messages)

# Topological proof of infinitude of primes

- [On an exotic topology of the integers](https://arxiv.org/pdf/1008.0713.pdf)

We take the topological proof and try to view it from the topology as
semidecidability perspective.

- Choose a basis for the topology as the basic open sets
  $S(a, b) = \{ a n + b : n \in \mathbb Z \} = \{ mathbb Z + b \}$.
  This set is indeed semi-decidable. Given a number $k$, I can check if
  $(k - b) % a == 0$. So this is our basic decidability test.
- By definition, $\emptyset$ is open, and $\mathbb Z = S(1, 0)$. Thus it is
  a valid basis for the topology. Generate a topology from this. So we are
  composing machines that can check in parallel if for *some* $i$,
  $(k - b[i]) % a[i] == 0$ for some index.
- The basis $S(a, b)$ is clopen, hence the theory is decidable.
- Every number other than the units $\{+1, -1\}$ is a multiple of
  a prime.
- Hence, $\mathbb Z \setminus \{ -1, +1 \} = \cup_{p \text{prime}} S(p, 0)$.
- Since there a finite number of primes [for contradiction], the right hand side
  must be must be closed.
- The complement of $\mathbb Z \setminus \{ -1, +1 \}$ is $\{ -1, +1 \}$. This
  set cannot be open, because it cannot be written as the union
  of sets of the form $\{ a n + b \}$: any such union would have infinitely
  many elements. Hence, $\mathbb Z \setminus \{ -1, +1 \}$ cannot be closed.


# Burnside Theorem


For a finite group $G$ acting on a set $X$, burnside's lemma equates
(i) the number of equivalence classes of $X$ under $G$'s action,
that is, the number of orbits of $X$ with (ii) the average number
of stabilized elements for each $g \in G$. Formally, it asserts:

$$
|Orb(X, G)| = 1/|G|\sum_{g \in G} |Stab(g)|
$$

#### As local/global principle

See that the right-hand-side measures "local fixed points" in terms of $|Stab(g)|$.
The left hand side measures "global fixed points": an orbit $O \subseteq X$
is a set such that $G \cdot O = O$. So it's a sort of "global fixed point of $G$".

The burnside lemms tells us that we can recover the size of the set of
global fixed points (the number of orbits) by averaging the size of the set
of local fixed points (the average of the sizes of the stabilizers).

#### As space/time average

The left hand size is a time average: If we consider $X, GX, \dots G^{n}X$,
we will finally be left with the images as the orbits. All other elements
would have been ``smashed together''.

On the right hand side, we are averaging the group over space. Yes,
but how does one perform averaging? One needs to have a measure!

#### A rephrasing in terms of integrators

Consider a system of a particle in a well. We consider two energy levels:
that with `E = 0`, and `E = 1`. This gives us the following five
states:

<img src="./static/burnside/setup.png" >

now I want to simulate this system, like a good computer scientist. So let's
write the stupdiest one possible, `Δ0`, that doesn't simulate anything
at all, and `Δ+1`, which steps the system forward by a single step.
These look like this:


<img src="./static/burnside/simulation-1.png" >

But why only these? Why privilege these time-scales? We should at least
have `Δ-1`, for the arrow of time is fiction:
<img src="./static/burnside/intergrator-minus-1.png">

We should also have coarser integrators. Hence we contemplate `Δ+2` and `Δ-2`.
Turns out these are equivalent:

<img src="./static/burnside/integrator-plus-2-minus-2.png">


We can also consider `Δ + 3`. We also see that `Δ + 4 = Δ`:
<img src="./static/burnside/integrator-3-4.png">


So in conclusion, the calculation gives us:

<img src="./static/burnside/conclusion.png" >


# The Ise Grand shrine

> The shrine buildings at Naikū and Gekū, as well as the Uji Bridge, are
> rebuilt every 20 years as a part of the Shinto belief of the death and
> renewal of nature and the impermanence of all things and as a way of passing
> building techniques from one generation to the next.

I really enjoy this philosophy. I feel I should reflect on this, and update
how I think about, say, code rewrites, and pouring billions into new
supercolliders simply to keep the knowledge of how to build it alive.


> The shrine has evolved throughout the years in its reconstruction, while
> maintaining some of its key features. The shrine was not originally
> constructed with gold copper adornments, however, because of advancements in
> technology as well as Buddhist influence, it gained them over the years.


# Edward Kmett's list of useful math

- I use Bayesian statistics constantly for probabilistic programming and neural
  networks. Calculus gave me access to understand automatic differentiation,
  which gets used in everything I do. Real analysis doesn't come up often, but
  intermediate value thm. style arguments are handy.
- I don't use classic geometry, but I when I was doing graphics I used projective
  geometry, and that served as a gateway to understand category theory's duality
  principle, and I use category theory to organize most of the code I write.

- I took one course on differential geometry. The knowledge I gained from it
  probably led to about half of my income to date. I've made a career out of
  weaponizing "obscure" math, e.g. using toric varieties of rational functions of
  Zhegalkin polynomials to schedule instructions...
- Differential equations? Physics? Well, I use Hamiltonian methods for most of
  the sampling I do in the world of probabilistic programming. So understanding
  symplectic integrators is a big step, and I have to move frictionless particles
  subject to a Hamiltonian, so there's diff eq.
- Fourier analysis, heat equations? Well, if I want to approximate a
  space/distribution, http://ddg.math.uni-goettingen.de/pub/GeodesicsInHeat.pdf
- Learning group theory "bottom up" from monoids and the like has been useful,
  because I use monoids basically everywhere as a functional programmer to
  aggregate data. It led to the work I did at S&P Capital IQ, and later to
  basically my entire niche as a functional programmer.
- But understanding more of the surrounding landscape has been useful as well, as
  I use all sorts of lattices and order theory when working with propagators. And
  I use regular and inverse semigroups (note, not groups!) when working with all
  sorts of fast parsing techniques.
- Complex analysis? Understanding Moebius transformations means I can understand
  how continued fractions work, which leads to models for computable reals that
  don't waste computation and are optimally lazy. Knowing analytic functions lets
  me understand complex step differentiation.
- Linear algebra is in everything I've done since highschool. Learning a bit of
  geometric algebra, and playing around with Plucker coordinates led to me
  licensing tech to old game companies for computational visibility back before
  it was a "solved" problem.
- Wandering back a bit, Gröbner bases wind up being useful for comparing circuits
  modulo 'don't care' bits for impossible situations, and all sorts of other
  simplification tasks.
- Let's go obscure. Pade approximants? Good rational approximations, not
  polynomial ones. Sounds academic, but computing exp and log is expensive, and
  fast rational approximations can be conservative, monotone and have nice
  derivatives, speeding NN-like designs a lot.
- Weird number systems => Data structures.  Category theory acts as a rosetta
  stone for so many other areas of math it isn't even funny. You can understand
  almost all of the essential bits of quantum computing just knowing by category
  theory.
- Logic. Well, which logic? You run into a modal logic in a philosophy class
  some time and think of it as a clever hack, but monads in FP are basically a
  modality. Modal logics for necessity/possibility model effect systems well.
  Substructural logics to manage resource usage...
- I don't use a lot of number theory. There. Mind you, this is also one of those
  areas where I'm just standing on weak foundations, so I don't know what I
  don't know. I just know it's hard to do all sorts of things that sound easy
  and try to muddle through w/ my limited background.


# Cokernel is not sheafy

I wanted to understand why the Cokernel is not a sheafy condition.
I found an [explanation in Ravi Vakil's homework solutions](https://math.mit.edu/~mckernan/Teaching/07-08/Spring/18.726/model2.pdf)
which I am expanding on here.

#### Core idea

We will show that there will be an exact sequence which is surjective
at each stalk, but not globally surjective. So, locally, we wil have
trivial cokernel, but globally, we will have non-trivial cokernel.

#### Exponential sheaf sequence


$$
\begin{aligned}
0
\rightarrow 2\pi i \mathbb Z
\xrightarrow{\alpha: \texttt{incl}} \mathfrak O
\xrightarrow{\beta:exp(\cdot)} \mathfrak O^*
\rightarrow 0
\end{aligned}
$$

- $\mathfrak O$ is the sheaf of the additive group of holomorphic functions.
  $\mathfrak O^*$ is the sheaf of the group of non-zero holomorphic functions.
- $\alpha$, which embeds $2\pi n \in 2\pi i \mathbb Z$ as a constant function $f_n(\cdot) \equiv  2 \pi i n$ is
  injective.
- $\beta(\alpha(n)) = e^{2 \pi i n} = 1$. So we have that the composition of the two maps $\beta \circ \alpha$ is
  the zero map (multiplicative zero), mapping everything in $2\pi i \mathbb Z$ to the identity of $\mathfrak O^*$.
  Thus, `d^2 = 0`, ensuring that this is an exact sequence.
- Let us consider the local situation. At each point `p`, we want to show
  that $\beta$ is surjective. Pick any $g \in \mathfrak O^*_p$. We have an open neighbourhood $U_g$
  where $g \neq 0$, since continuous functions are locally invertible.
  Take the logarithm of $g$ to pull back $g \in O^*_p$ to $\log g \in O_p$.
  Thus, $\beta: O \rightarrow O^p$ is surjective at each local point $p$, since every element
  has a preimage.
- On the other hand, the function $h(z) \equiv z$ cannot be in $O^*$ If it were,
  then there exists a homolorphic function called $l \in O$ [for $\log$] such that
  $\exp(l(z)) = h(z) = z$ everywhere on the complex plane.
- Assume such a function exists. Then it must be the case that
  $d/dz exp(l(z)) = d/dz(z) = 1$. Thus, $exp(l(z)) l'(z) = z l'(z) = 1$
  [use the fact that $exp(l(z)) = z$]. This means that $l'(z) = 1/z$.
- Now, by integrating in a closed loop of $e^{i \theta}$. we have $\oint l'(z) = l(1) - l(1) = 0$.
- We also have that $\oint l'(z) = \oint 1/z = 2\pi i$.
- This implies that $0 = 2\pi i$ which is absurd.
- Hence, we cannot have a function whose exponential gives $h(z) = z$ everywhere.
- Thus, the cokernel is nontrivial globally.


# Von neumann: foundations of QM

- I wanted to understand what von neumann actually did when he
  "made QM rigorous", what was missing, and why we need $C^\star$ algebras for
  quantum mechanics, or even "rigged hilbert spaces".
- I decided to read Von Neumann: Mathematical foundations of quantum mechanics.
- It seems he provides a rigorous footing for QM, without any dirac
  deltas. In particular, he proves the Reisez representation theorem,
  allow for transforming bras to kets and vice versa. On the other hand,
  it does not allow for dirac delta as bras and kets.
- The document [The role of rigged hilbert spaces in QM](https://arxiv.org/pdf/quant-ph/0502053.pdf)
  provides a gentle introduction on how to add in dirac deltas.
- Rigged hilbert spaces (by Gelfand) combine the theory of distributions
  (by Schwartz), developed to make dirac deltas formal, and the theory of
  hilbert spaces (by Von Neumann) developed to make quantum mechanics formal.
- To be even more abstract, we can move to $C^\star$ algebras, which allow
  us to make QFT rigorous.
- So it seems that in total, to be able to write, say, a "rigorous shankar"
  textbook, one should follow Chapter 2 of Von Neumann, continuing with the
  next document which lays out how to rig a hilbert space.
- At this point, one has enough mathematical machinery to mathematize all of
  Shankar.

#### References

- Von neumann: Mathematical foundations of quantum mechanics.
- [The role of rigged hilbert spaces in QM](https://arxiv.org/pdf/quant-ph/0502053.pdf)

# Discrete schild's ladder

If one is given a finite graph $(V, E)$, which we are guaranteed came
from discretizing a grid, can we recover a global sense of orientation?

- More formally, assume the grid was of dimensions $W \times H$. So we have
  the vertex set as $V \equiv \{ (w, h) 1 \leq w \leq W, 1 \leq h \leq H \}$.
  We have in the edge set all elements of the form $((w, h), (w \pm 1, h \pm 1))$
  as long as respective elements $(w, h)$ and $(w \pm 1, h \pm 1)$ belong to $V$.

- We lose the information about the grid as comprising of elements of the
  form $(w, h)$. That is, we are no longer allowed to "look inside". All we
  have is a pile of vertices and edges $V, E$.

- Can we somehow "re-label" the edges $e \in E$ as "north", "south", "east",
  and "west" to regain a sense of orientation?

- Yes. Start with some corner. Such a corner vertex will have degree 2. Now,
  walk "along the edge", by going from a vertex of degree 2 to an neighbour
  of degree 2. If we finally reach a vertex that has unexplored
  neighbours of degree 3 or 4, pick the neighbour of degree 3. This will give
  us "some edge" of the original rectangle.

- We now arbitrary declare this edge to be the North-South edge. We now need
  to build the perpendicular East-West edge.

- This entire construction is very reminisecent of
  [Schild's Ladder](https://en.wikipedia.org/wiki/Schild%27s_ladder)


# Derivative of step is dirac delta

I learnt of the "distributional derivative" today from my friend, Mahathi.
Recording this here.

#### The theory of distributions

As far as I understand, in the theory of distributions, A distribution
is simply a linear functional $F: (\mathbb R \rightarrow \mathbb R) \rightarrow \mathbb R$.
The two distributions we will focus on today are:
- The step distribution, $step(f) \equiv \int_0^\infty f(x) dx$
- The dirac delta distribution, $\delta(f) = f(0)$.
- Notationally, we write $D(f)$ where $D$ is a distribution, $f$ is a function as
 $\int D(x) f(x) dx$.
- We can regard any function as a distribution, by sending $f$ to $F(g) \equiv \int f(x) g(x) dx$.
- But it also lets us cook up "functions" like the dirac delta which cannot actually
  exist as a function. So we move to the wider world of distributions

#### Derivative of a distribution

Recall that notationally, we wrote $D(f)$ as $\int D(x)f(x) dx$. We now want
a good definition of the derivative of the distribution, $D'$. How? well,
use chain rule!

$$
\begin{aligned}
&\int_0^\infty U dV = [UV]|_0^\infty - \int_0^\infty V dU \\
&\int_0^\infty f(x) D'(x)  dx \\
&= [f(x) D(x)]|_0^\infty - \int_0^\infty D f'(x)
\end{aligned}
$$



Here, we assume that $f(\infty) = 0$, ahd that $f$ is differentiable at $0$.
This is because we only allow ourselves to feed into these distribtions
certain classes of functions (test functions), which are "nice". The test
functions $f$ (a) decay at infinity, and (b) are smooth.

The derivation is:

$$
\begin{aligned}
&\int_0^\infty U dV = \int_0^\infty f(x) \delta(x) = f(0) \\
&[UV]|_0^\infty - \int_0^\infty V dU = [f(x) step(x)]|_0^\infty - \int_0^\infty step(x) f'(x) \\
&= [f(\infty)step(\infty) - f(0)step(0)] - step(f') \\
&= [0 - 0] - (\int_0^\infty f'(x) dx) \\
&= 0 - (f(\infty) - f(0)) \\
&= 0 - (0 - f(0)) \\
&= f(0)
\end{aligned}
$$

- Thus, the derivative of the step distribution is the dirac delta distribution.

# Extended euclidian algorithm

#### Original definition

I feel like I only understand the extended euclidian algorithm algebraically,
so I've been trying to understand it from other perspectives. Note that
we want to find $gcd(p, p')$. WLOG, we assume that $p > p'$.
We now find a coefficient $d$ such that $p = d p' + r$ where $0  \leq r < p'$.
At this stage, we need to repeat the algorithm to find $gcd(p', r)$. We
stop with the base case $gcd(p', 0) = p'$.

#### My choice of notation

I dislike the differentiation that occurs between $p$, $p'$, and $r$
in the notation. I will notate this as $gcd(p_0, p_1)$. WLOG, assume
that $p_0 > p_1$. We now find a coefficient $d_0$ such that $p_0 = p_1 d_1 + p_2$
such that $0 \leq p_2 < p_1$. At this stage, we recurse to find
$gcd(p_1, p_2)$. We stop with the base case $gcd(p_{n-1}, p_n) = p_n$ iff
$p_{n-1} = d_n p_n + 0$. That is, when we have $p_{n+1} = 0$, we stop
with the process, taking the gcd to be $p_n$.

#### Matrices

We can write the equation $p_0 = p_1 d_1 + p_2$ as the equation
$p_0 = [d_1; 1] [p_1;  p_2]^T$. But now, we have lost some state. We used
to have both $p_1$ and $p_2$, but we are left with $p_0$. We should always
strive to have "matching" inputs and output so we can iterate maps. This
leads us to the natural generalization:

$$
\begin{bmatrix} p_0 \\ p_1 \end{bmatrix} =
\begin{bmatrix}
d_1  & 1 \\ 1 & 0
\end{bmatrix}
\begin{bmatrix} p_1 \\ p_2 \end{bmatrix}
$$

So at the first step, we are trying to find a $(d_1, p_2)$ such that the
matrix equation holds, and $0 \leq p_2 < d_1$.

#### Extended euclidian division

When we finish, we have that $gcd(p_{n-1}, p_n) = p_n$. I'll call the GCD
as $g$ for clarity. We can now write the GCD as a linear combination
of the inputs $g = p_n = 0 \cdot p_{n-1} + 1 \cdot p_n$. We now
want to backtrack to find out how to write $g = \omega_{n-2} p_{n-2} + \omega_{n-1} p_{n-1}$.
And so on, all the way to $g = \omega_0 p_0 + \omega_1 p_1$.


- We can begin with the general case:

$$
g =
\begin{bmatrix} \omega' & \omega'' \end{bmatrix}
\begin{bmatrix} p' \\ p'' \end{bmatrix}
$$

- We have the relationship:

$$
\begin{bmatrix} p \\ p' \end{bmatrix} =
\begin{bmatrix}
d'  & 1 \\ 1 & 0
\end{bmatrix}
\begin{bmatrix} p' \\ p'' \end{bmatrix}
$$

- We can invert the matrix to get:


$$
\begin{bmatrix} p' \\ p'' \end{bmatrix} =
\begin{bmatrix}
0  & 1 \\ 1 & - d'
\end{bmatrix}
\begin{bmatrix} p \\ p' \end{bmatrix}
$$

- now combine with the previous equation to get:

$$
\begin{aligned}
&g =
\begin{bmatrix} \omega' & \omega'' \end{bmatrix}
\begin{bmatrix} p' \\ p'' \end{bmatrix} \\
&g =
\begin{bmatrix} \omega' & \omega'' \end{bmatrix}
\begin{bmatrix}
0  & 1 \\ 1 & - d'
\end{bmatrix}
\begin{bmatrix} p \\ p' \end{bmatrix} \\
&g =
\begin{bmatrix} \omega'' & \omega - d' \omega'  \end{bmatrix}
\begin{bmatrix} p \\ p' \end{bmatrix} \\

\end{aligned}
$$

#### Fractions

- GCD factorization equation: $p/p' = (\alpha p' + p'')/p' = \alpha + p''/p'$.
- Bezout equation: $\omega' p' + \omega'' p'' = g$.
- Bezout equation as fractions $\omega' + \omega'' p''/p' = g/p'$.


# In a PID, all prime ideals are maximal, geometrically

Assume $R$ is Noetherian.

- By [Krull's principal ideal theorem](https://en.wikipedia.org/wiki/Krull%27s_principal_ideal_theorem),
  we have that given a principal ideal $I = (\alpha)$, all minimal prime
  ideals $\mathfrak p$ above $I$ has height at most 1.

- Recall that a minimal prime ideal $\mathfrak p$ lying over an ideal $I$
  is the minimal among all prime ideals containing $I$. That is, if
  $I \subseteq \mathfrak q \subseteq \mathfrak p$, then $\mathfrak q = I$
  or $\mathfrak q= \mathfrak p$.

- In our case, we have that $R$ is a PID. We are trying to show that all prime
  ideals are maximal. Consider a prime ideal $\mathfrak p \subseteq R$.
  It is a principal ideal since $R$ is a PID. It is also
  a minimal prime ideal since it contains itself. Thus by Krull's PID
  theorem, has height at most one.
- If the prime ideal is the zero ideal ($\mathfrak p = 0$),
  then it has height zero.
- If it is any other prime ideal $(\mathfrak p \neq (0))$, then it has height
  at least 1, since there is the chain $(0) \subsetneq \mathfrak p$. Thus
  by Krull's PID theorem, it has height exactly one.
- So all the prime ideals other than the zero ideal, that is, all the points
  of $Spec(R)$ have height 1.
- Thus, every point of $Spec(R)$ is maximal, as there are no "higher points"
  that cover them.
- Hence, in a PID, every prime ideal is maximal.

In a drawing, it would look like this:

```
NO IDEALS ABOVE  : height 2
(p0)  (p1) (p2)  : height 1
      (0)        : height 0
```

So each `pi` is maximal.

This is a geometric way of noting that in a principal ideal domain, prime
ideals are maximal.

#### References

- [Andreas Gathmann's notes](https://www.mathematik.uni-kl.de/~gathmann/class/commalg-2013/commalg-2013-c11.pdf)

# Prime numbers as maximal among principal ideals

I learnt of this characterization from benedict gross's lectures, [lecture 31](https://www.youtube.com/watch?v=l1OWAasmBLI&list=PLelIK3uylPMGzHBuR3hLMHrYfMqWWsmx5&index=31).

We usually define a number $p \in R$ as prime iff the ideal generated by
$p$, $(p)$ is prime. Formally, for all $a, b \in R$, if
$ab \in (p)$ then $a \in (p)$ or $b \in (p)$.

This can be thought of as saying that among all principal ideals, the
ideal $(p)$ is maximal: no other principal ideal $(a)$ contains it.

#### Element based proof

- So we are saying that if $(p) \subseteq (a)$ then either $(p) = (a)$
- Since $(p) \subseteq (a)$ we can write $p = ar$. Since $(p)$ is prime,
  and $ar = p \in (p)$, we have that either $a \in (p) \lor r \in (p)$.
- Case 1: If $a \in (p)$ then we get $(a) \subseteq (p)$.
  This gives $(a) \subseteq (p) \subseteq (a)$,
  or $(a) = (p)$.
- Case 2: Hence, we assume $a \not \in (p)$, and $r \in (p)$.
  Since $r \in (p)$, we can write $r = r'p$ for some $r' \in R$.
  This gives us $p = ar$ and $p = a(r'p)$. Hence $ar' = 1$. Thus $a$
  is a unit, therefore $(a) = R$.


# Axiom of Choice and Zorn's Lemma

I have not seen this "style" of proof before of AoC/Zorn's lemma
by thinking of partial functions $(A \rightarrow B)$ as monotone functions
on $(A \cup \bot \rightarrow B)$.

#### Zorn's Lemma implies Axiom of Choice

If we are given Zorn's lemma and the set $A_i$, to build a choice
function, we consider the collection of functions $(f: \prod_i A_i \rightarrow \rightarrow A_i \cup \bot)$
such that either $f(A_i) = \bot$ or $f(A_i) \in A_i$. This can be endowed with
a partial order / join semilattice structure using the "flat" lattice, where
$\bot < x$ for all $x$, and $\bot \sqcup x = x$.

For every chain of functions, we have a least upper bound, since a chain
of functions is basically a collection of functions $f_i$ where each function
$f_{i+1}$ is "more defined" than $f_i$.

Hence we can always get a maximal element $F$, which has a value defined
at _each_ $F(A_i)$. Otherwise, if we have $F(A_i) = \bot$, the element
is not maximal, since it is dominated by a larger function which is defined
at $A_i$.

Hence, we've constructed a choice function by applying Zorn's Lemma.
Thus, Zorn's Lemma implies Axiom of Choice.


# Local ring in terms of invertibility

Recall that a local ring $R$ is a ring with a unique maximal ideal $M$.
This is supposedly equivalent to the definition:

> A local ring is a ring $R$ such that $1 \neq 0$ and for all $x, y$ in $R$,
> $x + y \text{ invertible} \implies x \text{ invertible} \lor y \text{ invertible}$



#### Stepping stone: If $(R, M)$ is a local ring then set of all units of $R$ is equal to $R - M$

##### All elements of $(R - M)$ are units:

- Let $R$ be a local ring with unique maximal ideal $M$.
- Let $u \in R - M$. [$u$ for unit].
- If $u$ is a unit, we are done.
- Otherwise, consider the ideal generated by $u$, $(u)$.
- $(u)$ must live in some maximal ideal. Since
- $M$ is the only maximal ideal, we have that $u \in (u) \subseteq M$.
- This is a contradiction, since $u$ cannot be both in $M$ and $R - M$.
- Hence all elements $u \in R - M$ are units.

##### All units are in $(R - M)$:

- Let $u$ a unit.
- We cannot have $u \in M$ since $M$ is a maximal ideal, $M \neq R$.
- If $u \in M$ then $u^{-1} u = 1 \in M$, hence $M = R$.
- Contradiction.

#### Part 1: Local ring to to invertible:

- Let $R$ have a unique maximal ideal $M$.
- We have already shown that all invertible elements are in $R - M$.
- Hence if $x + y$ is invertible, it belongs to $R - M$.
- We must have either $x$ or $y$ invertible.
- Suppose not: $x, y \in M$ while $x + y \not \in M$.
- This is impossible because $M$ is an ideal and is thus closed under addition.
- So, we must have that if $x + y$ is invertible then either $x$ or $y$ is invertible.

#### Part 2: Invertible to Local ring.

- Let $R$ be a ring such that if $x + y$ is invertible then either $x$ or $y$ is invertible.
- Conversely, if neither $x$ nor $y$ are invertible then $x + y$ is not invertible.
- Hence the set of non-invertible elements form an ideal $I$, as $0 \in I$, sum of
  non-invertibles are not invertible (assumption),
  product of non-invertibles is not invertible (easy proof).
- This ideal $I$ is contained in some maximal ideal $M$.
- This maximal ideal $M$ is such that every element in $R - M$ is invertible,
  since all the non-invertible elements were in $I$ from which $M$ was built.
- Formally, assume not: Some element $s \in R - M$ is not invertible. Then $s \in I \subseteq M$.
  This contradicts assumption that $s \in R - M$.
- Hence $M$ is a unique maximal ideal and $R$ is a local ring.

#### References

- [Using the internal language of toposes in algebraic geometry](https://rawgit.com/iblech/internal-methods/master/notes.pdf)

# Nullstellensatz for schemes

#### System of equations

Consider a set of polynomials $\{F_1, F_2, \dots F_m\}$ subset $K[T_1, \dots, T_n]$.
A system of equations $X$ for unknowns $T$ is the tuple
$(K[T_1, \dots, T_n], \{ F_1, F_2, \dots F_m \} \subset K[T_1, \dots, T_n])$.
We abbreviate this to $(K[\mathbf T], \mathbf F)$ where the bolded version
implies that these are vectors of values.

#### Solutions to system of equations

Note that we often define equations, for example $x^2 + 1 = 0$ over a ring
such as $\mathbb Z$. But its solutions live elsewhere: In this case, the solutions
live in $\mathbb C$, as well as in $\mathbb Z/2Z$. Hence, we should not restrict
our solution space to be the ring where we defined our coefficients from!


Rather, as long as we are able to _interpret_ the polynomial $f \in K[\mathbf T]$
in some other ring $A$, we can look for solutions in the ring $A$. Some thought
will tell us that all we need is a ring homomorphism $\phi: K \rightarrow L$.
Alternatively/equivalently, [we need $L$ to be a $K$-algebra](https://math.stackexchange.com/questions/3756749/an-a-algebra-b-carries-the-same-data-as-a-ring-map-a-rightarrow-b).


Let us consider the single-variable case with $K[T]$. This naturally
extends to the multivariate case.
Using $\phi$, we can map $f \in K[T]$ to $\phi(f) \in L[T]$ by taking
$f = \sum_i k_i T^i$ to $\phi(f) = \sum_i \phi(k_i) T^i$. This clearly extends
to the multivariate case. Thus, we can interpret solutions $l \in L$ to an equation
$f \in K[T]$  as $f(l) = \sum_i \phi(k_i) l^i$.


Formally, the solution to a system $X \equiv (K[\mathbf T], \mathbf F)$
in ring $L$, written as $Sol(X, L)$ is a set of elements $ls \subseteq L$
such that $F_i(l) = 0$ for all $l$ in $ls$ and for all $F_i$ in $\mathbf F$.


#### Equivalent systems of equations

Two systems of equations $X, Y$ over the **same ring $K$** are said to be
equivalent over $K$ iff for all $K$-algebras $L$, we have
$Sol(X, L) = Sol(Y, L)$.

#### Biggest system of equations

For a given system of equations $X \equiv (K[\mathbf T], \mathbf F)$ over the ring $K$,
we can generate the largest system of equations that still has the same solution:
generate the ideal $\mathbf F' = (\mathbf F)$, and consider the system
of equations $X' \equiv (K[\mathbf T], \mathbf F' = (\mathbf F) )$.

#### Varieties and coordinate rings

Let $g \in K[T_1, \dots T_n]$. The polynomial is also a function which maps
$\mathbf x \in K^n$ to $K$ through evaluation $g(\mathbf x)$.


Let us have a variety $V \subseteq k^n$ defined by some set of polynomials
$\mathbf F \in K[T_1, \dots, T_n]$. So the variety is the vanishing set of $\mathbf F$,
and $\mathbf F$ is the **largest** such set of polynomials.

Now, two functions $g, h \in K[T_1, \dots, T_n]$ are equal on the variety $V$
iff they differ by a function $z$ whose value is zero on the variety $V$. Said
differently, we have that $g|V = h|V$ iff $h - g = z$ where $z$ vanishes on $V$.
We know that the polynomials in $\mathbf F$ vanish on $V$, and is the
largest set to do so. Hence we have that $z \in \mathbf F$.

To wrap up, we have that two functions $g, h$ are equal on $V$, that is,
$g|V = h|V$ iff $g - h \in \mathbf F$.

So we can choose to build a ring where $g, h$ are "the same function". We do
this by considering the ring $K[V] \equiv K[T_1, \dots, T_n] / \mathbf F$.
This ring $K[V]$ is called as the **coordinate ring of the variety $V$**.


#### An aside: why is it called the "coordinate ring"?

We can consider the ith coordinate function as one that takes $K[T_1, \dots, T_n]$ to $T_i$
So we have $\phi_i \equiv T_i \in K[T_1, \dots, T_n]$ which defines a function
$\phi_i: K^n \rightarrow K$ which extracts the $i$th coordinate.

Now the quotienting from the variety to build $K[V]$, the coordinate ring
of the variety $V$ will make sure to "modulo out" the coordinates that
"do not matter" on the variety.

#### Notation for coordinate ring of solutions: $Coord(X)$

For a system $X \equiv (K[\mathbf T], \mathbf F)$, we are interested in the
solutions to $\mathbf F$, which forms a variety $V(\mathbf F)$. Furthermore,
we are interested in the algebra of this variety, so we wish to talk about
the coordinate ring $k[V(\mathbf F)] = K[\mathbf T] / (\mathbf F)$. We will
denote the ring $k[\mathbf T] / (\mathbf F)$ as $Coord(X)$.

#### Solutions for $X$ in $L$: $K$-algebra morphisms $Coord(X) \rightarrow L$
Let's simplify to the single variable case. Multivariate
follows similarly by recursing on the single
variable case. $X \equiv (K[T], \mathbf F \subseteq K[T])$.

There is a one-to-one coorespondence between solutions to $X$ in $L$ and
elements in $Hom_K(Coord(X), L)$ where $Hom_K$ is the set of $K$-algebra
morphisms.

Expanding definitions, we need to establish a correspondence between
- Points $l \in L$ such that $eval_l(f) = 0$ for all $f \in F$.
- Morphisms $K[T] / (\mathbf F) \rightarrow L$.

##### Forward: Solution to morphism

A solution for $X$ in $L$ is a point $\mathbf l \in L$ such that $F$
vanishes on $l$. Thus, the evaluation map $eval[l]: K[T] \rightarrow L$
has kernel $(\mathbf F)$. Hence, $eval[l]$ forms an honest to god morphism
between $K[T] / (\mathbf F)$ and $L$.


##### Backward: morphism to solution

Assume we are given a morphism $\phi: Coord(X) \rightarrow L$. Expanding
definitions, this means that $\phi: K[T]/ (\mathbf F) \rightarrow L$.
We need to build a solution. We build the solution $l\star = \phi(T)$.

Intuitively, we are thinking of $\phi$ as $eval[l\star]$.
If we had an $eval[l\star]$, then we would learn the point $l\star \in L$
by looking at $eval[l\star](T)$, since $eval[l\star](T) = l\star$.


We can show that this point exists in the solution as follows:
$$
\begin{aligned}
&eval[l\star](f) = \sum_i a_i (l\star)^i \\
&= \sum_i a_i \phi(T)^i \\
&\text{Since $\phi$ is ring homomorphism:} \\
&= \sum_i a_i \phi(T^i)  \\
&\text{Since $\phi$ is $k$-algebra homomorphism:} \\
&= \phi(\sum_i a_i T^i)  \\
&= \phi(f) \\
\text{Since $f \in ker(\phi)$:} \\
&= 0
\end{aligned}
$$

- [This is also asked by me on this `math.se` question](https://math.stackexchange.com/questions/3766418/proof-verification-bijection-between-solutions-to-a-system-of-equations-and-k-a)


#### Consistent and inconsistent system $X$ over ring $L$

Fix a $K$-algebra $L$. The system $X$ is **consistent** over $L$ iff
$Sol(X, L) \neq \emptyset$. the system $X$ over $L$ is **inconsistent** iff
If $Sol(X, L) = \emptyset$.


#### Geometric Language: Points

Let $K$ be the main ring, $X \equiv (K[T_1, \dots T_n], \mathbf F)$ a system of
equations in $n$ unknowns $T_1, \dots, T_n$.

For any $K$-algebra $L$, we consider the set $Sol(X, L)$ as a collection
of points in $L^n$. These points are solutions to the system $X$.


#### The points of $K$-algebra


#### References

- [Manin, theory of schemes](https://sites.icmc.usp.br/grossi/Sasha/galg/manin.pdf)
- [Notes coordinate rings of affine varieties](http://pi.math.cornell.edu/~dmehrle/notes/old/alggeo/34CoordinateRingonAffineVariety.pdf)
- [Why is this called the coordinate ring](https://math.stackexchange.com/questions/2397249/the-coordinate-ring-its-etymology)

# Perspectives on Yoneda

We can try to gain intuition for Yoneda by considering a finite category
where we view arrows as directed paths.

The "interpretation" of a path is taken by going from edges to labels and then
concatenating all edge labels. We "interpret" the label `id_x` as `""` (the
empty string), and we "interpret" all other arrows `a` as some unique string
associated to each arrow. Composition of arrows becomes concatenation of
strings. This obeys all the axioms of a category. We are basically of a
category as a free monoid.


Let's being our consideration of the covariant functor `Hom(O, -): C → Set`.
Note that the objects of this category are **sets** of arrows `Hom(O, P)`.
To every arrow `a: P → Q` we associate the set function
`a': Hom(O, P) → Hom(O, Q)`. `a'(op) = pq . op`.

Now, to apply Yoneda, we need another covariant functor `G: S → Set`. We now
need to show that the set of natural transformations `η: F → G`  are in bijection
with the set `G[O] ∈ Set`.


We do this by the following consideration. Recall that for the natural transformation,
we have the commuting diagram:

```
x -p-> y

Hom(o, x) -p'-> Hom(o, y)
|                |
ηx               ηy
|                |
v                v
G[x] -G[p] --> G[y]
```

```
∀ x y ∈ C,
  o2x ∈ Hom(o, x),
  p ∈ Hom(x, y),
    G[p](ηx(o2x)) = ηy(p'(o2x))
```

Which on using the definition of `p'` becomes:

```
∀ x y ∈ C,
  o2x ∈ Hom(o, x),
  p ∈ Hom(x, y),
  G[p](ηx(o2x)) = ηy(o2x . p')
```

Now pick the magic `x = o` and `o2x = o2o = id_o`. This gives:

```
x = o, y ∈ C
o2x = id_o

∀ y ∈ C,
  p ∈ Hom(o, y),
  G[p](ηo(id_o)) = ηy(id_o . p')
  G[p](ηo(id_o)) = ηy(p') [By identity arrow]
  [assume we fix ηo(id_o) ∈ G[o] ]
  ηy(p') = G[p](ηo(id_o)) [ηy is now forced.
                          everything on the RHS is known]
```

Hence, we learn how to map every other arrow `ηy(p)`. If we know how to map
the arrows, we can map the objects in the hom-sets as images of the arrows,
since we know what `ηo[id_o]` maps to. Concretely:

##### Images `ηo(q)` for `q ∈ Hom(o, o)` after `ηo(id_o)` is fixed:


We have the relation `id_o . q = q`. So we get that the arrow `q': Hom(o, o) → Hom(o, o)`
takes `id_o` to `q`. By the structure of the natural transformation, we have that:

```
∀ x y ∈ C,
  o2x ∈ Hom(o, x),
  p ∈ Hom(x, y),
    G[p](ηx(o2x)) = ηy(p'(o2x))
```

- Pick `x = y = o`, `o2x = id_o`, `p = q`. This gives:

```
    G[q](ηo(id_o)) = ηo(q'(id_o))
    G[q](ηo(id_o)) = ηo(q' . id_o)
    G[q](ηo(id_o)) = ηo(q')
    ηo(q') = G[q](ηo(id_o))
```

Hence, we've deduced `ηo(q')`, so we know what element `q` gets mapped to.
The same process works with _any_ arrow!

#### A shift in perspective: Yoneda as partial monoid.

Since we're considering the sets $Hom(o, -)$, note that we can always
pre-compose any element of $Hom(o, o)$ to every $Hom(o, p)$. More-over,
if we know the value of $id_o$, then we have the equation that $id_o \circ a = a$.
since $id_o$ is the identity. Moreover, $id_o$ is the **only** identity arrow
we possess across all $Hom(o, -)$: We can only access the identity arrow
inside $Hom(o, o)$. For all other $Hom(o, p)$ where $p \neq o$, we do
not have the identity arrow $id_o$ or $id_p$. So we have a sort of _partial monoid_,
where we have a unique identity element $id_o$, and arrows that compose _partially_
based on domain/codomain conditions.


From this perspective, we can read the commutative diagram laws as a sort
of "Cayley's theorem". We have as elements the elements of the set $Hom(o, -)$.
For every arrow $a: p \rightarrow q$, we have the action
$Hom(o, p) \xrightarrow{a} Hom(o, q)$.


From this perspective, it is trivial to see that:
- Every monoid can be embedded into its action space (Cayley's theorem).
- This mapping of yoneda from $Hom(o, -)$ to arbitrary sets is like a "forgetful"
  functor from a monoid into a semigroup.
- If our monoid is "well represented" by a semigroup, then once we know what
  the identity maps to, we can discover all of the other elements by using the
  relation $f(ex) = f(e) f(x)$. The only "arbitrariness" introduced by forgetting
  the monoid structure is the loss of the unique identity. **NOTE**: This is handwavy,
  since the data given by a natural transformation is somehow "different", in a way
  that I'm not sure how to make precise.

# Germs, Stalks, Sheaves of differentiable functions

I know some differential geometry, so I'll be casting sheaves in terms
of tangent spaces for my own benefit

- **Presheaf:** Data about restricting functions.
- **Germ:** Equivalence class of functions in the neighbourhood at a point,
  which become equivalent on restriction. Example: equivalence classes of curves with the same directional derivative.
- **Stalk:** An algebraic object worth of germs at a point.

Next, to be able to combine germs together, we need more.
- **Sheaf:** Adds data to a presheaf to glue functions.

#### A presheaf that is not a sheaf: Bounded functions

Consider the function $f(x) \equiv x$. This is bounded on every open interval
$I \equiv (l, r)$: $l \leq f(I) \leq f(r)$ But the full function $f(x)$ is unbounded.


#### Holomorphic function with holomorphic square root.

Our old enemy, monodromy shows up here.
Consider the identity function $f(z) = z$. Let's analyze its square root
on the unit circle. $f(e^{i \theta}) = e^{i \theta/2}$. This can only be defined
continuously for _half_ the circle. As we go from $\theta: 0 \rightarrow 2 \pi$,
our $z$ goes from $0 \rightarrow 0$, while $f(z)$ goes $0 \rightarrow -1$. This
gives us a discontinuity at $0$.

#### Formalisms

- **Sections of a presheaf $F$ over an open set $U$:**
  For each open set $U \subseteq X$, we have a set $F(U)$, which are generally sets of functions.
  The elements of $F(U)$ are called as the **Sections of $F$ over $U$**.
  More formally, we have a function $F: \tau \rightarrow (\tau \rightarrow R)$
  $(\tau \rightarrow R)$ is the space of functions over $\tau$.
- **Restriction Map:** For each inclusion $U \hookrightarrow V$, ($U \subseteq V$)
  we have a restriction map $Res(V, U): F(V) \rightarrow F(U)$.
- **Identity Restriction:** The map $Res(U, U)$ is the identity map.
- **Restrictions Compose:** If we have $U \subseteq V \subseteq W$, we must have
  $Res(W, U) = Res(W, V) \circ Res(V, U)$.
- **Germ:** A germ of a point $p$ is any section over any open set $U$ containing $p$.
  That is, the set of all germs of $p$ is formally $Germs(p) \equiv \{ F(U_p) : U_p \subseteq X, p \in U, U \text{ open} \}$.
  We sometimes write the above set as $Germs(p) \equiv \{ (f, U_p) : f \in F(U_p), U_p \subseteq X, p \in U, U \text{ open} \}$.
  This way, we know both the function $f$ and the open set $U$ over which it is defined.
- **Stalk:** A stalk at a point $p$, denoted as $F_p$,
  consists of equivalence classes of all germs at a point, where two germs are
  equivalent if the germs become equal over a small enough set.
  We state that $(f, U) \sim (g, V)$ iff there exists a $W \subseteq U \cap V$ such that
  the functions $f$ and $g$ agree on $W$: $Res(U, W)(f) = Res(V, W)(g)$.
- **Stalk as Colimit:** We can also define the stalk as a colimit. We take the
  index category $J$ as a filtered set. Given any two open sets $U, V$, we have a smaller
  open set that is contained in $U \cap V$. This is because both $U$ and $V$ cannot
  be non-empty since they share the point $p$.
- If $p \in U$ and $f \in F(U)$, then the image of $f$ in $F_p$, as in, the value
  that corresponds to $f$ in the stalk is called as the germ of $f$ at $p$.
  **This is really confusing! What does this mean?**
  [I asked on `math.se`](https://math.stackexchange.com/questions/3761451/confusion-about-definition-of-germ-in-the-rising-sea-which-seems-circular).

#### References
- The rising sea by Ravi Vakil.


# Connectedness in terms of continuity

This was a shower thought.

- We usually define a topological space $X$ as connected
  iff there are disjoint open sets $U, V$ such that $U \cup V = X$. Since
  they are disjoint, we have that $U \cap V = \emptyset$.
- An alternative way of stating this is to consider two colors `C = {red, blue }` with
  the discrete topology.
- We use the discrete topology on `C` since we want the two
  colors to be "separate".
- Now, a space $X$ is connected iff there is a continuous
  surjective function $f: X \rightarrow C$. That is, we can color the whole space
  continuously with both colors.

This is equivalent to the original definition by setting $U = f^{-1}(red)$
and $V = f^{-1}(blue)$:

- Pre-images of a function must be disjoint. Hence, $U \cap V = \emptyset$.
- Preimages of $red$ and $blue$ must be open sets since $\{red\}$ and $\{blue\}$
  are open and $f$ is continuous: continuous functions have pre-images of open
  sets as open. Hence $U$ and $V$ are open.
- Since $f$ is surjective, we must have that the pre-images cover the entire set $X$.
  Hence $U \cup V = X$.

I find this to be appealing, since it's intuitively obvious to me that if a space
is disconnected, I can color it continuously with two colors, while if a space
is connected, I should be unable to color it continuously with two colors ---
there should be a point of "breakage" where we suddenly switch colors.


# Intuition for limits in category theory

#### A characterization of limits

The theorem that characterizes limits is this:
> A category has Finite Limits iff it has all finite products and equalizers.
> limits have maps *out* of them.


#### Ravi Vakil's intuition for limits: Take sub things.
- An element of a limit gives one of each of its ingredients. For example,
 $K[[X]] = \lim_n \text{degree}~n~\text{polynomials} $, since we can get
 a degree n polynomial for all n, from any power series by truncation.
- limits have maps *out* of them.
- **RAPL**: right adjoints preserve limits.
- Limits commute with limits.
- These are mentioned in "Algebraic geometry in the time of Covid: Pseudolecture 2"
- Also, recalling that kernels are limits allows one to remember that we have
  maps that **go out** of a limit.

#### Limits are things you get maps *out* of.

- product has projections going out of it.
- `gcd` is less than the things that build it:
  `gdb(a, b) -> a, b` since `gcd(a, b) < a` and `gcd(a, b) < b`.
- single point set can be mapped out of.
- `type Limit f = forall a. f a`

#### Limits in Haskell

```hs
{-# LANGUAGE ExplicitForAll #-}
{-# LANGUAGE RankNTypes #-}
{-# LANGUAGE KindSignatures #-}
{-# LANGUAGE GADTs #-}
data Limit (f :: * -> *) where
  MkLimit :: (forall a. f a) -> Limit f

projectOut :: Limit f -> f a
projectOut (MkLimit fa)  = fa

data Colimit (f:: * -> *) where
  MkCoLimit :: f a -> Colimit f

projectIn :: f a -> Colimit f
projectIn = MkCoLimit
```



# Finite topologies and DFS numbering

In this great math overflow question on
[How to think about non hausdorff topologies in the finite case](https://mathoverflow.net/questions/44109/how-should-one-think-about-non-hausdorff-topologies/44135#44135), there's an answer that encourages us
to think of them as preorders, which are basically graphs. I wanted to understand
this perspective, as well as connect it to DFS numbers, since they provide a
nice way to embed these topologies into $\mathbb R$.

### Closure axioms of topology
We can axiomatize a topology using the kurotawski closure axioms. We need an
idempotent monotonic function $c: 2^X \rightarrow 2^X$ which satisfies some
technical conditions. Formally:

1. $c(\emptyset) = \emptyset)$ [$c$ is a strict function: it takes bottoms to bottoms]
2. $A \subseteq c(A)$. [monotonicity]
3. $c$ is idempotent: $c(c(A)) = c(A)$. [idempotence]
4. for all $A, B$ in $X$, $c(A \cup B) = c(A) \cup c(B)$.

Under this, a set is closed if it is a fixed point of $c$: That is, a set $A$
is closed iff $c(A) = A$.

##### Slight weakening into Single axiom version

Interestingly, this also gives a single axiom version of topological axioms,
something that maybe useful for machine learning. The single axiom is that
for all $A, B \subseteq X$, $A \cup c(A) \cup c(C(B)) \subseteq c(A \cup B)$.
This does not provide that $c(\emptyset) = \emptyset$, but it does provide
the other axioms [2-4].


###### Continuous functions

A function is continuous iff $f(c(A)) \subseteq c'(f(A))$ for every $A \in X$.

**TODO:** give examples of why this works, and why we need $(\subseteq)$ and not just $(eq)$.

### Finite topologies as preorders
We draw an arrow $x \rightarrow y$ iff $x \in Closure(y)$. Alternatively stated,
draw an arrow iff $Closure(x) \subseteq Closure(y)$. That is, we have an injection
from the closure of $x$ into the closure of $y$, and the arrow represents
the injection. Alternatively, we can think of
this as ordering the elements $x$ by "information". A point $x$ has less information
than point $y$ if its closure has fewer points.

### T0 in terms of closure:
- $X$ is $T_0$ iff for points $p, q \in X$, we have an open set $O$ which contains
  one of the points but not the other. Formally,
  either $p \in O \land q \not \in O$, or $p \not \in O \land q \in O$.
- **Example** of a $T_0$ space is the [sierpinski space](https://en.wikipedia.org/wiki/Sierpi%C5%84ski_space).
  Here, we have the open set $\{ \bot \}$ by considering the computation
  `f(thunk) = force(thunk)`. For more on this perspective, see [Topology is
  really about computation ](#topology-is-really-about-computation--part-1).
  This open set contains only $\bot$ and not $\top$.
- **Closure definition:** $X$ is $T_0$ iff $x \neq y \implies c(\{x\}) \neq c(\{y\})$

### T1 in terms of closure:
- $X$ is $T_1$ iff for all $p, q$ in $X$, we have open sets $U_p, U_q$ such that
  $U_p, U_q$ are open neighbourhoods of $p, q$ which do not contain the "other point".
  Formally, we need $p \in U_p$ and $q \not \in U_p$, and similarly $q \in U_q$ and $p \not \in U_q$.
  That is, $U_p$ and $U_q$ can split $p, q$ apart, but $U_p$ and $U_q$ need not
  be disjoint.
- **Example** of $T_1$ is the zariski/co-finite topology on $\mathbb Z$, where
  the open sets are complements of finite sets. Given two integers $p, q$, use the
  open sets as the complements of the closed finite sets $U_p = \{q\}^C = \mathbb Z - q$,
  and $U_q = \{p\}^C = \mathbb Z - p$. These separate $p$ and $q$,
  but have _huge_ intersection: $U_p \cap U_q = Z - \{ p, q\}$.
- **Closure definition:** $X$ is $T_1$ iff $c(\{x\}) = \{x\}$.
- [T1 has all singleton sets as closed](https://mathoverflow.net/a/337/123769)

### Haussdorf (T2) in terms of closure
-  $X$ ix $T_1$ iff for all $p, q$ in $X$, we have open set $U_p, U_q$ such that
   they are disjoint ($U_p \cap U_q = \emptyset$) and are neighbourhoods of $p$, $q$:
   $p \in U_p$ and $q \in U_q$.
- **Example** of a $T_2$ space is that of the real line, where any two points $p, q$
  can be separated with epsilon balls with centers $p, q$ and radii $(p - q) / 3$.
- **Closure definition**: $X$ is $T_2$ iff $x \neq y$ implies there is a set $A \in 2^X$ such that
  $x \not \in c(A) \land y \not \in c(X - A)$ where $X - A$ is the set complement.

### Relationship between DFS and closure when the topology is $T0$

If the topology is $T0$, then we know that the relation will be a poset,
and hence the graph will be a DAG. Thus, whenever we have $x \rightarrow y$, we
will get

### DFS: the T0 case
### DFS: the back edges

# Categorical definition of products in painful detail

I feel like I have incorrectly understood, then un-understood, and re-understood
in a slightly less broken way the definition of the product in category theory
around 5 times. I'm documenting the journey here.

### The definition

Given two objects $a, b$, in a category $C$, any 3-tuple
$(p \in C, \pi_a \in Hom(p, a), \pi_b \in Hom(p, b))$ is called their _product_, if for any
other 3 tuple $(q \in C, \pi'_a \in Hom(q, a), \pi'_b \in Hom(q, b))$, we have a
**unique** factorization map $f \in Hom(q, p)$ such that $\pi'_a = \pi_a \circ f$,
$\pi'_b = \pi_b \circ f$.

(Note that I did not say **the** product. This is on purpose). We claim that
the product is unique up to unique isomorphism.

Let's choose the category to be the category of sets. Let's try and figure out
what a product of the sets $a = \{ \alpha, \beta \}$ and $b = \{ \gamma, \delta \}$
is going to be.


#### Non-example 1: product as $\{ 1 \}$
Let's try to choose the product set as simply $\{ 1 \}$, with the maps
being chosen as $\pi_a(1) = \alpha; \pi_b(1) = \gamma$:

```text
     πb
p{1}--->{ γ }
  |     { δ }
  |
πa|
  v
{ α , β }
```

In this case, it's easy to see the failure. I can build a set $q = \{ 2 \}$ with
the maps $\pi'_a(2) = \alpha; \pi'_b(2) = \delta$:

```text
     πb
q{2}-+  { γ }
  |  |  {   }
  |  +->{ δ }
  |
πa|
  v
{ α , β }
```

There is a single, unique map which takes $q$ to $p$, which is the function $f: 2 \mapsto 1$.
See that $\pi'_b(2) = \delta$, while $\pi_b(f(2)) = \pi_b(1) = \gamma$. Hence
the universal property can never be satisfied.

Thus $(\{ 1 \}, 1 \mapsto \alpha, 1 \mapsto \gamma)$ is not a
product of $\{ \alpha, \beta \}$ and $\{ \gamma, \delta \}$ as it is
**unable to represent** a pair $(\alpha, \delta)$.

#### Non-example 2: product as $\{ 1, 2, 3, 4, 5 \}$

In this case, we shall see that we will have *too much freedom*, so this will
violate the "unique map" aspect. Let's pick some choice of $\pi_a$ and $\pi_b$.
For example, we can use:

$$
\begin{aligned}
(&p = \{ 1, 2, 3, 4\}, \\
&\pi_a = 1 \mapsto \alpha, 2 \mapsto \alpha, 3 \mapsto \beta, 4 \mapsto \beta, 5 \mapsto \beta\\
&\pi_b = 1 \mapsto \gamma, 2 \mapsto \delta, 3 \mapsto \gamma, 4 \mapsto \delta, 5 \mapsto \delta)
\end{aligned}
$$

Now let's say we have a set $q = \{ 42 \}$ such that $\pi'_a(42) = \beta, \pi'_b(42) = \delta$.

If we try to construct the map $f: q \rightarrow p$, notice that we get \emph{two}
possible legal maps. We can set $f(42) = 4$, or $f(42) = 5$, because both $4$
and $5$ map into $(\beta, \delta)$.

This violates the **uniqueness** condition of the product. Thus, the set $\{1, 2, 3, 4, 5\}$
is not a product of $\{\alpha, \beta \}$ and $\{\gamma, \delta \}$ because it does not
provide a **unique** map from $q$ into $p$. Alternatively, it does not provide
a **unique** representation for the tuple $(\beta, \delta)$. Thus it can't be a product.

#### Checking an example: $\{ \alpha, \beta \} \times \{ \gamma , \delta \}$ as $\{1, 2, 3, 4\}$

I claim that a possible product of $a$ and $b$ is:

$$
\begin{aligned}
(&p = \{ 1, 2, 3, 4\}, \\
&\pi_a = 1 \mapsto \alpha, 2 \mapsto \alpha, 3 \mapsto \beta, 4 \mapsto \beta,\\
&\pi_b = 1 \mapsto \gamma, 2 \mapsto \delta, 3 \mapsto \gamma, 4 \mapsto \delta)
\end{aligned}
$$


```
p       πa            a
   1------------*--->{α}
   |  2--------─┘    { }
   |  | 3-------*--->{β}
   |  | | 4----─┘
   +----* |
πb |  |   |
   |  *---+
   |      |
   v      v
b {γ      δ}
```

Now given a 3-tuple $(q, \pi'_a \in Hom(q, a), \pi'_b \in Hom(q, b))$, we construct
the factorization map $f: q \rightarrow p$, where:
$$
f: q \rightarrow p; \quad
f(x) \equiv
\begin{cases}
1 & \pi'_a(x) = \alpha \land \pi'_b(x) = \gamma \\
2 & \pi'_a(x) = \alpha \land \pi'_b(x) = \delta \\
3 & \pi'_a(x) = \beta  \land \pi'_b(x) = \gamma \\
4 & \pi'_a(x) = \beta  \land \pi'_b(x) = \delta \\
\end{cases}
$$

That is, we build $f(x)$ such that on composing with $\pi_a$ and $\pi_b$, we will
get the right answer. For example, if $\pi'_a(x) = \alpha$, then we know that
we should map $x$ to an element  $y \in p$ such that $\pi(y) = \alpha$. So
we need $y = 1 \lor y = 2$. Then looking at $\pi'_b(x)$ allows us to pick a
**unique** y. There is zero choice in the
construction of $f$. We need _exactly_ 4 elements to cover all possible ways
in which $q$ could map into $a$ and $b$ through $\pi'_a, \pi'_b$ such that
we cover all possibilities with no redundancy.

This choice of product is _goldilocks_: it does not have too few elements such
that some elements are not representable; it also does not have too many
elements such that some elements are redundant.

#### Non uniqueness: product as $\{10, 20, 30, 40\}$

Note that instead of using $p = \{1, 2, 3 4\}$, I could have used
$p = \{10, 20, 30, 40 \}$
and nothing would have changed.
I have never depended on using the _values_ $1, 2, 3, 4$.
Rather, I've only used them as \emph{labels}.

#### Non uniqueness: product as  $\{ (\alpha,  \gamma), (\alpha, \delta), (\beta, \gamma), (\beta, \delta) \}$

Indeed, our usual idea of product also satisfies the product, since it is
in unique isomorphism to the set $\{1, 2, 3, 4\}$ we had considered previously.
But this might be strange: Why is it that the categorical definition of product
allows for so many other "spurious" products? Clearly this product of tuples
is the **best** one, is it not?

Of course not! Inside the category of sets, anything with the same cardinality
is isomorphic. So nothing inside the category can distinguish between the
sets $\{1, 2, 3, 4\}$ and  $\{ (\alpha,  \gamma), (\alpha, \delta), (\beta, \gamma), (\beta, \delta) \}$.
Hence, the _usual product_ we are so used to dealing with is not privileged.

This should make us happy, not sad. We have removed the (un-necessary)
privilege we were handing to this one set because it "felt" like it was
canonical, and have instead identified what actually makes the product of sets
tick: the fact that their cardinality is the product of the cardinalities of
the individual sets!


#### How to think about the product

Since we are specifying the data of $(p, \pi_a, \pi_b)$, we can simply think of
elements of $p$ as being "pre-evaluated", as $(x \in p, \pi_a(x), \pi_b(x))$.
So in our case, we can simplify the previous situation with $(p = \{ 10, 20, 30, 40 \}, \pi_a, \pi_b)$
by writing the set as
$p = \{ (10, \alpha, \gamma), (20, \alpha, \delta), (30, \beta, \gamma), (40, \beta, \delta) \}$.
This tells us "at a glance" that every element of $a \times b$ is represented,
as well as what element it is represented by.


#### Proof of uniqueness upto unique isomorphism

- Assume we have two products $(p, \pi_a, \pi_b)$ and $(q, \pi_a, \pi_b)$, which
  are products of $a$ and $b$
- By the universality of $p$ wrt $q$, we get a unique! map $q2p$ such that the diagaram commutes.
- By the universality of $q$ wrt $p$, we get a unique! map $p2q$
- We get a map $q2p \cdot p2q : p \rightarrow p$. by the universality of $p$ with
  respect to $p$, we get a unique! map that makes the diagram commute.But we have
  two such maps: $id_p$ as well as $q2p . p2q$. Hence we must have $id_p = q2p \cdot p2q$. In pictures:

```
          ∃!id(p)
          +---+
          |   |
          |   v
+---------ppppp--------+
| πa      |   ^     πb |
v      ∃!p2q  |        v
a         |   |        b
^         |  ∃!q2p     ^
| π'b     v   |    π'b |
+---------qqqqq--------+
```

- The full diagram commutes.
- By definition of identity/commutativity of the diagram, $\pi_a \circ id_p  = \pi_a$.
- By definition of identity/commutativity of the diagram, $\pi_b \circ id_p  = \pi_b$.
- By the commutativity of the diagram, we have $\pi_a \circ (q2p \circ p2q) = \pi_a$.
- By the commutativity of the diagram, we have $\pi_b \circ (q2p \circ p2q) = \pi_b$.
- We can consider the universal property of the product, where we have
  $(p, \pi_a, \pi_b)$ as one product, and $(p, \pi_a , \pi_b)$ as another
  product.
- This gives us a **unique map** $h$ such that $\pi_a \circ h = \pi_a$, and
  $\pi_b \circ h = \pi_b$.
- We have two candidates for $h$: $h = id_p$ and $h = p2q \circ q2p$.
  Hence, by the uniqueness of $h$, we have that $id_p = p2q \circ q2p$.

#### Wrapping up

- [Link to a misconception of the proof I had carried around for ages](https://math.stackexchange.com/questions/3756610/flaw-in-a-proof-of-uniqueness-of-products-in-a-category/3756693#3756693)

# Why is the spectrum of a ring called so?

I've been watching Ravi Vakil's excellent "pseudolectures" on algebraic geometry,
aptly titled
[AGITTC: Algebraic geometry in the time of Covid](https://www.youtube.com/channel/UCy3u23mZE4TyW88yr6JLx9A).
In lecture 3, there was a discussion going on in the sidebar chat where a user
said that the name "prime sprectrum" came from something to do with quantum
mechanics. To quote:

> letheology: spectrum of light -> eigenvalues of the hamiltonian operator ->
> prime ideal of the polynomial ring of the operator

I don't know what the prime ideal of the polynomial ring of the operator is,
so let's find out!  [I got a somewhat incomplete answer on `math.se`](https://math.stackexchange.com/questions/3754152/what-is-the-prime-ideal-of-the-polynomial-ring-of-an-operator)


Another user said:

> Lukas H: I like the definition of Spec A that doesn't include the word
> prime ideal, by a colimit of Hom(A, k) where k run over all fields and the
> maps are morphisms that make the diagrams commute.

That's a pretty crazy definition. One can apparently find this definition
in Peter Schloze's notes on AG. [I got an answer for this on `math.se`](https://math.stackexchange.com/questions/3754159/categorical-definition-of-spectrum-of-a-ring-as-a-colimit)

# Ergo proxy

I've been watching the anime "Ergo Proxy". I'll keep this section updated
with things I find intriguing in the anime.


- `bios` stood for both bow and life in greek, supposedly. Both lead to death.
  This is an interesting fact. I wonder if the `BIOS` of our computers is also
  from this, and was they backronymed into basic input/output system.

- "the white noise that reverberates within the white
  darkness is life itself". I have no idea what this means. It's a great
  sentence for sure.


#  [Satisfied and frustrated equations](#satisfied-and-frustrated-equations)

I found [this interesting terminology on a wiki walk](https://en.wikipedia.org/wiki/Gain_graph)
- An edge is satisfied if some equation `y = f(x)` is **satisfied**.
- Otherwise, the edge is said to be **frustrated**.

This is far more evocative terminology than UNSAT/unsatisfied, and also
makes for good haskell like variable names. `ss` for satisfied equations,
`fs` for frustrated equations!

# Combinatorial intuition for Fermat's little theorem

We wish to show that $x^p \equiv x (\mod p)$ _combinatorially_. Let's take
$2^3 (\mod 3)$ for simplicity. The general case follows. Let's first write
down strings which enumerate $2^3$:

```
000
001
010
011
100
101
110
111
```

To make use of $\mod 3$, we're going to treat our strings as _necklaces_. So,
for example, the string `011` looks like:

```
*-→ 0 -*
|      |
|      ↓
1 ←--- 1
```

So we have three possible rotations of the string `011`:

```
011
110
101
```

- Each of these rotations are unique, since they can be totally ordered using
  lexicographic ordering. Indeed, for **any string** other than `000`, `111`,
  all of its rotations are unique.

- So we can count the above 7 strings with equivalence class representatives.
  These representatives are those strings that are the lex smallest in their
  cyclic shifts. (Why are cyclic shifts _so important_?)

```
Cyclic subshifts of strings:
---------------------------
000, 000, 000
001, 010, 100
011, 110, 101
111, 111, 111
```

- We've written the strings along with their cyclic subshifts, with the
  representative of the equivalence class as the first element. So the
  representatitives are `000, 001, 011, 111`. Note that two of these (`000, 111`)
  are equal to their cyclic subshifts. All of the others are distinct, and generate
  3 elements.

- So we can count the above strings as:

```
all strings   = {shifts of 001, 011}U{000, 111}
|all strings| = |{shifts of 001, 011}|+|{000, 111}|
no. of shifts = 3*(no. of representatives)
2^3 = 3 * (no. of representatives) + 2
2^3 = 3 * (no. of representatives) + 2
2^3 % 3 = 2
```

In general, for `x^p % p`, we will get `x` strings that contain the same letter.
These will not have elements in their cyclic shift equivalence classes. The
other strings will be generated as the smallest cyclic subshift of some
string.

#### Why does this not work when `p` is not prime?

Let `p = 4`. In this case, I can pick the string `s = 0101`. It has shifts:

```
0101 <-
1010
0101 <-
1010
```

so two of its shifts overlap, hence we will double-count the string `0101`
if I counted its equivalence class as having size `4`.

#### Relationship to group theory?

- How does this relate to group theory? Well, what we are doing is providing
  an action of the group `Z/pZ` into the set of strings `X^p` where `X` is
  some set. Our group action for a number `n ∈ Z/pZ` takes a
  string `s ∈ X^p` to its cyclic shift by `n` characters.

- We are then using the fact that the orbits of an action when `p` is prime
  has size either `1` or `p`, since the size of the orbit divides the
  size of the group `Z/pZ`, which is `p`, a prime. The divisors of
  `p` are only `1` and `p`. Therefore, the size of the orbit is either `1`
  or `p`.

- Only necklaces that have identical elements like `000` and `111` have
  orbits of size `1`. We have `|X|` such necklaces.

- All other necklaces have size `p`.

- The rest of the proof follows similarly as before.


#### References

- [A string of pearls: proofs of Fermat's little theorem](https://ts.data61.csiro.au/publications/nicta_full_text/6061.pdf)
- [Algorithms thread 1: division under mod](https://www.youtube.com/watch?v=KfTcd0dg0DI&feature=youtu.be&t=815)

# An incorrect derivation of special relativity in 1D

I record an _incorrect_ derivation of special relativity, starting from the
single axiom "speed of light is constant in all inertial reference frames".
I don't understand why this derivation is incorrect. Help figuring this out
would be very appreciated.

### The assumption

We assume that the velocity of light as measured by any inertial frame
is constant. Thus if $x, x'$ are the locations of light as measured by
two inertial frames, and $t, t'$ is the time elapsed as measured by two
inertial frames, we must have that $dx/dt = dx'/dt'$. This ensures
that the speed of light is invariant.

### The derivation


- Our coordinate system has an $x$ space axis and a $t$ time axis.
- We have observer (1) standing still at the origin, and measures time
  with a variable $t$.
- We have observer (2) moving to the left with a constant velocity $v$.
- Observer (1) who is at rest sees a photon starting from the origin
  travelling towards the right with constant velocity $c$. The position of the
  photon at time $t$ is $x = c t$.
- Observer (2) also sees this photon. At time $t$, he sees the position
  of the photon as $x' = vt + ct$.
- From our rule of invariance, we have that $dx/dt = c = dx'/dt'$.

We calculate $dx'/dt' = (dx'/dt)(dt/dt')$ [chain rule], giving:

$$
\begin{aligned}
&c = \frac{dx}{dt} = \frac{dx'}{dt'} = \frac{dx'}{dt} \frac{dt}{dt'}  \\
&c = \frac{d(vt + ct)}{dt}\frac{dt}{dt'} \\
&c = (v + c) \frac{dt}{dt'} \\
&\frac{c}{v+c} = \frac{dt}{dt'} \\
&dt' = (v+c)dt/c \\
&t' = (v+c)t/c = (1 + v/c) t
\end{aligned}
$$

So we get the relation that time elapsed for observer (2) is related
to observer (1) as $t' = (1 + v/c) t$.

- This checks out: Assume our observer is moving leftward at $v = c$. He will
  then see the photon move rightward at $x' = 2ct$. So if his time slows down
  to have $t' = 2t$, we will have that $x/t' = 2ct/2t = c$.

- However, this forumla allows us to go faster than the speed of light with
  no repercurssions! (It is also not the correct formula as anticipated by
  the usual derivation). This can be fixed.

- Now assume that Observer 2 was moving _rightward_, not _leftward_. That is,
  we simply need to set $v = -v$, since this change of sign accomplishes
  flipping the direction of motion in 1D. This gives us the equation
  $t' = (1 - v/c)t$.

- According to this new equation, we are not allowed to approach the speed of
  light. If we attempt to do so, we will need to elapse zero time; and if
  we exceed the speed of light, we will need to elapse _negative time_.

- However, these formulae lead to an absurdity. If our observer 1 and observer 2
  witness two photons, one moving leftward and one moving rightward, one will
  need to write down the equations $t' = (1 \pm v/c)t$, which plainly leads
  one to contradiction.

### What's the issue?

The issue is the equation $x' = vt + ct$.
- It is true that _as per observer (1) standing at the origin_, the distance
  between observer (2) and the photon is $vt + ct$.
- It is _not_ true that observer(2) sees the distance between them and
  the photon  as $vt + ct$.
- Intuitively, this equation of $x' = vt + ct$ completely ignores length
  contraction, and hence cannot be right.
- Alternatively, the equation of $x' = vt + ct$ imposes galilean relativity,
  where I am attempting to naively connect reference frames, which cannot be
  correct.


#  [The geometry and dynamics of magnetic monopoles](#the-geometry-and-dynamics-of-magnetic-monopoles)

I found this cool document written by Sir Atiyah, called as
["The geometry and dynamics of magnetic monopoles"](https://www.jstor.org/stable/j.ctt7zv206)
which contains
a nice exposition of electromagnetism from the differential viewpoint.
I'll record what I read here.


# Sanskrit and Sumerian

#### Sanskrit's precursors

The oldest known sanskrit text that has been found is the Rig Veda. Eveyrthing
after is the study of sanskit proper. This is quite problematic because the
Rig Veda is a complete and consistent textbook with respect to language. It's
a black-box in terms of language evolution.

The question "what is the precursor" asks for a method of study to determine
the precursor. We just don't know because we have no writings, text, etc.

##### Archaeological data

Archaeological data is problematic as well. We don't know where the people who
knew sanskrit came from. Sanskrit was spoken in the northen part of
Hindusthan [what they originally called Bhrahma-nagar (?)]. While we can
try to undersatnd where it comes from, it's hard. The script is Brahmi / Devanagiri,
which means used by Brahma or god. The name "sanskrit" is a compound that stands
for "well-formed". It's really clean-slate in that sense. The study of Indo-Aryan
languages in the Indian subcontinent has only one possible known history, which
stops at the Rig Veda. We don't know the relationship between 2400BC when
Rig Veda was written to anything before it.

##### Non Vedic sanskrit

Studies in non-vedic sanskrit is known to be the "true" proto-Indo-Europoean (PIE)
language. The conjecture is that this Indo European language ought to be
able to cover middle greek, hittite, and sanskit.

##### Prakrit and its relationship to this story

Prakrit evolved as a vernacular of Sanskrit in the north pahadi region. Hindi
as we know toady evolved from Hindusthani, which came from languages in
northern india. Languages like Marathi, Marvadi, Gujurathi, etc. came a lot
before Hindi did.

##### TLDR on Sanskrit v/s Hindi

There is a huge gap of time between Sanskit, Prakrit, Pali, and Hindi.
Hindi evolved around the 1600s due to the Mughals who used to speak a
vernacular of Hindusthani. Kabir also wrote in Hindusthani. There was also
some Farsi and Urdu mixed in.

> Hindi is more of a political exploit than an actual language ~ Alok 2020


##### The relationship to Sumerian

We don't know what the relationship to sumerian is. Social expectations that
was setup is sumerian has become more stringent in Sanskrit.


# Writing Cuneiform

I've been reading about the Sumerian people, and I've gotten fascinated with
the question of how to write in Cuneiform, which is their script. I wanted
to learn how to write cuneiform. It appears that it was originally written
down by pressing reed styluses into clay. The script is syllabic in nature.
We have three components:

1. Vertical wedge `𐏑`
2. Horizontal wedge `𐎣`
3. Diagonal `𐏓`




##### References

- [Getty museum: Writing cuneiform](https://www.youtube.com/watch?v=HbZ2asfyHcA)
- [Irving Finkel teaches how to write cuneiform](https://www.youtube.com/watch?v=XVmsfL5LG90)
- [CLDI: Cuneiform Digital library initiative](http://cdli.ox.ac.uk/wiki/doku.php?id=cuneiform_writing_techniques)
- [Font: Old persian block](https://www.compart.com/en/unicode/block/U+103A0)

# The code of hammurabi

I've wanted to read the code of hammurabi since it was name dropped in
[Snow Crash by Neal Stephenson](https://en.wikipedia.org/wiki/Snow_Crash).
I finally got around to it. Here's some excerpts I found fascinating. The
numbers are according to
[this translation of the Code of Hammurabi](http://www.general-intelligence.com/library/hr.pdf).
Some helpful hints were found from the
[Avalon ancient law codes page of the Yale law school](https://avalon.law.yale.edu/ancient/).

- (5) If a judge try a case, reach a decision, and present his judgment in
  writing; if later error shall appear in his decision,and it be through his
  own fault, then he shall pay twelve times the fine set by him in the case, and
  he shall be publicly removed from the judge’s bench, and never again shall he
  sit there to render judgement. (**Commentary**: These are steep penalties for
  getting a case wrong. I suppose this encouraged innocent until proven guilty
  quite a bit.)

- (23) If the robber is not caught, then shall he who was robbed claim under
  oath the amount of his loss; then shall the community, and...on whose
  ground and territory and in whose domain it was compensate him for the goods
  stolen (**Commentary**: This rule appears to setup some sort of insurance where
  someone who is robbed is guaranteed recompence)

- (108) If a tavern-keeper (feminine) does not accept corn according to gross
  weight in payment of drink, but takes money, and the price of the drink is
  less than that of the corn, she shall be convicted and thrown into the water.
  (**Commentary**: I wonder why this rule specifically singles out women)

- (120) If any one store corn for safe keeping in another person’s house, and
  any harm happen to the corn in storage, or if the owner of the house open the
  granary and take some of the corn, or if especially he deny that the corn was
  stored in his house: then the owner of the corn shall claim his corn before God
  (on oath), and the owner of the house shall pay its owner for all of the corn
  that he took. (**Commentary**: I wonder whether there were many 'owners of corn'
  who swore false oaths. I suppose not, if this rule was enshrined into law.
  It is interesting that they held oaths to god as a mechanism to prevent lying)

- (137) 137. If a man wish to separate from a woman who has borne him children,
  or from his wife who has borne him children: then he shall give that wife her
  dowry, and a part of the usufruct offield, garden, and property, so that she
  can rear her children.When she has brought up her children, a portion of all
  that is given to the children, equal as that of one son, shall be given to her.
  She may then marry the man of her heart. (**Commentary**: their society
  seems egalitarian, and provides both a mechanism of divorce, and rights
  and property to the wife after divorce).

- (168) If a man wish to put his son out of his house, and declare before the
  judge: “I want to put my son out,” then the judge shall examine into his
  reasons. If the son be guilty of no great fault, for which he can be
  rightfully put out, the father shall not put him out; (169). If he be guilty of a
  grave fault, which should rightfully deprive him of the filial relationship,
  the father shall forgive him the first time; but if he be guilty of a grave
  fault a second time the father may deprive his son of all filial relation.
  (**Commentary**: I find this notion of 'forgive once' being encoded into law
  very interesting. I don't know of other law codes that have such a thing).

- (188). If an artizan has undertaken to rear a child and teaches him his
  craft, he can not be demanded back; (189) If he has not taught him his craft,
  this adopted son may return to his father’s house. (**Commentary**: I find it
  interesting that this notion of 'taking a son' is intertwined with caring
  for the son and teaching them a craft to become a future productive member
  of society)

- (196) If a man put out the eye of another man, his eye shall be put out.
  [ An eye for an eye ].  (**Commentary**: Fascinating that 'eye for an eye' comes from the code).

- (202). If any one strike the body of a man higher in rank than he,he shall
  receive sixty blows with an ox-whip in public.
  (**Commentary**: Neat how one can glean the existence of a social hierarchy
  from a law code. I wonder how this hierarchy was defined.)


- (215) If a physician make a large incision with an operating knife and cure
  it, or if he open a tumor (over the eye) with an operating knife, and saves
  the eye, he shall receive ten shekels in money.
  (**Commentary**: (i) It is weird that things like doctor's procedures are covered
  in the law code. How often is the code revised? What happens when a doctor
  comes up with a new treatment? (ii) It is weird that the prices are recorded
  in the law code. What about inflation?)

- (249) If any one hire an ox, and God strike it that it die, the man who hired
  it shall swear by God and be considered guiltless. (**Commentary**: Once again,
  their belief in the truthfulness of oaths sworn to God. Also, it's nice to
  know that they do understand and account for truly random events that one
  has no control over)

- Epilogue: In future time, through all coming generations, let the king,who may be in the
  land, observe the words of righteousness which I have written on my monument;
  let him not alter the law of the land which I have given, the edicts which I
  have enacted; my monument let him not mar. If such a ruler have wisdom, and
  beable to keep his land in order, he shall observe the words which I have
  written in this inscription (**Commentary**: This advice for future kings is
  interesting, and appears to imply that the rules and all the prices in the
  rules ought to be immutable. I really do wonder how they dealt with their
  society changing, new inventions, and inflation)

- [Taken from this introduction to the code of hammurabi from Yale](https://avalon.law.yale.edu/ancient/hammint.asp):
  An accused person was allowed to cast himself into "the river," the Euphrates.
  Apparently the art of swimming was unknown; for if the current bore him to the
  shore alive he was declared innocent, if he drowned he was guilty. So we learn
  that faith in the justice of the ruling gods was already firmly, though
  somewhat childishly, established in the minds of men

# The implicit and inverse function theorem

I keep forgetting the precise conditions of these two theorems. So here
I'm writing it down as a reference for myself.

### Implicit function: Relation to function
- Example 1: $x^2 + y^2 = 1$ to $y = \sqrt{1 - x^2}$.

If we have a function $y = g(p, q)$, we can write this as $y - g(p, q) = 0$.
This can be taken as an implicit function $h(y; p, q) = y - g(p, q)$. We then
want to recover the explicit version of $y = g'(p, q)$ such that
$h(g'(p, q); p, q) = 0$. That is, we recover the original explicit formulation
of $y = g'(p, q)$ in a way that satisfies $h$.

#### The 1D linear equation case

In the simplest possible case, assume the relationship between $y$ and $p$
is a linear one, given implicitly. So we have $h(y; p) = \alpha y + \beta p + \gamma = 0$.
Solving for $h(y,p) = 0$, one arrives at: $y = -1/\alpha (\beta p + \gamma)$.
- Note that the solution exists iff $\alpha \neq 0$.
- Also note that the the existence of the solution is equivalent to asking that
  $\partial h / \partial y = \alpha \neq 0$.


#### The circle case

In the circle case, we have $h(y; p) = p^2 + y^2 - 1$. We can write
$y = \pm \sqrt{p^2 - 1}$. These are _two_ solutions, not one, and hence
a relation, not a function.

- We can however build two functions by taking two parts. $y+ = +\sqrt{p^2 - 1}$;
  $y- = -\sqrt{p^2 - 1}$.

- In this case, we have $\partial h / \partial y = 2y$, which changes sign
  for the two solutions. If $y^\star > 0$, then $(\partial h / \partial y)(y^\star = 0)$.
  Similarly for the negative case.

#### Assuming that a solution for $h(y, p)$ exists

Let us say we wish to solve $h(y; p) = y^3 + p^2 - 3 yp - 7 = 0$. Let's assume
that we have a solution $y = sol(p)$ around the point $(y=3, p=4)$. Then we
must have: $sol(p)^3 + p^2 - 3 sol(p) p - 7 = 0$. Differentiating by $p$,
we get: $3 sol(p)^2 sol'(p) + 2p - 3 sol'(p) p - 3 sol(p) = 0$. This gives
us the condition on the derivative:

$$
\begin{aligned}
&3 sol(p)^2 sol'(p) + 2p - 3 sol'(p) p - 3 sol(p) = 0 \\
&sol'(p)\left[ 3 sol(p)^2 - 3p \right] = 3 sol(p) - 2p \\
&sol'(p) = [3 sol(p) - 2p] / \left[ 3(sol(p)^2 - 3p) \right]  \\
\end{aligned}
$$

The above solution exists  if $3(sol(p)^2 - 3p \neq 0)$. This quantity is again
$\partial h / \partial y$.

#### Application to economics

- We have two inputs which are purchaed as $x_1$ units of input 1, $x_2$ units of input $2$.
- The price of the first input is $w_1 BTC/unit$. That of the second input is $w_2 BTC/unit$.
- We produce an output which is sold at price $w BTC/unit$.
- For a given $(x_1, x_2)$ units of input, we can produce  $x_1^a x_2^b$  units of output where
  $a + b < 1$.
  [The Coob-douglas function](https://en.wikipedia.org/wiki/Cobb%E2%80%93Douglas_production_function).
- The profit is going to be $profit(x_1 x_2, w_1, w_2, w) = w(x_1^a x_2^b) - w_1 x_1 - w_2 x_2$.
- We want to select $x_1, x_2$ to maximize profits.
- Assume we are at break-even: $profit(x_1, x_2, w_1, w_2, w) = 0$.
- The implicit function theorem allows us to understand how any variable changes
  with respect to any other variable. It tells us that locally, for example,
  that the number of units of the first input we buy ($x_1$) is a function
  of the price $w_1$. Moreover, we can show that it's a _decreasing function_
  of the price.



### Inverse function: Function to Bijection

- Given a differentiable function $f$, at a point $p$, we will have a continuous inverse
  $f^{-1}(p)$ if the derivative $f'(p)$ is locally invertible.

- The intuition is that we can approximate the original function with a linear
  function. $y = f(p + \delta) = f(p) + f'(p) \delta$. Now since $f'(p)$ is
  locally invertible, we can solve for $\delta$. $y = f(p) + f'(p) \delta$
  implies that $\delta = 1/f'(p) [y - f(p + \delta) ]$.
  This gives us the pre-image $(p + delta) \mapsto y$.

- The fact that $1/f'(p)$ is non-zero is the key property. This generalizes
  in multiple dimensions to saying that $f'(p)$ is invertible.


One perspective we can adopt is that of Newton's method. Recall that Newton's
method allows us to find $x^*$ for a fixed $y^*$ such that $y^* = f(x^*)$. It follows
the exact same process!

- We start with some $x[1]$.
- We then find the tangent $f'(x[1])$.
- We draw the tangent at the point $x[1]$ as $(y[2] - y[1]) = f'(x[1])(x[2] - x[1])$.
- To find the $y^*$ we set $y[2] = y^*$.
- This gives us $x[2] = x[1] - (y^* - y[1])/f'(x[1])$.
- Immediately generalizing, we get $x[n+1] = x[n] - (y^* - y[n]) / f'(x[n])$.

##### Idea of proof of implicit function theorem (from first principles)


- Let $F(x, y) \neq 0$, point $p$ be the point where we wish to implicitize.
- To apply implicit fn theorem, take $\partial_y|_pF(x, y) \neq 0$.
  Say WLOG that $\partial_y|_p F(x, y) > 0$,
  since $F$ is assumed to be continuously differentiable.
- Since $\partial_y F$ is continuous and positive at $p$,
  it's positive in a nbhd of $p$ by continuity.
- Consider $F(p_x, y)$ as a single variable function of $y$. Its derivative with
  respect to $y$ is positive; it's an increasing function in terms of $y$.
- Since $F(x_0, y_0)$ and is an increasing function of $y_0$, we must have
  two $y$ values $y_-, y_+$ such that $F(p_x, y_+)$ is positive, and $F(p_x, y_-)$
  is negative.
- Since $F$ is zero and continuous, we have that for all $x$ near $x_0$, that
 $F(x_0, y_+) > 0 \implies F(x, y_+) > 0$ and $F(x_0, y_-) < 0 \implies F(x, y_-) < 0$.
 We have released $x_0$ into a wild $x$ in the neighbourhood!
- Now pick some $x_*$ near $x$. Since we have that $F(x_*, y_+) > 0$ and $F(x_*, y_-) < 0$,
  there exists a **unique** $y_*$ (by MEAN VALUE THEOREM) that $F(x_*, y_*) = 0$
- Since the $y_*$ is unique, we found a function: $x_* \xmapsto{f} y_*$.
- We are not done. We need to prove the formula for $f'(x)$ where $f$ is the
  implicit mapping.
- $F(x, f(x)) = 0$ by defn of $f(x)$. Apply chain rule!

$$
\begin{aligned}
&F(x, f(x)) = 0 \\
&dF = 0 \\
&\frac{\partial F}{\partial x} \cdot \frac{\partial x}{\partial x}  + \frac{\partial F}{\partial y} \frac{df}{dx} = 0 \\
&\frac{\partial F}{\partial x} \cdot 1  + \frac{\partial F}{\partial y} \frac{df}{dx} = 0 \\
&\frac{df}{dx} = \frac{- \frac{\partial F}{\partial y}}{\frac{\partial F}{\partial x} \cdot 1} \\
\end{aligned}
$$

#### Idea of proof of inverse function theorem (from implicit function theorem)

- Given the implicit function, say we want to locally invert $f(x)$.
- Pick the implicit function $F(x, y) = f(y) - x$. If we consider the level set $F(x, y) = 0$,
  the implicit function theorem grants us a $g(x)$ such that $F(x, y=g(x)) = 0$.
  That is, we get $f(g(x)) - x = 0$, or $f(g(x)) = x$.
- To show that it's also a right inverse, consider $F(f(k), k) = f(k) - f(k) = 0$.
  Since $y = g(x)$, we have that $k = g(f(k))$.
- Hence, $g$ and $f$ are both left and right inverses, and hence bijections.

#### Idea of proof of implicit function theorem (from inverse function theorem)

- We are given a function $F(x, y)$. We wish to find a formula $y = g(x)$ such that
 $F(x, g(x)) = 0$.
- The idea is to consider a function $f(x, y) = (x, F(x, y))$.
- Since this is invertible, we get a local inverse function $g$ such that $g(f(x, y)) = (x, y)$.
  That is, $g(x, F(x,y)) = (x, y)$.
- Now, for a given $x$, set  $y := snd(g(x, 0))$. This gives us a $(x, y)$ such that
  $g(x, F(x,y)=0) = (x, y)$. That is, we get a $y$ such that $F(x, y) = 0$ and
  this a bijection from $x$ to $y$ since $g$ is a bijection.

#### Idea of proof of inverse function theorem (from newton iterates)

We know that $F(x + \delta x) = F(x) + J \delta x + \eta$ where $J$ is the jacobian,
$\eta$ is error term. Upto first order, this works. We take iterates of this
process to get the full inverse.


#### References

- [Mathematics for economics, Natalia Lazzati](https://people.ucsc.edu/~nlazzati/Courses/Math519/Notes/Note%203.pdf)
- [Inverse function theorem via Newton's method](http://mtaylor.web.unc.edu/files/2018/04/invfn.pdf)

# Whalesong hyperbolic space in detail

We can build a toy model of a space where velocity increases with depth.
Let the x-y axis be: left-to-right (→) is positive x, top-to-bottom (↓) is positive y.
Now let the velocity at a given location $(x^\star, y^\star)$ be $(y^\star+1, 1)$.
That is, velocity along $y$ is constant; the velocity along $x$ is an increasing
function of the current depth. The velocity along $x$ increases linearly with depth.
Under such a model, our shortest paths will be 'curved' paths.


#### References

- Very funnily, the wikipedia page on Whale vocalization has a 'selected discograpy'
  section: [Whalesong, selected discography](https://en.wikipedia.org/wiki/Whale_vocalization#Selected_discography)


# Motivating Djikstra's

Usually I've seen Djikstra's algorithm presented as a greedy algorithm,
and then an analogy given to "fire" for the greediness. We can reverse
this presentation start with the "fire", and the discretize the "fire" solution
to arrive at Djikstra's

#### The fire analogy

- Assume we want to find the shortest path from point $A$ to point $B$. We
  should find the path that fire travels. How do we do this? Well, we simply
  simulate a fire going through all paths from our initial point,
  and then pick the shortest path (ala Fermat). We interpret the graph
  edges as distances between the different locations in space.

- So we write a function $simulate :: V \times T \rightarrow 2^{V \times T}$, which
  when given a starting vertex $v : V$ and a time $t : T$, returns the set
  of vertices reachable in at most that time, and the time it took to reach them.

- Notice that we are likely repeating a bunch of work. Say the fire
  from $x$ reaches $p$, and we know the trajectory of the fire from $p$. The
  next time where a fire from $y$ reaches $p$, we don't need to _recalculate_
  the trajectory. We can simply cache this.

- Notice that this time parameter being a real number is pointless;
  really the only thing that matters are the _events_ (as in computational geometry),
  where the time crosses some threshold.


- By combining the two pieces of information, we are led to the
  usual implementation: Order the events by time using a queue, and then
  add new explorations as we get to them.




# Intuitions for hyperbolic space

- [Combinatorial group theory](https://math.stackexchange.com/questions/689257/topics-in-combinatorial-group-theory-for-a-short-talk/692534#692534)
- [Van Kampen diagrams: an intuition](https://math.stackexchange.com/questions/330531/algebra-best-mental-images/331135#331135)
- [DIY Hyperbolic geometry](https://math.berkeley.edu/~kpmann/DIYhyp.pdf)
- [Hyperbolic Embeddings with a Hopefully Right Amount of Hyperbole](https://dawn.cs.stanford.edu/2018/03/19/hyperbolics/)
- [Notes on Hyperbolic geometry by Canon](library.msri.org/books/Book31/files/cannon.pdf)
- A question on `math.se` that attempts to describe hyperbolic space: [What hyperbolic space really looks like](https://math.stackexchange.com/questions/1407550/what-hyperbolic-space-really-looks-like)
- [Another question about what hyperbolic space feels like](https://math.stackexchange.com/questions/3520395/what-does-hyperbolic-space-feel-like)
- [Notes On Hyperbolic and Automatic Groups: Michael Batty](https://www.math.ucdavis.edu/~kapovich/280-2009/hyplectures_papasoglu.pdf)
- [The geometry of the word problem by Martin R Bridson](https://people.maths.ox.ac.uk/bridson/papers/bfs/bfs.pdf)
- [Living in Hyperbolic space](http://www.stevejtrettel.com/living-in-hyperbolic-space.html)
- [We can embed euclidian space into hyperbolic space](https://math.stackexchange.com/questions/1347/studying-euclidean-geometry-using-hyperbolic-criteria)
- [Amsler surface: A surface with constant negative gaussian curvature](https://math.stackexchange.com/questions/289716/hyperbolic-diameter-of-amslers-surface)
- [Hyperbolic distance naturally measures distance as paths of light with varying refractive index](https://math.stackexchange.com/questions/1887685/hyperbolic-distance-confusion)
- [The pseudosphere, another surface with constant negative curvature](https://mathworld.wolfram.com/Pseudosphere.html)
- [Whalesong, selected discography](https://en.wikipedia.org/wiki/Whale_vocalization#Selected_discography)

# Product of compact spaces in compact

<img src="./static/product-of-compact-is-compact.png">

# Hyperbolic groups have solvable word problem

I have never seen an elementary account of this in a 'trust these facts, now
here is why hyperbolic groups have a solvable word problem'. I am writing
such an account for myself. It's an account for building intuition, so no
proofs will be provided except for the final theorem. All facts will be backed
by intuition. Since most of it is geometric, it's easy to convey intuition.

### Graphs of groups, quasi-isometry.
- **NOTE:** I will consistently denote the inverse of $g$ by $g^{-1}$.

We can convert any group into a graph by using the cayley graph of the group.
We characterize hyperbolic space as a space where we can build 'thin triangles'.
We also think of hyperbolic space as where geodesics from a given point
diverge (in terms of angle) exponentially fast.

The choice of generators for the cayley graph gives different graphs. We can
assign a **unique** geometric object by considering cayley graphs upto quasi
isometry. The cayley graph of a group with respect to different generating sets
are quasi-isometric. We can now try to study properties that are invariant
under quasi-isometry, since these are somehow 'represented faithfully by the geometry'.

### Hyperbolicity enters the picture
We now say that a graph is hyperbolic if the cayley graph of the group is
hyperbolic. We can show that hyperbolicity is preserved by quasi-isometry.
So this property does not depend on the generating set.

### Isoperimetric Inequality

If we have a finitely presented group $G = \langle S | R \rangle$, and $w$
is a word in the free group $Free(S)$, if $[[w]] = 1$, we will have

$$
w = \prod_{i=1}^n u_i r_i^{\pm 1} u_i'
$$

This follows almost by definition. Since we have quotiented by $r$ we can have
elements of $r$ in between $u u'$. We will need to have a $u'$ since there's
nothing else to cancel off the $u$.

##### Area of a word
Let $G = \langle S | R \rangle$. Let $w$ be a word in $S$ such that $[[w]] = e$.
The area of the word $w$ is the minimal number of such $u r u'$ components
we need to write it down. Formally:

$$
Area(w) = \min { n | \prod_{i=1}^n u_i r+i^{\pm 1} u_i'}
$$

I don't understand the geometric content of this definition. I asked
[on mathoverflow](https://mathoverflow.net/questions/363455/geometric-content-of-area-of-a-word-in-geometric-group-theory).


##### Isopermetric function for a group

$f: \mathbb N \rightarrow \mathbb N$ is a Dehn function or isoperimetric function
if the area of the word is upper bounded by $f(|word|)$. In some sense, the
length of the word is the perimeter to the area, and this gives us a form
of the isoperimetric inequality. Formally, $f$ is a Dehn function if for all
words $w \in F(S)$ such that $[[w]] = e$, we have $A(w) \leq f(|w|)$. depending
on the growth of $f$, we say that $G$ has linear, quadratic, exponential etc.
Dehn function.

##### Geometric content of Area

We define a map to be aninite, planar, oriented, connected and simply connected
simplicial2-complex (!).  A map $D$ is a diagram over an alphabet $S$ iff every
edge $e \in D$ has a label $lbl(e) \in S$ such that $lbl(e^{-1}) = (lbl(e))^{-1}$.
Hang on: what does it mean to invert an edge?  I presume it
means to go backwards along an edge. So we assume the graph is directed, and we
have edges in both directions.

A Van Kampen diagram over a group $G = \langle S | R \rangle$  is a diagram $D$
over $S$ such that for all faces of $D$, the label of the boundary of $f$
is labelled by some $r^{\pm} : r \in R$. The area of such a diagram
is the number of faces.


### Hyperbolic iff Linear Isopermetric Inequality is satisfied
A finitely presented group is hyperbolic if and of if its cayley grah
satisfies the linear isoperimetric inequality.

### Deciding if elements are conjugate to each other

- If we can answer the question of whether two elements are conjugate to each
  other (does there exist a $g$ such that $ghg' =?= k$), we can solve
  that an element is equal to the identity:
-   Pick $k = e$. Then if we have $ghg' = k = e$, then $gh = g$ hence $h = e$.

- If we can check that an element is equal to the identity, we can check for
  equality of elements. two elements $k, l$ are equal iff $kl' = e$.

- So solving conjugacy automatically allows us to check of equality.


### Proof that conjugacy is solvable for hyperbolic groups

Consider a solution to the problem of finding an $x$ such that $xgx^{-1} = h$.
We claim that due to the hyperbolicity of the space, such an $x$ cannot be
"too long".

### Key intuition for hyperbolicity allows us to control word length

- Suppose we are interested to find a $g$ such that $ghg^{-1} = e$
- We can think of this as a case where $h$ is the base edge of a triangle, $e$ is the opposite vertex,
  and $g, g^{-1}$ are the other two sides:

```
    e
   / \
  g  g^{-1}
 /     \
+---h---+
```

- If the space is euclidea, then $g$ and $g^{-1}$ can be as long as they want to be while $h$ stays the same.
  The angles $gh, hg^{-1}$ will become larger, and the angle $gg^{-1}$ will become smaller as the length $g$
  increases.
- In a hyperbolic space, because the angle sum is less than 180, if we move $e$ too far away, the $h$ will "bend" to
  maintain the angle sum to be less than 180. But this means that we have distorted the $h$!
  There is a bound to how long we can make $g$ before we start distorting $h$. This bound on $g$ is exponential
  in the length of $h$.
- Alternatively, in a CAT-0 space, the base of the triangle cannot be too far
  away from the centroid. So we can't have $e$ be moved too far away, because if $g$
  gets too large.





### References
- [Notes On Hyperbolic and Automatic Groups: Michael Batty](https://www.math.ucdavis.edu/~kapovich/280-2009/hyplectures_papasoglu.pdf)
- [The geometry of the word problem by Martin R Bridson](https://people.maths.ox.ac.uk/bridson/papers/bfs/bfs.pdf)
- [My math.stackexchange question asking about why delta thin triangles help to solve conjugacy](https://math.stackexchange.com/questions/3789681/delta-thin-trianges-implies-solvable-conjugacy-problem-for-hyperbolic-groups)

# Elementary uses of Sheaves in complex analysis

I always wanted to see sheaves in the wild in a setting that was both
elementary but 'correct': In that, it's not some perverse example
created to show sheaves (DaTaBaSeS arE ShEAvEs). Ahlfors has a great example
of this which I'm condensing here for future reference.

### Sheafs: Trial 1

- We have function elements $(f:  \Omega \rightarrow \mathbb C, \Omega \subseteq \mathbb C)$.
  $f$ is complex analytic, $\Omega$ is an open subset of $\mathbb C$.
- Two function elements $(f_1, \Omega_1), (f_2, \Omega_2)$ are said to be analytic
  continuations of each other iff $\Omega_1 \cap \Omega_2 \neq \emptyset$, and
  $f_1 = f_2$ on the set $\Omega_1 \cap \Omega_2)$.
- $(f_2, \Omega_2)$ can be called as the continuation of $(f_1, \Omega_1)$ to
  region $\Omega_2$.
- We will have that the analytic continuation of $f_1$ to $\Omega_2$ is unique.
  If there exists a function element $(g_2, \Omega_2)$, $(h_2, \Omega_2)$ such that
  $g_2 = f_1 = h_2$ in the region $\Omega_1 \cap \Omega_2$, then by analyticity,
  this agreement will extend to all of $\Omega_2$.
- Analytic continuation is therefore an equivalence relation (prove this!)
- A chain of analytic continuations is a sequence of $(f_i, \Omega_i)$ such that
  the adjacent elements of this sequence are analytic continuations of each other.
  $(f_i, \Omega_i)$ analytically continues $(f_{i+1}, \Omega_{i+1})$.
- Every equivalence class of this equivalence relation is called as a global
  analytic function. Put differently, it's a family of function elements
  $(f, U)$ and $(g, V)$ such that we can start from $(f, U)$ and build
  analytic continuations to get to $(g, V)$.

### Sheafs: Trial 2

- We can take a different view, with $(f, z \in \mathbb C)$ such that $f$
  is analytic at some open set $\Omega$ which contains $z$. So we should
  picture an $f$ sitting analytically on some open set $\Omega$ which contains $z$.
- Two pairs $(f, z)$, $(f', z')$ are considered equivalent if $z = z'$ and
  $f = f'$ is some neighbourhood of $z (= z')$.
- This is clearly an equivalence relation. The equivalence classes are called as _germs_.
- Each germ $(f, z)$ has a unique projection $z$. We denote a germ of $f$ with projection $z$
  as $f_z$.
- A function element $(f, \Omega)$ gives rise to germs $(f, z)$ for each $z \in \Omega$.
- Conversely, every germ $(f, z)$ is determined by some function element $(f, \Omega)$
  since we needed $f$ to be analytic around some open neighbourhood of $z$: Call
  this neighbourhood $\Omega$.
- Let $D \subseteq \mathbb C$ be an open set. The set of all germs $\{ f_z : z \in D \}$
  is called as a _sheaf_ over $D$. If we are considering analytic $f$ then
  this will be known as the _sheaf of germs of analytic functions over $D$_. This
  sheaf will be denoted as $Sh(D)$.
- There is a projection $\pi: Sh(D) \rightarrow D; (f, z) \mapsto z$. For a fixed $z0 \in D$,
  the inverse-image $\pi^{-1}(z0)$ is called as the _stalk over $z0$_. It is
  denoted by $Sh(z)$.
- $Sh$ carries both topological and algebraic structure. We can give _the sheaf_
  a topology to talk about about continuous mappings in and out of $Sh$.
  It also carries a pointwise algebraic structure at each stalk: we can
  add and subtract functions at each stalk; This makes it an abelain group.

#### Sheaf: Trial 3

A sheaf  over $D$ is a topological space $Sh$ and a mapping $\pi: Sh \rightarrow D$
with the properties:
- $\pi$ is a local homeomorphism. Each $s \in S$ has an open neighbourhood $D$
  such that $\pi(D)$ is open, and the restriction of $\pi$ to $D$ is a homeomorphism.
- For each point $z \in D$, the stalk $\pi^{-1}(z) \equiv S_z$ has the structre of an abelian
  group.
- The group operations are continuous with respect to the topology of $Sh$.

We will pick $D$ to be an open set in the complex plane; Really, $D$ can
be arbitrary.

### Germs of analytic functions satisfy (Sheaf: Trial 3)

<img src="./static/sheaf.png">

# Snake lemma

## Why homomorphisms for chain maps?

First of all, to define a mapping between simplicial complexes $\{ G_i \}$
and $\{ H_i \}$, one might naively assume that we can ask for _functions_
$\{ f_i: G_i \rightarrow H_i \}$:

```
       ∂    ∂
    G3 → G2 → G1 → 0
    |    |    |
    f    g    h
    ↓    ↓    ↓
0 → H3 → H2 → H1
      ∂    ∂
```


Unfortunately, to be able to use the
machinery of Homology, we need the $\{ f_i \}$ to be abelian group homomorphisms.
However, this is no great loss. Intuitively, when we want to map complexes,
we first say where the _generators_ of the abelian group ($\mathbb Z$-module)
maps to; Everything else is determined by the generators. This aligns
nicely with our intuition of what a map between complexes should look like:
we tell where the geometry goes ("this edge goes there"), and the algebra
is "dragged along for the ride". This gives us the diagram:

```
    G3--∂-→G2--∂-→G1
    |      |      |
    f3     f2     f1
    ↓      ↓      ↓
0 →H3--∂-→H2--∂-→H1
```

where the `fi` are _homomorphisms_. So, this means we can talk about kernels and
images!

```
    Ker(f3)----→Ker(f2)--→Ker(f1)
       |         |          |
       ↓         ↓          ↓
       G3--∂----→G2----∂---→G1--→ 0
       |         |          |
       f3        f2         f1
       ↓         ↓          ↓
    Im(f3)--∂--→Im(f2)--∂-→Im(f1)
```

```
F → E → V → {0}
{0} → {e} → {v} → {0}
```

The _Snake Lemma_ gives us a mapping $d: Ker(f1) \rightarrow Im(f3)$ such that
this long exact sequence is saatisfied:


## What do we wish to compute?

- Now that we've agreed that this family of maps $\{ f_i : G_i \rightarrow H_i \}$
  ought to be structured maps, the next question is "OK, now what? What does
  one want to determine"? Ideally, we would get a _new_ chain complex which
  I tacitly denote as $\{ f(G_i) \}$, consisting of the image of $G_i$ inside
  $H_i$ and the ability to determine its structure.

- However, this is the boring bit. We don't _really_ care about the _chain complex_ $\{ f(G_i) \}$ per se.
  What we _actually_ care about are the homology groups! So we would really like a tool
  that allows us to compute $H_i(f(G))$ in some convenient fashion.


# Kernel, cokernel, image

Consider a linear map $T: X \rightarrow Y$. we want to solve for $\{ x : T(x) = y0 \}$.
- If we have an $x0$ such that $T(x0) = y0$, then see that $T(x0 + Ker(T)) = T(x0) + T(Ker(T)) = y0 + 0 = y0$.
  So the kernel gives us our degrees of freedom: how much can we change around without
  changing the solution.
- Now consider the cokernel: $Coker(T) = Y / Im(T)$. If we want to find
  a solution $\{ x : T(x) = y0 \}$. If we have $y0 \neq 0 \in Coker(T)$, then
  the solution set is empty. The cokernel tells us the _obstruction_ to a
  solution.

# The commutator subgroup

Define the commutator of $g, h$ as $[g, h] \equiv ghg^{-1}h^{-1}$.
The subgroup **generated** by all commutators
in a group is called as the commutator subgroup. Sometimes denoted as
$[G, G]$.

- We need to consider generation. Consider the free group on 4 letters
  $G = \langle a, b, c, d \rangle$. Now $[a, b] \cdot [c, d]$ has no
  expression in terms of $[\alpha, \beta]$.

- In general, the elements of the commutator subgroup will be products
  of commutators.

- It measures the degree of non-abelian-ness of the group. $G/[G, G]$ is
  the largest quotient of $G$ that is abelian. Alternatively, $[G, G]$
  is the smallest normal subgroup we need to quotient by to get an abelian
  quotient. This quotienting is called abelianization.


# Simplicity of A5 using PSL(2, 5)

#### Presentation of A5

We take as faith A5 has the presentation:

```
<a, b | a^2 = b^3 = (ab)^5 = 1>
```

If I find a nice proof of this isomorphism, or some other way to derive
the fact that `PSL(2, 5)` is isomorphic to `A5`, I will fill this up.

#### Step 1: `PSL(2, 5)` is isomorphic to `A5`

PSL(2, 5) consists of projective Mobius transformations with function composition
as the group operation. Here, we freely use the linear algebraic relationship
between transformations of the form `(az + b)/(cz + d)` and matrices `[a b; c z]`.


$$
\begin{aligned}
&a, b, c, d \in \mathbb Z5, ad - bc = 1 \\
&f: \mathbb Z5 \cup \{ \infty \} \rightarrow \mathbb Z5 \cup \{ \infty \} \\
&f(z) \equiv (az + b)/(cz + d) \\
\end{aligned}
$$

- We allow coefficients for the Mobius transform to be from $\mathbb Z5$,
  and we allow the domain and codomain of the function to be projectivized: so we
  add a point at infinity to $\mathbb Z5$.

- We construct a map from $PSL(2, 5)$ to $A5$ and then show that this map is
  an isomorphism. We exploit the presentation of $A5$ to find elements
  $a, b \in PSL(2, 5)$ such that $p^2 = q^3 = (pq)^5 = I$. We can link this
  to the presentation of A5 which requires precisely those relations.

- For an element of order 3, we pick `q(z) = 1/(1-z)`.

$$
\begin{aligned}
&q(z) = 1/(1-z) \\
&q(q(z)) = \frac{1}{1 - \frac{1}{1-z}}  \\
&         = \frac{1}{\frac{(1-z) - 1}{1-z}} \\
&         = \frac{(1-z)}{-z} = \frac{(z-1)}{z}  \\
&         = 1 - \frac{1}{z} \\
&q(q(q(z))) = 1 - \frac{1}{q(z)} = 1 - (1 - z) = z
\end{aligned}
$$

- I don't know of a principled way to arrive at this choice of `q(z)`, except
  by noticing that `az + b` does not work, and neither does `1/z`. The next
  simplest choice is things of the form `1/(1-z)`. If there is a nicer way,
  I'd love to know.

- For a function of order $5$, we have to use the structure of the finite field
  somehow. We can consider the function `r(z) = 1 + z`. On repeating this 5
  times, we wil get `5 + z = z`. However, it is hard to connect `r(z) = 1 + z`
  to the  previous choice of `q(z) = 1/(1-z)`.

- We use the same idea for `r(z)`, and pick `r(z) = z - 1`. This will allow
  us to accumulate `-1`s till we hit a `-5 = 0`.

- To get `r(z) = (z - 1)`, we need to compose `q(z) = 1/(1-z)` with `p(z) = -1/z`.
  This `p(z)` is of order 2.

To recap, we have achieved a set of functions:

```
p(z) = -1/z [order 2]
q(z) = 1/(1-z) [order 3]
r(z) = (z - 1) [order 5]
r = -1/[1/(1-z)] = p . q
```


That is, we have found a way elements in `PSL(2, 5)` such that `p^2 = q^3 = (pq)^5 = 1`.
This gives us the [surjective] map from `PSL(2, 5)` into `A5`.


- By a cardinality argument, we know that the size of `PSL(2, 5)` is 60. Hence,
  since `PSL(2, 5)` and `A5` have the same number of elements, this map
  must be a bijection.

#### Step 2: PSL(2, 5) is simple

TODO! I'm still reading Keith Conrad's notes.

#### References

- [Keith Conrad, Simplicity of PSL](https://kconrad.math.uconn.edu/blurbs/grouptheory/PSLnsimple.pdf)
- [Math.se: isomorphism from PSL to A5](https://math.stackexchange.com/questions/2051241/showing-psl2-5-is-isomorphic-to-a-5)


# A5 is not solvable

There are many accounts of why A5 is not solvable on the internet. I'm recording my
version here, because the proof involves certain ad-hoc choices which I want
to make sure I can find off-hand in the future.
We'll show that `[A5, A5] = A5`, thereby proving that `A5` not solvable.
This is useful for Galois theory, where we want to show tha `A5` cannot be
built as extensions of smaller cyclic groups.

### Notation

I'll be using non-standard notation: `(12);(34)` means 'perform `(12)` then perform `(34)`'.
I find this notation makes permutation composition intuitive for me. The `;`
is evocative of C-style languages, where we are ending a statement. I will
be consistently using $[g, h] \equiv ghg^{-1}h^{-1}$ to denote the commutator.

### permutations in A5

First, recall that `A5` only has the _even_ permutations in `S5`. So it can
have zero, two, four, involutions that build it up. There can't be more after
simplification, since `S5` ony has `5` elements --- the largest sequence
of transpositions we can do is `(12)(23)(34)(45)`. So, in `A5`, we have:

- The identity permutation `()`.
- The transpositions `(ij)(kl)` where `{i, j}` and `{k, l}` do not overlap.
  From these, we get the 2-cycles.
- The transpositions `(ij)(kl)` where `{i, j}` and `{k, l}` overlap. Here we
  cannot have `{i, j} = {k, l}` since then we will just have a single transposition.
  So, let us assume that we have `j = k`. If we have any other equality, we
  can always flip the transpositions around to get to the normal form `j = k`:

```
(23);(12)
= (32);(12) [(23) = (32)]
= (32);(21) [(12) = (21)]
```

- In this case, we can show that such a transposition _must_ be a cycle:

```
[a b c] -(32)->
[a c b] -(21)->
[c a b]
```

- Intuitively, we are pushing the element `c` backward, and allowing the
  other elements to take its place using the permutation `(23);(12)`.

- So, from the transpositions of the form `(ij)(kl)` where `{i, j}` and
  `{k, l}` intersect, we get the 3-cycles.

- Finally, we can have the transpositions of the form `(12)(23)(34)(45)`.
  It must be of this form, or some permutation of this form. Otherwise,
  we would have repeated elements, since these transpositions are packed
  "as close as possible". These generate the 5-cycles.

### A5 is generated by 3-cycles.

We claim that we can write any element of $A5$ in terms of 3-cycles.

- The disjoint transpositions of the type `(34)(12)` can be written as
  `(34)(23)(23)(12)`, because `(23)(23) = e`. This can be further
  broken down into `((34)(23)) ((23)(12))` which is two 2-cycles:
  `(234); (123)`.

- The non-disjoint transpositions of the type `(32)(21)` _are_ 3-cycles:
  `(32)(21) = (123)`.

- 3-cycles are 3-cycles.

- Any 5-cycle an be written as two 3-cycles: `(45)(34)(23)(12)` can be written
  as `((45)(34))((23)(12))` which is two 3-cycles: `(345); (123)`.

So, if we figure out how to write 3-cycles in terms of commutators, we win.
Because the commutator subgroup of $A_n$ is generated by elements that
can be written as $[g, h]$. If we can show that 3-cycles can be written
as $[g, h]$, then every other element has a representation in terms of
these 3-cycles, and are therefore elements of the commutator subgroup.


### 3-cycles can be generated as commutators of 2-cycles:

- We saw how we can write a 3-cycle of the form `C = (123)` as `(32)(21)`.
  We wish to write this as the commutator of two elements `g, h`: $C = [g, h]$.

- The idea is that we have the leftover elements `4, 5` that are unsused by `C` in `A5`
  [here is where `5` is important: `3 + 2 = 5`, and we need two leftover elements].

- We can use these two leftover elements `4, 5` to build elements `g, h`
  which cancel off, leaving us with `(32)(21)`. We start with `g = (32)___`,
  `h = (21)___` where the `___` is to be determined:


```
(32)___||(21)___||___(32)||___(21)
  g        h        g^-1    h^-1
```

- It is important that `g` and `h` contain another tuple, because they are
  members of `A5`! We need them to be permutations having `2, 4, 6` transpositions.
- We insert `(4 5)` everywhere. These `(4 5)` can slide over the `(2 1)` and thereby
  harmlessly cancel:


```
(32)(45)||(21)(45)||(45)(32)||(45)(21)
  g        h           g^-1       h^-1
```

- Simplify the above expression by moving the `(45)` over `(21), (32)`:

```
(32)||(21)(45)(45)||(32)||(45)(45)(21)
  g      h          g^-1    h^-1
```

- cancel the `(45)(45) = e`:

```
(32)||(21)||(32)||(21)
  g   h    g^-1   h^-1
```


So we are left with `(32);(21);(32);(21)`. This is the _square_ of what
we really wanted, `C = (32);(21)`. However, since `C` is a 3-cycle, we know
that $C = C^{-2}$. So, we can start with $C^{-1}$, use our trick to generate
$C^{-2}$ which is equal to $C$. Since this works for any $C$, we have shown
that we can generate 3-cycles from commutators of `A5`.

### Alternate viewpoint on above proof

We have a 3-cycle `s = (a b c)`. We first first a square root `t` such
that `t*t=s`. To do this, we make `t` have the cycles of `s` spread out
in gaps of 2:

```
t = (a _ _)
t = (a _ b) [+2]
t = (a c b) [+2, modulo]
```

It is hopefully clear that `t*t = s`:

```
t = (a c b)
t*t: apply the cycle twice.
t*t = a -(skip c) -> b
      b -(skip a) -> c
      c ->(skip b) -> a
    = (a b c) = s
```

Now, we will write `s = t*t` and then find the commutator decomposition from
it:

```
s = t*t
  = (abc)(abc)
  = (cb)(ba)(cb)(ba)
  = (cb)|(ba)|(cb)|(ba)
  = (cb)|(ba)|(cb)|(ba)
     g     h   g-1   h-1
```

But there's a problem: this `g` and `h` do not belong to `A5`, they belong
to `S5`. This is fixed by using a random `(pq)` which we know _will exist_.

### Recap: How have we shown that A5 is not solvable?

what have we shown?

- 3-cycles can be written as $[g, h]$ for $g, h \in A_5$. Alternatively,
  we can say that 3-cycles belong to the commutator subgroup of $A_5$,
  since they can be written as commutators.
- any element in $A5$ can be written as the composition of 3-cycles.
- Hence, any element in $A5$ can be written as the composition of commutators.


In my mind, I think of it as:

```
arbitrary g
= (3-cycle-1)(3-cycle-2)....(3-cycle-n)
= [g, h][g2, h2]....[gn, hn]
= member of [A5, A5]
```

Recall that $[A5, A5]$ is **generated** by commutators. It not only contains
elements of the form $[g, h]$, but also all products of the form $[g, h][g', h']$.
So we don't need to exhibit how to write a 5-cycle as some $[g, h]$. We just
need to exhibit how to write as the product of commutators, which we have
now shown.


### Solvable implies simple

We can consider the other definition of simple. Let there be a
chain of normal subgroups $G = N[0] \leq N[1] \leq N[1] \leq \dots \leq N[m] = e$,
such that each quotient $N[i] / N[i+1]$ is abelian. Then, if $G$ is
simple, this chain can only be $G = N[0] \leq N[1] = e$.

- If we want the quotient $G/N$ to be abelian, then we need the commutator
  subgroup $[G, G]$ to be a a subset of $N$.

- In our case, $[A_5, A_5] = A_5$. So if we want to remove the non-abelian-ness
  of A5, we need to quotient by the _whole_ of $A5$.

- This means that any such chain will immediately collapse to $e$.

- So, it's impossible to build $A5$ using 'cycling components' starting from $\{e\}$.
  Viewed from the field theoretic perspective, this means that it's impossible
  to reach a polynomial whose splitting field has galois group A5 by simply
  appending cycles.

### Nagging doubt: Did we depend on our numbering of cycles?

In all my proofs, I had used _one_ 3-cycle, or 5-cycle, or 2-cycle to
argue that it all works out. Is this really legal? Perhaps the argument
written for the 3-cycle `C = (123)` will break down for `D = (321)`. Fear not!

- We will show that all 3-cycles are conjugate to each other. So, we can always
  relabel a 3-cycle within A5.
- It is easy to note that $g[k, l]g^{-1} = [gkg^{-1}, glg^{-1}]$. This shows
  that the commutator subgroup is closed under conjugation. It better be,
  because it ought to be normal for us to take quotients from it.
- Combining these facts, if we show that `(123)` is in `[A5, A5]`, then some
  other cycle `(ijk)` can be conjugated to `(123)`. Since the commutator
  subgroup is closed under conjugation, we have that `(ijk)` is a member
  of `[A5, A5]`.


### All 3-cycles are conjugate to each other in A5.

- Given two 3-cycles `C=(abc)` and `D=(pqr)`, at least one of `a, b, c` must
  be equal to one of `p, q, r`. Since each `a, b, c` is unique, and each
  `p, q, r` is unique, for them to not overlap, we would need 6 elements.
  But we only have 5, so there must be some overlap:

```
a   b   c
1 2 3 4 5
  p   q r
```

So, we will perform our proof assuming there is 1 overlap, 2 overlap, 3 overlap.
Recall that if `C = (a b c)` is a cycle and `s` is a permutation, then the action
of conjugating `C` with `s` produces a permutation `(s(a) s(b) s(c))`. We will
prove our results by finding an `s`, and then **making `s` even**. This is
the difficult part of the proof, since we need to show that all 3-cycles are
conjugate _in A5_. We will write `s` as two distinct transpositions, which will
guarantee that it belongs to `A5`.


- Case 1: `(abx)` and `(pqx)` have a single element `x` in common:

```
C = (abx)
D = (pqx)

s: send a to p, b to q
s = (ap)(bq)
C = (abx) -conj s-> (pqx) = D
```

- Case 2: `(axy)` and `(pxy)` have two elements in common, `x` and `y`. Naively,
  we would pick `s: send x to y`. But this is odd, so this isn't a member of
  `A5`. To make it even, we rearrange `D = (pxy)` as `D = (yxp)`. This lets us
  go from `C` to `D` by relabelling `a` to `y`, `y` to `p`. This permutation
  is even since it has two distinct transpositions.

```
C = (axy)
D = (pxy) = (yxp) [cyclic property]

s: send a to y, y to p
s = (ay)(yp)

C = (axy) -conj s-> (yxp) = D
```

- Case 3: `(xyz)` and `(xyz)` have all three elements in common, `x`, `y`, `z`.
  Here we can conjugate by identity and we are done.

### Why do we care about solvable?

- Roughly, we can look at the solvability criterion as giving us a way to build
  our group $G$ from a series of extensions $N[1], N[2], \dots$. This extension
  is special, because at each step, we are adding a cyclic group.

- When we want to write a solution using nth roots, we can only add the
  nth roots of unity, a "cyclic" component. So, any element we can reach
  by using nth roots ought to be able to be written down as an extension of
  cyclic elements.

### SAGE code to play around with commutators of `A5`:

- Create a dictionary `m` which maps each element of `A5` to the commutators
  that create it.

```py
from collections import defaultdict
m = defaultdict(set)
A5 = AlternatingGroup(5)
S5 = SymmetricGroup(5) # if necessary
for g in A5:
    for h in A5:
        m[g * h * g^(-1) * h^(-1)] |= { (g, h) }

# all 60 elem can be written in terms of commutators
print("number of elem generated as commutator: " + str(len(m.keys())))

# Show how to access elements of A5 and their commutator representation
cyc5 = A5("(1, 2, 3, 4, 5)")
cyc3 = A5("(1, 2, 3)")
cyc2disj = A5("(1, 2) (3, 4)")

print(m[cyc5])
print(m[cyc3])
print(m[cyc2disj])
```

### Writing each element in `A5` directly as a commutator

We have shown how to write 3-cycles as the commutator of 2-cycles. We will now
show how to do this for disjoint 2-cycles and 5-cycles as a matter of
enlightenment.

### Writing disjoint 2-cycles as commutator


First, we will write a two disjoint two cycles as the square root of
a 4-cycle. We will then show how to write this 4-cycle as two
3-cycles.

```
s = (12)(34)
```

Note that if we choose `t = (abcd)`, then `t*t` will exchange the first
and third elements `a <-> c`, and the second and fourth elements `b <-> d`.
So, if we choose:

```
t = (1324)
t*t = (12) (34)
```

Next, we need to write this `t*t` as `[g, h]` for `g, h` from `A5`.

```
t*t = (1324)(1324)
    = (42)(23)(31);(42)(23)(31)
    = (42)(23)(31);(42)(23)(31)
    = (42)(23)(31);(23)(23);(42)(23)(31)
                   ^^^^^^^^ inserted
    = (42)(23)|(31)(23)|(23)(42)|(23)(31)
          g   |    h   |   g'   |   h'

    = [(42)(23), (31)(23)]
```

Where both `(42)(23)`, and `(31)(23)` are members of `A5`.

### Writing 3-cycle as commutator

In the description of showing how to generate 3-cycles, we do this
explicitly.


### Writing 5-cycle as commutator


Let `s = (1 2 3 4 5)`. we once again find a square root of `s`. To build
this, we will build an element with the elements of `s` written with
gaps of `2`:

```
t = (1 _ _ _ _)
  = (1 _ 2 _ _)  [+2 index]
  = (1 _ 2 _ 3)  [+2 index, wrap]
  = (1 4 2 _ 3)  [+2 index, wrap]
  = (1 4 2 5 3)  [+2 index, wrap]
```

It should be clear how `t*t = s`: When we take `s = t*t`, the resulting permutation `s`
will move an element `j = t[i]` to `k = t[i+2]`. But we have built `t` such
that `t[i+2] = s[i+1]`. So we will move the element according to how `s` pleases:

```
t = (1 4 2 5 3)
t*t = 1 -> (4 skip) -> 2
      2 -> (5 skip) -> 3
      3 -> (1 skip) -> 4
      3 -> (2 skip) -> 5
      5 -> (3 skip) -> 1
t*t = (1 2 3 4 5) = s
```

We will now use `t*t` to write the commutator:

```
s = t*t
  = (35)(52)(24)(41);(35)(52)(24)(41)
  =
  =
  =
  = (1, 2)(3, 5)|(1, 5)(2, 4)|(3, 5)(1, 2)|(2, 4)(1, 5)

  = (1, 2)(3, 5)|(1, 5)(2, 4)|(3, 5)(1, 2)|(2, 4)(1, 5)
         g             h          g^{-1}       h^{-1}
```


### To think: relationship between square roots and commutators?


# Complex orthogonality in terms of projective geometry

If we think of complex vectors $p = [p_1, p_2]$, $q = [q_1, q_2]$ as belonging to
_projective space_: that is, $p \simeq p_1/p_2$, and $q \simeq q_1 / q_2$, we can
interpret orthogonality as:

$$
\begin{aligned}
p . q = 0 \\
p_1 \overline q_1 + p_2 \overline q_2 = 0 \\
p_1 / p_2 = - \overline{q_2} / \overline{q_1} \\
p = -1/\overline{q} = -q/|q| \\
\end{aligned}
$$


<img src="./static/riemann-sphere-conjugate.png">
If we imagine these as points on the Riemann sphere, TODO

#### References

- Visual Complex analysis by Tristan Needham

# Arithmetic sequences, number of integers in a closed interval

This is a cute reason for why when we count the number of integers in
the closed interval `[a, b]`, it's going to be `b - a + 1`. We setup
an arithmetic sequence with initial term `a`, common difference `1`. Now
we know that the `n`th term is `a + (n-1)d`. So, we get

```
a + (n-1)d = b
(n-1).1 = b - a
n = b - a + 1
```

#  [The arg function, continuity, orientation](#the-arg-function-continuity-orientation)

Let us think of the function $arg: \mathbb C \rightarrow \mathbb R$ as a multi
valued function, which maps each complex number to the set of possible
valid angles that generate it:

$$
arg(z) \equiv \{ t \in \mathbb R : |z|e^{i (\pi/2)t} = z  \}
$$

We plot the function here:

<img src="./static/arg-multi-value-circle.png">
<img src="./static/arg-multi-value-plot.png">


- Note that for every value $z \in C$, we get a _set_ of values associated
  to it.


#### Recovering single valued-ness

Now, the question is, can we somehow automatically recover single
valued-ness? kind of, by stipulating that for any given curve $c: [0, 1] \rightarrow \mathbb C$,
the function $arg \circ c: [0, 1] \rightarrow \mathbb R$ is _continuous_.

Let's try to investigate what happens if we move from `right` towards `bot`,
arbitrarily stipulating ("picking a branch") that `arg(right) = 0` as a sort
of basepoint.

<img src="./static/arg-multi-value-branch-lower.png">

- Note that we were _forced_ to pick the value `arg(bot) = -1` from our
  considerations of continuity. No other value extends continuous from the
  right to the bottom.
- Also note that we got a *smaller* value: we move from `0 -> -1`: we decrease
  our value as we move clockwise.

This prompts the natural question:

> what happens if we move in the opposite direction?

#### Counter-clockwise movement

- Let's move counter-clockwise from `right`, arbitrarily picking the branch
  `arg(right) = 0` as before. This gives us:


<img src="./static/arg-multi-value-branch-upper.png">


- Note that once again, we were _forced_ to pick `arg(top) = 1` by continuity
  considerations.

- Also note that this time, we got a *larger* value: we move from `0 -> 1`: we
  increase our value as we move counter-clockwise


#### Multiple winding

the true power of this multi-valued approach comes from being able to handle
_multiple_ windings. Here the real meaning of being a multi-valued function shows
through. If we decide to go through the the loop _twice_, as:

```
bot -> right -> top -> left -> bot -> right -> top -> left
-1  -> 0     -> 1   -> 2    -> 3   -> 4     -> 5   -> 6
```

That is, we end up with the value `6`, which can only b



#### Orientation from continuity

There's something really elegant about being able to recover a notion of
"orientation" by simply:

1. Allowing multi-valued functions.
2. Forcing continuity constraints.
3. Interpreting increase/decrease in the value of the function.


#### Discretizing, gaining more insight

I was personally dis-satisfied with the above explanation, because it seemed
weird that we would need to depend on the history to define this function. We
can formalize this notion of history. Let's first discretize the situation,
giving us:

<img src="./static/discrete-multi-valued.png"/>

- We are on the space of the spokes, given by `a, b, c, d, e, f, g, h`.
- We have a function `f: Spoke -> Val` whose values are given on the spokes.
- We are interested in the path `p: Time -> Spoke`, `p = [a, b, c, d, e, f, g, h, a]`.
- If we evaluate the function `f` on the path `p`, we get `out: Time -> Val`, `out = [0, 1, 2, 3, 4, 5, 6, 7, 0]`.
- We have a "jump" from `7` to `0` in `out` as we cross from `h` to `a`. This is a
  discontinuity in `out` at time `7`.
- We want to fix this, so we make the function `f` multi-valued.

<img src=./static/discrete-multi-valued-assign-multi-value.png>

- We assign both values `8` and `0` to the spoke `a`. We wish to define
  the evaluation of `f: Spoke -> 2^N` relative to path `p`. At time `t`, point
  `p[t]`, we pick any value in `f(p[t])` that makes `out[t]` continuous.

- So in this case, when we start, we have two choices for `out[0] = f(p[0]) = f(a)`: `0` and `8`.
  But we know that `out[1] = f(p[1]) = f(b) = 1`. Hence, for `out[0]` to be continuous, we must
  pick `out[0] = 0`.

- Similarly, at `out[8]` we have two choices: `0` and `8`. But we have that
  `out[7] = 7`, hence we pick `out[8] = 8`.

- Note that we say 'we pick the value' that makes `out` continuous.  This is
  not really rigorous. We can fix this by re-defining `f` in such a way
  that `f` is not `Spoke -> Val`, but rather it knows the full path:
  `f': (Time -> Spoke) -> Val`.

#### Making the theory path-dependent

We originally had:

```
path: Time -> Spoke
f: Spoke -> 2^Val -- multi-valued

-- | morally, not mathematically.
out: Time -> Val
out t = choose_best_value (f(path[t]))
```

But there was a vagueness in this `choose_best_value`. So we redefine it:

```
path: Time -> Spoke
f': (Time -> Spoke) -> Time -> Val
f'(path, tcur) =
  argmax (\v -> |v - path[tcur-1]| + |v - path[tcur+1|)
         f(path[tcur])

out: Time -> Val
out = f'(path)
```

- The function `f'` that defines the value of the path has full
  access to the path itself!
- At time `tcur`, it attempts to pick the value in `f(path[tcur])` which
  makes the discontinuity as small as possible. It picks a value `v` from the
  possible values of `f(path[tcur])`. This `v` minimises the
  of the distances from the previous time point (`|v - path[tcur-1]`),
  and the distance from the next time point (`|v - path[tcur + 1]`).
- This provides a rigorous definition of what it means to "pick a value in the branch".
  This can clearly be extended to the continuous domain.

# Odd partitions, unique partitions

A well known identity in combinatorics is that the partitions `n = l1 + l2 + ... + ln`
where each `li` is odd is in bijectiion with a partition where each `li` is unique.
I really liked this bijection.


```
(15, 9, 9, 5, 5, 5, 3, 3, 3, 1, 1, 1, 1) [all odd]
=
(15, 9x2, 5x3, 3x3, 1x4) [group]
=
(15x1, 9x2, 5x(2+1), 3x(2+1), 1x4) [expand base-2]
=
(15, 18, [10, 5], [6, 3], 4) [all unique]
```

# Continued fractions, mobius transformations

read [`ekmett/fractions`](https://github.com/ekmett/fractions) properly
and write detailed log about it, and the related math.


# Permutations-and-lyndon-factorization

For a string `s`, the Lyndon factorization writes `s` as the concatenation of
substrings `t1`, `t2`, ..., `tn`, such that:

- each `ti` is a simple word. That is, it is lexicographically smaller than all
  of its cyclic shifts.
- the words are in non-increasing order: `t1 >= t2 >= t3 ... >= tn`.

For example, given the word `banana`, the lyndon factorization is:

```
b; an; an; a;
```

We can define a notation for writing permutation as:
- Each term in a cycle is written in _ascending_ order.
- Cycles are written in _descending_ order of the first element.
- Single element are ignored.

```
(7) (2 3) (1 4 5)
```

If we treat it as a string `723145`,
the duval algorithm provides the decomposition:

```
7; 23; 145;
```

So, we can treat the duval algorithm as a way to recover the permutation given
the raw string. It's a nice way to _remember_ the definition of lyndon
decomposition if nothng else.

# Graphs are preorders

I wanted to record this fact for myself, so that I have reason to come back
to it as I learn more preorder theory. Perhaps there are certain graph theoretic
phenomena that make more sense when looked at from a preorder point of view.


# Parallelisable version of maximum sum subarray

I learnt of a "prefix sum/min" based formulation from
[the solution to question D, codeforces educational round 88](https://codeforces.com/blog/entry/78116).

The idea is to start with the max prefix sum $opt$ (for optima)
as the difference of right minus
left:

$$
\begin{aligned}
&opt \equiv \max_{(L, R)}: \sum_{L \leq i \leq R} a[i] \\
&= \max_R: \left(\sum_{0 \leq i \leq R} a[i] - \min_{L \leq R}: \sum_{0 \leq i \leq L \leq R} a[i] \right) \\
\end{aligned}
$$

Which is then  expressed as:
$$
\begin{aligned}
&asum[n] \equiv \sum_{0 \leq i \leq n} a[i]  \\
&opt = \max_R: (asum[R] - \min_{(L \leq R)}: asum[L])
\end{aligned}
$$

$$
\begin{aligned}
&aminsum[n] \equiv \min_{0\leq i \leq n} asum[i] \\
&opt = \max_R: (asum[R] - aminsum[R])
\end{aligned}
$$

Since $asum$ is a prefix-sum of $a$, and $amin$ is a prefix min of
$asum$, the whole thing is $O(n)$ serial, $O(\log n)$ parallel.
In haskell, this translates to:

```hs
let heights deltas = scanl (+) 0 deltas
let lowest_heights = scanl1 min . sums
let elevations xs = zipWith (-) (sums xs) (lowest_heights xs)
-- elevations [1, 2, 3, -2, -1, -4, 4, 6]
-- > [0,1,3,6,4,3,0,4,10]
let max_elevation deltas = max (elevation deltas)
best = max_elevations [1, 2, 3, -2, -1, -4, 4, 6]
```

`lowest_heights` keeps track of the sea level, while the
`elevations` computes the elevation from the lowest height.
The maximum sum subarray will correspond to treating the elements of the array
as deltas, where we are trying to find the highest elevation. since elevation
is an integral (sum) of the deltas in height.


<img src="./static/max-sum-subarray.png">

# Thoughts on implicit heaps

Some musings I had on the ability to represent heaps as arrays, and in general,
the benifits of knowing the total number of elements.

- Knowing the total number of elements allows us to pre-ordain a memory layout.
  We can decide that for a node at index `i`, left child is at `2*i`, and
  right child is at `2*i+1`. This gives parent at `i//2`.

- This immediately gives us `O(1)` access to parent (`i//2`) and sibling `(i^1)`
  with no extra memory usage.                                                                                                                             S

- This cannot be done for data structures where we need to splice into
  the middle: For example, an implicit treap where we wish to splice sub-arrays
  together.

- On coding a heap, we can decide whether to use the left or right sibling by
  using `next = 2*i + predicate`. If `predicate = false = 0`, we will pick
  the left child, otherwise the right child. This allows us to compress
  some annoying if/then/elses into one-liners.

# Discriminant and Resultant

I had always seen the definition of a discriminant of a polynomial $p(x)$ as:
$$
Disc(p(x)) \equiv a_n^{(2n - n)} \prod_{i< j} (r_i - r_j)^2
$$

While it is clear _why_ this tracks if a polynomial has repeated roots
or not, I could never motivate to myself or remember this definition.

I learnt that in fact, this comes from a more general object, the **resultant**
of two polynomials $P(x), Q(x)$, which provides a new polynomial $Res(P(x), Q(x)$
which is zero iff $P, Q$ share a common root. Then, the discriminant is
defined as the resultant of a polynomial and its derivative. This makes far more
sense:

- If a polynomial has a repeated root $r$, then its factorization will
  be of the form $p(x) = (x - r)^2 q(x)$. The derivative of the polynomial
  will have an $(x-r)$ term that can be factored out.

- On the contrary, if a polynomial only has a root of degree 1, then the
  factorization will be $p(x) = (x - r) q(x)$, where $q(x)$ is not divisible by $(x-r)$.
  Then, the derivative will be $p'(x) = 1 \cdot q(x) + (x - r) q'(x)$. We cannot take $(x - r)$ common
   from this, since $q(x)$ is not divisible by $(x-r)$.

This cleared up a lot of the mystery for me.

### How did I run into this? Elimination theory.

I was trying to learn how elimination theory works: Given a variety
$V = \{ (x, y) : Z(x, y) = 0 \}$, how does one find a rational parametrization
$(p(t), q(t))$ such that  $Z(p(t), q(t)) = 0$, and $p(t), q(t)$ are
rational functions? That is, how do we find a rational parametrization of the
locus of a polynomial $Z(x, y)$? The answer is: use resultants!

- We have two univariate polynomials $p(a; x), p(b; x)$, where the notation
  $p(a; x)$ means that we have a polynomial $p(a; x) \equiv \sum_i a[i] x^i$.
  The resultant isa polynomial $Res(a; b)$ which is equal to $0$ when
  $p(a; x)$ and $p(b; x)$ share a common root.

- We can use this to eliminate variables. We can treat a bivariate polynomial $p(x, y)$
  as a univariate polynomial $p'(y)$ over the ring $R[X]$. This way, given two
  bivariate polynomial $p(a; x, y)$, $q(b; x, y)$, we can compute their resultant,
  giving us conditions to detect for which values of $a, b, x$, there exists
  a common $y$ such that $p(a; x, y)$ and $(q, x, y)$ share a root. If $(a, b)$
  are constants, then we get a polynomial $Res(x)$ that tracks whether $p(a; x, y)$
  and $q(a; x, y)$ share a root.

- We can treat the implicit equation above as two equations, $x - p(t) = 0$,
  $y - q(t) = 0$. We can apply the method of resultants to project out $t$
  from the equations.

### 5 minute intro to elimination theory.

Recall that when we have a linear system $Ax = 0$, the system has a non-trivial
solution iff $|A| = 0$. Formally: $x \neq 0 \iff |A| = 0$. Also, the
ratio of solutions is given by:

$$x_i / x_j = (-1)^{i+j} |A_i|/|A_j|$$

If we have two polynomials $p(a; x) = a_0 + a_1 x + a_2 x^2$, and
$q(b; x) = b_0 + b_1x + b_2 x^2$, then the system $p(a; x)$, $q(b; x)$ has
a simeltaneous zero iff:

$$
\begin{aligned}
&\begin{bmatrix}
a_2 & a_1 & a_0 & 0 \\
0 & a_2 & a_1 & a_0 \\
b_2 & b_1 & b_0 & 0\\
0 & b_2 & b_1 & b_0\\
\end{bmatrix}
\begin{bmatrix}
1 \\ x \\ x^2 \\ x^3
\end{bmatrix}
= 0 \\
&A x = 0
\end{aligned}
$$

#### Big idea

The matrix is setup in such a way that any solution vector $v$ such that
$Qv = 0$ will be of the form $v = (\alpha^3, \alpha^2, \alpha, 1)$. That is,
the solution vector is a _polynomial_, such that $Qv = 0$. Since $Qv = 0$,
we have that $a_2 \alpha^2 + a_1 \alpha + a_0 = 0$, and $b_2 \alpha^2 + b_1 \alpha + b_0 = 0$.

#### Proof

- **Necessity** is clear. If we have some non trivial vector $v \neq 0$ such that
  $Qv = 0$, then we need $|Q| = 0$.

- **Sufficiency**: Since $|Q| = 0$, there is some vector $v = (w, x, y, z)$
  such that $Qv = 0$.
  We need to show that this $v$ is non-trivial. If the polynomials $p(a;x)$,
  $q(b;x)$ are not equal, then we have that the rows which have coefficients
  from $p$ and $q$ are linearly independent. So, the pair of rows $(1, 3)$,
  and the pair $(2, 4)$ are linearly independent. This means that
  the linear system:

$$
a_2 w + a_1 x + a_0 y = 0 \\
b_2 w + a_1 x + a_0 y = 0 \\
$$

Similarly:

$$
a_2 x + a_1 y + a_0 z = 0 \\
b_2 x + a_1 y + a_0 z = 0 \\
$$

Since the coefficients of the two systems are the same, we must have that
$(w, x, y)$ and $(x, y, z)$ are linearly dependent. That is:

$$
(w, x, y) = \alpha (x, y, z) \\
w = \alpha x = \alpha^2 y = \alpha^3 z \\
$$

We can take $z = 1$ arbitrarily, giving us a vector of the form
$(w, x, y, z) = (\alpha^3, \alpha^2, \alpha, 1)$, which is the structure
of the solution we are looking for!



### References

- [CMU lectures on Math Fundamentals for Robotics](http://www.cs.cmu.edu/~me/811/notes/)



# Polynomial root finding using QR decomposition

1. For a polynomial $p(x)$, build the companion matrix $P(x)$.
2. Show that the characteristic polynomial $cp(P)$ of the companion matrix $P(x)$ is indeed $p(x)$.
3. Find eigenvalues of $P(x)$, which will be roots of $p(x)$, since the
   eigenvalues of a matrix $M$ are the roots of its characteristic polynomial $cp(M)$.
4. We use QR since it is numerically stable. The $Q$ matrix discovered by QR
   is orthogonal, and hence does not disturb the covariance of the noise
   on matrix multiplication.


# A hacker's guide to numerical analysis

> Life may toss us ill-conditioned problems, but it is too short
> to settle for unstable algorithms. - D.P. O'Leary

### Measures of error

If $x$ is a number and $\hat x$ is its approximation, then the are two notions of
error:
1. absolute errror: $|x - \hat x|$.
2. relative error: $|x - \hat x|/|x|$.

Since the relative error is invariant under scaling $(x \mapsto \alpha x)$, we
will mostly be interested in relative error.


### Significant digits

The significant digits in a number are the first nonzero digit and all
succeeding digits. Thus `1.7320` has five significant digits. `0.0491` has
only three significant digits.
**It is not transparent to me why this definition is sensible**.

### Correct Significant digits --- a first stab

We can naively define $\hat x$ agrees to $x$ upto $p$ significant digits
if $\hat x$ and $x$ round to the same number upto $p$ significant digits.
This definition is seriously problematic. Consider the numbers:

- $x = 0.9949$, $x_1 = 1.0$, $x_2 = 0.99$, $x_3 = 0.9950$
- $y = 0.9951$, $y_1 = 1.0$, $y_2 = 1.0$, $y_3 = 0.9950$

Here, $y$ has correct one and three significant digits relative to $x$,
but incorrect 2 significant digits, since the truncation at $x_2$ and $y_2$
do not agree even to the first significant digit.

### Correct Significant digits --- the correct definition

We say that $\hat x$ agress to $x$ upto $p$ significant digits if $|x - \hat x|$
is less than half a unit in the pth significant digit of $x$.

### Accuracy v/s precision

- Accuracy: absolute or relative error of a quantity.
- Precision: accuracy with which basic arithmetic `+, -, *, /` are performed.
  for floating point, measured by unit round-off (we have not met this yet).


**Accuracy is not limited by precision**: By using fixed precision arithmetic,
we can emulate arbitrary precision arithmetic. The problem is that often
this emulation is too expensive to be useful.

### Backward, Forward errors

Let $y = f(x)$, where $f: \mathbb R \rightarrow \mathbb R$. Let us compute $\hat y$ as an approximation to
$y$, in an arithmetic of precision $u$. How do we measure the quality of $\hat y$?

1. In many cases, we maybe happy with an $\hat y$ such that the relative error between
   $y$ and $\hat y$ is equal to $u$: we did the best we can with the precision
   that was given. This is the **forward error**.
2. An alternative question we can ask is, for what $\delta x$ do we have that
   $\hat y = f(x + \delta x)$. That is, how far away from the input do we
   need to stray, to get a matching output? There maybe many such $\delta x$,
   so we ask for $\min |\delta x|$. We can divide this error by $x$ as a
   normalization factor. This is the **backward error**.

<img src="./static/forward-backward-error.png">

There are two reasons we prefer backward error.

1. It converts error analysis into "data analysis". The data itself tends
   to be uncertain. If the error given by the backward analysis is smaller
   than the data uncertainty, then we can write off our error as being
   too small. Since for all we know, we have 'fixed' the uncertain data
   with our small error.
2. It reduces the question of error analysis into perturbation theory,
   which is very well understood for a large class of problems.

### Backward stable

A method for computing $y = f(x)$ is called **backward stable**
if it produces a $\hat y$ with small backward error. That is, we need a
small $\delta x$ such that $\hat y = f(x + \delta x)$.

### Mixed forward-backward error

We assume that addition and subtraction are backward stable, where $u$
is the number of significant digits to which our arithmetic operations
can be performed:

$$
x \pm y = x(1 + \Delta) \pm y(1 + \Delta) \forall |\Delta| \leq u
$$

Another type of error we can consider is that of the form:

$$
\hat y + \delta y = f(x + \Delta x)
$$

That is, for a small perturbation in the output $(\delta y)$, we can get a
backward error of $\delta x$. This is called as **mixed forward backward error**.

<img src="./static/mixed-forward-backward-error.png">

We can say that an algorithm with mixed-forward-backward-error is stable iff:

$$
\begin{aligned}
&\hat y + \delta y = f(x + \Delta x) \\
&|\Delta y|/|\hat y| < \epsilon \\
&|\Delta x|/|\hat x| < \eta \\
&\text{$\epsilon, \eta$ are small}
\end{aligned}
$$

This definition of stability is useful when rounding errors are the dominant
form of errors.

### Conditioning

Relationship between forward and backward error is govered by _conditioning_:
the sensitivity of solutions to perturbations of data. Let us have an approximate
solution $\hat y = f(x + \delta x)$. Then:

$$
\begin{aligned}
&\hat y - y = f(x + \delta x) - f(x) = f'(x) \delta x + O((\delta x)^2) \\
&(\hat y - y)/y = (x f'(x)/f(x)) (\Delta x/x) + O((\Delta x)^2) \\
&(\hat y - y)/y = c(x) (\Delta x/x) + O((\Delta x)^2)\\
&c(x) \equiv |x f'(x)/f(x)|
\end{aligned}
$$

The quantity $c(x)$ measures the scaling factor to go from the relative
change in output to the relative change in input. Note that this is a property
of the function $f$, not any particular algorithm.

##### Example: $\log x$

If $f(x) = \log x$, then $c(x) = |(x (\log x)') / \log x| = |1/\log x|$. This
quantity is very large for $x \simeq 1$. So, a small change in $x$ can
produce a drastic change in $\log x$ around $1$.

- Note the the _absolute_ change is quite small: $\log(x + \delta x) \simeq \log x + \delta x/x$.
  However, relative to $\log x$, this change of $\delta x/x$ is quite large.

##### Rule of thumb

We now gain access to the useful rule:

$$
\text{forward error} \lesssim \text{condition number} \times \text{backward error}
$$

- Glass half empty: Ill-conditioned problems can have large forward error.
- Glass half full: Well-conditioned problems do not amplify error in data.

### Forward stable

If a method produces answers with forward errors of similar magnitude to those
produced by a backward stable method, then it is called forward stable.
**Backward stability implies forward stability, but not vice-versa** (TODO: why?)

### Cancellation

Consider the following program:

```cpp
#include <cmath>
#include <stdio.h>

int main() {
    double x = 12e-9;
    double c = cos(x);
    double one_sub_c = 1 - c;
    double denom = x*x;
    double yhat = one_sub_c / denom;

    printf("x:         %20.16f\n"
           "cx:        %20.16f\n"
           "one_sub_c: %20.16f\n"
           "denom:     %20.16f\n"
           "yhat:      %20.16f\n",
            x, c, one_sub_c, denom, yhat);
}
```

which produces the output:

```
x:           0.0000000120000000
cx:          0.9999999999999999
one_sub_c:   0.0000000000000001
denom:       0.0000000000000001
yhat:        0.7709882115452477
```

This is __clearly wrong__, because we know that $(1-\cos x)/x^2) \leq 1/2$.
The reason for this terrible result is that:
- we know $\cos x$ to high accuracy, since $x$ was some fixed quantity.
- $1 - \cos x$ converted the **error** in $\cos x$ into its **value**.
- $1 - \cos x$ has only one significant figure.
- This makes it practically useless for anything else we are interested in doing.

In general:

$$
\begin{aligned}
&x \equiv 1 + \epsilon \text{error of order $\epsilon$} \\
&y \equiv 1 - x = \epsilon \text{value of order $\epsilon$} \\
\end{aligned}
$$

That is, subtracting values close to each other (in this case, $1$ and $x$)
converts **error order of magnitude** into **value order of magnitude**.
Alternatively, it brings earlier errors into promience as values.

### Analysis of subtraction

We can consider the subtraction:

$$
\begin{aligned}
&x = a - b; \hat x = \hat a - \hat b \\
&\hat a = a(1 + \Delta a) \\
&\hat b = b(1 + \Delta b) \\
&\left| \frac{x - \hat x}{x} \right|  \\
&= \left| \frac{-a\Delta a - b\Delta b}{a - b} \right| \\
&= \frac{|-a\Delta a - b\Delta b|}{|a - b|} \\
&=  \frac{|a\Delta a + b\Delta b|}{|a - b|} \\
&\leq  \frac{\max(|\Delta a|, |\Delta b|) (|a| + |b|)}{|a - b|}
\end{aligned}
$$

This quantity will be large when $|a - b| \ll |a| + |b|$: that is, when
there is heavy cancellation in the subtraction to compute $x$.

### Underflow

```cpp
#include <cmath>
#include <stdio.h>

int main() {
    double x = 1000;
    for(int i = 0; i < 60; ++i) {
        x = sqrt(x);
    }
    for(int i = 0; i < 60; ++i) {
        x = x*x;
    }
    printf("x: %10.20f\n", x);
}
```

This produces the output:

```
./sqrt-pow-1-12
...
x: 1.00000000000000000000
```

That is, even though the function is an identity function, the answer collapses
to `1`. What is happening?

### Computing $(e^x - 1)/x$
One way to evaluate this function is as follows:

```cpp
double f(double x) { return x == 0 ? 1 : (pow(M_E, x) - 1) / x; }
```

This can suffer from catastrophic cancellation in the numerator. When
$x$ is close to $0$, $e^x$ is close to 1, and $e^x - 1$ will magnify the
error in $e^x$.

```cpp
double f(double x) {
   const double y = pow(M_E, x);
   return y == 1 ? 1 : (y - 1) / log(y);
}
```

This algorithm seems crazy, but there's insight in it. We can show that
the errors cancel! The idea is that neither $(y - 1)$ nor $\log y$ are
particularly good, the errors accumulated in them almost completely
cancel out, leaving out a good value:

$$
\text{assume $\hat y = 1$} \\
1 = \hat y \equiv e^x(1 + \delta) \\
\log 1 = \log (e^x ) + \log(1 + \delta) \\
x = -\log(1 + \delta) \\
x = -\delta + O(\delta^2)
$$

If $\hat y \neq 1$:

$$
\hat f = (\hat y - 1)/\log{\hat y} = (1+\epsilon_3)(\hat y - 1)(1 + \epsilon+1)/(\log \hat y(1 + \epsilon_2))
$$



### IEEE floating point fun: `+0` and `-0` for complex analysis

> Rather than think of `+0` and `-0` as distinct numerical values, think of
> their sign bit as an auxiliary variable that conveys one bit of information
> (or misinformation) about any numerical variable that takes on 0 as its
> value.

We have two types of zeroes, `+0` and `-0` in IEEE-754. These are used in some
cases. The most famous is that $1/+0 = +\infty$, while $1/-0 = -\infty$. Here,
we proceed to discuss some complex-analytic considerations.

> Therefore. implementers of compilers
> and run-time libraries bear a heavy burden of attention to detail
> if applications programmers are to realize the full benefit of the
> IEEE style of complex arithmetic. That benefit deserves Some
> discussion here if only to reassure implementers that their
> assiduity will be appreciated.

$$
\sqrt{-1 + 0 i} = +0 + i \\
\sqrt{-1 - 0 i} = +0 - i \\
$$
These will ensure that $\sqrt{z*} = (\sqrt{z})*$:


$$
\texttt{copysign}(1, +0) = +1 \\
\texttt{copysign}(1, -0) = -1 \\
$$

These will ensure that $\texttt{copysign}(x, 1/x) = x$ when $x = \pm \infty$.


An example is provided where the two limits:

$$
\begin{aligned}
&f(x + i0) = \lim_{y \rightarrow 0-} f(x + i y) \\
&f(x + i0) = \lim_{y \rightarrow 0-} f(x + i y) \\
\end{aligned}
$$

#### Complex-analytic considerations

The principal branch of a complex function is a way to select one branch
of a complex-function, which tends to be multi-valued. A classical example
is the argument function, where $\arg(r e^{i \theta} = \theta$.
However, this is ambiguous: we can map $\theta \mapsto \theta + 2 \pi$
and still have the same complex number. So, we need to fix some standard.
We usually pick the "branch" where $0 \leq \theta < 2 \pi$.
In general, we need to carefully handle what happens to the function at
the discontinuity.


> What deserves to be undermined is blind faith in the power of Algebra. We
> should not believe that the equivalence class of expressions that all
> describe the same complex analytic function can be recognized by algebraic
> means alone, not even if relatively uncomplicated expressions are the only
> ones considered.


#### References
- Accuracy and stability of numerical algorithms
- [Branch Cuts for complex elementary functions, or much ado about Nothing's Sign Bit](https://people.freebsd.org/~das/kahan86branch.pdf)

# Mobius inversion on Incidence Algebras

Most of these functions are really defined on the _incidence algebra_ of
the poset $P$ with ground field $K$. An _incidence_ algebra $ I(P) $ is a
set of functions which maps intervals of $P$ to the ground field $K$. an
interval is a tuple $(x, y) \in P \times P$ such that $x \leq P$
(where the $\leq$ comes from the partial order on $P$). We have a product
structure which I denote $\star$, given by:

$$
(\alpha \star \beta)([x, z]) = \sum_{x \leq y \leq z} \alpha(x, y) \beta(y, z)
$$

A linear algebra way to look at this is to consider $|P| x |P|$ matrices over $K$
where the rows and columns are indexed by $P$.
The a function $\alpha: P \times P \rightarrow K$
can be written as the elements of the $P \times P$ matrix.
Then this convolution-like operator $\star$ is simply matrix multiplication.

We have three natural functions:

(1) The characteristic function, which is the identity for $\star$:

$$
\delta([x, z]) \equiv 1 \texttt{ if } x = z \texttt{; } 0 \texttt{ otherwise }
$$


(2) the zeta function, which plays the role of the constant $1$:

$$
\zeta([x, z]) \equiv  1 \texttt{ if } x \leq z \texttt{; } 0 \texttt{ otherwise }
$$

(3) The inverse of the zeta function, the mobius function, a tool for mobius inversion:

$$
\begin{aligned}
&\mu([x, z])  = 1 \\
&\mu([x, z])  = - \sum_{x \leq y < z} \mu([x, y]) \\
\end{aligned}
$$


The mobius inversion theorem for posets states that $\zeta$ and $\mu$ as
defined above are convolutional inverses. that is, $\zeta \star \mu = \delta$.

This allows us to prove:

$$
\begin{aligned}
&g([x, z]) = \sum_{x \leq y \leq z} f([x, y]) \\
&g([x, z]) = \sum_{x \leq y \leq z} f([x, y]) \cdot 1 \\
&g([x, z]) = \sum_{x \leq y \leq z} f([x, y]) \cdot \zeta(y, z) \\
&g = f \star \zeta \\
&g \star \mu = f \star \zeta \star \mu \\
&g \star \mu = f \star \delta \\
&g \star \mu = f
\end{aligned}
$$

We have managed to find $f$ in terms of $g$, when previously we had $g$
in terms of $f$.


**TODO**: we are usually interested in a _fixed_ $[x, z]$. What happens if we
make this implicit? We may get nice notation for all of this!

### Sums as mobius inversion

We can derive the formula we had for integrals, that:

$$
F(i) = \sum_{0 \leq i \leq n} f(i) \iff f(k) = F(k) - F(k-1)
$$

by setting up mobius inversion on the usual partial order for the natural
numbers. For simplicity, I'll show the example on $[0, 1, 2, 3, 4]$. The example
immediately generalizes.

- We have the partial (well, total) order $P$: $0 < 1 < 2 < 3 < 4$.
- We are given a function $f(\cdot)$ we wish to integrate. We define an
  auxiliary function $fi([x, y]) = f(y)$ which evaluates $f$ on the right
  endpoint.
- We can now define $F([x, z])$  as the sum of $f$ from $x$ to $z$:

$$
\begin{aligned}
&F([x, z]) \equiv \sum_{x \leq y \leq z} f(y) \\
&= \sum_{x \leq y \leq z} fi([x, y]) \\
&= \sum_{x \leq y \leq z} fi([x, y]) \cdot \zeta(y, z) \\
&= fi \star \zeta
\end{aligned}
$$

- This tells us that $f(n) = fi([0, n]) = (F \star \mu)([0, n])$:

$$
\begin{aligned}
&f(n) = fi([0, n]) \equiv  (F \star mu)[0, n] \\
&=  \sum_{0 \leq x \leq n} F([0, x]) \mu([x, n])
\end{aligned}
$$

- We note that we need to know the values of $\mu([x, n])$ for a _fixed_ n,
  for _varying_ x. Let us attempt to calculate $\mu([0, 4]), \mu([1, 4]), \mu([2, 4]), \mu([3, 4]), \mu([4, 4])$
  and see if this can be generalized:

$$
\begin{aligned}
& \mu([4, 4]) = 1 \text{ By definition} \\
& \mu([3, 4]) = - \left (\sum_{3 \leq x < 4} \right) \text{ By definition } \\
\end{aligned}
$$


# Finite differences and Umbral calculus

Umbral calculus lays out a large collection of "umbral" / "shadowy"
coincidences across combinatorics and calculus. Here, I'll lay out some of
these that I learnt from [Concrete Mathematics](https://en.wikipedia.org/wiki/Concrete_Mathematics).
I hope to use this for myself to motivate a bunch of combinatorics. I'll
provide an interesting proof of why $\sum{1 \leq k < n} k^2 = k(k-1)/2$
using this umbral calculus.

### Discrete Derivative: Forward difference

We begin by trying to build a discrete version of the derivative operator. The
derivative of `f` will be denoted using `f'`. The _forward_ difference
of $f: \mathbb R \rightarrow \mathbb R$ is defined as:

$$
\delta f: \mathbb R \rightarrow \mathbb R; (\delta f)(x) = f(x + 1) - f(x)
$$

Immediately, we can see that this operator is linear:

$$
\begin{aligned}
&\delta(f + g)
  &= (f+g)(x+1) - (f+g)(x)  \\
  &= (f(x+1) - f(x)) + (g(x+1)-g(x))  \\
  &= (\delta f) + (\delta g)  \\
&\delta(\alpha f)(x)
  &= (\alpha f)(x+1) - (\alpha f)(x) \\
  &= \alpha \cdot (f(x+1) - f(x))   \\
  &= \alpha (\delta f)
\end{aligned}
$$

it obeys a slightly corrupted version of the chain rule, $(fg)' = f' g + g' f$:

$$
\begin{aligned}
&\delta(fg)  \\
  &= (fg)(x+1) - (fg)(x)  \\
  &= f(x+1)g(x+1) - f(x)g(x) + 0 \\
  &= f(x+1)g(x+1) - f(x)g(x) + [f(x)g(x+1) - f(x)g(x+1)] \\
  &= g(x+1)[f(x+1) - f(x)] + f(x)[g(x+1) - g(x)] \\
  &= g(x+1)(\delta f)(x) + f(x) (\delta g)(x) \\
  &= (S \delta f)(x) + (f \delta g)(x) [(Sh)(x) \equiv h(x+1)] \\
  &= (S  \delta f + f \delta g)(x) \\
\end{aligned}
$$

We need this new $S$ operator to shift the function's input from $x$ to $x+1$.

### Falling factorial as polynomials

cool, now that we seem to have a linear derivative operator that behaves
roughly sanely, let's test it out! The first reasonable target is a polynomial,
so let's try $x^2$:

$$
\delta(x^2) = (x+1)^2 - x^2 = 2x + 1
$$

This is disappointing, it does not behave very well `:(` However, there _is_
an analogue that does well. This is the _falling factorial_, defined as:

$$
x^{(n)} \equiv x(x-1)(x-2)\cdots(x-n+1)
$$

For example:

$$
x^{(0)} = 1 \\
x^{(1)} = x \\
x^{(2)} = x(x-1) \\
x^{(3)} = x(x-1)(x-2) \\
$$

Let's try and apply our discrete difference $\delta$:

$$
\begin{aligned}
&\delta(x^{(2)})  \\
  & = (x+1)(x-1+1) - x(x-1) \\
  & = (x+1)(x) - x(x-1) \\
  & = x*2 = 2x(1) \\
&\delta(x^{(3)})  \\
  &= (x+1)(x-1+1)(x-2+1) - x(x-1)(x-2) \\
  &= (x+1)(x)(x-1) - x(x-1)(x-2) \\
  &= x(x-1)((x+1) - (x-2)) = 3x(x-1) = 3x^{(2)} \\
\end{aligned}
$$

These falling factorials look pretty unnatural though, why do we care?
Well, once we build some integral calculus, we can handle our problem
of $\sum_{1 \leq i < k} i^2$ using this calculus, by rewriting $i^2$
in terms of these falling factorials.

### Sums as discrete integrals

We want to think of $\sum_{0 \leq i < n} f(i)$ as the correct variant of
$\int_0^n f(i) di$. The most important property of an integral is
the fundamental theorem of calculus:

$$
\int_a^b f'(i) di = f(b) - f(a) \mapsto \sum_{a \leq i < b} (\delta f)(i) =?= f(b) - f(a)
$$

we can check if the assertion is true:

$$
\begin{aligned}
&\sum_{a \leq i < b} (\delta f)(i)  \\
&= [f(a+1) - f(a)] + [f(a+2) - f(a+1)] + [f(a+3)-f(a+2)] + \cdots + [f(b) - f(b-1)] \\
&= f(b) - f(a) \quad \text{(The sum telescopes)}
\end{aligned}
$$

Sweet, so we just kicked a theory of calculus of the ground. Let's put
this to some use:

### Gauss' famous formula from discrete calculus

Let's begin by deriving the closed form for $[1\cdot(k-1)]$ naturals:

$$
\sum_{0 \leq i < n} i = \sum_{0 \leq i < n} i^{(1)} = i^{(2)}/2 \big|_{0}^n = n(n-1)/2
$$

Let's now derive the closed form form the sum of squares of $[1\cdot(k-1)]$:

$$
\begin{aligned}
&\sum_{0 \leq i < n} i^2  \\
&= \sum_{0 \leq i < n} i*(i-1) + i  \\
&= \sum_{0 \leq i < n} i^{(2)} + i^{(1)} \\
&= n^{(3)}/2 + n^{(2)}/2 \\
&= n(n-1)(n-2)/3 + n(n-1)/2 \\
&= n(n-1)(n/3 - 2/3 + 1/2) \\
&= n(n-1)(2n - 1)/6 \\
\end{aligned}
$$

Trying to perform this process in general does beg a question: how do we
convert from $x^n$ into some combination of rising and falling factorials?
It turns out that _Stirling Numbers_ will show up to aid this conversion.
But before that, let's see some more connections.

### $2^x$ as the combinatorial version of $e^x$

We want to find the analogue of the exponential function $e^x$, which
satisfies the equation $f'(x) = f(x)$. Setting this up in the discrete case:

$$
\begin{aligned}
&d'f(x) = f(x) |  f(0) = 1 \\
&f(x+1) - f(x) = f(x) | f(0) = 1 \\
&f(x+1) = 2f(x) | f(0) = 1 \\
&f(n) = 2^n
\end{aligned}
$$

What does this buy us? It gives us a nice proof that $\sum_{k} nCk = 2^n$.
It proceeds by taking the taylor of $e^x$, "combinatorializing it", and then
simplifying:

$$
\begin{aligned}
&e^x = \sum_{n=0}^\infty \frac{x^n}{n!} \\
&2^x = \sum_{n=0}^\infty \frac{x^{(n)}}{n!} \\
&     = \sum_{n=0}^\infty \frac{x*(x-1)*(x-2)*\cdots(x-n+1)}{n!} \\
&     = \sum_{n=0}^\infty \frac{x*(x-1)*(x-2)*\cdots(x-n+1)}{n!}
\end{aligned}
$$

### Harmonic series as the combinatorial version of logarithm

In the continuous case, we have that $\int 1/x = \log x$. In the
discrete case, we get $\sum_{i=1}^n 1/x \equiv H_n$, the sum of the
first $n$ harmonic numbers. This explains _why_ the harmonic numbers
keep showing up in different places across discrete math --- We're often
trying to integrate some kind of $1/x$ quantity.
This also may tell us that $H_n$ and $2^n$ are somewhat "weak inverses" of each other.
I haven't thought about this weak inverse thing too much.

### Stirling numbers of the first kind for convering between polynomials and falling factorials

We can express $x^{(n)} = \sum_{k=0}^n [n, k] x^k$ where $[n, k]$
are the (yet to be defined) unsigned stirling numbers of the first kind.
(aside: I wonder if this can be derived from some kind of mobius inversion).

We begin my in fact _defining_ the stirling numbers of the first kind, $[n, k]$
as the coefficients of the rising factorial:

$$
x^{(n)} = x(x+1)(x+2) \dots (x+n-1) = \sum_{i=0}^n [n, i] x^i
$$

The question as a combinatorialist is:

> what do the unsigned striling numbers of the first kind, $[n, i]$, count?

The answer is:

> $[n, i]$ counts the number of permutations of $n$ elements with $i$
> disjoint cycles.

There is a more evocative definition, which goes like this:

> $[n, i]$ counts the number of ways to seat $n$ people at $i$
> circular tables, such that no table is left empty.

For example, in the case of the permutations of the set $\{1, 2, 3\}$,
we have the permutations:

$$
\begin{aligned}
(1)(2)(3) \text{3 cycles} \\
(12)(3) \text{2 cycles} \\
(1)(23) \text{2 cycles} \\
(2)(13) \text{2 cycles} \\
(132) \text{1 cycle} \\
(123) \text{1 cycle} \\
\end{aligned}
$$

So, this gives the counts:

- $[3, 1] = 2$
- $[3, 2] = 3$
- $[3, 3] = 1$

From the seating people perspective, here's how this goes:
- $[3, 1]$ is the number of ways to seat 3 people at 1 table. The first
  person sits at the table in only **one way**. The second person can sit to the
  left or to the right of the first person, but this is symmetric: they too
  have only **one way**. Now the third person can sit to the left of the first
  person or to the left of the second person. So there are **two ways**.
  In total, there are only two ways. **Key idea:** On a circular table, it
  only matters who is to your left, since there is no difference between left
  and right.
  The second person has two choices: they
- $[3, 3]$ is the number of ways to seat 3 people at 3 tables so that no table
  is empty. We are forced to place one person per table.
- $[3, 2]$ is the number of ways to seat 3 people at 2 tables so that no table
  is empty. So we will need to have two people on the first table,
  and then the final personal on the second table.
  Once we pick which two people sit together in the first table, we are done,
  because for upto two people, it doesn't matter how they sit at a table,
  the situation is symmetric.


These stirling numbers satisfy a recurrence:

$$
[n+1, k] = n[n, k] + [n, k-1]
$$

This can be seen combinatorially. If we want the number permutations of $n+1$ objects
with $k$ cycles, we can either:

1. Take the permutations of $n$ objects with $k-1$ cycles, $[n, k-1]$, and then
   insert the new $(n+1)$th object into a new cycle all by itself. That is,
   we create a new permutation where $p(n+1) = (n+1)$.
2. Take the permutation of $n$ objects with $k$ cycles, and insert this new $(n+1)$th
   object into any of the $k$ cycles. If the original permutation had `x -p-> y`,
   we can insert this new object as `x -p-> * -p->y` for any `x`. Thus, there are
   $n$ choices of locations to inser `*` --- as the image of all possible `x`s.
   This gives us the $n[n, k]$ term.

Another cute fact of the unsigned stirling numbers of the first kind $[n, k]$
is that since permutations are partitioned by their number of cycles, we have:

$$
\sum_{k=1}^n [n, k] = n!
$$



### References

- [Concrete Mathematics](https://en.wikipedia.org/wiki/Concrete_Mathematics)
- [Cornell 18.312: algebraic combinatorics](http://pi.math.cornell.edu/~levine/18.312/alg-comb-lecture-10.pdf)
- [An introduction to posets and mobius inversion](https://community.plu.edu/~edgartj/posetMobius.pdf)


# Permutahedron

The permutahedron over $n$ letters is a polytope which is defined as the convex
hull of all permutations of the point $(1, 2, \dots, n)$.
For example, the permutahedron over 3 letters is the convex hull of the
points $(1, 2, 3), (1, 3, 2), (2, 1, 3), (2, 3, 1), (3, 1, 2), (3, 2, 1)$.


Here, we show that it can be embedded in $(d-1)$ dimensionl space, and that each point
$perm((1, 2, \dots n))$ is indeed a vertex of the convex hull.

An example of a situation where a point is _not_ in the vertex of a convex hull
is `convexhull(1, 2, 3) = [1, 3]`. Note that `2` was used to generate the
convex hull, but is not a vertex since it is the convex combination of `1, 3`.
We wish to prove that such a situation does not happen in the case of the
permutahedron.

I have not seen an elementary proof that each point that is a permutation of
the original is a vertex, so I'm recording that proof out of interest.


### Showing that all permutations of $(1, 2, \dots, n)$ are vertices

#### Core idea

start by looking at index `i` of the "largest value" `N` in the point `P`.
Since it's the largest point, if it's a convex combination, all other points in
the convex combination must have the same "largest value" at that index `i`. So
we can now ignore the index `i` and get permutations of `[1..N-1]`

Repeat this process to prove that _all_ indexes of things in the convex sum
must be equal to `P`. But this is absurd, because all vertices are distinct.
Hence, the only way for this to work out is if we have only one point that we
are convex-summing over. That is, `P` _cannot_ be written as the convex sum of
two or more vertices.

#### Formal proof


Let us be working with permutations of `[1, 2, ..., N]`. Pick point `P`. Assume
`P` is in the convex sum of some `{ Xi }`.

Let `index(N, P)` be the index of number `N` in `P`. For example, if
`P = [2, 3, 1]`, then

```
index(2, P) = 0 (assuming 0-based indexing)
index(3, P) = 1
index(1, P) = 2
```

If `P` is the convex sum of vertices `{ Xi }`, all of them _must_ have that:

```
Xi[index(N, P)]  = N forall Xi in the convex sum
```


since `N` is the largest value that `X_I` can have at any index. The only way
to get the maximum value by a convex sum is for all values to be that maximum
value.

So, we can now ignore dimension `index(N, P)`, since _all the vertices_ `X_i`
involved in the convex combination and `P` have `index(N, P) = N`. If we
project out this dimension, we are left with permutation of `(1..N-1)`.

Repeat the same process. We will need to have all `X_i` to have their value at
`index(N-1, P)` to be `N-1`.

Keep doing this till we get that the dimensions of all points in `Xi` and `P`
are equal. But all the points in `{ Xi }` are distinct since they are
permutation of `[1..n]`. Hence, `{ Xi }` can contain only a single point, and
this point is `P`.

Hence, `P` cannot be written as the convex combination of other points. Hence,
`P` is a vertex.

#### Proof that convex sum of maximum must have maximum

Assume we have values `{v1, v2, ... vn}` where without loss of generality,
`v1 <= v2 <= ... <= vn`. We can always relabel otherwise.

Now we want to write `vn` as the convex sum of `{v1, v2, ... vn}`. We can draw this on
the number line as:

```
---[v1--v2--v3--...--vn]---
```

- A convex sum must be inside this line segment between `[v1--...--vn]` (`vn` is
  to the rightmost since it's known to be the largest value in `{v1...vn}`).
- So, if we try to write `vn` as the convex sum, we _must_ have the coefficient
  of `vn=1` and the coefficient of all other points `=0`, since any other
  combination will "pull the convex sum away from the right (where `vn` sits),
  towards the left".

# Lyndon + Christoffel = Convex Hull
Actual "real world" use-case of lyndon factorization, cribbed from here:

- [Lyndon + Christoffel = digitally convex](https://archipel.uqam.ca/8354/1/Reutenauer-2009a-preprint.pdf)
- Combinatorics on Words: Christoffel Words and Repetitions in Words

I wanted to learn a real-world use-case of lyndon factorization so I could
remember it. I found a whole bridge between combinatorics/strings and
discrete geometry (they call it "digital geometry") that I didn't know
existed before.


- If you have a line with rational slope $p/q$ and you want to draw a
  "discretized line" by connecting integer points in ZxZ, you can describe this
  discretized line as starting from $(0, 0)$, making moves $x$ (move up 1 unit
  along $x$-axis), $y$ (move up 1 unit along $y$-axis), finally reaching the point
  $(p, q)$. For example, to reach the point $(2, 3)$, you can make the moves
  $[x, x, x, y, y]$.

- A christoffel word is a word $w \in \{x, y \}^\star$ such that it hugs a line of
  rational slope $p/q$ as close as possible. Formally, there are no integer
  points between the line with slope $p/q$ starting from the origin, and the
  discretized line as described by $w$. An example picture:

<img src="./static/christoffel-word-example.png">

- It turns out that all primitive christoffel words are Lyndon words. I'm not
  100% sure what primitive is, but the take-away is that these primitive
  christoffel words represent discrete lines that are *good* approximations
  of lines.

- Now, we are given a discrete sequence of adjacent line segments going
  upwards, where the line segments are described by $x, y$ moves. We want to
  check if the discrete curve defined by them is well-approximating a convex
  polygon.

- We compute the lyndon factorization of the word. This splits the
  original line segment into a series of line segments, where each
  successive line segment has lower slope than the previous (since the
  lyndon decomposition splits words into non-decreasing lex order).

<img src="./static/lyndon-convex.png">

- We can then check that each word in the lyndon decomposition is a Christoffel
  word. If it is, then your sequence of moves describes a "good  discrete
  convex hull", since as described above, a christoffel word "hugs the line"
  well.


### Bonus: slick characterization of line drawing

<img src="./static/christoffel-cyclic-7-4.png">


If we want to draw a line with slope `p/q = 4/7` using the lower approximation the idea
is that we keep taking `4` steps along `x`, and every time we "exceed" `7` steps
along `x`, we take a step along `y`.

This is the same as:
1. working in `Z/(4+7)Z`, starting from `0`, writing down multiples of `4` till we cycle back to `0`
2. marking an "increase" in a step with an `x`, and a "decrease" in a step
  with `y`.

The intuition is that once we walk `k*p` steps where `k*p >= q`, we want
to increment `y`. So, at first glance, we may believe we should consider
`Z/qZ`. However, this is misguided. Examples to enlighten:


1. Consider `x=1, y=0`. We should use `Z/1Z = { 0 }`: that is, we must keep
  moving along `0 -x -> 0 -x-> 0 -x-> ...`. This is unlike what happens if we choose
  `Z/0Z` (which is not a well-defined idea).
2. Consider `x=1,y=1`. We should use `Z/2Z`, so we keep going `0 -x-> 1 -y-> 0 -> ...`
  which will cause is to flip `x -> y -> x -> y -> ...`.


In some sense, we are making sure that we can "start" with an `x` and see where that takes us.
In the `Z/1Z` case, we realise that we can keep taking `x`s. In the
`Z/2Z` case, we realise we need to flip between `x` and `x`.

Let's try to show this formally, where `k` is the smallest number
such that `kp >= q`. We'll also have concrete examples where
`p=2, q=7`. For the example, `k=4` since `kp = 4*2 = 8 > 7`.
If we work in `Z/yZ = Z/7Z`, we will get the numbers:


```
Z:    0, p, 2p, ... (k-1)p, [q] kp
Z/qZ: 0, p, 2p, ... (k-1)p, [q] (kp % q)
Z/7z: 0, 2,  4, ...      6, [7] (8 % 7 = 1)
```

But notice that we are inserting `x` _between_ numbers. So we will get:

```
Z:    0 -x-> p -x-> 2p, ... (k-1)p -y-> (k+1)p
Z/qZ: 0 -x-> p -x-> 2p, ... (k-1)p -y-> ((k+1)p % y)
Z/7z: 0 -x-> 2 -x->  4, ...      6 -y-> (8      % 7 = 1)
         ^                            ^
      x since [0 < 2]              y since [6 > 1]
```

which gives us the moves:

```
Z/7Z: 0 -x-> 2 -x-> 4 -x-> 6 -y-> 8 % 7 = 1
```

We only get `3` occurences of `x`, after which on the next accumulation of `p`,
becomes an `8` which wraps around to a `1`. This is the age-old tension that exists
between **points** and **gaps**. For `k` points, there are `k-1` gaps. In our
case, we have `4` points `[0, 2, 4, 6]`, but this leaves us room for only
three gaps for three`x` moves, while in reality we need `4`.
We remedy this situation by giving ourselves space enough for _one_ more `x`, by changing from `Z/qZ`
to `Z/(p+q)Z`. We should look at this as creating space for another gap.


```
Z:        0, p, 2p, ... (k-1)p, [q] kp,  [q+p  ], (k+1)p
Z/(p+q)Z: 0, p, 2p, ... (k-1)p, [q] kp,  [q+p  ], (k+1)p % (p+q)
Z/9z: 0, 2,  4, ...          6, [7]  8,  [7+2=9], (10    %    9=1)
```

which gives us the moves:

```
Z:        0 -x-> p -x-> ... (k-1)p -x-> kp -y-> (k+1)p
Z/(p+q)Z: 0 -x-> p -x-> ... (k-1)p -x-> kp -y-> (k+1)p % (p+q)
Z/9Z:     0 -x-> 2 -x-> ...      6 -x->  8 -y-> (   10 %     9 = 1)
             ^                             ^
           x since [0 < 2]               y since [8 > 1]

```

That is, we are able to get `k` occurences `x` between `0, p, ..,kp` which
has `(k+1)` points. Concretely, we have:

```
Z/9Z: 0 -x-> 2 -x-> 4 -x-> 6 -x-> 8 -y-> 1
```
where we have 4 occurences of `x` in between after which we have an occurence
of `y`, which is what we want when `x=2, y = 7`. We need to reach at least
`q=7` before we have exceeded our denominator and need to make a move
along `y`.


# Geometric proof of `e^x >= 1+x`, `e^(-x) >= 1-x`

Let's concentrate on the `e^x >= 1 + x` part.

1. The tangent of `e^x` at `x = 0` is `1 + x`, since the taylor series
   of `e^x` truncated upto `x` is `1 + x`.
2. `e^x` is a strongly convex function, since `(e^x)'' = e^x` which is positive
   everywhere. Hence, `e^x` will always lie above its tangent.

Similarly for `e^(-x)`, working through the math:

1. `1 -x` is tangent at `x=0` to `e^(-x)`
2. `(e^(-x))'' = -(e^(-x))' e^(-x)` which is again positive everywhere, and
   hence, `e^(-x)` is strongly convex.




# Ranking and Sorting

We we want to sort an arrray `xs` and write the results into an array `ys`.
In both cases, the invariant to be satisfied is that `ys` is `xs` in ascending
order. I'll be considering two broad ways to implement such a thing:


- 1. **(RANK)** Index straight into `ys`, reindexed into `xs`. We name the reindexing
  array as `rs` (`rs` for _ranks_).

```cpp
for(int i = 0; i < N; ++i) {
   ys[rs[i]] = xs[i]
}
```

- 2. **(SELECT)** Reindex into `ys`, index straight into `xs`.
  We name the reindexing array `ss` (`ss` for _selects_).

```cpp
for(int i = 0; i < N; ++i) {
   ys[i] = xs[ss[i]]
}
```

#### Defnition of rank

In the case of **(RANK)**, the specification is that the rank of an element `e`
is the number of elements that are:

1. less than `e`.
2. equal to `e` but occur before `e`.

This ensures that rank is a _permutation_: that is, every element `e` is given
a _unique_ index.

```cpp
int rank(const int *xs, int i) {
    int cnt = 0;
    for (int j = 0; j < N; ++j) {
        if (xs[j] < xs[i] || (xs[j] == xs[i] && j < i)) cnt += 1;
    }
    return cnt;
}

for(int i = 0; i < N; ++i) {
  rs[i] = rank(xs, i);
}
```

##### Rank: Alternative 1
An alternative way to look at our definition of rank is that we are
sorting the tuples  `(xs[i], i)` using lex ordering. So if two indeces
`i, j` have the same value, then we sort on the index.


##### Rank: Alternative 2
We could have also defined rank as:

```cpp
int rank(int *xs, int i) {
    int cnt = 0;
    for (int j = 0; j < i; ++j) {
        if (xs[j] <= xs[i]) cnt += 1
    }
    return cnt;
}
```

I declined from doing so because I wanted to show the lex-ordering
interpretation of `rank` will be be useful later.

#### Definition of select

For **(SELECT)**, we'll need to think a little harder. Let's try to rewrite
our way to glory:

- 1. From definition of rank:

```cpp
ys[rs[i]] = xs[i]
```

- 2. move `i -> ss[i]` where `ss[i]` is guaranteed to be a permutation,
  so we will write each index eventually:

```cpp
ys[rs[ss[i]]] = xs[ss[i]]
```

- 3. Stipulate that `rs[ss[i]] = i`, since we want a `ys[i]`:

```cpp
ys[i] = xs[ss[i]]
```

This gives us necessary and sufficient conditions on how to find an `ss`:
`ss` must be a permutation that is an inverse permutation to `rs`.


#### How to invert a permutation?

How does one invert a permutation? We have a permutation `rs[i]` that maps
`i` to `rs[i]`. We want to find a new permutation `ss[i]` such that

```
rs[ss[i]] = i
```

Equivalently:

```
// ss[i] is an index 'k'...
ss[i] = k
// 'k' is the location of 'i' in rs.
rs[k] = i
```

So if we first tag each location of `rs` with its index, and then sort
with the values of `rs` being the keys, then `ss[i]` will be the values.

In pictures:

```
rs[i]          [3 4 0 1 2]
rs_tagged[i]   [(3, 0) (4, 1) (0, 2) (1, 3) (2, 4)]
rs_sorted[i]   [(0, 2) (1, 3) (2, 4) (3, 0) (4, 1)]
ss[i]          [    2      3      4      0      1 ]
rs[ss[i]]      [ rs[2]  rs[3]  rs[4]  rs[0]  rs[1]]
rs[ss[i]]      [    0      1      2      3      4 ]
```

#### Rank and Select are inverses

It's nice, there are a couple of miracles that lined up here:

- Rank starts with `r` and select starts with `s` so we get nice naming.
- Rank and select are true inverse permutations of each other.

#### Generalized rank and select are adjoint

We had to "fix" our definition of rank to avoid equal elements in the array.
Hence, we had the rule that we also sort by indexes if the elements are
equal. However, if we now decide to ignore this rule, we will then recreate
the classical _adjunction_ between rank and select.

#### References
- Richard Bird: Pearls of functional algorithm design



# Proof of minkowski convex body theorem

We can derive a proof of the minkowski convex body theorem starting from
Blichfeldt’s theorem.

#### Blichfeldt's theorem

This theorem allows us to prove that a set
of large-enough-size in any lattice will have two points such that their
difference lies in the lattice. Formally, we have:

1. A lattice $L(B) \equiv \{ Bx : x \in \mathbb Z^n \}$ for some basis
   $B \in \mathbb R^n$. The lattice $L$ is spanned by integer linear
   combinations of rows of $B$.
2. A body $S \subseteq R^n$ which **need not be convex!**, which
   has volume greater than $\det(B)$. Recall that for a lattice $L(B)$,
   the volume of a fundamental unit / fundamental parallelopiped is $det(B)$.


Blichfeldt's theorem tells us that there exists two points $x_1, x_2 \in S$
such that $x_1 - x_2 \in L$.

##### Proof

The idea is to:

1. Chop up sections of $S$ across all translates of the fundamental parallelopiped
   that have non-empty intersections with $S$ back to the origin. This makes
   all of them overlap with the fundamental parallelopiped with the origin.
2. Since $S$ has volume great that $\det(B)$, but the fundamental paralellopiped
   only has volume $\det(B)$, points from two different parallelograms **must**
   overlap.
3. "Undo" the translation to find two points which are of the form $x_1 = l_1 + \delta$,
   $x_2 = l_2 + \delta$. they must have the same $\delta$ since they overlapped
   when they were laid on the fundamental paralellopiped. Also notice that $l_1 \neq l_2$
   since they came from two different parallograms on the plane!
4. Notice that $x_1 - x_2 = l_1 - l_2\in L \neq 0$, since we already argued
   that $l_1 \neq l_2$. This gives us what we want.

#### Minkowskis' Convex body Theorem from Blichfeldt's theorem

Consider a convex set $S \subseteq \mathbb R^n$
that is symmetric about the origin with volume greater than $2^n det(B)$.

Create a new set $T$ which is $S * 0.5$. Formally:

$$T \equiv S/2 = \{ (x_1/2, x_2, \dots, x_n/2)  : (x_1, x_2, \dots, x_n) \in S \}$$

We now see that $Vol(T) > det(B)$ to invoke  Blichfeldt's theorem.
Formally:

$$Vol(T) = 1/2^n Vol(S) > 1/2^n (2^n det(B)) = det(B)$$

We can apply Blichfeldt's theorem to get our hands on two points $x_1, x_2 \in T$
such that $x_1 - x_2 \in L$.

$$
\begin{aligned}
&x_1 \in T \Rightarrow 2x_1 \in S ~(S = 2T) \\
&x_2 \in T \Rightarrow 2x_2 \in S ~(S = 2T) \\
&2x_2 \in S \Rightarrow -2x_2 \in S~\text{($S$ is symmetric about origin)} \\
&\frac{1}{2}(2x_1) + \frac{1}{2} (-2x_2) \in S~\text{($S$ is convex)}\\
&x_1 - x_2 \in S~\text{(Simplification)}\\
&\text{nonzero lattice point}~\in S \\
\end{aligned}
$$


#### References
- [Theorem of the day](https://www.theoremoftheday.org/GeometryAndTrigonometry/Minkowski/TotDMinkowski.pdf)


# Burrows Wheeler

We aim to get the $O(n)$ algorithm for burrows wheeler, by starting from the
naive $O(n^2)$ implementation and then slowly chipping away to get to the
fastest algorithm

### String rotations

Given a string $s$ of length $n$, we can index it as $s[0]$, $s[1]$, upto
$s[n-1]$. We can now build a table consisting of _rotations_ of the string.
We'll define:

```hs
lrot :: [a] -> [a]
lrot [] = []; lrot (x:xs) = xs ++ [x]
```

We can build a table of left-rotations:

```
foobar
oobarf
obarfo
barfoo
arfoob
rfooba
```

We can immediately notice that it's a _symmetric matrix_. We can prove
this as follows. We write $lrot(rot, s)$ as an array such that:

$$
lrot(rot, s)[i] = s[(rot + i) % n] \text{where $n = |s|$}
$$

Now, we note that on row $r$ of our array we have the string $lrot(r, s)$.
So the value at row $r$, column $c$ is $lrot(r, s)[c] = s[(r + c)%n]$.
But this is symmetric in $c, r$ so can be written as $s[(c + r)%n]$,
which is equal to $lrot(c, s)[r]$. Formally:

$$
lrot(r, s)[c] = s[(r + c) %n] = s[(c + r)%n] = lrot(c, s)[r]
$$

### Sorts of string rotations

We're next interested in considering _sorted order_ of the string
rotations. For example, in the case of the string "here, there",
all the rotations are:

```
here-there  0
ere-thereh  1
re-therehe  2
e-thereher  3
-therehere  4
therehere-  5
herehere-t  6
erehere-th  7
rehere-the  8
ehere-ther  9
```

which is calculated with the help of the following haskell code:

```hs
lrot :: [a] -> [a]
lrot [] = []; lrot (a:as) = as ++ [a]

lrots :: [a] -> [[a]]; lrots as = take (length as) (iterate lrot as)

main =  putStrLn $ intercalate "\n"
  (zipWith (\s i -> s <> "  " <> show i)
           (lrots "here-there") [0,1..])
```

If we now *sort* these rotations, we get:

```
-therehere  0
e-thereher  1
ehere-ther  2
ere-thereh  3
erehere-th  4
here-there  5
herehere-t  6
re-therehe  7
rehere-the  8
therehere-  9
```

we produce this by chainging the above definition of `main` to:

```
main =  putStrLn $ intercalate "\n"
  (zipWith (\s i -> s <> "  " <> show i)
           -- | extra `sort` here
           (sort $ lrots "here-there") [0,1..])
```

Let's look at the **final column** of that table. We have:

```
-thereher|e|  0
e-therehe|r|  1
ehere-the|r|  2
ere-there|h|  3
erehere-t|h|  4
here-ther|e|  5 <- ORIGINAL STRING
herehere-|t|  6
re-thereh|e|  7
rehere-th|e|  8
therehere|-|  9

0123456789
errhhetee-
```

Now, we'll show how to write a _really cool_ function call `bwt` such that:

```hs
bwtinv ("errhhetee-",5) = "here-there"
```

The `5` is the index of the original string in the list. That is, given
the jumbled up last-column and the index of the original string, we're
able to reconstruct the original string. The reason this is useful is
that the jumbled string `"errhhetee-"` is easier to compress: it has
long runs of `r`, `h`, and `e` which makes it easier to compress.

The process we performed of rotating, sorting the rotations and taking
the final column is the Burrows-Wheeler transform. in code:

```hs
import Data.List
lrot :: [a] -> [a]
lrot [] = []; lrot (a:as) = as ++ [a]

lrots :: [a] -> [[a]]
lrots as = take (length as) (iterate lrot as)

findix :: Eq a => a -> [a] -> Int
findix a as = length (takeWhile (/= a) as)

lastcol :: [[a]] -> [a]; lastcol = map last

bwt :: Eq a => Ord a => [a] -> ([a], Int)
bwt as = let as' = (sort . lrots) as in (lastcol as', findix as as')
```

Now we need to understand how `bwtinv` is defined and what it does.
The definition is:

```
import Control.Arrow (&&&)

bwtinv :: Eq a => Ord a => ([a], Int) -> [a]
bwtinv (as, k) = recreate as !! k

-- recreate · lastcol · sort · rots = sort · rots
recreate :: (Eq a, Ord a) => [a] -> [[a]]
recreate as = recreate' (length as) as

recreate' :: (Eq a, Ord a) => Int -> [a] -> [[a]]
recreate' 0 = map (const [])
recreate' n = hdsort . consCol . (id &&& recreate' (n-1))


hdsort :: Ord a => [[a]] -> [[a]]
hdsort = let cmp (x:xs) (y:ys) = compare x y
         in sortBy cmp

consCol :: ([a], [[a]]) -> [[a]]
consCol = uncurry (zipWith (:))
```

OK, so much for the code. what does it _do_?

The idea is that:
- we recreate the entire matrix from the last column using `recreate`
  and take the `k`th element.

- `recreate` apprents a copy of the initial last column to a matrix of
  columns, and then sorts this.

#### Alternate explanation of why this is invertible.

Consider the string `banana` and its cyclic permutations:

```
banana$
$banana
a$banan
na$bana
ana$ban
nana$ba
anana$b
```

Then sorted (where `$` is considered smallest letter):

```
$banan|a|
a$bana|n|
ana$ba|n|
anana$|b|
banana|$|
na$ban|a|
nana$b|a|
```

The BWT will be `annb$aa`. Notice that we also know the FIRST column of the BWT table,
since it's just the string with its letters sorted! So given the last column, we really know:

```
|$|?????|a|
|a|?????|n|
|a|?????|n|
|a|?????|b|
|b|?????|$|
|n|?????|a|
|n|?????|a|
```

- This means we know all "2-mers" of our string, which are: `a$`, `na`, `na`, `ba`, `$b`, `an`, `an`.
- If we sort these, then we get the first two letters of our BWT matrix! That is, the sorted 2-mers:

```
$b
a$
an
an
ba
na
na
```

However, we see that we also know the last column of the BWT matrix, so now we know:

```
|$b|????|a|
|a$|????|n|
|an|????|n|
|an|????|b|
|ba|????|$|
|na|????|a|
|na|????|a|
```

We now know 3-mers! Sort again, find 4-mers, etc. till we reconstruct the whole string `:)`
This is memory intensive. Can we do better?

#### First last property of BWT

Consider the cyclic permutations:

```
b1 a1 n1 a1 n2 a3 $1
$1 b1 a1 n1 a2 n2 a3
a3 $1 b1 a1 n1 a2 n2
n2 a3 $1 b1 a1 n2 a2
a2 n2 a3 $1 b1 a2 n2
n1 a2 n2 a3 $1 b1 a1
a1 n1 a2 n2 a3 $1 b1
```

Now let's sort them:

```
$1 b1 a1 n1 a2 n2 a3
a3 $1 b1 a1 n1 a2 n2
a2 n2 a3 $1 b1 a2 n1
a1 n1 a2 n2 a3 $1 b1
b1 a1 n1 a1 n2 a3 $1
n2 a3 $1 b1 a1 n2 a2
n1 a2 n2 a3 $1 b1 a1
```

- We see that the order of occurrence of `a` in the first column is `[a3 a2 a1]`. Similarly in the last column, it occurs
  in the order `[a3 a2 a1]`. Furthermore, this holds for `n` as well: we have the order `[n2 n1]` in both the first and last
  column.
- Claim: this always occurs! Proof: consider the strings with `[a3, a2, a1]` in the first column:

```
a3 $1 b1 a1 n1 a2 n2
a2 n2 a3 $1 b1 a2 n2
a1 n1 a2 n2 a3 $1 b1
```

- These strings are sorted, since they come from BWT. Thus, I can chop off the `a` from all of them, and they remain sorted (we sort by lex):

```
$1 b1 a1 n1 a2 n2
n2 a3 $1 b1 a2 n2
n1 a2 n2 a3 $1 b1
```

- Furthermore, since we sort by lex, I can place the `a`s at the end of the strings, still retaining lex ordering:


```
$1 b1 a1 n1 a2 n2 a3
n2 a3 $1 b1 a2 n2 a2
n1 a2 n2 a3 $1 b1 a1
```

- These new strings are (a) still sorted, and (b) cyclic shifts of the original strings! Thus, these occur in the BWT table, and are exactly the strings
  in the last column which have `{a1, a2, a3}`. Since they're sorted, they'll occur in the order `[a3 a2 a1]` just like the did in the first column!
- This shows that if the first column has `a` in the order `[a3 a2 a1]`, then so too does the last column have `a` in the order `[a3, a2, a1]`.

- So now, given the last column of the BWT, we add the first column of the BWT and the numbers, since we know that we can always add the numbers by the
  first-last property:

```
1 $1 ? ? ? ? ? a3
2 a3 ? ? ? ? ? n2
3 a2 ? ? ? ? ? n1
4 a1 ? ? ? ? ? b1
5 b1 ? ? ? ? ? $1
6 n2 ? ? ? ? ? a2
7 n1 ? ? ? ? ? a1
```

- In the first column, we have `$1...a3`, which we treat as the string `$1 a3`.
- We see that `a3` corresponds to 2nd column. We have `a3...n2`, which we combine with `$1 a3` to get `$1 a3 n2`.
- We see that `n2` corresonds to the 6th column , where we have `n2...a2`. We combine this with `$1 a3 n2` to get `$1 a3 n2 a2`.
- We see that `a2` corresonds to the 3r column , where we have `a2...n1`. We combine this with `$1 a3 n2 a2` to get `$1 a3 n2 a2 n1`.
- We see that `n1` corresonds to the 7th column , where we have `n1...a1`. We combine this with `$1 a3 n2 a2 n1` to get `$1 a3 n2 a2 n1 a1`.
- We see that `a1` corresonds to the 4th column , where we have `a1...b1`. We combine this with `$1 a3 n2 a2 n1 a1` to get `$1 a3 n2 a2 n1 a1 b1`.
- See that `$1 a3 n2 a2 n1 a1 b1` is the reverse of `banana`, the string we encoded!
- This lets us rediscover the BWT'd string in O(n) time using the neat property of the BWT!

#### Finding substrings with BWT

Since the BWT list is sorted, can keep top and bottom pointers which tell us where we are looking
for current letter. Can find next letter using BWT matix.

#### Why BWT gives good run length encoding

- Suppose we have a book with many words.
- The book will have many occurrences of the word `the`.
- In the BWT, we will have many strings of the form `e.......th`
   to reflect substrings that have a `the`.
- This will give us many occurences of `h` in the last column!.


#### References
- Richard Bird: Pearls of functional algorithm design
- [Algorithms on strings UCSD](https://www.coursera.org/learn/algorithms-on-strings/lecture/C0opC/inverting-burrows-wheeler-transform)

# Intuitionstic logic as a Heyting algebra

_open sets_ form a Heyting Algebra, which is a lattice plus an implication
operator. So it's stronger than a lattice, but weaker than a boolean algebra.
Formally, a Heyting algebra over a set $X$ is a collection $(L, \lor, \land, \Rightarrow)$
where $(X, \lor, \land)$ form a lattice, and $\Rightarrow$ obeys the axiom

$$
\Rightarrow: L \rightarrow L; (c \land a) \leq b \iff c \leq (a \Rightarrow b)
$$

In any topological space $(U, \tau)$ ($U$ for universe set)
the open sets of that space form a Heyting algebra.
Here, set-union and set-intersection become the lattice join and lattice meet.
We define a "weak complement" denoted by $\lnot$ which is defined as:

$$
\lnot A \equiv \texttt{interior}(A^C)
$$

We need the $\texttt{interior}$ to make sure that we're left with an open
set. Also, this $\lnot$ is not really a complement, since we won't have that
$\lnot \lnot A = A$. but, more on that later!

We write open intervals with round parenthesis:

```
    A
--(===)--
```

$\lnot A$ of the above set $A$ becomes the open interval that is in the
interior of $A$ complement.


```
--(===)-- A
==]---[== A complement
==)---(== Not A
```

Now, we can try to ask, when is $\lnot \lnot A = U$ (where $U$ is the universe
set or the full space). If we consider a set containing a single point,
then we will have:


```
==)(== A
------------ Not A
============ Not (Not A)
```
in words:

$$
\begin{aligned}
&A = U \setminus \{ 1 \} \\
&\lnot A = \texttt{interior}(A^c) = \texttt{interior}(\{ 1 \}) = \emptyset \\
&\lnot \lnot A = \texttt{interior}((\lnot A)^c) = \texttt{interior}(\emptyset^c) = \texttt{interior}(U) = U \\
\end{aligned}
$$

So in some sense, the law of excluded middle is "almost true": It holds that $A \simeq \lnot \lnot A$,
where $A$ excludes a set of points of measure zero.
This is really interesting, since it gives some sort of oddball probabilistic
flavour to things where if we blind ourselves to measure-0 sets, then $\lnot \lnot A = A$.


Now, we look at implication. The implication $A \Rightarrow B$ is the largest
set open $C$ such that $C \land A = B$. In pictures:

```
---(========)----- A
---------(=====)-- B
---------(==)----- A && B
===)-----(======== A -> B
```

The reason this is true is that from the definition:

$$
\begin{aligned}
&\Rightarrow: L \rightarrow L;  c \leq (a \Rightarrow b) \iff (c \land a) \leq b \\
&\text{replacing $\leq$ with $=$ for insight:} \\
&\Rightarrow: L \rightarrow L;  c = (a \Rightarrow b) \iff (c \land a) = b  \\
\end{aligned}
$$

Alternatively, we can use the fact that in regular boolean algebra:

$$a \Rightarrow b = \lnot a \lor b$$

to derive $A -> B$:

```
---(========)----- A
===)--------(===== NOT A
---------(=====)-- B
[Extend B to everything that doesn't include
  more of A than already included]
===)-----(======== NOT A or B = A -> B
```


#### `a -> b` as `a` contained in `b`:

We'll show that `a -> b` is true/top/the full real line if and only if
`a` is contained in `b`. We can show this using $\lnot a \lor b$ definition:

1. $a \leq b$ (given)
2. Since $a \leq b$, $\lnot a \geq \lnot b$, since $\lnot$ reverses inclusion order.
3. $x \geq y$ implies that $x \lor p \geq y \lor p$ for all p, since $p$ is
   on both sides.
4. Specializing to $x = \lnot a$, $y = \lnot b$, $p = b$ gives us
   $\lnot a \lor b \geq \lnot b \lor b$
5. $\lnot b \lor b$ is universe $U$
6. $\lnot a \lor b \geq U$, which means it's equal to $U$ (nothing can be greater than $U$).

We can also show this geometrically:

```
----------(===)---- A
------(==========) B
----------(===)---- A && B
[Extend B to everything that doesn't include
  more of A than already included.
  But all of A is
  already included!]
================== A -> B
```


#### reading `curry`, `uncurry` using `a -> b` as containment:

`curry`, `uncurry` are the adjunction/isomorphism:

```
((c,a) -> b) ~ (c -> (a -> b))
```

Read this as:

```
( c     ,         a)     ->         b
(c `intersection` a) `contained in` b
```

if and only if

```
c      ->        (a       ->      b)
c `contained in` (a `implication` b)
```

That is, we have "read" `curry/uncurry` as:

$$
c \land a \leq b \iff c \leq a \Rightarrow b
$$

which was the definition of $\Rightarrow$ we wanted!



##### References

- [Email by Olaf Klinke on haskell-cafe](https://mail.haskell.org/pipermail/haskell-cafe/2020-May/132297.html)

# Edit distance

This implementation of edit distance crystallizes the fact that when computing
edit distance, we only ever move forwards on solving the problem. we _do not_
store the results of the overlapping computations, though we could. Rather,
the goal of this implementation is to capture the traversal pattern necessary
for edit distance into a `Cursor`, and to view the edit distance problem from
the point of view of this `Cursor`.

The problem setting is that we have a source string, a destination
string, and we wish to perform operations that convert the source
string into the destination string. The operations allowed are to:

- Insert a character from the destination to the source.
- Remove a character from the source.
- Replace a character in the source with a character from the destination.

We want to minimise the number of operations to be used.
Let's see how we model this.


```hs
{-# LANGUAGE ViewPatterns #-}
type Ix = Int; type DestIx = Ix; type SrcIx = Ix;
data Move = InsertFromDest DestIx |
            RemoveFromSrc SrcIx |
            ReplaceSrcWithDest SrcIx DestIx
        deriving(Show)
```

Our cost model says that each move costs `1`. We are charged for every
move we make. We are to minimize the number of operations.

```hs
movescost :: [Move] -> Int; movescost = length
```

We model this as us having a `Cursor` which contains  list `[a]` and information
about where we are in the list as an `Ix`.
This is the same as a `Zipper` for a list, except that in this case, we only
allow ourselves to walk forward.

```hs
data Cursor a = Cursor Ix [a]
```


- `cdone` tells is if we have completely consumed a cursor.
- `cix` tells us the index of the cursor.
- `cval` lets us dereference a cursor.
- `incr` lets us move a cursor to the next array entry.
- `cursor` converts a list into a `Cursor` at the first index.

```hs
cdone :: Cursor a -> Bool; cdone (Cursor ix vs) = ix >= length vs
cix :: Cursor a -> Ix; cix (Cursor ix _) = ix
cval :: Cursor a -> a; cval c@(Cursor ix vs) = vs !! ix
incr :: Cursor a -> Cursor a; incr (Cursor ix vs) = Cursor (ix+1) vs
cursor :: [a] -> Cursor a; cursor = Cursor 0
```

We implement `edit`, that tells us how to edit the source string into
the destination string. The convention is `edit <src-str> <dest-str>`.

```hs
-- | decide how to get ixth character of bs from our as.
edit :: Eq a => Cursor a -> Cursor a -> [Move]
```

- 1. If both strings have been consumed, then no moves are to be made.

```hs
edit (cdone -> True) (cdone -> True) = []
```

- 2. If the destination string has been fully matched while the source string
   has not, then remove characters from the source string.

```hs
edit a@(cdone -> False) b@(cdone -> True) =
  (RemoveFromSrc (cix a)):edit (incr a) b
```

- 3. If the source string has run out of characters while the destination string
   still has characters, insert characters from the destination string.

```hs
edit a@(cdone -> True) b@(cdone -> False) =
  (InsertFromDest (cix b)):edit a (incr b)
```

- 4. Otherwise, we have characters remaining in both strings. Try the
   options of (1) replacing a source character with a destination
   character (2) removing a character from the source and continuing,
   and (3) if the current characters match, then keep the match and try
   to combine characters that come later in the string. We pick the
   best out of these using the `argmin` combinator.

```hs
edit a b =
  let nomatch = argmin movescost
                (ReplaceSrcWithDest (cix a) (cix b):edit (incr a) (incr b))
                (RemoveFromSrc (cix a):edit (incr a) b)
  in case cval a == cval b of
      True -> argmin movescost nomatch (edit (incr a) (incr b))
      False -> nomatch
```

The helper used for finding minimum according to a cost model.

```hs
argmin :: (a -> Int) -> a -> a -> a
argmin f a a' = if (f a) < (f a') then a else a'
```

# Evolution of bee colonies (TODO)

This kind of culture that beehives have is called as 'eusociality'.
I'm interested in this because I want to understand what alien societies might
look like, and what selection pressures are required to have bee-like societies
evolve. Many sci-fi books (Ender's game for example) depict aliens with such
a society, but tend to be hazy on how this state of affairs came to be.


- [Evolution of eusociality](https://en.wikipedia.org/wiki/Evolution_of_eusociality)


# Best practices for array indexing

These are rules I'm going to follow when I solve problems on
[codeforces](https://codeforces.com/). I've arrived at these rules by repeatedly
noticing the kinds of mistakes I make and attempting to adopt conventions
to eliminate these.

##### Rule 1: Half-open intervals

Intervals are only represented as `[begin, past-the-end)` That is, we start at
`begin`, include numbers `begin+1, begin+2, ...`, upto, **but excluding**
`past-the-end`.

So, for example, `[0, 3) = [0, 1, 2]`, while `[0, 1) = [0]`, and `[0, 0) = []`.


I am not allowed to use `[begin, end]`, or `(before-begin, past-the-end)` or
any such variation I represent and think of intervals.

##### Rule 2: No relational operators when using `for/while/do while` loops.

When I write my loop conditions, I am not allowed to use relational operators.
I must only write `i != n` or `i == m`.
I am not allowed to write `i < n`, `i <= n`, `i > n`, `i >= n` for my `for` loops.


##### Rule 3: The loop iterator lives in "getting to" space:

The loop iterator `i` in `for(int i = a; i != b; ++i)` is to be thought of as
getting to/living right before" the values `[a, a+1, a+2, ... b-1]`. In
ASCII-art:

```
|| a-1 || a   || a+1 || ... || b-1 ||  b  || b+1 ||
       ^^     ^^     ^^            ^^
     (i=a) (i=a+1)  (i=a+2) ...   (i=b)
```

##### Ruel 4: One always reads loops according to the above rules

```c
for(int i = begin; i != past-the-end; ++i) {
  // NO: i from begin to past-the-end.
  // YES: [i _getting to_ the beginning] till [i _getting_ past-the-end]
}
```

#### The rationale for banning relational operators

There is a strong difference in qualia between `i < n` and `i != n`. The former
makes on aware of when the loop runs; the latter of when the loop quits.

I wish to be cognizant of the precisely when a loop quits.
On writing `i != past-the-end`, I know that we quit as soon as we
**get past the end**. This feels much clearer than being aware that the loops
runs as long as `i < n`.

#### half-open indexing: length <-> index

The first advantage of these conventions is that
`[begin, past-the-end)` is the same as `[begin, begin+length)`. I've found this
to be of great help to flit between length-based-thoughts and
indexing-based-thoughts.


#### half-open indexing: `0` length

The second almost trivial point is that `[begin, begin+length)` holds when
`length` is **zero**. That is,

```c
for(int i = begin; i != begin + 0; ++ i) { ... }
```

does the right thing and iterates over no elements.


#### half-open indexing: `-ve` length

The third neat point is that `[begin, begin+length)` holds even when `length`
is **negative**. Hence, if we want to index the last two elements of an
array, we recall that we start from index `(n-1)`, and we want a segment
of length `-2` from there, so our loop is:


```c
for(int i = n-1; i != (n-1) + -2; i--) {
 // loops over the correct segment.
}
```


#### half-open indexing: splitting an array

Finally, this convention helps when attempting to take the beginning part
of a list and the rest of the list. If we want to split an array into
two segments at some index `len`,

- The first sub-array is `[0, len)` since it starts at location `0` and has
  length `len`.
- Since we have taken `len` elements, the second sub-array must have length
  `n-len`. It must start at index `len` since `len` is past-the-end for the
  first sub-array. So, the second sub-array has indeces `[len, n-len)`.

Notice how we used _both_ the "length view" and the "past the end" view to
quickly derive the bounds of the second array from the first array.

#### half-open indexing: uniformly generate power-of-2 intervals.

If we want intervals of length $2^n$: `1, 2, 4, 8, ...` which is common if one
is building data structures such as segment trees and fenwick trees,
in a half-open representation, this literally becomes `[a, a+1)`,
`[a, a+2)`, `[a, a+4)` and so on. On the other hand, if one wants
to use closed interval based indexing, one needs to generate the
series $2^n - 1$, which is `[a, a+0]`, `[a, a+3]`, `[a, a+7]` which is
slightly more finicky.

#### How to deal with strides

If there's a loop

```c
for(int i = 0; i < 5; i += 2) { ... }
```

the naive `i != 5` translation will not work since `i` only takes
on even numbers `[0, 2, 4, 6, ...]`. For this, we can perform a
simple transformation and always make sure our loop variables increment
by `1`. In a compiler, this is often called as "canonicalizing the loop
induction variable". In LLVM the canonicalization is
[performed by the `-indvars` pass](https://llvm.org/docs/Passes.html#indvars-canonicalize-induction-variables).
The above example canonicalized becomes:

```c
// btc = backedge taken count. How many times we have
// gone past the "back edge" of the loop to go back to the
// beginning of the loop.
for(int btc = 0; btc != 5 / 2; btc += 1) { const int i = btc * 2; }
```


#### In conclusion

These are rules that I dreamed up after noticing my idiosyncracies in
loop-writing.



# Algebraic structure for vector clocks

_I_ update my time, ie, union(time me, time me), I get an element that's one up the lattice.
When I union with someone else, I get the max. So we have an algebraic structure
which is $(L, \leq, next: L \rightarrow L)$ where `next` is monotone for `(L, <=)`.
The  induced union operator $\cup: L \times L \rightarrow L$ is:

$$
x \cup y \equiv \begin{cases} \texttt{next}(x) & x = y  \\ \max(x, y) & x \neq y \end{cases}
$$

- Is the total ordering on vector clocks *not* isomorphic to the total ordering on $\mathbb{R}$?


This also shows up in the case of the "Gallager-Humblet-Spira Algorithm" and
the fragment-name-union-rule.

# Networks are now faster than disks

I learnt of this counter-intutive fact first from this
[usenix article no SQL](https://www.usenix.org/legacy/publications/login/2011-10/openpdfs/Burd.pdf).
On checking up, it seems to actually be true.

[Jeff Dean's keynote at LADIS 2009](https://research.cs.cornell.edu/ladis2009/talks/dean-keynote-ladis2009.pdf) report these numbers:

- Round trip within same datacenter: 500,000 ns
- Disk seek: 10,000,000 ns [regular disk]

On the other hand, a commentor on [this discussion at serverfault](https://serverfault.com/questions/238417/are-networks-now-faster-than-disks)
mentioned that SSDs might be much faster, and the numbers bear out:

- Read 4K randomly from SSD: 150,000 ns
- Round trip within same datacenter: 500,000 ns
- Disk seek: 10,000,000 ns [regular disk]

# Einstein-de Haas effect

I learnt of this from hacker news. This is some crazy experiment that shows
that the 'quantum angular momentum' (spin) and the 'classical angular momentum'
need to be conserved _together_ for physics to work out:

> There's an experiment that transfers that angular momentum all the way up to
> macroscopic levels. By magnetizing a cylinder of iron, all the spins start
> pointing in the same direction. By conservation of angular momentum, the
> cylinder itself has to start spinning in the opposite direction. I'm very
> fond of this experiment, because it magnifies a strange quantum phenomenon to
> the classical level.

So, my understanding of the experiment is:

- classical angular momentum and quantum angular momentum are related.
- quantum angular momentum is decomposed into spin and orbital angular momentum.
- for something like iron, spin is 96% of magnetization
- angular momentum is proportional to magnetization
- So, the experiment measures the _spin_ (mostly) in terms of the classical
  spinning of the cylinder.


##### References

- [Einstein-de Hass effect on Wikipedia](https://en.m.wikipedia.org/wiki/Einstein%E2%80%93de_Haas_effect)




# Rank-select as adjunction

We will introduce two operations `rank`, `select`, --- these are used to
build memory-efficient data structures that can still be queried quickly.

We will show how `rank` and `select` are adjoint. This will also us to also
consider `coselect`, which is a variation of `select` that is not commonly
discussed.

```hs
{-# LANGUAGE GeneralizedNewtypeDeriving #-}

import Data.List
newtype Count = Count Int deriving(Eq, Show, Ord, Num)
newtype Ix = Ix Int deriving(Eq, Show, Ord, Num)


eqscan :: Eq a => a -> [a] -> [Count]
eqscan a0 as = map Count $ scanl (+) 0 [if a0 == a then 1 else 0 | a <- as]

-- | finds the index `Ix` in `as` at which `a` has occured
-- | for the `Count`th time.
select :: Eq a => a -> [a] -> Count -> Maybe Ix
select a0 as c = Ix <$> findIndex (== c) (eqscan a0 as)

-- | finds the number of times `a` has occured in `as` till `Ix`.
rank :: Eq a => a -> [a] -> Ix -> Count
rank a as (Ix ix) = (eqscan a as) !! ix
```

Given this, we can prove that `select` and `rank` are adjunctions. There
are different ways to think about this. My favourite way to is to notice
that an `Ix` (index) is much "finer" information than `Count`. Hence,
the concrete domain must be `Ix`, the abstract domain must be `Count`,
and rank-select is an abstract interpretation!

##### Co-select

We can build another version of `select` called `co-select` that scans
from the right. Alternatively, it finds on the reverse list:

```
coselect :: Eq a => a -> [a] -> Count -> Maybe Ix
coselect a0 as c = Ix <$> findIndex (== c) (reverse (eqscan a0 as))
```

Thanks to Edward Kmett for teaching me this.


# Bounding chains: uniformly sample colorings

We wish to _uniformly sample_ `k` colorings of a graph $G$ with maximum degree
$\Delta$. Hence, we require $k \geq \Delta + 1$. To perform this sampling,
we use MCMC to sample from a markov chain whose states are $k$-colorings of $G$,
whose stationary distribution is the uniform distribution over valid colorings.


The issue with MCMC techniques is that we never know when our chain has reached
the stationary state. To ensure we receive uniformly distributed samples,
we built a "bounding chain" $W$ which has the following properties:

- States of $W$ cover states of $X$ [ie, state space of $W$ are subsets of the state space of $X$].
- $W$'s convergence to a stationary state can be checked.
- Upon convergence of $W$, state of $W$ = state of $X$.

We will in fact run the $W$ chain, and prove that running the $W$ chain
is equivalent to running a 'shadow' of the $X$ chain, and that stationary
states of the $W$ chain correspond to stationary sates of the $X$ chain.

Let $X$ be the chain whose states are valid $k$ colorings of $G$. In one step
of the chain $X$, we choose a vertex $v$ uniformly at random; we then choose a
color $c'_v$ uniformly at random for $v$ that makes it a proper coloring. The vertex
$v$ is changed to this new color $c'$. This is a symmetric proposal distribution,
Hence this chain has the uniform distribution over $k$-colorings to be
the stationary state.

Sampling exactly from this chain is hard: construct an initial state $X_0$
amounts to finding some valid $k$ coloring which in itself might be
challenging. Worse, we do not know whether the chain $X$ has reached a
stationary state or not.

##### Bounding Chain

We construct a new chain $W$ (the bounding chain of $X$), whose states are _sets of colors_ for
vertices in $G$. Formally, the states of $W$ are functions $Vert(G) \rightarrow 2^C$ where
$Vert(G)$ denotes the vertices of $G$; $C$ the set of colors. The transition
will be to pick a vertex $v$ uniformly at random. Then, pick a new set of
legal colors $C'_v$ for $v$, such that:

- It is guaranteed that if $X$ were transitioning on $v$, the
  color $c'_v$ that would be picked by $X$ for $v$ is a member of $C'_v$. [state is covered]
- The size of the set $C'_v$ attempts to be smaller than the current set of colorings $C_v$. [convergence]

We describe the transition function next. But first, we need an alternate
lens on the transitions of $X$ that is amenable to massaging.

#### Equivalent description of the transitions of $X$:

1. Choosing a color uniformly at random from the set of valid colors
   for a vertex.
2. Choosing colors from $C$ without replacement until we get a color
   that is a valid color.

We claim that (1) and (2) have the same probability distribution.

Abstracting slightly, we state:

1. Probability of choosing an element $t \in T$ uniformly from  $T \subseteq S$.
   This has probability $1/|T|$.
2. Probability of choosing a particular element $t \in T$, by picking elements
   from $S$ without replacement until we get some element in $T$.

(1) and (2) have the same probability distribution.

##### Proof by induction:

Process (2) in code is the following:

```py
def process(S, T):
  assert(issubset(T, S)) # precondition
  s = np.random.choice(S) # uniform choice over S.
  if s in T: return s # |T|/|S| prob. to enter `if`.
  else:
    # (1 - |T|/|S|) to enter `else`
    Snext = S.remove(s); return process(Snext, T)
```


We claim that the probability that `process(S, T) = t0` for a fixed `t0` in `T`
is $1/|T|$. We create a new function `indicator` to express this:



```py
def indicator(t0, S, T):
  assert(t0 in T) # precondition
  assert(issubset(T, S)) # precondition

  return t0 == process(S, T)
```

Let's push in `t0 ==` into the definiton of `process` after inling `process`.
This gives us:

```py
def indicator(t0, S, T):
  assert(t0 in T) # precondition
  assert(issubset(T, S)) # precondition

  s = np.random.choice(S)
  if s in T:
    # T/S prob. for x in T
    return t0 == s # 1/|T| prob. for t0 == x
  else:
    #  (1 - |T|/|S|) to reach else branch.
    Snext = S.remove(s); return process(Snext, T)

```

Now, we write down the recurrence for the probability that we are trying
to compute: $P(t0, S, T)$ is the probability that `indicator(t0, S, T)` returns
`True`. Alternatively, it's the probability that `process(S, T)` returns `t0`.

```
P(t0, S, T) = prob. that process(S, T) = t0
P(t0, T, T) = T/|T| * 1/|T| = 1/|T| [base case]
P(t0, S, T) = 1/|S| + (1 - |T|/|S|) * P(t0, |S|-1, T) [induction]
```

We assume for induction that `P(t0, |S|-1, T) = 1/|T|`. On substitution into `[induction]`,
we get:

```
P(t0, S, T)
= 1/|S| + (1 - |T|/|S|) * P(t0, |S|-1, T) [induction]
= 1/|S| + (1 - |T|/|S|) * 1/|T|
= 1/|S| + (1/|T| - 1/|S|)s
= 1/|T|
```
Which is indeed the same probability as (1):

> 1. Choosing an element uniformly from a subset $T$ = `1/|T|`.

##### Proof by program analysis, Version 1

```py
def process(S, T):
  s = np.random.choice(S)
  if s in T: return s
  else return process(S.remove(s), T)
```

Notice that the last return is tail-call. This program can be rewritten as:

```py
def process(S, T):
  while True:
    s = np.random.choice(S)
    if s in T: return s
    S = S.remove(s)
```

As previously, we create an `indicator` function and study its behaviour:

```py
def indicator(t0, S, T):
  assert(t0 in T) # precondition
  assert(issubset(T, S)) # precondition

  while True:
    s = np.random.choice(S)
    if s in T: return t0 == s
    S = S.remove(s)
```

We know that this programs only returns a value from the line:
- `if s in T: return t0 == s`

We now compute `P(process(S, T) == t0)`.
Whatever the return value of `indicator`, we can assume that it occured within
the `if` condition. We can use this to compute:

```
P(indicator(t0, S, T) = True)
 = P(t0 == s | s in T) [program only returns in this case]
 = 1/|T|
```

##### Proof by program analysis, Version 2


Alternatively, we can also analyze this as we did in the _first_ proof,
using the rule:

```py
def f():
  return if cond1 then cond2 else cond3
```

will have probability:

```
P(cond1) * P(cond2|cond1) + P(not cond1) * P(cond3|not cond1)
```

Using this, we can analyze `indicator `as:

```
P(indicator(t0, S, T) = True)
 = P(s in T) * P(t0 == s |s in T) +
    P(s not in T) * P(indicator(t0, S.remove(s), T) | s not in T)
 = |T|/|S| * 1/|T| +
    (|S|-|T|)/|S| * P(indicator(t0, S.remove(s), T))
 = 1/|S| + (|S|-|T|)/|S| * 1/|T| [by induction]
 = 1/|T|
```

#### Sampling using the above definition

Recall that $State(X) \equiv V \rightarrow C$, $State(W) \equiv V \rightarrow 2^C$.
Let $x[~], w[~]$ be the states of some run in the markov chains.

We start by having $x[0]$ to be _any_ valid k-coloring of $G$, and $w[0]$ to
be the state where all vertices have all possible colors; $w[0] \equiv \_ \mapsto C$.
Clearly, $x[0] \in w[0]$.


By induction we assume that $x[n-1] \in w[n-1]$. We must now calculate a
$w[n], x[n]$ such that (1) $x[n] \in w[n]$, (2) $x[n]$'s proposal is symmetric.
(3) $w[n]$'s proposal is symmetric.

##### Occluded set $O$

Define $O \subseteq C$ (for occluded) be the set colors that might possibly
be blocked for $v$ from our view of `w`. Note that this is an
**over-approxmation**: that is, there may be colors that are not blocked for `v`, which we
believe to be blocked from `w`'s point of view.

$$O \equiv  \{ c \in C : (v, \alpha) \in E, c \in w[n-1](\alpha) \}$$

##### Allowed set $A$

Define $A \subset C$ (for allowed) to be $C - O$. Note that $A$ is
an **under-approxmation**, since `O` was an _over-approximation_. That is:
- Any color in `A` is definitely a legal color for `v` in `x[n]`.
- There are colors which are legal for `v` in `x[n]` that is not in `A`.

##### S: the sequence of states for transition

Now, we pick elements of $C$ in sequence till we get an element of `A`.
call this sequence $S$.

We will at worst pick $\Delta + 1$ elements for $S$, since the max-degree
of the graph is $\Delta$.

##### Transition

Let $i$ be the first index in $S$ where we get a color that is _truly legal_
for $v$ in $x[n]$. Note that such an index will always exist: We pick
elements into $S$ till we get an element in $A$, and elements of $A$ are
always legal. However, there can be elements which are not in $A$ that
are still legal for $v$ in $x[n]$, since $A$ is an under-approximation.

- We assign $x[n](v) = i$. So, `x` only cares about `S[:i]`.
- We assign  $w[n](v) = A$. So, `W` cares about the entire sequence.

By the lemma proven, we know that this process of picking colors `C`
in a sequence till we get a color that is legal for $v$ at index $i$
is the same as picking uniformly at random from the set of colors that are legal for
$v$.


#### An example
For example, we could have:

```
X | p:2 --- q:4
W | p:{1, 2} --- q:{4, 5}

we are sampling q:

O = {1, 2}
A = {3, 4, 5}
S = [2, 1, 3]

X | p:1 -- q:2
W | p:{1, 2} -- q:{1, 2, 3}
```

If we analyze `S = [2, 1, 3]` we notice that:

```
2: invalid for W(p:[1, 2]), invalid for X(p:2)
1: invalid for W, valid for X
3: valid for W, valid for X
```

So, what we are really sampling ix:
- A _prefix_ sequence `SX = [1]` (for Xs transition)
- A _leftover_ sequence `SW = [2, 3]` (for Ws transition)


To transition `X`, we can safely drop `SW`. However, to transition `W` correctly,
we generate more elements in the sequence, till we hit a "safe" element.


#### An optimisation on picking colors: why we need a blocking set


Define the set $B \subseteq C$ (for blocked) which governs which values
$x[n]$ **surely cannot take** from our view of $w[n-1]$.
Note that $B$ is an **under-approximation**. `v` might have
more colors that are blocked than what `w` sees.

$$B \equiv \{ c \in C : (v, \alpha) \in E, w[n-1](\alpha) = \{c\} \}$$

Rather than sampling colors from `C` till we get an element of `A`, we can
sample colors from `C/B`. We know that the colors in `B` can **never** be used
by $X$, since the colors in `B` are those that we know are blocked **for sure**.

This is used in the theoretical analysis of the paper.

#### Termination

We terminate when $W$ has "trapped" $X$. That is, $|w[n](v)| = 1$ forall $v \in V$.
In such a case, the states of $W$ is equal to states of $X$. This is
a coalescence (as it occurs in coupling from the past). From the coupling
from the past theory, we know that we have reached a stationary state of $A$
when this happens.


#### Pseudocode

```hs
-- | colors, vertices, edges
cs :: [C]; cs = ...
vs :: [V]; vs = ...
es :: [(V, V); es = ...


-- | definitely not allowed
blocked :: (V -> [C]) -> (V -> [C])
blocked v2cs v0 = concat [v2cs w | (v, w) <- es, v == v0, length (v2cs w) == 1]


-- | maybe not allowed
occluded :: (V -> [C]) -> (V -> [C])
occluded v2cs v0 = concat [v2cs w | (v, w) <- es, v == v0]

-- | definitely allowed from Ws point of view
allowed :: (V -> [C]) -> (V -> [C])
allowed v2cs = cs \\ occluded v2cs

-- | perturb the color function to another function
perturb :: (V -> [C]) -> Rand (V -> [C])
perturb v2cs = do $
  randv <- uniform_rand vs
  randc_for_v <- uniform_rand (allowed v2cs v)
  return $ \v -> if v == randv then randc_for_v else v2cs v


-- | check if we are done
terminated :: (V -> [C]) -> Bool
terminated v2cs = all [length (v2cs v) == 1 | v <- vs]

-- | generate chain
chain :: (V -> [C]) -> Rand [V -> [C]]
chain f = do
  if terminated f
  then [] else do
    f;' <- perturb f; fs <- chain f'; return (f:fs)

-- | return a sample
sample :: (V -> [C]) -> Rand (V -> [C])
sample = last . chain

```



##### References

- [Exact Sampling and Approximate Counting Techniques](https://dl.acm.org/doi/10.1145/276698.276709)

# Coupling from the past

##### Relationship between CFTP and reset transitions

##### References
- [Dan piponi, running from the past](http://blog.sigfpe.com/2018/10/running-from-past.html)
- [Coupling from the past, a user's guide](https://pdfs.semanticscholar.org/622e/a9c9c665002670ff26119d1aad5c3c5e0be8.pdf)


# Word problems in Russia and America

- [link to article by *Andrei Toom*](http://toomandre.com/travel/sweden05/WP-SWEDEN-NEW.pdf)

scathing critique of how ameriacn math education is screwed:
 also, interesting
anecdote about how looking for 'reality' in mathematical problems may in fact
break student's ability to think in the abstract! This is a deep insight.

# Encoding mathematical hieararchies

I've wanted to learn how the SageMATH system is organized when it comes to math
hieararchies. I also wish to learn how `lean4` encodes their hiearchies. I know
how mathematical components does it. This might help narrow in on what what the
"goldilocks zone" is for typeclass design.

##### References

- [Slides : Infrastructure for generic code in `SageMath`](https://cicm-conference.org/2016/slides/I3.pdf)
- [Tabled typeclass resolution](https://arxiv.org/abs/2001.04301)
- [Mathematical components, the book](https://math-comp.github.io/mcb/)



# Learning code by hearing it

I learnt of this from an amazing discussion on HackerNews, where a sighted
programmed, who is going blind, asked the community if he could remain
a software engineer. An answer by `kolanos` read:

> You can definitely continue as a software engineer. I'm living proof. ...
> For example, as you get better with a
> screen reader, you'll be bumping the speech rate up to 1.75-2X normal speech.
> ... Typos will be easily spotted as they just won't "sound right". It will be
> like listening to a familiar song and then hitting an off note in the melody.
> **And this includes code**. Also, because code is no longer represented
> visually as blocks,
> you'll find you're **building an increasingly detailed memory model of your code**.
> Sighted people do this, too, but they tend to visualize in their mind. When
> you abandon this two dimensional representation,
> **your non-visual mental map suffers no spatial limits**. You'll be amazed
> how good your memory will get without the crutch of sight.

I find this incredibly fascinating. I think I'm going to try this: I'll listen
to lectures on `1.5-2x` anyway, so this may work just as well. I'm planning
on trying this with the MLIR codebase, which I want to get to know intimately.
I'll write updates on how this goes.

[Drew DeVault](https://drewdevault.com/) also posted links to tools/scripts
for programming without needing visual feedback:
- [vimspeak.vim](https://git.sr.ht/~sircmpwn/dotfiles/tree/master/lib/vim/vimspeak.vim)
  for, if I understand correctly, speaking out loud the current state
  [which buffer, which mode, what line], as well as reading out text from
  the buffer.
- [An extension to the Sway tiling window manager](https://git.sr.ht/~sircmpwn/dotfiles/tree/master/bin/swaytalk)
  for providing audio cues.

I also learnt about [emacspeak](http://emacspeak.sourceforge.net/), which
supposedly works well for an audio-based-workflow.


- [https://news.ycombinator.com/item?id=22919455]

### Setting up festival

It seems that festival is the best(?) TTS engine for linux. One should
1. install `festival`
2. install the voice packs, given by the name `festvox-*`.
3. The best (?) festival voice is supposedly in the package `festvox-us-slt-hts`,
   with voice name `voice_cmu_us_slt_arctic_hts`. The pacakge is also available at
   the debian site: https://packages.debian.org/sid/all/festvox-us-slt-hts/download
4. edit the festival config file `/etc/festival.scm` and add a line

```
; the ' is important to escape the string
; (set! voice_default '<voice-name>)
(set! voice_default 'voice_cmu_us_slt_arctic_hts)
```

### Setting up SVOX pico2wave

- Ubuntu package: `sudo apt install libttspico-utils`
- Run instructions:

```
#!/bin/bash
pico2wave -w=/tmp/test.wav "$1"
aplay /tmp/test.wav
rm /tmp/test.wav
```



# Your arm can be a spinor

I tend to forget the name of this trick. It exhibits spinors in real life:
a system that needs to rotate by 720 degrees to return back to its
original state, versus the usual 360 tha we are generally used to. We need
to consider our entire arm + cup we are holding as a system for this to work.

- ['Plate trick'](https://en.wikipedia.org/wiki/Plate_trick)
- [Baliense cup trick](https://www.youtube.com/watch?v=Rzt_byhgujg)


# Self modifying code for function calls: Look ma, I don't need a stack!

If one does not have recursive calls, one can eliminate the need to push
return addresses on a call stack by writing self-modifying code ---
I leant of this from TAOCP, volume 1.
Knuth shows this off once he introduces `MIXAL`, his fantasy
aseembly language in which TAOCP programs are written.

I'll explain the usual way one performs call-return, then explain the nifty
self-modifying-code way. I think this is the cleanest, most accessible
example of self-modifying-code that I know.

#### The traditional solution for `call/ret`

We wish to have function `f` call function `g`. For `g` to be able to
return control to `f`, `f` pushes a return address into the call stack,
that `g` pops and `jmp`s to `f`s body. In code:

```text
START_F:
      ...
L0    push addr(L0); location of instr to be run after call.
      jmp START_G
L1:   <code after call>

=========

g's body
START_G:
      ...
      retloc = pop ; pop location to jump to
RETG: jmp retloc

```


Rather than `push` ing and `pop` ing, we can _rewrite_ the code of `g`, to
_change_ `retloc` before a call to `g`. In made-up-pseudocode, here's what that
would look like:


#### The jump based solution

```text
* f's body
START_F:
      ...
L0    store loc(RETG) assemble(jmp addr(L1))
      jmp START_G
L1:   <code after call>

=========

* g's body
START_G:
      ...
RETG: <###-to-be-filled-dummy-###>
```

instead of having a call stack, before `f` calls g, `f` modify `g`'s code at location `RETG`
into a `jmp` instruction by `store` ing the instruction `jmp addr(L1)`.
This effectively creates a 'custom' `g` that knows how  to return
control flow into `f`.

```
* g's body (after execution of L0)
START_G:
      ...
RETG: jump addr(L1)
```

This way, we have obviated the need for a `push/pop` sequence, by directly
modifying `g`'s code. This is really neat --- we replace the overhead of
a `push/pop` with a single `store`.

#### Why recursion breaks.

We don't actually need a call stack, as long as we don't want to write recursive functions.
We can't have recursion, or more generally "re-entrance": consider a call chain of the form:

- `A -> B -> C -> B`.
- during `A -> B`, `A` will scribble a `<return to A>` into `B`.
- during  `B -> C`, `B` will scribble a `<return to  B>` into `C`.
- during `C -> B`, `C` will scribble `<return to C>` into `B`,
  **destroying the previous `<return to A>` **.
- This creates a cycle, where `C` will attempt to return to `B`
  and vice versa.


# Adjunctions as advice

An adjunction `F |- U` allows us to go from `F a -> x` to `a -> U x`. We
can look at this as shifting the "before-advice" from the _input_ to an
"after advice" of the _output_, where I'm using
<!-- [advice in the CLOS/LISP sense](https://en.wikipedia.org/wiki/Advice_(programming)) -->

Also, to remember this, we can write it as:

```
F a <--F--- a
|           |
v           v
x ----U--> U x
```

Where `F` is for `F`ree and `U` is for forgetf`U`l.
Recall that if `F` is free and `U` is forgetful, then `U(F(x)) = x`, since
adding more structure through the free functor and then stripping it away gives
us the object back. We can prove that if `U(F(x)) = x` and `U, F` are functors,
then we have a function `fwd: (f a -> x) -> (a -> u x)` as:

```
f      :: (f a -> x)
fmap   :: (p   -> q) -> (u p     -> u q)
fmap   :: (p   -> q) -> (u ( p ) -> u q)
fmap f :: (f a -> x) -> (u (f a) -> u x)
fmap f :: (f a -> x) -> (a       -> u x) [using u (f a) = a]
```




#### References

- [Profunctor optics: the categorical approach, `33:00` onwards](https://www.youtube.com/watch?v=l1FCXUi6Vlw)



# Reversible computation as groups on programs

If we consider a language like [`Janus`](https://en.wikipedia.org/wiki/Janus_(time-reversible_computing_programming_language)
where every program is reversible, we can then get a group structure on
programs with the identity program not computing anything at all, the inverse
performing the reverse operation.

Alternatively, one can use the trick from quantum mechanics of using anciliary
qubits to build reversible classical gates.

The question is, do either of these approaches allow for better-than-STOKE
exploration of the program space? Ie, can we somehow exploit the
discrete group structure (in the case of Janus) or the Lie group structure
of the unitary group (as in the QM case) to find programs in far quicker ways?

# Blazing fast math rendering on the web

So, I've shifted the blog to be static-site-generated using a
static-site-generator written by yours truly. The code clocks in at around a
thousand lines of C++:

- [bollu/bollu.github.io/builder/builder.cpp](https://github.com/bollu/bollu.github.io/tree/master/builder/builder.cpp)

What did I gain?

1. My generator is a real compiler, so I get errors on math and markdown
  malformation.
2. I can write math that _loads_ instantly on your browser, using no MathJax,
   KaTeX or any client side processing, _nor_ the need to fetch images, which looks like this:

$$
h(x) \equiv
\begin{cases}
\int_{i=0}^\infty f(x) g(x) dx & x > 0 \\
\sum_{i=0}^\infty f(x) + g(x) & \text{otherwise}
\end{cases}
$$

#### Why?

My blog is a [single 9000 line markdown file](https://github.com/bollu/bollu.github.io/blob/master/README.md),
rendered as a _single HTML page_, so I
_need it to compile fast, render fast, render beautiful_.
Existing tools compromise on one or the other.

#### No seriously, why a single markdown file?

I need a single file to edit, so I can rapidly jot down new ideas. This is
the essence of why I'm able to log most of what I study:
_because it's seamless_.

Far more importantly, it provides **spatio-temporal locality**. I add things
in chronological order to tbe blog, as I learn thing. If I need to recall
something I had studied, go to that location in the blog
_based on a sense of when_.

When I do get to a location I want, the scrollbar gives me a sense of
_where I am_ in the file.  this is important to me, since it hepls me reason
spatially about what i know and what I've learnt. It's someting I love about
books, and deeply miss when navigtaing the web.I'm determined to keep this
spatio-temporal locality on my little slice of the internet.

#### Why is this awful?

As elegant as this model is to _edit_, it's awful for browsers to render. The
file used to take on the order of minutes for all the math to finish
rendering. MathJax (and KaTeX) painfully attempt to render each
math block. As they do, the page jumps around until everything has settled.
As this is happening, your CPU throttles, your lap or hand gets warm,
and the page is stuck. Clearly not great UX.

I still want math. What do I do?  The solution is easy: Approximate the math
rendering using ASCII/UTF-8 characters!  There are tools that do this ---
[`hevea`](http://hevea.inria.fr/) is one of them. Unfortunately, there is no
markdown-based-blogging-platform that uses this, so I _had_ to write my own.

#### The cure

The solution is easy. I wrote the tool. The page you're reading it
is rendered using the tool. All the math renders in under a second because
it's nothing crazy, it's just text and tables which browsers know how to
render. No JavaScript necessary. snappy performance. Whoo!

#### The details: Writing my own Markdown to HTML transpiler.

the final transpiler clocks in at `1300Loc` of C++,
which is very small for a feature-complete markdown-to-HTML piece of code
that's blazing fast, renders math correctly, and provides error messages.

#### Quirks fixed, features gained.

I got quite a bit "for free" as I wrote this, fixing mild annoyances
and larger pain points around using github + markdown for publishing on
the web:

- I really don't want tables, but I do want the ability to write vertical bars
  `|` freely in my text. Unfortunately, github _insists_ that those are tables,
   and completely wrecks rendering.

- I get line numbers in code blocks now, which Github Flavoured Markdown
  did not have.

- I get error messages on incorrectly closed bold/italic/code blocks, using
  heuristics that prevent them from spanning across too many lines.

- I get error messages on broken latex, since all my latex passes through
  `hevea`. This is awesome, since I no longer need to refresh my browser,
  wait for mathjax to load, go make myself tea (remember that mathjax was slow?),
  and then come back to see the errors.

- I can get error messages if my internal document links are broken. To be
  fair, my tool doesn't currently give me these errors, but it can (and soon
  will).

- In general, I get _control_, which was something I did not have with
  rendering directly using Github, or using someone else's tool.

#### Choice of language

I choose to write this in C-style-C++, primarily because I wanted the tool
to be fast, and I'd missed writing C++ for a while. I really enjoy how
stupid-simple C style C++ turns out to be: the C++ papers over some of C's
annoyances (like formatted output for custom types), while still preserving the
KISS feeling of writing C++.

**Why not Rust?** I freely admit that rust might have been a sane choice as
well.  unfortunately, asking rust to treat UTF-8 string as a "ball of bytes" is
hard, when it's stupidly easy with C. Plus, I wanted to use arena-style-allocation
where I make _huge_ allocations in one go and then don't think about memory,
something that I don't have control over in Rust. I don't have any segfaults
(yet, perhaps), thanks to UBSAN and ASAN. I find Rust to have more impedance
than C on small applications, and this was indeed small.


#### Performance

Everything _except_ the latex to HTML is blazing fast. Unfortunately,
calling `hevea` is slow, so I implemented a caching mechanism to make using
`hevea` not-slow. `hevea` does not have an API, so I need to `fork` and
talk to its process which is understandably flow. I built a "key-value-store"
(read: serialize data into a file) with the stupidly-simple approach of writing
an append-only log into a file. `hevea` is a pure function conceptally,
since on providing the same latex input it's going to produce the same HTML
output, so it's perfectly safe to cache it:

```cpp
const char DB_PATH[]="./blogcache.txt";
unordered_map<ll, const char *> G_DB;
void loadDB() {
    G_DB = {};
    FILE *f = fopen(DB_PATH, "rb");
    ...
    while (!feof(f)) {
        ll k, len;
        fread(&k, sizeof(ll), 1, f); if (feof(f)) break;
        fread(&len, sizeof(ll), 1, f);
        ...
        char *buf = (char *)calloc(sizeof(char), len + 2);
        fread(buf, sizeof(char), len, f);
        ...
    }
    fclose(f);
};

const char *lookup_key(ll k) {
    unordered_map<ll, const char *>::iterator it = G_DB.find(k);
    if (it == G_DB.end()) { return nullptr; } return it->second;
};

void store_key_value(const ll k, KEEP const char *v, const ll len) {
    assert(G_DB.count(k) == 0);
    G_DB.insert(make_pair(k, strdup(v)));

    FILE *f = fopen(DB_PATH, "ab");
    assert(f != nullptr && "unable to open DB file");
    fwrite(&k, sizeof(ll), 1, f);
    fwrite(&len, sizeof(ll), 1, f);
    fwrite(v, sizeof(char), len, f);
    fclose(f);
}
```

#### For the future

I plan to rip out `hevea` and write my own `latex -> HTML` converter for
the _subset of LaTeX I actually use_. `hevea`'s strength is its downfall:
It can handle all of LaTeX, which means it's really slow. If I can concentrate
on a small subset, I don't need to play caching tricks, and I can likely
optimise the layout further for my use-cases.

I also want colored error messages, because who doesn't?

I'll probably gradually improve my static site generator over time. Once it's
at a level of polish where I'm happy with it, I'll spin it out as a separate
project.

#### Conclusions

Am I glad I did it? Yes, purely because my chunk of the internet aligns with
how I want it to be, and that makes me $\epsilon$ more happy.

I think of it as an investment into future me, since I can extend the
markdown and the transpiler in the way _I_ want it to be.

# VC dimension

Consider a ground set $X$. Let the space of all possible binary classifications
be the function space $C \equiv \{ f \mid f : X \rightarrow \pm 1 \}$.
Now, a hypothesis class $H$ is a subset of $C$. For example, some model
such as "return $+1$ if a point is inside a region, $-1$ otherwise" is a subset
of the full class $C$.

The VC dimension of $H$ measures how good $H$ is generating different classification.
We first need the notion of shattering to define this.

A subset $S \subseteq X$ of the ground set shatters a hypothesis class $H$
if the function $act_S$ has full range, where $act_S$ is defined as:

$$
act_S: H \rightarrow |S|^{\{0, 1\}}
act_S(h) = (h(s_0), h(s_1), h(s_2), \dots, h(s_n))
$$

That is, the hypothesis class $H$ can classify all the subsets of $S$.

Now the **VC dimension of the hypothesis class $H$ of a ground set $X$** is
the size of **largest possible $S \subseteq X$** such that $S$ is shattered
by $H$.

#### Correct interpretation
- We need _just one set_ $S$ of size $n$ to be shattered by $H$. We get
  to pick the set $S$.

#### Subtletly 1:
- We do not need _all sets_ of size $n$ to be shattered by $H$.

We **can** have the case where:

- All sets of size 3 are shattered by H
- Only one set of size 4 is shattered by H. All other sets of size 4 are not.
- Only one size of size 5 is shattered by H. All other sets of size 5 are not.
- No set of size 6 is shattered by H.

In this case, the VC dimension of $H$ is **5, not 3**.

#### Subtletly 2:

We **cannot** have the case where:
- All sets of size 3 are shattered by H
- No set of size 4 is shattered by H
- Some set of size 5 is shattered by H

For contradiction, let $S$ be the set of size $5$ that is shattered by $H$.
Let $T \subsetneq S$, $|T| = 4$. Now, $H$ shatters $T$ since $H$ shatters $S$.
Hence, Some set of size 4 has been shattered. Contradiction, since we assumed
that no set of size 4 is shattered by $H$.

So, to prove that sets of size $(\geq n)$ cannot be shattered, it suffices
to prove that sets of size equal to $n$ cannot be shattered.

#### Growth of number of sets shattered in $|S|$ for $S \subseteq X$ for a fixed $H$.

If we fix a hypothesis class $H$ for $X$, and we want to understand how $H$
varies over subsets of $X$, the idea is this:

Let $S$ be a set that is the maximum sized set that is shattered by $X$. ie,
$|S| = Vcdim(H)$ and $H$ shatters $S$.

Now, the idea is this:

- For subsets $T \subseteq S$, $|act_T(H)| = 2^{|T|}$ -- exponential.
- For subpersets $S \subsetneq Sup$, $|act_{Sup}(H) = Comb(|Sup|, |S)$ -- polynomial.

We can show that this exponential/polynomial behaviour happens in general
for $S \subseteq X$.

# Symplectic version of classical mechanics

#### Basics, symplectic mechanics as inverting $\omega$:

I've never seen this kind of "inverting $\omega$" perspective written down
anywhere.  Most of them start by using the inteior product $i_X \omega$ without
ever showing where the thing came from. This is my personal interpretation of
how the symplectic version of classical mecanics comes to be.

If we have a non-degenerate, closed
two-form $\omega: T_pM \times T_pM \rightarrow \mathbb R$.

Now, given a hamiltonian $H: M \rightarrow \mathbb R$, we can construct a
vector field $X_H: M \rightarrow TM$ under the definition:

$$
\begin{aligned}
&\text{partially apply $\omega$ to see $\omega$ as a mapping from $T_p$ to $T_p^*M$} \\
&\omega2: T_p M \rightarrow T_p*M \equiv \lambda (v: T_p M). \lambda (w: T_p M) . \omega(v, w) \\
&\omega2^{-1}: T_p^*M \rightarrow T_p M; dH: M \rightarrow T_p* M \\
&X_H \equiv \lambda (p: M) \rightarrow \omega2^{-1} (dH(p)) \\
&(p: M) \xrightarrow{dH} dH(p) : T_p*M \xrightarrow{\omega2^{-1}} \omega2^{-1}(dH(p)): T_pM \\
&X_H = \omega2^{-1} \circ dH
\end{aligned}
$$

This way, given a hamiltonian $H: M \rightarrow \mathbb R$, we can construct
an associated vector field $X_H$, in a pretty natural way.

We can also go the other way. Given the $X$, we can build the $dH$
under the equivalence:

$$
\begin{aligned}
&\omega2^{-1} \circ dH  = X_H\\
&dH = \omega2(X_H) \\
&\int dH  = \int \omega2(X_H)  \\
&H = \int \omega2(X_H)
\end{aligned}
$$

This needs some demands, like the one-form $dH$ being integrable. But this
works, and gives us a bijection between $X_H$ and $H$ as we wanted.

We can also analyze the definition we got from the previous manipulation:
$$
\begin{aligned}
&\omega2(X_H) =  dH \\
&\lambda (w: T_p M) \omega(X_H, w) = dH \\
&\omega(X_H, \cdot) = dH \\
\end{aligned}
$$

We can take this as a _relationship_ between $X_H$ and $dH$. Exploiting
this, we can notice that $dH(X_H) = 0$. That is, moving along $X_H$ does
not modify $dH$:

$$
\begin{aligned}
&\omega2(X_H) =  dH \\
&\lambda (w: T_p M) \omega(X_H, w) = dH \\
&dH(X_H) = \omega(X_H, X_H) = 0 ~ \text{$\omega$ is anti-symmetric}
\end{aligned}
$$

#### Preservation of $\omega$

We wish to show that $X_H^*(\omega) = \omega$. That is, pushing forward
$\omega$ along the vector field $X_H$ preserves $\omega$.

TODO.


#### Moment Map

Now that we have a method of going from a vector field $X_H$ to a Hamiltonian
$H$, we can go crazier with this. We can _generate vector fields_ using
Lie group actions on the manifold, and then look for hamiltonians corresponding
to this lie group. This lets us perform "inverse Noether", where for a given
choice of symmetry, we can find the Hamiltonian that possesses this symmetry.

We can create a map from the Lie algebra $\mathfrak{g} \in \mathfrak{G}$ to
a vector field $X_{\mathfrak g}$, performing:

$$
\begin{aligned}
&t : \mathbb R \mapsto e^{t\mathfrak g} : G \\
&t : \mathbb R \mapsto \phi(e^{t\mathfrak g}) : M \\
&X_{\mathfrak g} \equiv \frac{d}{dt}(\phi(e^{t\mathfrak g}))|_{t = 0}: TM
\end{aligned}
$$

We can then attempt to recover a hamiltonian $H_{\mathfrak g}$ from
$X_{\mathfrak g}$. If we get a hamiltonian from this process, then it
will have the right symmetries.


# Theorems for free

These are personal notes I made of a custom notation for denoting the relations
from the theorems for free paper. I developed the notation since I wanted
to keep track of what types are floating around and what the relations are doing.

We interpret types as sets.  If elements belong to the relation, ie, if `(a, a') ∈ R ⊂ AxA`,
we will denote this as `a[A -R- A']a'`. We will now write down some inference
rules:

1. We define `ReflB` as `a[Bool ReflB Bool]a`
2. We define `ReflI` as `i[Int ReflI Int]i`
3. The product of two relations `[A R B]`, `[X S Y]` is called as `RxS`,
   and is defined as: `(a,x)[AxX RxS BxY](b,y)` iff: `∀ abxy, a[A R B]b ∧ x[X S Y]y`.
4. The list space of a `[A R B]` is called `[A* [A R B] B*]`,
   and is defined as: `la[A* [A R B] B*]lb` iff:
   `∀ la lb, |la| = |lb| ∧ (∀ i, la[i][A R B]lb[i])`
5. The function space of two relations`[A R B]`, `[X S Y]` is called `[A->X R->S B->Y]`,
   and is defined as: `f[A->X R->S B->Y]g` iff: `∀ a b, a[A R B]b => f(a)[X S Y]g(b)`.
6. The type family space of two relations is a function that takes
   a relation `[A R B]` and produces a new relation:
   `g[FA | [A R B] | FB]h`. The relation takes as parameter a relation `[A R B]`
    for each choice.
7. The space of relations of `∀X.F(X)` is a relation defined by:
   `g[A->FA | ∀X.F(X) [FA [A R B] FB]| B->FB]h`
    `∀ A B R, (g A)[FA | [A R B] |  FB](h B)`.

#### Parametricity theorem

The parametricity thm states that for all terms `(r: R)`, we can deduce
`r[R rel(R) R]r` where `rel(R)` is the relation that fits the type, and is
derived from the above rules.

#### Parametricity for lists when the relation is a function:

The list space of a `[A R B]` is called `[A* [A R B] B*]`,
and is defined as: `la[A* [A R B] B*]lb` iff:
- `∀ la lb, |la| = |lb| ∧ (∀ i, la[i][A R B]lb[i])`

Now, let us take a special case where `[A R B]` is a function `δ: A -> B`. That is:
- `a[A R B]b` iff `δ(a) = b`.

If this is the case, then we can simplify the math to be:

- `la[A* [A R B] B*]lb <=> ∀ la lb, |la| = |lb| ∧ (∀ i, la[i][A R B]lb[i])`
- `la[A* [A R B] B*]lb <=> ∀ la lb, |la| = |lb| ∧ (∀ i, δ(la[i]) = lb[i]`
- `la[A* [A R B] B*]lb <=> ∀ la lb, map δ la = lb`

#### Parametricity to prove rearrangements

- `r[∀ X. X* -> X*]r`
- `(r A)[A*->A*  | [A*->A* [A R B] B*->B*] |  B*->B*](r B)`
- `as[A* [A R B]  B*]bs => (r A as)[A* [A R B] B*](r B bs)`
- Pick `[A R B]` to be a _function_ `δ: A -> B`. Ie, `a[A R B]b` iff `δ(a) = b`.
- This lets us convert all occrences of `α[A R B]ω` into `ω = δ(α)`.
- Hence, `as[A* [A R B]  B*]bs` becomes `map δ as = bs`.
- Hence, `(r A as)[A* [A R B] B*](r B bs)` becomes `map δ (r A as) = (r B bs)`
- In toto, this let us replace `bs` with `map δ as`. We derive:
- `map δ (r A as) = (r B bs)`
- `map δ (r A as) = (r B (map δ as)`
- `map δ . (r A) = (r B) . map δ`
- Replace `bs[i]` with `δ(as[i])`to get result:
   `δ(r A as[i]) = r B δ(as[i])`, which was indeed what we were looking for.


#### References
- [Theorems for free by Phil Wadler](https://ecee.colorado.edu/ecen5533/fall11/reading/free.pdf)

# How to reason with half-open intervals

I've always found code that uses half-open intervals far harder to write
than using closed intervals. For example, when performing string processing,
I prefer to write `closed` over `halfopen` since I find it easier
to think about:

```cpp
void closed(int begin, int end, char *c) { //easier
  for(int i = begin; i <= end; ++i) {... }
}

void open(int begin, int len, char *c) { //harder
  for(int i = begin; i < begin + len; ++i) { ... }
}
```

However, I realised that by changing how I think about this to:

```cpp
void open(int begin, int len, char *c) { //harder
  for(int i = begin; i != begin + len; ++i)
}
```

It somehow made it way easier to grok.

- I had problems with `<` since I would
  mentally shift from `i < begin + len` to `i <= begin + len - 1`. Making
  this move would then make _all other reasoning_ harder, since I had
  keep switching between the `<` and `<=` point of view.

- On the other hand, when using `i != begin + len`, there was a single location
  to focus on: the point `begin + len`, and what happens when `i` reaches it.

Of course, this is old had to anyone who performs loop optimisatison: LLVM
internally converts most comparisons into the `a != b` form, because it's
easier to analyse. It took me this long it's easier for me to _think_
in this viewpoint as well.


# How does one build a fusion bomb?

I haven't found anything on the internet that describes how to build
a fusion bomb; it's almost as if this information has been supressed
by governments. However, I'm curious --- would a physics grad student
studying nuclear physics or explosives have the theoretical know-how to
precisely build one, given the raw materials? Or is there some
"secret sauce" that's necessary?

I read on wikipedia that most countries classify the details:

> Detailed knowledge of fission and fusion weapons is classified to some
> degree in virtually every industrialized nation. In the United States,
> such knowledge can by default be classified as "Restricted Data",
> even if it is created by persons who are not government employees or
> associated with weapons programs, in a legal doctrine known as "born secret".

# Christoffel symbols, geometrically

Suppose we have a manifold $M$. of dimension $d$ that has been embedded isometrically
into $\mathbb R^n$. So we have a function $e: \mathbb R^d \rightarrow \mathbb R^n$
which is the embedding. We will identify $M$ to be the subspace $Im(e)$.

Recall that $\partial_{x_i} e : \mathbb R^d \rightarrow \mathbb R^n$
is defined as:

$$
\begin{aligned}
&\partial_{x_i}e : \mathbb R^d \rightarrow \mathbb R^n \\
&[\partial {x_i}e](p) \equiv
 \lim_{\delta x \rightarrow 0} \frac{e(p + (x_0=0, x_1=0\dots, x_i=\delta_x, \dots, x_n=0)) - e(p)}{\delta x}
\end{aligned}
$$

Note that it is a function of type $\mathbb R^d \rightarrow \mathbb R^n$.


- The tangent space at point $p \in Image(e)$ is going to be spanned by
  the basis $\{ \partial_{x_i}e \vert_p : \mathbb R^n \}$.
- The metric tensor of $M$,
 $g_{ij} \equiv \langle \frac{\partial e}{\partial x_i} \vert \frac{\partial e}{\partial x_j} \rangle$.
 That is, the metric tensor "agrees" with the dot product of the
 ambient space $\mathbb R^n$.
- A vector field $V$ on the manifold $M$ is by definition a combination of
  the tangent vector fields. $V(p_0) \equiv v^j(p_0) \partial_{x_j} e(p_0)$


We can calculate the derivaive of this vector field as follows:

$$
\begin{aligned}
&\frac{V(p)}{\partial x^i} = \partial_{x_i} \left[ v^j(p) \partial_{x_j} e \right] \\
&= v^j \cdot \partial_{x_i} \partial_{x_j} e + \partial_{x_j}e \cdot \partial_{x_i} v^j
\end{aligned}
$$

We choose to rewrite the second degree term in terms of the tangent
space, and some component that is normal to us that we have no
control over.

$$
(\partial_{x_i} \partial_{x_j} e )(p) \equiv \Gamma^k_{ij} \partial_{x_k} e + \vec{n}
$$

This gives us the Christoffel symbols as "variation of second derivative _along_
the manifold.


#### Relationship to the Levi-Cevita connection

The covariant derivative defined by the Levi-Cevita connection is the derivative
that contains the projection of the full derivative in $\mathbb R^n$ onto
the tangent space $T_p M$. This is defined by the equations:

$$
\begin{aligned}
 &\nabla_{e_i} V \equiv \partial_{x_i} V - \vec{n}  \\
 &= \Pi_{\vec{n}^\bot} \left [v^j \cdot \partial_{x_i} \partial_{x_j} e + \partial_{x_j}e \cdot \partial_{x_i} v^j \right] \\
 &= \Pi_{\vec{n}^\bot} \left[ v^j \cdot (\Gamma^k_{ij} \partial_{x_k} e + \vec{n})+ \partial_{x_j}e \cdot \partial_{x_i} v^j \right] \\
 &= v^j \cdot (\Gamma^k_{ij} \partial_{x_k} e + \vec 0) + \partial_{x_j}e \cdot \partial_{x_i} v^j \\
 &= v^j \cdot (\Gamma^k_{ij} \partial_{x_k} e + \vec 0) + \partial_{x_k}e \cdot \partial_{x_i} v^k \\
 &= v^j \cdot \Gamma^k_{ij} \partial_{x_k} e  + \partial_{x_k}e \cdot \partial_{x_i} v^k \\
 &= \partial_{x_k} e \left( v^j \cdot \Gamma^k_{ij}  + \partial_{x_i} v^k \right) \\
\end{aligned}
$$



#### References

- [The wikipedia page on Covariant derivative](https://en.wikipedia.org/wiki/Covariant_derivative#Informal_definition_using_an_embedding_into_Euclidean_space)

# A natural vector space without an explicit basis

On learning about infinite dimensional vector spaces, one learns that
we need to use the axiom of choice to assert that every such vector space
has a basis; indeed, it's equivalent to the AoC to assert this. However,
I had not known any "natural" examples of such a vector space till I studied
the proof of the barvinok algorithm. I produce the example here.

Consider a space such as $S \equiv \mathbb R^3$. Now, consider the vector
space spanned by the indicator functions of polyhedra in $S$. that's a mouthful,
so let's break it down.

A polyhedra is defined as a set of points that is defined by linear
inequalities: $P \equiv \{ x \in S : a_i \cdot x \leq b_i, i \in [1\dots n] \}$,
for all $a_i \in S$, $b \in \mathbb R$.

The indicator functions are of the form:

$$
[poly]: S \rightarrow \mathbb R;
[poly](x) \equiv
\begin{cases} 1 & x \in poly \\
0 & \text{otherwise} \end{cases}
$$

we can define a vector space of these functions over $\mathbb R$, using
the "scaling" action as the action of $\mathbb R$ on these functions:


The vector space $V$ is __defined__ as the span of the indicator functions
of all polyhedra. It's clearly a vector space, and a hopefully intuitive
one. However, note that the set we generated this from (indicators of polyhedra)
don't form a basis since they have many linear dependencies between them.
For example, one can write the equation:

```
*---*   *-*   *-*   *
|###|   |#|   |#|   |
|###| = |#| + |#| - |
|###|   |#|   |#|   |
*---*   *-*   *-*   *
```


# Cache oblivious B trees

Central idea: assume a memory model where computation is free, only cost
is pulling data from cache into memory. Cache has total size $M$, can hold
blocks of size $B$. So it can hold $M/B$ blocks of main memory. Memory memory
has infinite size. Cost is number of transfers.

We assume that the algorithm _does not know M or B_. We assume that the cache
replacement strategy is optimal (kick out block that is going to be used
farthest in the future). This is an OK assumption to make since an LRU cache
using _twice_ the memory of a "oracular" cache performs equally well (citation?)


These data structures are cool since they essentially "Adapt" to varying cache
hierarchies and even multiple level cache hierarchies.

We study how to build cache-oblivious B-trees.

#### Building optimal cache-oblivious B trees to solve search

- We use a balanced BST. We want to find an order to store nodes in memory
  such that when we search for an element, we minimize number of blocks
  we need to pull in.
- All standard orders such as level order, pre-order, post-order fail.
- Corrrect order is "VEB (Van Em De Boas) order": carve a tree at the middle
  level of its edges. Layout a "triangle" or smaller collection
  of nodes linearly. Then Recursively layout the trees, linearly in memory.
- Supposedly if the number of nodes is $N$, we wil have roughly $\sqrt(N)$
  nodes on the top, and then $\sqrt(N)$ _triangles_ at the bottom.

#### Analysis Claim: we need to pull $O(\log_B N)$ blocks for any $B$ for any search query

$N$ is the number of nodes in the BST. Note that in the analysis, _we know what B is_,
even though the _algorithm does not_.

- We look at a particuar level of recursion. We will call it a "level of detail"
  straddling B.
- We will have large triangles of size $\geq B$, inside which there are smaller
  triangles of size $\leq B$ (reminds me of sierpinski).
- We know that the algorithm recursively lays it out, and triangle stores
  everything "inside" it _in a contiguous region_. So we stop at the
  requisite size where we know that the tree's triangles themselves
  contain triangles which fit into the block size.
- A little triangle of size less than B can live in at most two memory blocks
  by straddling a block boundary: by eg. having $(B-1)$ bits in one block
  and a single bit in another block.

```
1 2 3 4 5 6 7 8 <- index
|     |       | <- boundary
|-xxxxxxx-----| <-  data
```

- The question is that on a root-to-leaf bpath, how many such triangles do
  we need to visit. Since we repeatedly divide the nodes in half
  _with respect to height_ until the little triangle has number of nodes less
  than $B$, the height is going to be $O(\log B)$ since it's still a binary tree.
- total height in $O(\log N)$.
- so height of "chunked tree" where we view each triangle as a single node
  is $\log N / \log B = \log_B n$.
- **insight**: ou data structure construction in some sense permits us to
  "binary search on $B$" since we divide the data structure into levels
  based on $B$. if $B = N$, then the full data structure fits into memory
  and we're good.

#### Black box: ordered file maintainince

We need a black box: ordered file maintainance (linked list for arrays)

- Store $n$ elements in specified order in an array of linear size $O(N)$.
  Array permits gaps.
- updates: delete element, insert elements between 2 elements.
- cannot do this in linear time, but we can move elements in an interval of
  size $\log^2(N)$ amortized.
- We need $O(1)$ scans for the data structure.

#### Next: _dynamic_ BST (inserts and deletes): layout

we take a VEB static tree on top of an ordered file. Tree is a segtree
that has max of nodes. Leaves are the members of the ordered file.

#### Updates

- search for node.
- update ordered file.
- propogate updates into the tree. This will have to be done in post-order
  because we need the leaves to be fixed before we can update the parent
  `max`.

#### Updates: analysis.

- look at level of detail that straddles $B$.
- Let us look at the bottom 2 levels.
- Note that when we perform post-order inside a triangle that has 3 triangles
  of size $\leq B$, we need to alternate between parent triangle and child triangle.
  Since the parent triangle is of size $\leq B$ and can therefore take
  at most $2B$ blocks of memory, similarly the child can take at most $2B$
  blocks of memory.
- So if our cache can hold $4$ blocks of memory, we're done.
  We won't need to kick anything out when performing the post-order
  traversal.
- For levels that are above the bottom 2 levels, we're still OK. there
  are not many triangles! / not many nodes! (`1:16:00` in the video)





#### References

- [Erik demaine, advanced data structures, lecture 7: Memory hiearchy: models, cache oblivious B trees](https://courses.csail.mit.edu/6.851/fall17/lectures/L07.html?notes=5)

# Krohn-Rhodes decomposition

We denote partial functions with $X \rightharpoonup Y$ and total functions
with $X \rightarrow Y$.

A set $X$ equipped with a binary operator
$\star: X \times X \rightarrow X$ which is closed and associative
is a semigroup.

#### Partial function semigroup

For a ground set $X$, the set of partial functions $Pf(X) \equiv \{ f: X \rightharpoonup X \}$
along with function composition forms a semigroup. This is in fact stronger
than a semigroup. There exists:

- An identify function $e_x: X \rightarrow X; e_X(x) = x$
- A zero function $\theta_x: X \rightharpoonup X; \theta_x(x) = \texttt{undef}$, where by
  $\texttt{undef}$ we mean that it is _undefined_.

#### Transformation semigroup(TS)

Let $Q$ be a set. Let $S \subseteq Pf(Q)$ be a sub-semigroup of $Pf(Q)$.
Then the semigroup $X \equiv (Q, S)$ is called as the
 _transformation semigroup_(X) of states $Q$.

- The elements of $Q$ are called states of $X$
- while  the elements of $S$ are called  _actions_ of $X$.
- The set $Q$ itself is called as the _underlying set_ of $X$.
- For a fixed transformation semigroup $X$, we will write $Q_X$ and $S_X$
  to refer to its states and actions.


We call $X \equiv (Q, S)$ as a _transformation monoid_ if $S$ contains $1_Q(q) = q$.

##### Subtlety of being a transformation monoid.

There is some subttlety here. Just because $S$ is a monoid does not mean that
it that is a _transformation monoid_. It must have the identity element of
$Pf(Q)$ to be called a transformation monoid. For example, consider the
set $Q \equiv \\{ a, b \\}$ and the transformation semigroup $S \equiv \\{ f \equiv \alpha \mapsto b \\}$.
Now the set $S$ is indeed a monoid with identity element as $f: Q \rightarrow Q$.
however, $f \neq 1_Q$ , andh ence, $S$ is a not a _transformation monoid_.



##### Examples of transformation semigroups

1. $(X, \{ \theta(x) = \texttt{undef} \})$. The semigroup with the empty transformation.
2. $(X, \emptyset)$, the semigroup with _no_ transformations.


#### Semigroup action

We sometimes wish to represent a semigroup using an action/transformation semigroup
on a ground set $X$. So, given some semigroup $(T, \times)$ that needs to be represented,
if we can find a morphism $r: T \rightarrow Pf(X)$ ($r$ for representation)
such that:

- $ r(t_1 + t_2) = r(t_1) \circ r(t_2)$. [$r$ is a semigroup morphism].
- $t_1 \neq t_2 \implies \exists x \in X$ such that $r(t_1)(x) \neq r(t_2)(x)$.
  [Faithfulness].

Put more simply, $t_1 \neq t_2 \implies r(t_1) \neq r(t_2)$ where we define
function equality extensionally: $f = g \equiv \forall x, f(x) = g(x)$.


#### Embedding actions into the transformation semigroup
We often wish to represent some semigroup $S$ as the transformation semigroup
of some set of states $Q$. We can achieve this by proving a morphism:

- $r: S \rightarrow Pf(Q)$ that is faithful.

Then, we can treat elements of $S$ as elements of $Pf(Q)$.


#### Completion of a transformation semigroup

Given a transformation semigroup $X \equiv (Q, S)$ we can _complete_ it
by adding a new sink state $\bot$, and then converting all partial
functions in $S$ to total functions that transition to $\bot$. We have that
$\bot \cdot s = s \cdot \bot ~ \forall s \in S$.

We denote the completion as $X^c \equiv (Q^c, S^c)$.



#### Coverings

Let $X \equiv (Q_X, S_X)$ and $Y \equiv (Q_Y, S_Y)$ be transformation
semigroups. Let $\phi \subseteq Q_Y \times Q_X$ be a relation. Let $s_x \in S_X$
and $s_y \in S_Y$. Then, if the following diagram commutes:

$$
\begin{array}{ccc}
a & \rightarrow & b \\
\downarrow & & \downarrow \\
x & \rightarrow & y \\
\end{array}
$$

If $s_x(\phi(q_y)) = \phi(t_y(q_y))$ then we say that $t_y$ covers $s_x$ relative to $\phi$.
We imagine the $t_y$ lying above $s_x$, being projected down by $\phi$.

If a fixed $\phi$, for all $s_x \in S_X$ there exists a $t_y \in S_Y$ such that
$t$ covers $s$ relative to $\phi$, then we say that $\phi:$ is a
_relation of automata_.

- If $\phi: Q_Y \rightarrow Q_X$ is surjective,
  then we say that $\phi$ is a __relational covering__ and write: $X \triangleleft_{\phi} Y$.
- If $\phi \subseteq Q_Y \times Q_X $ is _both_ surjective and partial,
  then we say that $\phi$ is a __covering__ and write: $X \prec_\phi Y$
- If $X \prec_\phi Y$, we say that $Y$ dominates $X$, or $Y$ covers $X$, or
  $X$ divides $Y$.

#### Checking coverings and generating subsets

We note that for a given covering $\phi$, if $s_x$ is covered by $t_y$
and $p_x$ is covered by $q_y$, then $s_x \circ t_x$ is covered by $t_y \circ q_y$.

Thus, to check if $X$ is covered by $Y$, we simply need to check if
__some generating subset of $X$ is covered by $Y$__.

#### Checking coverings of representations

Let us assume we have a representation of a transformation semigroup
given with a semigroup $\Sigma$, a transformation semigroup
$X \equiv (Q_X, S_X)$, and a representation $r: \Sigma \rightarrow S_X$ that is
faithful.

Now, to check that $X$ is covered by another $Y$, it suffices to check that
there exists a $t_y \in Y$ for each $\sigma \in X$ such that $r(\sigma)$ is
covered by this $t_y$.

#### Companion relation
Given a relation $\phi: Y \rightarrow X$, then we define:

$$
\Sigma \equiv \{ (s, t) : t \in T_Y \text{ covers } s \in S_X \}
$$

Recall compositions of elements are covered by a composition
of their coverings. Hence, if $(s, t), (s', t') \in \Sigma$, then
$(ss', tt') \in \Sigma$. thus, $\Sigma$ is a subsemigroup of $S_X \times S_Y$.

We can regard $\Sigma$ as the graph of a relation $\phi' \subseteq Q_Y \times Q_X$.
This will be called as __companion relation__ of $\phi$.

#### Wreath products

Let $X \equiv (Q_X, S_X)$ and $Y \equiv (Q_Y, S_Y)$. We're going to define a large
product $X \wr Y$.

We begn with the set $W \equiv S_X^{Q_Y} \times S_Y$, where
$S_X^{Q_Y} \equiv \{ f : Q_Y \rightarrow S_X \}$.
The wreath product then becomes:

$$
X \wr Y \equiv (Q_X \times Q_Y, W)
$$

with the action of $W$ on an element of $Q_X \times Q_Y$ being defined as:

$$
(f : Q_Y \rightarrow S_X, s_y : S_Y) (q_x : Q_X, q_Y : Q_Y) \equiv ( f(q_y)(q_x) , s_y (q_y))
$$

it's a "follow the types" sort of definition, where we edit the right component
as $r_y \mapsto t_y(r_y)$ since that's all we can do. In the case of
the left component, we have a $q_x$, and we need to produce another element
in $Q_X$, so we "must use $f$". The only way to use $f$ is to feed it
a $t_y$. This forces us into the above definition.


##### Composition of wreath products

To show that its closed under composition, let's consider $(f, s_y), (g, t_y) \in W$
with $f, g: Q_Yg \rightarrow S_X$, and $s_y, t_y \in S_Y$. The result is
going to be:

$$
(f, s_y)  (g, t_y) =  (\lambda q_y. f(q_y) \circ g(q_y), t_y \circ u_y)
$$

#### Equivalences of subsets of states

Let $X = (Q, S)$ be a transition system. Given subsets $(a, b, \subseteq Q)$,
we shall write $b \leq a$ if either $b \subseteq a$ or there exists some $s \in S$
such that $b \subseteq sa$, where $s(a) \equiv \{ s(a_i) : a_i \in a\}$. We can
define an equivalence relation $a \sim b \iff a \leq b \land b \leq a$.

##### Note
$ b \leq a \implies |b| \leq |a|$, since
$b \leq a$ means that $b \subseteq s(a)$. Note that $s$ is actually a
function $s: Q \rightarrow Q$, and a function mapped over a set can only
ever decrease the number of elements in a set, since a function can only
xglomp elements together; it can never break an element apart into two.
Hence, $b \subseteq sa \subseteq a$, and thus $|b| \leq |a|$.


Similiarly, $a \leq b \implies |a| \leq |b|$. Therefore, $b \sim a$ means
that $|b| = |a|$.

##### Theorem
for all $a, b \in Q_X$ such that
$a ~ b$ such that $b \subseteq s(a)$, we show that $b = s(a)$, and there exists
a $t \in S_X$ such that $a = t(b)$.

##### Proof
Since $b \subseteq s(a) \subseteq a$ and $|b| = |a|$, $b = s(a)$.
Therefore $s$ is a permutation. Hence, $s$ is invertible and there exists
an inverse permutation $t$ such that $a = t(b)$. We now need to show that
$t \in S_X$. To do this, first note that if the order of the permutation
$s$ is $n$, then $t = s^{n-1}$, since $t \circ s = s^{n-1} \circ s = 1_S$.
Since the semigroup $S$ is closed under composition $t = s^{n-1}$ is in $S$,
since it is $s$ composed with itself  $(n-1)$ times.

#### Subset families of interest

We will be interest in a family of subsets of $Q_X$ called $A$, of the form:
- all sets of the form $s(Q)$ for all $s \in S_X$
- the set $Q$
- the empty set $\emptyset$
- all the singleton sets $\{ q \}$ for all $q \in Q$.

In the above set, we have $\leq$ and $\sim$ as defined above.

We note that the set $A$ is **closed under the action of all $s \in S_X$**.
For example, the empty set is taken to the empty set. All singleton
sets are taken to other singleton sets. For the full set $Q$, we add
the sets $s(Q)$ for all $s \in S_X$.

#### Height function

A height function for a transition system $X \equiv (Q_X, S_X)$ is a function
$h: A \rightarrow \mathbb Z$ such that:


1. $h(\emptyset) = -1$.
2. $h(\{ q \}) = 0 \forall q \in Q$.
3. $a \sim b \implies h(a) = h(b)$ for all $a, b \in A$.
4. $b < a \implies h(b) < h(a)$ for all $a, b \in A$.

The notation $b < a \equiv (b \leq a) \land \lnot (a \leq b)$.

(3) + (4) imply that two elements of the same height are either equivalent
or incomparable.

#### Pavings and bricks

for $a \in A$ such that $|a| > 1$, we denote by $B_a$ the set of all $b \in A$
what are maximal subsets of $a$. That is, if $b \in B_a$ then $b \subsetneq a$,
and $\not \exists c, b \subsetneq c \subsetneq a$. Equivalently, if there
exists a $c$ such that $b \subseteq c \subseteq a$, then $b = c$ or $b = a$.

Note that we can assert that $a = \cup_{b \in B_a} b$. This is because $B_a$
contains all the singletons of $Q_X$. so we can begin by writing $a$ as
a union of singletons, and then merging elements of $B_a$ into larger elements
of $B$, terminating when we cannot merge any more elements of $B_a$.

- The set $B_a$ is called as the **paving of $a$**.
- The elements of $B_a$ are called as the **bricks of $a$**.

#### Group of permutations for $a \in A$

Let us assume that there exists a $s \in S$ such that $s(a) = a$. Let $A_a$
be the set of all elements in $A$ contained in $a$:
$A_a = \{ A_i : A_i \in A, A_i \subseteq a \}$.

Recall that the set $A$ was closed under the action of all $s$, and hence,
since $s$ is a permutation of $a$, this naturally extends into a
permutation of $A_a$: $s A_a = A_a$. Now note that this induces a permutation
of the set $B_a$. This creates a transition system:

$$
\begin{aligned}
&G_a \equiv \{ s \in S : s a = a \} \\
&H_a \equiv (B_a, G_a) \\
\end{aligned}
$$

We have already shown how if $s \in S$ defines a permutation of some set $X$
by its action, then its inverse also exists in $S$. So, this means that
$G_a$ is in fact a transition _group_ that acts on $B_a$.

It might turn out that $G_a = \emptyset$. However, if $G_a \neq \emptyset$,
then as stated above, $G_a$ is a group.

We will call such a transition group a **generalized transition group**, since
either $G_a = \emptyset$ or $G_a$ is a group.


Now, the generalized transition group $H_a$ is called as the
**holonomy transition system** of $a$, and the group $G_a$ is called as
the **holonomy group** of $a$.


We have that $G_a \prec S$ since $G_a$ is a quotient of the sub-semigroup
$\{ s | s \in S, as = a \}$. (TODO: so what? why does this mean that it's $\prec$?)

##### Theorem:

If $a \sim b$, then $H_a \simeq H_b$ (similar subsets have isomorphic holonomy transition systems).

##### Proof:

Let us assume that $a \neq b$. since $a \sim b$, we have elements
of the form $s, s^{-1} \in S$ such that $b = s(a)$, $a = s^{-1}(b)$.

Recall that for $b_a \in B_a$ is such that for a member $g \in G_a$,
$g(b_a) = b_a$. $B_b$ must have the element $s(b_a) $  [TODO!]

#### Holonomy decomposition

Let $X \equiv (Q, S)$ be a transition system and let $h$ be a height
function for $X$, such that $h(Q) > 0$. For a fixed $i$,
let $a_1, a_2, \dots a_k$ be the representatives of equivalence classes of
elements of $A$ of height equal to $i$. We define:

$$
H_i^\lor \equiv H_{a_1} \lor H_{a_2} \dots \lor H_{a_n}
$$


#### Inductive hypothesis for coverings

We will say a relational covering $X \triangleleft_{\phi} Y$ is **of rank $i$**
with respect to a given height function $h$ if $\phi$ relates states in $Y$
to subsets of states in $x$ that are members of $A$ and have rank at most i.
Formally, for each $p \in Q_Y$, we have that $\phi(p) \in A$ and$h(\phi(p)) \leq i$.


We prove that if $X \triangleleft_{\phi} Y$ is a relational covering of rank $i$,
then $X \triangleleft_{\phi} \overline{H_i^\lor} \wr Y$ is a relational covering
of rank $i - 1$.

The proof is a proof by induction.

##### Base case:

Start with the relational covering with $Q_Y = \{ 0 \}, S_Y = \{ id \}$,
and the cover $\phi(0) = Q_X$. Clearly, this has rank $n$ since the height
of $Q_X$ is $n$, and $\phi$ is inded a covering, since the only transition
that $Y$ can make (stay at the same state) is simulated by any transition
in $S_X$ [TODO: is this really the argument?]

For induction, assume $X \triangleleft_{\phi} Y$ is a relational covering of rank $i$
with respect to some height function $h$. $X\equiv (Q_X, S_X)$ and
$Y \equiv (Q_Y, S_Y)$. We define
- $QY_i \equiv \{ q_y : q_y \in Q_Y, h(\phi(q_y)) = i \}$
- $QY_< \equiv \{ q_y : q_y \in Q_Y, h(\phi(q_y)) < i \}$


We know that $A$ contains elements of height exactly $i$. Let $a_1, a_2, \dots a_k$
be representatives of sets of of height $i$ in $A$. Thus, for each $qy_i \in QY_i$,
we have that:

- $\phi(qy_i) = a_j$ for a **unique** $1 \leq j \leq k$.
- We select elements $u, \overline{u} \in S$ such that $u(\phi(qy_i)) = a_j$
  and $\overline{u}(a_j) = \phi(qy_i)$.

We will show how to establish a relational covering:
- $X \triangleleft_{\phi} \wr \overline{H_i^\lor} Y$ using a relation:
- $\phi \subseteq [(B_{a_1} \cup B_{a_2} \cup \dots B_{a_k})\times Q_Y ] \times Q_X$

#### References

- Automata, Languages and Computation by Elinberg.
- [On the Krohn-Rhodes decomposition theorem by Oded Maler](http://www-verimag.imag.fr/~maler/Papers/kr-new.pdf)
- [Ideas of the Holonomy Decomposition of Finite Transformation Semigroups](http://www.egri-nagy.hu/pdf/holonomy_general.pdf)
- [Nine chapters on the semigroup art](http://www-groups.mcs.st-andrews.ac.uk/~alanc/pub/c_semigroups/c_semigroups_a4.pdf)
- [Computational holonomy decompositions of transformation semigroups](http://www.biomicsproject.eu/file-repository/category/CompHolonomy.pdf)
- [Algebraic Hierarchical Decomposition of finite automata: webpage with links to implementations](http://graspermachine.sourceforge.net/)
- [`sgpdec` library on github](https://github.com/gap-packages/sgpdec)
- [Computational semigroup theory blog](https://compsemi.wordpress.com/)
- [Compact notation for semigroup/automata](https://arxiv.org/pdf/1306.1138.pdf)

# Proving block matmul using program analysis

It's a somewhat well-known fact that given matrix multiplication: $O = AB$
where $O \in \mathbb R^{2n \times 2m}$ ($O$ for output),
$A \in \mathbb R^{2n \times r}, B \in \mathbb R^{r \times 2m}$ are matrices.

We can also write this as follows:

$$
\begin{bmatrix} o_{11} & o_{12} \\ o_{21} & o_{22} \end{bmatrix} =
\begin{bmatrix} a_{11} & a_{12} \\ a_{21} & a_{22} \end{bmatrix}
\begin{bmatrix} b_{11} & b_{12} \\ b_{21} & b_{22} \end{bmatrix}
=
\begin{bmatrix}
a_{11} b_{11} + a_{12} b_{21} & a_{11} b_{12} + a_{12} b_{22} \\
a_{21} b_{11}+ a_{22} b_{21} & a_{21} b_{12} + a_{22} b_{22}
\end{bmatrix}
$$

When written as code, the original matrix multiplication is:

```cpp
// a:[2N][2Z] b:[2Z][2M] -> out:[2N][2M]
int matmul(int N, int Z, int M, int a[N][Z], int b[Z][M], int out[N][M]) {
  for(int i = 0; i < 2*N; ++i) {
    for(int j = 0; j < 2*M; ++j) {
      for(int k = 0; k < 2Z; ++k) out[i][j] += a[i][k] * b[k][j]
    }
  }
}
```

and the block-based matrix multiplication is:

```cpp
// a:[2N][2Z] b:[2Z][2M] -> out:[2N][2M]
int matmulBlock(int N, int Z, int M, int a[N][Z], int b[Z][M], int out[N][M]) {
  for (int BI = 0; BI < 2; ++BI) {
    for (int BJ = 0; BJ < 2; ++BJ) {
      for(int i = BI*N; i < BI*N+N; ++i) {
        for(int j = BJ*M; j < BJ*M+M; ++j) {
          for(int k = 0; k < 2Z; ++k) { out[i][j] += a[i][k] * b[k][j] }
        }
      }
    }
  }
}
```

we wish to show that both of these programs have the _same semantics_.
We will do this by appealing to ideas from program analysis.

#### The key idea

We will consider the statement:

```cpp
out[i][j] += a[i][k] * b[k][j]
```

as occuring at an abstract "point in time" $(i, j, k)$ in the `matmul` function.
I also occurs at an abstract "point in time" $(BI, BJ, i', j', k')$ in
the `matmulBlock` function.

We will then show that the loops `for(i...) for(j...) for(k...)` are fully
parallel, and hence we can reorder the loops any way we want.

Then, we will show that the ordering imposed by $(BI, BJ, i', j', k')$
is a reordering of the original $(i, j, k)$ ordering. We do this by
showing that there is a bijection:

$$
(i=i_0, j=j_0, k=k_0) \rightarrow (BI=i_0/N, BJ=j_0/N, i=i_0\%N, j=j_0\%N, k=k_0)
$$

Thus, this bijection executes all loops, and does so without affecting the
program semantics.

#### Schedules

We'll zoom out a little, to consider some simple programs and understan
how to represent parallelism.

```cpp
void eg1(int N, int M, int out[N][M]) {
for(int i = 0; i < N; ++i) {
  for(int j = 1; j < M; ++j) {
    out[i][j] = out[i][j-1];
  }
}
```

Notice that this program is equivalent to the program with the $i$ loop
reversed:

```cpp
void eg1rev(int N, int M, int out[N][M]) {
for(int i = N-1; i >=0; --i) {
  for(int j = 1; j < M; ++j) {
    out[i][j] = out[i][j-1];
  }
}
```

What's actually _stopping_ us from reversing the loop `for(j...)`? it's
the fact that the value of, say, `out[i=0][j=1]` _depends_ on
`out[i=0][j=0]`. We can see that in general, `out[i=i_0][j=j_0]` _depends_
on `out[i=i_0][j=j_0-1]`. We can represent this by considering a
_dependence set_:

$$
\{ \texttt{write}:(i_0, j_0-1) \rightarrow \texttt{write}:(i_0, j_0) \}
$$

in general, we can reorder statements as long as we do not change
the _directions_ of the arrows in the dependence set.

We can imagine the scenario as follows:

```
^
| (1, 0)->(1, 1)->(1, 2)->(1, 3) ...
| (0, 0)->(0, 1)->(0, 2)->(0, 3) ....
(i, j) -->
```


#### Dependence structure of `matmul`.

#### Fully parallel, reordering

[TODO]


#### References

- Optimizing Compilers for Modern Architectures: A Dependence-based Approach
- [Polyhedral compilation](http://polyhedral.info/)


# Why I like algebra over analysis

Midnight discussions with my room-mate
[Arjun P](https://researchweb.iiit.ac.in/~arjun.p/).

This tries to explore what it is about algebra that I find appealing.

I think the fundamental difference to me comes down to flavour ---
analysis and combinatorial objects feel very "algorithm", while Algebra feels
"data structure".

To expand on the analogy, a proof technique is like an algorithm, while an
algebraic object is like a data structure. The existence of an algebraic object
allows us to "meditate" on the proof technique as a separate object that does
not move through time. This allows us to "get to know" the algebraic object,
independent of how it's used. So, at least for me, I have a richness of
feeling when it comes to algebra that just doesn't shine through with analysis.
The one exception maybe reading something like "by compactness", which has
been hammered into me by exercises from Munkres :)

Meditating on a proof technique is much harder, since the proof technique
is necessarily intertwined with the problem, unlike a data structure which
to some degree has an independent existence.


This reminds me of the quote: "“Art is how we decorate space;
Music is how we decorate time.”. I'm not sure how to draw out the
tenuous connection I feel, but it's there.

Arjun comes from a background of combinatorics, and my understanding of his
perspective is that each proof is a technique unto itself. Or, perhaps
instantiating the technique for each proof is difficult enough that abstracting
it out is not useful enough in the first place.

A good example of a proof technique that got studied on its own right in
combinatorics is the probabilistic method. A more reasonable example is that of
the Pigeonhole principle, which still requires insight to instantiate in
practise.

Not that this does not occur in algebra either, but there is something in
algebra about how just meditating on the definitions. For example,
Whitney trick that got pulled out of the proof of the Whitney embedding
theorem.

To draw an analogy for the haskellers, it's the same joy of being able to write
down the type of a haskell function and know exactly what it does, enough that
a program can automatically derive the function (djinn). The fact that we know
the object well enough that just writing the type down allows us to infer the
_program_, makes it beautiful. There's something very elegant about the
_minimality_ that algebra demands. Indeed, this calls back to another quote:
"perfection is achieved not when there is nothing more to add, but when there
is nothing left to take away".

I'm really glad that this 2 AM discussion allowed me to finally pin down
why I like algebra.

# `using` for cleaner function type typedefs

I've always struggled with remembering the syntax for function type typedefs:

```cpp
typedef RETTY (*FNTYNAME)(ARGTY1, ARGTY2, ..., ARGTYn);
```

we can now use `using` for a far more pleasant syntax:

```cpp
using FNTYNAME = RETTY(ARGTY1, ARGTY2, ..., ARGTYn);
```

which is also intuitive. You write down the "type"
on the right hand side, and give it a name on the left.

This is not strictly the same, since the `typedef`
`typedefs` `FNTYNAME` to a _function pointer type_, while
the C++ version typedefs the _function type_. I prefer
the latter at any rate, since I dislike the fact
that the usual typedef tends to hide the fact that a
function pointer is some pointer-like-thing.


# A walkway of lanterns (TODO)

### Semidirect products

- $(\alpha \equiv \{ a, b, \dots\}, +, 0)$
- $(\omega \equiv \{ X, Y, \dots\}, \times, 1)$
- $\cdot ~: ~\omega \rightarrow Automorphisms(\alpha)$

- [How to twist pointers without breaking them](https://www.cse.iitk.ac.in/users/ppk/research/publication/Conference/2016-09-22-How-to-twist-pointers.pdf)

- rotations: $\mathbb Z 5$
- reflection: $\mathbb Z 2$

- $D_5 = \mathbb Z5 \rtimes \mathbb Z2$

$$
\begin{aligned}
\begin{bmatrix}
1 & 0 \\
a & X
\end{bmatrix}
\begin{bmatrix}
1 & 0 \\
b & Y
\end{bmatrix}
=  \begin{bmatrix}
1 & 0 \\
a + X \cdot b & XY
\end{bmatrix}
\end{aligned}
$$

- $(Y \mapsto b) \xrightarrow{act} (X \mapsto a)$

- $XY \mapsto a + X \cdot b$


### A walkway of lanterns

- Imagine $\mathbb Z$ as a long walkway. you start at 0. You are but a poor lamp lighter.
- Where are the lamps? At each $i \in \mathbb Z$, you have a lamp that is either on, or off. So you have $\mathbb Z2$.

- $L \equiv \mathbb Z \rightarrow \mathbb Z2$ is our space of lanterns. You can act on this space by either moving using $\mathbb Z$, or toggling a lamp using $\mathbb Z2$. $\mathbb Z2^{\mathbb Z} \rtimes \mathbb Z$

- $g = (lights:\langle-1, 0, 1\rangle,  loc:10)$
- $move_3: (lights: \langle \rangle, loc: 3)$
- $move_3 \cdot g =  (lights:\langle-1, 0, 1\rangle,  loc:13)$
- $togglex = (lights:\langle 0, 2 \rangle, loc: 0)$
- $togglex \cdot g = (lights: \langle -1, 0, 1, 13, 15 \rangle, loc:13)$
- $toggley = (lights: \langle -13, -12 \rangle, loc:0)$
- $toggley\cdot g= (lights:\langle -1 \rangle, loc:13)$




# Natural transformations

<img  src="./static/natural-transformation.png">


I don't find people who draw "all three parts" of the natural transformation:
the catories $C$, $FC$, and $GC$, and then show the relationship between
them, so I made this for my own reference.


# The hilarious commentary by dinosaure in OCaml git

the [Ocaml-git](https://github.com/mirage/ocaml-git/) project is a
re-implementation of `git` in `OCaml`. It's well-written, and I was
walking through the codebase, when I found absolutely amazing, hilarious,
and deep comments from `dinosaure`. I really enjoyed reading through the
codebase, and the existence of these comments made it more humane to read.
I don't know who `dinosaure` is, but I'm really glad they wrote the comments
they did, it really made my day.

##### The one that takes a stab at Haskell for fun

```
(* XXX(dinosaure): ...we can fix this detail but
I'm lazy like haskell. TODO! *)
```

##### The academic one that broken-links to a paper

```
(* XXX(dinosaure): see this paper
https://github.com/ocamllabs/papers/blob/master/irmin/2014.08.matthieu/rapport.pdf *)
```

##### The one about the frustrations of bug-hunting

```
(* XXX(dinosaure): [~chunked:false] is mandatory, I don't want to explain
why (I lost one day to find this bug) but believe me. *)
```

##### The one about a potential heisenbug

```
(* XXX(dinosaure): if, one day, we find a bug about the serialization of the
IDX file, may be it's about this function (stable/unstable sort). *)
```

##### The requisite comment in french for an OCaml project

```
(* XXX(dinosaure): bon ici, c'est une note compliqué, j'ai mis 2 jours
à fixer le bug. Donc je l'explique en français, c'est plus simple.
En gros, [Helper.MakeDecoder] utilise ce buffer comme buffer interne
pour gérer les alterations. Ce qui ce passe, c'est que dans la
fonction [refill], il s'agit de compléter à partir d'un [input]
(typiquement [zl]) le buffer interne. C'est finalement un
__mauvais__ jeu entre un [Cstruct.t] et un [Bigarray].
Il s'agit de connaître la véritable taille du [Bigarray] et de
rajouter avec [blit] le contenu de l'[input] si la taille du
[Bigarray] (et pas du [Cstruct]) est suffisante.
Avant, cette modification, [zl], [de] et [io] partagaient le même
[Bigarray] découpé (avec [Cstruct]) en 3. Donc, dans le
[MakeDecoder], [refill] considérait (pour des gros fichiers faisant
plus de 0x8000 bytes) que après [de], nous avions encore de la
place - et dans ce cas, nous avions [io].
Ainsi, on [blit]ait [zl] dans [de+sizeof(de) == io], et finalement,
on se retrouvait à essayer de décompresser ce que nous avions
décompressé. (YOLO).
Donc, on considère maintenant [de] comme un [Cstruct.t] et un
[Bigarray] physiquement différent pour éviter ce problème.
Cependant, il faudrait continuer à introspecter car j'ai
l'intuition que pour un fichier plus gros que [2 * 0x8000], on
devrait avoir un problème. Donc TODO. *)
```

###### The deep one

```
(* XXX(dinosaure): at the end, we don't care if we lost something. *)
```

# How to link against MLIR with CMake

Since `MLIR` hasn't setup the nice tooling that LLVM has around `CMake`
as far as I can tell, one needs to actually _know_ `CMake` to link against
`MLIR`. However, as is well known, `CMake` incantations are handed down
by preists who spend the better part of their lives studying the tome
that is the CMake manual. I, an unlucky soul had to go on this adventure,
and I hope to spare you the trouble.

I wished to link against a static library build of MLIR. The secret
lies in the `find_library` call:

```
#If the variable has been set by -DMLIR_INCLUDE_PATH, then keep it.
#Otherwise fallback to the environment variable $MLIR_INCLUDE_PATH.
#if neither, then *shrug*.
IF(NOT MLIR_INCLUDE_PATH)
    set (MLIR_INCLUDE_PATH $ENV{MLIR_INCLUDE_PATH})
endif()

#Resolve for:
#- a library target called `MLIRAnalysis`
#- asking to link against `libMLIAnalysis.a`
#- using the variable MLIR_INCLUDE_PATH which as we saw before
##  is either an environment variable or a cmake option
target_include_directories(languagemodels PRIVATE ${MLIR_INCLUDE_PATH})
```

I cribbed the actual things to link against from the path
[`mlir/examples/Toy/Ch2/CMakeLists.txt`](https://github.com/llvm/llvm-project/blob/master/mlir/examples/toy/Ch2/CMakeLists.txt)
which helpfully lists MLIR things it needs to link against.

The full `CMakeLists` is here:

```
cmake_minimum_required(VERSION 3.5)
project(languagemodels)

set(CMAKE_CXX_STANDARD 14)

## I don't want to use find_package since I want proper control over where my LLVM comes from.
## find_package(LLVM REQUIRED)

add_executable(languagemodels
        rnn.cpp codegenc.h lang.h codegenmlir.h)

## Attempt to take these as command line arguments. IF that fails,
## lookup environment.
IF(NOT MLIR_INCLUDE_PATH)
    set (MLIR_INCLUDE_PATH $ENV{MLIR_INCLUDE_PATH})
endif()

IF(NOT MLIR_LIBRARY_PATH)
    set (MLIR_LIBRARY_PATH $ENV{MLIR_LIBRARY_PATH})
endif()

target_include_directories(languagemodels PRIVATE ${MLIR_INCLUDE_PATH})
find_library(MLIRAnalysis MLIRAnalysis ${MLIR_LIBRARY_PATH})
find_library(MLIRIR MLIRIR ${MLIR_LIBRARY_PATH})
find_library(MLIRParser MLIRParser ${MLIR_LIBRARY_PATH})
find_library(MLIRSideEffects MLIRSideEffects ${MLIR_LIBRARY_PATH})
find_library(MLIRTransforms MLIRTransforms ${MLIR_LIBRARY_PATH})
find_library(LLVMCore LLVMCore ${MLIR_LIBRARY_PATH})
find_library(LLVMSupport LLVMSupport ${MLIR_LIBRARY_PATH})

## debugging to check if it's been set properly
message(MLIR_INCLUDE_PATH ${MLIR_INCLUDE_PATH})
message(MLIR_LIBRARY_PATH ${MLIR_LIBRARY_PATH})
message(MLIRAnalysis ${MLIRAnalysis})

target_link_libraries(languagemodels
        ${MLIRAnalysis}
        ${MLIRIR}
        ${MLIRParser}
        ${MLIRSideEffects}
        ${MLIRTransforms}
        ${LLVMCore}
        ${LLVMSupport})
```



# Energy as triangulaizing state space

This comes from The wild book by John Rhodes, which I anticipate I'll be posting more of in the coming weeks.

#### Experiments

Let an experiment be a tuple of the phase space $X$, action space $A$,
and an action of the actions onto the phase space
$\curvearrowright: A \times X \rightarrow X$. We will write
$x' = a \curvearrowright x$ to denote the new state of the system
$x$. So the experiment $E$ is the data
$E \equiv (X, A, \curvearrowright : A \times X \rightarrow X)$.

#### Coordinate systems.

The existence of the action $\curvearrowright$ allows us to
write the evolution of the system recursively:

$x_{t+1} = a \rightarrow x_t$.

However, to understand the final state $x_{t+1}$, we need to essentially
"run the recursion", which does not permit us to
_understand the experiment_.

What we really need is the ability to "unroll" the loop. To quote:

> Informally, understanding an experiment $E$ means
> introducing coordinates into phase space of $E$ which are in triangular form
> under the action of the inputs of $E$.

#### Conservation laws as triangular form

We identify certain interesting invariants of a system by two criteria:

1. The parameter $Q(t)$ determines some obviously important aspects of
   the system. That is, there is a deterministic function $M(Q(t))$ which
   maps $Q(t)$ to "measure" some internal state of the system.
2. If the values of such a  parameter $Q$ is known at time $t_0$ (denoted $Q(t_0)$)
    and it is also known what inputs are presented to the
    system from time $t$ to time $t + \epsilon$
    (denoted $I[t_0, t_0 + \epsilon]$), then the new value of $Q$ is a
    deterministic function of $Q(t_0)$ and $I[t_0, t_0+ \epsilon]$.


Such parameters allow us to understand a system, since they are deterministic
parameters of the evolution of the system, while also provding a way to
measure some internal state of the system using $M$.

For example, consider a system $x$ with an energy function $e(x)$. If we
perform an action $a$ on the system $x$, then we can predict the action
$e(x' = a \curvearrowright x)$ given just $e(x)$ and $a$ --- here,
$(x' = a \curvearrowright x)$ is the action of the system $a$ on $x$.

> In general, conservation principles give a first coordinate
> of a triangularization. In the main a large part of physics can be viewed as
> discovering and introducing functions $e$ of the states $q$ of the
> system such that under action $a$, $e(a \curvearrowright q)$ depends
> only on $e(q)$ and $a$, and **not** on $q$.


#### Theory: semidirect and wreath products

- For semidirect products, I refer you to
    [the cutest way to write semidirect products](#the-cutest-way-to-write-semidirect-products)
    [Line of investigation to build physical intuition for semidirect products](#line-of-investigation-to-build-physical-intuition-for-semidirect-products).

#### Symmetries as triangular form

> We first heuristically indicate the construction involved in going from the
> group of symmetries to the triangularization, and then precisely write it out
> in all pedantic detail.

Let an experiment be $E \equiv (X, A, \curvearrowright)$. Then we define $\Pi$
is a _symmetry_ of $E$ iff:

1. $\Pi: X \rightarrow X$ is a permutation of $X$.
2. $\Pi$ commutes with the action of each $a$:
       $ \Pi(a \curvearrowright x) = a \curvearrowright \Pi(x) $.

We say that the theory $E$ is _transitive_ (in the action sense) if for
all $x_1, x_2 \in X, x_1 \neq x_2$, there exists $a_1, a_2, \dots a_n$
such that $ x_2 = a_n \curvearrowright \dots (a_1 \curvearrowright x_1) $.

Facts of the symmetries of a system:

1. We know that the symmetries of a theory $E$ form a group.
2. If $E$ is transitive, then each symmetry $\Pi$ is a regular permutation
   --- If there exists an $x$ such that $\Pi(x_f) = x_f$ (a fixed point), then
   this implies that $\Pi(x) = x$ for _all_ $x$.
3. Let the action split $X$ into disjoint orbits $O_1, O_2, \dots O_k$ from whom
   we choose representatives $x_1 \in O_1, x_2 \in O_2, \dots x_k \in O_k$.
   Then, if $E$ is transitive, there is _exactly one_ action that sends a
   particular $x_i$ to a particular $x_j$. So, on fixing _one component_
   of an action, we fix _all components_.

To show that this gives rise to a triangulation, we first construct
a semigroup of the actions of the experiment:
$S(E) \equiv \{ a_1 \dots a_n : n \geq 1 \text{~and~} a_i \in A \}$.

Now, let $G = Sym(E)$, the full symmetry group of $E$. One can apparently
express the symmetry group in terms of:

$$(X, S) \leq (G, G)  \wr (\{ O_1, O_2, \dots O_k\}, T)$$


# The cutest way to write semidirect products

Given two monoids $(M, +, 0_M)$ and $(N, \times, 1_N)$, and a
homomorphism $\phi: N \rightarrow End(M)$, where $End(M)$
is the endomorphism group of $M$. We will notate $\phi(n)(m)$ as $n \cdot m \in M$.

Now the semidirect product $M \ltimes_\phi N$ is the set $M \times N$ equipped
with the multiplication rule:

- $(m, n) (m', n') = (m + n \cdot m', nn')$

This can also be written down as:

$$
\begin{bmatrix}
1 & 0 \\ m & n
\end{bmatrix}
\begin{bmatrix}
1 & 0 \\ m' & n'
\end{bmatrix} =
\begin{bmatrix}
1 & 0 \\ m + n \cdot m' & n \times n'
\end{bmatrix}
$$

This way of writing down semidirect products as matrices makes many things
immediately clear:

- The semidirect product is some kind of "shear" transform, since that's
  what a shear transformation looks like, matrix-wise.
- The resulting monoid $M \ltimes_{\phi} N$ has identity $(0_M, 1_N)$,
  since for the matrix to be identity, we need the 2nd row to be $(0, 1)$.
- The inverse operation if $(M, N)$ were groups would have to be such that

$$
\begin{bmatrix} 1 & 0 \\ m + n \cdot m' & n \times n' \end{bmatrix} =
\begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}
$$

Hence:
- $nn' = 1$ implies that $n' = 1/n$.
- $m + n m' = 0$ implies that $m' = -m/n$.

which is indeed the right expression for the inverse.



# My Favourite APLisms

#### identity matrix
```
n←3 ⋄ id ← n n ⍴(1,n⍴0) ⋄ id
```

This relies heavily on `⍴` replicating its arguments.


#### histogram
```
xs←(1 1 3 3 3 6) ⋄ n←(⌈/xs)⍴0 ⋄ n[xs]+←1 ⋄ n
```

The use of `n[x] +←1` will stably write `+1` as many times as there are repeated
indexes in `xs`.

#### String matching / parity as fold `≠`:


```
]disp str ← (1 0 0 1 0 0 0 0 1 0 1 0 0 0) ⋄ 2 1 ⍴ ((⊂ str) ⍪ ⊂((≠\str)))
┌→──────────────────────────┐
↓1 0 0 1 0 0 0 0 1 0 1 0 0 0│
├~─────────────────────────→┤
│1 1 1 0 0 0 0 0 1 1 0 0 0 0│
└~─────────────────────────→┘
```

# Proof of chinese remainder theorem on rings

#### General operations on ideals
We have at our hands a commutative ring $R$, and we wish to study the ideal
structure on the ring. In particular, we can combine ideals in the following
ways:

1. $I + J \equiv \{ i + j : \forall i \in I, j \in J \}$
2. $I \cap J \equiv \{ x : \forall x \in I \land x \in J \}$
3. $I\oplus J \equiv \{ (i, j) : \forall i \in I \land j \in J \}$
4. $IJ \equiv \{ ij : \forall i \in I \land j \in J \}$

We have the containment:

$$
IJ \subseteq I \cap J \subseteq I, J \subseteq I + J \subseteq R
$$

#### $IJ$ is a ideal, $IJ \subseteq I \cap J$

it's not immediate from the definition that $IJ$ is an ideal. The idea is
that given a sum $\sum_k i_k j_k \in IJ$, we can write each $i_k j_k = i'_k$,
since the ideal $I$ is closed under multiplication with $R$. This gives
us $\sum i'_k = i'' \in I$. Similarly, we can interpret $\sum_k i_k j_k = \sum_k j'_k = j''k \in J$.

Hence, we get the containment $IJ \subseteq I \cap J$.

#### $I \cap J subseteq I$, $I \cap J \subseteq J$

Immediate from the inclusion function.

#### $I, J \subseteq I + J$

Immediate from inclusion

#### CRT from an exact sequence

There exists an exact sequence:

$$
\begin{aligned}
0 \rightarrow I \cap J \xrightarrow{f} I \oplus J \xrightarrow{g} I + J \rightarrow 0 \\
&f(r) = (r, r) \\
&g((i, j)) = i + j
\end{aligned}
$$

We are forced into this formula by considerations of dimension. We know:

$$
\begin{aligned}
&dim(I \oplus J) = dim(I) + dim(J) \\
&dim(I + J) = dim(I) + dim(J) - dim(I \cap J) \text{[inclusion-exclusion]} \\
&dim(I + J) = dim(I \oplus J) - dim(I \cap J) \\
&dim(I + J) - dim(I \oplus J) + dim(I \cap J) = 0\\
&V - E + F = 2
\end{aligned}
$$

By analogy to euler characteristic which arises from homology, we need to have
$I \oplus J$ in the middle of our exact sequence. So we must have:

$$
0 \rightarrow ? \rightarrow I \oplus J \rightarrow ?\rightarrow 0
$$

Now we need to decide on the relative ordering between $I \cap J$ and $I + J$.
- There is  no _universal_ way to send $I oplus J \rightarrow I \cap J$. It's
  an unnatural operation to restrict the direct sum into the intersection.
- There is a _universal_ way to send $I \oplus J \rightarrow I + J$: sum
  the two components. This can be seen as currying the addition operation.

Thus, the exact sequence _must_ have $I + J$ in the image of $I \oplus J$. This
forces us to arrive at:

$$
0 \rightarrow I \cap J \rightarrow I \oplus J \rightarrow I + J \rightarrow 0
$$

The product ideal $IJ$ plays no role, since it's not possible to define a
product of modules _in general_ (just as it is not possible to define
a product of vector spaces). Thus, the exact sequence better involve
module related operations.  We can now recover CRT:

$$
\begin{aligned}
0 \rightarrow I \cap J \xrightarrow{f} I \oplus J \xrightarrow{g} I + J \rightarrow 0 \\
0 \rightarrow R \xrightarrow{f} R \oplus R \xrightarrow{g} R \rightarrow 0 \\
0 \rightarrow R / (I \cap J) \rightarrow R/I \oplus R /J \rightarrow R/(I + J) \rightarrow 0
\end{aligned}
$$



#### References

- [I learnt the material from this course on commutative algebra from IIT bombay](https://www.youtube.com/watch?v=YxyxP894MLk).


# monic and epic arrows

This is trivial, I'm surprised it took me _this long_ to internalize this fact.

When we convert a poset $(X, \leq)$ into a category, we stipulate that
$x \rightarrow y \iff x \leq y$.

If we now consider the category $Set$ of sets and functions between sets,
and arrow $A \xrightarrow{f} B$ is a function from $A$ to $B$. If $f$ is
monic, then we know that $|A| = |Im(f)| \leq |B|$. That is, a monic arrow
behaves a lot like a poset arrow!

Similarly, an epic arrow behaves a lot like the arrow in the inverse poset.
I wonder if quite a lot of category theoretic diagrams are clarified by thinking
of monic and epic directly in terms of controlling sizes.

# The geometry of Lagrange multipliers
If we want to minise a function $f(x)$ subject to the constraints $g(x) = c$,
one uses the method of lagrange multipliers. The idea is to consider a new
function $L(x, \lambda) = f(x) + \lambda (c - g(x))$. Now, if one has a local maxima
$(x^\star, y^\star)$, then the conditions:

1. $\frac{\partial L}{\partial x} = 0$: $f'(x^\star) - \lambda g'(x^\star) = 0$.
2. $\frac{\partial L}{\partial \lambda} = 0$: $g(x^\star) = c$.

Equation (2) is sensible: we want our optima to satisfy the constraint that
we had originally imposed. What is Equation (1) trying to say?
Geometrically, it's asking us to keep $f'(x^\star)$ parallel to $g'(x^\star)$.
Why is this a good ask?

Let us say that we are at an $(x_0)$ which is a feasible point ($g(x_0) = c$).

We are interested in wiggling
$(x_0) \xrightarrow{wiggle} (x_0 + \vec\epsilon) \equiv x_1$.

- $x_1$ is still feasible: $g(x_1) = c = g(x_0)$.
- $x_1$ is an improvement: $f(x_1) > f(x_0)$.

- If we want $g(x_1)$ to not change, then we need $g'(x_0) \cdot \vec \epsilon = 0$.
- If we want $f(x_1)$ to be larger, we need $f'(x_0) \cdot \vec \epsilon > 0$.

If $f'(x_0)$ and $g'(x_0)$ are parallel, then attempting to improve $f(x_0 + \vec \epsilon)$
by change $g(x_0 + \vec \epsilon)$, and thereby violate the constraint
$g(x_0 + \epsilon) = c$.

# Efficient tree transformations on GPUs (TODO)

All material lifted straight from [Aaron Hsu's PhD thesis](https://scholarworks.iu.edu/dspace/handle/2022/24749). I'll be converting
APL notation to C++-like notation.


#### Tree repsentation as multi-dimensional ragged nested arrays

We're interested in this tree:
```
      ∘
┌──┬──┴────┐
a  b       c
│ ┌┴┐  ┌───┼───┐
p q r  s   t   u
  │    │   |
  │   ┌┴┐ ┌┴┐
  v   w x y z
```

I'll be writing APL commands in front of a `$` to mimic bash, and I'll
write some arrays as multi-line. To run them, collapse them into a single
line. The `ast` object is represented in memory as:
```
$ ast ← ('∘'
           ('a' ('p'))
           ('b'
             ('q' ('v'))
             ('r'))
           ('c'
             ('s' ('w' 'x'))
             ('t' ('y' 'z'))
             ('u')))
$ ]disp ast
┌→┬──┬────────┬───────────────────┐
│∘│ap│┌→┬──┬─┐│┌→┬──────┬──────┬─┐│
│ │  ││b│qv│r│││c│┌→┬──┐│┌→┬──┐│u││
│ │  │└─┴─→┴─┘││ ││s│wx│││t│yz││ ││
│ │  │        ││ │└─┴─→┘│└─┴─→┘│ ││
│ │  │        │└─┴─────→┴─────→┴─┘│
└─┴─→┴───────→┴──────────────────→┘
```

Here's how read the array representation. Look at the top level of the tree.
we have a root node with three children:

```
      ∘
┌──┬──┴────┐
a  b       c

┌→┬──┬────────┬─────────────┐
│∘│  │        │             │
│ │ a│   b    │     c       │
│ │  │        │             │
└─┴─→┴───────→┴────────────→┘
```

With the first `∘` being the root node, and the three adjacent cells
being the children.

Next, we look at how `x` is represented. This is predictably recursive. Let's
see the subtree under `x`:

```
      ∘
┌──┬──┴────┐
a  b       c
│
p

┌→┬──┬────────┬─────────────┐
│∘│ap│        │             │
│ │  │  b     │   c         │
│ │  │        │             │
└─┴─→┴───────→┴────────────→┘

```

Similarly for `y`:

```
      ∘
┌──┬──┴────┐
a  b       c
│ ┌┴┐
p q r

┌→┬──┬────────┬─────────────┐
│∘│ap│┌→┬──┬─┐│             │
│ │  ││b│q │r││   c         │
│ │  │└─┴─→┴─┘│             │
└─┴─→┴───────→┴────────────→┘
```

And so on, leading to the final representation:

```
      ∘
┌──┬──┴────┐
a  b       c
│ ┌┴┐  ┌───┼───┐
p q r  s   t   u
  │    │   |
  │   ┌┴┐ ┌┴┐
  v   w x y z
┌→┬──┬────────┬───────────────────┐
│∘│ap│┌→┬──┬─┐│┌→┬──────┬──────┬─┐│
│ │  ││b│qv│r│││c│┌→┬──┐│┌→┬──┐│u││
│ │  │└─┴─→┴─┘││ ││s│wx│││t│yz││ ││
│ │  │        ││ │└─┴─→┘│└─┴─→┘│ ││
│ │  │        │└─┴─────→┴─────→┴─┘│
└─┴─→┴───────→┴──────────────────→┘
```


Note that for this representation to work, we need to be able to:

- nest arrays inside arrays.
- have subarrays of different sizes (ragged arrays)
- of different _nesting depths_ --- so it's really not even an array?

I don't understand the memory layout of this, to be honest. I feel like to
represent this in memory would still rely on pointer-chasing, since we need
to box all the arrays. This is possibly optimised by APL to not be too bad.

#### The depth vector representation

```
      ∘             0
┌──┬──┴────┐
a  b       c        1
│ ┌┴┐  ┌───┼───┐
p q r  s   t   u    2
  │    │   |
  │   ┌┴┐ ┌┴┐
  v   w x y z       3
```

If we visit this tree and record depths in pre-order `(node left right)`, we
arrive at the list:

```
(∘:0
  (a:1 (p:2)) (b:1 (q:2 (v:3)) (r:2))
  (c:1 (s:2 (w:3 x:3)) (t:2 (y:3 z:3)) (u:2)))
```

formatted as:

```
(∘:0
  (a:1
    (p:2))
  (b:1
    (q:2 (v:3))
    (r:2)
  )
  (c:1 (s:2 (w:3 x:3))
       (t:2 (y:3 z:3))
       (u:2))
)
```

This linearlized is the list:

```
    (∘ a p b q v r c s w x t y z u)
d ← (0 1 2 1 2 3 2 1 2 3 3 2 3 3 2)

      ∘             0
┌──┬──┴────┐
a  b       c        1
│ ┌┴┐  ┌───┼───┐
p q r  s   t   u    2
  │    │   |
  │   ┌┴┐ ┌┴┐
  v   w x y z       3
```


To convert the `ast` object into a depth vector representation, we can
use the following call:

```
$ ast ← ('∘' ('a' ('p')) ('b' ('q' ('v')) ('r')) ('c' ('s' ('w' 'x')) ('t' ('y' 'z')) ('u')))
$ d ← ∊0{(⊢,(⍺+1)∇⊣)/⌽⍺,1↓⍵}ast
0 1 2 1 2 3 2 1 2 3 3 2 3 3 2
```

Let's break this down:

TODO

#### Inverted tables

We represent data associated with our nodes as follows:

```
$ data ← ⍪ ¨d(15⍴'T')(↑15⍴⊂'n.')
$ ]disp data
┌→┬─┬──┐
│0│T│n.│
│1│T│n.│
│2│T│n.│
│1│T│n.│
│2│T│n.│
│3│T│n.│
│2│T│n.│
│1│T│n.│
│2│T│n.│
│3│T│n.│
│4│T│n.│
│2│T│n.│
│3│T│n.│
│4│T│n.│
│2↓T↓n.↓
└→┴→┴─→┘
```

This is the same thing as a
[structure of arrays (SOA) representation](https://en.wikipedia.org/wiki/AoS_and_SoA#Structure_of_Arrays),
where each array of information (eg, the depth at `data[1]`, the `T`
information at `data[2]`) are each _arrays_ which can be accessed well on SIMD
instructions.

#### AST representation

TODO

#### Path matrices

We want information of how to go up and down the tree in ideally constant time.
We store this information in what is known as a _path matrix_.

For our recurring example, the path matrix is:

```
∘ a p b q v r c s w x t y z u | preorder traversal
──────────────────────────────────────────────────
∘ ∘ ∘ ∘ ∘ ∘ ∘ ∘ ∘ ∘ ∘ ∘ ∘ ∘ ∘ | depth=0
- a a b b b b c c c c c c c c | depth=1
- - p - q q r - s s s t t t u | depth=2
- - - - - v - - - w x - y z - | depth=3

      ∘             0
┌──┬──┴────┐
a  b       c        1
│ ┌┴┐  ┌───┼───┐
p q r  s   t   u    2
  │    │   |
  │   ┌┴┐ ┌┴┐
  v   w x y z       3
```

To efficiently compute this, we first replace every value in
our tree with its preorder traversal visit time. This changes
the tree to:

```
              ∘:0                               0
┌──────────┬──┴─────────────────┐
a:1        b:3                 c:7              1
│      ┌───┴───┐     ┌──────────┼───────┐
p:2    q:4     r:6   s:8        t:11    u:14    2
       │             │          │
       │          ┌──┴──┐     ┌─┴───┐
       v:5        w:9   x:10  y:12  z:13        3
```

The values we store in the tree are the integers. The old labels
are represented for clarity.

The path matrix for this tree is:

```
0  1  2  3  4  5  6  7  8  9 10 11 12 13 14  | preorder traversal
────────────────────────────────────────────────────────────
0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  | depth=0
-  1  1  3  3  3  3  7  7  7  7  7  7  7  7  | depth=1
-  -  2  -  4  4  6  -  8  8  8 11 11 11 14  | depth=2
-  -  -  -  -  5  -  -  -  9 10  - 12 13  -  | depth=3

              ∘:0                               0
┌──────────┬──┴─────────────────┐
a:1        b:3                 c:7              1
│      ┌───┴───┐     ┌──────────┼───────┐
p:2    q:4     r:6   s:8        t:11    u:14    2
       │             │          │
       │          ┌──┴──┐     ┌─┴───┐
       v:5        w:9   x:10  y:12  z:13        3
```

#### Rendering the depth information in 2D

We use the incantation:

```
$ d ← (0 1 2 1 2 3 2 1 2 3 3 2 3 3 2)
$ ((⍳≢d)@(d,¨⍳≢d)) ((⌈/d) (≢d))⍴'-'
0 - - - - - - - - -  -  -  -  -  -
- 1 - 3 - - - 7 - -  -  -  -  -  -
- - 2 - 4 - 6 - 8 -  - 11  -  - 14
- - - - - 5 - - - 9  -  - 12  -  -
- - - - - - - - - - 10  -  - 13  -
```

Let's break this down (the symbol ` ` means a lamp, for commenting/illumination)


```
$ ⍳ 3 ⍝ iota: make a list of n elements:.
1 2 3
```

```
$ d
0 1 2 1 2 3 2 1 2 3 4 2 3 4 2

$ ≢d ⍝ tally: ≢`. count no. of elements in d:
15
```

```
⍳≢d  ⍝ list of elements of len (no. of elements in d).
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
```

```
$ ]disp (1 2 3),(4 5 6) ⍝ ,:concatenate
┌→────┬─────┐
│1 2 3│4 5 6│
└~───→┴~───→┘
```

```
]disp (1 2 3) ,¨ (4 5 6)
┌→──┬───┬───┐
│1 4│2 5│3 6│
└~─→┴~─→┴~─→┘
```

The use of `¨` needs some explanation. `¨` is a higher order function which
takes a function and makes it a mapped version of the original function.
So, `,¨` is a function which attemps to map the concatenation operator.
Now, given two arrays `(1 2 3)`
and `(4 5 6)`, `(1 2 3) ,¨ 4 5 6` attemps to run `,` on each pair
`1 and 4`, `2 and 5`, `3 and 6`. This gives us tuples `((1 4) (2 5) (3 6))`.
So, for our purposes, `zip ← ,¨`.

```
]disp (d,¨⍳≢d) ⍝ zip d with [1..len d].
┌→──┬───┬───┬───┬───┬───┬───┬───┬───┬───┬────┬────┬────┬────┬────┐
│0 0│1 1│2 2│1 3│2 4│3 5│2 6│1 7│2 8│3 9│4 10│2 11│3 12│4 13│2 14│
└~─→┴~─→┴~─→┴~─→┴~─→┴~─→┴~─→┴~─→┴~─→┴~─→┴~──→┴~──→┴~──→┴~──→┴~──→┘
```

```
$ ((⌈/d) (≢d))⍴'-' ⍝ array of dim (max val in d) x (no. of elem in d)
---------------
---------------
---------------
---------------
```

- `⌈` is the maximum operator and `/` is the fold operator, so
  `⌈/d` finds the maximum in `d`. Recall that `(≢d)` find the no. of
   elements in `d`. `⍴` reshapes an array to the desired size. We pass it
   a `1x1` array containing only `-`, which gets reshaped into a
   `(⌈/d) x (≢d)` sizes array of `-` symbols.


TODO: explain @ and its use

#### Creating the path matrix

```
$ ⎕IO ← 0 ⍝ (inform APL that we wish to use 0-indexing.)
$ d ← (0 1 2 1 2 3 2 1 2 3 3 2 3 3 2)
$ PM ← ⌈\((⍳≢d)@(d,¨⍳≢d))(((⌈/d+1)(≢d))⍴0)

0 0 0 0 0 0 0 0 0 0  0  0  0  0  0
0 1 1 3 3 3 3 7 7 7  7  7  7  7  7
0 0 2 2 4 4 6 6 8 8  8 11 11 11 14
0 0 0 0 0 5 5 5 5 9 10 10 12 13 13

      0               0
┌──┬──┴───────┐
1  3          7       1
│ ┌┴┐  ┌──────┼───┐
2 4 6  8     11   14  2
  │    │      |
  │   ┌┴─┐   ┌┴──┐
  5   9  10  12  13   3
```

The incantation can be broken down into:


- `(((⌈/d+1)(≢d))⍴0)` is used to create a `max(d+1)x|d|` dimension array of zeros.
   Here, the rows define depths, and the columns correspond to tree nodes
   which for us are their preorder indexes.

```
$ grid←(⌈/d+1) (≢d) ⍴ 0
$ grid
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```

- `((d ,¨ ⍳≢d))` creates an array of pairs `(depth, preindex)`. We will use
  this to fill index `(d, pi)` with the value `pi`.

```
$ writeixs ← (d,¨⍳≢d)
$ ]disp writeixs
┌→──┬───┬───┬───┬───┬───┬───┬───┬───┬───┬────┬────┬────┬────┬────┐
│0 0│1 1│2 2│1 3│2 4│3 5│2 6│1 7│2 8│3 9│3 10│2 11│3 12│3 13│2 14│
└~─→┴~─→┴~─→┴~─→┴~─→┴~─→┴~─→┴~─→┴~─→┴~─→┴~──→┴~──→┴~──→┴~──→┴~──→┘
```

- `ixgrid ← ((⍳≢d)@writeixs) grid` rewrites at index `writeixs[i]` the value (`(i≢d)[i]`).

```
$ ixgrid ← ((⍳≢d)@writeixs) grid
$ ixgrid
0 0 0 0 0 0 0 0 0 0  0  0  0  0  0
0 1 0 3 0 0 0 7 0 0  0  0  0  0  0
0 0 2 0 4 0 6 0 8 0  0 11  0  0 14
0 0 0 0 0 5 0 0 0 9 10  0 12 13  0
```

- Finally, `⌈` is the maximum operator, and `\` is the [prefix scan]() operator,
  so `⌈\ixgrid` creates a prefix scan of the above grid to give us our
  final path matrix:

```
$ PM ← ⌈\ixgrid
$ PM
0 0 0 0 0 0 0 0 0 0  0  0  0  0  0
0 1 1 3 3 3 3 7 7 7  7  7  7  7  7
0 0 2 2 4 4 6 6 8 8  8 11 11 11 14
0 0 0 0 0 5 5 5 5 9 10 10 12 13 13
```

#### Using the path matrix:  distance of a node from every other node.

Note that the maximum distance between two nodes is to climb
all the way to the top node, and then climb down:

```
dmax ← depth(a) + depth(b)
```

If we know the lowest common ancestor of two nodes,
then the distance of one node to another is:

```
dcorrect ← dist(a, lca(a, b)) + dist(b, lca(a, b))
```

So, we can compute the depth as:

```
dcorrect ← dist(a, lca(a, b)) + dist(lca(a, b), b)
 = dist(a, lca(a, b)) + depth(lca(a, b)) +
   dist(b, lca(a, b)) + depth(lca(a, b)) +
   -2 * depth(lca(a, b))
 = depth(a) +
   depth(b) +
   -2 * depth (lca(a, b))
```

[TODO: picture]
[TODO: finish writing this]


#### Parent vector representation

A parent vector is a vector of length `n` where `Parent[i]` denotes an
index into `Parent`. Hence, the following condition will return 1
if V is a parent vector.

For example, for our given example, here is the parent vector:

```
d ← (0  1  2  1  2  3  2  1  2  3  3  2  3  3  2) │ depths
    (∘  a  p  b  q  v  r  c  s  w  x  t  y  z  u) │ values
p ← (∘  ∘  a  ∘  b  q  b  ∘  c  s  s  c  t  t  c) │ parents
    (0  1  2  3  4  5  6  7  8  9 10 11 12 13 14) | indexes
P ← (0  0  1  0  3  4  3  0  7  8  8  7 11 11  7) │ parent indices



              ∘:0                               0
┌──────────┬──┴─────────────────┐
a:1        b:3                 c:7              1
│      ┌───┴───┐     ┌──────────┼───────┐
p:2    q:4     r:6   s:8        t:11    u:14    2
       │             │          │
       │          ┌──┴──┐     ┌─┴───┐
       v:5        w:9   x:10  y:12  z:13        3
```


The condition a parent vector must satisfy is:

```
∧/V ∊(⍳≢V) ⍝ [All elements of V belong in the list [1..len(V)] ]
```

- `V ∊ (⍳≢V)` will be a list of whether each element in v belongs (`∊`) to the list
  `(⍳≢V) = [1..len(V)]`
- Recall that `/` is for reduction, and `∧/` is a boolean `AND` reduction.
  Hence, we compute whether each element of the vector `V` is in the range `[1..len(V)]`.
- We add the constraint that root notes that don't have a parent simply
  point to themselves. This allows us to free ourselves from requiring
  some kind of `nullptr` check.


The root node (parent of all elements) can be found using the fixpoint operator (`⍨`):

```
I←{(⊂⍵)⌷⍺} ⍝ index into the left hand side param using right hand side param
I⍣≡⍨p ⍝ compute the fixpoint of the I operator using ⍨ and apply it to p
```



#### Converting from depth vector to parent vector, Take 1

As usual, let's consider our example:

```
d ← (0  1  2  1  2  3  2  1  2  3  3  2  3  3  2) │ depths
    (∘  a  p  b  q  v  r  c  s  w  x  t  y  z  u) │ values
p ← (∘  ∘  a  ∘  b  q  b  ∘  c  s  s  c  t  t  c) │ parents
    (0  1  2  3  4  5  6  7  8  9 10 11 12 13 14) | indexes
P ← (0  0  1  0  3  4  3  0  7  8  8  7 11 11  7) │ parent indices



              ∘:0                               0
┌──────────┬──┴─────────────────┐
a:1        b:3                 c:7              1
│      ┌───┴───┐     ┌──────────┼───────┐
p:2    q:4     r:6   s:8        t:11    u:14    2
       │             │          │
       │          ┌──┴──┐     ┌─┴───┐
       v:5        w:9   x:10  y:12  z:13        3
```

Note that the depth vector already encodes parent-child information.
- The parent of node `i` is a node `j` such that `d[j] = d[i] - 1` and
  `j` is the closest index to the left of `i` such that this happens.

For example, to compute the parent of `t:11`, notice that it's at depth `2`.
So we should find all the nodes from `d[0..11]` which have depths equal to
`2`, and then pick the rightmost one. This translates to the expression:

```
$ d ← (0  1  2  1  2  3  2  1  2  3  3  2  3  3  2)
$ t ← 11   ⍝ target node
$ ixs ← ⍳t   ⍝ array indexes upto this node
  0 1 2 3 4 5 6 7 8 9 10
$ d[ixs]   ⍝ depths of nodes to the left of the given node t
  0 1 2 1 2 3 2 1 2 3 3
$ d[ixs]  = d[t]-1  ⍝ boolean vector of nodes whose depth is that of t's parent
  0 1 0 1 0 0 0 1 0 0 0
$ eqds ← ⍸ (d[ixs] = d[t]-1)  ⍝ array indexes of nodes whose depth is that of t's parent
  1 3 7
$ ⌽ eqds ⍝ reverse of array indexes to extract `7`
  7 3 1
$ ⊃ ⌽ eqds ⍝ first of the reverse of the array indexes to extract `7`
  7
$ (⌽⍸(d[⍳t] = d[t]-1))[0]  ⍝ APL style one-liner of the above
```

While this is intuitive, this does not scale: It does not permit us to find
the parent of all the nodes _at once_ --- ie, it is not parallelisable
over choices of `t`.

#### Converting from depth vector to parent vector, Take 2 (Or scan idiom)

Imagine we have a list of `0`s and `1`s, and we want to find the _index_ of
the rightmost `1` value. For example, given:

```
       0 1 2 3 4 5 6 7 8 9 10 11 12
$ a ← (0 0 1 0 0 0 1 0 1 0  0  0  0)
```

we want the answer to be `f a = 8`. We saw an implementation in terms of
`f←{(⌽⍸⍵)[0]}` in Take 1.
(recall that `⍵` is the symbol for the right-hand-side argument of a function).

We're going to perform the same operation slightly differently. Let's consider
the series of transformations:

```
⍝      0 1 2 3 4 5 6 7 8 9 10 11 12
$ a ← (0 0 1 0 0 0 1 0 1 0  0  0  0) ⍝ original array

$ ⌽a  ⍝ reverse of a
  0 0 0 0 1 0 1 0 0 0 1 0 0

$ ∨\ ⌽a ⍝ prefix scan(\) using the OR(∨) operator. Turn all
        ⍝ entries after the first 1 into a 1
  0 0 0 0 1 1 1 1 1 1 1 1 1

$ +/ (∨\ ⌽a)  ⍝ sum over the previous list, counting number of 1s
  9

$ ¯1 +  (+/ (∨\ ⌽a))  ⍝ subtract 1 from the previous number
  8
```

Why the hell does this work? Well, here's the proof:

- On running `⌽a`, we reverse the `a`. The last 1 of `a` at index $i$
  becomes the first $1$ of `⌽a` at index $i' \equiv n-i$.
- On running  `∨\ ⌽a`, numbers including and after the first 1
  become `1`. That is, all indexes $j \geq i'$ have 1 in them.
- On running `+/ (∨\ ⌽a)`, we sum up all 1s. This will give us $n-i'+1$ 1s.
  That is, $n-i'+1 = n-(n-i)+1 =i+1$.
- We subtract a $1$ to correctly find the $i$ from $i+1$.

This technique will work for __every row of a matrix__. This is paramount,
since we can now repeat this for the depth vector we were previously
interested in for each row, and thereby compute the parent index!


#### Converting from depth vector to parent vector, Take 3 (full matrix)

We want to extend the previous method we hit upon to compute the parents
of all nodes in parallel. To perform this, we need to run the moral
equivalent of the following:

```
$ ⎕IO ← 0 ⍝ 0 indexing
$ d ← (0  1  2  1  2  3  2  1  2  3  3  2  3  3  2) ⍝ depth vector
$ t ← 11 ⍝ node we are interested in
$ a←d[⍳t]=d[t]-1  ⍝ boolean vector of nodes whose depth is that of t's parent
  0 1 0 1 0 0 0 1 0 0 0
$ ¯1 +  (+/ (∨\ ⌽a)) ⍝ index of last 0 of boolean vector
7
```

for _every single choice of t_. To perform this, we can build a 2D matrix
of `d[⍳t]=d[t]-1` where `t` ranges over `[0..len(d)-1]` (ie, it ranges
over all the nodes in the graph).

We begin by using:

```
$ ⎕IO ← 0 ⋄ d ← (0  1  2  1  2  3  2  1  2  3  3  2  3  3  2) ⍝ depths
$ ]display ltdepth ← d ∘.> d ⍝ find `d[i] > d[j]` for all i, j.
┌→────────────────────────────┐
↓0 0 0 0 0 0 0 0 0 0 0 0 0 0 0│
│1 0 0 0 0 0 0 0 0 0 0 0 0 0 0│
│1 1 0 1 0 0 0 1 0 0 0 0 0 0 0│
│1 0 0 0 0 0 0 0 0 0 0 0 0 0 0│
│1 1 0 1 0 0 0 1 0 0 0 0 0 0 0│
│1 1 1 1 1 0 1 1 1 0 0 1 0 0 1│
│1 1 0 1 0 0 0 1 0 0 0 0 0 0 0│
│1 0 0 0 0 0 0 0 0 0 0 0 0 0 0│
│1 1 0 1 0 0 0 1 0 0 0 0 0 0 0│
│1 1 1 1 1 0 1 1 1 0 0 1 0 0 1│
│1 1 1 1 1 0 1 1 1 0 0 1 0 0 1│
│1 1 0 1 0 0 0 1 0 0 0 0 0 0 0│
│1 1 1 1 1 0 1 1 1 0 0 1 0 0 1│
│1 1 1 1 1 0 1 1 1 0 0 1 0 0 1│
│1 1 0 1 0 0 0 1 0 0 0 0 0 0 0│
└~────────────────────────────┘
```

- Note that `gt[i][j] = 1` iff `d[j] < d[i]`. So, for a given row (`i = fixed`), the `1s`
  nodes that are at lower depth (ie, potential parents).

- If we mask this to only have those indeces where `j <= i`, then the
  last one in each row will be such that `d[last 1] = d[i] - 1`. Why? Because
  the node that is closest to us with a depth less than us _must_ be our parent,
  in the preorder traversal.

```
$ ⎕IO ← 0 ⋄ d ← (0  1  2  1  2  3  2  1  2  3  3  2  3  3  2) ⍝ depths
$ ]display left ←  (⍳3) ∘.> (⍳3) ⍝ find `i > j` for all i, j.
┌→────┐
↓0 0 0│
│1 0 0│
│1 1 0│
└~────┘
```

Combining the three techniques, we can arrive at:

```
$ ⎕IO ← 0 ⋄ d ← (0  1  2  1  2  3  2  1  2  3  3  2  3  3  2) ⍝ depths
$ ltdepth ← d ∘.> d ⍝ find `d[i] > d[j]` for all i, j.
$ preds ←  (⍳≢d) ∘.> (⍳≢d) ⍝ predecessors: find `i > j` for all i, j.
$ pred_higher ←  ltdepth ∧ left   ⍝ predecessors tht are higher in the tree
$  parents_take_3 ← ¯1 +  +/∨\⌽pred_higher  ⍝ previous idiom for finding last 1.
¯1 0 1 0 3 4 3 0 7 8 8 7 11 11 7
```

For comparison, the actual value is:

```
    (0   1  2  3  4  5  6  7  8  9 10 11 12 13 14)  | indexes
d ← (0   1  2  1  2  3  2  1  2  3  3  2  3  3  2)  │ depths
P ← (0   0  1  0  3  4  3  0  7  8  8  7 11 11  7)  │ parent indices
    (¯1  0  1  0  3  4  3  0  7  8  8  7 11 11  7) | parents, take 3

              ∘:0                               0
┌──────────┬──┴─────────────────┐
a:1        b:3                 c:7              1
│      ┌───┴───┐     ┌──────────┼───────┐
p:2    q:4     r:6   s:8        t:11    u:14    2
       │             │          │
       │          ┌──┴──┐     ┌─┴───┐
       v:5        w:9   x:10  y:12  z:13        3
```
We have an off-by-one error for the `0` node! That's easily fixed, we simply
perform a maximum with `0` to move `¯1 -> 0`:

```
$  parents_take_3 ← 0⌈  ¯1 +  +/∨\⌽pred_higher
0 0 1 0 3 4 3 0 7 8 8 7 11 11 7
```

So, that's our function:

```
parents_take_3 ← 0⌈  ¯1 +  +/∨\⌽ ((d∘.>d) ∧ (⍳≢d)∘.>(⍳≢d))
0 0 1 0 3 4 3 0 7 8 8 7 11 11 7
```

Note that the time complexity for this is dominated by having to calculate
the outer products, which even given infinite parallelism, take $O(n)$ time.
We will slowly chip away at this, to be far better.

#### Converting from depth vector to parent vector, Take 4 (log critial depth)
We will use the Key(`⌸`) operator which allows us to create key value pairs.

```
$ d ← 0 1 2 1 2 3 2 1 2 3 3 2 3 3 2
$ ]disp (⍳≢d) ,¨ d ⍝ zip d with indexes
┌→──┬───┬───┬───┬───┬───┬───┬───┬───┬───┬────┬────┬────┬────┬────┐
│0 0│1 1│2 2│3 1│4 2│5 3│6 2│7 1│8 2│9 3│10 3│11 2│12 3│13 3│14 2│
└~─→┴~─→┴~─→┴~─→┴~─→┴~─→┴~─→┴~─→┴~─→┴~─→┴~──→┴~──→┴~──→┴~──→┴~──→┘
```

```
$ d ← 0 1 2 1 2 3 2 1 2 3 3 2 3 3 2
$ ]display b ← {⍺ ⍵}⌸d  ⍝ each row i has tuple (i, js): d[js] = i
┌→──────────────────┐
↓   ┌→┐             │
│ 0 │0│             │
│   └~┘             │
│   ┌→────┐         │
│ 1 │1 3 7│         │
│   └~────┘         │
│   ┌→────────────┐ │
│ 2 │2 4 6 8 11 14│ │
│   └~────────────┘ │
│   ┌→───────────┐  │
│ 3 │5 9 10 12 13│  │
│   └~───────────┘  │
└∊──────────────────┘
```

In fact, it allows us to apply an arbitrary function to combine keys and values.
We will use a function that simply returns all the values for each key.

```
$ d ← 0 1 2 1 2 3 2 1 2 3 3 2 3 3 2
$ ]display b ← {⍵}⌸d ⍝ each row i contains values j such that d[j] = i.
┌→──────────────┐
↓0 0  0  0  0  0│
│1 3  7  0  0  0│
│2 4  6  8 11 14│
│5 9 10 12 13  0│
└~──────────────┘
```

Our first try doesn't quite work: it winds up trying to create a numeric matrix,
which means that we can't have different rows of different sizes. So, the
information that _only_ index `0` is such that `d[0] = 0` is lost. What we
can to is to wrap the keys to arrive at:

```
$ d ← 0 1 2 1 2 3 2 1 2 3 3 2 3 3 2
$ ]display b ← {⊂⍵}⌸d ⍝ d[b[i]] = i
┌→───────────────────────────────────────────┐
│ ┌→┐ ┌→────┐ ┌→────────────┐ ┌→───────────┐ │
│ │0│ │1 3 7│ │2 4 6 8 11 14│ │5 9 10 12 13│ │
│ └~┘ └~────┘ └~────────────┘ └~───────────┘ │
└∊───────────────────────────────────────────┘
```
Consider the groups `b[2] = (2 4 6 8 11 14)` and `b[3] = (5 9 10 12 13)`. All of `3`'s parents
are present in `2`. Every element in `3` fits at some location in `2`. Here is what
the fit would look like:

```
b[2]  2 4 _ 6 8 _  _ 11 __ __ 14   (nodes of depth 2)
b[3]      5     9  10   12 13      (leaf nodes)
          4     8   8   11 11      (parents: predecessor of b[3] in b[2])

              ∘:0                               0
┌──────────┬──┴─────────────────┐
a:1        b:3                 c:7              1
│      ┌───┴───┐     ┌──────────┼───────┐
p:2    q:4     r:6   s:8        t:11    u:14    2
       │             │          │
       │          ┌──┴──┐     ┌─┴───┐
       v:5        w:9   x:10  y:12  z:13        3
```

We use the Interval Index(`⍸`) operator to solve the problem of finding the
parent / where we should sqeeze a node from `b[3]` into `b[2]`
(This is formally known as the
[predecessor problem](https://en.wikipedia.org/wiki/Predecessor_problem))

```
⍝ left[a[i]] is closest number < right[i]
⍝ left[a[i]] is the predecessor of right[i] in left[i].
$ a ← (1 10 100 1000) ⍸ (1 2000 300 50 2 )
0 3 2 1 0
```

Now, we can use the technology of predecessor to find parents
of depth 3 nodes among the depth 2 nodes:

```
$ depth2 ← 2 4 6 8 11 14
$ depth3 ← 5 9 10 12 13 ⍝ parents (from chart): 4 8 8 11 11
$ depth3parentixs ← depth2 ⍸ depth3
$ depth3parents  ← depth2[depth3parentixs]
4 8 8 11 11

              ∘:0                               0
┌──────────┬──┴─────────────────┐
a:1        b:3                 c:7              1
│      ┌───┴───┐     ┌──────────┼───────┐
p:2    q:4     r:6   s:8        t:11    u:14    2
       │             │          │
       │          ┌──┴──┐     ┌─┴───┐
       v:5        w:9   x:10  y:12  z:13        3
```

We need to know one-more APL-ism: the `2-scan`. When we write
a usual scan operation, we have:

```
$ ⍳5
1 2 3 4 5
```
```
$ +/⍳5 ⍝ reduce
15
```

```
$ 2+/⍳5 ⍝ apply + to _pairs_ (2 = pairs)
3 5 7 9 ⍝ (1+2) (2+3) (3+4) (4+5)
```

```
$ 3+/⍳5 ⍝  apply + to 3-tuples
6 9 12 ⍝ (1+2+3) (2+3+4) (3+4+5)
```

We begin by assuming the parent of `i` is `i` by using `p←⍳≢d`.

```
$ d ← (0 1 2 1 2 3 2 1 2 3 3 2 3 3 2)
$ d2nodes ← {⊂⍵}⌸d
┌→┬─────┬─────────────┬─────────────┐
│1│2 4 8│3 5 7 9 12 15│6 10 11 13 14│
└→┴~───→┴~───────────→┴~───────────→┘
$ p←⍳≢d
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
```

Now comes the biggie:
```
$ findparent ← {parentixs ← ⍺⍸⍵ ⋄ p[⍵]←⍺[parentixs]}
```
- `⍺` is the list of parent nodes.
- `⍵` is the list of current child nodes.
- We first find the indexes of our parent nodes by using
  the `pix ← parent ⍸ child` idiom.
- Then, we find the actual parents by indexing into
  the parent list: `pix[parentixs]`.
- We write these into the parents of the child using:
  `p[children] ← parent[parent ⍸ child]`


This finally culminates in:
```
$ d←0 1 2 1 2 3 2 1 2 3 3 2 3 3 2
$ p←⍳≢d ⋄ d2nodes←{⊂⍵}⌸d ⋄ findp←{pix ← ⍺⍸⍵ ⋄ p[⍵]←⍺[pix]} ⋄ 2findp/d2nodes ⋄ p
0 0 1 0 3 4 3 0 7 8 8 7 11 11 7


    (0   1  2  3  4  5  6  7  8  9 10 11 12 13 14)  | indexes
d ← (0   1  2  1  2  3  2  1  2  3  3  2  3  3  2)  │ depths
P ← (0   0  1  0  3  4  3  0  7  8  8  7 11 11  7)  │ parent indices
              ∘:0                               0
┌──────────┬──┴─────────────────┐
a:1        b:3                 c:7              1
│      ┌───┴───┐     ┌──────────┼───────┐
p:2    q:4     r:6   s:8        t:11    u:14    2
       │             │          │
       │          ┌──┴──┐     ┌─┴───┐
       v:5        w:9   x:10  y:12  z:13        3
```

Which can be further golfed to:
```
$ p⊣2{p[⍵]←⍺[⍺⍸⍵]}⌿⊢∘⊂⌸d⊣p←⍳≢d
0 0 1 0 3 4 3 0 7 8 8 7 11 11 7
```

The total time complexity of this method assuming infinite parallelism is as follows:
```
$ p←⍳≢d ⋄ d2nodes←{⊂⍵}⌸d ⋄ findp←{pix ← ⍺⍸⍵ ⋄ p[⍵]←⍺[pix]} ⋄ 2findp/d2nodes ⋄ p
```
- `(p←⍳≢d)` can be filled in `O(1)` time.
- `(d2nodes←{⊂⍵}⌸d)` is searching for keys in a small integer domain, so this is `O(#nodes)` using
  radix sort as far as I know. However, the thesis mentions that this can be done in
  `O(log(|#nodes|))`. I'm not sure how, I need to learn this.
- For each call of `findp`, the call `(pix ← ⍺⍸⍵)` can be implemented using binary search
  leading to a logarthmic complexity in the size of `⍺` (since we are looking up
  for predecessors of `⍵` in `⍺`).
- The time complexity of the fold `2findp/d2nodes` can be done entirely in parallel
  since all the writes into the `p` vector are independent: we only write the
  parent of the current node we are looking at.


### 3.4: Computing nearest Parent by predicate

I'm going to simplify the original presentation by quite a bit.


```
     a b c d e f g h i  | names
     0 1 2 3 4 5 6 7 8  | indexes
P ← (0 0 1 2 0 4 5 6 7) | parents
X ← (0 1 0 0 1 1 0 0 0) | marked nodes

     a:0
┌────┴───┐
b:1(X)   e:4(X)
|        |
c:2      f:5(X)
|        |
d:3      g:6
         │
         h:7
         |
         i:8
```

We want to find nodes marked as `X` that are the closest parents to a
given node. The `X` vector is a boolean vector that has a `1` at
the index of each `X` node: `(b, e, f)`. So, the indexes `(1, 4, 5)`
are `1` in the `X` vector.

The output we want is the vector:

```
      0 1 2 3 4 5 6 7 8  | indexes
      a b c d e f g h i  | names
PX ← (0 0 1 1 0 4 5 5 5) | closest X parent index
      a a b b a e f f f  | closest X parent name

    a:0
┌────┴───┐
b:1(X)   e:4(X)
|        |
c:2      f:5(X)
|        |
d:3      g:6
         │
         h:7
         |
         i:8
```

The incantation is:

```
$ I←{(⊂⍵)⌷⍺} ⍝ index LHS by RHS | (100 101 102 103)[(3 1 2)] := 103 101 102
$ PX ← P I@{X[⍵]≠1} ⍣ ≡ P
0 0 1 1 0 4 5 5 5
```

TODO. At any rate, since this does not require any writes and purely reads,
and nor does it need any synchronization, this is fairly straightforward
to implement on the GPU.

### 3.5: Lifting subtrees to the root

Once we have marked our `X` nodes, we now wish to lift entire subtrees of `X`
up to the root.
-  This pass displays how to lift subtrees and add new nodes to replace the subtree's original nodes.
- Luckily, there are no _sibling_ relationships that need to be maintained since
  we are uprooting an entire subtree.
- There are no _ordering constraints_ on how the subtrees should be arranged at
  the top.
- Hence, we can simply add new nodes to the _end_ of the tree (in terms of the preorder traversal).
  Adding to the middle of the tree will be discussed later.

There is some good advice in the thesis:
> When using APL primitives this way, it may be good to map
> their names and definitions to the domain of trees. For example,
> the primitive `⍸Predicate` is read as "the nodes where `Predicate` holds"
> and not as "the indexes where `Predicate` is 1".

For example, given the tree:

```
      0 1 2 3 4 5  | indexes
      a b c d e f  | names
P  ← (0 0 1 0 3 4) | parents
X  ← (0 1 0 1 1 0) | X nodes
PX ← (0 0 1 0 3 4) | closest X parent index

    a:0
┌────┴───┐
b:1(X)   d:3(X)
|        |
c:2      e:4(X)
         |
         f:5
```

we want the transformed tree to be:

```
    a:0
┌────┴───┐
bp:1(X)   ep:4(X)
---------
b:1(X)
|
c:2
---------
e:4
|
fp:5
---------
f:5(X)
|
g:6
```

We first look for nodes that need to be lifted.  There are:
- Non-root nodes (ie, nodes whose parents are not themselves: `p≠(⍳≢p)`)
- Which have the property `X`.

```
nodes←⍸(X ∧ p≠(⍳≢p))  ⍝ ⍸:pick indexes.
```

### 3.6: Wrapping Expressions
### 3.7: Lifting Guard Test Exprsessions
### 3.8: Couting rank of index operators
### 3.9: Flattening Expressions
### 3.10: Associating Frame slots and variables
### 3.11: Placing frames into a lexical stack
### 3.12: Recording Exported names
### 3.13: Lexical Resolution

### 5.2.1 Traversal Idioms
### 5.2.2 Edge Mutation Idioms
### 5.2.3 Node Mutation Idioms

# Things I wish I knew when I was learning APL

- For pasting multi-line code,
  [there is a bug in the bug tracker for RIDE](https://github.com/Dyalog/ride/issues/323).
  For multi-line dfns, one can use `∇`. For multi-line values, I don't know yet.

- Operators in APL terminology (such as `¨`) are higher order functions.
  Thus, an operator allows one to modify known functions.

- Use `]disp` and `]display` to understand the structure of APL arrays.

- Set `]box on -style=max` to _always enable_ drawing arrays with `]display`.
  This is supremely useful as a newbie to understand array structure.

- Set `]box on -trains=parens` to render trains as trees. Super
  helpful when attempting to grok `train` code.

- Set `]boxing on` to enable boxing for trains, arguments, everything.

# Every ideal that is maximal wrt. being disjoint from a multiplicative subset is prime

I ran across this when reading another question on math.se, so I
[posted this proof for verification](https://math.stackexchange.com/questions/3570129/proof-verification-request-complement-of-multiplicative-set-is-ideal-iff-the-id) just to be sure I wasn't missing
something.

We wish to characterise prime ideals as precisely those that are disjoint from
a multiplicative subset $S \subseteq R$. That is:

- An ideal $P$ is prime iff $P = R \setminus S$, where $S$ is a multiplicative subset
  that cannot be made larger (ie, is maximal wrt to the $\subseteq$ ordering).

I'll be using the definition of prime as:

- An ideal $P$ is prime if for all $x, y \in R$,
  $xy \in P \implies x \in P \lor y \in P$.


#### Prime ideal implies complement is maximal multiplicative subset:

Let $S = \equiv R \setminus P$ be the complement of the prime ideal $P \subsetneq R$
in question.
- Since $P \neq R$, $1 \not \in $P. (if $1 \in P$, then every element $x . 1 \in P$
  since $P$ is an ideal, and must be closed under multiplication with the
  entire ring). Hence, $1 \in S$.
- For any $x, y \in S$, we need $xy \in S$ for $S$ to be mulitplicative.
- For contradiction, let us say that $x, y \in S$ such that $xy \not \in S$.
  Translating to $P$, this means that $x, y \not \in P$ such that $xy \in P$.
  This contradictions the definition of $P$ being prime.

#### Ideal whose complement is maximal multiplicative subset implies ideal is prime.

- Let $I$ be an ideal of the ring $R$ such that its complement $S \equiv R / I$
  is a maximal multiplicative subset.
- Let $i_1 i_2 \in I$. For $I$ to be prime,
  we need to show that $i_1 \in I$ or $i_2 \in I$.
- For contradiction, let $i_1, i_2 \not \in I$.
  Thus, $i_1, i_2 \in S$. Since $S$ is multiplicative, $i_1 i_2 \in S$. That is,
  $i_1 i_2 \not \in I$ (since $I$ is disjoint from $S$).
- But this violates our assumption that $i_1 i_2 \in I$. Hence, contradiction.


# Getting started with APL

- Install [Dyalog APL](https://www.dyalog.com/download-zone.htm).
- Setup [RIDE](https://github.com/Dyalog/ride), the IDE for dyalog APL.
  This IDE comes with auto complete, good key bindings, a top bar chock-full of
  information of all the APL symbols. It's really well designed and a pleasure
  to use.
- Follow the [Dyalog tutorial](https://tutorial.dyalog.com/), solving it
  chapter by chapter.
- Bookmark [APLCart](https://aplcart.info/), a collection of APL idioms, and
  refer to it when in need.
- Ask questions at [the APL orchard](https://chat.stackexchange.com/rooms/52405/the-apl-orchard)

# SpaceChem was the best compiler I ever used

It's kind of sad that this is the case, but on thinking about this, I realised
that the SpaceChem game was essentially a compiler, and it was such a pleasure
to learn how to use and debug --- the visual nature of it made it amazing to
find out.

# Mnemonic for Kruskal and Prim

I often forget which is which, so I came up with this:

- Prim is very prim and proper, and therefore doesn't spread herself out. She
  picks out the minimum spanning tree one vertex at a time.


# Legendre transform

<img  src="./static/legendre.png">


# Cartesian Trees

Cartesian trees construct a tree $T = C(A)$ given an array $A$, such that
range minimum query (RMQ) on the array $A$ is equivalent to the lowest common ancestor (LCA)
of the nodes of the tree $T$.


<img src="./static/cartesian-tree.svg">

Note that the tree looks like a _min-heap_.

To see the connection to LCA, if we want to find the range minimum in the range containing the
elements `[12, 10, 20, 15, 18]` of the array, the minimum is `10`, which is
indeed the lowest common ancestor of the nodes of `12` and `18` in the tree.

#### Building a Cartesian tree in linear time:

#### Converting LCA to RMQ

We can go the other way, and convert an LCA problem into a RMQ problem. We
perform an inorder traversal of the nodes, scribbling down the
depth of the node ([Link to lecture at 15:30](https://youtu.be/0rCFkuQS968?t=934)).
We ask for the _argmin_ version of RMQ, that gives us the _index_ of
the node with the lowest depth. This gives us the index of where the node lives.

#### Universe reduction in RMQ

We can have an arbitrary ordered universe, on which we want to perform RMQ.
We can convert this to LCA by using a cartesian tree, and then convert to
a "clean" RMQ (by using the LCA -> RMQ using depth conversion). This now
will give us way faster operations (since we now have integers).

#### `+-1` RMQ:

We want the differences between nodes to have a difference of only `+-1`. We
had a much wider gap. Here, we perform an Euler tour (walk the tree DFS search order),
and sribble down every vertex we visit.

To find the LCA, we perform the RMQ on the locations of the _first_ occurence
of the node. (I think we don't actually need the first occurence, any
occurence will do).

#### References

- Material shamelessly written down from
  [Eric Demaine's excellent (MIT 6.851 Advanced Data Structures): Lecture 15](https://www.youtube.com/watch?v=0rCFkuQS968)
- Image of the tree [taken from WikiMedia](https://upload.wikimedia.org/wikipedia/commons/d/d5/Cartesian_tree.svg)




# DFS numbers as a monotone map

Really, we want a partial order that is defined with the tree as the
Hasse diagram. However, performing operations on this is hard. Hence,
the DFS numbering is a good monotone map from this partial order
to the naturals, which creates a total order.

I want to think about this deeper, I feel that this might be a good way
to think about the `low` numbers that show up in
[tarjan's algorithm for strongly connected components](https://en.wikipedia.org/wiki/Tarjan%27s_strongly_connected_components_algorithm)

This also begs the question: can we use other partial orders, that chunk
some information, but don't lose _all_ the information as going to a total
order (the naturals) does?

# Self attention? not really

The code is taken from [The annotated transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html)
which explains the "attention is all you need paper".

On skimming the code, one sees the delightful line of code:

```py
class EncoderLayer(nn.Module):
  "Encoder is made up of self-attn and feed forward (defined below)"
  def __init__(self, size, self_attn, feed_forward, dropout):
     super(EncoderLayer, self).__init__()
     self.self_attn = self_attn
     self.feed_forward = feed_forward
     self.sublayer = clones(SublayerConnection(size, dropout), 2)
     self.size = size
  def forward(self, x, mask):
    "Follow Figure 1 (left) for connections."
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
    return self.sublayer[1](x, self.feed_forward)
```

where the line:

```py
x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
```

seems to imply that we are, indeed, performing a self attention with the same
value `x` as the query, key, and value.

However, reading the code of the self-attention (or the paper) leads
one to realise:

```py
class MultiHeadedAttention(nn.Module):
  def __init__(self, h, d_model, dropout=0.1):
    "Take in model size and number of heads."
    super(MultiHeadedAttention, self).__init__()
    assert d_model % h == 0
    # We assume d_v always equals d_k
    self.d_k = d_model // h
    self.h = h
    self.linears = clones(nn.Linear(d_model, d_model), 4)
    self.attn = None
    self.dropout = nn.Dropout(p=dropout)

  def forward(self, query, key, value, mask=None):
    "Implements Figure 2"
    if mask is not None:
        # Same mask applied to all h heads.
        mask = mask.unsqueeze(1)
    nbatches = query.size(0)

    # 1) Do all the linear projections in batch from d_model => h x d_k
    query, key, value = \
        [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)
         for l, x in zip(self.linears, (query, key, value))]

    # 2) Apply attention on all the projected vectors in batch.
    x, self.attn = attention(query, key, value, mask=mask,
                             dropout=self.dropout)

    # 3) "Concat" using a view and apply a final linear.
    x = x.transpose(1, 2).contiguous() \
         .view(nbatches, -1, self.h * self.d_k)
    return self.linears[-1](x)
```

where we notice:

```py
# 1) Do all the linear projections in batch from d_model => h x d_k
query, key, value = \
  [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)
   for l, x in zip(self.linears, (query, key, value))]

# 2) Apply attention on all the projected vectors in batch.
x, self.attn = attention(query, key, value, mask=mask,
                         dropout=self.dropout)
```

where we see that `query, key, value` are being linearly transformed
before being used. Hence, an input of $(x, x, x)$ is transformed
to $(q', k', v') = (Qx, Kx, Vx)$ where $Q, K, V$ are arbitrary matrices.

Next, when we pass these into attention, the output we get is:

$$
\text{softmax}(q', k'^T) v = (Q x) (K x)^T (V x) = Q x x^T K^T V x
$$

the code below is the same thing, spelled out:


```
def attention(query, key, value, mask=None, dropout=None):
    "Compute 'Scaled Dot Product Attention'"
    d_k = query.size(-1)
    scores = torch.matmul(query, key.transpose(-2, -1)) \
             / math.sqrt(d_k)
    if mask is not None:
        scores = scores.masked_fill(mask == 0, -1e9)
    p_attn = F.softmax(scores, dim = -1)
    if dropout is not None:
        p_attn = dropout(p_attn)
    return torch.matmul(p_attn, value), p_attn
```

So It's not _really_ self attention: it's more like: modulated attention
to self `:)`


# Coarse structures

A coarse structure on the set $X$ is a collection of relations on $X$:
$E \subseteq 2^{X \times X}$ (called as _controlled sets_ / _entourages_)
such that:

- $(\delta \equiv \{ (x, x) : x \in X \}) \in  E$.
- Closed under subsets: $\forall e \in E, f \subset e \implies f \in E$.
- Closed under transpose: if $e \in E$ then $(e^T \equiv \{ (y, x) : (x, y) \in e \}) \in E$.
- Closed under finite unions.
- Closed under composition: $\forall e, f \in E, e \circ f \in E$, where $\circ$
  is composition of relations.

The sets that are controlled are "small" sets.

The bounded coarse structure on a metric space $(X, d)$ is the set of all relations
such that there exists a uniform bound such that all related elements are within
that bounded distance.
$$
(e \subset X \times X) \in E \iff \exists \delta \in \mathbb R, \forall (x, y) \in E, d(x, y) < \delta
$$


We can check that the functions:
- $f: \mathbb Z \rightarrow \mathbb R, f(x) \equiv x$ and
- $g: \mathbb R \rightarrow \mathbb Z, g(x) \equiv \lfloor x \rfloor$

are coarse inverses to each other.

I am interested in this because if topology is related to semidecidability,
then coarse structures (which are their dual) are related to..?

#### References
- [What is a.. coarse structure by AMS](http://www.ams.org/notices/200606/whatis-roe.pdf)

# Matroids for greedy algorithms (TODO)

#### Definitions of matroids

A matrioid $M$ is a set $X$ equipped with an independence set $I \subseteq 2^X$.
- The empty set is independent: $\emptyset \in I$.
- The independence set is downward-closed/closed under subsets:  $ \forall i \in I, \forall i' \subseteq i, i' \in I$.
- For any independent sets $A, B \in I$, if $\vert A \vert$ is larger than
  $\vert B \vert$, then we must be able to add an element from
  $a \in A$ into $B' \equiv B \cup {a}$ such that $B'$ is both independent and larger than $B$:
  $B' \in I \land \vert B' \vert > \vert B \vert$. (**The exchange property**)

#### Example 1: Linearly independent sets
Let $V$ be a vector space. The independent sets $I$ are of the form:


$$ I \equiv \{ S \subseteq V ~:~ \text{vectors in $S$ are lineary independent} \} $$

This is an independence system because the empty set is linearly independent,
and subsets of a linearly independent collection of vectors will be linearly
independent.

The exchange property is satisfied because of linear algebraic reasons.

#### Example 2: The graphic/cyclic Matroid: Matroid of Forests

Let $G = (V, E)$ be a graph. Then collections of edges of the form:

$$ I \equiv \{ F \subseteq E : \text{$F$ contains no cycles} \} $$

is an independence system because the empty forest is a forest, and
a subset of edges of a forest continues to be a forest.

To check the exchange property, TODO

#### Example 3: The partition matroid

Consider the partition matroid $M \equiv (E, I)$, where we have a
partitioning of $E$ known as $E_i$, and numbers $k_i$ the
independence set consists of subsets $F$ which have at most $k_i$
elements in common with each $E_i$.
$$
I \equiv \{ F \subseteq E  : \forall i = 1, \dots N, \vert F \cap E_i \vert \leq k_i \}
$$

The independence axioms are intuitively satisfied, since our constraints on picking
edges are of the form $\vert F \cap E_i \vert \leq k_i$, which will continue to
hold as $F$ becomes smaller.

For the exchange axiom, let $\vert Y \vert > \vert X \vert$. Then, we can assert that for some index
$i$, it must be the case that $\vert Y \cap E_i \vert > \vert X \cap E_i \vert$. Hence,
we can add an element in $E_i \cap (Y / X)$ into $X$ whilst still maintaining independence.


#### Bases and Circuits

- **Bases** are the maximal independent sets of $I$ (ordered by inclusion). On adding an element into a basis element, they
  will become dependent. They are called bases by analogy with linear algebra.

- **Circuits** are minimal dependent sets of $I$. This comes from analogy with trees: if we remove an element
  from any circuit (loop) in a graph, what we are left with is a tree.

A matroid can be completely categorized by knowing either the bases or the circuits of that matroid.

#### Unique Circuit property
- **Theorem**: Let $M \equiv (E, I)$ be a matroid, and let $S \in I, e \in E$ such that $S \cup \{e \} \not \in I$.

Then, there exists a **unique circuit** $C \subseteq S \cup \{ e \}$.

That is, when we go from independent to dependent by adding an element, we will
have a **single, unique circuit**. For example, when we add an edge into a
forest to create a cycle, this cycle will be unique!

##### Proof

Let $C_1, C_2$ be circuits
created when $e$ was added into $S$, where $C_1$ is the **largest** circuit of $S$,
and $C_2$ is the **smallest** circuit of $S$.

Notice that $C_1, C_2$ __must__ contain $e$ ---
if they did not, then $C_1, C_2$ would be circuits in
$S$, contradicting the assumption that $S$ is independent.

Recall that $C_1, C_2$ are both circuits, which means that removing even a
single element from them will cause them to become independent sets.

Let us contemplate $C \equiv C_1 \cup C_2$. Either $C = C_1$ in which
case we are done.

Otherwise, $\vert C \vert > \vert C_1 \vert$, $\vert C \vert > \vert C_2 \vert$.

Otherwise, consider $C' \equiv C \ \{ e \} = (C_1 \cup C_2) \ \{e\} = (C_1 \ \{e\}) \cup (C_2 \ \{ e \})$.
- $C' \subseteq S$, since $C_1 \ \{e\}, C_2 \ \{e\} \subseteq S$.
- $S$ is an independent set, all of whose subsets are independent by
  definition.  So $C'$ is an independent set.
- $\vert C' \vert \geq \vert C_1 \vert$, $\vert C' \vert \geq \vert C_2 \vert$.

Now, we consider $C$. Clearly, this is a dependent set,
since $C_1 \subsetneq C$, and $C_1$ is a dependent set.

Since, $C = C' \cup \{e \}$, this means that $C'$ is a maximally independent set.
Since $C'$ does not contain $e$, $C' = S$.


#### Rank functions

A rank function of a matroid $M \equiv \langle X, I \rangle$
is a function:

$$
r: 2^X \rightarrow \mathbb N : r(S) = \max \{ \vert T \vert : T \subseteq S \land T \in I \}
$$

That is, for any subset $S \subseteq X$, $r(S)$ is the cardinality of the
largest independent subset of $S$.

- In the matroid of linearly independent sets of vectors, the rank of
  a set of vectors is the dimension of their spanning set.


In this matroid, the

TODO: picture


#### Intersection of matroids is not necessarily a matroid:

```
M1 = < d {[(a) (b)] c}>
```

```
M2 = < {d [(a) (b)]} c>
```

The intersection of these two matroids will be:

```
M1 cap M2 = < d [(a) (b)] c>
```

This is not a matroid because the exchange property fails. There's no
way to go from `[a, b]` to `< d a b c >` by exchanging one element.



#### Bipartite matching as matroid intersection

Matchings in a bipartite graph $G = (V, E)$ with partition $(A, B)$ arise
as the intersection of the independent sets of two matroids.
We will denote by $\delta: V \rightarrow 2^E$ the function which takes
a vertex to the set of edges incident on that vertex.

Let $M_A$ be a _partition matroid_: $M_A \equiv (E, I_A)$ where $I_A$ is:
$$
I_A \equiv \{ F \subseteq E : \vert F \cap \delta(a) \vert \leq 1 \forall a \in A \}
$$
That is, in $I_A$, every independent set has for each vertex of $A$, at most
one edge incident. We need to check that this is an independent set.
The empty set of no edges is independent. If some collection of edges are
such that they have at most one edge incident, then removing edges can
only _decrease_ incidence. Hence, it's also downward closed.


TODO: add picture

Similarly, we define $M_B \equiv (E, I_B)$:
$$
I_B \equiv \{ F \subseteq E : \vert F \cap \delta(b) \vert \leq 1 \forall b \in B \}
$$

Now, notice that any collection of edges $F \in I_A \cap I_B$ is a legal
matching, since the edges cover all vertices of $A$ and $B$ at most once.
The largest element of $I_A \cap I_B$ is the _maximum matching_ that we
are looking for.

#### Largest common independent set

Given two matroids $M_1 \equiv (E, I_1)$, $M_2 \equiv (E, I_2)$, with rank
functions $r_1$ and $r_2$. Let $S \in I_1 cap I_2$ and let $F \subseteq E$.
-  $\vert S \vert = \vert S \cap F \vert + \vert S \cap (E / F) \vert$.


#### References:
- [Michel Goeman's standalone notes on matroids](http://math.mit.edu/~goemans/18433S11/matroid-notes.pdf)
- [Michel Goeman's standalone notes on matroid intersection](http://math.mit.edu/~goemans/18433S11/matroid-intersect-notes.pdf)
- [Lecture 11 of Michel Goeman's lecture on Advanced Combinatorial Optimisation](https://math.mit.edu/~goemans/18438F09/lec11.pdf)
- [Video lecture on fixed-parameter tractability and matroid interesction](https://www.youtube.com/watch?v=BA7ZUz5c3V0)
- [FTP Lecture 25: introduction to matroids](https://www.youtube.com/watch?v=6uGcXMjse20)
- [FTP lecture 26: Faster matroid intersection](https://www.youtube.com/watch?v=eq0nb3C9JWU)

# Grokking Zariski

There's a lot written on the Zariski topology on the internet, but most
of them lack explicit examples and pictures. This is my attempt to
communicate what the Zariski topology looks like, from the perspectives
that tickle my fancy (a wealth of concrete examples,
topology-as-semi-decidability, and pictures).

#### The Zariski topology

Recall that the Zariski topology is defined by talking about what its
closed sets are. The common zero sets of a family of polynomials are
the closed sets of the Zariski topology. Formally, the topology $(\mathbb R^n, \tau)$
has as closed sets:

$$
\{ x \in \mathbb R^n : \forall f_i \in \mathbb R[X_1, X_2, \dots X_n],  f_i(x) = 0  \}
$$

Open sets (the complement of closed sets) are of them form:

$$
\{ x \in \mathbb R^n : \exists f_i \in \mathbb R[X_1, X_2, \dots X_n],  f_i(x) \neq 0  \} \in \tau
$$

The empty set is generated as $\{ x \in \mathbb R^n : 0 \neq 0 \}$ and the
full set is generated as $\{ x \in \mathbb R^n : 1 \neq 0 \}$.


#### Semi-decidability

Recall that in this view of topology, for a space $(X, \tau)$, for every
open set $O \in \tau$, we associate a turing machine $T_O$ which semi-decides
inclusion. That is, if a point is in $O$ then it halts with the output `IN-SET`.
if the point is not in $O$, $T_O$ infinite loops. Formally:

$$
\begin{aligned}
x &&\in O \iff \text{$T_O$ halts on input $x$} \\
x &&\not \in O \iff \text{$T_O$ does not halts on input $o$}
\end{aligned}
$$

Alternatively, for a closed set $C \in \tau$, we associate a a turing machine
$T_C$ which semi-decides exclusion. That is, if a point is _not_ in $C$
it halts with the output "NOT-IN-SET". If the point is in $C$, the turing
machine $T_C$ infinite loops.

Now in the case of polynomials, we can write a function that semidecides
exclusion from closed sets:

```cpp
# return NOT-IN-SET of x is not a zero of the polynomial
def is_not_in_zeros(poly, x0):
  precision = 0 # start with zero precision
  while True:
    if poly(x0[:precision]) != 0: return NOT-IN-SET
    precision += 1 # up the precision
```

Since we can only evaluate a polynomial up to some finite precision, we
start with zero precsion and then gradually get more precise. If some
$x0$ is _not_ a root of $poly$, then at some point, we will have
that $poly(x0) /neq 0$. If $x0$ is indeed a root, then we will never halt
this process; We will keep getting `poly(x0[:precision]) = 0` for all
levels of precision.

#### `Spec(R)`

- To setup a topology for the prime spectrum of a ring, we define the topological
  space as $Spec(R)$, the set of all prime ideals of $R$.
- The closed sets of the topology are $\{ V(I) : I \text{is an ideal of } R \}$,
  where the function $V: \text{Ideals of } R \rightarrow 2^{\text{Prime ideals of } R}$
  each ideal to the set of prime ideals that contain it. Formally,
  $V(I) = \{ p \in Spec(R) : I \subseteq p \}$.
- We can think of this differently, by seeing that we can rewrite the condition
  as  $V(I) = \{ P \in Spec(R) : I \xrightarrow{P} 0 \}$: On rewriting using the prime ideal $P$, we send the ideal $I$ to $0$.
- Thus, the closed sets of $Spec(R)$ are precisely the 'zeroes of polynomials' / 'zeroes of ideals'.
- To make the analogy precise, note that in the polynomial case, we imposed a
  topology on $\mathbb R$ by saying that the closed sets were $V(p_i) = \{ x \in \mathbb R : p(x) = 0 \}$
  for some polynomial $p \in \mathbb R[x]$.
- Here, we are saying that the closed sets are $V(I) = \{ x \in Spec(R) : I(x) = 0 \}$
  for some ideal $I \in R$. so we are looking at  ideals as functions
  from the prime ideal to the reduction of the ideal. That is, $I(P) = I/P$.

#### $Spec(\mathbb Z)$ from this perspective

Since $\mathbb Z$ is a PID, we can think of numbers instead of ideals. The above
picture asks us to think of a number as a function from a prime to a reduced
number. $n(p) = n \% p$. We then have that the closed sets are those primes
which can zero out some number. That is:

$$
\begin{aligned}
V(I) = \{ x \in Spec(\mathbb Z) : I(x) = 0 \}
V((n)) = \{ (p) \in Spec(\mathbb Z) : (n)/(p) = 0 \}
V((n)) = \{ (p) \in Spec(\mathbb Z) : (n) \mod (p) = 0 \}
\end{aligned}
$$

So in our minds eye, we need to imagine a space of prime ideals (points), which
are testing with all ideals (polynomials). Given a set of prime ideals (a tentative locus, say a circle),
the set of prime ideals is closed if it occurs as the zero of some collection of ideas
(if the locus occurs as the zero of some collection of polynomials).


#### Nilpotents of a scheme

- Consider the functions $f(x) = (x - 1)$ and $g(x) = (x - 1)^2$. as functions on $\mathbb R$.
  They are indistinguishable based on Zariski, since their zero sets are
  the same ($\{ 1 \}$).

- If we now move to the scheme setting, we get two different schemes: $R_g \equiv \mathbb R[X] / (x - 1) \simeq \mathbb R$,
  and $R_g \equiv R[X] / (x - 1)^2$.

- In the ring $R_g$, we have an element $(x-1)$
  such that $(x-1)^2 = 0$, which is a nilpotent. This "picks up" on the repeated
  root.

 - So the scheme is stronger than Zariski, as it can tell the difference
   between these two situations. So we have a kind of "infinitesimal thickening"
   in the case of $R_g$.
   [For more, check the `math.se` question: 'Geometric meaning of the nilradical'](https://math.stackexchange.com/questions/3751728/geometric-meaning-of-the-nilradical)

- Another example is to consider (i) the pair of polynomials $y = 0$
  (the x-axis) and $y = \sqrt(x)$.
  The intersection is the zero set of the ideal
  $(y, y^2 - x) = (y, 0 - x) = (y, x)$.

- Then consider (ii) the pair of $y = 0$ (the x-axis) and $y = x^2$.
  Here, we have "more intersection" along
  the x-axis than in the previous case, as the parabola is "aligned" to the x-axis.
  The intersection is the zero set of the ideal
  $(y, y - x^2) = (y, 0 - x^2) = (y, x^2)$.

- So (i) is governed by $\mathbb R[X, Y] / (y, x)$, while (ii) is governed by $\mathbb R[X, Y] /(y, x^2)$
  which has a nilpotent $x^2$. This tells us that in (ii), there is an
  "infinitesimal thickening" along the $x$-axis
  of the intersection.

# My preferred version of quicksort

Wikipedia lists the implementation of quicksort as:

```cpp
algorithm quicksort(A, lo, hi) is
    if lo < hi then
        p := partition(A, lo, hi)
        quicksort(A, lo, p - 1)
        quicksort(A, p + 1, hi)

algorithm partition(A, lo, hi) is
    pivot := A[hi]
    i := lo
    for j := lo to hi do
        if A[j] < pivot then
            swap A[i] with A[j]
            i := i + 1
    swap A[i] with A[hi]
    return i
```

Here, the indeces `[lo..i-1]` have values less than the pivot, while
`[i..j]` are great or equal to the pivot.

##### The version I prefer

```cpp
// #define SWAP(ix, ix2) { int t = a[ix]; a[ix] = a[ix2]; a[ix2] = t; }
// sorts the interval [l, r]
void qs(int l, int r) {
    if (r - l < 0) return;
    int part = a[r]; // the partition

    // a[getill...n] >= part (getill = greater or equal till)
    // starts at r since we know that a[r] >= (partition=a[r])
    int getill = r;
    // a[l..lttill] < part (lttill = less or equal till.
    // starts at (l-1) since we do not know about any value < partition
    int lttill = l-1;


    // loop until they start probing into the other set
    while(!(lttill+1 >=getill || getill-1 <=lttill)) {
        // if the speculated element is < partition
        if (a[getill-1] < part) {
            // swap the value at getill-1 will the slot at lttill+1
            SWAP(getill-1, lttill+1);
            // increment lttill, since we KNOW that the
            // value at lttill+1 = a[getill-1] is < part
            lttill++;
        } else {
            // all we know is that a[getill-1] < part, so we can engulf
            // the region into
            getill--;
        }
    }
    // the partitions must be next to each other, since we have engulfed everything
    assert(getill - lttill == 1);
    // move the partition value to the center.
    SWAP(getill, r);

    // recurse:solve [l..littil] (leave getill=part alone) solve [getill+1..r]
    qs(l, lttill);
    qs(getill+1, r);
}
```

This implementation to me makes very clear to me what information is "known":
- The segments that is strictly less than the partition.
- The segment that is strictly great or equal the partition.

It also makes clear what is being "probed"/"tentative":
- anything we are accessing as `+-1` is not known yet, we are feeling out
  the boundaries of our partitions.

The termination condition is clear: when one partition starts reaching into
the other partitions resources, its done.

Due to using closed intervals everywhere, it's very easy to see precisely
what data starts and ends where.

What version of quicksort do you prefer? Drop me an email!

# Geometric proof of Cauchy Schwarz inequality

<img src="./static/cauchy-schwarz.svg">

- All credit goes to `p0a` on `##math` on freenode for teaching me this proof!

Here's one fun application of Cauchy-Schwarz. We can apply it to two vectors
$x=(\sqrt a, \sqrt b)$ and $y=(\sqrt b, \sqrt a)$ to derive the AM-GM
inequality:




# Dataflow analysis using Grobner basis

This was a quick experiment in using Grobner basis to model situations. We
can represent our dataflow analysis constraints in terms of polynomial
rewrites over $F_2$.

Given the program:

```py
p = { 0: ["=", "x", 'y'],
      1: ['br', 2, 100],
      2: ['=', 'z', 'x'],
      3: ['br', 2],
      100: ['ret', 'z'] }
```

whose semantics I hope are fairly straightforward --- the dictionary represents
instruction locations. Instructions proceed sequentially. branch moves
control flow around. Note that `br` can branch to multiple locations,
since we are not control-flow sensitive.

The idea is that since in a dataflow analysis, we need information at
each variable at each program point, we can create a ring of polynomials
over $F_2$ for each variable at each program point. So in this case,
we wold need:

```
R = F_2[x0, y0, z0, x1, y1, z1, x2, y2, z2, x3, y3, z3, x100, y100, z100]
```

We then add elements into the ideal that represents our constraints.
For example, to perform dataflow analysis, we need to add constraints
about how if a variable `z` is alive, all variables that are used
to compute `z` at `100` are alive. This sets up equations that may
have cycles (in the case of loops).

These are usually resolved using the
[Kildall algorithm](https://en.wikipedia.org/wiki/Data-flow_analysis#An_iterative_algorithm).

However, we can also ask SAGE to kindly solve the Grobner basis. I hypothesize
that the "easy" dataflow problems out to be [toric ideals](https://hal.inria.fr/inria-00074446/document)
which admit much faster solutions.



# Fenwick trees and orbits

I learnt of a nice, formal way to prove the correctness of Fenwick
trees in terms of orbits that I wish to reproduce here.

One can use a Fenwick tree to perform cumulative sums
$Sum(n) \equiv \sum_{i=0}^n A[i]$, and updates $Upd(i, v) \equiv A[i] += v$. Naively,
cumulative sums can take $O(n)$ time and updates take $O(1)$ time.

A Fenwick tree can perform _both_ in $\log(n)$. In general, we can perform
any monoid-based catenation and update in $\log(n)$, **as long as our queries**
start from the 0th index till some index $n$. So we can only handle monoidal
fold queries of the form $\sum_{i=0}^n$ and point updates.

#### organization

We allow indexes $[1, 2, \dots n]$. The node with factorization $i \equiv 2^k \times l$,
$2 \not \vert l$ (that is, $k$ is the highest power of $2$ in $i$)
is responsible for the interval $[i-2^k+1, i] = (i-2^k, i]$.


I'm going to state all the manipulations in terms of prime factorizations,
since I find it far more intuitive than bit-fiddling. In general, I want
to find a new framework to discover and analyze bit-fiddling heavy algorithms.

Some examples of the range of responsibility of an index are:

- $1 = 2^0 \times 1 = (0, 1]$ (Subtract $2^0 = 1$)
- $2 = 2\times 1 = (0, 2]$ (Subtract $2^1 = 2$)
- $3 = 3 = (2, 3]$
- $4 = 2^2 = (0, 4]$
- $5 = 5 = (4, 5]$
- $6 = 2\times 3 = (4, 6]$
- $7 = 7 = (6,7]$
- $8 = 2^3 = (0,8]$
- $9 = 9 = (8, 9]$
- $10 = 2\times 5 = (8, 10]$
- $11 = 11 = (10, 11]$
- $12 = 2^2\times 3 = (8, 12]$
- $13 = 13 = (12, 13]$
- $14 = 2\times 7 = (12, 14]$
- $15 = 15 = (14, 15]$
- $16 = 2^4 = (0, 16]$

<img src="./static/fenwick-structure.gif">


#### query

To perform a cumulative sum, we need to read from the correct overlap regions
that cover the full array. For example, to read from $15$, we would want
to read:

- $a[15] = (14, 15], a[14] = (12, 14], a[12] = (8, 12], a[8] = (0, 8]$.

So we need to read the indices:
- $15=2^0 \cdot 15 \xrightarrow{-2^0} 14=2^1 \cdot 7 \xrightarrow{-2^1} 12=2^2\cdot3 \xrightarrow{-2^2} 8=2^3\cdot1 \xrightarrow{-2^3} 0$

At each  location, we strip off the value $2^r$. We can discover this value
with bit-fiddling: We claim that $a \& (-a) = 2^r$.

Let $a \equiv \langle x 1 0^r \rangle$. We wish to extract the output as $2^r = \langle 1 0^r \rangle$,
which is the power of 2 that we need to subtract from $a$ to strip the rightmost $1$.
We get:

$$
\begin{aligned}
&-a = \lnot a + 1 = x01^r + 1 = \overline{x}10^r \\
&a \& (-a) = a \& (\lnot a + 1) = (x 10^r) \& (\overline{x}10^r) = 0^{|\alpha|}10^r = 2^r
\end{aligned}
$$


$$
a - (a \& (-a)) = \langle x 1 0^r \rangle - \langle 1 0^r \rangle = \langle x 0 0^r \rangle
$$

That is, we successfully strip off the trailing $1$.
Armed with the theory, our implemtation becomes:

```cpp
#define LSB(x) x&(-x)
int a[N];
int q(int i) {
    int s = 0;
    while (i > 0) {
        s += a[i];
        i -= LSB(i); // strip off trailing 1.
    }
    return s;
}

```

#### update

To perform an update at $i$, we need to update all locations which on querying
overlap with $i$. For example, to update the location $9$, we would want to
update:

- $a[9] = (8, 9], a[10] = (8, 10], a[12] = (8, 12], a[16] = (0, 16]$.

So we need to update the indices:

- $9=2^0 \cdot 9 \xrightarrow{+2^0} 10=2^1 \cdot 5 \xrightarrow{+2^1} 12=2^2\cdot3 \xrightarrow{+2^2} 16=2^4\cdot1 \xrightarrow{+2^4} \dots$

We use the same bit-fiddling technique as above to strip off the value $2^r$


```cpp
#define LSB(x) x&(-x)
int tree[N];
int u(int i, int v) {
    while (i < N) { tree[i] += v; i += LSB(i); }
}
```


#### correctness

We wish to analyze the operations $Query(q) \equiv \sum_{i=1}^q a[i]$, and
$Update(i, val) \equiv a[i]~\texttt{+=}~val$. To do this, we are allowed to maintain
an auxiliary array $d$ which we will manipuate. We will stipulate the
conditions of operations on $d$ such that they will reflect the values of
$Query$ and $Update$, albeit much faster.

We will analyze the algorithm in terms of orbits. We have two operators, one
for update called $U$, and one for query called $Q$. Given an index $i$,
repeatedly applying the query operator gives us the indeces we need to read and
accumulate from the underlying array $a$ to get the total sum $a[0..i]$:

- $Query(i) = \sum_i d[Q^i(q)]$

Given an index $u$, repeatedly applying the update operator $U$ gives us all
the indeces we need to add the change to update:
- $Update(i, val) = \forall j~, d[U^j(i)]~\texttt{+=}~ val$

For query and update to work, we need the condition that:
- $q \geq u \iff \left\vert \{ Q^i(q)~:~ i \in \mathbb{N} \} \cap \{ U^i(u)~:~i \in \mathbb{N} \} \right\vert = 1$

That is, if and only if the query index $q$ includes the update location $u$,
will the orbits intersect.

The intuition is that we want updates at an index $u$ to only affect queries
that occur at indeces $q \geq u$. Hence, we axiomatise that for an update
to be legal, it must the orbits of queries that are at indeces greater than it.

We will show that our operators:
- $Q(i=2^r\cdot a) = i - 2^r = 2^r(a-1)$
- $U(j=2^s\cdot b) = j + 2^{s} = 2^{s}(b+1)$

do satisfy the conditions above.

For a quick numerical check, we can use the code blow to ensure
that the orbits are indeed disjoint:
```py
# calculate orbits of query and update in fenwick tree

def lsb(i): return i & (-i)
def U(i): return i + lsb(i)
def Q(i): return i - lsb(i)
def orbit(f, i):
    s = set()
    while i not in s and i > 0 and i < 64:
        s.add(i); i = f(i)
    return s

if __name__ == "__main__":
    for q in range(1, 16):
        for u in range(1, 16):
            qo = orbit(Q, q); uo = orbit(U, u)
            c = qo.intersection(uo)
            print("q:%4s | u:%4s | qo: %20s | uo: %20s | qu: %4s" %
                  (q, u, qo, uo, c))

        print("--")
```

##### Case 1: $q = u$

We note that $Q$ always decreases the value of $q$, and $u$ always increases
it. Hence, if $q = u$, they meet at this point, and
$\forall i, j \geq 1, \quad Q^i (q) \neq U^j(u)$.
Hence, they meet exactly once as required.

##### Case 2: $q < u$

As noted above, $q$ always decreases and $u$ always increases, hence in this
case they will never meet as required.


##### Case 3: $q > u$

Let the entire array have size $2^N$.
Let $q = \texttt{e1 f\_q}, u = \texttt{e0 f\_u}$, where
$\texttt{e, f\_q, f\_u}$ may be empty strings.

Notice that $Q$ will always strip away rightmost ones in $f_q$,
leading to $q = \texttt{e10...0}$ at some point.

Similarly, $U$ will keep on adding new rightmost ones, causing the
state to be $u = \texttt{e01...10...0} \xrightarrow{U} \texttt{e100...}$.

Hence, at some point $q = u$.

#### References

- [Fenwick trees on PolyMath](http://michaelnielsen.org/polymath1/index.php?title=Updating_partial_sums_with_Fenwick_tree)
- [Hacker's delight](https://doc.lagout.org/security/Hackers%20Delight.pdf)

# Dirichlet inversion

We call all functions $f: \mathbb Z \rightarrow \mathbb R$ as
_arithmetic functions_, since they operate on the integers.

We introduce an operator $f \star g: \mathbb Z \rightarrow \mathbb R$.
It is defined by:
- $(f \star g)(n) \equiv \sum_{d \vert n} f(d) g(n/d)$

We will show that the set of arithmetic functions forms a group
under the operator $\star$, with identity:

$$id_\star(n) \equiv \lfloor 1/n \rfloor = \begin{cases} 1 & n = 1 \\ 0 & \text{otherwise} \end{cases}$$


The reason all of this is interesting is that the inverse of the constant function $1(n) \equiv 1$
is going to be this function called as the mobius function $\mu$:

$$
\mu(n=p_1^{\alpha_1} p_2^{\alpha_2} \dots p_r^{\alpha_r}) \equiv
\begin{cases}
  0 & \text{if any $\alpha_i > 1$} \\
  (-1)^{\alpha_1 + \alpha_2 + \dots + \alpha_r} & \text{if all $\alpha_i \in \{ 0, 1 \}$}
\end{cases}
$$

The mobius function will allow us to perform _mobius inversion_:

$$
\begin{aligned}
  f(n) &\equiv \sum_{d \vert n} g(d) = \sum_{d \vert n} g(d) 1(n/d) = g \star 1 \\
  f \star 1^{-1} &=  g \star 1 \star 1^{-1} \\
  f \star \mu &= g
\end{aligned}
$$

That is, we originally had $f$ defined in terms of $g$. We can
recover an expression for $g$ in terms of $f$.

### The algebra of multiplicative functions

We claim that the set of functions $\{ \mathbb Z \rightarrow \mathbb C \}$
is a commutative group, with the group operation $\star$ such that:

- $(f \star g)(n) \equiv \sum_{d \vert n} f(d) g(n/d)$.

with the identity element being $id_\star(n) \equiv \lfloor 1 / n \rfloor$. The idea
is that if $(n = 1)$, then $\lfloor 1/1 \rfloor = 1$, and for any other
number $n > 0$, $1/n < 1$, hence $\lfloor 1/n \rfloor = 0$.

### verification of $istar$ being the identity
$$
\begin{aligned}
&(f \star id_\star)(n) \equiv \sum_{d \vert n} f(d) id_\star(n/d) \\
&= f(n) id_\star(1) + \sum_{d \vert n, d > 1} f(n) id_\star(d) \\
&= f(n) \cdot 1 + \sum_{d \vert n, d > 1} f(n) \cdot 0 \\
&= f(n) \\
\end{aligned}
$$

### associativity, commutativity of $\star$

To prove associativity, it's better to write the formula as:
$$
(f \star g)(n) \equiv \sum_{d \vert n} f(n) g(n/d) = \sum_{xy = n} f(x) g(y)
$$

From this rewrite, it's clear that $(f \star g \star h)(n)$ will unambiguously
sum over tripes $(x, y, z)$ such that $xyz = n$. I leave the working-this-out
to you. This should also make the commutativity immediate. Summing over pairs
of the form $f(x) g(y) : xy = n$ is the same as summing over $f(y) g(x) : yx = n$.



### Existence of inverse

We can show that an inverse exists by showing that a formula for it exists; The
idea is to construct one by induction.

Clearly, for a given function $f$, we need the inverse $f^{-1}$ to be such that
$(f \star f^{-1})(n) = id_\star$. Hence:

$$
\begin{aligned}
&(f \star f^{-1})(1) = id_\star(1) = 1 \\
&f(1) f^{-1}(1) = 1 \\
& f^{-1}(1) \equiv 1 / f(1)\\
\end{aligned}
$$

Great, we have a base case; We can now compute $f^{-1}(n)$ inductively, assuming
we know the value of $f^{-1}(d)$ for all $d \vert n$.

$$
\begin{aligned}
&(f \star f^{-1})(n) = id_\star(1) = 0 \\
&\sum_{d \vert n} f(d) f^{-1}(n/d) = 0 \\
&f(1) f^{-1}(n) + \sum_{d \vert n, d < n} f(d) f^{-1}(n/d) = 0 \\
&f^{-1}(n) = -\frac{\sum_{d \vert n, d < n} f(d) f^{-1}(n/d)}{f(1)}
\end{aligned}
$$

### $\mu$ as the inverse of the $one$ function


### Mobius inversion

Now that we know that $\mu = \texttt{const 1}^{-1}$, we can use this fact
to perform _mobius inversion_:

$$
f(n) \equiv \sum_{d \vert n} g(n/d) = \texttt{const 1} \star g
$$

We have $f$ written in terms of $g$. We can now write $g$ in terms of $f$:

$$
\begin{aligned}
&f(n)  = \texttt{const 1} \star g \\
&f \star \texttt{const 1}^{-1} = g \\
&g = f \star \mu \\
&g = \sum_{d \vert n} f(d) \mu(n/d)
\end{aligned}
$$

### $n = \sum_{d \vert n} \phi(d)$

$$
\begin{array}{|c|c|c|c|}
d & \{ 1 \leq x \leq 12 : (x, 12) = d \} & \{ 1 \leq x \leq 12: (x/d, 12/d) = 1\} & \text{size of set} \\
1 & \{ 1, 5, 7, 11 \} & (x, 12) = 1 & 4 \\
2 & \{2, 10 \} & (x/2, 6) = 1& 2 \\
3 & \{3, 9 \} & (x/3, 4) = 1 & 2 \\
4 & \{4, 8 \} & (x/4, 3) = 1 & 2 \\
6 & \{ 6 \} & (x/6, 2) = 1 & 1 \\
12 & \{ 12 \} (x/12, 1) = 1 & 1
\end{array}
$$

Notice that the sizes of sets that we are calculating, for example,
$|\{ 1 \leq x \leq 12 : (x/2, 6) = 1 \}| =  \phi(6)$. Summing over all of
what we have, we've counted the numbers in $[1, 2, \dots, 12]$ in two ways ---
one directly, and the other by partitioning into equivalence classes:

$$ 12 = \phi(1) + \phi(2) + \phi(3) + \phi(4) + \phi(6) + \phi(12) = \sum_{d \vert 12} \phi(12/d) $$

In general, the same argument allows us to prove that:

$$ n = \sum_{d \vert n} n/d $$

### Using mobius inversion on the euler totient function


### Other arithmetical functions and their relations


# Incunabulum for the 21st century: Making the J interpreter compile in 2020

This is me trying to understand the fabled interpreter of the `J` language
working, so I could absorb Arthur Whitney's style of writing C: it's
cryptic, short, and fits in a page. [I learnt of this from the `J` language page](https://code.jsoftware.com/wiki/Essays/Incunabulum),
which comes with the quote:

> One summer weekend in 1989, Arthur Whitney visited Ken Iverson at Kiln Farm
> and produced—on one page and in one afternoon—an interpreter fragment on the
> AT&T 3B1 computer. I studied this interpreter for about a week for its
> organization and programming style; and on Sunday, August 27, 1989, at about
> four o'clock in the afternoon, wrote the first line of code that became the
> implementation described in this document.
> Arthur's one-page interpreter fragment is as follows:

#### The original source

```c
typedef char C;typedef long I;
typedef struct a{I t,r,d[3],p[2];}*A;
#define P printf
#define R return
#define V1(f) A f(w)A w;
#define V2(f) A f(a,w)A a,w;
#define DO(n,x) {I i=0,_n=(n);for(;i<_n;++i){x;}}
I *ma(n){R(I*)malloc(n*4);}mv(d,s,n)I *d,*s;{DO(n,d[i]=s[i]);}
tr(r,d)I *d;{I z=1;DO(r,z=z*d[i]);R z;}
A ga(t,r,d)I *d;{A z=(A)ma(5+tr(r,d));z->t=t,z->r=r,mv(z->d,d,r);
 R z;}
V1(iota){I n=*w->p;A z=ga(0,1,&n);DO(n,z->p[i]=i);R z;}
V2(plus){I r=w->r,*d=w->d,n=tr(r,d);A z=ga(0,r,d);
 DO(n,z->p[i]=a->p[i]+w->p[i]);R z;}
V2(from){I r=w->r-1,*d=w->d+1,n=tr(r,d);
 A z=ga(w->t,r,d);mv(z->p,w->p+(n**a->p),n);R z;}
V1(box){A z=ga(1,0,0);*z->p=(I)w;R z;}
V2(cat){I an=tr(a->r,a->d),wn=tr(w->r,w->d),n=an+wn;
 A z=ga(w->t,1,&n);mv(z->p,a->p,an);mv(z->p+an,w->p,wn);R z;}
V2(find){}
V2(rsh){I r=a->r?*a->d:1,n=tr(r,a->p),wn=tr(w->r,w->d);
 A z=ga(w->t,r,a->p);mv(z->p,w->p,wn=n>wn?wn:n);
 if(n-=wn)mv(z->p+wn,z->p,n);R z;}
V1(sha){A z=ga(0,1,&w->r);mv(z->p,w->d,w->r);R z;}
V1(id){R w;}V1(size){A z=ga(0,0,0);*z->p=w->r?*w->d:1;R z;}
pi(i){P("%d ",i);}nl(){P("\n");}
pr(w)A w;{I r=w->r,*d=w->d,n=tr(r,d);DO(r,pi(d[i]));nl();
 if(w->t)DO(n,P("< ");pr(w->p[i]))else DO(n,pi(w->p[i]));nl();}

C vt[]="+{~<#,";
A(*vd[])()={0,plus,from,find,0,rsh,cat},
 (*vm[])()={0,id,size,iota,box,sha,0};
I st[26]; qp(a){R  a>='a'&&a<='z';}qv(a){R a<'a';}
A ex(e)I *e;{I a=*e;
 if(qp(a)){if(e[1]=='=')R st[a-'a']=ex(e+2);a= st[ a-'a'];}
 R qv(a)?(*vm[a])(ex(e+1)):e[1]?(*vd[e[1]])(a,ex(e+2)):(A)a;}
noun(c){A z;if(c<'0'||c>'9')R 0;z=ga(0,0,0);*z->p=c-'0';R z;}
verb(c){I i=0;for(;vt[i];)if(vt[i++]==c)R i;R 0;}
I *wd(s)C *s;{I a,n=strlen(s),*e=ma(n+1);C c;
 DO(n,e[i]=(a=noun(c=s[i]))?a:(a=verb(c))?a:c);e[n]=0;R e;}

main(){C s[99];while(gets(s))pr(ex(wd(s)));}
```

It's a lot to take in --- it's quite breathtaking really, the way it all
hangs together in one page.

#### The attempt to get it run

Unfortunately, this does not work if we try to get it to run in 2020. I decided
to read the code and understand what would happen. I managed to read enough
to understand that the code `a=~3` ought to create an array with values `[0 1 2]`.
On attempting to _run_ this however, we get:

```
$ gcc -O0 -g -std=c89 -fsanitize=address -fsanitize=undefined incunabulum.c -o bin/incunabulum && ./bin/incunabulum
...
(many many GCC warnings elided)
...
a=~3
=================================================================
==23726==ERROR: AddressSanitizer: heap-buffer-overflow on address
  0x60300000eff0 at pc 0x000000402be3 bp 0x7ffe6dde6b70 sp 0x7ffe6dde6b60
WRITE of size 8 at 0x60300000eff0 thread T0
    #0 0x402be2 in wd /home/bollu/work/w/incunabulum.c:40
    #1 0x402d28 in main /home/bollu/work/w/incunabulum.c:42
    #2 0x7f7ae901082f in __libc_start_main (/lib/x86_64-linux-gnu/libc.so.6+0x2082f)
    #3 0x400ca8 in _start (/home/bollu/w/bin/incunabulum+0x400ca8)
...
SUMMARY: AddressSanitizer: heap-buffer-overflow /home/bollu/work/w/incunabulum.c:40 wd
...
==23726==ABORTING
```

oops! The code uses a lot of punning between `int`
and `int*`. These assumptions break now that we're in 64-bit. The patch to
get this to work is:

#### the patch

```diff
diff --git a/incunabulum.c b/incunabulum.c
index 2cae744..778e35a 100644
--- a/incunabulum.c
+++ b/incunabulum.c
@@ -1,11 +1,11 @@
-typedef char C;typedef long I;
+typedef char C;typedef long long I;
 typedef struct a{I t,r,d[3],p[2];}*A;
 #define P printf
 #define R return
 #define V1(f) A f(w)A w;
 #define V2(f) A f(a,w)A a,w;
 #define DO(n,x) {I i=0,_n=(n);for(;i<_n;++i){x;}}
-I *ma(n){R(I*)malloc(n*4);}mv(d,s,n)I *d,*s;{DO(n,d[i]=s[i]);}
+I *ma(n){R(I*)malloc(n*8);}mv(d,s,n)I *d,*s;{DO(n,d[i]=s[i]);}
 tr(r,d)I *d;{I z=1;DO(r,z=z*d[i]);R z;}
 A ga(t,r,d)I *d;{A z=(A)ma(5+tr(r,d));z->t=t,z->r=r,mv(z->d,d,r);
  R z;}
@@ -34,9 +34,10 @@ I st[26]; qp(a){R  a>='a'&&a<='z';}qv(a){R a<'a';}
 A ex(e)I *e;{I a=*e;
  if(qp(a)){if(e[1]=='=')R st[a-'a']=ex(e+2);a= st[ a-'a'];}
  R qv(a)?(*vm[a])(ex(e+1)):e[1]?(*vd[e[1]])(a,ex(e+2)):(A)a;}
-noun(c){A z;if(c<'0'||c>'9')R 0;z=ga(0,0,0);*z->p=c-'0';R z;}
-verb(c){I i=0;for(;vt[i];)if(vt[i++]==c)R i;R 0;}
+I noun(c){A z;if(c<'0'||c>'9')R 0;z=ga(0,0,0);*z->p=c-'0';R z;}
+I verb(c){I i=0;for(;vt[i];)if(vt[i++]==c)R i;R 0;}
 I *wd(s)C *s;{I a,n=strlen(s),*e=ma(n+1);C c;
  DO(n,e[i]=(a=noun(c=s[i]))?a:(a=verb(c))?a:c);e[n]=0;R e;}

 main(){C s[99];while(gets(s))pr(ex(wd(s)));}
+
```

#### It runs!

After applying the patch, we manage to get the interpreter to run!

```
./bin/incunabulum
a=~3
3
0 1 2
```

#### The lock screen

I liked it so much that I took a screenshot and made it my lock screen.

<img src="./static/screenshot-j-incunabulum.png">

#### Thoughts

I'm really fascinated by the code. I loved I could simply stare the screenshot
to absorb the code. There was no scrolling involved.  The variables are
well-named (to the extent I understand the code), and it's clearly extremely
well thought out. If there's someone who understands some of the thorny
aspects of the code:

- What is the `t` variable really tracking?
- How does one create a multi-dimensional array easily?
- What are some interesting programs one can run with this mini-interpreter?

I'd be really glad to know the details. Please leave
[an issue or a pull request against the repo](https://github.com/bollu/bollu.github.io/issues/new).

I'm going write a dissection of the code once I fully understand it, since I
couldn't find explanaing the code on the internet.

Until then, enjoy the monolith of code!


# An example of a sequence whose successive terms get closer together but isn't Cauchy (does not converge)

#### The problem
Provide an example of a sequence $a_n: \mathbb N \rightarrow \mathbb R$
such that $\lim_{n \rightarrow \infty} \vert a_{n+1} - a_n \vert \rightarrow 0$,
but $\lim_{n, m \rightarrow \infty, m > n} |a_n - a_m| \neq 0$. That is,
proide a series where the distances between successive terms converges to zero,
but where distances between terms that are "farther apart than 1" does
not converge to 0. That is, the sequence is not _Cauchy_.

#### Regular solution: Harmonic numbers

The usual solution is to take the harmonic numbers,
$H_n \equiv \sum_{i=1}^n 1/i$. Then, we show that:

$$
\begin{aligned}
\lim_{n \rightarrow \infty} \left| H_{n+1} - H_n \right|
&= \left| \frac{1}{n+1} - \frac{1}{n} \right| \\
&= \frac{1}{(n+1)n} \rightarrow 0
\end{aligned}
$$

$$
\begin{aligned}
&\lim_{n \rightarrow \infty} \left| H_{2n} - H_n \right| \\
&= \left|\frac{1}{2n} - \frac{1}{n} \right| \\
&= \sum_{i=n+1}^{2n} \frac{1}{n+1} + \frac{1}{n+2} + \dots + \frac{1}{2n} \\
&\geq \sum_{i=n+1}^{2n} \frac{1}{2n} + \frac{1}{2n} + \dots + \frac{1}{2n} \\
&\geq \frac{n}{2n} = \frac{1}{2} \neq 0 \text{on} x \rightarrow \infty
\end{aligned}
$$


#### Memorable solution: logarithm

We can much more simply choose $a_n = \log(n)$. This yields the simple
calculation:

$$
\begin{aligned}
&\lim_{n \rightarrow \infty} a_{n+1} - a_n = \log(n+1) - \log(n) \\
&= \log((n+1)/n)) \\
&= \log(1 + 1/n) \xrightarrow{n \rightarrow \infty} \log(1) = 0
\end{aligned}
$$

while on the other hand,


$$
\begin{aligned}
\lim_{n \rightarrow \infty} a_{2n} - a_n
= \log(2n) - \log(n)
= \log(2) + \log(n) - \log(n)
= \log 2 \neq 0
\end{aligned}
$$

I find this far cleaner conceptually, since it's "obvious" to everyone
that $a_n = \log(n)$ diverges, while the corresponding fact for $H_n$
is hardly convincing. We also get straightforward equalities everywhere,
instead of inequalities.

I still feel that I don't grok what precisely fails here, in that, my intuition
still feels that the local condition _ought_ to imply the Cauchy condition:
if $a_n$ tells $a_{n+1}$ to not be too far, and $a_{n+1}$ tells $a_{n+2}$,
surely this _must_ be transitive?

I have taught my instincts to not trust my instincts on analysis, which is a
shitty solution :) I hope to internalize this someday.

__EDIT:__ I feel I now understand what's precisely happening
after ruminating a bit.

The Cauchy convergence criterion allows us to drop a finite number
of terms, and then capture _everything after that point_ in a ball
of radius $\epsilon$. As $\epsilon$ shrinks, _all_ the terms in the
sequence are "squeezed togeher".

In the $a_{n+1} - a_n$ case, only successive terms must maintain
an $\epsilon$ distance. But as the $\log$ example shows, you can steadily
plod along, keeping $\epsilon$ ball next to $\epsilon$ ball, to reach:

$$
\lim_{n \rightarrow \infty} \lim_{\epsilon \rightarrow 0} f(n) \cdot \epsilon
$$
whose behaviour can do unexpected things depending on the choice of $n$.

# Krylov subspace method

<!-- https://www.youtube.com/watch?v=R9DHmkCE9oI -->

This is a class of methods used to solve $Ax = b$, where $A$ is sparse.
Krylov subspace methods are a class of methods which use the idea of a
Krylov subspace. There is conjugate gradient (CG), GMRES (Generalized minimal
residual method).

$$
K_m(A, v) \equiv span \{ v, Av, A^2v, \dots, A^m v\}
$$

Clearly, $K_m \subseteq K_{m+1}$, and there is a maximum $K_N$ that we can span
(the full vector space). We are interested in the smallest index $M$
such that $K_M = K_{M+1}$.

We notice that $K_M$ is invariant under the action of $A$.


Now, let's consider:
$$
\begin{aligned}
K_m(A, x) &\equiv span \{x, Ax, A^2x, \dots A^m x \} \\
        &= span \{ A^{-1} b, b, Ab, \dots A^{m-1} x \} \qquad \text{(substitute $x = A^{-1}b$)} \\
        &= A span \{ A^{-1} b, b, Ab, \dots A^{m-1} b\} \qquad \text{(Invariance of Krylov subspace)} \\
        &= span \{b, Ab, \dots A^m b\}  \\
        &= K_m(A, b)
\end{aligned}
$$

We learnt that $Ax = b$ has a solution in $K_m(A, b)$. Using this, we can build
solvers that exploit the Krylov subspace. We will describe GMRES and CG.

## Generalized minimal residual --- GMRES

We wish to solve $Ax = b$ where $A$ is sparse and $b$ is normalized. The $n$th
Krylov subspace is $K_n(A, b) \equiv span~\{b, Ab, A^2b, \dots, A^nb  \}$.

We approximate the actual solution with a vector $x_n \in K_n(A, b)$. We
define the _residual_ as $r_n \equiv A x_n - b$.

## Conjugate gradient descent

# Good reference to the Rete pattern matching algorithm

The [Rete pattern matching algorithm](https://en.wikipedia.org/wiki/Rete_algorithm)
is an algorithm that allows matching a huge number of rules with a huge database
of "facts".

MLIR ("multi-language intermediate representation") is a new technology that
hopes to centralize much of the research and development of various compilers
into a single authoritative source. The major claim-to-fame is that it allows
one to mix various "dialects" (much as Racket does). So, to a first order
approximation, MLIR is "JSON for compiler intermediate representations".

What MLIR gets right is _tooling_. They take the experience that the LLVM project
has mined for the last decade and a half, and bake many of the good stuff that
came with LLVM right in. For example, MLIR comes in-built with a pretty printer,
a notion of types, a notion of "attributes", SSA, enforced provenance
tracking of code (so one can _always_ know what the original source code was
that led to some assembly). Sound engineering might see MLIR succeed where
many others failed.

I was reminded of Rete since the MLIR folks are trying to solve the pattern
matching problem in general for their [Generic DAG Rewriter](https://mlir.llvm.org/docs/GenericDAGRewriter/).

They currently just use a worklist based algorithm. I'm trying to understand
if Rete can be used instead. Rete is famous for being hard to understand,
so I began a quest to look for good sources to implement it. I found a great
[PhD thesis written by Robert B. Doorenboos](http://reports-archive.adm.cs.cmu.edu/anon/1995/CMU-CS-95-113.pdf),
which quips:

> Since the Rete match algorithm provides the starting point for much of the work in this thesis,
> this chapter describes Rete. Unfortunately, most of the descriptions of Rete in the literature
> are not particularly lucid,1 which is perhaps why Rete has acquired \a reputation for extreme
> differentialculty."(Perlin, 1990b) To remedy this situation, this chapter describes Rete in a tutorial
> style, rather than just briey reviewing it and referring the reader to the literature for a full
> description. We will first give an overview of Rete, and then discuss the principle data structures
> and procedures commonly used to implement it. High-level pseudocode will be given for many
> of the structures and procedures, so that this chapter may serve as a guide to readers who want
> to implement rete (or some variant) in their own systems.

I now have a reference to an accessible description of this stuff. I might
implement Rete to understand it, so that it's part of my toolkit if I ever
need it.

# Leapfrog Integration

We have a system we wish to simulate using hamilton's equations:

$$
\begin{aligned}
\frac{\partial q}{\partial t} = \frac{\partial H}{\partial p}|_{(p_0, q_0)} \\
\frac{\partial p}{\partial t} = -\frac{\partial H}{\partial q}|_{(p_0, q_0)} \\
\end{aligned}
$$

We want to simulate a system using these differential equations. We will begin
with some initial position and momentum $(q_0, p_0)$, evaluate
$\frac{\partial q}{\partial t} \rvert_{(q_0, p_0)}$, $\frac{\partial p}{\partial t} \rvert_{(q_0, p_0)}$, and use
these to find $(q_{next}, p_{next})$. An integrator is a general algorithm
that produces the next position and momentum using current information:

$$
(q_{next}, p_{next}) =
  I \left(q_0,
    p_0,
    \frac{\partial q}{\partial t}\rvert_{(q_0, p_0)},
    \frac{\partial p}{\partial t}\rvert_{(q_0, p_0)} \right)
$$

The design of $I$ is crucial: different choices of $I$ will have different
trade-offs for accuracy and performance. Another interesting property
we might want is for $I$ to be a _symplectic integrator_ --- that is,
it preserves the total energy of the system. For example, here's a plot
of the orbits of planets using two integrators, one that's symplectic (leapfrog)
and one that isn't (Euler)


<img src="./static/leapfrog-vs-euler.png">

Notice that since leapfrog attempts to keep energy conserved, the orbits stay
as orbits! On the other hand, the euler integrator quickly spirals out, since
we lose energy during the integration. Note that this is
_not an issue of numerical precision_: The euler integrator is ineherently
such that over long timescales, it will lose energy. On the other hand, the
leapfrog integrator will _always remain stable_, even with very large timesteps
and low precision.

I present the equations of the leapfrog integrator, a proof sketch that it
is symplectic, and the code listing that was used to generate the above plot.
Often, code makes most ideas very clear!

#### The integrator


#### Code listing

##### Incantations
```py
# Run HMC with a particular choice of potential
import numpy as np
from matplotlib.animation import FuncAnimation
import matplotlib.pyplot as plt
import numpy.linalg
```

```py
# dq/dt = dH/dp|_{p0, q0}
# dp/dt = -dH/dq|_{p0, q0}
def leapfrog(dhdp, dhdq, q0, p0, dt):
    p0 += -dhdq(q0, p0) * 0.5 * dt

    # full step position
    # q += dt * p
    q0 += dhdp(q0, p0) * dt

    # half step position
    p0 += -dhdq(q0, p0) * 0.5 * dt
    return (q0, p0)
```

For reference, we also implement an euler integrator, that uses the derivative
to compute the position and momentum of the next timestep independently.

```py
def euler(dhdp, dhdq, q, p, dt):
    pnew = p + -dhdq(q, p) * dt
    qnew = q + dhdp(q, p) * dt
    return (qnew, pnew)
```


Finally, we implement `planet(integrator, n, dt)` which simulates gravitational
potential and usual kinetic energy, using the integrator given by `integrator`
for `n` steps, with each timestep taking `dt`.

```py
def planet(integrator, n, dt):
    STRENGTH = 0.5

    # minimise potential V(q): q, K(p, q) p^2
    q = np.array([0.0, 1.0])
    p = np.array([-1.0, 0.0])

    # H = STRENGTH * |q| (potential) + p^2/2 (kinetic)
    def H(qcur, pcur): return STRENGTH * np.linalg.norm(q) + np.dot(p, p) / 2
    def dhdp(qcur, pcur): return p
    def dhdq(qcur, pcur): return STRENGTH * 2 * q / np.linalg.norm(q)

    qs = []
    for i in range(n):
        print("q: %10s | p: %10s | H: %6.4f" % (q, p, H(q, p)))
        (q, p) = integrator(dhdp, dhdq, q, p, dt)
        qs.append(q.copy())
    return np.asarray(qs)
```


We plot the simulations using `matplotlib` and save them.
```py
NITERS = 15
TIMESTEP = 1

print("planet simulation with leapfrog")
planet_leapfrog = planet(leapfrog, NITERS, TIMESTEP)

plt.rcParams.update({'font.size': 12, 'font.family':'monospace'})
fig, ax = plt.subplots()
print(planet_leapfrog)
ax.plot(planet_leapfrog[:, 0], planet_leapfrog[:, 1], label='leapfrog',
        linewidth=3, color='#00ACC1')
print("planet simulation with euler")
planet_euler = planet(euler, NITERS, TIMESTEP)
ax.plot(planet_euler[:, 0], planet_euler[:, 1], label='euler',
        linewidth=3, color='#D81B60')

legend = plt.legend(frameon=False)
ax.set_title("leapfrog v/s euler: NITERS=%s dt=%s" % (NITERS, TIMESTEP))
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
plt.savefig("leapfrog-vs-euler.png")
plt.show()
```

# Comparison of forward and reverse mode AD

Quite a lot of ink has been spilt on this topic. My favourite reference
is the one by [Rufflewind](https://rufflewind.com/2016-12-30/reverse-mode-automatic-differentiation).

However, none of these examples have a good stock of examples for the diference.
So here, I catalogue the explicit computations between computing forward
mode AD and reverse mode AD.

In general, in forward mode AD, we fix how much the inputs wiggle with
respect to a parameter $t$. We figure out how much the output wiggles
with respect to $t$. If $output = f(input_1, input_2, \dots input_n)$,
then $\frac{\partial output}{\partial t} = \sum_i \frac{\partial f}{\partial input_i} \frac{\partial input_i}{\partial dt}$.

In reverse mode AD, we fix how much the parameter $t$ wiggles with
respect to the output. We figure out how much the parameter $t$
wiggles with respect to the inputs.
If $output_i = f_i(input, \dots)$, then $\frac{\partial t}{\partial input} = \sum_i \frac{\partial t}{\partial output_i} \frac{\partial f_i}{input}$.
This is a much messier expression, since we need to accumulate the data
over all outputs.

Essentially, deriving output from input is easy, since how to compute an output
from an input is documented in one place. deriving input from output is
annoying, since many outputs can depent on a single output.

The upshot is that if we have few "root outputs" (like a loss function),
we need to run AD once with respect to this, and we will get the wiggles
of _all inputs_ at the same time with respect to this output, since we
compute the wiggles output to input.

The first example of `z = max(x, y)` captures the essential difference
between the two approached succinctly. Study this, and everything else will make
sense.


#### Maximum: `z = max(x, y)`


- Forward mode equations:

$$
\begin{aligned}
z &= max(x, y) \\
\frac{\partial x}{\partial t} &= ? \\
\frac{\partial y}{\partial t} &= ? \\
\frac{\partial z}{\partial t}
  &= \begin{cases}
        \frac{\partial x}{\partial t} & \text{if $x > y$} \\
        \frac{\partial y}{\partial t} & \text{otherwise} \\
    \end{cases}
\end{aligned}
$$

We can compute $\frac{\partial z}{\partial x}$ by setting $t = x$.
That is, $\frac{\partial x}{\partial t} = 1, \frac{\partial y}{\partial t} = 0$.
Similarly, can compute $\frac{\partial z}{\partial y}$ by setting $t = y$.
That is, $\frac{\partial x}{\partial t} = 1, \frac{\partial y}{\partial t} = 0$.
If we want both gradients $\frac{\partial z}{\partial x}, \frac{\partial z}{\partial y}$,
we will have to **rerun the above equations twice** with the two initializations.

In our equations, we are saying that we know how sensitive
the inputs $x, y$ are to a given parameter $t$. We are deriving how sensitive
the output $z$ is to the parameter $t$ as a composition of $x, y$. If
$x > y$, then we know that $z$ is as sensitive to $t$ as $x$ is.


- Reverse mode equations:

$$
\begin{aligned}
z &= max(x, y) \\
\frac{\partial t}{\partial z} &= ? \\
\frac{\partial t}{\partial x}
  &= \begin{cases}
    \frac{\partial t}{\partial z} & \text{$if x > y$} \\
    0 & \text{otherwise}
  \end{cases} \\
\frac{\partial t}{\partial y}
  &= \begin{cases}
    \frac{\partial t}{\partial z} & \text{$if y > x$} \\
    0 & \text{otherwise}
  \end{cases}
\end{aligned}
$$

We can compute $\frac{\partial z}{\partial x}, \frac{\partial z}{\partial y}$
**in one shot** by setting $t = z$. That is, $\frac{\partial z}{\partial t} = 1$.

In our equations, we are saying that we know how sensitive
the parameter $t$ is to a given output $z$. We are trying to see
how sensitive $t$ is to the inputs $x, y$. If $x$ is active (ie, $x > y$),
then $t$ is indeed sensitive to $x$ and $\frac{\partial t}{\partial x} = 1$.
Otherwise, it is not sensitive, and $\frac{\partial t}{\partial x} = 0$.


#### sin: `z = sin(x)`

- Forward mode equations:

$$
\begin{aligned}
z &= sin(x) \\
\frac{\partial x}{\partial t} &= ? \\
\frac{\partial z}{\partial t}
  &= \frac{\partial z}{\partial x} \frac{\partial x}{\partial t} \\
  &= cos(x) \frac{\partial x}{\partial t}
\end{aligned}
$$

We can compute $\frac{\partial z}{\partial x}$ by setting $t = x$.
That is, setting $\frac{\partial x}{\partial t} = 1$.

- Reverse mode equations:

$$
\begin{aligned}
z &= sin(x) \\
\frac{\partial t}{\partial z} &= ? \\
\frac{\partial t}{\partial x}
  &= \frac{\partial t}{\partial z} \frac{\partial z}{\partial x} \\
  &= \frac{\partial t}{\partial z} cos(x)
\end{aligned}
$$


We can compute $\frac{\partial z}{\partial x}$ by setting $t = z$.
That is, setting $\frac{\partial z}{\partial t} = 1$.

#### addition: `z = x + y`:

- Forward mode equations:

$$
\begin{aligned}
z &= x + y \\
\frac{\partial x}{\partial t} &= ? \\
\frac{\partial y}{\partial t} &= ? \\
\frac{\partial z}{\partial t}
  &= \frac{\partial z}{\partial x} \frac{\partial x}{\partial t} +
    \frac{\partial z}{\partial y} \frac{\partial y}{\partial t} \\
  &= 1 \cdot \frac{\partial x}{\partial t} + 1 \cdot \frac{\partial y}{\partial t}
  = \frac{\partial x}{\partial t} + \frac{\partial y}{\partial t}
\end{aligned}
$$


- Reverse mode equations:

$$
\begin{aligned}
z &= x + y \\
\frac{\partial t}{\partial z} &= ? \\
\frac{\partial t}{\partial x}
  &= \frac{\partial t}{\partial z} \frac{\partial z}{\partial x} \\
  &= \frac{\partial t}{\partial z} \cdot 1 = \frac{\partial t}{\partial z} \\
\frac{\partial t}{\partial y}
  &= \frac{\partial t}{\partial z} \frac{\partial z}{\partial y} \\
  &= \frac{\partial t}{\partial z} \cdot 1 = \frac{\partial t}{\partial z}
\end{aligned}
$$


#### multiplication: `z = xy`

- Forward mode equations:

$$
\begin{aligned}
z &= x y \\
\frac{\partial x}{\partial t} &= ? \\
\frac{\partial y}{\partial t} &= ? \\
\frac{\partial z}{\partial t}
  &= \frac{\partial z}{\partial x} \frac{\partial x}{\partial t} +
    \frac{\partial z}{\partial y} \frac{\partial y}{\partial t} \\
  &= y \frac{\partial x}{\partial t} + x \frac{\partial y}{\partial t}
\end{aligned}
$$

- Reverse mode equations:

$$
\begin{aligned}
z &= x y \\
\frac{\partial t}{\partial z} &= ? \\
\frac{\partial t}{\partial x}
  &= \frac{\partial t}{\partial z} \frac{\partial z}{\partial x}
  = \frac{\partial t}{\partial z} \cdot y \\
\frac{\partial t}{\partial y}
  &= \frac{\partial t}{\partial z} \frac{\partial z}{\partial y}
  = \frac{\partial t}{\partial z} \cdot x
\end{aligned}
$$


#### subtraction: `z = x - y`:

- Forward mode equations:

$$
\begin{aligned}
z &= x + y \\
\frac{\partial x}{\partial t} &= ? \\
\frac{\partial y}{\partial t} &= ? \\
\frac{\partial z}{\partial t}
  &= \frac{\partial z}{\partial x} \frac{\partial x}{\partial t} -
    \frac{\partial z}{\partial y} \frac{\partial y}{\partial t} \\
  &= 1 \cdot \frac{\partial x}{\partial t} - 1 \cdot \frac{\partial y}{\partial t}
  = \frac{\partial x}{\partial t} - \frac{\partial y}{\partial t}
\end{aligned}
$$

- Reverse mode equations:

$$
\begin{aligned}
z &= x - y \\
\frac{\partial t}{\partial z} &= ? \\
\frac{\partial t}{\partial x}
  &= \frac{\partial t}{\partial z} \frac{\partial z}{\partial x} \\
  &= \frac{\partial t}{\partial z} \cdot 1 = \frac{\partial t}{\partial z} \\
\frac{\partial t}{\partial y}
  &= \frac{\partial t}{\partial z} \frac{\partial z}{\partial y} \\
  &= \frac{\partial t}{\partial z} \cdot -1 = -\frac{\partial t}{\partial z}
\end{aligned}
$$


# An invitation to homology and cohomology, Part 1 --- Homology

There are many introductions to homology on the internet, but none of them
really met my criteria for being simple, picture filled, and getting the
basic ideas across. I feel that Hatcher might come closest to what I want
(and where I originally learnt the material), but their description of homology
is surrounded by the context of Algebraic Topology, while really, simplicial
homology is accessible to anyone who has seen some linear algebra and group
theory. This is my attempt to get the ideas across.

Let's first try to understand what we're trying to do here. We want to detect
holes in a space, broadly construed. We focus in _simplicial complexes_, which
are collections of triangles and triangle-like objects in higher (and lower)
dimensions. We define what holes are for these simplicial complexes, and we then
try to find algebraic objects that allow us to "detect" these holes.

### Simplices

- A 0-simplex is a point

```
*
```

- A 1-simplex is a line

```
*===*
```

- A 2-simplex is a filled triangle

```
   *
  / \
 *---*
```

- A $k$-dimensional simplex is the convex hull of $k+1$
  linearly independent points $(u_i \in \mathbb R^{k+1})$
  in $k+1$ dimensional space.

$$S_k \equiv \left \{ \sum \theta_i u_i ~\mid~ \theta_i \geq 0, ~ \sum_i \theta_i = 1 \right \} $$

### Simplicial complexes

A simplicial complex $K$ is a collection of simplices where:
- (1) Every boundary of a simplex from $K$ is in $K$
- (2) The intersection of any two simplices in $K$ is also in $K$

Examples of simplicial complexes:

- Every simplex is trivially a simplicial complex.

<img src="static/simplices/complex-0-simplices.svg" width="50">
- A collection of points is a simplicial complex with all simplices of degree $0$.

<img src="static/simplices/complex-unfilled-triangle.svg" width="50">
- An unfilled triangle is a simplicial complex with simplices of degree $0$, $1$.

<img src="static/simplices/complex-unfilled-butterfly.svg" width="50">
- Non-triangular shapes such  as this "butterfly" are also simplicial complexes,
  this one of degree $0$, $1$.

<img src="static/simplices/complex-half-filled-butterfly.svg" width="50">
- This is the same shape as the unfilled butterly, except now containing a
  simplex of degree 2: the filling in of the bottom of the butterfly.


Non-examples of simplicial complexes are:

<img src="static/simplices/non-simplex-1.svg" width="50">
- This does not contain the point at the lower-left corner, which should exist
  since it is a boundary of the straight line. This violates rule (1):
  Every boundary of a simplex from $K$ is in $K$


<img src="static/simplices/non-simplex-2.svg" width="50">
- This does not contain the points which are at the intersection of the
  triangle and the line. This violates rule (2):
  The intersection of any two simplices in $K$ is also in $K$.

### Holes in a space: Homology of a triangle

Let's consider the simplest possible case of computing the homlogy, and we
do so, we will expand on what homology _is_, and what we're trying to do.

<img src="static/simplices/homology-triangle-edges.svg">

Look at the triangle above. We have the red, green, and blue vertices, which
I'll notate $r, g, b$. We also have the edges that are orange ($o$), cyan ($c$), and
magenta ($m$).

What we are interested in doing is to be able to detect the "hole" in the
triangle in between the edges `o-m-c`. That is, we want some algorithm which
when offered the representation of the triangle, can somehow detect the hole.
Note that the hole doesn't really depend on the length of the edges. We can
"bend and stretch" the triangle, and the hole will still exist. The only way
to destroy the hole is to either _cut_ the triangle, or _fill in_ the triangle.

We first need to agree on an abstract _representation_ of the triangle,
which ideally does not change if we were to stretch out the edges,
before we can discuss how we can detect the existence of the hole.

##### Representation of the triangle: boundary operators

We first describe the shape of the triangle in terms
of two sets, $E$ and $V$ representing the edges and the vertices, and
a function $\partial_{EV}$, called as the
boundary operator, which tells us how edges
are glued to vertices.

We first have a ground set of edges $E \equiv \\{o, m, c\\}$ and a set of
vertices $V \equiv \\{r, g, b \\}$.

What we now need is to know how the edges are connected to the vertices,
since that's what really makes a triangle. We would like to say something
like "the boundary of the edge $o$ has points $r, g$". In fact, we have
slightly more information than that: the _orientation_. So what we
really ought to be saying is "the edge $o$ points from $g$ to $r$".

To do this, we create a map from $o$ to $r - g$, where we think of $o$
as a "vector", pointing from $g$ to $r$. But hang on, what _is_ $r - g$?
we don't have a mathematical structure on $V$ that lets us add and subtract
vertices. So, we _create_ a new set $\mathcal V$, which represents linear
combinations of vertices in $V$. Similarly, anticipating some future
development, we also _create_ a new set $\mathcal E$ of linear combinations
of edges $E$.

##### Formal definition of the boundary operator

We define $\mathcal E \equiv \mathbb Z \times \mathbb Z \times \mathbb Z$
that represents linear combinations of edges. For example, $(1, 2, 3) \in \mathcal E$
represents $o + 2m + 3c$ --- that is, take 1 copy of the orange edge, 2
copies of the magenta edge, and 3 copies of the cyan edge.

We define $\mathcal V \equiv \mathbb Z \times \mathbb Z \times \mathbb Z$
which represents linear combinations of vertices. For example,
$(1, -1, 2) \in V$ represents $r - g + 2b$ --- that is, take a copy of the
red vertex, subtract the green vertex, and add two copies of the blue vertex.

The boundary operator $\partial_{EV}: \mathcal{E} \rightarrow \mathcal V$ is
depicted in the picture. This operator sends edges to their _boundary_, and is
therefore called the _boundary operator_.  The _boundary_ of an edge describes
the edge in terms of vertices, just like we would describe a direction vector
(to borrow physics parlance) by subtracting points.

The action of the operator on a linear combination of edges is:

$$
\begin{aligned}
&\partial_{EV}: \mathcal E \rightarrow \mathcal V \\
&\partial_{EV}(1, 0, 0) \equiv (1, -1, 0) \qquad o \mapsto r - g \\
&\partial_{EV}(0, 1, 0) \equiv (-1, 0, 1) \qquad m \mapsto b - r \\
&\partial_{EV}(0, 0, 1) \equiv (0, 1, -1) \qquad c \mapsto b - g \\
&\text{(Extend using linearity)} \\
&\partial_{EV}(s, t, u) \equiv
  s \partial_{EV}(1, 0, 0) +
  t \partial_{EV}(0, 1, 0) +
  u \partial_{EV}(0, 0, 1) = (s - t, u - s, t - u)
\end{aligned}
$$

Now, notice that to traverse the cycle, we should traverse the orange edge,
then the magenta edge, then the cyan edge, in that direction. That is,
the cycle can be thought of as $o + m + c$. However, how do we _detect_ this
cycle? The key idea is that if we look at the
_image of the cycle $o + m + c$ under the boundary operator_ $\partial_{EV}$,
we will get $0$! For us to have completed a cycle, we must have both
entered and exited each vertex, so the total sum must be $0$.

Formally:

$$
\begin{aligned}
  &\partial_{EV}(s, t, u) \equiv (s - t, u - s, t - u) \\
  &o + m + c = (1, 1, 1) \in \mathcal E \quad
  \partial_{EV}((1, 1, 1) = (1 - 1, 1 - 1, 1 - 1) = (0, 0, 0)
\end{aligned}
$$

##### Formal definition of cycles

This is very nice, since we have converted the topological invariant
of a _hole in the space_ into an algebraic invariant of "linear combination
of edges that map to 0". That is, we want to consider all thoose loops
that belong to the _kernel_ of $\partial_{EV}$. (Terminology:
the kernel of a linear transformation is the set of all things in the domain
which map to zero)

So, we define (tentatively) the first homology group:

$$
\begin{aligned}
H_1 \equiv Kernel(\partial_{EV}) \equiv
\left \{ (a, b, c) \in \mathcal E \mid \partial_EV((a, b, c)) = (0, 0, 0) \right \}
\subset \mathcal E
\end{aligned}
$$

If we try to compute this, we will have to have:

$$
\begin{aligned}
H_1 &\equiv Kernel(\partial_{EV}) \\
&= \{ (s, t, u) ~\mid~ \partial_{EV}(s, t, u) = (0, 0, 0) ~ s, t, u \in \mathbb Z \} \\
&= \{ (s, t, u) ~\mid~ (s-t, u-s, t-u) = (0, 0, 0) ~ s, t, u \in \mathbb Z  \} \\
&= \{ (s, t, u) ~\mid~ s = t = u \quad s, t, u \in \mathbb Z \} \\
&= \{ (x, x, x) ~\mid~ x \in \mathbb Z \} \simeq \mathbb Z
\end{aligned}
$$

So, we know that we have a $\mathbb Z$ worth of cycles in our triangle, which
makes sense: We can go clockwise (positive numbers)
and counter-clockwise (negative numbers) around the triangle,
and we can go as many times as we wish, so we have $\mathbb Z$ as the
number of cycles.

that is, it's the linear combination of edges that map to zero through the
boundary map. Note that this also includes combinations such as _two_ loops
around the triangle, such as $o + m + c + o + m + c$.

### (No) Holes in a space: Homology of a _filled_ triangle

<img src="static/simplices/homology-triangle-faces.svg">

In this case, notice that the triangle is _filled_ with a face $f$.
Therefore, the "hole" that we had previously is now filled up, and does not
count anymore. So, we now need to amend our previous definition of $H_1$ to
kill the hole we had detected.

The idea is that the hole we had previously is now the
_boundary of the new face $f$_.
Since it is the boundary of a "filled in" region, it does not count anymore,
since we can "shrink the hole" across the face to make it a non-loop.
Hence, we need to quotient our $H_1$ with the boundary of the face.

Formally, what we do is we create another group $\mathcal F \equiv \mathbb Z$,
which counts copies of our face $f$, and we define another boundary operator,
such that the boundary of the face $f$ is $o + m + c$.

$$
\begin{aligned}
&\partial_{FE} : \mathcal F \rightarrow \mathcal E \\
&\partial_{FE}(1) \equiv (1, 1, 1)  \\
&\text{(Extend using linearity)} \\
&\partial_{FE}(c) \equiv c \partial(1) = (c, c, c)
\end{aligned}
$$

Now, we should notice that the _image_ of $\partial_{FE}$ is a loop
$(o + m + c)$, which lies ie the _kernel_ of $\partial_{EV}$. This is a
general feature of homology, so it bears repeating:

- $Image(\partial_{FE}) \subset Kernel(\partial_{EV})$
- $\partial_{FE} \circ \partial_{EV} = 0$
- The above equation is sometimes stylishly (somewhat misleadingly) written as
  $\partial^2 = 0$. More faithfully, one can write $\partial_{EV} \circ \partial_{FE} = 0$.

Now, since the image of $\partial_{FE}$ lies entirely in the kernel of $\partial_{EV}$,
we can construct $H_1$ as:

- $H_1 \equiv Kernel(\partial_{EV}) / Image(\partial_{FE}) \subset E$




# An invitation to homology and cohomology, Part 2 --- Cohomology

<!--
f is closed <=> df = 0
f is exact <=> f = dg
-->

<img src="static/simplices/cohomology-triangle-vertices.svg">

Once again, we have our humble triangle with vertices $V = \{r, g, b\}$,
edges $E = \{o, m, c \}$, faces $F = \{ f \}$ with boundary maps $\partial_{EV}$,
$\partial_{FE}$:

- $\partial_{FE}(f)= o + m + c$
- $\partial_{EV}(o) = r - g$
- $\partial_{EV}(m) = b - r$
- $\partial_{EV}(c)= g - b$

We define a function $h_v: V \rightarrow \mathbb R$ on the vertices as:
-  $h_v(r) = 3$, $h_v(g) = 4$, $h_v(b) = 10$.

We now learn how to _extend_ this function to the higher dimensional objects,
the edges and the faces of the triangle.

To extend this function to the edges, we define a new function:

- $h_e: E \rightarrow R$
- $h_e(e) \equiv \sum_i \alpha_i h_v(v_i)$ where $\partial_{EV} e = \sum_i \alpha_i v_i$

Expanded out on the example, we evaluate $h_v$ as:

- $h_e(o) \equiv d h_v(o)  = h_v(r) - h_v(g) = 3 - 4 = -1$
- $h_e(m) \equiv d h_v(m)  = h_v(b) - h_v(r) = 10 - 3 = +7$
- $h_e(c) \equiv d h_v(c)  = h_v(g) - h_v(b) = 4 - 10 = -6$

More conceptually, we have created an _operator_ called $d$ (the **coboundary operator**)
which takes functions defined on vertices to functions defined on edges. This
uses the boundary map on the edges to "lift" a function on the vertices to a
function on the edges.  It does so by assigning the "potential difference" of
the vertices to the edges.


- $d: (V \rightarrow \mathbb R) \rightarrow (E \rightarrow \mathbb R)$
- $d(h_v) \equiv h_e$, $h_e(e) \equiv \sum_i \alpha_i f(v_i)$ where $\partial_{EV} e = \sum_i \alpha_i v_i$


We can repeat the construction we performed above, to construct another operator
$d : (E \rightarrow \mathbb R) \rightarrow (F \rightarrow \mathbb R)$, defined
in _exactly the same way_ as we did before. For example, we can evaluate:

- $h_f \equiv d(h_e)$
- $h_f(f) \equiv d h_e(f) = h_e(o) + h_e(m) + h_e(c) = -1 + 7 -6 = 0$

What we have is a chain:

- $h_v \xrightarrow{d} h_e \xrightarrow{d} h_f$

Where we notice that $d^2 = d \circ d = 0$, since the function $h_f$ that we have gotten
evaluates to zero on the face $f$. We can prove this will happen _in general_,
for any choice of $h_v$.
(it's a good exercise in definition chasing).


Introducing some terminology, A differential form $f$ is said to be a **closed differential form**
iff $df = 0$.

In our case, $h_e$ **is closed**, since $d h_e = h_f = 0$. On the other hand
$h_v$ is **not closed**, since $d h_v = h_e \neq 0$.

The intuition for why this is called "closed" is that its coboundary vanishes.

## Exploring the structure of functions defined on the edges

Here, we try to understand what functions defined on the edges can look like,
and their relationship with the $d$ operator. We discover that there are
some functions $g_e: E \rightarrow \mathbb R$ which can be realised as the differential
of another function $g_v: V \rightarrow \mathbb R$. The differential
forms such as $g_e$ which can be generated a $g_v$ through the $d$ operator
are called as **exact differential forms**. That is, $g_e = d g_v$ _exactly_,
such that there is no "remainder term" on applying the $d$ operator.

<img src="static/simplices/cohomology-triangle-edges.svg">

We take an example of a differential form that is _not exact_, which has been
defined on the edges of the triangle above. Let's call it $h_e$.

It is defined on the edges as:
- $h_e(c) = 3$
- $h_e(m) = 2$
- $h_e(o) = 1$

We can calcuate $h_f = d h_e$ the same way we had before:
- $h_f(f) \equiv d h_e(f) = h_e(o) + h_e(m) + h_e(c) = 3 + 1 + 2 = 6$.

Since $d h_e \neq 0$, this form is not exact.

Let's also try to generate $h_e$ from a potential. We arbitrarily fix the
potential of $b$ to $0$. That is, we fix $h_v(b) = 0$, and we then try to
see what values we are forced to values of $h_v$ across the rest of the triangle.

- $h_v b = 0$
- $h_e(c) = h_v(g) - h_v(b)$. $h_v(g) =  h_v(b) + h_e(c) = 0 + 3 = 3$.
- $h_e(o) = h_v(r) - h_v(g)$. $h_v(r) =  h_v(g) + h_e(o) = 3 + 1 = 4$.
- $h_e(m) = h_v(b) - h_v(r)$ $2 = 0 - 4$. This is a contradiction!
- Ideally, we need $h_v(b) = 6$ for the values to work out.


Hence, there can exist no such $h_v$ such that $h_e \equiv d h_v$.
The interesting thing is, when we started out by assigning $h_v(b) = 0$,
we could make _local choices_ of potentials that seemed like they would fit
together, but they failed to fit _globally_ throughout the triangle. This
failure of _locally consistent choices_ to be _globally consistent_ is
the essence of cohomology.

## Cohomology of half-filled butterfly

<img  src="static/simplices/cohomology-half-filled-butterfly.svg">

Here, we have vertices $V \equiv \\{ r, g, b, b, p \\}$, edges
$E \equiv \\{rb, gr, bg, m, o, c \\}$ and faces $F \equiv \\{ f \\}$.

Here, we see a differential form $h_e$ that is defined on the edges,
and also obeys the equation $dh_e = 0$ (Hence is closed). However, it
_does not have an associated potential energy_ to derive it from. That is,
there cannot exist a certain $h_v$ such that $d h_v = h_e$.


So, while every exact form is closed, _not every_ closed form is exact.

Hence, this $g$ that we have found is a non-trivial element of $Kernel(d_{FE}) / Image(d_{EV})$,
since $dh_e = 0$, hence $h_e \in Kernel(d_{FE})$, while there does not exist
a $h_v$ such that $d h_v = h_e$, hence it is _not quotiented_ by the image of
$d_{EV}$.

So the failure of the space to be fully filled in (ie, the space has a hole),
is measured by the _existence of a function $h_e$ that is closed but not exact!_

This reveals a deep connection between homology and cohomology, which is
made explicit by the [Universal Coefficient Theorem](https://en.wikipedia.org/wiki/Universal_coefficient_theorem)

# Stuff I learnt in 2019

I write these retrospective blog posts every year since 2017. I tend to post a
collection of papers, books, and ideas I've stumbled across that year.
Unfortunately, this year, the paper list will be sparser, since I lost some
data along the way to the year, and hence I don't have links to everything I
read. So this is going to be a sparser list, consisting of things that I found
_memorable_.

I also re-organised my website, letting the link die, since keeping it up was
taking far too many cycles (In particular, CertBot was far too annoying to
maintain, and the feedback of hugo was also very annoying). I now have a
_single_ file, the
[`README.md`of the `bollu/bollu.github.io`](https://github.com/bollu/bollu.github.io)
repo,
to which I add notes on things I find interesting. I've bound the `i` alias
(for idea) on all my shells everywhere, to open the `README.md` file, wait
for me to write to it, run a `git commit` so I can type out a commit, and
then push. This has been _massive_ for what I manage to write down: I feel
like I've managed to write down a lot of one-liners / small facts that I've
picked up which I would not otherwise. I'm attempting to similarly pare down
other friction-inducing parts of my workflow. Suggestions here would be very
welcome!


If there's a theme of the year (insofar as my scattered reading has a
theme...), it's "lattices and geometry". Geometry in terms of differential
geometry, topology, and topoi. Lattices in the sense of a bunch of abstract
interpretation and semantics.

#### Course work: optimisation theory, quantum computation, statistics

My course work was less interesting to me this time, due to the fact that I had
chosen to study some wild stuff earlier on, and now have to take reasonable stuff
to graduate. However, there were courses that filled in a lot of gaps in my
self-taught knowledge for me, and the ones I listed were the top ones in that
regard.

I wound up reading
[Boyd on optimisation theory](https://web.stanford.edu/~boyd/cvxbook/),
[Nielsen and Chuang](http://mmrc.amss.cas.cn/tlb/201702/W020170224608149940643.pdf) for quantum computation,
where I also
[solved a bunch of exercises in Q#](https://github.com/bollu/quantum-course-exercises)
which was very fun and rewarding. I'm beginning to feel that learning quantum
computation is the right route to grokking things like entanglement and
superposition, unlike the physics which is first of all much harder due to
infinite dimensionality, and less accessible since we can't _program_ it.

#### Formal research work: Compilers, Formal verification, Programming languages

My research work is on the above topics, so I try to stay abreast of what's
going on in the field. What I've read over the past year on these topics is:


- [`A^2I`: meta-abstract interpretation](https://popl19.sigplan.org/details/POPL-2019-Research-Papers/71/A-2-I-Abstract-2-Interpretation).
  This paper extends the theory of abstract interpretation to perform abstract
  interpretation on program analyses themselves. I'm not sure how _useful_ this
  is going to be, as I still hold on to the belief that AI as a framework is
  too general to allow one to prove complex results. But I am still interested
  in trying to adapt this to some problems I have at hand. Perhaps it's going
  to work.


- [Cubicial Agda](https://dl.acm.org/citation.cfm?id=3341691). This paper introduces
  cubical type theory and its implementation in Agda. It appears to solve many
  problems that I had struggled with during my formalization of loop
  optimisations: In particular, dealing with Coinductive types in Coq, and that
  of defining quotient types / setoids. Supposedly, cubical Agda makes dealing
  with Coinduction far easier. It allows allows the creation of "real" quotient
  types that respect equality, without having to deal with `setoid` style
  objects that make for large Gallina terms. I don't fully understand how the
  _theory_ works: In particular, as far as I can tell, the synthetic interval
  type `I` allows one to only access the start and end points (`0` and `1`),
  but not anything in between, so I don't really see how it allows for
  interpolation.  I also don't understand how this allows us to make Univalence
  computable.  I feel I need to practice with this new technology before I'm
  well versed, but it's definitely a paper I'm going to read many, many times
  till I grok it.


- [Naive Cubical type theory](https://arxiv.org/abs/1911.05844). This paper
  promises a way to perform informal reasoning with cubical type theory, the
  way we are able to do so with, say, a polymorphic type theory for lambda
  calculus. The section names such as "how do we think of paths",
  "what can we do with paths", inspire confidence

- [Call by need is Clairvoyant call by value](https://icfp19.sigplan.org/details/icfp-2019-papers/26/Call-By-Need-is-Clairvoyant-Call-By-Value). This key insight is to notice that call by need
  is "just" call by value, when we evaluate only those values that are
  eventually forced, and throw away the rest. Thus, if we had an oracle that
  tells us which values are eventually forced, we can convert call by need into
  call by value, relative to this oracle. This cleans up many proofs in the
  literature, and might make it far more intuitive to teach call by need to
  people as well. Slick paper, I personally really enjoyed reading this.

- [Shift/Reset the Penultimate Backpropagator](https://arxiv.org/abs/1803.10228)
  This paper describes how to implement backprop using delimited continuations.
  Also, supposedly, using staging / building a compiler out of this paradigm
  allows one to write high performance compilers for backprop without having
  to suffer, which is always nice.


- [Closed forms for numerical loops](https://www.cs.princeton.edu/~zkincaid/pub/popl19a.pdf)
  This paper introduces a new algebra of polynomials with exponentials. It then
  studies the eigenvalues of the matrix that describes the loop, and tries to
  find closed forms in terms of polynomials and exponentials. They choose
  to only work with rationals, but not extensions of rational numbers
  (in terms of field extensions of the rationals). Supposedly, this is easier
  to implement and reason about. Once again, this is a paper I'd like to
  reimplement to understand fully, but the paper is well-done!


- [Composable, sound transformations of Nested recursion and loops](https://engineering.purdue.edu/Papers/Sundararajah.pdf).
  This paper attempts to bring ideas from polyhedral compilation
  into working with nested recursion. They create a representation using
  multitape finite automata, using which they provide a representation for
  nested recursion. I was somewhat disappointed that it does not handle
  mutual recursion, since my current understanding is that one can always
  convert nested recursion into a "reasonable" straight line program by
  simply inlining calls and then re-using polyhedral techniques.


- [Reimplementation of `STOKE` at `bollu/blaze`.](https://github.com/bollu/blaze/blob/master/notebooks/tutorial.ipynb)
  I reimplemented the [STOKE: stochastic superoptimisation](http://stoke.stanford.edu/)
  paper, and much to my delight, it was super-effective at regenerating common
  compiler transformations. I want to use this to generate loop optimisations
  as well, by transforming a polyhedral model of the original program.


#### Internship at [Tweag.io](http://tweag.io/) over the summer: Hacking on Asterius (Haskell -> WebAssembly compiler)

- [Blog post on the progress made by me hacking on Austerius over at Tweag](https://www.tweag.io/posts/2019-09-12-webassembly-internship.html)

I really enjoyed my time at Tweag! It was fun, and
[Shao Cheng](https://github.com/TerrorJack)
was a great mentor. I must admit that I was somewhat distracted, by all the new
and shiny things I was learning thanks to all the cool people there `:)` In
particular, I wound up bugging
[Arnaud Spiwack](http://assert-false.net/arnaud/),
[Simeon Carstens](http://simeon-carstens.com/),
and [Matthias Meschede](https://github.com/mmesch)
quite a bit, about type theory, MCMC sampling, and signal processing of storm
clouds.

I wound up reading a decent chunk of GHC source code, and while I can't link
to specifics here, I understood a lot of the RTS much better than I did before.
It was an enlightening experience, to say the least, and being paid to hack on
a GHC backend was a really fun way to spend the summer.

It also led me to fun discoveries, such as
[how does one debug debug info?](https://github.com/ghc/ghc/blob/535a26c90f458801aeb1e941a3f541200d171e8f/compiler/cmm/Debug.hs#L458)


I also really loved Paris as a city. My AirBnb host was a charming artist who
suggest spots for me around the city, which I really appreciated. Getting
around was disorienting for the first week or so, due to the fact that I could
not (and still do not) really understand how to decide in which direction to
walk inside the subways to find a particular line
_going in a particular direction_.

The city has some great spots for quiet work, though! In particular, the
[Louvre Anticafe](https://www.anticafe.eu/lieux/louvre-paris-75001/)
was a really nice place to hang out and grab coffee. The model is great: you
pay for hours spent at the Anticafe, with coffee and snacks free. They also
had a discount for students which I gratefully used.
I bumped into interesting artists, programmers, and students who were open for
conversation there. I highly recommend hanging out there.

#### Probabilistic programming & giving a talk at FunctionalConf

This was the first talk I'd ever given, and it was on probabilistic programming
in haskell. In particular, I explained the
[`monad-bayes`](https://github.com/adscib/monad-bayes) approach of
doing this, and why this was profitable.
[The slides are available here](https://github.com/bollu/functionalconf-2019-slides-probabilistic-programming/blob/master/slides.pdf).


It was a fun experience giving a talk, and I'd like to do more of it, since I
got a lot out of attempting to explain the ideas to people. I wish I had more
time, and had a clearer idea of who the audience was. I got quite a bit of
help from [Michael Snoyman](https://www.snoyman.com/) to whip the talk into
shape, which I greatly appreciated.

The major ideas of probabilistic programming as I described it are
from Adam Scibior's thesis:

- [Adam Scibior: Formally justified and modular Bayesian inference for probabilistic programs](https://www.cs.ubc.ca/~ascibior/assets/pdf/thesis.pdf)

Along the way, I and others at tweag read the other major papers in the space,
including:

- [Church, a language for generative models](https://arxiv.org/pdf/1206.3255),
  which is nice since it describes it's semantics in terms of sampling. This is
  unlike Adam's thesis, where they define the denotational semantics in terms
  of measure theory, which is then approximated by sampling.
- [Riemann Manifold Langevin and Hamiltonian Monte Carlo](https://pdfs.semanticscholar.org/16c5/06c5bb253f7528ddcc80c72673fabf584f32.pdf)
  which describes how to perform Hamiltonian Monte Carlo on the
  _information geometry_ manifold.  So, for example, if we are trying to sample
  from gaussians, we sample from a 2D Riemannian manifold with parameters mean
  and varince, and metric as the [Fisher information metric](https://en.wikipedia.org/wiki/Fisher_information_metric).
  This is philosophically the "correct" manifold to sample from, since it
  represents the intrinsic geometry of the space we want to sample from.
- [An elementary introduction to Information geometry by Frank Nielsen](https://arxiv.org/pdf/1808.08271.pdf)
  something I stumbled onto as I continued reading about sampling from
  distributions. The above description about the "correct" manifold for
  gaussians comes from this branch of math, but generalises it quite a bit
  further. I've tried to reread it several times as I gradually gained maturity
  in differential geometry. I can't say I understand it just yet, but I hope to
  do so in a couple of months. I need more time for sure to meditate on the
  objects.
- [Reimplementation of `monad-bayes`](https://github.com/bollu/shakuni).
  This repo holds the original implementation on which the talk is based on.
  I read through the `monad-bayes` source code, and then re-implemented the
  bits I found interesting. It was a nice exercise, and you can see
  the git history tell a tale of my numerous mis-understandings of MCMC methods,
  till I finally got what the hell was going on.

#### Presburger Arithmetic

Since we use a bunch of [presburger arithmetic](https://en.wikipedia.org/wiki/Presburger_arithmetic)
for [polyhedral compilation](http://polyhedral.info/)
which is a large research interest of mine, I've been trying to build a
"complete" understanding of this space. So this time, I wanted to learn
how to build good solvers:

- [`bollu/gutenberger`](https://github.com/bollu/gutenberger) is a decision
  procedure for Presburger arithmetic that exploits their encoding as finite
  automata. One thing that I was experimenting with was that we only use
  numbers of finite bit-width, so we can explore the entire state space
  of the automata and then perform NFA reduction using
  [DFA minimisation](https://en.wikipedia.org/wiki/DFA_minimization). The
  reference I used for this was the excellent textbook
  [Automata theory: An algorithmic approach, Chapter 10](https://www7.in.tum.de/~esparza/autoskript.pdf)
- [The taming of the semi-linear set](http://www.lsv.fr/~haase/documents/ch16.pdf)
  This uses a different encoding of presburger sets, which allows them to bound
  a different quantity (the norm) rather than the bitwidth descriptions. This allows
  them to compute _exponentially_ better bounds for some operations than
  were known before, which is quite cool. This is a paper I keep trying to
  read and failing due to density. I should really find a week away from civilization
  to just plonk down and meditate upon this.

##### Open questions for which I want answers

I want better references to being able to _regenerate_ the inequalities
description from a given automata which accepts the presburger set automata.
This will allow one to smoothly switch between the _geometric_ description
and the _algebraic_ description. There are some operations that only work
well on the geometry (such as optimisation), and others that only work well on
the algebraic description (such as state-space minimisation). I have not found
any good results for this, only scattered fragments of partial results.
If nothing else, I would like some kind of intuition for _why this is hard_.

Having tried my stab at it, the general impression that I have is that the
space of automata is much larger than the things that can be encoded as
presburger sets. Indeed, it was shown that automata accept numbers which
are ultimately periodic.

-  first order logic + "arithmetic with +" + (_another operation I cannot recall_).
   I'm going to fill this in once I re-find the reference.

But yes, it's known that automata accept a language that's broader than just
first order logic + "arithmetic with +", which means it's hard to dis-entangle
the presburger gits from the non-presburger bits of the automata.


#### Prolog

I wanted to get a better understading of how prolog works under the hood, so I began
re-implementing the [WAM: warren abstract machine](http://wambook.sourceforge.net/).
It's really weird, this is the _only stable reference_ I can find to implementing
high-performance prolog interpreters. I don't really understand how to chase the
paper-trail in this space, I'd greatly appreciate references. My implementation
is at [`bollu/warren-cpp`](https://github.com/bollu/warren-cpp/). Unfortunately,
I had to give up due to a really hard-to-debug bug.

It's crazy to debug this abstract machine, since the internal representation gets
_super convoluted_ and hard to track, due to the kind of optimised encoding it
uses on the heap.

If anyone has a better/cleaner design for implementing good prologs, I'd love
to know.

Another fun paper I found in this space thanks to Edward Kmett was
[the Rete matching algorithm](http://www.drdobbs.com/architecture-and-design/the-rete-matching-algorithm/184405218),
which allows one to declare many many pattern matches, which are then "fused"
together into an optimal matcher that tries to reuse work across failed
matchers.

#### General Relativity

This was on my "list of things I want to understand before I die", so I wound
up taking up an Independent Study in university, which basically means that
I study something on my own, and visit a professor once every couple weeks,
and am graded at the end of the term. For GR, I wound up referencing a wide
variety of sources, as well as a bunch of pure math diffgeo books. I've read
everything referenced to various levels. I feel I did take away the core
ideas of differential and Riemannian geometry. I'm much less sure I've grokked
general relativity, but I can at least read the equations and I know all the
terms, so that's something.

- [The theoretical minimum by Leonard Susskind](https://theoreticalminimum.com/courses/general-relativity/2012/fall).
  The lectures are breezy in style, building up the minimal theory (and no proofs)
  for the math, and a bunch of lectures spent analysing the physics. While I wish
  it were a little more proof heavy, it was a really great reference to learn the
  basic theory! I definitely recommend following this and then reading other
  books to fill in the gaps.
- [Gravitation by Misner Thorne and Wheeler](https://en.wikipedia.org/wiki/Gravitation_(book))
  This is an imposing book. I first read through the entire thing (Well, the parts I thought I needed),
  to be able to get a vague sense of what they're going for. They're rigorous in
  a very curious way: It has a bunch of great _physics_ perspectives of looking
  at things, and that was invaluable to me. Their view of forms as "slot machines"
  is also fun. In general, I found myself repeatedly consulting this book for
  the "true physical" meaning of a thing, such as curvature, parallel transport,
  the equation of a geodesic, and whatnot.
- [Differential Geometry of Curves and Surfaces by do Carmo](http://www2.ing.unipi.it/griff/files/dC.pdf)
  This is the best book to intro differential geometry I found. It throws away
  all of the high powered definitions that "modern" treatments offer, and
  starts from the ground up, building up the theory in 2D and 3D. This is amazing,
  since it gives you small, computable examples for things like
  "the Jacobian represents how tangents on a surface are transformed locally".
- [Symplectic geometry & classical mechanics by Tobias Osborne](https://www.youtube.com/watch?v=pXGTevGJ01o&list=PLDfPUNusx1EoVnrQcCRishydtNBYU6A0c)
  This lecture series was great, since it re-did a lot of the math I'd seen
  in a more physicist style, especially around vector fields, flows, and
  Lie brackets. Unfortunately for me, I never even _got_ to the classical
  mechanics part by the time the semester ended. I began
  [taking down notes in my repo](https://github.com/bollu/notes/blob/master/diffgeo/main.pdf),
  which I plan to complete.
- [Introduction to Smooth manifolds: John Lee](https://sites.math.washington.edu/~lee/Books/ISM/)
  This was a very well written _mathematical_ introduction to differential geometry.
  So it gets to the physically important bits (metrics, covariant derivatives)
  far later, so I mostly used it as a reference for problems and more rigour.
- [Einstein's original paper introducing GR, translated](http://hermes.ffn.ub.es/luisnavarro/nuevo_maletin/Einstein_GRelativity_1916.pdf)
  finally made it click as to _why_
  he wanted to use tensor equations: tensor equations of the form `T = 0` are
  invariant in _any coordinate system_, since on change of coordinates, `T`
  changes by a multiplicative factor! It's a small thing in hindsight, but it
  was nice to see it explicitly spelled out, since as I understand, no one
  among the physicists knew tensor calculus at the time, so he had to introduce
  all of it.

#### Discrete differential geometry

I can't recall how I ran across this: I think it was because I was trying to
get a better understanding of Cohomology, which led me to Google for
"computational differential geometry", that finally led me to Discrete
differential geometry.

It's a really nice collection of theories that show us how to discretize
differential geometry in low dimensions, leading to rich intuitions and
a myriad of applications for computer graphics.

- [The textbook by Kennan Crane on the topic](https://www.cs.cmu.edu/~kmcrane/Projects/DDG/paper.pdf)
  which I read over the summer when I was stuck (more often than I'd like) in
  the Paris metro. The book is very accessible, and requires just some
  imagination to grok. Discretizing differential geometry leads to most things
  being linear algebra, which means one can calculate things on paper easily.
  That's such a blessing.
- [Geodesics in Heat](https://arxiv.org/pdf/1204.6216)
  explores a really nice way to discover geodesics by simulating the heat
  equation for a short time. The intuition is that we should think of the heat
  equation as describing the evolution of particles that are performing random
  walks. Now, if we simulate this system for a short while and then look at the
  distribution, particles that reach a particular location on the graph
  _must have taken the shortest path_, since any longer path would not have
  allowed particles to reach there. Thus, the distribution of particles at
  time `dt` does truly represent distances from a given point.  The paper
  explores this analogy to find accurate geodesics on complex computational
  grids. This is aided by the use of differential geometry, appropriately
  discretized.
- [The vector heat method](https://arxiv.org/pdf/1805.09170.pdf)
  explores computing the parallel transport of a vector across a discrete
  manifold efficiently, borrowing techniques from the 'Geodesics in Heat'
  paper.
- [Another paper by Kennan Crane: Lie group integrators for animation and control of vehicles](https://www.cs.cmu.edu/~kmcrane/Projects/LieGroupIntegrators/paper.pdf)
  This paper describes a general recipe to tailor-make integrators for a system
  of constraints, by directly integrating over the lie group of the
  configuration space.  This leads to much more stable integrators. I have some
  misguided hope that we can perhaps adapt these techniques to build better FRP
  (functional reactive programming) systems, but I need to meditate on this a
  lot more to say anything definitively.




#### Synthetic differential geometry

It was [Arnaud Spiwack](http://assert-false.net/arnaud/)
who pointed me to this. It's a nice axiomatic
system of differential geometry, where we can use physicist style proofs of
"taking stuff upto order `dx`", and having everything work upto mathematical
rigor.

The TL;DR is that we want to add a new number called `dx` into the reals,
such that `dx^2 = 0`. But if such a number did exist, then clearly `dx = 0`.
However, the punchline is that to prove that `dx^2 = 0 => dx = 0` requires
the use of contradiction!

So, if we banish the law of excluded middle (and therefore no longer use
proof by contradiction), we are able to postulate the existence of a new
element `dx`, which obeys `dx^2 = 0`. Using this, we can build up the
whole theory of differential geometry in a pleasing way, without having to
go through the horror that is real analysis. (I am being hyperbolic, but really,
real analytic proofs are not pleasant).

[I began formalizing this in Coq and got a formalism going: `bollu/diffgeo`](https://www.github.com/bollu/diffgeo).

Once I was done with that, I realised I don't know how to exhibit _models_ of
the damn thing! So, reading up on that made me realise that I need around 8
chapters worth of a grad level textbook (the aptly named
[Models of Smooth Infinitesimal Analysis](https://link.springer.com/book/10.1007/978-1-4757-4143-8)).

I was disheartened, so I [asked on `MathOverflow`](https://mathoverflow.net/questions/346385/constructing-computable-synthetic-differential-geometry)
(also my first ever question there), where I learnt about tangent categories and
differential lambda calculus. Unfortunately, I don't have the bandwidth to read
another 150-page tome, so this has languished.


### Optimisation on Manifolds

I began reading
[Absil: Optimisation on matrix manifolds](http://www.eeci-institute.eu/GSC2011/Photos-EECI/EECI-GSC-2011-M5/book_AMS.pdf)
which describes how to perform optimisation / gradient descent on
_arbitrary Riemannian manifolds_, as well as closed forms for well-known
manifolds. The exposition in this book is really good, since it picks a
concrete manifold and churns out all the basic properties of it manually. The
only problem I had with the books was that there were quite a few gaps (?) in
the proofs -- perhaps I missed a bunch.

This led me to learn Lie theory to some degree, since that was the natural
setting for many of the proofs. I finally saw _why_ anyone gives a shit about
the tangent space at the identity: because it's _easier to compute!_ For a
flavour of this,
[consider this question on `math.se` by me that asks about computing tangent spaces of $O(n)$](https://math.stackexchange.com/questions/3389983/explicit-description-of-tangent-spaces-of-on).

#### AIRCS workshop

I attended the
[AI risk for computer scientists](https://intelligence.org/ai-risk-for-computer-scientists/)
workshop hosted by
[MIRI (Machine intelligence research institute)](https://intelligence.org/) in
December. Here, a bunch of people were housed at a bed & breakfast for a
week, and we discussed AI risk, why it's potentially the most important thing
to work on, and anything our hearts desired, really. I came away with new
branches of math I wanted to read, a better appreciation of the AI risk
community and a sense of what their "risk timelines" were, and some
explanations about sheaves and number theory that I was sorely lacking. All in
all, it was a great time, and I'd love to go back.

#### P-adic numbers

While I was on a particularly rough flight back from the USA to India when
coming back from the AIRCS workshop, I began to read the textbook
[Introduction to p-adic numbers by Fernando Gouvea](https://www.springer.com/gp/book/9783540629115),
which fascinated me, so I then
[wrote up the cool parts introduced in the first two chapters as a blog post](http://bollu.github.io/#a-motivation-for-p-adic-analysis).
I wish to learn more about the p-adics and p-adic analysis, since they
seem to be deep objects in number theory.

In particular, a question that I thought might have a somewhat trivial answer
([why do the p-adics use base p in defining norm](https://math.stackexchange.com/questions/3482489/why-does-the-p-adic-norm-use-base-p))
turned out to have answers that were quite deep, which was something
unexpected and joyful!

#### Topology of functional programs

- [Slides by Martın Escardo](http://cs.ioc.ee/ewscs/2012/escardo/slides.pdf)
- [Synthetic topology of data types and classical spaces](https://pdf.sciencedirectassets.com/272990/1-s2.0-S1571066104X00177/1-s2.0-S1571066104051357/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEJP%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIGQAb828p1io4csznEej60j0PwJteuXf7OoHLSCDhkUTAiEA9ITs1JrUEOE%2Ft%2Fl5TI9ZkNLUfBIx42IZ%2FoAqQpdX4twq2AII6%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARACGgwwNTkwMDM1NDY4NjUiDBQOxJ3s3HCbVxSheCqsAt65yorZMMtIhLF7ML5sJQ9S5wZxBayKDrRkUKOjSzXxtQWebXs70FXhhpToXKvJoDrLgsqDzdF%2FAshZY%2FkDUep6KILxKnYxCBrBINhjFqxDlRZH0s1Y991RgCyNNnwmFI%2BrH70lSrV0OxQ9Z5WdXXPDkTLXv8512Xz%2BJn5DqEqdqD49FLbOuHl6PRM0TnYyNJkLBXNVwt75kkGkaTfdgmgiqh7YpcXcHlbqI2oqNcaxFDewXwKDCC7qWD6ECclLgszoeOXOtRI91nvNac8%2BLV4bXkKLXpd99H94N2vXPUPz99p6oqfdY9ixtcfI9POFX8agUilYjXKVhAWk4FSzzzMqbtZLBfkCZT4ffDTxRgL52yD%2FmL5E0Pe4mczVlUoB5DKoB8Lkitrt0BumQzDr4ffvBTrQAjVRuzG5V0CC%2Fd1t%2BUMPkrywaYytbrXCZ%2BkDo0xDBqsljY8DaGIiFINr8BEEpT7UX42GRhcDzpnOnztdAOTea3qZ3SmXJwgEoh0aiz%2B87MmsC57s0Q%2F%2B%2FDDvHBY3zLCrz7rdewXOgk6VxI9d5mhG3Du1dwPRbgOe798S2waDCD8LQA3rw7w5wNGa9Uv3xtNVH%2BHw%2FXcQ6OiubO4GL9mK8U5g7TVPh1hLB26XBQooKJ564VGf4J9VqWxjlx3NicVhqnFlGevNJNKyVLiyRsRCyQGMV59%2BXqUwdEMQZYWLbfUwELNz1NKfWumvu9BXC5jjsJgNx%2FRERSb7hqT1svMJU91o%2FHtatGAnPvVjYaNthha9O9jm%2BG9nw1vMsdyJ0asI5w5SrlsEyb5C7Vk7aLBcHAEi3XPRhivY1Q4hZAN0xY9VfEZrF%2FoM9HCGxr5cYs%2BP9w%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20191221T113658Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTY6QRXTPOC%2F20191221%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=8a26656e8f8c8772afdc2ae6caa9b583fd59a8ee6303d9770d25b4a3d8a6291f&hash=42518d3e5cc1e77ed961c359d0ea8f59bd582d1e5f13d69c3eeb2563a6c82abd&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1571066104051357&tid=spdf-584e8188-4806-44bb-a118-9b63a53caaff&sid=f53691052392834d3e18a62484e2909639a9gxrqb&type=client)

Both of these describe a general method to transfer all topological ideas as
statements about _computability_ in a way that's far more natural (at least for
me, as a computer scientist). The notion of what a continuous function "should
be" (keeping inverse images of open sets open) arises naturally from this
computational viewpoint, and many proofs of topology amount to finding
functional programs that fit a certain type. It's a great read, and I feel gave
me a much better sense of what topology is trying to do.

- [I've written some exposition on this topic](http://bollu.github.io/#topology-is-really-about-computation--part-1),
  which maybe a more accessible read than the links above, since it tries to
  distill the fundamental idea into a blog post.

#### Philosophy

I've wanted to understand philosophy as a whole for a while now, at least
enough to get a general sense of what happened in each century. The last year,
I meandered through some philosophy of science, which led me to some really
wild ideas (such as that of
[Paul Feyerabend's 'science as an anarchic enterprise'](https://en.wikipedia.org/wiki/Epistemological_anarchism)
which I really enjoyed).

I also seem to get a lot more out of audio and video than text in general, so
I've been looking for podcasts and video lectures. I've been following:

- [The history of philosophy without any gaps](https://historyofphilosophy.net/)
  for a detailed exposition on, say, the greeks, or the arabic philosophers.
  Unfortunately, this podcast focuses on far too much detail for me to have been
  able to use it as a way to get a broad idea about _philosophy_ in itself.

- [Philosophize This! by Stephen West](http://philosophizethis.org/)
  Is a good philosophy podcast for a _broad_ overview of different areas
  of Philosophy. I got a lot out of this, since I was able to get a sense
  of the progression of ideas in (Western) Philosophy. So I now know what
  [Phenomenology](https://plato.stanford.edu/entries/phenomenology/) is,
  or what Foucault was reacting against.


I also attempted to read a bunch of philosophers, but the only ones I could
make a good dent on were the ones listed below. I struggled in writing this
section, since it's much harder to sanity check my understanding of philosophy,
versus mathematics, since there seems to be a range of interpretations of the
same philosophical work, and the general imprecise nature of language doesn't
help here at all. So please take all the descriptions below with some salt
to taste.

- [Discipline and Punish by Michel Foucault](https://en.wikipedia.org/wiki/Discipline_and_Punish)
  Here, Foucault traces the history of the criminal justice system of society,
  and how it began as something performed 'on the body' (punishment),
  which was then expanded to a control 'of the mind' (reform). As usual,
  the perspective is fun, and I'm still going through the book.

- [Madness and Civilization by Michel Foucault](https://en.wikipedia.org/wiki/Madness_and_Civilization)
  which attempts to chronicle how our view of madness evolved as society did.
  It describes how madmen, who were on the edges of society, but still
  "respected" (for exmaple, considered as 'being touched by the gods') were
  pathologized by the Renaissance, and were seen as requiring treatment. I'm
  still reading it, but it's enjoyable so far, as a new perspective for me.


- [The value of science by Henri Poincare](https://en.wikipedia.org/wiki/The_Value_of_Science).
  Here, he defends the importance of experimentation, as well as the value of
  intuition to mathematics, along with the importance of what we consider
  formal logic. It's a tough read sometimes, but I think I got something out of
  it, at least in terms of perspective about science and mathematics.

#### Information theory

I've been on a quest to understand information theory far better than I
currently do. In general, I feel like this might be a much better way to
internalize probability theory, since it feels like it states probabilistic
objects in terms of "couting" / "optimisation of encodings", which is a
perspective I find far more natural.

Towards this aim, I wound up reading:

- [Information theory, Learning, and inference algorithms](http://www.inference.org.uk/mackay/itila/book.html)
  This book attempts to provide the holistic view I was hoping for. It has
  great illustrations of the basic objects of information theory. However,
  I was hoping that the three topics would be more "unified" in the book,
  rather than being presented as three separate sections with some amount
  of back-and-forth-referencing among them. Even so, it was a really fun read.

- [Elements of information theory](http://www.cs-114.org/wp-content/uploads/2015/01/Elements_of_Information_Theory_Elements.pdf)

#### Building intuition for Sheaves, Topoi, Logic

I don't understand the trifecta of sheaves, topoi, geometry, and logic, and
I'm trying to attack this knot from multiple sides at once.

- [Understanding networks and their behaviours using sheaf theory](https://arxiv.org/pdf/1308.4621)
- [Sheaves, objects, and distributed systems](https://www.sciencedirect.com/science/article/pii/S1571066108005264)
- [Sheaves are the canonical data strucure for sensor integration](https://arxiv.org/pdf/1603.01446.pdf)
- [Elementary applied topology, Chapter 9: Sheaves](https://www.math.upenn.edu/~ghrist/EAT/EATchapter9.pdf)
- [Sheaf theory: The mathematics of data fusion (video) (link to HackerNews)](https://news.ycombinator.com/item?id=13677308)

All of these provide geometric viewpoints of what sheaves are, in low-dimensional
examples of graphs which are easy to visualize. I'm also trudging through the
tome:

- [Sheaves in geometry and logic: A first introduction to Topos theory](https://www.springer.com/gp/book/9780387977102)

which appears to follow the "correct path" of the algebraic geometers, but this
requires a lot of bandwidth.

- [The Rising Sea: foundations of algebraic geometry by Ravi Vakil](http://math.stanford.edu/~vakil/216blog/FOAGnov1817public.pdf)

This is a hardcore algebraic geometry textbook, and is arguably
_great for studying sheaves_ because of it. Sheaves are Chapter 2, and allows
one to see them be developed in their "true setting" as it were. In that
Grothendeick first invented sheaves for algebraic geometry, so it's good to
see them in the home they were born in. Once again, this is a book I lack
bandwidth for except to breezily read it as I go to bed. I did get something
out from doing this. I'm considering taking this book up as an independent
study, say the first four chapters. I'll need someone who knows algebraic
geometry to supervise me, though, which is hard to find in an institute geared
purely for computer science. (If anyone on the internet is kind enough to
volunteer some of their time to answer questions, I'll be very glad! Please
email me at `rot13(fvqqh.qehvq@tznvy.pbz)`)

#### The attic

This section contains random assortments that I don't recall how I stumbled
across, but too cool to not include on the list. I usually read these in bits
and pieces, or as bedtime reading right before I go to bed to skim.  I find
that skimming such things gives me access to knowing about tools I would not
have known otherwise. I like knowing the existence of things, even if I don't
recall the exact thing, since knowing that something like `X` exists has saved me
from having to reinvent `X` from scratch.

- [Group Theory: Birdtracks, Lie's and Exceptional Groups by Predrag Cvitanovic](http://www.cns.gatech.edu/GroupTheory/version9.0/GroupTheory.pdf)
  is an exposition of Lie theory using some notation called as "Birdtrack notation",
  which is supposedly a very clean way of computing invariants, inspired by
  Feynmann notation. The writing style is informal and pleasant, and I decided
  to save the book purely because the first chapter begins with
  "Basic Concepts: A typical quantum theory is constructed from a few building blocks...".
  If a book considers building quantum theories as its starting point, I really
  want to see where it goes.

- [Elementary Applied topology by Robert M Ghirst](https://www.math.upenn.edu/~ghrist/notes.html)
  I wouldn't classify the book as elementary because it skims over too much to be
  useful as a reference, but it's great to gain an intuition for what, say,
  homology or cohomology is. I am currently reading the section on Sheaf theory,
  and I'm getting a lot out of it, since it describes how to write down, say,
  min-cut-max-flow or niquist-shannon in terms of sheaves. I don't grok it yet,
  but even knowing this can be done is very nice. The book is a wonderful
  walkthrough in general.


- [On polysemous mathematical illustration by Robert M Ghirst](https://icerm.brown.edu/video_archive/?play=2034)
  This is a talk on the wonderful illustrations by the above author, about
  the different types of mathematical illustrations one can have, and different
  "levels of abstraction".

- [Mathematical Impressions: The illustrations of AT Femenko](http://chronologia.org/en/math_impressions/poster016.html)
  These are _beautiful_ illustrated pictures of various concepts in math, which
  tend to _evoke_ the feeling of the object, without being too direct about it.
  For example, consider "gradient descent" below. I highly recommend going
  through the full gallery.


- [Gradient Descent](http://chronologia.org/art/math/123a176.jpg)
  <img width=200 height=200 src="http://chronologia.org/art/math/123a176.jpg">

- [Topological Zoo](http://chronologia.org/art/math/077a011.jpg)
  <img width=200 height=200 src="http://chronologia.org/art/math/077a011.jpg">

- [Persistent Homology in Multivariate Data Visualization](https://bastian.rieck.me/research/Dissertation_Rieck_2017.pdf)
  This is the PhD dissertation of [Bastian Rieck](https://bastian.rieck.me/),
  who's now a postdoc at ETH. I deeply enjoyed reading it, since it pays
  a lot of attention to the _design_ of analyses, and how to interpret
  topological data. I really enjoyed getting a good sense of how one can
  use persistent homology to understand data, and the trade-offs between
  [Vietoris-Rips complex](https://en.wikipedia.org/wiki/Vietoris%E2%80%93Rips_complex)
  and the [Cech complex](https://en.wikipedia.org/wiki/%C4%8Cech_complex).

- [An introduction to Geometric algebra](https://arxiv.org/pdf/1205.5935.pdf)
  I fell in love with geometric algebra, since it provides a really clean way
  to talk about _all possible subspaces_ of a given vector space. This provides
  super slick solutions to many geometry and linear algebra problems. The
  way I tend to look at it is that when one does linear algebra, there's a strict
  separation between "vectors" (which are elements of the vector space), and,
  say, "hyperplanes" (which are _subspaces_ of the vector space), as well as
  objects such as "rotations" (which are _operators_ on the vector space).
  Geometric algebra provides a rich enough _instruction set_ to throw all
  these three distinct things into a blender. This gives a really concise
  language to describe all phenomena that occurs in the vector space world ---
  which, let's be honest, is _most_ tractable phenomena! I had a blast
  reading about GA and the kinds of operators it provides.

- [Circuits via Topoi](https://arxiv.org/pdf/1807.07159). This paper attempts
  to provide an introduction to topos theory by providing a semantics for
  both combinational and sequential circuits under a unifying framework. I keep
  coming back to this article as I read more topos theory. Unfortunately, I'm
  not "there yet" in my understanding of topoi. I hope to be next year!


- [Fearless Symmetry](https://press.princeton.edu/books/paperback/9780691138718/fearless-symmetry)
  This is definitely my favourite non-fiction book that I've read in 2019, hands
  down. The book gives a great account of the mathematical objects that went
  into Wiles' book of Fermat's last theorem. It starts with things like
  "what is a permutation" and ends at questions like "what's a reciprocity law"
  or "what's the absolute galois group". While at points, I do believe the book
  goes far too rapidly, all in all, it's a solid account of number theory
  that's distilled, but not in any way diluted. I really recommend reading this
  book if you have any interest in number theory (or, like me, a passing
  distaste due to a course on elementary number theory I took, with proofs that
  looked very unmotivated). This book made me decide that I should, indeed,
  definitely learn algebraic number theory, upto at least
  [Artin Reciprocity](https://en.wikipedia.org/wiki/Artin_reciprocity_law).


- [Rememberance of Earth's past trilogy by Liu Cixin](https://en.wikipedia.org/wiki/Remembrance_of_Earth%27s_Past)
  While I would not classify this as "mind-blowing" (which I do classify Greg
  Egan books as), they were still a solidly fun read into how humanity would
  evolve and interact with alien races. It also poses some standard solutions
  to the Fermi Paradox, but it's done well. I felt that the fact that it was
  translated was painfully obvious in certain parts of the translation, which
  I found quite unfortunate. However, I think book 3 makes up in grandeur for
  whatever was lost in translation.

- [Walkaway by Cory Doctorow](https://en.wikipedia.org/wiki/Walkaway_(Doctorow_novel))
  The book is set in a dystopian nightmare, where people are attempting to
  "walk away" from society and set up communes, where they espouse having
  a post-scarcity style economy based on gifting. It was a really great
  description of what such a society could look like. I took issue with some
  weird love-triangle-like-shenanigans in the second half of the book, but
  the story arc more than makes up for it. Plus, the people throw a party
  called as a "communist party" in the first page of the book, which grabbed
  my attention immediately!

- [PURRS: Parma University Recurrence Relation Solver](http://www.cs.unipr.it/purrs/)
  I wanted better tactics for solving recurrences in Coq, which led me into
  a rabbit hole of the technology of recurrence relation solving. This was the
  newest _stable_ reference to a complete tool that I was able to find. Their
  references section is invaluable, since it's been vetted by them
  actually implementing this tool!

- [Term rewriting and all that](https://www21.in.tum.de/~nipkow/TRaAT/).
  I read this book purely for its description of Groebner bases and the Bucchberger
  algorithm in a way that _made sense_ for the first time.
  [I've written about this more extensively before](http://bollu.github.io/#what-the-hell-is-a-grobner-basis-ideals-as-rewrite-systems)
  so I'm not going to repeat myself here. In general, I think it's a great book
  that's worth reading, if nothing else, for at least the chapter on Groebner
  bases.

- [Lucid: The dataflow programming language](http://worrydream.com/refs/Wadge%20-%20Lucid,%20the%20Dataflow%20Programming%20Language.pdf)
  This document is the user manual of Lucid. I didn't fully understand the
  book, but what I understood as their main argument is that full access too
  looping is un-necessary to perform most of the tasks that we do. Rather,
  one can provide a "rich enough" set of combinators to manipulate streams
  that allows one to write all programs worthy of our interest.

- [Bundle Adjustment — A Modern Synthesis](https://hal.inria.fr/inria-00548290/document)
  I learnt about Bundle Adjustment from a friend taking a course on robotics.
  The general problem is to reconstruct the 3D coordinates of a point cloud
  given 2D projections of the points and the camera parameters, as the camera
  moves in time. I found the paper interesting since it winds up invoking a
  decent amount of differential geometric and gauge theoretic language to
  describe the problem at hand. I was unable to see why this vocabulary helped
  in this use-case, but perhaps I missed the point of the paper. It was hard to
  tell.

#### Conclusions

I always feel a little wrong posting this at the end of every year, since I
feel that among the things I cover under "read", I've internalized some things
far better than others: For example, I feel I understannd Riemannian geometry
far better than I do General Relativity. I try to put up the caveats at the
beginning of each section, but I'd really like a way to communicate my
confidence without reducing readability.


The final thing that I wish for is some kind of reading group? It's hard
to maintain a group when my interests shift as rapidly as they do, which
was one of the reason I really loved the AIRCS workshop: They were people
who were working on formal methods, compilers, type theory, number theory,
embedded systems, temporal logic... It was very cool to be in a group of
people who had answers and intuitions to questions that had bugged me for
some time now. I wonder if attending courses at a larger research university
feels the same way. My uni is good, but we have quite small population, which
almost by construction means reduced diversity.

I also wish that I could openly add more references to repos I've been working
on for a while now, but I can't due to the nature of academia and publishing.
This one bums me out, since there's a long story of a huge number of commits
and trial-by-fire that I think I'll be too exhausted to write about once the
thing is done.

Sometimes, I also wish that I could spend the time I spend reading _disparate_
topics on _focused reading on one topic_. Unfortunately, I feel like I'm not
wired this way, and the joy I get from sampling many things at the same time
and making connections is somehow much deeper than the joy I get by deeply
reading one topic (in exclusion of all else). I don't know what this says
about my chances as a grad student in the future `:)`.


# A motivation for p-adic analysis

I've seen the definitions of p-adic numbers scattered around on the internet,
but this analogy as motivated by the book
[p-adic numbers by Fernando Gouvea](https://www.springer.com/gp/book/9783540629115)
really made me understand why one would study the p-adics, and why the
definitions are natural. So I'm going to recapitulate the material, with the
aim of having somoene who reads this post be left with a sense of why it's
profitable to study the p-adics, and what sorts of analogies are fruitful when
thinking about them.

We wish to draw an analogy between the ring $\mathbb C[X]$, where $(X - \alpha)$
are the prime ideals, and $\mathbb Z$ where $(p)$ are the prime ideals. We wish
to take all operations one can perform with polynomials, such as generating
functions ($1/(X - \alpha) = 1 + X + X^2 + \dots$ ),
taylor expansions (expanding aronund $(X - \alpha)$),
and see what their analogous objects will look like in $\mathbb Z$
relative to a prime $p$.

#### Perspective: Taylor series as writing in base $p$:

Now, for example, given a prime $p$, we can write any positive integer $m$
in base $p$, as $(m = \sum_{i=0}^n a_i p^i)$ where $(0 \leq a_i \leq p - 1)$.

For example, consider $m = 72, p = 3$. The expansion of 72 is
$72 = 0\times 1 + 0 \times 3 + 2 \times 3^2 + 2 \times 3^3$.
This shows us that 72 is divisible by $3^2$.

This perspective to take is that this us the information local to prime $p$,
about what order the number $m$ is divisible by $p$,
just as the taylor expansion tells us around $(X - \alpha)$ of a polynomial $P(X)$
tells us to what order $P(X)$ vanishes at a point $\alpha$.

#### Perspective: rational numbers and rational functions as infinite series:

Now, we investigate the behaviour of expressions such as
- $P(X) = 1/(1+X) = 1 - X + X^2 -X^3 + \dots$.

We know that the above formula is correct formally from the theory of
generating functions.  Hence, we take inspiration to define values for
_rational numbers_.

Let's take $p \equiv 3$, and we know that $4 = 1 + 3 = 1 + p$.

We now calculate $1/4$ as:

$$
1/4 = 1/(1+p) = 1 - p + p^2 - p^3 + p^4 - p^5 + p^6 + \cdots
$$

However, we don't really know how to interpret $(-1 \cdot p)$, since we assumed
the coefficients are always non-negative. What we can do is to rewrite $p^2 = 3p$,
and then use this to make the coefficient positive. Performing this transformation
for every negative coefficient, we arrive at:


$$
\begin{aligned}
1/4 &= 1/(1+p) = 1 - p + p^2 - p^3 + p^4 + \cdots \\
&= 1 + (- p + 3p) + (- p^3 + 3p^3)  +  \cdots \\
&= 1 + 2p + 2p^3 + \cdots
\end{aligned}
$$

We can verify that this is indeed correct, by multiplying with $4 = (1 + p)$
and checking that the result is $1$:

$$
\begin{aligned}
&(1 + p)(1 + 2p + 2p^3 + \cdots) \\
&= (1 + p) + (2p + 2p^2) + (2p^3 + 2p^4) + \cdots \\
&= 1 + 3p + 2p^2 + 2p^3 + 2p^4 + \cdots \\
&\text{(Rewrite $3p = p \cdot p = p^2$)} \\
&= 1 + (p^2 + 2p^2) + 2p^3 + 2p^4 + \cdots \\
&= 1 + 3p^2 + 2p^3 + 2p^4 + \cdots \\
&\text{(Rewrite $3p^2 = p^3$ and collect $p^3$)} \\
&= 1 + 3p^3 + 2p^4 + \cdots \\
&= 1 + 3p^4 + \cdots \\
&= 1 + \cdots = 1
\end{aligned}
$$

What winds up happening is that all the numbers after $1$ end up being cleared
due to the carrying of $(3p^i \mapsto p^{i+1})$.

This little calculation indicates that we can also define take the $p$-adic
expansion of _rational numbers_.

#### Perspective: -1 as a p-adic number

We next want to find a p-adic expansion of -1, since we can then expand
out theory to work out "in general". The core idea is to "borrow" $p$, so
that we can write -1 as $(p - 1) - p$, and then we fix $-p$, just like we fixed
$-1$. This eventually leads us to an infinite series expansion for $-1$. Written
down formally, the calculation proceeds as:

$$
\begin{aligned}
-1 &= -1 + p - p  \qquad \text{(borrow $p$, and subtract to keep equality)} \\
&= (p - 1) - p \qquad \text{(Now we have a problem of $-p$)} \\
&= (p - 1) - p + p^2 - p^2  \\
&= (p - 1) + p(p - 1) - p^2 \\
&= (p - 1) + p(p - 1) - p^2 + p^3 - p^3 \\
&= (p - 1) + p(p - 1) + p^2(p - 1) - p^3 \\
&\text{(Generalizing the above pattern)} \\
-1 &= (p - 1) + p(p - 1) + p^2(p - 1) + p^3(p - 1) + p^4(p - 1) + \cdots \\
\end{aligned}
$$

This now gives us access to negative numbers, since we can formally multiply
the series of two numbers, to write $-a = -1 \cdot a$.


Notice that this definition of $-1$ also curiously matches the 2s complement
definition, where we have $-1 = 11\dots 1$. In this case, the expansion is
_infinite_, while in the 2s complement case, it is finite. I would be very
interested to explore this connection more fully.

#### What have we achieved so far?

We've now managed to completely reinterpret all the numbers we care about in
the rationals as power series in base $p$. This is pretty neat. We're next
going to try to _complete_ this, just as we complete the rationals to get
the reals. We're going to show that we get a _different_ number system on
completion, called $\mathbb Q_p$.

To perform this, we first look at how the $p$-adic numbers help us solve
congruences mod p, and how this gives rise to completions to equations such
as $x^2 - 2 = 0$, which in the reals give us $x = \sqrt 2$, and in $\mathbb Q_p$
give us a different answer!

#### Solving $X^2 \equiv 25 \mod 3^n$

Let's start by solving an equation we already know how to solve:
$X^2 \equiv 25 \mod 3^n$.

We already know the solutions to $X^2 \equiv 25 \mod 3^n$ in $\mathbb Z$ are
$X \equiv \pm 5 \mod 3^n$.

Explicitly, the solutions are:
- $X \equiv 3 \mod 3$
- $X \equiv 5 \mod 9$
- $X \equiv 5 \mod 27$
- At this point, the answer remains constant.

This was somewhat predictable. We move to a slightly more interesting case.

#### Solving $X = -5 \mod 3^n$

The solution sets are:
- $X \equiv -5 \equiv 1 \mod 3$
- $X \equiv -5 \equiv 4 = 1 + 3 \mod 9$
- $X \equiv -5 \equiv 22 = 1 + 3 + 2 \cdot 9 \mod 27$
- $X \equiv -5 \equiv 76 = 1 + 3 + 2 \cdot 9 + 2 \cdot 27 \mod 81$



This gives us the infinite 3-adic expansion:

- $X = -5 = 1 + 1\cdot 3 + 2\cdot 3^2 + 2\cdot 3^3 + \dots$

Note that we can't really _predict_ the digits in the 3-adic sequence of -5,
but we can keep expanding and finding more digits.

Also see that the solutions are "coherent". In that, if we look at the
solution mod 9, which is $4$, and then consider it mod 3, we get $1$. So,
we can say that given a sequence of integers $0 \leq \alpha_n \leq p^n - 1$,
**$\alpha_n$ is p-adically coherent sequence** iff:

- $ \alpha_{n+1} = \alpha_n \mod p^n$.


#### Viewpoint: Solution sets of $X^2 = 25 \mod 3^n$

Since our solution sets are coherent, we can view the solutions as a tree,
with the expansions of $X = 5, X = -5 \mod 3$ and then continuing onwards
from there. That is, the sequences are

- $2 \rightarrow 5 \rightarrow 5 \rightarrow 5 \rightarrow \dots$
- $1 \rightarrow 4 \rightarrow 22 \rightarrow 76 \rightarrow \dots$

#### Solving $X^2 \equiv 2 \mod 7^n$

We now construct a solution to the equation $X^2 = 1$ in the 7-adic system,
thereby showing that $\mathbb Q_p$ is indeed strictly _larger_ than $\mathbb Q$,
since this equation does not have rational roots.

For $n=1$, we have the solutions as $X \equiv 3 \mod 7$, $X \equiv 4 \equiv -3 \mod 7$.

To find solutions for $n = 2$, we recall that we need our solutions to be consistent
with those for $n = 1$. So, we solve for:
- $(3 + 7k)^2 = 2 \mod 49$, $(4 + 7k)^2 = 2 \mod 49$.

Solving the first of these:

$$
\begin{aligned}
(3 + 7k)^2 &\equiv 2 \mod 49 \\
9 + 42 k + 49k^2 &\equiv 2 \mod 49 \\
9 + 42 k + 0k^2 &\equiv 2 \mod 49 \\
7 + 42 k &\equiv 0 \mod 49 \\
1 + 6 k &\equiv 0 \mod 49 \\
k &\equiv 1 \mod 49
\end{aligned}
$$

This gives the solution $X \equiv 10 \mod 49$. The other branch ($X = 4 + 7k$)
gives us $X \equiv 39 \equiv -10 \mod 49$.

We can continue this process indefinitely (_exercise_), giving us the sequences:

- $3 \rightarrow 10 \rightarrow 108 \rightarrow 2166 \rightarrow \dots$
- $4 \rightarrow 39 \rightarrow 235 \rightarrow 235 \rightarrow \dots$

We can show that the sequences of solutions we get satisfy the equation
$X^2 = 2 \mod 7$. This is so by construction. Hence, $\mathbb Q_7$ contains
a solution that $\mathbb Q$ does not, and is therefore strictly bigger, since
we can already represent every rational in $\mathbb Q$ in $\mathbb Q_7$.


#### Use case: Solving $X = 1 + 3X$ as a recurrence

Let's use the tools we have built so far to solve the equation $X = 1 + 3X$.
Instead of solving it using algebra, we look at it as a recurrence $X_{n+1} = 1 + 3X_n$.
This gives us the terms:
- $X_0 = 1$
- $X_1 = 1 + 3$
- $X_2 = 1 + 3 + 3^2$
- $X_n = 1 + 3 + \dots + 3^n$

In $\mathbb R$, this is a divergent sequence. However, we know that the
solution so $1 + X + X^2 + \dots = 1/(1-X)$, at least as a generating function.
Plugging this in, we get that the answer should be:

- $1/(1 - 3) = -1/2$

which is indeed the correct answer.

Now this required some really shady stuff in $\mathbb R$. However, with a change
of viewpoint, we can explain what's going on. We can look at the above series
as being a series in $\mathbb Q_3$.  Now, this series does _really_ converge,
and by the same argument as above, it converges to $-1/2$.

The nice thing about this is that a dubious computation becomes a legal one
by changing one's perspective on where the above series lives.

#### Viewpoint: 'Evaluation' for p-adics

The last thing that we need to import from the theory of polynomials
is the ability to _evaluate_ them: Given a rational function $F(X) = P(X)/Q(X)$,
where $P(X), Q(X)$ are polynomials, we can
evaluate it at some arbitrary point $x_0$, as long as $x_0$ is not a zero
of the polynomial $Q(X)$.

We would like a similar function, such that for a fixed prime $p$, we obtain
a ring homomorphism from $\mathbb Q \rightarrow \mathbb F_p^x$, which we will
denote as $p(x_0)$, where we are imagining that we are "evaluating" the prime
$p$ against the rational $x_0$.

We define the value of $x_0 = a/b$ at the prime $p$ to be equal to
$ab^{-1} \mod p$, where $b b^{-1} \equiv 1 \mod p$. That is, we compute the
usual $ab^{-1}$ to evaluate $a/b$, except we do this $(\mod p)$, to stay with
the analogy.

Note that if $b \equiv 0 \mod p$, then we cannot evaluate
the rational $a/b$, and we say that $a/b$ has a pole at $p$. The order
of the pole is the number of times $p$ occurs in the prime factorization of $b$.

I'm not sure how profitable this viewpoint is, so I
[asked on math.se](https://math.stackexchange.com/questions/3483369/profit-of-definition-evaluation-of-a-rational-at-a-p-adic),
and I'll update this post when I recieve a good answer.


#### Perspective: Forcing the formal sum to converge by imposing a new norm:

So far, we have dealt with infinite series in base $p$, which have terms
$p^i, i \geq 0$.
Clearly, these sums are divergent as per the usual topology on $\mathbb Q$.
However, we would enjoy assigning analytic meaning to these series. Hence, we
wish to consider a new notion of the absolute value of a number, which makes it
such that $p^i$ with large $i$ are considered small.


We define the absolute value for a field $K$ as a function
$|\cdot |: K \rightarrow \mathbb R$. It obeys the axioms:


1. $\lvert x \rvert = 0 \iff x = 0$
2. $\lvert xy \rvert =  \lvert x \rvert  \lvert y \rvert$ for all $x, y \in K$
3. $\lvert x + y \rvert \leq \lvert x \rvert + \lvert y \rvert$, for all $x, y \in K$.


We want the triangle inequality so it's metric-like, and the norm to be
multiplicative so it measures the size of elements.

The usual absolute value $\lvert x \rvert \equiv \\{ x : x \geq 0; -x : ~ \text{otherwise} \\}$ satisfies
these axioms.

Now, we create a new absolute value that measures primeness. We first introduce
a gadget known as a valuation, which measures the $p$-ness of a number. We use
this to create a norm that makes number smaller as their $p$-ness increases.
This will allow infinite series in $p^i$ to converge.

#### p-adic valuation: Definition

First, we introduce
a valuation $v_p: \mathbb Z - \\{0\\} \rightarrow \mathbb R$, where $v_p(n)$ is
the power of the prime $p^i$ in the prime factorization of $n$. More formally,
$v_p(n)$ is the unique number such that:

- $n = p^{v_p(n)} m$, where $p \nmid m$.
- We extend the valuation to the rationals by defining $v_p(a/b) = v_p(a) - v_p(b)$.
- We set $v_p(0) = +\infty$. The intuition is that $0$ can be divided by $p$
  an infinite number of times.

The valuation gets larger as we have larger powers of $p$ in the prime
factorization of a number. However, we want the norm to get _smaller_. Also,
we need the norm to be multiplicative, while $v_p(nm) = v_p(n) + v_p(m)$, which
is additive.


To fix both of these, we create a norm by exponentiating $v_p$.
This converts the additive property into a multiplicative property. We
exponentiate with a negative sign so that higher values of $v_p$ lead to
smaller values of the norm.

#### p-adic abosolute value: Definition

Now, we define the **p-adic absolute value** of a number $n$ as
$|n|_p \equiv p^{-v_p(n)}$.

- the norm of $0$ is $p^{-v_p(0)} = p^{-\infty} = 0$.
- If $p^{-v_p(n)} = 0$, then $-v_p(n) = \log_p 0 = -\infty$, and hence $n = 0$.
- The norm is multiplicative since $v_p$ is additive.
- Since $v_p(x + y) \geq \min (v_p(x), v_p(y)), |x + y|_p \leq max(|x|_p, |y|_p) \leq |x|_p + |y|_p$.
  Hence, the triangle inequality is also satisfied.

So $|n|_p$ is indeed a norm, which measures $p$-ness, and is smaller as $i$
gets larger in the power $p^i$ of the factorization of $n$, causing our
infinite series to converge.

There is a question of why we chose a base $p$ for $|n|_p = p^{v_p(n)}$. It would
appear that any choice of $|n|_p = c^{v_p(n)}, c > 1$ would be legal.
[I asked this on `math.se`](https://math.stackexchange.com/questions/3482489/why-does-the-p-adic-norm-use-base-p),
and the answer is that this choosing a base $p$ gives us the nice formula

$$
\forall x \in \mathbb Z, \prod_{\{p : p~\text{is prime}\} \cup \{ \infty \}} |x|_p = 1
$$

That is, the product of all $p$ norms and the usual norm
(denoted by $\lvert x \rvert_\infty $ )
give us the number 1. The reason is that the $ \lvert x\rvert_p $ give us
multiples $p^{-v_p(x)}$,
while the usual norm $\lvert x \rvert_\infty$ contains a multiple
$p^{v_p(x)}$, thereby cancelling each other out.


#### Conclusion

What we've done in this whirlwind tour is to try and draw analogies between
the ring of polynomials $\mathbb C[X]$ and the ring $\mathbb Z$, by trying
to draw analogies between their prime ideals: $(X - \alpha)$ and $(p)$. So,
we imported the notions of generating functions, polynomial evaluation, and
completions (of $\mathbb Q$) to gain a picture of what $\mathbb Q_p$ is like.

We also tried out the theory we've built against some toy problems, that shows
us that this point of view maybe profitable. If you found this interesting,
I highly recommend the book
[p-adic numbers by Fernando Gouvea](https://www.springer.com/gp/book/9783540629115).



# Line of investigation to build physical intuition for semidirect products

To quote wikipedia:
> In crystallography, the space group of a crystal splits as the semidirect
> product of the point group and the translation group if and only if the space
> group is symmorphic

The if and only if is interesting: The geometry ofthe crystal lattice truly
appears to capture the structure of the semidirect product. It's a discrete
object as well, which makes it way easier to visualize. I'm going to hunt down
the definitions involved so I can finally feel like I truly understand semidirect
products from the "action" perspective.

# Topology is really about computation --- part 2

Here, we're going to describe whatever I've picked up of sheaves in the past
couple of weeks. I'm trying to understand the relationship between sheaves,
topoi, geometry, and logic. I currently see how topoi allows us to model logic,
and how sheaves allow us to model geometry, but I see nothing about the
relationship! I'm hoping that writing this down will allow me to gain some
perspective on this.

### What is a sheaf?

Let's consider two sets $P, A$, $P \subseteq A$. Now, given a function
$f: A \rightarrow X$, we can restrict this function to $ A_P: P \rightarrow X $.
So, we get to _invert the direction_:

$$
(P \subseteq A) \iff (f: A \rightarrow X) \rightarrow (f_P: P \rightarrow X)
$$

We should now try to discover some sort of structure to this "reversal"
business. Perhaps we will discover a contravariant functor! (Spoiler: we will).


# Topology is really about computation --- part 1

Most people believe that topology is about some notion of "nearness" or
"closeness", which has been abstracted out from our usual notion of
continuity that we have from a metric space. Here, I make the claim that
topology is really about _computation_, and more specifically, _decidability_.
These are not new ideas. I learnt of this from a monograph
[Synthetic topology of data types and classical spaces. Martın Escardo](https://www.cs.bham.ac.uk/~mhe/papers/entcs87.pdf).
This does not seem very well known, so I decided to write about it.

The idea is this: We have turing machines which can compute things. We then
also have a set $S$. Now, a topology $\tau \subset 2^S$ precisely encodes
which of the subsets of $S$ can be separated from the rest of the space by a turing machine.
Thus, a discrete space is a very nice space, where every point can be separated
from every other point. An indescrete space is one where no point can be separated.

Something like the reals is somewhere in between, where we can separate
stuff inside an open interval from stuff clearly outside, but there's some
funny behaviour that goes on at the boundary due to things like `(0.999... = 1)`,
which we'll see in detail in a moment.

#### Semidecidability

A subset $Q\subseteq S$ is _semidecidable_, if there exists a turing machine
$\hat Q: Q \rightarrow \{ \bot, \top \}$, such that:

$$
\begin{aligned}
\hat Q(q) = \top \iff q \in Q \\
\hat Q(q) = \bot \iff q \notin Q \\
\end{aligned}
$$

Where $\top$ signifies stopping at a state and returning `TRUE`, and
$\bot$ signifies _never halting at all_!. So, the subset $Q$ is
_semidedicable_, in that, we will halt and say `TRUE` if the element
belongs in the set. But if an element does not belong in the set, we are
supposed to never terminate.

#### Deep dive: semidecidability of the interval $(1, 2)$

Let's start with an example. We consider the interval $I = (1, 2)$, as a
subset of $\mathbb{R}$.Let the turing machine recieve the real number
as a function $f: \mathbb N \rightarrow \{0, 1, \dots 9\}$, such that
given a real number ${(a_0 \cdot a_1 \cdot a_2 \dots)}$, this is encoded as a
function ${f_a(i) = a_i}$.

We now build a turing machine $\hat I$ which when given the input the function $f_a$,
semi-decides whether ${a \in I}$.

Let's consider the numbers in $I$:

$$
\begin{aligned}
&0 \rightarrow \texttt{NO} \\
&0.\overline{9} \rightarrow \texttt{NO} \\
&1.00\dots \rightarrow \texttt{NO} \\
&1.a_1 a_2 \dots \rightarrow \texttt{YES} \\
&1.\overline{9} \rightarrow \texttt{NO} \\
&2.0 \rightarrow \texttt{NO} \\
&2.a_1 a_2 \rightarrow \texttt{NO}
\end{aligned}
$$

So, we can write a turing machine (ie, some code) that tries to decide whether
a real number $a$'s encoding $f_a$ belongs to the interval $I = (1, 2)$
as follows:

```py
def decide_number_in_open_1_2(f):
  # if the number is (1.abcd)
  if f(0) == 1:
    # (1.0...0<NOT0>) | look for the <NOT0>
    # If the number is 1.00..., do not terminate.
    if f(1) == 0: while f(i) == 0: i += 1
    # (1.99...9<NOT9>) | look for the <NOT9>
    # If the number is 1.99..., do not terminate.
    if f(1) == 9:  while f(i) == 9: i += 1
    else: return
    return
  # if the number is not 1.abcd, do not terminate
  while True: pass
```

Hence, we say that the interval $I = (1, 2)$ is _semi-decidable_, since we
have a function
$\hat I \equiv \texttt{decide-number-in-open-1-2}$
such that
$\hat I (f_a) \text{ terminates } \iff a \in I$.
We don't make _any claim_ about
what happens if $a \notin I$. This is the essence of semidecidability: We
can precisely state when elements in the set belong to the set, but not
when they don't.

### Semi decidability in general

To put this on more solid ground, we define a topology on a set $S$ by considering
programs which recieve as input elements of $S$, suitably encoded. For example,
the way in which we encoded real numbers as functions from the index to the
digit. Similarly, we encode other mathematical objects in some suitable way.

Now, we define:

- For every program $P$ which takes as inputs elements in $S$, the set
  ${halts(P) \equiv \\{ s \in S \vert P(s) \text{halts} \\}}$ is called as a
  _semidecidable set_.

- Alternatively, we can say for a subset ${T \subset S}$, if there
  exists a program ${\hat T}$, such that
  ${s \in T \iff \hat T(s) \text{ halts}}$, then $T$ is semi-dedecidable.

These are just two viewpoints on the same object. In one, we define the
set based on the program. In the other, we define the program based on the
set.

### Semi decidability of the empty set and the universe set.

The empty set is semi-decidable, due to the existence of the program:
```py
def semidecide_empty(x):
  while True: continue
```


The universe set is semi-decidable, due to the existence of the program:
```py
def semidecide_univ(x): return
```

### Semi decidability of the union of sets

infinite unions of sets are semi decidable, since we can "diagonalize" on
the steps of all programs. That way, if any program halts, we will reach
the state where it halts in our diagonalized enumeration.



Let `A00, A01... A0n` be the initial states of the machines. We are trying to
semidecide whether any of them halt. We lay out the steps of the machines
in an imaginary grid:

```
A00 A01 A02 ... A0n
A10 A11 A12 ... A1n
A20 A21 A22 ... A2n
Am0 Am1 Am2 ... Amn
```

For example, machine `A0` has states:

```
A00 -> A10 -> .. -> Am0
```
We can walk through the combined state-space of the machines as:

```
A00
A01 A10
A02 A11 A20
A03 A12 A21 A30
...
```

Where on the `k`'th line, we collect all states $A_{ij}$ such that $(i + j = k)$.

Now, if any of the machines have a state that is `HALT`, we will reach the
state as we enumerate the diagonals, and the machine that explores the
combined state space can also return `HALT`.

### Semi decidability of the intersection of sets

infinite intersections of sets are _not_ semi decidable, since by running
these programs in parallel, we cannot know if an infinite number of programs
halt in finite time. We _can_ tell if _one_ of them halts, but of if _all_
of them halt.

For example, consider the sequence of machines produced by `machine_creator`:

```py
# creates a machine that stops after n steps
def machine_creator(n):
    # f terminates after n steps
    def f(x):
      for _ in range(n):
        continue
    return

    return f
```

We wish to check if the intersection of all `machine_creator(n)` halt, for all
$n \geq 0, n \in \mathbb N$. Clearly, the answer is an infinite number of steps,
even though every single machine created by `machine_creator` halts in a
finite number of steps.

### An even deeper dive: re-examining the topology of the reals

We generally think of the topology of reals as being generated from the
base of intervals $(a, b)$. But really, this is a perverse perspective
from the point of view of computation.

Structurally speaking, the only comparison operator we have on the reals
is a $<$ operator. So we should ideally start by taking as a base
the sets $(-\infty, r)$. This is elegant, because:
1. it relates to the order theoretic notion of [downward closed set](https://en.wikipedia.org/wiki/Upper_set)
2. [By yoneda](https://math.stackexchange.com/a/37209/261373), the downward closed set $(-\infty, r)$ contains the exact same order theoretic information as $r$ itself.
3. It makes our "code" easier to write:

```
z = 10 # arbitrary fixed integer
def is_in_downward_closed_set(x_int, x_frac):
    """
    return true if x_int.x_frac < z
    """
    if x_int < z:
        i = 0
        while True:
           elif x_frac[i] == 9: i += 1 # examine next number.
           else: return True # x_frac[i] < r_frac[i]
    else:
        # loop forever
        loop()

def loop(): while True: pass
```

#### References
- [Synthetic topology of data types and classical spaces. Martın Escardo](https://www.cs.bham.ac.uk/~mhe/papers/entcs87.pdf)

# PSLQ algorithm: finding integer relations between reals

An algorithm to find _integer_ relations between _real_ numbers. It was
apparently named "algorithms of the century" by Computing in science and
engineering.

- [Wolfram link](http://mathworld.wolfram.com/PSLQAlgorithm.html)

# Geometric characterization of normal subgroups
> $Stab(Orb(x)) = Stab(x) \iff Stab(x) \text{ is normal}$

> $\forall x' \in Orb(x), Stab(x') = Stab(x) \iff Stab(x) \text{ is normal}$


#### Forward: if the stabilizer is normal, then all elements in the orbit have the same stabilizer

Let a group $G$ act on a set $X$ with action $(~\dot~) : G \times X \rightarrow X$.
Let $H \subseteq G$ be the stabilizer of a point $x \in X$. Now, let
$K = kHk^{-1}$, a conjugacy class of $H$. Clearly, the element $(k \cdot x)$
in the orbit of $x$ is stabilized by $K$.

If the group $H$ is normal, then $K = H$. So every element in the orbit of $x$
is stabilized by $H$.

#### Interaction of stablizer and the orbit:

> $Stab(g \cdot x) = g Stab(x) g^{-1}$

> $g^{-1} Stab(g \cdot x) g = Stab(x)$

-  Proof of $s \in Stab(x) \implies gsg^{-1} \in Stab(g \cdot x)$:
   The action of $gsg^{-1}$ on $g \cdot x$ is:
   $(g \cdot x \rightarrow_{g^-1} x \rightarrow_s x \rightarrow_g g \cdot x)$.

- Proof of $s' \in Stab(g \cdot x) \implies g^{-1}s'g \in Stab(x)$:
  The action of $g^{-1}s'g$ on $x$ is:
  $(x \rightarrow_{g} g \cdot x \rightarrow_{s'} g \cdot x \rightarrow_{g^{-1}} x)$.

Hence, both containments are proved.

#### Backward: if all elements in the orbit have the same orbit, then the stabilizer is normal.

From the above equation $Stab(g \cdot x) = g Stab(x) g^{-1}$. If the
entire orbit has the same stabilizer, $Stab (g \cdot x) = Stab(x)$. Hence,
we get $Stab(x) = g Stab(x) g^{-1}$, proving that it's normal.

# Handy characterization of adding an element into an ideal, proof that maximal ideal is prime

##### The characterization

Let $I$ be an ideal. The ideal generated by adding $(a \in R)$ to $I$ is
defined as $A \equiv (I \cup \{ a\})$. We prove that $A = I + aR$.


$$
\begin{aligned}
&(I \cup \{a \})  \\
&= \quad \{ \alpha i + \beta a | i \in I, \alpha, \beta \in R \} \\
&= \quad \{ i' + \beta a | i' \in I, \alpha, \beta \in R \} \qquad \text{($I$ is closed under multiplication by $R$)} \\
&= I + aR
\end{aligned}
$$

##### Quotient based proof that maximal ideal is prime

An ideal $P$ is prime iff the quotient ring $R/P$ is an integral domain. An
ideal $M$ is maximal $R/M$ is a field. Every field is an integral domain,
hence:

$M \text{ is maximal } \implies R/M \text{ is a field } \implies R/M \text {is an integral domain} \implies M \text{ is prime}$.

I was dissatisfied with this proof, since it is not ideal theoretic: It argues
about the behaviour of the quotients. I then found this proof that argues
purly using ideals:

#### Ideal theoretic proof that maximal ideal is prime

##### Sketch
Let $I$ be a maximal ideal. Let $a, b \in R$ such that $ab \in I$. We need
to prove that $a \in I \lor b \in I$. If $a \in I$, the problem is done.
So, let $a \notin I$. Build ideal $A = (I \cup {a})$. $I \subsetneq A$. Since
$I$ is maximal, $A = R$. Hence, there are solutions for
$1_R \in A \implies 1_r \in I + aR \implies \exists i \in I, r \in R, 1_R = i  + ar$.
Now, $b = b \cdot 1_R = b(i + ar) = bi + (ba)r \in I + IR = I$. ($ba \in I$ by assumption).
Hence, $b \in I$.


##### Details

let $i$ be a maximal ideal. let $a, b \in r$ such that $ab \in i$. we need
to prove that $a \in i \lor b \in i$.

if $a \in i$, then the problem is done. so, let $a \notin i$. consider
the ideal $A$ generated by adding $a$ into $I$. $A \equiv (I \cup \{a\})$.

We have shown that $A = I + aR$. Hence, $I + a0 = I \subset A$.
Also, $0 + ac \dot 1 = a \in A$, $a \neq I$ \implies $A \neq I$. Therefore,
$I \subsetneq A$. Since $I$ is maximal, this means that $A = R$

Therefore, $I + aR = R$. Hence, there exists some $i \in I, r \in R$ such
that $i + ar = 1_R$.

Now, $b = b \cdot 1_R = b \cdot (i + ar) = bi + (ba) r \in I + IR = I$ Hence,
$b \in I$.



# Radical ideals, nilpotents, and reduced rings

##### Radical Ideals
A radical ideal of a ring $R$ is an ideal such that
$\forall r \in R, r^n \in I \implies r \in I$.
That is, if any power of $r$ is in $I$, then the element
$r$ also gets "sucked into" $I$.

##### Nilpotent elements
A nilpotent element of a ring $R$ is any element $r$ such that there exists
some power $n$ such that $r^n = 0$.

Note that every ideal of the ring contains $0$. Hence, if an ideal $I$
of a ring is known to be a radical ideal, then for any nilpotent $r$,
since $\exists n, r^n = 0 \in I$, since $I$ is radical, $r \in I$.

That is, _a radical ideal with always contain all nilpotents!_ It will
contain other elements as well, but it will contain nilpotents for sure.

##### Radicalization of an ideal
Given a ideal $I$, it's radical idea $\sqrt I \equiv \{ r \in R, r^n \in I \}$.
That is, we add all the elements $I$ needs to have for it to become a radical.

Notice that the radicalization of the zero ideal $I$ will precisely contain
all nilpotents. that is, $\sqrt{(0)} \equiv \{ r \in R, r^n = 0\}$.

##### Reduced rings
A ring $R$ is a reduced ring if the only nilpotent in the ring is $0$.

##### creating reduced rings (removing nilpotents) by quotienting radical ideals
Tto remove nilpotents of the ring $R$, we can create $R' \equiv R / \sqrt{(0}$. Since
$\sqrt{(0)}$ is the ideal which contains all nilpotents, the quotient ring $R'$ will contain
no nilpotents other than $0$.

Similarly, quotienting by any larger radical ideal $I$ will remove all nilpotents
(and then some), leaving a reduced ring.

> A ring modulo a radical ideal is reduced

##### Integral domains
a Ring $R$ is an integral domain if $ab = 0 \implies a = 0 \lor b = 0$. That is,
the ring $R$ has no zero divisors.

##### Prime ideals

An ideal $I$ of a ring $R$ is a prime ideal if
$\forall xy \in R, xy \in I \implies x \in I \lor y \in I$. This generalizes
the notion of a prime number diving a composite: $p | xy \implies p | x \lor p | y$.

##### creating integral domains by quotenting prime ideals

Recall that every ideal contains a $0$. Now, if an ideal $I$ is prime, and if
$ab = 0 \in I$, then either $a \in I$ or $b \in I$ (by the definition of prime).

We create $R' = R / I$. We denote $\overline{r} \in R'$ as the image of $r \in R$
in the quotient ring $R'$.

The intuition is that quotienting by a  $I$, since if $ab = 0 \implies a \in I \lor b \in I$,
we are "forcing" that in the quotient ring $R'$, if $\overline{a} \overline{b} = 0$, then either
$\overline{a} = 0$ or $\overline{b} = 0$, since $(a \in I \implies \overline a = 0)$,
and $b \in I \implies \overline b = 0)$.

> A ring modulo a prime ideal is an integral domain.


I learnt of this explanation from this
[excellent blog post by Stefano Ottolenghi](http://quickmathintuitions.org/relationship-between-reduced-rings-radical-ideals-and-nilpotent-elements/).

# My disenchantment with abstract interpretation

When I first ran across the theory of abstract interpretation, it seemed magical:
Define two functions, check that they're monotone maps, and boom, we have
on our hands an analysis.

However, the problem appears to be that in reality, it's not as simple. Here is
the list of issues I've run across when trying to use abstract interpretation
for a "real world" use-case:


First of all, all interesting lattices are infinte height, requiring some
choice of widening.  Defining a good widening is a black art.  Secondly, while
there is a lot of theory on combining abstract domains (reduced products and
the like), it seems hard to deploy the theory in the real world.

I read a fair bit into the theory of abstract acceleration, where the idea is
that instead of widening indiscriminately, if our theory is powerful enough to
compute an exact closed form, we choose to do so. However, the problem is that
this regime does not "fit well" into abstract interpretation: We have the
abstract interpreter on the one hand, and then the acceleration regime on the
other, which is a separate algorithm. So the full analysis looks something
like:

```python
def analyze(program):
  analysis = {}
  for loop in inner to outer:
     loop_data = abstract_interpret(loop)
     analaysis.append(accelerate(loop))
  return analysis
```

That is, what used to be a nice theory of just "do things in any order and
it will converge", now becomes a new algorithm, that uses abstract interpretation
as a subroutine. This was not the hope I had! I wanted to _get away_ from having
to do proofs by analyzing an algorithm, this was the entire promise: Define
a lattice well enough and the proof is guaranteed. Rather, what I had
imagined was:

```python
def analyze(program):
  return abstract_interpret_using_acceleration_domain(program)
```

Now this `acceleration_domain` maybe frightfully complicated, but I'm willing
to pay that price, as long as it's an honest-to-god abstract interpretation.
This was a huge bummer for me to find out that this is not the case.


# Computing equivalent gate sets using grobner bases

Here's a fun little problem, whose only solution I know involves a fair
bit of math and computer algebra:

We are given the grammar for a language `L`:

```
E = T +_mod8 E | T -_mod8 E | T
T = V | V ^ V | V ^ V ^ V
V = 'a1' | 'a2' | ...
```


where `+_mod8` is addition modulo 8, `-_mod8` is subtraction modulo 8,
and `^` is XOR.

This language is equipped with the obvious
evaluation rules, corresponding to those of arithmetic. We are guaranteed
that during evaluation, the variables `a_i` will only have values `0` and `1`.
Since we have addition, we can perform multiplication by a constant
by repeated addition. So we can perform `3*a` as `a+a+a`.


We are then given the input expression `(a0 ^ a1 ^ a2 ^ a3)`. We wish
to find an equivalent expression in terms of the above language `L`.

We think of `E` as some set of logic gates we are allowed to use, and we are
trying to express the operation `(a0 ^ a1 ^ a2 ^ a3)` in terms of these gates.

The first idea that I thought was that of employing a grobner basis,
since they essentially embody rewrite rules modulo polynomial equalities, which
is precisely our setting here.

In this blog post, I'm going to describe what a grobner basis is and why it's
natural to reach for them to solve this problem, the code, and the eventual
solution.

As a spolier, the solution is:

```
a^b^c^d =
-a - b + c + 3*d - 3*axorb - axorc
+ axord - bxorc + bxord + 3*cxord
- 3*axorbxorc - axorbxord
+ axorcxord + bxorcxord
```

Clearly, this contains only additions/subtractions and multiplications by
a constant.

If there's some principled way to derive this (beyond throwing symbolic
algebra machinery), I'd really love to know ---
[Please raise an issue with the explanation!](https://github.com/bollu/bollu.github.io/issues)

##### What the hell is Grobner Basis?

The nutshell is that a grobner basis is a way to construct rewrite rules which
also understand arithmetic (I learnt this viewpoint from the book "Term
rewriting and all that". Fantastic book in general). Expanding on the
nutshell, assume we have a term rewriting system:

```
A -> -1*B -- (1)
C -> B^2  -- (2)
```

over an alphabet `{A, B, C}`.

Now, given the string `C + AB`, we wish to find out if it can be rewritten to
`0` or not. Let's try to substitute and see what happens:

```
C + AB -2-> B^2 + AB -1-> B^2 + (-1*B)B
```

At this point, we're stuck! we don't have rewrite rules to allow us to
rewrite `(-1*B)B` into `-B^2`. Indeed, creating such a list would be
infinitely long. But if we are willing to accept that we somehow have
the rewrite rules that correspond to polynomial arithmetic, where we view
`A, B, C` as variables, then we _can_ rewrite the above string to 0:

```
B^2 + (-1*B)B -> B^2 - B^2 -> 0
```

A Grobner basis is the algorithmic / mathematical machine that allows us
to perform this kind of substitution.

In this example, this might appear stupid: what is so special? We simply
substituted variables and arrived at `0` by using arithmetic. What's
so complicated about that? To understand why this is not always so easy,
let's consider a pathological, specially constructed example


##### A complicated example that shatters dreams

Here's the pathological example:

```
A -> 1     -- (1)
AB -> -B^2 -- (2)
```

And we consider the string `S = AB + B^2`.  If we blindly apply the
first rule, we arrive at:

```
S = AB + B^2 -1-> 1B + B^2 = B + B^2 (STUCK)
```

However, if we apply `(2)` and then `(1)`:

```
S = AB + B^2 -2-> -B^2 + B^2 -> 0
```

This tells us that we _can't just apply the rewrite rules willy-nilly_.
It's sensitive to the _order_ of the rewrites! That is, the rewrite system
is not [confluent](https://en.wikipedia.org/wiki/Confluence_(abstract_rewriting)).


The grobner basis is a function from rewrite systems to rewrite systems.
When given a rewrite system `R`, it produces a _new_ rewrite system `R'`
that _is confluent_. So, we can apply the rewrite rules of `R'` in any order,
and we guaranteed that we will only get a 0 from `R'` if and only if
we could have gotten a `0` from `R` for all strings.

We can then go on to phrase this whole rewriting setup in the language of
ideals from ring theory, and that is the language in which it is most
often described. I've gone into more depth on that perspective here:
["What is a grobner basis? polynomial factorization as rewrite systems"](#what-the-hell-is-a-grobner-basis-ideals-as-rewrite-systems).

Now that we have a handle on what a grobner basis is, let's go on to solve
the original problem:


##### An explanation through a slightly simpler problem

I'll first demonstrate the idea of how to solve the original problem
by solving a slightly simpler problem:

> Rewrite `a^b^c` in terms of `a^b`, `b^c`, `c^a` and the same `+_mod8` instruction
> set as the original problem. The only difference this time
> is that we do _not_ have `T -> V ^ V ^ V`.


The idea is to construct the polynomial ring over `Z/8Z` (integers modulo 8) with
variables as `a, b, c, axorb, bxorc, axorc`. Now, we know that `a^b = a + b - 2ab`. So,
we setup rewrite rules such that `a + b - 2ab -> axorb`, `b + c - 2bc -> bxorb`,
`c + a - 2ca -> cxora`.


We construct the _polynomial_ `f(a, b, c) = a^b^c`, which
has been written in terms of addition and multiplication, defined
as `f_orig(a, b, c) = 4*a*b*c - 2*a*b - 2*a*c - 2*b*c + a + b + c`. We then
rewrite `f_orig` with respect to our rewrite rules. Hopefully, the rewrite
rules should give us a clean expression in terms of one variable and
two-variable `xor`s. There is the danger that we may have some term
such as `a * bxorc`, and we do get such a term (`2*b*axorc`) in this case,
but it does not appear in the _original_ problem.



```py
# Create ring with variables a, b, c, axorb, bxorc, axorc
R = IntegerModRing(8)['a, b, c, axorb, bxorc, axorc']
(a, b, c, axorb, bxorc, axorc) = R.gens()


# xor of 2 numbers as a polynomial
def xor2(x, y): return x + y - 2*x*y

# xor of 3 numbers as a polynomial
def xor3(x, y, z): return xor2(x, xor2(y, z))

# define the ideal which contains relations:
# xor2(a, b) -> axorb, xor2(b, c) -> bxorc, xor2(a, c) -> axorc
# we also add the relation (a^2 - a = 0 => a = 0 or a = 1)
# since we know that our variables are only {0, 1}
I = ideal((axorb - xor2(a, b), bxorc - xor2(b, c), axorc - xor2(a, c), a*a-a, b*b-b, c*c-c))

# the polynomial representing a^b^c we wish to reduce
f_orig = xor3(a, b, c)

# we take the groebner basis of the ring to reduce the polynomial f.
IG = I.groebner_basis()

# we reduce a^b^c with respect to the groebner basis.
f_reduced = f_orig.reduce(IG)

print("value of a^b^c:\n\t%s\n\treduced: %s" % (f_orig, f_reduced))

# Code to evaluate the function `f` on all inputs to check correctness
def evalxor2(f):
    for (i, j, k) in [(i, j, k) for i in [0, 1] for j in [0, 1] for k in [0, 1]]:
      ref = i^^j^^k
      eval = f.substitute(a=i, b=j, c=k, axorb=i^^j, bxorc=j^^k, axorc=i^^k)
      print("%s^%s^%s: ref(%s) =?= f(%s): %s" %
        (i, j, k, ref, eval, ref == eval))

# check original formulation is correct
print("evaulating original f for sanity check:")
evalxor2(f_orig)

# Check reduced formulation is correct
print("evaulating reduced f:")
evalxor2(f_reduced)
```

Running the code gives us the reduced polynomial `-2*b*axorc + b + axorc`
which unfortunately contains a term that is `b * axorc`. So, this approach
does not work, and I was informed by my friend that she is unaware
of a solution to this problem (writing `a^b^c` in terms of smaller xors and
sums).


The full code output is:

```
value of a^b^c:
	4*a*b*c - 2*a*b - 2*a*c - 2*b*c + a + b + c
	reduced: -2*b*axorc + b + axorc
evaulating original f for sanity check:
0^0^0: ref(0) =?= f(0): True
0^0^1: ref(1) =?= f(1): True
0^1^0: ref(1) =?= f(1): True
0^1^1: ref(0) =?= f(0): True
1^0^0: ref(1) =?= f(1): True
1^0^1: ref(0) =?= f(0): True
1^1^0: ref(0) =?= f(0): True
1^1^1: ref(1) =?= f(1): True
evaulating reduced f:
0^0^0: ref(0) =?= f(0): True
0^0^1: ref(1) =?= f(1): True
0^1^0: ref(1) =?= f(1): True
0^1^1: ref(0) =?= f(0): True
1^0^0: ref(1) =?= f(1): True
1^0^1: ref(0) =?= f(0): True
1^1^0: ref(0) =?= f(0): True
1^1^1: ref(1) =?= f(1): True
```

That is, both the original polynomial and the reduced polynomial match
the expected results. But the reduced polynomial is not in our language `L`,
since it has a term that is a _product_ of `b` with `axorc`.


##### Tacking the original problem.

We try the exact same approach to the original problem of expressing
`a ^ b ^ c ^ d`. We find that the reduced polynomial is

```
-a - b + c + 3*d - 3*axorb - axorc
+ axord - bxorc + bxord + 3*cxord
- 3*axorbxorc - axorbxord
+ axorcxord + bxorcxord
```

which happily has no products between terms! It also passes our sanity
check, so we've now found the answer.

The full output is:
```
value of a^b^c^d:
	4*a*b*c + 4*a*b*d + 4*a*c*d + 4*b*c*d
      - 2*a*b - 2*a*c - 2*b*c - 2*a*d
      - 2*b*d - 2*c*d + a + b + c + d
reduced: -a - b + c + 3*d - 3*axorb
      - axorc + axord - bxorc + bxord
      + 3*cxord - 3*axorbxorc
      - axorbxord + axorcxord + bxorcxord
evaluating original a^b^c^d
0^0^0^0: ref(0) =?= f(0): True
0^0^0^1: ref(1) =?= f(1): True
0^0^1^0: ref(1) =?= f(1): True
0^0^1^1: ref(0) =?= f(0): True
0^1^0^0: ref(1) =?= f(1): True
0^1^0^1: ref(0) =?= f(0): True
0^1^1^0: ref(0) =?= f(0): True
0^1^1^1: ref(1) =?= f(1): True
1^0^0^0: ref(1) =?= f(1): True
1^0^0^1: ref(0) =?= f(0): True
1^0^1^0: ref(0) =?= f(0): True
1^0^1^1: ref(1) =?= f(1): True
1^1^0^0: ref(0) =?= f(0): True
1^1^0^1: ref(1) =?= f(1): True
1^1^1^0: ref(1) =?= f(1): True
1^1^1^1: ref(0) =?= f(0): True
evaluating reduced a^b^c^d
0^0^0^0: ref(0) =?= f(0): True
0^0^0^1: ref(1) =?= f(1): True
0^0^1^0: ref(1) =?= f(1): True
0^0^1^1: ref(0) =?= f(0): True
0^1^0^0: ref(1) =?= f(1): True
0^1^0^1: ref(0) =?= f(0): True
0^1^1^0: ref(0) =?= f(0): True
0^1^1^1: ref(1) =?= f(1): True
1^0^0^0: ref(1) =?= f(1): True
1^0^0^1: ref(0) =?= f(0): True
1^0^1^0: ref(0) =?= f(0): True
1^0^1^1: ref(1) =?= f(1): True
1^1^0^0: ref(0) =?= f(0): True
1^1^0^1: ref(1) =?= f(1): True
1^1^1^0: ref(1) =?= f(1): True
1^1^1^1: ref(0) =?= f(0): True
```

##### code for `a^b^c^d` reduction:


```py
def xor3(x, y, z): return xor2(x, xor2(y, z))

R = IntegerModRing(8)['a, b, c, d, axorb, axorc, axord, bxorc, \
        bxord, cxord, axorbxorc, axorbxord, axorcxord, bxorcxord']

(a, b, c, d, axorb, axorc, axord, bxorc, bxord, cxord, axorbxorc, \
        axorbxord, axorcxord, bxorcxord) = R.gens()
I = ideal((axorb - xor2(a, b),
           axorc - xor2(a, c),
           axord - xor2(a, d),
           bxorc - xor2(b, c),
           bxord - xor2(b, d),
           cxord - xor2(c, d),
           axorbxorc - xor3(a, b, c),
           axorbxord - xor3(a, b, d),
           axorcxord - xor3(a, c, d),
           bxorcxord - xor3(b, c, d),
           a*a-a,
           b*b-b,
           c*c-c,
           d*d-d
           ))
IG = I.groebner_basis()
f_orig = (xor2(a, xor2(b, xor2(c, d))))
f_reduced = f_orig.reduce(IG)
print("value of a^b^c^d:\n\t%s\n\treduced: %s" % (f_orig, f_reduced))

def evalxor3(f):
    for (i, j, k, l) in [(i, j, k, l) for i in [0, 1] \
                           for j in [0, 1] \
                           for k in [0, 1] \
                           for l in [0, 1]]:
      ref = i^^j^^k^^l
      eval = f.substitute(a=i, b=j, c=k, d=l,
                          axorb=i^^j, axorc=i^^k,
                          axord=i^^l, bxorc=j^^k,
                          bxord=j^^l, cxord=k^^l,
                          axorbxorc=i^^j^^k, axorbxord=i^^j^^l,
                          axorcxord=i^^k^^l, bxorcxord=j^^k^^l)
      print("%s^%s^%s^%s: ref(%s) =?= f(%s): %s" %
        (i, j, k, l, ref, eval, ref == eval))

print("evaluating original a^b^c^d")
evalxor3(f_orig)


print("evaluating reduced a^b^c^d")
evalxor3(f_reduced)
```

##### Closing thoughts

This was a really fun exercise: Around a hundred lines of code illuminates
the use of machinery such as grobner basis for solving real-world problems!
I really enjoyed hacking this up and getting nerd sniped.


# The janus programming language --- Time reversible computation

- [Wiki link](https://en.wikipedia.org/wiki/Janus_(time-reversible_computing_programming_language)
- [Original letter to Landlauer](http://tetsuo.jp/ref/janus.pdf)

I found out it's called Janus, since Janus is the god of doorways in greek
mythology. Hence, he is also the god of duality and transitions --- he
_literally_ looks both into the future and into the past.

> He is usually depicted as having two faces, since he looks to the future and
> to the past.

An apt name for the language!

# `A = B` --- A book about proofs of combinatorial closed forms


The book explains algorithms on solving closed forms for combinatorial
recurrences, by means of [Zeilberger's algorithm](http://mathworld.wolfram.com/ZeilbergersAlgorithm.html).

The book is written by Zeilberger himself, and supposedy also teaches one Maple.
I'd like to learn the algorithm, since it might be useful eventually for
Groebner basis / loop analysis shenanigans I like to play as part of
my work on compilers.

- [Download link here](https://www.math.upenn.edu/~wilf/AeqB.pdf)

# Generating `k` bitsets of a given length `n`:

The problem is to generate all bitvectors of length `n` that have `k` bits
set. For example, generate all bitvectors of length `5` that have `3` bits
set.

I know that an algorithm exists in Hacker's delight, but I've been too sick
to crack open a book, so I decided to discover the algorithm myself. The one
I came up with relies on looking at the numbers moving at a certain velocity,
and them colliding with each other. For example, let us try to generate all
`5C3` combinations of bits.


We start wih:
```
#1           count of position
a b c d e    positions
1 1 1 0 0    bitset
< - - - -    velocity
```

Where the `<` represents that the `1` at position `a` is moving leftwards.
Our arena is _circular_, so the leftmost `1` can wrap around to the right.
This leads to the next state

```
#2
a b c d e
0 1 1 0 1
- - - - <
```

We continue moving left peacefully.

```
#3
a b c d e
0 1 1 1 0
- - - < -
```

whoops, we have now collided with a block of `1`s. Not to worry, we simply
transfer our velocity by way of collision, from the `1` at `d` to the `1` at `b`.

I denote the transfer as follows:
```
#3
a b c d e
0 1 1 1 0  original state
- - - < -
- < < < -  transfer of velocity
- < - - -  final state after transfer of velocity
```

The `1` at `b` proceeds along its merry way with the given velocity

```
#4
a b c d e
1 0 1 1 0
< - - - -
```

Once again, it wraps around, and suffers a collision

```
#5
a b c d e
0 0 1 1 1
- - - - - < (collision, transfer)
- - < < < transfer of velocity
- - < - - final state after transfer of velocity
```

This continues:

```
0 1 0 1 1  #6
- < - - -
1 0 0 1 1  #7
< - - - - (collision, transfer velocity)
< - - < <
- - - < -
1 0 1 0 1 #8
- - < - -
1 1 0 0 1 #9
- < - - - (colision, transfer velocity
< < - - <
- - - - <
1 1 0 1 0 #10
- - - < -
1 1 1 0 0 #11: wrap around to initial state
```

I don't have a proof of correctness, but I have an intuition that this
should generate all states. Does anyone have a proof?

_EDIT:_ [this algorithm does not work](https://math.stackexchange.com/questions/3398241/correctness-proof-for-algorithm-to-generate-k-bitsets-of-n-bits-nck),
since it will keep clusters of $k-1$ bits next to each other, when a
bit hits a cluster of $k - 1$ bits.  For completeness, I'm going to draft out
the usual algorithm in full:

### Usual Algorithm

Let's consider the same example of `5C3`:

```
   a b c d e
1| 0 0 1 1 1 (LSB)
```

We start with all bits at their lowest position. Now, we try to go to
the next smallest number, which still has 3 bits toggled. Clearly, we need
the bit at position `b` to be 1, since that's the next number. Then,
we can keep the lower 2 bits `d, e` set to 1, so that it's still as small a
number as possible.

```
   a b c d e
2| 0 1 0 1 1 (LSB)
```

Once again, we now move the digit at `d` to the digit at `c`, while keeping
the final digit at `e` to make sure it's still the smallest possible.

```
   a b c d e
3| 0 1 1 0 1 (LSB)
```

Now, we can move the `1` at `e` to `d`, since that will lead to the smallest
increase:

```
   a b c d e
4| 0 1 1 1 0 (LSB)
```

At this point, we are forced to move to location `a`, since we have exhausted
all smaller locations. so we move the `1` at `b` to `a`, and then reset all
the other bits to be as close to the LSB as possible:

```
   a b c d e
5| 1 0 0 1 1 (LSB)
```

Continuing this process gives us the rest of the sequence:

```
    a b c d e
5 | 1 0 0 1 1
6 | 1 0 1 0 1
7 | 1 0 1 1 0
8 | 1 1 0 0 1 (note the reset of d!)
9 | 1 1 0 1 0
10| 1 1 1 0 0
```
# Bondi k-calculus

- [Link here](https://en.wikipedia.org/wiki/Bondi_k-calculus)

An alternative formalism to derive special relativity geometrically,
resting purely on hypotehses about the way light travels.

However, I've not been able to prove the correctness of the assumptions made,
by using coordinate geometry. I suspect this is because I will need to use
hyperbolic geometry for the "side lengths" to work out.


Indeed, I found another source, called as [The k-calculus fiddle](http://bearsoft.co.uk/Kcalc.html)
which attempts to discredit k-calculus. The author of the above blog writes at
the end:

> In asking Ray D'Inverno's permission to use his book as the example of
> k-calculus, he was kind enough to point out that the arguments I have given
> are invalid. Chapter 2 of his book should be read through to the end and then
> reread in the light of the fact that the geometry of space and time is
> Minkowskian. Euclidean geometry should not be used in interpreting the
> diagrams because their geometry is Minkowskian.

which seems to imply that we need to use hyperbolic geometry for this.

# Topology as an object telling us what zero-locus is closed:

- [Idea from this amazing post on `math.se`](https://math.stackexchange.com/questions/53852/is-there-a-way-of-working-with-the-zariski-topology-in-terms-of-convergence-limi)

# Vivado toolchain craziness

I found this file as I was cleaning up some old code, for a project to implement
a [fast K/V store on an FPGA](https://github.com/AakashKT/CuckooHashingHLS),
so I thought I should put this up for anyone else who stumbles on the
same frustrations / errors. I'm not touching this particular toolchain again
with a 10-foot pole till the tools stabilize by *a lot*.

##### Vivado HLS issues


- Unable to create BRAM for fields such as `bool`, `int16`. The data buses
  will be `8/16` bits long, with error:

```
[BD 41-241] Message from IP propagation TCL of /blk_mem_gen_7: set_property
error: Validation failed for parameter 'Write Width A(Write_Width_A)' for BD
Cell 'blk_mem_gen_7'. Value '8' is out of the range (32,1024) Customization
errors found on 'blk_mem_gen_7'. Restoring to previous valid configuration.
```

- I had an array of structs:

```cpp
struct S {
    bool b;
    int16 x;
    int16 y;
}
```

This gets generated as 3 ports for memory, of widths `1`, `16`, `16`. Ideally,
I wanted *one* port, of width `16+16+1=33`, for each struct value.
However, what was generated were three ports of widths `1`, `16`, and `16`
which I cannot connect to BRAM.

- `data_pack` allows us to create one port of width `16+16+1=33`

- Shared function names allocated on BRAM causes errors in synthesis:


```cpp
struct Foo {...};
void f (Foo conflict) {
    #pragma HLS interface bram port=conflict
}

void g (Foo conflict) {
    #pragma HLS interface bram port=conflict
}
```

- Enums causes compile failure in RTL generation  (commit `3c0d619039cff7a7abb61268e6c8bc6d250d8730`)
- `ap_int` causes compile failurre in RTL generation (commit `3c0d619039cff7a7abb61268e6c8bc6d250d8730`)
- `x % m` where `m != 2^k` is very expensive -- there must be faster encodings of modulus?
- How to share code between HLS and vivado SDK? I often wanted to share constant values between
  my HLS code and my Zynq code.
- Can't understand why array of structs that were packed does not get deserialized correctly. I had to manually
  pack a struct into a `uint32`. For whatever reason, having a `#pragma pack` did something to the representation of the struct
  as far as I can tell, and I couldn't treat the memory as just a raw `struct *` on the other side:


```cpp
// HLS side
struct Vec2  { int x; int y};
void f(Vec2 points[NUM_POINTS]) {
	#pragma HLS DATA_PACK variable=points
    #pragma HLS INTERFACE bram port=points

    points[0] = {2, 3};
}

// Host side
Vec2 *points = (Vec2 *)(0xPOINTER_LOCATION_FROM_VIVADO);

int main() {
    // points[0] will *not* be {2, 3}!
}
```

- If I change my IP, there is no way to preserve the current connections in the
  GUI why just updating the "changed connections". I'm forced to remove the IP
  and add it again (no, the Refresh IP button does not work).
- On generating a new bitstream from Vivado, Vivado SDK tries to reload the config,
  fails at the reloading (thinks `xil_print.h` doesn't exist), and then fails to compile code.
  Options are to either restart Vivado SDK, or refresh `xil_print.h`.


- It is entirely unclear what to version control in a vivado project, unless one
  has an omniscient view of the _entire toolchain_. I resorted to `git add` ing
  everything, but this is a terrible strategy in so many ways.


#### SDAccel bugs

**[link to tutorial we were following](https://www.xilinx.com/support/documentation/sw_manuals/xilinx2017_1/ug1028-sdsoc-intro-tutorial.pdf)**
- The executable is named `.exe` while it's actually an ELF executable (The SDAccel tutorials say it is called as `.elf`)
- the board is supposed to automatically boot into linux, which it does not. One is expected to call `bootd` manually (for "boot default") so it boots ito linux. (The SDAccel tutorials say it automatically boots into it)
- At this point, the SD card is unreadable. It took a bunch of time to figure out that the SD card needs to be mounted by us, and has the mount name `/dev/mmcblk0p1`. (The SDAccel tutorials say that it should be automatically mounted)
- At this point, we are unable to run `hashing.elf`. It dies with a truly bizarre error: `hashing.elf: command not found`. This is almost un-googleable, due to the fact that the same problem occurs when people don't have the correct file name.
- I rewrote `ls` with `hashing.elf` to see what would happen, because I conjectured that the shell was able to run `coreutils`.
- This dies with a different error `ls: core not found`. I'd luckily seen this during my android days, and knew this was from busybox.
- This led me to google "busybox unable to execute executable", which led me to this [StackOverflow link](https://stackoverflow.com/questions/1562071/how-can-i-find-which-elf-dependency-is-not-fulfilled) that clued me into the fact that the ELF interpreter is missing.
- When I discovered this, I wound up trying to understand how to get the right ELF interpreter. `readelf -l <exe name>` dumps out `[Requesting program interpreter: /lib/ld-linux-armhf.so.3]`. So, I bravely copied: `cp /lib/ld-linux.so.3 /lib/ld-linux-armhf.so.3`.
- Stuff is *still* broken, but I now get *useful* error messages:

```
zynq> /hashing.elf
/hashing.elf: error while loading shared libraries:
libxilinxopencl.so: cannot open shared object file: No such file or directory
```

At this point, clearly we have some linker issues (why does `xocc` not correctly statically link? What's up with it? Why does it expect it to be able to load a shared library? **WTF is happening**). do note that this is _not_ the way the process
is supposed to go according to the tutorial!
- Of course, there's no static library version of `libxilinxopencl.so`, so that's a dead end. I'm completely unsure if the tutorial even makes sense.
- This entire chain of debugging is full of luck.

- [Link talking about generating `BOOT` file](https://www.xilinx.com/html_docs/xilinx2018_2/sdsoc_doc/compiling-and-running-applications-on-arm-processor-hjy1504034381720.html)


At some point, I gave up on the entire enterprise.

# What the hell _is_ a Grobner basis? Ideals as rewrite systems

##### A motivating example

The question a Grobner basis allows us to answer is this: can the polynomial
$p(x, y) = xy^2 + y$ be factorized in terms of $a(x, y) = xy + 1, b(x, y) = y^2 - 1$,
such that $p(x, y) = f(x, y) a(x, y) + g(x, y) b(x, y)$ for some _arbitrary_ polynomials
$f(x, y), g(x, y) \in R[x, y]$.

One might imagine, "well, I'll divide and see what happens!" Now, there are two
routes to go down:

- $xy^2 + y = y(xy + 1) = y a(x, y) + 0 b(x, y)$. Well, problem solved?
- $xy^2 + y = xy^2 - x + x + y = x (y^2 - 1) + x + y = x b(x, y) + (x + y)$. Now what? we're stuck, and we can't apply `a(x, y)`!

So, clearly, the _order_ in which we perform of factorization / division starts
to matter! Ideally, we want an algorithm which is _not sensitive_ to the order
in which we choose to apply these changes. $x^2 + 1$.


##### The rewrite rule perspective


An alternative viewpoint of asking "can this be factorized", is to ask
"can we look at the factorization as a rewrite rule"? For this perspective,
notice that "factorizing" in terms of $xy + 1$ is the same as being
able to set $xy = -1$, and then have the polynomial collapse to zero.
(For the more algebraic minded, this relates to the fact that $R[x] / p(x) \sim R(\text{roots of p})$).
The intuition behind this is that when we "divide by $xy + 1$", really what
we are doing is we are setting $xy + 1 = 0$, and then seeing what remains. But
$xy + 1 = 0 \iff xy = -1$. Thus, we can look at the original question as:

How can we apply the rewrite rules $xy \rightarrow -1$, $y^2 \rightarrow 1$,
along with the regular rewrite rules of polynomial arithmetic to the polynomial
$p(x, y) = xy^2 + y$, such that we end with the value $0$?

Our two derivations above correspond to the application of the rules:

- $xy^2 + y \xrightarrow{xy = -1} -y + y = 0$
- $xy^2 + y \xrightarrow{y^2 = 1} x + y \nrightarrow \text{stuck!}$

That is, our [rewrite rules are not confluent](https://en.wikipedia.org/wiki/Confluence_(abstract_rewriting))

The grobner basis is a mathematical object, which is a  _a confluent set of rewrite rules_
for the above problem. That is, it's a set of polynomials which manage to find
the rewrite $p(x, y) \xrightarrow{\star} 0$, regardless of the order in which
we apply them. It's also _correct_, in that it only rewrites to $0$ if the
original system had _some way_ to rewrite to $0$.

###### The buchberger's algorithm

We need to identify
[critical pairs](https://en.wikipedia.org/wiki/Critical_pair_(logic)),
which in this setting are called as S-polynomials.

Let $f_i = H(f_i) + R(f_i)$ and $f_j = H(f_j) + R(f_j)$. Let $m = lcm(H(f_i), H(f_j))$,
and let $m_i, m_j$ be monomials such that $m_i \cdot H(f_i) = m = m_j \cdot H(f_j)$.
The S-polynomial induced by $f_i, f_j$ is defined as $S(f_i, f_j) = m_i f_i - m_i f_j$.


##### References
- [The term rewriting perspective is from the book "term rewriting and all that"](https://www21.in.tum.de/~nipkow/TRaAT/)
- [Sympy has excellent reading material on grobner basis](https://mattpap.github.io/masters-thesis/html/src/groebner.html)


# [Lie bracket versus torsion](lie-bracket-versus-torsion)


<img src="static/lie-bracket-versus-torsion.png">

This picture _finally_ made the difference between these two things clear.
The lie bracket moves along the _flow_, while the torsion moves along
_parallel transport_.

This is why the sides of the parallelogram that measure torsion form,
well, a parallelogram: we set them up using parallel transport.

On the other hand, the lie bracket measures the actual failure of the parallelogram
from being formed.

# [Blog post: Weekend paper replication of STOKE, the stochastic superoptimizer](https://github.com/bollu/blaze/blob/master/notebooks/tutorial.ipynb)

Click the title to go to the post. We replicate the `STOKE` paper in haskell,
to implement a superoptimiser based on MCMC methods.

# Collapsing `BlockId`, `Label`, `Unique`:

We have this hiearchy of `BlockId`, `Label`, and `Unique` that can be
collapsed.


# Spatial partitioning data structures in molecular dynamics

- [Cell lists](https://en.wikipedia.org/wiki/Cell_lists)
- [Verlet lists](https://en.wikipedia.org/wiki/Verlet_list)

appear to be version of spatial hierarchical data structures for fast
interaction computation. Apparently, multipole expansions are not useful
in this case since multipole expansions are useful to take into account
long range effects, but not short range effects.


# Vector: Arthur Whitney and text editors

- http://archive.vector.org.uk/art10501320


# Representing CPS in LLVM using the `@coro.*` intrinsics

This is part of a larger thread --- [Adding CPS call support to LLVM](http://lists.llvm.org/pipermail/llvm-dev/2017-April/112212.html) where there is a large discussion on the correct design of how to teach LLVM about CPS.

Gor Nishanov proided the above example of encoding CPS using the llvm `coro` instructions.

- https://gist.github.com/bollu/e0573dbc145028fb42f89e64c6dd6742

# Bug in the LLVM code generator: Lowering of `MO_Add2` and `MO_AddWordC`

[Both of these are lowered the same way](https://github.com/ghc/ghc/blob/bf73419518ca550e85188616f860961c7e2a336b/compiler/llvmGen/LlvmCodeGen/CodeGen.hs#L817),
but they should be different.

In particular, `GHC.Prim` explains:
- [`AddWordC#`](http://hackage.haskell.org/package/ghc-prim-0.5.3/docs/GHC-Prim.html#v:addWordC-35-) returns `(result, carry)`
- [`PlusWordC#`](http://hackage.haskell.org/package/ghc-prim-0.5.3/docs/GHC-Prim.html#v:plusWord-35-) returns `(carry, result)`

Honestly, this is confusing, but I guess there's some story to having two separate primops for this?


# Discrete random distributions with conditioning in 20 lines of haskell

```hs
newtype D a = D { unD :: [(a, Double)] } deriving(Eq, Show, Ord)

instance Functor D where
    -- fmap :: (a -> b) -> D a -> D b
    fmap f (D xs) = D $ fmap (\(a, d) -> (f a, d)) xs

instance Monad D where
    return x = D $ [(x, 1.0)]
    -- f :: a -> (D b)
    (D as) >>= f = D $ do -- list monad
                      (a, p) <- as
                      (b, p2) <- unD (f a)
                      return $ (b, p * p2)

-- [(a, 0.5), (b, 0.5)]
-- [(a, 0.3), (a, 0.2), (b, 0.1), (b, 0.4)]
--
instance Applicative D where
    pure = return
    ff <*> fa = do
        f <- ff
        a <- fa
        return $ f  a

condition :: Bool -> D ()
condition True = D [((), 1.0)]
condition False = D [((), 0.0)]


dice :: D Int
dice = let p = 1.0 / 6 in D $ [(x, p) | x <- [1..6]]


dice_hard :: D Int
dice_hard = do
    x <- dice
    condition $ x > 3
    return $ x


main :: IO ()
main = do
    print dice
    print dice_hard
```

This gives the output:

```
D {unD = [(1,0.16666666666666666),
          (2,0.16666666666666666),
          (3,0.16666666666666666),
          (4,0.16666666666666666),
          (5,0.16666666666666666),
          (6,0.16666666666666666)]}

D {unD = [(1,0.0),
          (2,0.0),
          (3,0.0),
          (4,0.16666666666666666),
          (5,0.16666666666666666),
          (6,0.16666666666666666)]}
```

Notice that `D a ~= WriterT (Product Float) []`!

# Everything you know about word2vec is wrong

The classic explanation of `word2vec`, in skip-gram, with negative sampling,
in the paper and countless blog posts on the internet is as follows:

```
while(1) {
   1. vf = vector of focus word
   2. vc = vector of context word
   3. train such that (vc . vf = 1)
   4. for(0 <= i < negative samples):
           vneg = vector of word *not* in context
           train such that (vf . vneg = 0)
}
```

Indeed, if I google "word2vec skipgram", the results I get are:
- [The wikipedia page which describes the algorithm on a high level](https://en.wikipedia.org/wiki/Word2vec#Training_algorithm)
- [The tensorflow page with the same explanation](https://www.tensorflow.org/tutorials/representation/word2vec)
- [The towards data science blog which describes the same algorithm](https://towardsdatascience.com/word2vec-skip-gram-model-part-1-intuition-78614e4d6e0b)

the list goes on. However, __every single one of these implementations is wrong__.

The original word2vec `C` implementation does _not_ do what's explained above,
and is _drastically different_. Most serious users of word embeddings, who use
embeddings generated from `word2vec` do one of the following things:

1. They invoke the original C implementation directly.
2. They invoke the `gensim` implementation, which is _transliterated_ from the
   C source to the extent that the variables names are the same.

Indeed, the `gensim` implementation is the
__only one that I know of which is faithful to the C implementation__.

### The C implementation

The C implementation in fact maintains _two vectors for each word_, one where
it appears as a focus word, and one where it appears as a context word.
(Is this sounding familiar? Indeed, it appears that GloVe actually took this
idea from `word2vec`, which has never mentioned this fact!)

The setup is incredibly well done in the C code:

- An array called `syn0` holds the vector embedding of a word when it occurs
  as a _focus word_. This is __random initialized__.

```cpp
https://github.com/tmikolov/word2vec/blob/20c129af10659f7c50e86e3be406df663beff438/word2vec.c#L369
  for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++) {
    next_random = next_random * (unsigned long long)25214903917 + 11;
    syn0[a * layer1_size + b] =
       (((next_random & 0xFFFF) / (real)65536) - 0.5) / layer1_size;
  }

```

- Another array called `syn1neg` holds the vector of a word when it occurs
  as a _context word_. This is __zero initialized__.

```cpp
https://github.com/tmikolov/word2vec/blob/20c129af10659f7c50e86e3be406df663beff438/word2vec.c#L365
for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++)
  syn1neg[a * layer1_size + b] = 0;
```

- During training (skip-gram, negative sampling, though other cases are
  also similar), we first pick a focus word. This is held constant throughout
  the positive and negative sample training. The gradients of the focus vector
  are accumulated in a buffer, and are applied to the focus word
  _after it has been affected by both positive and negative samples_.

```cpp
if (negative > 0) for (d = 0; d < negative + 1; d++) {
  // if we are performing negative sampling, in the 1st iteration,
  // pick a word from the context and set the dot product target to 1
  if (d == 0) {
    target = word;
    label = 1;
  } else {
    // for all other iterations, pick a word randomly and set the dot
    //product target to 0
    next_random = next_random * (unsigned long long)25214903917 + 11;
    target = table[(next_random >> 16) % table_size];
    if (target == 0) target = next_random % (vocab_size - 1) + 1;
    if (target == word) continue;
    label = 0;
  }
  l2 = target * layer1_size;
  f = 0;

  // find dot product of original vector with negative sample vector
  // store in f
  for (c = 0; c < layer1_size; c++) f += syn0[c + l1] * syn1neg[c + l2];

  // set g = sigmoid(f) (roughly, the actual formula is slightly more complex)
  if (f > MAX_EXP) g = (label - 1) * alpha;
  else if (f < -MAX_EXP) g = (label - 0) * alpha;
  else g = (label - expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP / 2))]) * alpha;

  // 1. update the vector syn1neg,
  // 2. DO NOT UPDATE syn0
  // 3. STORE THE syn0 gradient in a temporary buffer neu1e
  for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1neg[c + l2];
  for (c = 0; c < layer1_size; c++) syn1neg[c + l2] += g * syn0[c + l1];
}
// Finally, after all samples, update syn1 from neu1e
https://github.com/tmikolov/word2vec/blob/20c129af10659f7c50e86e3be406df663beff438/word2vec.c#L541
// Learn weights input -> hidden
for (c = 0; c < layer1_size; c++) syn0[c + l1] += neu1e[c];
```

### Why random and zero initialization?

Once again, since none of this actually explained in the original papers
_or on the web_, I can only hypothesize.

My hypothesis is that since the negative samples come from all over the text
and are not really weighed by frequency, you can wind up picking _any word_,
and more often than not, _a word whose vector has not been trained much at all_.
If this vector actually had a value, then it could move the actually important
focus word randomly.

The solution is to set all negative samples to zero, so that
_only vectors that have occurred somewhat frequently_ will affect the representation
of another vector.

It's quite ingenious, really, and until this, I'd never really thought of
how important initialization strategies really are.


### Why I'm writing this

I spent two months of my life trying to reproduce `word2vec`, following
the paper exactly, reading countless articles, and simply not succeeding.
I was unable to reach the same scores that `word2vec` did, and it was not
for lack of trying.

I could not have imagined that the paper would have literally fabricated an
algorithm that doesn't work, while the implementation does something completely
different.

Eventually, I decided to read the sources, and spent three whole days convinced
I was reading the code wrong since literally everything on the internet told me
otherwise.

I don't understand why the original paper and the internet contain zero
explanations of the _actual_ mechanism behind `word2vec`, so I decided to put
it up myself.

This also explains GloVe's radical choice of having a separate vector
for the negative context --- they were just doing what `word2vec` does, but
they told people about it `:)`.

Is this academic dishonesty? I don't know the answer, and that's a heavy
question. But I'm frankly incredibly pissed, and this is probably the last
time I take a machine learning paper's explanation of the algorithm
seriously again --- from next time, I read the source _first_.

# Hamiltonian monte carlo, leapfrog integrators, and sympletic geometry

This is a section that I'll update as I learn more about the space, since I'm studying
differential geometry over the summer, I hope to know enough about "sympletic manifolds".
I'll make this an append-only log to add to the section as I understand more.

##### 31st May

- To perform hamiltonian monte carlo, we use the hamiltonian and its
  derivatives to provide a momentum to our proposal distribution --- That is,
  when we choose a new point from the current point, our probability
  distribution for the new point is influenced by our current momentum.

- For some integral necessary within this scheme, Euler integration doesn't cut it
  since the error diverges to infinity

- Hence, we need an integrator that guarantees that the energy of out system is
  conserved.  Enter the leapfrog integrator. This integrator is also
  _time reversible_ -- We can run it forward for `n` steps, and then run it
  backward for `n` steps to arrive at the same state.  Now I finally know how
  Braid was implemented, something that bugged the hell out of 9th grade me
  when I tried to implement Braid-like physics in my engine!

- The actual derivation of the integrator uses Lie algebras, Sympletic
  geometry, and other diffgeo ideas, which is great, because it gives me
  motivation to study differential geometry `:)`

- Original paper: [Construction of higher order sympletic integrators](https://www.sciencedirect.com/science/article/abs/pii/0375960190900923)

##### Simulating orbits with large timesteps

<img src="./static/leapfrog-vs-euler.png">

Clearly, the leapfrog integrator preserves energy and continues to move
in an orbit, while the euler integrator goes batshit and causes orbits
to spiral outwards. Full code is available below. More of the code is
spent coaxing matplotlib to look nice, than doing the actual
computation.

```py
import numpy as np
import matplotlib.pyplot as plt
import numpy.linalg

# dq/dt = dH/dp | dp/dt = -dH/dq (a = -del V)
def leapfroge(dhdp, dhdq, q, p, dt):
    p += -dhdq(q, p) * 0.5 * dt # halfstep momentum
    q += dhdp(q, p) * dt # fullstep position
    p += -dhdq(q, p) * 0.5 * dt # halfstep momentum
    return (q, p)

def euler(dhdp, dhdq, q, p, dt):
    pnew = p + -dhdq(q, p) * dt
    qnew = q + dhdp(q, p) * dt

def planet(integrator, n, dt):
    STRENGTH = 0.5

    q = np.array([0.0, 1.0]); p = np.array([-1.0, 0.0])

    # H = STRENGTH * |q| (potential) + p^2/2 (kinetic)
    def H(qcur, pcur): return STRENGTH * np.linalg.norm(q) + np.dot(p, p) / 2
    def dhdp(qcur, pcur): return p
    def dhdq(qcur, pcur): return STRENGTH * 2 * q / np.linalg.norm(q)

    qs = []
    for i in range(n):
        (q, p) = integrator(dhdp, dhdq, q, p, dt)
        qs.append(q.copy())
    return np.asarray(qs)

NITERS = 15
TIMESTEP = 1

plt.rcParams.update({'font.size': 22, 'font.family':'monospace'})
fig, ax = plt.subplots()

planet_leapfrog = planet(leapfroge, NITERS, TIMESTEP)
ax.plot(planet_leapfrog[:, 0], planet_leapfrog[:, 1], label='leapfrog',
        linewidth=3, color='#00ACC1')
planet_euler = planet(euler, NITERS, TIMESTEP)
ax.plot(planet_euler[:, 0], planet_euler[:, 1], label='euler',
        linewidth=3, color='#D81B60')

legend = plt.legend(frameon=False)
ax.set_title("leapfrog v/s euler: NITERS=%s dt=%s" % (NITERS, TIMESTEP))
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
plt.show()
plt.savefig("leapfrog-vs-euler.png")
```

# Small Haskell MCMC implementation

We create a simple monad called `PL` which allows for a single operation: sampling
from a uniform distribution. We then exploit this to implement MCMC using metropolis hastings,
which is used to sample from arbitrary distributions. Bonus is a small library to render sparklines
in the CLI.

For next time:

- Using applicative to speed up computations by exploiting parallelism
- Conditioning of a distribution wrt a variable

### Source code
```hs
{-# LANGUAGE GeneralizedNewtypeDeriving #-}
{-# LANGUAGE GADTs #-}
{-# LANGUAGE StandaloneDeriving #-}
{-# LANGUAGE FlexibleContexts #-}
{-# LANGUAGE FlexibleInstances #-}
{-# LANGUAGE UndecidableInstances #-}
{-# LANGUAGE DeriveFunctor #-}
import System.Random
import Data.List(sort, nub)
import Data.Proxy
import Control.Monad (replicateM)
import qualified Data.Map as M


-- | Loop a monadic computation.
mLoop :: Monad m =>
      (a -> m a) -- ^ loop
      -> Int -- ^ number of times to run
      -> a -- initial value
      -> m a -- final value
mLoop _ 0 a = return a
mLoop f n a = f a >>= mLoop f (n - 1)


-- | Utility library for drawing sparklines

-- | List of characters that represent sparklines
sparkchars :: String
sparkchars = "_▁▂▃▄▅▆▇█"

-- Convert an int to a sparkline character
num2spark :: RealFrac a => a -- ^ Max value
  -> a -- ^ Current value
  -> Char
num2spark maxv curv =
   sparkchars !!
     (floor $ (curv / maxv) * (fromIntegral (length sparkchars - 1)))

series2spark :: RealFrac a => [a] -> String
series2spark vs =
  let maxv = if null vs then 0 else maximum vs
  in map (num2spark maxv) vs

seriesPrintSpark :: RealFrac a => [a] -> IO ()
seriesPrintSpark = putStrLn . series2spark

-- Probabilities
-- ============
type F = Float
-- | probability density
newtype P = P { unP :: Float } deriving(Num)

-- | prob. distributions over space a
newtype D a = D { runD :: a -> P }

uniform :: Int -> D a
uniform n =
  D $ \_ -> P $ 1.0 / (fromIntegral $ n)

(>$<) :: Contravariant f => (b -> a) -> f a  -> f b
(>$<) = cofmap

instance Contravariant D where
  cofmap f (D d) = D (d . f)

-- | Normal distribution with given mean
normalD :: Float ->  D Float
normalD mu = D $ \f -> P $ exp (- ((f-mu)^2))

-- | Distribution that takes on value x^p for 1 <= x <= 2.  Is normalized
polyD :: Float -> D Float
polyD p = D $ \f -> P $ if 1 <= f && f <= 2 then (f ** p) * (p + 1) / (2 ** (p+1) - 1) else 0

class Contravariant f where
  cofmap :: (b -> a) -> f a -> f b

data PL next where
    Ret :: next -> PL next -- ^ return  a value
    Sample01 :: (Float -> PL next) -> PL next -- ^ sample uniformly from a [0, 1) distribution

instance Monad PL where
  return = Ret
  (Ret a) >>= f = f a
  (Sample01 float2plnext) >>= next2next' =
      Sample01 $ \f -> float2plnext f >>= next2next'

instance Applicative PL where
    pure = return
    ff <*> fx = do
        f <- ff
        x <- fx
        return $ f x

instance Functor PL where
    fmap f plx = do
         x <- plx
         return $ f x

-- | operation to sample from [0, 1)
sample01 :: PL Float
sample01 = Sample01 Ret


-- | Run one step of MH on a distribution to obtain a (correlated) sample
mhStep :: (a -> Float) -- ^ function to score sample with, proportional to distribution
  -> (a -> PL a) -- ^ Proposal program
  -> a -- current sample
  -> PL a
mhStep f q a = do
 	a' <- q a
 	let alpha = f a' / f a -- acceptance ratio
 	u <- sample01
 	return $ if u <= alpha then a' else a

-- Typeclass that can provide me with data to run MCMC on it
class MCMC a where
    arbitrary :: a
    uniform2val :: Float -> a

instance MCMC Float where
	arbitrary = 0
	-- map [0, 1) -> (-infty, infty)
	uniform2val v = tan (-pi/2 + pi * v)


{-
-- | Any enumerable object has a way to get me the starting point for MCMC
instance (Bounded a, Enum a) => MCMC a where
     arbitrary = toEnum 0
     uniform2val v = let
        maxf = fromIntegral . fromEnum $ maxBound
        minf = fromIntegral . fromEnum $ minBound
        in toEnum $ floor $ minf + v * (maxf - minf)
-}


-- | Run MH to sample from a distribution
mh :: (a -> Float) -- ^ function to score sample with
 -> (a -> PL a) -- ^ proposal program
 -> a -- ^ current sample
 -> PL a
mh f q a = mLoop (mhStep f q) 100  $ a

-- | Construct a program to sample from an arbitrary distribution using MCMC
mhD :: MCMC a => D a -> PL a
mhD (D d) =
    let
      scorer = (unP . d)
      proposal _ = do
        f <- sample01
        return $ uniform2val f
    in mh scorer proposal arbitrary


-- | Run the probabilistic value to get a sample
sample :: RandomGen g => g -> PL a -> (a, g)
sample g (Ret a) = (a, g)
sample g (Sample01 f2plnext) = let (f, g') = random g in sample g' (f2plnext f)


-- | Sample n values from the distribution
samples :: RandomGen g => Int -> g -> PL a -> ([a], g)
samples 0 g _ = ([], g)
samples n g pl = let (a, g') = sample g pl
                     (as, g'') = samples (n - 1) g' pl
                 in (a:as, g'')

-- | count fraction of times value occurs in list
occurFrac :: (Eq a) => [a] -> a -> Float
occurFrac as a =
    let noccur = length (filter (==a) as)
        n = length as
    in (fromIntegral noccur) / (fromIntegral n)

-- | Produce a distribution from a PL by using the sampler to sample N times
distribution :: (Eq a, Num a, RandomGen g) => Int -> g -> PL a -> (D a, g)
distribution n g pl =
    let (as, g') = samples n g pl in (D (\a -> P (occurFrac as a)), g')


-- | biased coin
coin :: Float -> PL Int -- 1 with prob. p1, 0 with prob. (1 - p1)
coin p1 = do
    Sample01 (\f -> Ret $ if f < p1 then 1 else 0)


-- | Create a histogram from values.
histogram :: Int -- ^ number of buckets
          -> [Float] -- values
          -> [Int]
histogram nbuckets as =
    let
        minv :: Float
        minv = minimum as
        maxv :: Float
        maxv = maximum as
        -- value per bucket
        perbucket :: Float
        perbucket = (maxv - minv) / (fromIntegral nbuckets)
        bucket :: Float -> Int
        bucket v = floor (v / perbucket)
        bucketed :: M.Map Int Int
        bucketed = foldl (\m v -> M.insertWith (+) (bucket v) 1 m) mempty as
     in map snd . M.toList $ bucketed


printSamples :: (Real a, Eq a, Ord a, Show a) => String -> [a] -> IO ()
printSamples s as =  do
    putStrLn $ "***" <> s
    putStrLn $ "   samples: " <> series2spark (map toRational as)

printHistogram :: [Float] -> IO ()
printHistogram samples = putStrLn $ series2spark (map fromIntegral . histogram 10 $  samples)


-- | Given a coin bias, take samples and print bias
printCoin :: Float -> IO ()
printCoin bias = do
    let g = mkStdGen 1
    let (tosses, _) = samples 100 g (coin bias)
    printSamples ("bias: " <> show bias) tosses



-- | Create normal distribution as sum of uniform distributions.
normal :: PL Float
normal =  fromIntegral . sum <$> (replicateM 5 (coin 0.5))


main :: IO ()
main = do
    printCoin 0.01
    printCoin 0.99
    printCoin 0.5
    printCoin 0.7

    putStrLn $ "normal distribution using central limit theorem: "
    let g = mkStdGen 1
    let (nsamples, _) = samples 1000 g normal
    -- printSamples "normal: " nsamples
    printHistogram nsamples


    putStrLn $ "normal distribution using MCMC: "
    let (mcmcsamples, _) = samples 1000 g (mhD $  normalD 0.5)
    printHistogram mcmcsamples

    putStrLn $ "sampling from x^4 with finite support"
    let (mcmcsamples, _) = samples 1000 g (mhD $  polyD 4)
    printHistogram mcmcsamples
```

### Output

```
***bias: 1.0e-2
   samples: ________________________________________█_█________
***bias: 0.99
   samples: ███████████████████████████████████████████████████
***bias: 0.5
   samples: __█____█__███_███_█__█_█___█_█_██___████████__█_███
***bias: 0.7
   samples: __█__█_█__███_█████__███_█_█_█_██_█_████████__█████
normal distribution using central limit theorem:
_▄▇█▄_
normal distribution using MCMC:
__▁▄█▅▂▁___
sampling from x^4 with finite support
▁▁▃▃▃▄▅▆▇█_

```

# The smallest implementation of reverse mode AD (autograd) ever:

```hs
{-# LANGUAGE GeneralizedNewtypeDeriving #-}
import qualified Data.Map.Strict as M

-- | This file can be copy-pasted and will run!

-- | Symbols
type Sym = String
-- | Environments
type E a = M.Map Sym a
-- | Newtype to represent deriative values
type F = Float
newtype Der = Der { under :: F } deriving(Show, Num)

infixl 7 !#
-- | We are indexing the map at a "hash" (Sym)
(!#) :: E a -> Sym -> a
(!#) = (M.!)

-- | A node in the computation graph
data Node =
  Node { name :: Sym -- ^ Name of the node
       , ins :: [Node] -- ^ inputs to the node
       , out :: E F -> F -- ^ output of the node
       , der :: (E F, E (Sym -> Der))
                  -> Sym -> Der -- ^ derivative wrt to a name
       }

-- | @ looks like a "circle", which is a node. So we are indexing the map
-- at a node.
(!@) :: E a -> Node -> a
(!@) e node = e M.! (name node)

-- | Given the current environments of values and derivatives, compute
-- | The new value and derivative for a node.
run_ :: (E F, E (Sym -> Der)) -> Node -> (E F, E (Sym -> Der))
run_ ein (Node name ins out der) =
  let (e', ed') = foldl run_ ein ins -- run all the inputs
      v = out e' -- compute the output
      dv = der (e', ed') -- and the derivative
  in (M.insert name v e', M.insert name dv ed')  -- and insert them

-- | Run the program given a node
run :: E F -> Node -> (E F, E (Sym -> Der))
run e n = run_ (e, mempty) n

-- | Let's build nodes
nconst :: Sym -> F -> Node
nconst n f = Node n [] (\_ -> f) (\_ _ -> 0)

-- | Variable
nvar :: Sym -> Node
nvar n = Node n [] (!# n) (\_ n' -> if n == n' then 1 else 0)

-- | binary operation
nbinop :: (F -> F -> F)  -- ^ output computation from inputs
 -> (F -> Der -> F -> Der -> Der) -- ^ derivative computation from outputs
 -> Sym -- ^ Name
 -> (Node, Node) -- ^ input nodes
 -> Node
nbinop f df n (in1, in2) =
  Node { name = n
       , ins = [in1, in2]
       , out = \e -> f (e !# name in1) (e !# name in2)
       , der = \(e, ed) n' ->
                 let (name1, name2) = (name in1, name in2)
                     (v1, v2) = (e !# name1, e !# name2)
                     (dv1, dv2) = (ed !# name1 $ n', ed !# name2 $ n')
                     in df v1 dv1 v2 dv2
       }

nadd :: Sym -> (Node, Node) -> Node
nadd = nbinop (+) (\v dv v' dv' -> dv + dv')

nmul :: Sym -> (Node, Node) -> Node
nmul = nbinop (*) (\v (Der dv) v' (Der dv') -> Der $ (v*dv') + (v'*dv))

main :: IO ()
main = do
  let x = nvar "x" :: Node
  let y = nvar "y"
  let xsq = nmul "xsq" (x, x)
  let ten = nconst "10" 10
  let xsq_plus_10 = nadd "xsq_plus_10" (xsq, ten)
  let xsq_plus_10_plus_y = nadd "xsq_plus_10_plus_y"  (xsq_plus_10, y)
  let (e, de) = run (M.fromList $ [("x", 2.0), ("y", 3.0)]) xsq_plus_10_plus_y
  putStrLn $ show e
  putStrLn $ show $ de !@ xsq_plus_10_plus_y $ "x"
  putStrLn $ show $ de !@ xsq_plus_10_plus_y $ "y"
```

Yeah, in ~80 lines of code, you can basically build an autograd engine. Isn't
haskell so rad?


# Timings of passes in GHC, and low hanging fruit in the backend:

- One can use `-v3` to get pass timings.
- Apparently, GHC spends a lot of time in the simplifier, and time
  spend in the backend is peanuts in comparison to this.

To quote `AndreasK`:

> - Register allocation, common block elimination, block layout and pretty printing are the "slow" things in the backend as far as I remember.
> - There are also a handful of TODO's in the x86 codegen which still apply. So you can try to grep for these.
> - Strength reduction for division by a constant

- [NCG generates slow loop code](https://gitlab.haskell.org/ghc/ghc/issues/9041)

# Varargs in GHC: `T7160.hs`

A comment from this test case tells us why the function `debugBelch2` exists:

```hs
ghc/testsuite/tests/rts/T7160.hs
-- Don't use debugBelch() directly, because we cannot call varargs functions
-- using the FFI (doing so produces a segfault on 64-bit Linux, for example).
-- See Debug.Trace.traceIO, which also uses debugBelch2.
foreign import ccall "&debugBelch2" fun :: FunPtr (Ptr () -> Ptr () -> IO ())
```

The implementation is:

```c
ghc/libraries/base/cbits/PrelIOUtils.c

void debugBelch2(const char*s, char *t)
{
    debugBelch(s,t);
}
```

```
ghc/rts/RtsMessages.c

RtsMsgFunction *debugMsgFn  = rtsDebugMsgFn;
...

void
debugBelch(const char*s, ...)
{
  va_list ap;
  va_start(ap,s);
  (*debugMsgFn)(s,ap);
  va_end(ap);
}
```
# Debugging debug info in GHC


I wanted to use debug info to help build a better debugging experience
within [`tweag/asterius`](http://github.com/tweag/asterius). So, I was
reading through the sources of `cmm/Debug.hs`.
I'd never considered how to debug debug-info, and I found the information
tucked inside a cute note in GHC (`Note [Debugging DWARF unwinding info]`):

> This makes GDB produce a trace of its internal workings. Having gone this far,
> it's just a tiny step to run GDB in GDB. Make sure you install debugging
> symbols for gdb if you obtain it through a package manager.

- [Link to GHC sources](https://github.com/ghc/ghc/blob/535a26c90f458801aeb1e941a3f541200d171e8f/compiler/cmm/Debug.hs#L458)


# GHC LLVM code generator: Switch to unreachable

The [switch to out of range](https://github.com/ghc/ghc/blob/master/compiler/llvmGen/LlvmCodeGen/CodeGen.hs#L1102)
code generator switches to the first label. It should be more profitable
to switch to a `unreachable` block. That way, LLVM can take advantage of UB.

# Concurrency in Haskell

Great link to the GHC wiki that describes the concurrency primitives
"bottom up": https://gitlab.haskell.org/ghc/ghc/wikis/lightweight-concurrency

# Handy list of differential geometry definitions

There are way too many objects in diffgeo, all of them subtly connected.
Here I catalogue all of the ones I have run across:

##### Manifold

A manifold $M$ of dimension $n$ is a topological space. So, there is a
topological structure $T$ on $M$. There is also an _Atlas_, which is a family
of _Chart_s that satisfy some properties.

##### Chart

A chart is a pair $(O \in  T , cm: O -> \mathbb R^n$. The $O$ is an open set of the
manifold, and $cm$ ("chart for "m") is a continuous mapping from $O$ to $\mathbb R^n$
under the subspace topology for $U$ and the standard topology for $\mathbb R^n$.

#####  Atlas

An _Atlas_ is a collection of _Chart_s such that the charts cover the manifold,
and the charts are pairwise compatible. That is, $A = \{ (U_i, \phi_i) \}$, such
that $\cup{i} U_i = M$, and $\phi_j \circ phi_i^{-1}$ is smooth.

##### Differentiable map

$f: M \to N$ be a mapping from an $m$ dimensional manifold to an $n$ dimensional
manifold. Let $frep = cn \circ f \circ cm^{-1}: \mathbb R^m -> \mathbb R^n$
where $cm: M \to \mathbb R^m$ is a chart for $M$, $cn: N \to \mathbb R^n$
is a chart for $N$. $frep$ is $f$ represented
in local coordinates. If $frep$ is smooth for all choices of $cm, cn$,
then $f$ is a differentiable map from $M$ to $N$.

##### Curve:

Let $I$ be an open interval of $\mathbb R$ which includes the point `0`.  A Curve is a
differentiable map $C: (a, b) \to M$ where $a < 0 < b$.

##### Function: (I hate this term, I prefer something like Valuation):

A differentiable mapping from $M$ to $R$.


##### Directional derivative of a function `f(m): M -> R` with respect to a curve `c(t): I -> M`, denoted as `c[f]`.

Let `g(t) = (f . c)(t) :: I -c-> M -f-> R = I -> R`.
This this is the value `dg/dt(t0) = (d (f . c) / dt) (0)`.

##### Tangent vector at a point `p`:

On a `m` dimensional manifold `M`, a tangent vector at a point `p` is an
equivalence class of curves that have `c(0) = p`, such that `c1(t) ~ c2(t)` iff
:

- For a (all) charts `(O, ch)` such that `c1(0) ∈  O`, `d/dt (ch . c1: R -> R^m) = d/dt (ch . c2: R -> R^m)`.

 That is, they have equal derivatives.

##### Tangent space(`TpM`):

The set of all tangent vectors at a point `p` forms a vector space `TpM`.
We prove this by creating a bijection from every curve to a vector `R^n`.

Let `(U, ch: U -> R)` be a chart around the point `p`, where `p ∈ U ⊆ M`. Now,
the bijection is defined as:

```
forward: (I -> M) -> R^n
forward(c) = d/dt (c . ch)

reverse: R^n -> (I -> M)
reverse(v)(t) = ch^-1 (tv)
```

##### Cotangent space(`TpM*`): dual space of the tangent space / Space of all linear functions from `TpM` to `R`.

- Associated to every function `f`, there is a cotangent vector, colorfully
  called `df`. The definition is `df: TpM -> R`, `df(c: I -> M) = c[f]`. That is,
  given a curve `c`, we take the directional derivative of the function `f`
  along the curve `c`. We need to prove that this is constant for all vectors
  in the equivalence class and blah.

######  Pushforward `push(f): TpM -> TpN`

Given a curve `c: I -> M`, the pushforward
is the curve `f . c : I -> N`. This extends to the equivalence classes
and provides us a way to move curves in `M` to curves in `N`, and thus
gives us a mapping from the tangent spaces.

This satisfies the identity:

```
push(f)(v)[g] === v[g . f]
```

##### Pullback `pull(f): TpN* -> TpM*`

Given a linear functional `wn : TpN -> R`, the pullback is defined as
` wn . push(f) : TpM -> R`.


This satisfies the identity:

```
(pull wn)(v) === wn (push v)
(pull (wn : TpN->R): TpM->R) (v : TpM) : R  = (wn: TpN->R) (push (v: TpM): TpN) : R
```



##### Lie derivation

##### Lie derivation as lie bracket


# Lazy programs have space leaks, Strict programs have time leaks

Stumbled across this idea while reading some posts on a private discourse.
- Continually adding new thunks without forcing them can lead to a space leak,
  aka the dreaded monadic parsing backtracking problem.

- Continually _running_ new thunks can lead to a "time leak", where we spend
  far too much time running things that should not be run in the first place!

This is an interesting perspective that I've never seen articulated before, and
somehow helps make space leaks feel more... palatable? Before, I had no
analogue to a space leak in the strict world, so I saw them as a pathology. But
with this new perspective, I can see that the strict world's version of a space
leak is a time leak.

# Presburger arithmetic can represent the Collatz Conjecture

An observation I had: the function

```
f(x) = x/2      if (x % 2 == 0)
f(x) = 3x + 1   otherwise
```

is a Presburger function, so by building better approximations to the
transitive closure of a presburger function, one could get better answers
to the Collatz conjecture. Unfortunately, ISL (the integer set library) of today
is not great against the formidable foe.

The code:

```cpp
#include <isl/set.h>
#include <isl/version.h>
#include <isl/map.h>
#include <isl/aff.h>
#include <isl/local_space.h>
#include <isl/constraint.h>
#include <isl/space.h>

int main() {
    isl_ctx *ctx = isl_ctx_alloc();
    const char *s = "{ [x] -> [x / 2] : x >= 1 and x % 2 = 0; [x] -> [3 * x + 1] : x % 2 = 1}";

    isl_map *m = isl_map_read_from_str(ctx, s);

    isl_map_dump(m);

    int b = 0;
    isl_map *p = isl_map_transitive_closure(m, &b);
    p = isl_map_coalesce(p);
    printf("exact: %d\n", b);
    printf("map:\n");
    isl_map_dump(p);
    printf("map's range:\n");
    isl_set_dump(isl_set_coalesce(isl_map_range(isl_map_copy(p))));
    // print("map's range intersect 1: %d\n");


}

```

Produces the somewhat disappointing, and yet expected output:

```
$ g++ isl.c -lisl -Lisl-0.20/.libs -o isl -I/usr/local/include/ && ./isl
{ [x] -> [o0] : (2o0 = x and x > 0) or (exists (e0 = floor((1 + x)/2): o0 = 1 + 3x and 2e0 = 1 + x)) }
exact: 0
map:
{ [x] -> [o0] : (o0 < x and o0 > 0) or (exists (e0 = floor((x)/2), e1 = floor((2 + o0)/6), e2, e3, e4 = floor((-x + o0 + e2 - e3)/4): 2e0 = x and 6e1 = 2 + o0 and x >= 2 and 4e4 >= -3 - x + o0 + e2 - e3 and 4e4 >= 4 - x + o0 - 2e2 + 2e3 and 4e4 <= -x + o0 + e2 - e3)) or (exists (e0 = floor((x)/2), e1, e2, e3 = floor((-x + o0 + e1 - e2)/4): 2e0 = -1 + x and o0 > 0 and 4e3 >= -3 - x + o0 + e1 - e2 and 4e3 >= 3 - x + o0 - 2e1 + 2e2 and 4e3 <= -x + o0 + e1 - e2)) or (exists (e0 = floor((x)/2), e1, e2, e3 = floor((-x + o0 + e1 - e2)/4): 2e0 = x and x >= 2 and o0 > 0 and 4e3 >= -3 - x + o0 + e1 - e2 and 4e3 >= 3 - x + o0 - 2e1 + 2e2 and 4e3 <= -x + o0 + e1 - e2)) or (exists (e0 = floor((x)/2), e1 = floor((2 + o0)/6): 2e0 = -1 + x and 6e1 = 2 + o0 and o0 < x)) or (exists (e0 = floor((x)/2), e1 = floor((2 + o0)/6): 2e0 = x and 6e1 = 2 + o0 and x >= 2 and o0 <= -2 + x)) or (exists (e0 = floor((x)/2), e1 = floor((2 + o0)/6), e2, e3, e4 = floor((-x + o0 + e2 - e3)/4): 2e0 = -1 + x and 6e1 = 2 + o0 and 4e4 >= -3 - x + o0 + e2 - e3 and 4e4 >= 3 - x + o0 - 2e2 + 2e3 and 4e4 <= -x + o0 + e2 - e3)) }
map's range:
{ [i0] : i0 > 0 or exists (e0 = floor((2 + i0)/6): 6e0 = 2 + i0) }
```

I've yet to check that the image contains a `1` for every choice of `x`.


# Using compactness to argue about covers

I've always seen compactness be used by _starting_ with a possibly infinite
coverm and then _filtering it_ into a finite subcover. This finite
subcover is then used for finiteness properties (like summing, min, max, etc.).

I recently ran across a use of compactness when one _starts_ with the set
of _all possible subcovers_, and then argues about why a cover cannot be built
from these subcovers if the set is compact. I found it to be a very cool
use of compactness, which I'll record below:

#### Theorem:

If a family of compact, countably infinite sets `S_a` have all
_finite intersections_ non-empty, then the intersection of the family `S_a`
is non-empty.

#### Proof:

Let `S = intersection of S_a`. We know that `S` must be compact since
all the `S_a` are compact, and the intersection of a countably infinite
number of compact sets is compact.

Now, let `S` be empty. Therefore, this means there must be a point `p ∈ P`
such that `p !∈ S_i` for some arbitrary `i`.


#### Cool use of theorem:

We can see that the cantor set is non-empty, since it contains a family
of closed and bounded sets `S1, S2, S3, ...` such that  `S1 ⊇ S2 ⊇ S3 ...`
where each `S_i` is one step of the cantor-ification. We can now see
that the cantor set is non-empty, since:

1. Each finite intersection is non-empty, and will be equal to the set that
   has the highest index in the finite intersection.
2. Each of the sets `Si` are compact since they are closed and bounded subsets of `R`
3. Invoke theorem.


# Japanese Financial Counting system

- [Wikipedia](https://en.wikipedia.org/wiki/Japanese_numerals#Formal_numbers)

Japanese contains a separate kanji set called `daiji`, to prevent people
from adding strokes to stuff previously written.

```
#  |Common |Formal
1  |一     |壱
2  |二     |弐
3  |三     |参
```


# Stephen wolfram's live stream

- [Twitch.tv link](https://www.twitch.tv/videos/408653972)


I've taken to watching the live stream when I have some downtime and want
some interesting content.

The discussions of Wolfram with his group are great, and they bring up
_really_ interesting ideas (like that of cleave being very irregular).

# `Cleave` as a word has some of the most irregular inflections
- cleave
- clove
- cleaved
- clave
- cleft

# McCune's single axiom for group theory

[Single Axioms for Groups and Abelian Groups with Various Operations](http://ftp.mcs.anl.gov/pub/tech_reports/reports/P270.pdf)
provides a single axiom for groups. This can be useful for some ideas I have
for training groups, where we can use this axiom as the loss function!

# `Word2Vec` C code implements gradient descent really weirdly
I'll be posting snippets of the original source code, along with a
link to the Github sources. We are interested in exploring the skip-gram
implementation of Word2Vec, with negative sampling, without hierarchical
softmax. I assume basic familiarity with word embeddings and the skip-gram
model.

#### Construction of the sigmoid lookup table

```cpp
// https://github.com/tmikolov/word2vec/blob/master/word2vec.c#L708

expTable = (real *)malloc((EXP_TABLE_SIZE + 1) * sizeof(real));
for (i = 0; i < EXP_TABLE_SIZE; i++) {
  expTable[i] = exp((i / (real)EXP_TABLE_SIZE * 2 - 1) *
                    MAX_EXP);  // Precompute the exp() table
  expTable[i] =
      expTable[i] / (expTable[i] + 1);  // Precompute f(x) = x / (x + 1)
}
```
Here, the code constructs a lookup table which maps `[0...EXP_TABLE_SIZE-1]`
to `[sigmoid(-MAX_EXP)...sigmoid(MAX_EXP)]`. The index `i` first gets mapped
to `(i / EXP_TABLE_SIZE) * 2 - 1`, which sends `0` to `-1` and `EXP_TABLE_SIZE`
to `1`. This is then rescaled by `MAX_EXP`.

#### Layer initialization

- `syn0` is a global variable, initialized with random weights in the range of
  `[-0.5...0.5]`. It has dimensions `VOCAB x HIDDEN`.  This layer holds the
   hidden representations of word vectors.

```cpp
// https://github.com/imsky/word2vec/blob/master/word2vec.c#L341
a = posix_memalign((void **)&syn0, 128,
               (long long)vocab_size * layer1_size * sizeof(real));
...

// https://github.com/imsky/word2vec/blob/master/word2vec.c#L355
for (a = 0; a < vocab_size; a++)
        for (b = 0; b < layer1_size; b++) {
            next_random = next_random * (unsigned long long)25214903917 + 11;
            syn0[a * layer1_size + b] =
                (((next_random & 0xFFFF) / (real)65536) - 0.5) / layer1_size;
        }
```


- `syn1neg` is a global variable that is zero-initialized. It has dimensions
  `VOCAB x HIDDEN`. This layer also holds hidden representations of word vectors,
  _when they are used as a negative sample_.

```cpp
// https://github.com/imsky/word2vec/blob/master/word2vec.c#L350
a = posix_memalign((void **)&syn1neg, 128,
                   (long long)vocab_size * layer1_size * sizeof(real));
...
for (a = 0; a < vocab_size; a++)
    for (b = 0; b < layer1_size; b++) syn1neg[a * layer1_size + b] = 0;
```

- `neu1e` is a temporary per-thread buffer (Remember that the `word2vec` C code
  use CPU threads for parallelism) which is zero initialized. It has dimensions
  `1 x HIDDEN`.

```cpp
// https://github.com/imsky/word2vec/blob/master/word2vec.c#L370
real *neu1e = (real *)calloc(layer1_size, sizeof(real));
```

#### Backpropogation

Throughout `word2vec`, no 2D arrays are used. Indexing of the form
`arr[word][ix]` is manually written as `arr[word * layer1_size + ix]`. So, I
will call `word * layer1_size` as the "base address", and `ix` as the "offset
of the array index expression henceforth.

Here, `l1` is the base address of the word at the center of window (the focus
word).  `l2` is the base address of either the word that is negative sampled
from the corpus, or the word that is a positive sample from within the context
window.

`label` tells us whether the sample is a positive or a negative sample.
`label = 1` for positive samples, and `label = 0` for negative samples.

```cpp
// zero initialize neu1e
// https://github.com/imsky/word2vec/blob/master/word2vec.c#L419
for (c = 0; c < layer1_size; c++) neu1e[c] = 0;
...
// loop through each negative sample
// https://github.com/imsky/word2vec/blob/master/word2vec.c#L508
if (negative > 0)  for (d = 0; d < negative + 1; d++) {
  ...
  // https://github.com/imsky/word2vec/blob/master/word2vec.c#L521
  // take the dot product: f=  syn0[focus] . syn1neg[context]
  for (c = 0; c < layer1_size; c++) f += syn0[c + l1] * syn1neg[c + l2];

  // compute: g = (label - sigmoid(2f - 1)) * alpha
  // g is computed using lookups into a lookup table and clamping for
  // efficiency.
  if (f > MAX_EXP) g = (label - 1) * alpha;
  else if (f < -MAX_EXP) g = (label - 0) * alpha;
  else
  g = (label - expTable[(int)((f + MAX_EXP) *
                              (EXP_TABLE_SIZE /
                               MAX_EXP / 2))]) * alpha;
  // Now that we have computed the gradient:
  // `g = (label - output) * learningrate`,
  // we need to perform backprop. This is where the code gets weird.

  for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1neg[c + l2];
  for (c = 0; c < layer1_size; c++) syn1neg[c + l2] += g * syn0[c + l1];
  } // end loop through negative samples
// Learn weights input -> hidden
for (c = 0; c < layer1_size; c++) syn0[c + l1] += neu1e[c];
```

- We have _two_ vectors for each word, one called `syn0[l1 + _]` and
  the other `syn1neg[l2 + _]`. The `syn1neg` word embedding is used whenever
  a word is used a negative sample, and is not used anywhere else. Also,
  the `syn1neg` vector is zero initialized, while the `syn0` vectors are
  randomly initialized.

- The values we backprop with `g * syn1neg[l2 + _]`, `g * syn0[l1 + _]` are
  _not_ the correct gradients of the error term! The derivative of a sigmoid
  is `dsigmoid(x)/dx = sigmoid(x) [1 - sigmoid(x)]`. The `[1 - sigmoid(x)]`
  is nowhere to be seen, let alone the fact that we are using
  `sigmoid(2x - 1)` and not regular sigmoid. Very weird.

- We hold the value of `syn0` constant throughout all the negative samples,
  which was not mentioned in any tutorial I've read.

The paper does not mentioned these implementation details, and neither
does _any blog post that I've read_. I don't understand what's going on,
and I plan on updating this section when I understand this better.


# Arthur Whitney: dense code


- Guy who wrote a bunch of APL dialects, write code in an eclectic style
  that has very little whitespace and single letter variable names.
- Believes that this allows him to hold the entire program in his head.
- Seems legit from my limited experience with APL, haskell one-liners.
- [The b programming language](http://kparc.com/b/readme.txt). It's quite
  awesome to read the sources. For example, [`a.c`](http://kparc.com/b/a.c)

- [A history of APL in 50 functions](https://www.jsoftware.com/papers/50/) ---
  A great list of APL snippets that solve classical problems.

# How does one work with arrays in a linear language?

Given an array of qubits `xs: Qubit[]`, I want to switch to little endian.
Due to no-cloning, I can't copy them! I suppose I can use recursion to build
up a new "list". But this is not the efficient array version we know and love
and want.

The code that I want to work but does not:
```csharp
function switchEndian(xs: Qubit[]): Unit {
    for(i in 0..Length(xs) - 1) {
        Qubit q = xs[i]; // boom, this does not work!
        xs[i] = xs[Length(xs) - 1 - i]
        xs[Length(xs) - 1 - i] = q;
    }
}
```

On the other hand, what _does work_ is to setup a quantum circuit that
performs this flipping, since it's a permutation matrix at the end of
the day. But this is very slow, since it needs to simulate the "quantumness"
of the solution, since it takes `2^n` basis vectors for `n` qubits.

However, the usual recursion based solution works:
```csharp
function switchEndian(xs: Qubit[]): Qubit[] {
    if(Length(xs) == 1) {
        return xs;
    } else {
        switchEndian(xs[1..(Length(xs) - 1)] + xs[0]
    }
}
```

This is of course, suboptimal.

I find it interesting that in the linear types world, often the "pure" solution
is _forced_ since mutation very often involves temporaries / copying!

(I'm solving assignments in [qsharp](https://docs.microsoft.com/en-us/quantum/)
for my course in college)

# Linear optimisation is the same as linear feasibility checking
Core building block of effectively using the ellipsoid algorithm.

- If we posess a way to check if a point $p \in P$ where $P$ is a polytope, we
  can use this to solve optimisation problems.
- Given the optimisation problem maximise $c^Tx$ subject to $Ax = b$, we can
  construct a new _non-emptiness_ problem. This allows us to convert optimisation
  into _feasibility_.
- The new problem is $Ax = b, A^Ty = c, c^Tx = b^T y$. Note that by duality,
  a point in this new polyhedra will _be an optimal solution to the above linear program_.
  We are forcing $c^Tx = b^Ty$, which will be the optimal solution, since the
  solution where the primal and dual agree is the optimal solution by strong
  duality.
- This way, we have converted a _linear programming_ problem into a
  _check if this polytope is empty_ problem!

# Quantum computation without complex numbers

I recently learnt that the Toeffili and Hadamard gates are universal for
quantum computation. The description of these gates involve no complex numbers.
So, we can write any quantum circuit in a "complex number free" form. The caveat
is that we may very well have _input qubits_ that require complex numbers.


Even so, a large number (all?) of the basic algorithms shown in Nielsen and
Chaung can be encoded in an entirely complex-number free fashion.

I don't really understand the ramifications of this, since I had the intuition
that the power of quantum computation comes from the ability to express
complex phases along with superposition (tensoring). However, I now have
to remove the power from going from R to C in many cases. This is definitely
something to ponder.

- [Dorit Aharonov: A Simple Proof that Toffoli and Hadamard are Quantum Universal](https://arxiv.org/pdf/quant-ph/0301040)


# Linguistic fun fact: Comparative Illusion

I steal from wikipedia:

> Comparative Illusion, which is a grammatical illusion where certain
> sentences seem grammatically correct when you read them, but upon further
> reflection actually make no sense.

For example: "More people have been to Berlin than I have."


# Long-form posts:
## Reading
- [2018 reading](content/blog/stuff-i-learnt-this-year-2018.md)
- [2017 reading](content/blog/papers-I-read-and-loved-in-2017.md)

## Haskell
- [Reading the `structs` library](content/blog/reading-kmett-structs.md)
- [Reading the `machines` library (TODO)](content/blog/machines/reading-kmett-machines.md)
- [Explaining STG(TODO)](stg-explained.md)

## Simplexhc (STG -> LLVM compiler) progress
- [proc points suck / making GHC an order of magnitude faster](content/blog/ghc-micro-optimisations-or-why-proc-points-suck.md)
- [dec 2017](this-month-in-simplexhc-dec-2017.md)
- [oct 29 2017](this-week-in-simpexhc-oct-29-2017.md)
- [july 2017](this-week-in-simplexhc-07-2017.md)
- [july 6th 2017](this-week-in-simplexhc-2017-07-06.md)
- [announcement](content/blog/announcing-simplexhc.md)

## GSoC (2015)
- [proposal](content/blog/gsoc-vispy.md)
- [week 1](content/blog/gsoc-vispy-week-1-and-2.md)
- [week 3 and 4](content/blog/gsoc-vispy-week-3-and-4.md)
- [week 5](content/blog/gsoc-vispy-week-5.md)
- [week 6](content/blog/gsoc-vispy-week-6.md)
- [week 7](content/blog/gsoc-vispy-week-7.md)
- [final report](content/blog/gsoc-vispy-report-6.md)

# Emacs Cheat Sheet

- `M-,`: go back
- `M-\`: `delete-horizontal-space`. when ranting about how `C-<backspace>` kills too much, just use `M-\` instead!
- `M-q`: `fill-paragraph`: make stuff 80 column, at least in text.  so this is not that bad.
- `C-u C-space`: go back to where you were in the file.
- `C-x r t`: `string-rectangle`. insert new text in a rectangle
     [ergoemacs ascii art](http://ergoemacs.org/emacs/emacs_string-rectangle_ascii-art).  I bind this to `C-x r i` for `insert`.
- `C-x r k`: delete column of text. For `kill`.
- `C-x space`: `rectangle-mark-mode` to select rectangles. `C-space` to lay down mark.
   I bind it to `C-x r r`.
- `C-x tab` (`indent-rigidly`): move the indent of a region left or right with arrow keys.

#### Org
- `C-c C-c`: org-capture into code snippet.
- `C-c C-d`: open org-capture list.
- `C-c C-o`: follow a link.

#### Auctex

- `C-c C-a`: compile file.
- `C-c backtick`: go to error.
- `C-c C-v`: view file.
- `M-x TeX-error-overview`: see all errors
- `C-c C-s`: enter section
- `C-c C-e`: enter environment (stuff in between `\begin{}...\end{}`)
- `M-g n`: goto next error. `M-g p`: goto previous error.

## Magit
- `C-x g`: pop up magit

## LSP mode

```emacs
(define-key lsp-mode-map (kbd "C-c l") lsp-command-map)
```

- `C-c l g r`: goto ref
- `C-c l g g`: goto definition


## Eshell

- `C-c C-r`: go to output.
- `C-u C-c C-r`: narrow to output.
- `cd = ` gives a list to go do.
- Using `C-c =` gives a completion list.

## Dired

- `dired-jump`: open current file in dired.

## Gripes

#### `markdown-mode` lags when I open a paren `[for a link`.

I suppose this is because
it's attempting to match it, and is unable to figure out
what to match to. I now edit markdown in `text-mode`.

#### `ctrl-backspace`/`backward-kill-word` kills far too much.

- [reference `emacs.se`](https://emacs.stackexchange.com/questions/30401/backward-kill-word-kills-too-much-how-to-make-it-more-intelligent)

The answer seems to be:
yes, it kills a word. You can redefine what a word is,
and break lots of other stuff in the process, or redefine
what `ctrl-backspace` does. However, as a non-expert, it's hard
to say what redefining this will mean. Will it still interact
with history the same way?


#### there is no centralized notion of `C-o` (go back to where I came from).

- [reference `emacs.se`](https://emacs.stackexchange.com/questions/9908/can-cursor-jump-back-to-the-previous-position)
- [reference `stackoverflow`](https://stackoverflow.com/questions/4918707/in-emacs-how-to-go-back-to-previous-line-position-after-using-semantic-jump-to)

Instead, it differentiates between "go back in buffer" versus
"go back across buffers".

This is extremely confusing when one is attempting to read
code and understand control-flow: I want a _unified_ way
to say "go forward in my history; OK go back" when I am
exploring code. I don't *want* to keep track of whether
I came to this buffer from the same buffer or another buffer.
The fact that emacs needs this is moronic.

Furthermore, once a mark is popped, it is lost forever. In vim, one can
navigate backwards and forwards across movement. This is not possible with
emacs.

#### Scrolling half a page is broken

- [reference `emacs.se`](https://emacs.stackexchange.com/questions/27698/how-can-i-scroll-a-half-page-on-c-v-and-m-v)
- [reference `emacswiki`](https://www.emacswiki.org/emacs/HalfScrolling)

There is no inbuilt functionality to scroll half a page. The canonical
reference points to this:

```lisp
(autoload 'View-scroll-half-page-forward "view")
(autoload 'View-scroll-half-page-backward "view")
(global-set-key (kbd "C-d") 'View-scroll-half-page-forward)
(global-set-key (kbd "C-u") 'View-scroll-half-page-backward)
```

However, this does not work well. On press `C-u` to go to
the top of the file, it does not move the cursor to the
top completely; once  _the first line is in view_
(with my cursor still on line 30),
emacs obstinately refuses to scroll up with a 'beginning of buffer'
message. I'm sure there's more `elisp` I can write to fix this,
but the fact that something like moving-half-a-page
is rocket science just rubs me the wrong way.

This code that is given in `emacswiki` also
has the exact same issue, I don't understand
how the poster says they come from vim and
did not notice this inconsistency.

```lisp
(defun zz-scroll-half-page (direction)
  "Scrolls half page up if `direction' is non-nil, otherwise will scroll half page down."
  (let ((opos (cdr (nth 6 (posn-at-point)))))
    ;; opos = original position line relative to window
    (move-to-window-line nil)  ;; Move cursor to middle line
    (if direction
	(recenter-top-bottom -1)  ;; Current line becomes last
      (recenter-top-bottom 0))  ;; Current line becomes first
    (move-to-window-line opos)))  ;; Restore cursor/point position

(defun zz-scroll-half-page-down ()
  "Scrolls exactly half page down keeping cursor/point position."
  (interactive)
  (zz-scroll-half-page nil))

(defun zz-scroll-half-page-up ()
  "Scrolls exactly half page up keeping cursor/point position."
  (interactive)
  (zz-scroll-half-page t))


(global-set-key (kbd "C-d") 'zz-scroll-half-page-down)
(global-set-key (kbd "C-u") 'zz-scroll-half-page-up)
```

#### Default encoding is weird: `chinese-iso-8bit`

- [`emacs.se reference`](https://emacs.stackexchange.com/questions/34322/set-default-coding-system-utf-8)

Why in the world is this the option that shows up by default?
There are so many better options, with `utf-8` being the
sanest of them all; this is a nice spherical cow of
the problems with emacs: too much stuff, too like sanity.

The spell is:

```
(set-language-environment "UTF-8")
```

##### linum lags on large files

`global-linum-mode` lags on very long files.

##### emacs lags on long lines

`emacs` lags given very long lines.

[A comment by `eli-zaretskli` on reddit](https://old.reddit.com/r/emacs/comments/9qtpak/what_would_it_take_to_make_emacs_perform_well_on/)
says:

> That is true, but the "fix" part misses the point. There's nothing wrong with
> the current algorithms, they just cannot handle these situations better than
> they already do. The main problem that makes redisplay slow in these cases is
> that, given a cursor motion command, such as `C-n` or `M-v`, the display engine
> needs first to find where in the buffer that command puts point. And that is
> non-trivial when variable-size fonts are supported and variable-size
> characters (or images) can be anywhere on display.


So there's a fundamental problem. He continues:

> ... we are talking about one of the following two
> alternatives: Add new members to the data structures used by the display
> engine, that would allow it to find good approximations for buffer positions
> corresponding to given screen coordinates, then augment the algorithms to
> generate and use this additional data.  edesign the display code to use a
> model that is entirely different from the current simple 2D canvas.


##### emacs' single threading causes pauses on auto-complete/company

##### emacs crashes on attempting to open an SVG file

- [Link to `emacs` bug repo about segfault](http://emacs.1067599.n8.nabble.com/bug-29581-26-0-90-SVG-file-can-cause-emacs-to-crash-imagemagick-td443659.html)

My `emacs --version` says:
```
╰─$ emacs --version
GNU Emacs 26.2
Copyright (C) 2019 Free Software Foundation, Inc.
GNU Emacs comes with ABSOLUTELY NO WARRANTY.
You may redistribute copies of GNU Emacs
under the terms of the GNU General Public License.
For more information about these matters, see the file named COPYING.
```

I ran it with `emacs -q`. The bactrace points at a segfault in `ImageMagick`:

```
Fatal error 11: Segmentation fault
Backtrace:
emacs[0x50fdc9]
emacs[0x4f61f7]
emacs[0x50e77e]
emacs[0x50ea83]
emacs[0x50eac0]
/lib/x86_64-linux-gnu/libpthread.so.0(+0x11390)[0x7f213756b390]
/usr/lib/x86_64-linux-gnu/ImageMagick-6.8.9/modules-Q16/coders/svg.so(+0xb8b8)[0x7f211676e8b8]
/usr/lib/x86_64-linux-gnu/libMagickCore-6.Q16.so.2(ReadImage+0x198)[0x7f213d439a18]
/usr/lib/x86_64-linux-gnu/libMagickWand-6.Q16.so.2(MagickReadImage+0x6a)[0x7f213d90ba3a]
emacs[0x5e65fc]
emacs[0x5eed1d]
emacs[0x5ef1a0]
emacs[0x56cf26]
emacs[0x5a5ff8]
emacs[0x56ce93]
emacs[0x5a5ff8]
emacs[0x56ce93]
emacs[0x5a5ff8]
emacs[0x56ce93]
emacs[0x5a5ff8]
emacs[0x56ce93]
emacs[0x5a5ff8]
emacs[0x56ce93]
emacs[0x5a5ff8]
emacs[0x56ce93]
emacs[0x5a5ff8]
emacs[0x56ce93]
emacs[0x5a5ff8]
emacs[0x56ce93]
emacs[0x5a5ff8]
emacs[0x56ce93]
emacs[0x5a5ff8]
emacs[0x56ce93]
emacs[0x5a5ff8]
emacs[0x56ce93]
emacs[0x5a5ff8]
emacs[0x56ce93]
emacs[0x568c9d]
emacs[0x56cf26]
emacs[0x56eb24]
emacs[0x56904e]
...
[3]    7224 segmentation fault (core dumped)  emacs -q ~/work/IIIT-H-Code/softwarefoundations/project
```

This is tagged as "not a bug" --- because
"if imagemagick crashes, there is no recourse".



# Coq Cheat Sheet

Things in Coq that I keep forgetting, and are hard to lookup.

#### Manually set the value of an existential

```
instantiate
```

#### Rename an expression with an identifier throughout the proof

```
set (ident := expr) in *
```

This is useful to not lose information when `destruct` ing.

# Writing Cheat Sheet

#### Books about charming sentences and how to construct them

#### Active v/s passive vocabulary

- passive vocabulary: Words one knows and can understand from context.
- active vocabulary: Words one uses actively while speaking.

The key to good writing for those who read a lot is to expand their
active vocabulary to match their passive vocabulary.

- A useful exercise is to look for synonyms during speech; This way,
  one forces an enlargening of active vocabulary.

- Moulding one's inner mologoue to reach the ideal 'Voice' might also be
  benificial; However, there is a tendency that speech is not the same as
  writing --- very few people speak as they write. I wish to write like my idol
  (David Foster Wallace), who does speak like he writes. I surmise it's
  worthwhile to mould my inner speech to align with how my writing is supposed
  to be.

#### Punctuation

Should one use punctuation, or shoud not? How much should one use punctuation?
What range of punctuation should one use --- from the common`,` and `.`, all the
way up to `:`, `;`, and `---`.

There appear to be three distinct schools of thought.

- The first school of thought is prescriptive;
  They hold the belief that one must use _as much_ punctuation as is necessary to
  accurately transcribe cadence.

- The second school are the moderates. Too much of
  punctuation can leave writing stilted, or worse, give it an appearance of putting
  on a veneer of respectability. Use as much punctation as is necessary, they say.

- The third school of thought is anarchic and recommend no punctuation at all
  except for `.` as this is a terrific way to get a sense for how to place
  words as one is forced to switch up vocabulary based on the cadence one
  wishes for instead of relying on artificial markers afforded by our system of
  writing.

#### English grammar

- [english club](https://www.englishclub.com/grammar/pronouns-relative.htm)
- [ginger software: grammar rules](https://www.gingersoftware.com/content/grammar-rules/)
- [Literary devices](https://literarydevices.net/)

I couldn't really find a good "grammar book", so I decided
to simply poll friends every time I came across a word that I
didn't know. Assumes knowledge of `noun`, `pronoun`,
`verb`, `adjective`.


#### Pronoun resolution

- cataphora: later reference, anaphora: past reference?

The connection between this and `catamorphism`/`anamorphism`
is something I wish to explore.

- `let ([x 5]) (+ x 3))`: `x` is anaphora resolution.


# Latex Cheat Sheet


#### write text under some equation --- variable under max or argmax

```
y = \underset{x \in X}{\max} f(x)
```

#### Spell check

```
ispell yourfile.tex
aspell --mode=tex -c yourfile.tex
hunspell -l -t -i utf-8 yourfile.tex
```


# Architecture Cheat Sheet

I have an interest in architecture and how it might relate to software.
While the two are quite different, I feel that a deep look at both could
be useful for both discplines. I think my favourite building to date
has been [fallingwater](https://en.wikipedia.org/wiki/Fallingwater). Here are
things on architecture I wish to read and/or have read:

- The way buildings learn.
- The sciences of the artifical.
- The timeless way of building.
- Eisenman
- [Why you hate contemporary architecture](https://www.currentaffairs.org/2017/10/why-you-hate-contemporary-architecture):
  An article that provides points of view and a broad set of link on further
  reading to how architecture reached the 'contemporary', almost
  'uncomfortable' style it has today. Some choice quotes:

> There was a good reason why, historically, religious architecture has been
> the most concerned with beauty for beauty’s sake; the more time is spent
> elegantly decorating a cathedral, the more it serves its intended function of
> celebrating God’s glory, whereas the more time is spent decorating an office
> building, the less money will be left over for the developer.

- The Geography of Nowhere: The Rise and Decline of America's Man-Made Landscape

- This place is not a place of honor... no highly esteemed deed is commemorated
  here... nothing valued is here. Design to ward off people for nuclear waste.

- [When is the revolution in architecture coming](https://www.currentaffairs.org/2021/04/when-is-the-revolution-in-architecture-coming)

> Beauty is kind of “objective” in this sense, in that something either does or
> doesn’t give you pleasure.
- [Antoni Gaudi](https://en.wikipedia.org/wiki/Antoni_Gaud%C3%AD)


- [we forbit what we value most](https://www.strongtowns.org/journal/2017/11/20/we-forbid-what-we-value-most)

# Recipes Cheat Sheet

#### A Simple Stew

- chop onions
- fry Ground nut oil with chopped onions
- add the tomato to the mixture
- allow that to fry for about 5 minutes
-  add the meat water to the mixture
- curry, thyme, maggi (bouillon cubes), salt, peppers
- boil for like 5 minutes
- boil white rice and then serve with stew
- Thanks to Danda for the recipe!


#### Babish recipes

- [Binging with babish: Shwarma makes pita](https://www.youtube.com/watch?v=iErqWGwso7o)
- Chicken breast: https://www.youtube.com/watch?v=hR6agVkRRUo&list=PLopY4n17t8RBuyIohlCY9G8sbyXrdEJls&index=106

#### Upma

- start with ghee, sesame seeds, curry leaves, red + green chili, ginger garlic
  paste, hing (asaefodita).
- finely chopped onion, allow this to caramelize.
- A dash of turmeric for depth.
- Add in the rava, allow it to cook/heat.
- Add in tomato and a little water when it's done heating. Allow tomato to cook.
- Add in more water, cover with a lid, and let it come to a boil. Keep stirring
  to prevent clumps.
- Garnish with coriander.

#### General Coconut based thickening agent


- A few methi seeds (pungent, deep scent)
- some coriander seeds (mild herbal scent)
- Chopped up red chilis (heat, spice, color)
- Chopped up green chilis (spice)
- Chopped up green chilis (spice)
- Chopped up garlic (some; strong, garlicky flavour and scent)

Heat the spices with oil to create a fragrant mix (Tadka[Hindi] / Oggarane[Kannada]).


- Grated coconut
- Salt (to taste)

Finally, throw in the above heated spices into the blender along with the
grated coconut and blend all of it. It turns into a thick red paste.


#### Breadfruit Sambhar


- Heat up oil.
- Fry **sesame seeds, cumin seeds, curry leaves, a tiny cinnamon stick** first.
- Once fried, add in **garlic** to taste.
- After garlic has fried as well, saute **onions** till golden.
- Finely chop **tomatoes** and add it to the sauteed onions. Cover with a lid
- till the tomatoes release all their water.
- Now that we have a solid flavour base, pour in water to cook the breadfruit.
- Add in the **chopped breadfruit** --- chop the breadfruit in thin slices
- along the center; the center has interesting texture we wish to maximize.
- Add in the **[General coconut based thickening agent](#general-coconut-based-thickening-agent)**.
- Also add salt to taste.
- Cover with a lid. Allow breadfruit, water, and thickening agent to come to a boil.
- Lower flame to low. Allow breadfruit to soften and cook.
- Once breadfruit is cooked, pour in **coconut milk**. Continue cooking for
  ten minutes.

#### Rava Dosa
- Mix bombay rava, maida/refined flour(2 tablespoons), rice flour (2 tablespoons),
  curd/buttermilk(100ml), salt (2 tablespoon), water (2 cups). Mix to form wet batter.
- We add the bombay rava for softness, refined flour as glue, and rice flour for
  crispiness. Curd for sourness and thickening.
- Next, heat up some oil, fry sesame seeds, finely chopped onions, curry leaves,
  asaefoedita, garlic. Add all of this into the batter mix.
- Allow batter to ferment overnight in the fridge.
- Make pancakes the next day.

#### Kerela style chicken curry

- Chop ginger and garlic roughly, boil chicken, salt, pepper-ginger-garlic-turmeric.
- Grate coconut finely, Roast grated coconut in a heated iron pan. Once well roasted,
  kill heat, add chili and coriander powder and salt, and mix.
- Next, fry thinly sliced onions in coconut oil.
- Add the onions in as a garnish at the last step.

#### Chutney

- Green chili
- Dried Coconut  pieces
- Salt
- Blend
- Add tamarind and water
- Blend

#### Regular dosa batter:

- Grind coconut pieces
- Add dosa rice (2 cups)
- Add some water (100ml)
- Blend
- Salt
- Add more water (300ml).

# History Cheat Sheet

##### Crusades were a thing of the past by the time of the fall of Constatinople. (1453)

So the historian (Dr. Mario Philippedes) says on netflix's
rise of the empires:the Ottoman empire.
The crusades were roughly from 1000 to 1200.

##### undermine

Comes from miners digging under the walls. Learnt this from
'Rise of Empires: Ottoman'.

> The mining under the tunnel for the offensive (the Ottomans) was by serbian
> silver miners.  John Grant is the engineer during the siege of constantinople
> for the defense of the Byzantines/romans. He put barrels of water, and looked
> at the water ripples to figure out where the digging was going on. To quote:
> In pretty much all of history you will find a random British person, perhaps
> Scotsman involved in a war


##### decephalized

> We need to clone decephalized humans and livestock.  With thousands of
> brainless bodies kept alive on life support, you have test subjects for a
> limitless number of experiments that would have never been possible before.
> You also create a never-ending O negative blood supply and organ harvesting
> program.  It the case of decephalized animals, you also get cruelty free
> meat. And that's how you bootstrap the program and port it to the human
> model.

##### demagoguery

The ancient Greeks had a word for our modern systems “demagoguery” which
equates to charismatic liars manipulating gullible people to vote against their
own good

##### laconic

Named after the spartans.

# Words Cheat Sheet

Contains words that I write, and ones that I enjoy.

##### Recondite

little known; abstruse

##### Mendicant

Given to begging

##### gesamtkunstwerk

A Gesamtkunstwerk (German: [gəˈzamtˌkʊnstvɛʁk], literally "total artwork",
frequently translated as "total work of art", "ideal work of art",
"universal artwork", "synthesis of the arts", "comprehensive artwork", or
"all-embracing art form") is a work of art that makes use of all or many art
forms or strives to do so. The term is a German loanword which has come to be
accepted in English as a core term in aesthetics.



##### anodyne

not likely to cause offence or disagreement and somewhat dull.
> "anodyne music"

#### syncretism

I ran into the word in the description of the electronic artist 'Jaenga'.

> human technological syncretism ...


**Meaning:** the amalgamation or attempted amalgamation of different religions,
cultures, or schools of thought.

#### absurd

The word “absurd” has a number of standard connotations: outlandish, crazy,
amazing, freakish. It comes from the Latin absurdum, meaning “out of tune,”
extraordinary. This, however, is not the way that Albert Camus meant the term
when he coined l’absurd as a philosophical concept in 1942. To Camus, the
absurd was strangely normal, a state of affairs that describes the human
condition—in a nutshell, the utter dissonance between the human quest for
meaning in life and the silent indifference of the universe

#### opprobrium

> public disgrace arising from shameful conduct.
> "the opprobrium of being closely associated with gangsters"

##### Pyretology

study of fevers

##### Soubrette

an actress or other female performer playing a lively, flirtatious role in a play or opera.


##### fiat

> fiat lux.

Let there be light

##### eudaimonia

happiness as a result of fulfilling one's purpose (eudaimonia)


##### ubac/adret

> ubac "shady side of a mountain" and adret "sunny side of a mountain" (which
> are of French origin). Used to translate yin/yang.

##### Metier

> a profession or occupation.
> "the boy must begin to learn his métier as heir to the throne"


##### Livery

> a special uniform worn by a servant, an official, or a member of a City Company.
> "yeomen of the guard wearing a royal red and gold livery"


##### intransigence

> refusal to change one's views or to agree about something.
> Example: The underlying reason for the prolongation of the war is intransigence on all sides.
> Example from Downton Abbey: the aristocracy did not progress by their intransigence.


##### pip
> Pips are small but easily countable items, such as the dots on dominoes and
> dice, or the symbols on a playing card that denote its suit and value.
> Pip cards are the cards from 2..10 in a deck.


##### pusillanimity

> lack of courage or determination; timidity.
> "the pusillanimity of his answer surprised me"


##### Askefise

> one who blows on ashes to bring them to flame


# Clojure Sheat Sheet

### Neovim/Conjure/Coc-Conjure

```
Plug 'neoclide/coc.nvim', {'branch': 'release'}
Plug 'Olical/conjure'
let g:coc_global_extensions = ['coc-conjure']
let maplocalleader = ","
let g:conjure#mapping#eval_current_form = "er"
let g:conjure#mapping#eval_root_form = "ee"
let g:conjure#mapping#def_word = "d"
let g:conjure#mapping#eval_visual = "E"
let g:conjure#mapping#eval_motion = "E"
```

- evaluate OUTERMOST at point `<localleader>ee` [I find this very useful]
- evaluate INNERMOST at point `<localleader>er` [I find this not so useful]
- evaluate WORD at point: `<localleader>ew`
- lookup documentation: `<localleader>K`
- goto definition: `<localleader>d`
- evaluate selection in visual mode `<localleader>E`
- split vertical:  `<localleader> lv`
- auto complete `C-x C-o`
- I fucking love `parinfer`.
- [tutorial](https://oli.me.uk/getting-started-with-clojure-neovim-and-conjure-in-minutes/)
- On using multi-methods, make sure to refresh!

### Emacs/CIDER

- [Cheat sheet](https://github.com/mlakewood/cider-cheatsheet/blob/master/cheat.md)
- Switch between REPL and file: `C-c C-z`
- Go to previous location: `M-,`
- Go back inside file: `C-u C-SPC`
- Go back across files: `C-x C-SPC`
- Switch to REPL: `C-c C-z`
- Eval buffer: `C-c C-k`
- Docs: `C-c C-d C-d`
- Goto symbol: `M.`
- Eval last sexp: `C-c C-e` / `C-x C-e`
- eval last definition: `C-c C-c`

# Big list of quotes

> The advantages of implicit definition over construction are
> roughly those of theft over honest toil.

> "If you think experts are expensive, wait and see what amateurs will cost you."

> “You cannot go on 'seeing through' things for ever.
> The whole point of seeing through something is to see something through it. 
> It is good that the window should be transparent, because the street or garden beyond it is opaque. 
> How if you saw through the garden too? It is no use trying to 'see through' first principles. 
> If you see through everything, then everything is transparent. 
> But a wholly transparent world is an invisible world. 
> To 'see through' all things is the same as not to see.”

> A simple theory of aesthetics:
> If the best stuff from then is still better than good stuff from now, it's art
> If the best stuff from then is worse than bad stuff from now, it's technology

- Tradition is not the worship of ashes, but the preservation of fire.

- For every problem, there is a solution that is simple, elegant, and wrong.

> If it's worth doing, it's worth overdoing.

> We treated science like it’s a weak-link problem where progress depends on
> the quality of our worst work. But science is a strong-link problem: progress
> depends on the quality of our best work.

> Pirates of the caribbean: Take what you can, give nothing back.

- A simulation of a hurricane is not a real hurricane, but a simulation of a chess game *is* a real chess game.

- When leaving a party, Brahms is reported to have said ‘If there is anyone
  here whom I have not offended tonight, I beg their pardon.

- Pirates of the caribbean: Take what you can, give nothing back.

> How can Alice communicate all of math to Bob? Mail him some chalk and wait!

> Love is not a craving, love is a yearning. ~ Contrapoints.

> If Alice uses abstract algebra to solve problem and Bob uses concrete calculation, Alice's result is more generalizable than Bob's,
> while Bob's method is more generalizable than Alice's.
> This is one reason why combining the two approaches is so valuable.
> You can start with something you know will work but may not unlock a great mystery, and then look for patterns that clue you in to a wider story.

> "There are two kinds of scientific progress:
> the methodical experimentation and categorization which gradually extend the boundaries of knowledge,
> and the revolutionary leap of genius which redefines and transcends those boundaries.
> Acknowledging our debt to the former, we yearn nonetheless for the latter"


> you can be dead right. (Being right has a time and a place)

> Bott also used to say that a cocyle was "something that hovers over a space
> and when it sees a cycle, pounces on it and spits out a number".

> I'm not complaining here, quite the opposite: this story is really quite
> exciting and the work mentioned is both real and fascinating. We are
> essentially back to the days when Newton tried to explain the nature of
> gravity looking at Kepler's laws trying various options and separating what
> works from what doesn't. I'm only saying that the famous "physicists'
> intuition", which is so overrated, is actually just the benevolence of
> Nature. Why should the Nature be so benevolent to us remains a mystery and I
> know neither a physicist, nor a mathematician, who could shed any light on
> that. The best explanation so far is contained in Einstein's words "God is
> subtle, but not malicious", or, in a slightly less enigmatic form, "Nature
> conceals her mystery by means of her essential grandeur, not by her cunning".



> Whoever is meek to the cruel ones, is cruel to the meek.

> Treat everybody the same v/s treat everybody fairly.

> "Everyone must choose one of two pains: The pain of discipline or the pain of regret.”

> “We have two lives, and the second begins when we realize we only have one.”
> -- Confucius



>  "Think of yourself as dead. You have lived your life. Now, take what's left
>  and live it properly." - Marcus Aurelius


> It is only when a mosquito sits on your testicles do you learn that some
> problems must be solved without violence.

> The threat is greater than the execution. ~ GM Danya

> No guest should be admitted without a date of departure ~ Violet, Downton Abbey

> Not knowing things isn't dumb; pretending to know is.

> magic is when you have expended more effort to achieve a trick than
> observers think is reasonable. That you've spent hundreds of hours practising
> with decks of cards, that you've built a secret passageway across your stage,
> that you've erected an enormous mirror in a public place, etc..


> Knuth says something similar (on his web page I think). He says he doesn't
> read email because email is good for people who want to stay on top of things
> but he wants to get to the bottom of things.

> "In the past everything was better, even the future" (K. Valentin, translated)


> You never rise to the occasion, you sink to the level of your training.

> "the mark of an enlightened mind is the ability to entertain ideas without
> accepting them"

> The most intelligent creature in the universe is a rock.
> None would know it because they have lousy I/O.


> Now symmetry and consistency are convertible terms - thus Poetry
> and Truth are one ~ Noether's theorem?

> Science is a differential equation. Religion is a boundary condition.
>(Alan Turing, quoted in J.D. Barrow, “Theories of everything”)

> (I really detest the use of the word "training" in relation to professional
> activities. Training is what you do to dogs. What you should be doing with
> people is educating them, not training them. There is a big, big difference.)
> ~ Ron Garret at JPL

> “Simulated consciousness" was as oxymoronic as "simulated addition.”


> A cylinder will roll like a sphere in one direction but not roll like a cube
> in the other. That doesn't make it a sphere and a cube at the same time. It
> makes it something different. (in analogy to wave-particle duality)


> Talent hits a target no one else can hit; Genius hits a target no one else
> can see..

> Raising your floor (consistency) is just as important as raising your ceiling
> (skill)

> "The sky is the limit, so lets build rockets!"


> The manner in which the mathematician works his way towards discovery by
> shifting his confidence from intuition to computation and back again from
> computation to intuition, while never releasing his hold on either of the
> two, represents in miniature the whole range of operations by which
> articulation disciplines and expands the reasoning powers of man. (Personal
> Knowledge, 131)

> Everyone knows that putting a untrained business major in charge of a
> squadron of soldiers would end badly. He might be able skate by until they
> got into combat, maybe, but after that they wouldn’t listen to him for long.
> But for some reason we think that putting an mba in charge of an engineering
> team is a good idea.

> "On and on you will go, making sense of the world, forming notions of order,
> and being surprised in ways large and small by their failure, forever." —
> Albert Burneko on Wile E. Coyote.

> "There is a special providence that protects idiots, drunkards, children, and
> the United States of America." ~ Otto van bismarck

> "Never believe anything in politics until it has been officially denied"
> ~ Otto von Bismarck


> A good proof is one that makes us wiser. -- Yuri Manin


> Keep things in their Gauss given order. -- Gilbert Strang


> It is interesting to see where people insist proximity to a subject makes one
> informed, and where they insist it makes them biased. It is interesting that
> they think it’s their call to make. [in the context of 'as a male, you don't
> get a say about toxic masculinity' v/s other 'viewpoints']
> ~ [medium article link](https://medium.com/@jencoates/i-am-a-transwoman-i-am-in-the-closet-i-am-not-coming-out-4c2dd1907e42)


> "Feeding two birds with one scone"
> Peta recommended version of "killing two birds with one stone"


> the first sign of civilization in an ancient culture was a femur
> that had been broken and then healed ~ Margaret Mead

> The mistake of many adults is confusing serious with solemn.

> I hate greek drama. You know, where everything happens off-stage.
> ~Downton abbey, s02e01

> you have to speculate to accumulate

> It's so reassuring to see the future unfurl, as long as you remember
> that it bears no resemblance to the past.

> Sybil, vulgarity is no substitute for wit. ~  Violet, Downton Abbey

> "Why dwell on that now?" "Because I want to feel the pleasure of telling you I
> told you so".


> The law, in its majestic equality, forbids rich and poor alike to sleep under
> bridges, to beg in the streets, and to steal loaves of bread.”


> 'The history of transistors is the history of solving Schrödinger's equation in various materials.' -- Leon Lederman

> tradition that contested poems would be thrown into a pool. The better poems
> would float. Now you know why you shouldn't write dense prose. ~ History of india podcast

> children cried with hunger. Women plaited their braids without flowers. ~ History of india podcast.

> "There is a spooky quality about the ability of mathematicians to get there
> ahead of physicists. It's as if when Neil Armstrong first landed on the moon
> he found in the lunar dust the footsteps of Jules Verne" - Steven Weinberg on
> old math being applied in physics

> You can try; trying is the first step of failure ~ GM Ben finegold on mating sequences.

> Some folks prefer the carrot, I the stick. So I will use my considerable
> expertise to stick it to you.

> "Machine learning is like money laundering for bias"

> Criticism is prejudice made plausible.” - H.L. Mencken

> David Marquet's credos from "Turn The Ship Around!". Don't ask "Are we
> ready?"; instead, ask "How ready are we?".  Everything needs to be phrased so
> as to invite people to express the knowledge they have, rather than demanding
> what amounts to a declaration of
> tribal identity.

> You can't just go around recognizing what people don't understand. That's
> what got Socrates killed. You've gotta make them understand what they don't
> understand without making them want to kill you. That's what makes a great
> teacher / leader / etc.

> 'Every work of art is an uncommitted crime.' - Adorno.


> Policies are nice but at the end of the day we need folks to set an example
> (rather than being made an example of)


> “The math students dropped out because they could not understand anything. Of
> course, I didn’t understand anything either, but non-math students have a
> different standard of what it means to understand something,” Huh said. “I
> did understand some of the simple examples he showed in classes, and that was
> good enough for me.”
> https://www.quantamagazine.org/a-path-less-taken-to-the-peak-of-the-math-world-20170627/

> "you're such a dick!".
> "I'm moby goddamn dick, and you're swimming in my water".

> When people thought the earth was flat, they were wrong. When people thought
> the earth was spherical, they were wrong. But if you think that thinking the
> earth is spherical is just as wrong as thinking the earth is flat, then your
> view is wronger than both of them put together.


> "Ethereum has said they're moving from Proof of Work to Stake; I'm not
> surprised, given the Ethereum developers seem to abhor Work in all of its
> forms, including making progress on Ethereum itself"


> The man is nothing, the work is everything. ~ Napoleon
> L’homme c’est rien–l’oeuvre c’est tout


# Empathy

> Oof, I don't really know what to say right now but I'm glad you told me

- [Brene brown on empathy](https://www.youtube.com/watch?v=1Evwgu369Jw)
- [It's not about the nail](https://www.youtube.com/watch?v=-4EDhdAHrOg)



# Vim Cheat Sheet

### Using `:grep` and friends

```
:grep <grep-invocation>
```

- This will populate the error window.
- Open the error window with `:copen`.
- Thanks to `vim-unimpaired`, going next/previous is as easy as `[q` and `]q`
  (`q` for `quickfix`).
- To open quickfix ist, use `:copen`. To close, use `:cclose`. To go next/prev, it's `:cn` and `:cp`.
- Can create stupid mapping: `nnoremap / :grep   %<Left><Left><Left>`, which switches `/` based search
  to always become `grep` based search.

##### sed matching syntax


- `\<word\>`: match word starting and ending.

##### vim motion mnemonics

- f<char> - (f)ind a character forward in a line and move to it
- T<char> - find a character backward in a line and move un(t)il it
- t<char> - find a character forward in a line and move un(t)il it (one character before)
- F<char> - (f)ind a character backward in a line and move to it


##### vim unimpaired for loclist movement


- `]q` /`[q`: move loclist.

##### vim-ninja-feet for motions using text objects

With it installed, add [ or ] between the operator and text object to specify
which end you wish edit: press c]i} to perform the edit you describe.

-`a)`: a parentheses block
-`i)`: inner parentheses block
-`a]`: a bracketed block
-`i]`: inner bracketed block
-`a}`: a brace block
-`i}`: inner brace block


# Big list of Chess

- On Lichess, goto `sound -> speech` to be able to HEAR moves! Similarly,
  enable notation everywhere in preferences to get used to reading moves in
  notation.

- [How to defend `e5` in king's indian defense](https://www.youtube.com/watch?v=jAwSBrLk3Uw)
- [King and pawn versus king](https://www.youtube.com/watch?v=OzskUgwPCEg&list=PLVWaFpMwtaGiBxi79IUqnqn67WF5g5PR4&index=27)
- [All about forks](https://www.youtube.com/watch?v=51vnCWXXLGc&list=PLVWaFpMwtaGiBxi79IUqnqn67WF5g5PR4&index=49)

- Good linux app: `scid vs pc`. Seems to contain engines .
- Keep king on a *diagonal* 2 squares away from the knight to ensure safety.
- Pro tip for king+queen checkmate : always keep the queen at a position as if u r trying to give a check with a knight.
- knight+bishop: Bishop B7, King to B8. Knight to D7, and that's checkmate

# Big list of shitposting

> ~ Siddharth, you said you're wired that way and thus can't believe in religion.
> So you can't change yourself, thus you're pure.
> Therefore, all you need is a [monad](https://en.wikipedia.org/wiki/Monad_(philosophy))
> to change the immutable into the mutable --- Thus, embrace the Leibniz.

# Big list of Breakdance

##### Week 1 moves

- hustle step
- [Indian step](https://www.youtube.com/watch?v=enFnW4LWYw4)
- [kick out]()
- [C-C](https://www.youtube.com/watch?v=QgQ75yoQ0QA)
- [Breaking made simple](https://www.youtube.com/watch?v=8kmU3XFcnUY)



# Big list of Cardistry

## Current Practice

- [Snap Change](https://www.youtube.com/watch?v=zhoafsPWaQo&list=PLNZrOW6NuocraONXJjyPrDcGnHJt5dUJV&index=4)

## Current Polish

- [Spring cards to show off](https://www.youtube.com/watch?v=avoKr-mvfzI).
- Shuffle with charlier cut.
- peel top card off with [angel](https://www.youtube.com/watch?v=fRH4MyB4RVs) to display card, put card back.
- [Overhand shuffle control](https://www.youtube.com/watch?v=VkE8fNFBUw8) to shuffle
  (Learn [Hindu Shffle: control](https://www.youtube.com/watch?v=P_C1clIaOX4) eventually).
- Peel top card off with the [Chinese deal](https://www.youtube.com/watch?v=kppssPG7etM)
- Show that it's the same card!
- Put card back with [flirt flourish](https://www.youtube.com/watch?v=tFb7gCgsqcQ)

## Future

##### [Bow to Stern: Single card sticking out: Chris Ramsay](https://www.youtube.com/watch?v=NCUfHRvCJj0)
- Something called the "plunger principle"?

##### [Tenkai palm](https://www.youtube.com/watch?v=sMLOjQTaKtg): pluck card out of air.

##### [Bertram change card color change](https://www.youtube.com/watch?v=omcbLkcQkBk)
- convincer: one card is two
- Tenkai palm is a prereq.



##### Flirt Flourish
- [Flourish: Flirt](https://www.youtube.com/watch?v=tFb7gCgsqcQ)
- hold top card between index and middle finger, flip middle and index, then land card back on top of packet.
- Can be used to switch top two cards, by peeling the top card with your pinky and putting the top card in.

##### [3pac flourish](https://www.youtube.com/watch?v=AgsIfxtVjkk)



#### Card Spring

- The key insight is to bend the deck such that there is no gap between the deck and the
  palm of our hand. This will provide enough force on the cards to allow them to be sprung forth.

#### Next

- [Chris Ramsay: collection of all tutorials](https://www.youtube.com/watch?v=vM1_u-A4zgk&list=PLNZrOW6NuocraONXJjyPrDcGnHJt5dUJV)
- [Push off second deal](https://www.youtube.com/watch?v=i5JlED3erBY)
- [Bow to Stern: Show card being put in the middle that ends up at the top](https://www.youtube.com/watch?v=NCUfHRvCJj0)
- [False riffle shuffle by 52kards](https://www.youtube.com/watch?v=sLIS4c2dUwc)
- [Straddle pass control by Champion Magic](https://www.youtube.com/watch?v=Hp-lpNJAo5Q)
- [Card control chris ramsay](https://www.youtube.com/watch?v=NCUfHRvCJj0)
- [Riffle shuffle from 52kards](https://www.youtube.com/watch?v=uW8zMwJF5ys)
- [Sybil](https://www.youtube.com/watch?v=s6F3Em7McOs&list=PLIYzPFCPrDTDGSbF0Epp7_ZGCCSsUVM1d&index=20)
- [Basic passes: control top card, prereq for color change](https://www.youtube.com/watch?v=yM-m6j2WuL4)
- [Bertram color change](https://www.youtube.com/watch?v=omcbLkcQkBk)
- [Tenkai palm](https://www.youtube.com/watch?v=fsy1FA2n1RY)
- [Ekatarina list of tutorials](https://www.youtube.com/watch?v=XGCCqdr6r08&list=PLUCOIt3_dATNX4A4W4pBMr7MERO64-aBL)
- [Hot shot sandwhich: magic trick](https://www.youtube.com/watch?v=RJjzc1w7u5I)
- [Chris Ramsay list of tutorials](https://www.youtube.com/watch?v=vM1_u-A4zgk&list=PLNZrOW6NuocraONXJjyPrDcGnHJt5dUJV)

#### Hiatus (too difficult for now)

- [Lepaul spread](https://www.youtube.com/watch?v=0s6beNSX-L0)
- [Hot shot](https://www.youtube.com/watch?v=ZmXMgJGtgts)

#### Learnt

- [How to get started?](https://www.youtube.com/watch?v=g8mbn7TLATA)
   1. Basic grips (School of Cardistrys youtube channel and start from their first video "grips) 2. Cuts 3. Flourishes

- [Basics: grips](https://www.youtube.com/watch?v=bt0RumRuwGQ)

1.  Dealer's  / Mechanic's grip (thumb left, index top, others right)
2. Straddle Grip (pinky bottom, index top, thumb left, others right)
3. Biddle Grip
4. End Grip (two index fingers opposing each other)
5. "Z" Grip


- Basics: Thumb Fan: key ingredients are (a) hold the palming hand straight so
  fingers don't intervene, (b) thumb grip should be strong to allow index finger
  to go wild, (c) pull with the index finger in a semicircular arc.
  I practiced this for two weeks till it suddenly snapped into place.

- [Overhand Shuffle](https://www.youtube.com/watch?v=0_aY0jC8DY4)
- [Overhand Shuffle: controlling the top card](https://www.youtube.com/watch?v=VkE8fNFBUw8)
- [Basic Cardistry: Charlier Cut](https://www.youtube.com/watch?v=BNC_DD9XccI&list=PLIYzPFCPrDTDGSbF0Epp7_ZGCCSsUVM1d&index=2):
  Cut, pick it up, slide, hold. Dealer's grip little finger is useful to keep the non-picked-up part of deck from sliding!
- Basic Cardistry: Thumb cut
- [Chinese deal](https://www.youtube.com/watch?v=FYGY-Z2qQVY)
- [Overhand Shuffle control](https://www.youtube.com/watch?v=P_C1clIaOX4)
- [Basic Cardistry: Revolution Cut](https://www.youtube.com/watch?v=4modjrvBopw)

#### Card control

#### Long term
- [Cardistry bootcamp](https://www.youtube.com/watch?v=bt0RumRuwGQ&list=PLIYzPFCPrDTDGSbF0Epp7_ZGCCSsUVM1d)
- [Basics: Scissor cut](https://www.youtube.com/watch?v=z9YkyM0hG3M)
- Basics: Swing Cut
- Basics: Card spring
- Basics: Pressure Fan
- Basics: Faro Shuffle
- Basics: Sybil Cut
- Basics: Werm
- Basics: Hot Shot Cut

#### Resources

- [Cardistry forum at theory11](https://www.theory11.com/forums/cat/general-discussion/)
- [Deceptionary: card stacks](https://www.deceptionary.com/aboutstacks.html)

> Eight kings threatened to save,
> nine fine ladies for one sick knave. 8–K–3–10–2–7–9–5–Q–4–A–6–J)

- [Deceptionary: suit order](https://www.deceptionary.com/aboutsuits.html)

- [Kruskal card trick](http://www.ams.org/publicoutreach/feature-column/fcarc-mulcahy6)

- [Big list of card mnemonics on wikipedia](https://en.wikipedia.org/wiki/List_of_playing-card_nicknames)

# Poems to memorize
- [Ode on the Death of the Duke of Wellington](https://www.bartleby.com/246/385.html)


# X86 Cheat Sheet

##### Mnemonical for CCall

```
%rdi:   Diane's
%rsi:   Silk
%rdx:   dress
%rcx:   costs
%r8:    $8
%r9:    9
```

##### Mnemonic for syscall calling convention

```
* rax  system call number  - All (system, can make universal quantification!)
* rdi  arg0 - Diane's
* rsi  arg1 - Silk
* rdx  arg2 - Dress
* r10  arg3 (uses r10 instead of rcx)
* r8   arg4 - 8$
* r9   arg5 - 9
```



# Common Lisp Cheat Sheet

- [Peter Norvig's common lisp guide](https://www.cs.umd.edu/~nau/cmsc421/norvig-lisp-style.pdf)
- To make a runnable file, add `;; #!/usr/bin/env sbcl --script` to the top.
- To change package, use ", set package"
- Good starting kit:

```lisp
;; to change package, goto SLIME, type `,` for `, set package`.
(declaim (optimize (speed 0) (safety 3) (debug 3)))
(defpackage :rasterizer1 (:use :common-lisp))
```

- [Paredit cheat sheet](https://www.emacswiki.org/emacs/PareditCheatsheet)
- [SLIME tutorial](https://www.youtube.com/watch?v=_B_4vhsmRRI)
- First thing to do: `slime-sync-package-and-default-directory` (`C-c ~`) to setup package and `cwd`.
- SLIME + parinfer + SBCL is quite a pleasant emacs lisp experience.
- LISPY-mode interface: eval expr (`e`), jump to definition (`F`), go back (`D`)
- SLIME debugger: abort(`a`), continue(`c`), quit(`q`),  goto frame source (`v`), toggle frame details (`t`),
  navigate next/prev frame(`n`, `p`), begin/end (`<`,`>`),
  inspect condition (`c`), interactive evaluate at frame (`:`)
- SLIME REPL: send expr to repl(`C-c C-y`), switch to repl (`C-c C-z`), eval last expr (`C-x C-e`), trace (`C-c C-t`)
- SMILE REPL debug: trace (`C-c C-t`). Write `(break)` in code and then run expression to enter debugger,
  step into (`s`), step over (`x`), step till return (`o`), restart frame (`r`), return from frame (`R`),
  eval in frame (`e`)
- SLIME compile: compile whole file (`C-c C-k`), eval defun (`C-c C-c`), trace (`C-c C-t`).
- SIME docs: lookup on hyperref (`C-c C-d h`)
- SLIME goto: edit definition (`M-.`), come back (`M-,`). Find all references (`M-?`)
- TODO: consider [Sly](https://github.com/joaotavora/sly) rather than SLIME?
- SLIME repl options: set current working directory (`,!d`), set package
  (`,push-package <package-name>`). Alternatively, execute `(swank:set-default-directory "/path/to/desired/cwd/")`
- SLIME Restart: [`M-x slime-restart-inferior-lisp`](https://stackoverflow.com/questions/3725595/reset-state-in-common-lisp),
    or call [`(progn (unload-feature 'your-lib) (load-library "your-lib"))`](https://emacs.stackexchange.com/a/26606/28600)
- [SLIME force re-evaluation of `defvar`, use `M-x slime-eval-defun` (`C-M-x`)](https://emacs.stackexchange.com/questions/2298/how-do-i-force-re-evaluation-of-a-defvar).
- [Serepeum library for exhaustiveness checking](https://github.com/ruricolist/serapeum/)
- [Alexandria `destructuring-case` for pattern matching](https://alexandria.common-lisp.dev/draft/alexandria.html#Data-and-Control-Flow)
- [Sycamore for purely functional data structures](https://github.com/ndantam/sycamore)
- [Screamer for logic programming](https://github.com/nikodemus/screamer)

##### Entertaining footgun: `let` bindings

```lisp
(defgeneric errormsg (x))
(let* (x (errormsg 12)) x)
```

The above silently compiles, with an SBCL error:

```lisp
;; caught STYLE-WARNING:
;;   The variable ERRORMSG is defined but never used.
```

This should clue you in that something terrible has happened.
The correct form of the `let*` requires ONE outer paren
group to denote bindings, and ANOTHER paren for each key-value
pair.

So this should have been written:

```lisp
(let* ( ;; <- OPEN pairs of bindings
   (x (errormsg 12))
   ) ... ;; <- CLOSE bindings
```

But has been written as:

```lisp
(let* (
   x
   (errormsg 12)
  ) ... )
```

This gets interpreted as:

```lisp
(let* (
   (x nil) ;; notice the `nil` introduction
   (errormsg 12)
   ) ... )
```

The takeaway appears to be that `SBCL` warnings
ought to be treated as errors.


##### ASDF: treat warnings as errors:

```lisp
;; 23:49 <@jackdaniel> bollu: I don't know whether this is documented
(setf asdf:*compile-file-warnings-behaviour* :error)
```


##### Toys

> Special variables (Mutable globals) should be surrounded by asterisks. These are called earmuffs.
> (defparameter *positions* (make-array ...))

```lisp
(assert (condition)
       (vars-that-can-be-edited))
;; https://lispcookbook.github.io/cl-cookbook/error_handling.html#handler-case-vs-handler-bind
(defun divide (x y)
  (assert (not (zerop y))
          (y)   ;; list of values that we can change.
          "Y can not be zero. Please change it") ;; custom error message.
  (/ x y))
```

- [common lisp libraries read-the-docs](https://common-lisp-libraries.readthedocs.io/asdf/)
- [Code eval play loop: livecoding opengl things](https://github.com/cbaggers/cepl)
- Consider [lispy](https://github.com/abo-abo/lispy)  instead of `parinfer`.
- [`cl-repl`](ros install koji-kojiro/cl-repl) for quick command line hackery.
- stdlib is large.

- Loading new libraries:

```
(ql:quickload "str")
```

# Agda Cheat Sheet

- Load/check file: `C-c C-l`.
- Show goals: `C-c C-?`.
- Accept goal value: `C-c C-SPACE`
- forward goal: `C-c C-f`
- backward goal: `C-c C-b`
- Normal form: `C-c C-n`
- see how to write symbol: `M-x quail-show-key`.
- Within goal: Case split: `C-c C-c`.
- Within goal: Refine: `C-c C-r`. Partial give: makes new holes for missing arguments
- Within goal: Type: `C-c C-t`.
- Within goal: Deduce type: `C-c C-d`.
- Within goal: Information: `C-c C-;`.

# Don't Try

  ROLL THE DICE
  -------------

  If you’re going to try, go all the way.
  Otherwise, don’t even start.
  If you’re going to try, go all the way.
  This could mean losing girlfriends, wives, relatives, jobs and maybe even your mind.
  It could mean not eating for three or four days.
  It could mean freezing on a park bench.
  It could mean jail.

  It could mean derision, mockery, isolation.
  Isolation is the gift.
  All the others are a test of your endurance, of how much you really want to do it.
  And, you’ll do it, despite rejection and the worst odds.
  And it will be better than anything else you can imagine.
  If you’re going to try, go all the way.
  There is no other feeling like that.
  You will be alone with the gods, and the nights will flame with fire.
  DO IT. DO IT. DO IT. All the way
  You will ride life straight to perfect laughter. It’s the only good fight there is.



# Big list of Hacker news

> The road to hell is paved with good intentions
> I am a coloured South African(an ethnic group that was previously disadvantaged due to apartheid era racial policies) we in South Africa have Affirmative action policies called Black Economic Empower(BEE) (Its open to all previously advantaged racial groups ie Black, Coloured, Indian they just call it BEE) that has led to mass corruption and cronyism.
> >Start with crony capitalism, which in South Africa goes by the euphemism “black economic empowerment”. The idea behind it seemed laudable enough—to right a historical wrong. Under apartheid, the country produced white titans of industry such as the Oppenheimer family (owners of DeBeers), while making it hard for black South Africans to own businesses. The ANC(Ruling political party) felt it only fair that there should be black billionaires, too. To give them a leg-up it insisted that mining companies should hand at least 26% of their shares to the “historically disadvantaged”. Mining companies (as well as banks and insurers) did so willingly, diluting existing shareholdings when they transferred stakes to the likes of Cyril Ramaphosa, now the president, along with Patrice Motsepe, his brother-in-law, and Bridgette Radebe, his sister-in-law.[1]
> I and alot of South Africans could stomach a one-off payment or one-off percentage equity stake in firms(in South Africa the government instituted a policy that South African Corporate firms would sell shares preferential)to disadvantaged groups but after these shares were sold, the government wanted to continuously repeat it.
> >If these handouts had been a one-off tax, their harm would by now have been forgotten. But once the new black shareholders had sold their holdings, the government drafted regulations to repeat the process. And so capital investment in mines fell by 45% between 2010 and 2018, with output falling by 10% and employment by 50,000—a tenth of direct employment in the industry in 2010.[1]
> When the government gives support not based on merit and competence but gender, race, religion or ethnicity you undermine industrial policy(Instead of support based on a person's potential ability or ability to do things)With affirmative action you end up institutionalising incompetence.
> >Black Economic Empowerment, a policy that incentivises firms to give equity to black investors or business to black-owned suppliers, has created a new generation of Randlords with more political acumen than entrepreneurial talent. “Cadre deployment”, whereby ANC party(Ruling political party) members get jobs on the basis of factional fealty rather than merit, has degraded the state. These appointees steer contracts towards chosen “tenderpreneurs”, who in turn donate to the party. By 2007 Kgalema Motlanthe, a party grandee, said: “This rot is across the board...Almost every project is conceived because it offers opportunities for certain people to make money.”[2]
> Many South African feel that our counrty has become "a cappuccino society, A vast, huge, black majority at the bottom with a layer of white cream and a few chocolate sprinklings at the top of it" referring to the small black elite who have gained great riches from the post-apartheid years - from a failed attempt to rebalance the wealth among the many.
> Yes, I acknowledge the present-day inequities that racist, sexist, etc policies can cause, but if a Government was serious about addressing historical inequalities then you need to invest in education and skills development. Affirmative action never works in the long term, instead of making people competent and self-reliant,it makes them dependent on handouts.
> Contrast Taiwan and Malaysia's Industrial Policies and Outcomes
> Taiwan's has currently a healthy semiconductor industry with many successful and impressive firms ie TSMC, etc.
> And Malaysia with its affirmative action laws favouring certain ethnicities that ultimately undermined their industrial policies. The corruption and shenanigans that result from affirmative action policies happened in South Africa also happened in Malaysia and undermined their long term industrial goals.
> Appropriating a quote from Deng Xiaoping "It doesn't matter whether a cat is black or white, as long as it catches mice." This is taken to mean that as long as the economy works, it is a good economy.
> Affirmative action is equality of outcome. Do people think they have godly powers that can guarantee certain outcomes or results? There is an inherent risk of failure in all ventures and endeavours.
> A correct criticism of capitalism is when it does not provide equal opportunity and so we should always strive to provide equal opportunity, but people confuse that with the equal outcome when, equal outcome can only be enforced through violence because different people, free people make different choices and when they make different choices they have different outcomes if you don't let them suffer the consequences of bad choices or reap the rewards from good choices then you have to use force or violence to get a prefered outcome
> If people are really serious about freedom and equality then you should want not just the freedom to succeed, but also the freedom to fail.
> [1]https://www.economist.com/leaders/2021/07/24/end-of-the-line...
> [2]https://www.economist.com/middle-east-and-africa/2021/07/24/...




> Strongest words ought to start and begin a sentences. A re-phrasing I made:
 "Thus, we know that `pr-ty` lives in UNIV because of correctness of `synth`" into
 "Correctness of `synth` guarantees that `pr-ty` lives in UNIV".

> There is low satisfaction of finishing and understanding a section, it seems
  to flow a little too continuous.

> Align figures to either all left or all right.

> In structure, label references to future sections are non existent, so it
  would help assure the reader in section x that you will talk more about the
  uses of this in section y.



> What do you have in mind? works well to get to know what the other person
   would like.


> So the way I see it, is that as soon as you are
  naming something, people may ask things like "What
  is X exactly? What is X composed of?". So I can
  clearly see reviewers ask "What is DSL composed
  of?", but if we wouldn't name it, I wouldn't expect
  reviewers to ask "What is the python interface composed of?"


> She told me that I was what she calls institutionally poor. That I had been
> conditioned thru my childhood to think like a poor person and in doing so you
> send out unconscious signals to others. She told me this because she came up
> similar. She told me that it causes you to over analyze and over estimate
> risk and therefore you will not take the bold moves that people that don't
> have to worry do. That while you can change the world and everyone see it. If
> you hold onto the fear on meeting your net under you, that you will never
> extract your true value from other. So I said, so you are going to pay me my
> fair value, she laughed and said no, I got you for a very good deal. 3 Days
> latter I walked into her office, with my resignation letter and told her I
> had an offer from another company. She said, now you get it, how much did
> they offer. I told her, and she said I will double that if you stay.



> Here's a discontinuity irl that I read about: you bite into an apple and find
> a worm. Disgusting. But worse would be to find 1/2 a worm, worse still 1/4 of
> a worm, etc... continuity would imply the worst case scenario is biting into
> an apple and not finding a worm.

> PORT (wine) is always LEFT at sea, but never left at dinner.
> L for LEFT, is close to P for PORT. R for RIGHT, is close to S for STARBOARD


> Mona Lisa was special in part because it was uncommon for people to smile. In
> Middle Ages, someone smiling a lot would be perceived as stupid. That's why
> facial expressions in medieval imagery are so serious. Today, being surprised
> a lot is often taken as a sign of stupidity, whereas in ancient Greece an owl
> was the bird of Athena, the goddess of wisdom. Because, obviously, an owl is
> always surprised, and surprise is the first step to understanding.


- [HN link for quote below](https://news.ycombinator.com/item?id=24265400)

> Social justice and "fairness" is rarely one of the main goals of a
> meritocracy. The main goal of a meritocracy is peak performance. NFL teams
> select the "best" quarter-backs not because it's most fair, but because it
> will produce the most wins. Universities grant tenure to the most productive
> professors, because that will enhance the University's reputation. Hospitals
> hire the best doctors, because they can save the most lives. A society should
> delegate its most important responsibilities to its smartest/most-knowledgable
> members, because they can best lead society through worldly challenges.
>
> Which is not to say that Social Justice isn't important. It is vital. But you
> don't get to it by hiring the wrong people in the wrong roles. A meritocracy
> excels at producing wealth - Universal Basic Income, Universal Healthcare,
> Unemployment Insurance, better Public Schooling... these are the kind of Social
> Justice programs that best distribute the wealth back to society.


> my only other critique, which is good in general, but try to force yourself to
speak slower than you want to.

> taking time to build a diagram is the best way to convey knowledge

> learning to be comfortable with silences while speaking doesn't come naturally to anyone.


> Some kids grow up on football. I grew up on public speaking (as behavioral
> therapy for a speech impediment, actually). If you want to get radically better
> in a hurry: 1) If you ever find yourself buffering on output, rather than
> making hesitation noises, just pause. People will read that as considered
> deliberation and intelligence. It's outrageously more effective than the
> equivalent amount of emm, aww, like, etc. Practice saying nothing.  Nothing is
> often the best possible thing to say. (A great time to say nothing: during
> applause or laughter.) 2) People remember voice a heck of a lot more than they
> remember content. Not vocal voice, but your authorial voice, the sort of thing
> English teachers teach you to detect in written documents. After you have found
> a voice which works for you and your typical audiences, you can exploit it to
> the hilt.  I have basically one way to start speeches: with a self-deprecating
> joke. It almost always gets a laugh out of the crowd, and I can't be nervous
> when people are laughing with me, so that helps break the ice and warm us into
> the main topic.  3) Posture hacks: if you're addressing any group of people
> larger than a dinner table, pick three people in the left, middle, and right of
> the crowd. Those three people are your new best friends, who have come to hear
> you talk but for some strange reason are surrounded by great masses of mammals
> who are uninvolved in the speech. Funny that. Rotate eye contact over your
> three best friends as you talk, at whatever a natural pace would be for you.
> (If you don't know what a natural pace is, two sentences or so works for me to
> a first approximation.) Everyone in the audience -- both your friends and the
> uninvolved mammals -- will perceive that you are looking directly at them for
> enough of the speech to feel flattered but not quite enough to feel creepy.  4)
> Podiums were invented by some sadist who hates introverts. Don't give him the
> satisfaction. Speak from a vantage point where the crowd can see your entire
> body.  5) Hands: pockets, no, pens, no, fidgeting, no. Gestures, yes. If you
> don't have enough gross motor control to talk and gesture at the same time (no
> joke, this was once a problem for me) then having them in a neutral position in
> front of your body works well.  6) Many people have different thoughts on the
> level of preparation or memorization which is required. In general, having
> strong control of the narrative structure of your speech without being wedded
> to the exact ordering of sentences is a good balance for most people. (The fact
> that you're coming to the conclusion shouldn't surprise you.) 7) If you
> remember nothing else on microtactical phrasing when you're up there, remember
> that most people do not naturally include enough transition words when speaking
> informally, which tends to make speeches loose narrative cohesion. Throw in a
> few more than you would ordinarily think to do.

# Hair in a bun with stick

- Start with stick like `<---`, such that stick is below hair.
- Twist stick 90 degrees, taking a twist of the hair along with it, such that it is now vertical (`|`).
- Twist stick 90 degrees further, this time **scraping the scalp** to go "under" with the tip, such that it is now `--->`.
- Tie the loose end of the hair that you were holding once more under the stick.
- Push the stick further into the scalp to the left.
- Voila, hair-in-a-stick.

- [Reference Video](https://www.youtube.com/watch?v=5EX6_5lY6Yk)

# Big list of shuffle dancing
- [Blue book: Shuffle dancing](https://lyz-code.github.io/blue-book/dancing/shuffle_basics/)

- Running man
- Charleston
- Backward Charleston
- T step

# Latte Art

#### Steaming milk

- Phase 1: Keep the steam tip right at the surface, need the paper ripping sound.
- Phase 2: Insert tip deep inside, get a whirlpool to incorporate all the air.
- Move from Phase 1 to Phase 2 when the temperature is warm.
- If we inject too little air, then we won't have foam.
- If we inject too much air, then the foam will be too "lumpy" to shape.
- If we don't get a consistent whirlpool in phase 2, then milk can split into two layers.
  What we need is the foam to be mixed up.
- Consider getting a second pitcher to exchange milk in.
- The correct texture is a glossy surface.

#### Pouring for Heart

##### Painting the Canvas
- Base phase: First pour from a height into the center to make the milk go below the coffee.
  **high and slow** pour. This paints the canvas.

##### Painting the lobes of the heart
- Pitcher touches the cup, and the spout is almost above the inside of the cup.
- Bring the coffee mug as close as possible to the pouring jug,
  will cause the foam to float on top. Tilt the cup so that the coffee is almost spilling out.
- Shake the milk jug as you pour to make for ripples. **low and fast** pour.
- While shaking, pour "forward", so that we start making the two lobes of the heart.

##### Cutting for the heart shape
- Finish phase: As one nears the end, raise milk pitcher up again to suck the milk in and cut through forward,
  cutting completeley, in a **high and slow** pour.

# Big list of tmux

- `C-b d`: detach from session (have tmux running in the background)
- `C-b ,`: rename
- `C-b n/p`: next/previous window movement.
- `C-b c`: create new window.
- `C-b %/"`: create pane; deete process to cose pane.
- `C-b (/)`: move pane eft or rigt
- `C-b o`: oter pane
- `C-b space`: maximise pane
- `C-b x`: cose pane
- `C-b !`: mae pane into window.
- `C-b [`: copy mode.
- `:ist-eys` to see a eys.


#### Session movement
- `tmux list-sessions` / `C-b s`: show all sessions.
- `C-b (/)`: move between sessions

# Big list of new words

- Hermeneutics: Derives from hermes who gave language to humans. 
  the study of interpretation, particularly of philosophical, wisdom literature, and biblical texts.

# Favourite OP1 tutorials
- [Opz trap](https://www.youtube.com/watch?v=F1snsWHrUms)
- [opz boombap hip hop](https://www.youtube.com/watch?v=WVllTjtBTZk)
- [opz hiphop](https://www.youtube.com/watch?v=OQ509eGdmGk)
- [opz hiphop 2](https://www.youtube.com/watch?v=dRBBwMYrybs)
- [lofi hip hop](https://www.youtube.com/watch?v=nXg7Mw0vwMk)
- [hard hitting hip hop](https://www.youtube.com/watch?v=tFRyL42itNk)
- [opz daft punk like](https://www.youtube.com/watch?v=olGUyIRi5Ig)
- [how to make opz album pt 1](https://www.youtube.com/watch?v=gMlRTO93Q38)

# Favourite Demoscenes

- [Engage by Logicoma](https://www.youtube.com/watch?v=r7IIawcFXHA)
- [Number One / Another one by fairlight](https://www.youtube.com/watch?v=TaEoAJw_0Zc)
- [Clean Slate by Conspiracy](https://www.youtube.com/watch?v=O3T1-nadehU)
- [Ziphead by Fairlight & Carillon](https://www.youtube.com/watch?v=rJYVDuEOLLQ)
- [Sokia by CNCD/Fairlight](https://www.youtube.com/watch?v=ilHnGKGPsy8)
- [Surge Response by approximate](https://www.youtube.com/watch?v=I4C7RtiqL_0)
- [Zetsubo by Prismbeings](https://www.youtube.com/watch?v=ncdA3t_vzF8)
- [Absolute territory by Prismbeings](https://www.youtube.com/watch?v=9r8pxIogxZ0)
- [Decompress of Empty](https://www.youtube.com/watch?v=_-0d7B9RNxw&list=PL_lmHTgqbbe9HKVe_25kjqe8kzB-6eGYJ&index=2)


# Classical music

- References: inside the score
- Prelude: musical form on wikipedia
- [Musical forms on wikipedia](https://en.wikipedia.org/wiki/Musical_form)

##### What is a symphony?
- a work usually consisting of multiple distinct sections or movements, often four, with the first movement in sonata form.
- Symphonies are almost always scored for an orchestra.

##### Prelude
- Develops a singular theme.

##### Sonata Form

- Exposition: two conflicting keys / two groups. First group: home tonic. Second group: different key.
  Usually `I -> V`, or `i -> V / bIII`
- Exposition ends with a codetta, to transition to the development. Often, the whole exposition is repeated.
- Development: looser, more free form. Will avoid the expository keys. Unstable key.
  Some composers might insert a new theme into the development --- an expansion of the sonata form.
- Recapitulation: Goes back to exposition with a twist. Here, the second group *will also be in the home tonic*.
  The transition from group 1 to group 2, that makes sure group 2 from the exposition is in the same key gives
  a large point of interest. Note that this can be in the home tonic **major or minor**.
  This can change the entire tone of the group by going from tonic major to tonic minor.
- Coda: closure at the recap.

##### What is a sonata? (stuff I should practice on piano!)

- This is not the same as a sonata form!
- A group of pieces called movements. Eg. moonlight sonata has three movements.
- Upto two instruments. For more instrument, we call them trio, quartet, quintet, etc.
- A full sized sontata will have four movements.
- The first movement is usually in sonata form.
- The second movement will be a slow movement. Can be in modified sonata form, with exposition, recap, and coda,
  no development. Will often be ABA' movement.
- The third movement will be a minuet or scherzo (dance).
- The fourth movement will be lively, often in sonata or rondo form. Rondo goes round and round again.
  Comes in episodes which are contrasting. ABACA or ABA'CA''BA'''

##### Mini sonatas

- Sometimes we only have three movements, which exclude the dance movement.


##### Two other forms that might occur: Variations

- Restatements of the theme.
- Variation takes the whole structure of a theme and remakes it.
- Variation form is cumulative. Each variation builds on the other one.

##### Two other forms that might occur: Fugue
- Bach was a master of the fugue. Well tempered Clavier. 24 preludes and fugues.
- A fugue has a process of development.
- It's a discussion of a compact melodic idea, by a definite number of voices, in imitation of each other.
- The fugues depend on each other for harmony. Horizontally, they are all self-consistent, but vertically, they intertwine to create chords.
- This is called counterpoint.
- A **fugato** is a section of music in fugue.
- A fugue begins with an exposition.
- The melodic idea is called as the subject.
- The fugue begins with a single voice stating the subject.
- Then, another voice answers in the dominant key.
- The answer could be either the "real answer" (straight transposition), or a tonal answer (slight delta).
- Voices are introduced in the same way: `V1: tonic subject, V2: dominant answer`, followed by `V3: tonic subject, V4: dominant answer`.
- An episode in a fugue is when the complete subject is not being heard.
- A canon is when different voices play the same music at different times.
- Augmentation is the delivery of the subject or countersubject in consistently slower notes.
- Diminution is the delivery of the subject or countersubject in consistently faster notes.
- Inversion is the delivery of the subject or countersubject in reflected notes.
- Stretto is the delivery of the subject that has been squeezed.

#### What is chamber music?

- Music for a small space, such as a castle, which is a new venue from the church and theater.


### Biographies

- Collect biographies from wikipedia, and "Five minute mozart".

##### Hildegard von Bingen (1098-1179)
- Rhineland of Germany.
- Had visons, was accepted into a monastary.
- Pre Renaissance
- Was a great nun, who exchanged letters with kings and popes.

##### Claudio Monteverdi (1567-1643)
- Renaissance

##### Bach (1690-1750)
- Baroque

##### George Frideric Handel (1685-1759)
- Baroque
- Handel's oratorio, "messaiah" is the most famous one.
- Handel was blind for the last seven years of his life. Dictate compositions.

##### Antonio Vivaldi (1680-1740)
- Baroque


##### Mozart (1756 - 1791)
- Classical
- Austria.
- Child prodigy, learnt music from his father.
- Wanted to be free of the royal patronage system, tried to strike his own path.

##### Franz Joseph Haydn (1730-1809)
- Classical
- Did not come from a musical family.
- Notable singing abilities, travelled to Vienna to join choir.
- Wrote a bunch of piano sonatas.

##### Beethoven (1770-1827)
- Classical/Romantic
- German, baptized in Bonn.
- Father was a singer and musician, wanted his son to be a mozart as a child prodigy.
- Father was abusive, he was an incompetent teacher for Beethoven.
- Beethoven travelled to Vienna to study under Mozart.
- Trip was cut short when his mother died of tuberculosis.
- He went back to vienna around 1790, studied with Haydn. 
- His hearing started to diminish, penned his testament.

##### Franz Schubert (1800-1830)
- Romantic
- Quit school.
- Wrote "lieder" (songs), inspired by Goethe.
- Attended funeral of Beethoven as pallbearer.
- Died in Vienna.


##### Richard Wagner (1810-1880)
- Romantic
- Born in Leipzig during the Napoleonic wars.
- Wagner's early idols were Beethoven and Shakespeare.
- Most inspiring composer of the 19th century.
- Did away with earlier french and italian styles of opera.
- Later in life, his polemical ideas were better known than his music. 
- Anti-semitism, adoped by Hilter and the Nazis

##### Johannes Brahms (1840-1900)
- Romantic
- Took him 20 years to publish his 1st symphony, out of fear that it would never live up to beethoven.
- Best known now for hungarian dances.

##### Frederic Chopin (1810-1850)

- Piano virtuoso, great composer.
- Talent as a musician was apparent at a young age. By the age of 7, was composing and performing.
- Most well known for his work on the piano. Waltzes, Nocturnes, etc.
- Untimely death from tuberculosis. Died in Paris.

##### Felix Mendelssohn (1809 – 1847)
- Part of the upper class.
- Made his musical debut at age 9, was accomplished composer by age 13.
- Performed one of bach's pieces for the first time since his death.
- Founded the Leipzig conservatory of music.
- Died when he heard of the death of his sister, along with overwork.

##### Franz Liszt (1810-1890)
- Prodigious musical talent at a young age.
- Made his debut at the age of 9.
- Funded by prince Nicholas, he travelled to Vienna. Here, he met Beethoven and Schubert.
- Affairs with married noblewomen.
- Apex was his years spend at Weimar, composed his major works.


##### Giuseppe Verdi (1813 – 1901)

##### Bruckner (1825-1900)


##### Richard Strauss (1860-1940)

##### Gustav Mahler (1860-1910)

##### Robert Schumann (1810-1850)

##### Antonín Dvorak (1841 – 1904)

##### Claude Debussy (1860-1910)

##### Pyotr Ilyich Tchaikovsky (1840-1890)

##### Vaughan Williams (1875-1950)

##### Rachmaninoff (1880-1950)

##### Maurice Ravel (1875-1935)
- Romantic impressionist composer, leading figure in Modernism.
- Born in france, next to the french spanish border.
- At age 14, entered the paris conservatory.
- During WW1, applied to the military, but was declined for his small stature. Drove ambulance.
- lived out his remaining days in Paris.
- Contracted dementia and died 5 years later.

##### Igor Stravinsky (1880-1970)
- Modern
- Born in russia.
- Father was an opera singer, mother a pianist.
- Parents encouraged him to study law, but he met a talented composer and decided to learn music.
- Collaborated with the ballet company in paris.
- Following WW1, began to compose in various styles and genres, shifted towards Objectivity, shun emotions of the Romantic era.
- Was inspired by pre-romantics (Mozart, Bach, Handl).
- Began changing composition based on his own uncommon rhythmic and harmonic style (neo-classicism).
- Implemented the twelve-tone technique, which uses all twelve tones.
- Moved to NYC.

##### Shostakovich (1900-1975)
- Modern
- Under rule of joseph stalin
- 9th symphony was too insolent, had name dragged through mud for it.

##### Sergei Rachmaninov (1873-1943)

##### Leonard Bernstein (1918-1990)

##### Philip Glass (1930-)



#### Double Fugue
- Fugue exposes with two subjects

## Concerto

- A sonata for solo instrument(s).
- We get anthesis between soloist versus orchestra, and how do we balance this?
- Eg. orchestral introduction (ritornello / return), soloist enters, soloist climax, orhestral climax (ritornello).
- An example is vivaldi's spring. soloist imitates birdsong. the solo section imitates different natural phenomena.



# Blues and Jazz Piano Improv

#### Jazz Piano: The Theoretical Minimum

- [Link](https://www.thejazzpianosite.com/jazz-piano-lessons/jazz-chord-voicings/jazz-piano-minimum-requirements/)
- Left Hand, Bass: Walking bassline, Stride, Root notes.
- Left Hand, Chords: Rootless, Shell, Quartal.
- Right Hand, Melody: Scale, Improv, Licks.
- Right Hand, Chords: Rootless, Shell, Quartal.
- Both hands, Chords: Two handed voicings, Spread, Quartal.

##### Things I need to learn

- Bossa nova beat.
- Crafting Walking basslines.
- Quartal Voicings
- Two handed Voicings.
- Creating basslines

#### Diminished Scale

- Alternate whole and half notes.


#### Interesting Basslines / Left hand patterns

- Key search term: "left hand patterns".
- Stride.
- Walking bass line.
- Jerry Lee Lewis left hand pattern.
- Bumble boogie pattern.

#### Creating smooth basslines with slash chords

- [Video](https://www.youtube.com/watch?v=_GzloA_IDmk)
- Key idea: use inversions to smoothly move notes.

#### Stride Piano

- [Video](https://www.youtube.com/watch?v=TbOuxeldeqA)
- to make a stride chord, take the chord, e.g. Cminor (C Eb G). Then take the 3rd out, and put it on the top. This gives us (C G Eb).
- Now alternate the loweer note 'C', then the other two notes `(G Eb)`. See that this will be quite large, since the `Eb` is from the next octave.
- Do this with whatever chord progression one has.
- I must try this with the bakemonogatari soundtrack, particularly the song [sutekimeppou](https://www.youtube.com/watch?v=cJyPtpldb78&list=PLA0KqNE_ppfAPeYtMyt4QzyU1aB5cizrD&index=18), and [in the hall of the mountain king](https://www.youtube.com/watch?v=gSY-wD4l5DM).
- This style is great to generate a strong bassline.

#### Bird Changes

- This comes from Bebop.
- Suppose we want to play blues, so in bar 1, we want to play CMaj7, then on bar 4, we want to play F7, and then on bar 10, we want to play the 5th (G7).
- So we do a thing where we play the II and the V for half time (ie, in each bar, we play the II and the V of some scale).
- Which scale do we play? We choose a descending sequence of scales: CMaj7 -> Am -> Gm -> F7 -> [F7] -> Fm7 -> Bb7 -> Em7 -> A7 -> EbM7 -> Ab7 -> [Dm7] -> [G7] -> C -> A7 -> Dm7 -> G7.
- Play descending 2-5s, to get from I to IV chord in Blues. Then repeat the same descending 2 5s to get from IV to V.
- Example song: Freight Trane.
- Use stride voicings, or bud powell voicings (2/3 note voicings).

#### Latin Bass

- [Video reference](https://www.youtube.com/watch?v=8BShjpnliKc)
- Pick chords, e.g. `Cm7 -> Fm7 -> G7 -> Fm7 -> ... `
- Arpeggiate the C chord. First play `1-8`, then play `3-5`. (`C-C`, `Eb-G`).
- Bass rhythm: Clave pattern. 2 bar pattern, repeated throughout the song.
- Son clave 2/3: `1rest 2 3 4rest`, `1 2rest' 2&quaver 3rest 4`.

#### Walking bass

- Style of playing on the left hand.
- Play notes: `1, 2, 3, 5`, `8, 7, 6, 5`, `1, 5, 1, 5`

#### Rootless voicings (lighter sound)

- Take the `1-3-5-7`, delete the `1`, and play `7-3-5`.
- For example, to play `C Em G Bm` in a rootless fashion, instead play `Bm Em G`.

#### Kenny Baron Chord Voicings (large, rich, good for rippling)

- [Jazz Piano site](https://www.thejazzpianosite.com/jazz-piano-lessons/jazz-chord-voicings/barron-chord/)
- Only useful for m7 chords, when the 11th is in the melody (the top note).
- Left hand stacks fifths starting from 1.
- Right hand stacks fifths, starts from minor 3rd (3 semitones up).
- Right hand ends on the 11th. 

#### Quartal voicings (sound 'edgy')

- Literally memorization, need to know what the 4ths is for each note, just as we remember minor 3rd and perfect 5th.
- [All perfect 4th intervals](https://www.pianoscales.org/perfect-fourth.html)
- `C up a 4th is F`
- `D up a 4th is `
- `E up a 4th is A`
- `F up a 4th is Bb`
- `G up a 4th is C`
- `A up a 4th is D`
- `B up a 4th is E`

#### Two handed voicings (nice for light bass, light treble.)

- Left hand: `1st and 7th`, Right hand: `3rd and 5th`.
- Left hand: `1st and 3rd/10th`, Right hand: `5th and 7th`.
- Want melody note to be on the top of the chord.


#### Tritone substitution

- The theory that I can find talks about major, not about minor.
- Idea is that we want a different chord with the same 3th and 7th notes.
- On the major scale, this is given by the chord that is a 6 semitones / 3 whole notes away (in either direction, since we have 12 notes.)
- For example, `G7` is given by `G B D F`
- `Db7` has notes `Db F Ab B` which shares the same 3th and 7th (`B` and `F`).

##### Walking Bass Line

- Suppose we have one chord per bar, with chords `ii-v` in the two bars. 
- Take the notes from your 7th chord, e.g. C minor ii7 `D, F, A♭, C`
- Play the first three notes of the chord, so play `D, F, A♭`.
- Then, for the next note, look at the next chord, e.g. C minor v7: `G, B♭, E♭,  C`.
- We want to go to `G` next, we have one quarter note left in the bar, so play a **leading tone** to `G`.
- Since I like bluesey, I can play `F#` from the blues scale, to anticipate the `G` in the next chord.
- So for this bar, we play `D F A♭ F#`.
- Play the corresponding shell voicing or melody with the right hand.
- If we have two chords per bar, then all we get to play are `root ii`-`leading v`-`root v`-`leading i` etc.
- To add an arpeggio, add a `853` if you want some flourish.


#### Pedal Usage

- pedal moves *opposite* to hands.
- Foot should be down whilst hand goes up to play the next chord.
- Hand comes down once again, plays the next chord, and then the foot goes up.
- Pivot the pedal from the heel. For this, we need to sit far enough back away from the piano.
- To practice, go back and forth between two chord positions --- I and V.



#### Best References for theory

- [The Jazz piano site](https://www.thejazzpianosite.com/about/)
- [Learn EVERY Chord and Chord Symbol - The 7 Systems by Musicians Inspired](https://www.youtube.com/watch?v=CyNiY1jzOuQ&t=1112s)
- [Jazz improv with julian bradley](https://www.youtube.com/watch?v=lhNZEIFv3uk)
- [Jazz tutorial](https://jazztutorial.com/video-library)
- The real book. Get one in key C.

#### Types of Seventh Chords

#### Dominant 7th (default) `C7`: 
- [`1, 3, 5, ♭7`](https://m.basicmusictheory.com/c-dominant-7th-chord)
- Major triad + two semitones below octave note.
- Used on the fifth degree of the scale. One will common see `G7`.
- It's called dominant since it's used on the fifth scale degree.
- The only place we can build a dominant 7th and stay within key is on the 5th.
- `F7` adds an `Eb` which makes it bluesey, so this is useful.

#### Major 7th `Cmaj7` / `C△7`: 
- [`1, 3, 5, 7`](https://m.basicmusictheory.com/c-major-7th-chords).
- Major triad + one semitone below octave. Seventh degree of the major scale.

#### Minor 7th `Cmin7`
- [`1, ♭3, 5, ♭7`](https://m.basicmusictheory.com/c-minor-7th-chords).
- Lush, smooth sound.

#### Diminished 7th.
- [`1, ♭3, ♭5, ♭♭7`](https://m.basicmusictheory.com/c-diminished-7th-chord).

#### Minor 2 5 1 for Jazz
- We are playing in the key of C minor
- we want the `ii v i` chords.
- [Scale chords](https://m.basicmusictheory.com/c-minor-7th-chords)
- 2: C minor chord iiø7: `D, F, A♭, C`. Voiced as  `D, F, A♭, C`.
- 5: C minor chord v7: `G, B♭, D, F`. Voiced as `D F G B ♭`.
- 1: C minor chord i7: `C, E♭, G, B♭`. Voiced as `C, E♭, G, B♭`.
- What scale to play? consider chord + whole step, which gives us the following:
- 2:`D E F G A♭ B♭ C D`, ie, `C D E F G A♭ B♭` (C aeolian dominant scale / C [hindu scale](https://pianoencyclopedia.com/scales/hindu/C-hindu.html)) 
- 5:`G A B♭ C D E F G`, ie, `C D E F G A B♭` (C mixolydian).
- 1:`C D E♭ F G A B♭` (C natural minor).

##### 2, 5, 1

```
2: C D F A♭
C D E F G A♭ B♭ (C hindu scale)
---
5: B♭ D F G
G A B♭ C D E F G (C mixolydian)
--
1: C, E♭, G, B♭
C D E♭ F G A B♭ (C natural minor).
```
### Melody: Approch pattern --- half step below

- Approach each note with the note that is a semitone below.
- Dmin7: C# -> D
- Dmin7: E -> F
- Dmin7: G -> A
- Dmin7: B -> C
- G7: F -> G
- G7: A -> B
- G7: C -> D
- G7: E -> F
- Cmaj7: B -> C
- Cmaj7: D -> E
- Cmaj7: F -> G
- Cmaj7: A -> B


### Melody: Approach pattern / scale associated to a chord: Chordal tone + whole step

- For any given chord, eg. Cmaj7 = C E G B, one is allowed to use notes that are a whole step up from each of the notes.
- This gives us the notes: C D E F# G A B C. This is the C lydian scale.
- For the next one, Cmin7, we get C D Eb F G A Bb C. This is the C dorian scale.
- For Dmin7, we get D E F G A B C D. This is the D dorian scale.
- For G7, we get G A B C D E F G. This is the G mixolydian scale.
- For A7, we get A B C# D E F# G A. This is the A mixolydian scale.

### Melody: Approach pattern --- chord scale above

- Play C major scale, approach from above before playing note

- Dmin7: E -> D
- Dmin7: F -> E
- Dmin7: G -> F
- Dmin7: A -> G
- G7: B -> A
- G7: C -> B
- G7: D -> C
- G7: F -> E
- Cmaj7: E -> D
- Cmaj7: F -> E
- Cmaj7: G -> F
- Cmaj7: B -> A

### Melody: Approach pattern --- enclosures
- Approach from both sides, chromatically, before playing the main note.
- Dmin7: C# -> E -> D


### Melody: Walking Bass line
- We want the notes to be the root note of the chord
- For example, with the standard Dmin7, G7, Cmaj7, A7 progression, we would have:
- Play D, Play G, Play C, Play A
- We can move to the notes by leaping via 3rd / 5th / octave.
- But when we leap, we want to use notes from the chord.
- For example, to go from D -> G, we want to go as: `D F A`, and then at the note, transition with a whole step or a half step, so we go via `Gsharp G`.
- So, to go from D to G in four beats, we use `D F A Gsharp`followed by the `G`.

### Learning Jazz Chord Voicings [Link to tutorial](https://www.thejazzpianosite.com/jazz-piano-lessons/jazz-chord-voicings/)
- This `melody:improv::chords:voicings`
- **Quick hack:** `root + 7th` on bass, `3rd+5th+melody` note on treble.

### Chord voicing for bossa nova: Rootless chord voicings (sophisticated)

- Key idea: leave out the root note, only keep 3 5 7 9.
- 3 5 7 9 (position A)
- 7 9 3 5 (position B) [7, 9 are octave lower]

# Sheet Music

#### C Minor Scales

<img src="/static/scales.cropped.svg" />

#### Bossa Nova Rhythm

<img src="/static/bossa-nova.cropped.svg" />

#### Wutang Clan: CREAM

<img src="/static/wutang-cream.cropped.svg" />

#### Madoka Magica OST

<!-- img src="/static/madoka-ost.cropped.svg" / -->

```abc
T: Madoka Magica (C mixolydian)
(C2 z1 D) _E2 _B,2 C2 D2 | C2 z D _E2 F2 E2 D z | {D}_E2 C2 z2
(CD_EFG2) C2 z | G  F2 _E2 D z | D_E C2  z2
(CD_EF) G2 C2 z | G F2 _E2 D2 | _EF G2  z2
(CDEF) G2 C2 z | (GzG_A) F2 z |  (_Ez_EF)  D2  z | (DzD_E) C2
```

#### Wave Teng

```abc
X: 1
T: Wave Teng (C mixolydian)
| GGG G2 FE F F2 E C2 z |
w: I wan na be where the wave hits the shore
GGG G2 FE F F2 A G2 z |
w: Right by the sea down in El Sal va dor
C GGG G2 FE F F2 E C2 |
w: han ging on the beach with the one I ad- ore
D z D_B,G, z  D_B,G, z _B,2 C2 C2 |
w: yeah gi- ddy up gi- ddy up ro me o 
z  D_B,G, z  D_B,G, z _B,2 C2 C2
w: gi- ddy up gi- ddy up ro me o
```

### Fur Elise

```abc
T: Fur Elise (C blues scale)
| G F# G F# F |
D F E_ C | 
f A_ B D |
g F D E_ |
c G F# G F# G |
D F E_ C |
F A_ C D |
G E_ D C
```

### In The End

```abc
T: In The End (C harmonic)
|C2 G2 G2 _E2 | D2 D2 D2 D_E | C2 G2 G2 _E2 D4 |
G2 G4 _A4 G4 | 
w: It starts with why
```

### Breaking The Habit

```abc
T: Breaking The Habit
|G4 _E4 | F4 C4 | z C2 _E2  _E _E2 z D C2 |
w: mem-ories con sume like op-en-ing the wound
_E z  _E  _E2  z  | D2 _E2  _E C4
w:  pick-ing-me a-part ag-ain
|G4 _E4 | F4 C4 | z C2 _E2  _E _E2 z D C2 |
w: you all ass-ume  I'm safe here in my room
_E z  _E  _E2  z  | D2 _E2   F G4
w: Unless I try to start again
c2 c c3 | _B2 A2 F F3 | c c2 c2 _B2 A4
w: I dont want to be the one bat-tles al-ways choose
c2 c c3 | _B2 A2 F F3 | c c2 c2 _B2 A4
w: Inside I re-a-lize | I'm the one con-fused
C2 _E2 _E D2 C2 z _B, C2 C4 | _B, _E2 _E D2 C2 D4
w: I don't know what's worth fight-ing for | or why I have to scream
C2 _E2 _E D2 C2 z _B, C2 C4 | _B, _E2 _E D2 C2 D4
w:I don't know why I ins-ti-gate And say what I don't mean
C2 _E2 _E D2 C2 z _B, C2 C4 | _B, _E2 _E D2 C2 D4
w: I don't know how I got this way I know it's not alright
C2 C2 _E3 D2 C2 _E4 D2 | C2 _E3 F2 _E2 _E4 D2 
w: So, I'm brea-king the ha-bit | I'm brea-king the ha-bit 
C C4
w: to-night
```

### Gin Soaked Boy


```abc
T: Gin Soaked Boy (C major)
CD G2 G2 F E2 {F} G2 |
w: I'm the dark- ness in the li:ght
CD G2 G2 F E2 C2 |
w: I'm the left ness in the right
T: Gin Soaked Boy (C major)
CD G2 GG F E2 C2 |
w: I'm the gin in the gin soaked boy
CD F E2 C2 |
w: yeah the gin soaked boy
T: Gin Soaked Boy (C major)
C z C2 z C z C2 A, C2 E z |
w: ba ba ba ba du ba ba 
C z C2 z C z C2 A, C2 A, z |
w: ba ba ba ba du ba ba 
C z C2 z C z C2 A, C2 E z |
w: ba ba ba ba du ba ba 
C z C2 z C z C2 CG,A, C2 z |
w: ba ba ba ba du ba ba ba
```


### Breezeblocks (WIP)

```
T: Breezeblocks (C Natural Minor)
G F E_ E_ |
F G F_ G F E_ |
F 
G F_ G F |
E_ F D E_ C |
E_ E_ E_ | 
{F} G G G G |
C B_ G G |
F G F E_ |
F G C C |
```

### Dissolve by Absofacto (WIP)

```abc
T: Dissolve by  Absofacto (C harmonic minor)
   C _E   F   G   _B  G  _e    c _B   F  G  _B   C
w: I just wan ted you to watch me dis ol ve slow ly
   G  F G _B G C    C  D  _E
w: in a po o l slow ly ly ly 
```

### Rest by El Huevro

```abc
c d _e f g2 | f2 c2 f2 |
c d _e f g2 | f2 c2 f2 |
c d _e f g2 | f2 c2 f2 |
c d _e f g2 | f2 c2 f2 |
c2 c2 G2 G _A _A2 C2 C2 D2 C C2
```

### Naruto OST Drill Remix

```abc
T: Naruto OST Drill Remix
_B, C D _E2 D2 C2 |
_B,2 C2 D2 _E2 F2 _E2 _F2 G2 |
_B,2 C D _E2 D2 C2 |
C2 F2 F4 C2 G2 F4 |
_B2 _B3 C C4 |
```

### Candleburn by Rabbitology

```abc
T: Candleburn by Rabbitology
C2 C _E2 C _E2 |
C2 C _E2 C _E2 |
C2 C _E2 C _E2 |
_B, z _B, z _B, z _B, |
```

```abc
Q: 1/4=150
T: Candleburn by Rabbitology
   _E2   C    C   _E2   C    C
w: bap-tize her bap tize her
   _E2    C   C   _E2   C     C
w: rose wat er soft daught-er
   F     F   F   F   G  _E  C2
w: don't for-get to flo-ra-lize
   C     _E _E C   C  _E    _E  C2 
w: don't vo-ca-lize the smoke in eyes
   _B,2  z  _B,2  z  _B,2   C4
w: don't don't don't strike

w: catch-ing on that dis-tant lie
w: she's got-ta be di-vi-ine
w: then line breaks spine aches
w: coiled snake bro-ken rope
w: and joa-nie cho-kes
```

```
w: well they better hope that their
w: per-fume is stron-ger than the soul 
```

```abc
they'll put an ap-ple in your hand
but don't you dare 
```

### Carnival of Rust (WIP)

```abc
T: Carnival of Rust
C2 G2 F2 G2
w: come feel the rain
C2 G2 GF _E _E F
w: cause I'm thirs-ty for your love
  _E    _E   _E D  _E    D   C    _B, C
w: dan-cing un-der-neath the skies of lust
 c G  _E _B, _E _B, C 
 o o  ye-ah ye-ah yeah
```


### Lovesick Fuck (by Mura Masa)
### Maroon 5 This Love
### Maroon 5 Maps

# Big List of Artists and Illustrators

#### Franklin Booth

#### Berine Wrightson

#### Pen and Ink: Texturing

- [How to texture](https://www.youtube.com/watch?v=p0iaumF6Eb8)
- [Architectural Sketching: texture](https://www.youtube.com/watch?v=zJKZhxV4W9o&list=PL-7IZmGjCRjDEVs-7jjNAepfkBp95VouI&index=3)

# Big List of Art and Paintings I Enjoy

##### Hiroshi Yoshida

- [hisorhi yoshida](https://en.wikipedia.org/wiki/Hiroshi_Yoshida) makes beautiful paintings, including of India.

#### Klimt

- [Death and life](https://bluesurfart.com/collections/gustav-klimt/products/death-and-life)
- [Judith and the head](https://upload.wikimedia.org/wikipedia/commons/9/92/Gustav_Klimt_039.jpg)

