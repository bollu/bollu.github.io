<h2>
<img style="float:left;display:inline-block;padding-right: 16px; width: 48px" src="./static/banner.png">
A Universe of Sorts
</h2>


### Siddharth Bhat

- [Please leave feedback!](https://www.admonymous.co/bollu)
- [Vidcall/Hang out](https://calendly.com/bollu/)
- Reach me: <a href='mailto:siddu.druid@gmail.com'> `siddu.druid@gmail.com` </a>
- [github](http://github.com/bollu)
- [math.se](https://math.stackexchange.com/users/261373/siddharth-bhat)
- [resume](resume/main.pdf)
- [reading list and link dump](todo.html)
- Here is the <a type="application/rss+xml" href="feed.rss"> RSS feed for this page</a>

# Ordinals and cardinals


This a rough sketch of a part of set theory I know very little about, which I'm encountering as I solve
the "supplementary exercises" in Munkres, chapter 1.

#### Ordinals

- Two totally ordered sets have the same order type if there is a monotone isomorphism between them.
  That is, there's a function $f$ which is monotone, and has an inverse. The inverse is guaranteed
  to be motone (1), so we do not need to stipulate a _monotone_ inverse.
- Definition of **well ordered set**: totally ordered set where every subset has a least element.
- Theorem: The set of **well ordered sets** is itself well ordered.
- Definition **ordinals**: Consider equivalence classes of well ordered sets under order type.
  of well ordered sets with the same order type. The equivalence classes are **ordinals**.

##### (1) Inverse of a Monotone function is monotone.

- Let $f: A \rightarrow B$ be monotone: $a < a'$ implies $f(a) < f(a')$. Furthermore,
  there is a function $g: B \rightarrow A$ such that $g(f(a)) = a$ and $f(g(b)) = b$.
- Claim: if $b < b'$ then $g(b) < g(b')$.
- Let $b < b'$. We must have (a)  $g(b) < g(b')$, or (b) $g(b) = g(b')$, or (c) $g(b) > g(b')$.
- If $g(b) < g(b')$ we are done.
- Suppose for contradiction $g(b) \geq g(b')$ then we must have $f(g(b)) \geq f(g(b'))$ since $f$ is monotone. Since $f, g$ are inverses
  we get $b \geq b'$. This contradicts the assumption $b < b'$. 
- This doesn't work for partial orders because we may get $b$ and $b'$ as _incomparable_.


#### Von Neumann Ordinals

- **Von neumann ordinals:** Representatives of equivalence classes of ordinals.
  Formally, each Von-Neumann ordinal is the well-ordered set of all smaller ordinals.
- Formal defn of  Von-Neumann ordinal $o$: (1) every element $x \in o$ will be a subset of $o$, since $x$
  is itself a set `{ ordinal < x }`, which is a subset of `{ ordinal < o }`. (2) the set $o$
  is well ordered by set membership, since two such ordinals will always be comparable, and one must
  contain the other. 
- For example of Von Neumann ordinals, consider `0 = {}`, `1 = {0}`, `2 = {0, 1}`, `3 = {0, 1, 2}`.
  We can order `3` based on membership: `0 ∈ 1, 2` so `0 < 1, 2`. `1 ∈ 2` hence `1 < 2`. This totally orders `3`
  based on set membership. Next, also see that a **member** of `3`, such as `2`, is in face `2 = {0, 1}`, which is a subset of `3`.
  So every member of `3` is a subset of `3`. (Not vice versa: not every subset is a member! The subset `{1, 2}` is not a member of `3`).

#### Limit ordinals

- A **limit ordinal** is an ordinal that cannot be written as the successor of some other ordinal.
- **Theorem**: An ordinal must be either zero, or the successor of some other ordinal, or a limit ordinal (2)
- [References on ordinals](http://www-users.math.umn.edu/~garrett/m/algebra/notes/14.pdf)

#### Cardinality and cardinals
- We can define cardinality as equivalence classes of sets that are
  **equinumerous**: ie, sets with bijections between them.  This does not strictly speaking work
  due to set-theoretic issues, but let's go with it.
- In each such equivalence class of sets which are equinumerous, there will be many well ordered sets.
  The smallest such well ordered set (recall that the set of well ordered sets is itself totally ordered).
  This is called as the **cardinal** for that cardinality.
- So we redefine cardinality as the smallet ordinal $\alpha$ such that there is
  a bijection between $X$ and $\alpha$.
  This is motivated from the "equivalence class of all equinumerous sets", but
  sidesteps set theoretic issues. For this to work, we need well ordering. Otherwise,
  there could a set with no ordering that is in bijection with it.



#### Rank
- The **rank** of the empty set is zero. The rank of a set is recursively the smallest ordinal greater
  than the ranks of all the members of the set. Every ordinal has a rank equal to itself.
- $V_0$ is the empty set.
- $V_{n+1} \equiv 2^{V_n}$. This defines $V$ for successor ordinals.
- $V_\lambda \equiv \cup_{\beta < \lambda} V_\beta$. This defines $V$ for limit ordinals.
- The set $V_\alpha$ are also callled stages or ranks. We can define the rank of a set $S$ to be the smallest $\alpha$
  such that $S \subseteq V_\alpha$.


#### Inaccessible cardinal

A cardinal that cannot be created by adding cardinals, taking unions of cardinals, taking power sets
of cardinals. So the set of cardinals smaller than an inacessible cardinal give a model for ZFC.
if $\kappa$ is an inaccessible cardinal, then $V_\kappa$, collection of all sets of rank less than $\kappa$
acts as a place to do mathematics safely, while still having access to the "set of all sets" $V_\kappa$
(Grothendeick universes, apparently).



#### Alternative definition of cardinality using rank

- Recall that we wanted to define cardinality as the equivalence class of 
  of equinumerous sets, but this ran into set theoretic issues.
- A fix [(by Dana Scott)](https://en.wikipedia.org/wiki/Scott%27s_trick) is for a set $A$, consider the least rank $\kappa$
  where some set in bijection with $A$ appears. Then we define the cardinality
  of $A$ to be the equivalence classes of sets in $V_\kappa$ that are in
  bijection with $A$. This gives us the cardinals without needing us to
  consider all sets. This works even without well ordering. 
- I don't actually understand why this works. In my mind, the set `{0}` and `{{0}}` both have the same size, but `{0}` lives in `V1` while `{{0}}`
  lives in `V2`, so they won't have the same cardinality? Actually, I think I do understand: for the set `{{0}}`, the set `{0}` which is in bijection
  with `{{0}}` occurs at rank `1`, so the cardinality of `{{0}}` is given by the equivalence class in `V1`: `[{0}]`. 
- The key part seems to be "find the **smallest** rank". I have no idea how one would formalize this. 




# Musing about Specht modules

If we generalize, to each point $x$, we are creating a group of orthogonal
matrices $O_x$ (like $C_t$), such that 
- All points in the orbit have (the same/similar, unsure?) $C_t$
- For points outside the orbit, we evaluate to zero.

At least in dim=2, we can't take rotations (of finite order) as elements of $O_x$. These behave
like nth roots of unity on averaging, so we get $1 + \omega + \omega^2 + \dots + \omega^{n-1} = 0$,
leading to not giving any new points in $O_x$.

- The only way to get new points in dim=2 is by taking reflections. So, for example:

```
  y
  |
p | q
  |
```

- reflection of `p` about the `y` axis gives us `q`. So if we set $O_p = \{I, Y\}$, we get $O_p(p) = I - Y$.
- We need $O_p(q) = sgn(Y)O_p(p)$, which does indeed happen, as $O_p(p) = p - q$, with $O_p(q) = q - p = - (p-q)$.
- Let's add more points:

```
  y
  |
p | q
c | d
```

- The problem with the new points $c, d$ is that they are not in the orbit $O_p(p)$, but they also don't evaluate to zero!
- This tells us that after we pick the points $p, q$, any new points we pick *must lie on the axis of reflection* to be annhilated.
- Thus, one valid way of adding new points is:


```
  y
  |
  c
p | q
--+-----x
  |
  d
  |
```

- Here, $c, d$ have as group $O_c = O_d = \{I, X\}$, reflection about the $X$ axis. Check that all the axioms are satisfied: elements 
  in the orbits $O_c, O_d, O_p, O_q$ evaluate to $\pm A_c c, \pm A_p p$. While elements not the orbit become zero.
- Thus, it seems like the Specht module attempts to construct "reflections" that somehow represent $S_n$. Is this why it is related
  to Coxeter theory?

- [What is a Coxeter diagram good for](https://math.stackexchange.com/questions/735679/what-is-the-coxeter-diagram-for)
- [What is a Coxeter group](https://math.stackexchange.com/questions/2895896/what-is-a-coxeter-group)


# Every continuous function on $[a, b]$ attains a maximum

The high-level machinery proof:
1. Continuous image of a compact set `[a, b]` under function $f$ is a compact set `f([a, b])` (1).
2. Compact set in $\mathbb R$ is closed (2) (Heine Borel).
3. $sup(f[a, b])$ is a limit point of $f([a, b])$. (4: `sup` is a limit point).
4. Thus $f([a, b])$ (closed) contains $sup(f([a, b])$ (limit point) (5: closed set contains all limit points).
5. Thus $f$ attains maxima $sup(f([a, b]))$ on $[a, b]$.


##### (1) Continuous image of compact set is compact

- Let $f: A \rightarrow B$ be a continuous function. Let $C \subseteq A$ be a compact set.
- Need to show $f(C)$ is compact.
- Take any open cover $\{ V_i \}$ of $f(C)$. Need finite subcover.
- Pullback $V_i$:  Let $U_i \equiv f^{-1}(V_i)$.  Each $U_i$ open as $f$ is continuous. $\{ U_i = f^{-1}(V_i) \}$ cover  $C$ since $\{ V_i \}$ cover $f(C)$.
- Extract finite subcover $\{ U_j : j \in J \}$ for finite set $J$.
- Push forward finite subcover: $\{ V_j : j \in J \}$ cover $f(C)$ as $U_j$ cover $C$.


# Invisible cities

> The city does not consist of this, but of relationships between the
> measurements of its space and the events of its past: the height of a lamppost
> and the distance from the ground of a hanged usurper’s swaying feet

> Perinthia’s astronomers are faced with a difficult choice. Either they must
> admit that all their calculations were wrong and their figures are unable to
> describe the heavens, or else they must reveal that the order of the gods is
> reflected exactly in the city of monsters.

> ... seek and learn to recognize who and what, in the midst of the inferno,
> are not inferno, then make them endure, give them space.



> Bear with me,’ that man answered. ‘I am a wandering herdsman. Sometimes my
> goats and I have to pass through cities; but we are unable to distinguish them.
> Ask me the names of the grazing lands: I know them all, the Meadow between the
> Cliffs, the Green Slope, the Shadowed Grass. Cities have no name for me: they
> are places without leaves, separating one pasture from another, and where the
> goats are frightened at street corners and scatter. The dog and I run to keep
> the flock together.’




> description of Zaira as it is today should contain all Zaira’s past. The city,
> however, does not tell its past, but contains it like the lines of a hand,
> written in the corners of the streets, the gratings of the windows, the
> banisters of the steps, the antennae of the lightning rods, the poles of the
> flags, every segment marked in turn with scratches, indentations, scrolls.



> The city’s gods, according to some people, live in the depths, in the black
> lake that feeds the underground streams. According to others, the gods live in
> the buckets that rise, suspended from a cable, as they appear over the edge of
> the wells, in the revolving pulleys, in the windlasses of the norias, in the
> pump handles, in the blades of the windmills that draw the water up from the
> drillings, in the trestles that support the twisting probes, in the reservoirs
> perched on stilts over the roofs, in the slender arches of the aqueducts, in
> all the columns of water, the vertical pipes, the plungers, the drains,

> the emperor is he who is a foreigner to each of his subjects, and only through
> foreign eyes and ears could the empire manifest its existence to Kublai. In
> languages incomprehensible to the Khan, the envoys related information heard in
> languages incomprehensible to them: from this opaque, dense stridor emerged the
> revenues received by the imperial treasury, the first and last names of
> officials dismissed and decapitated, the dimensions of the canals that the
> narrow rivers fed in times of drought.

> Perhaps, Kublai thought, the empire is nothing but a zodiac of the mind’s phantasms.



> Marco Polo imagined answering (or Kubiai Khan imagined his answer) that the
> more one was lost in unfamiliar quarters of distant cities, the more one
> understood the other cities he had crossed to arrive there; and he retraced the
> stages of his journeys, and he came to know the port from which he had set
> sail, and the familiar places of his youth, and the surroundings of home, and a
> little, square of Venice where he gambolled as a child. At this point Kublai
> Khan interrupted him or imagined interrupting him, or Marco Polo imagined
> himself interrupted, with a question such as: ‘You advance always with your
> head turned back?’ or ‘Is what you see always behind you?’ or rather, ‘Does
> your journey take place only in the past?’


> It is pointless to ask whether the new ones are better or worse than the old,
> since there is no connection between them, just as the old postcards do not
> depict Maurilia as it was, but a different city which, by chance, was called
> Maurilia, like this one.


> No one remembers what need or command or desire drove Zenobia’s founders to
> give their city this form, and so there is no telling whether it was satisfied
> by the city as we see it today, which has perhaps grown through successive
> superimpositions from the first, now undecipherable plan. But what is certain
> is that if you ask an inhabitant of Zenobia to describe his vision of a happy
> life, it is always a city like Zenobia that he imagines, with its pilings and
> its suspended stairways, a Zenobia perhaps quite different, a-flutter with
> banners and ribbons, but always derived by combining elements of that first
> model.



> the others tell, each one, his tale of wolves, sisters, treasures, scabies,
> lovers, battles. And you know that in the long journey ahead of you, when to
> keep awake against the camel’s swaying or the junk’s rocking, you start
> summoning up your memories one by one, your wolf will have become another wolf,
> your sister a different sister, your battle other battles, on your return from
> Euphemia, the city where memory is traded at every solstice and at every
> equinox.


> Kublai interrupted him: ‘From now I shall describe the cities and you will tell
> me if they exist and are as I have conceived them

> Abandoned before or after it was inhabited. Armilla cannot be called deserted

> A girl comes along, twirling a parasol on her shoulder, and twirling slightly
> also her rounded hips. A woman in black comes along, showing her full age, her
> eyes restless beneath her veil, her lips trembling. A tattooed giant comes
> along; a young man with white hair; a female dwarf; two girls, twins, dressed
> in coral. Something runs among them, an exchange of glances like lines that
> connect one figure with another and draw arrows, stars, triangles, until all
> combinations are used up in a moment, and other characters come on to the scene

> The ancients built Valdrada on the shores of a lake, with houses all verandas
> one above the other, and high streets whose railed parapets look out over the
> water. Thus the traveller, arriving, sees two cities: one erect above the lake,
> and the other reflected, upside-down



> Even when lovers twist their naked bodies, skin against skin, seeking the
> position that will give one the most pleasure in the other, even when murderers
> plunge the knife into the black veins of the neck and more clotted blood pours
> out the more they press the blade that slips between the tendons, it is not so
> much their copulating or murdering that matters as the copulating or murdering
> of the images, limpid and cold in the mirror.


> The city of Sophronia is made up of two half cities. In one there is the great
> roller-coaster with its steep humps, the carousel with its chain spokes,...The
> other half-city is of stone and marble and cement, with the bank, the
> factories, the palaces, the slaughterhouse, the school, and all the rest. One
> of the half-cities is permanent, the other is temporary, and when the period if
> its sojourn is over, they uproot it, dismantle it....And so every year the day
> comes when the workmen remove the marble pediments, lower the stone walls, the
> cement pylons, take down the Ministry, the monument, the docks, the petroleum
> refinery, the hospital, load them on trailers, to follow from stand to stand
> their annual itinerary. ..

> then the whole citizenry decides to move to the next city, which is there
> waiting for them, empty and good as new; there each will take up a new job, a
> different wife, will see another landscape on opening his window, and will
> spend his time with different pastimes, friends, gossip. So their life is
> renewed from move to move, among cities whose exposure or declivity or streams
> or winds make each site somehow different from the others.


> have constructed in my mind a model city from which all possible cities can be
> deduced,’ Kublai said. ‘It contains everything corresponding to the norm. Since
> the cities that exist diverge in varying degree from the norm, I need only
> foresee the exceptions to the norm and calculate the most probable
> combinations.’ ‘I have also thought of a model city from which I deduce all the
> others’ Marco answered, ‘It is a city made only of exceptions, exclusions,
> incongruities, contradictions. If such a city is the most improbable, by
> reducing the number of elements, we increase the probability that the city
> really exists. So I have only to subtract exceptions from my model, and in
> whatever direction I proceed, I will arrive at one of the cities which, always
> as an exception, exist. But I cannot force my operation beyond a certain limit:
> I would achieve cities too probable to be real.’


> This is the foundation of the city: a net which serves as passage and as
> support. All the rest, instead of rising up, is hung below...

> You reach a moment in life when, among the people you have known, the dead
> outnumber the living. And the mind refuses to accept more faces, more
> expressionsSuspended over the abyss, the life of Octavia’s inhabitants is
> less uncertain than in other cities. They know the net will last only so
> long.

> Besides, the more Leonia’s talent for making new materials excels, the more
> the rubbish improves in quality, resists time, the elements, fermentations,
> combustions. A fortress of indestructible leftovers surrounds Leonia,
> dominating it on every side, like a chain of mountains.


> 'Why is Thekla’s construction taking such a long time?’ the inhabitants
> continue hoisting sacks, lowering leaded strings, moving long brushes up and
> down, as they answer, ‘So that its destruction cannot begin.’ And if asked
> whether they fear that, once the scaffolding is removed, the city may begin to
> crumble and fall to pieces, they add hastily, in a whisper, ‘Not only the
> city.’

>  It is not the voice that commands the story: it is the ear.’

# Associativity of addition in cubicaltt

Let's first understand what we need to prove. we're trying to prove that addition is associative. addition is defined as follows:

```
data nat = zero | suc (n : nat)

-- recursive on right argument
add (m : nat) : nat -> nat = split
  zero -> m
  suc n -> suc (add m n)
```

Since `add` is recursive on the right, we can simplify (by computation) values such as `add x (S y)` to `S (add x y)`. This will be important when reasoning about induction later.

Now, we wish to prove that:



```
for all a b, c, 
  a + (b + c) = (a + b) + c
```


we prove this by induction on `c`. Let's consider the base case and the inductive case:

```
-- BASE CASE:
-- a + (b + 0) = (a + b) + 0
-- [computation]: a + (b) = (a + b)
```

By computation on the base case, we simplify `(b+0)` to `b`, and we similary simplify `(a + b) + 0` to `(a + b)`. So we're really asked to prove `add a b  = add a b` which is trivial (by reflexivity).

Next, let's think of the inductive case, where we suppose `c = S n`
and then simplify what we have to prove to a normal form:

```
-- INDUCTIVE HYPOTHESIS: let c = S n:
-- a + (b + S n) = (a + b) + S n
-- =[computation]: a + (S (b + n)) = (a + b) + S n
-- =[computation]: S (a + (b + n)) = (a + b) + S n
-- =[computation]: S (a + (b + n)) = S ((a + b) + n)
```

We see that after simplification by computation, we need to prove that
`S (a + (b + n)) = S ((a + b) + n`. The core idea is to use associativity
to prove that `(a + (b + n)) = ((a + b) + n)` and to then stick a `S _` on it, giving `S (a + (b + n)) = S ((a + b) + n)`. In a cubical diagram, this looks like:

```
-- j=1
--  ^  S(a+(b+n)) - -- -- -- -- -- - S((a+b) + n)
--  |  ^                                 ^
--  |  |                            <j> suc (add (add a b) n)
--  |  |                                 |
--  |<j> suc(add a (add b n))            |
--  |  |                                 |
--  |  |                                 |
--  |  S(a+(b+n)) ---------------------> S((a+b)+n)
--  |           suc (add A a b n @ i)
-- j=0
-- i=0 -------------------------------> i=1
```

- The bottom horizontal line is the first to `comp`, given as `(suc (addA a b n @ i))` 

And in cubical code, it's written as:

- The left and right vertical lines are the second inputs to comp.
- The left vertical line is given by `<j> suc (add a (add b n)`
- The right vertical line is given by ` <j> suc (add (add a b) n)`.

In total, the implementation is:

```
addA (a b: nat) :
  (c: nat) -> Path nat (add a (add b c))
                       (add (add a b) c) = split
  zero -> <i> add a  b
  suc n -> <i> comp (<i> nat) (suc (addA a b n @ i))
                [ (i = 0) -> <j> suc (add a (add b n))
		        , (i = 1) -> <j> suc (add (add a b) n)]

```

**EDIT:** I now realise that we do not need to use `comp` since both the left and right edges of the square are constant. We can implement the above as:

```
addA (a b: nat):
  (c: nat) -> Path nat (add a (add b c))
                       (add (add a b) c) = split
  zero -> <i> add a  b
  suc n -> <i> (suc (addA a b n @ i))
```


# Etymology of fiber bundle $F \rightarrow E \rightarrow B$


The $F$ stands for fibre, $E$ for ensemble (total space), and $B$ for base space,
as told in this [math.stackexchange answer](https://math.stackexchange.com/questions/4165418/etymology-of-mathbfbg-for-category-of-one-object-for-g/4165440#4165440)

# Galois correspondence, functorially

For a given group $G$, build the category of subgroups as follows:
The objects aren't exactly subgroups, but are isomorphic to them ---
for each coset $H$, the category has the object as the coset space $G/H$,
equipped with the left-action of $G$ on the coset space . The morphisms
between $G/H$ and $G/K$ are the intertwining maps $\phi: G/H \rightarrow G/K$
which commute with the action of $G$: $(g \times ) \circ \phi = \phi \circ (g \times )$.


We first work out what it means to have such an intertwining map. Suppose we pick 
a coset of $H$, which is an element of the coset space $\alpha H \in G/H$ for some $\alpha \in G$.
Now the intertwining condition says that $\phi(g \alpha H) = g \phi(\alpha H)$. If we pick
$\alpha = e$, then we get $\phi(g H) = g \phi(H)$. Thus, the intertwining map 
is entirely determined by where it sends $H$, ie, the image $\phi(H)$.


Now, let the image of $\phi(H)$ be some coset $\gamma K \in G/K$. Suppose
that the coset $gH = g'H$, since writing a coset as $gH$ is not unique. Apply $\phi$
to both sides and use that $\phi$ is intertwining. This gives
$\phi(gH) = g \phi(H) = g \gamma K$ and $\phi(g'H) = g'\phi(H) = g' \gamma K$.
For these to be equal, we need $\gamma^{-1} g'^{-1} g \gamma  \in K$. But since
$gH = g'H$, we know that this is equivalient to $g g'^{-1} \in H$. Thus, the above condition becomes
equivalent to $\forall h \in H, \gamma^{-1} h \gamma \in K$.

So we now have a category whose objects are coset spaces and whose morphisms are intertwining maps.
We now consider the category of a given field extension $L/F$, which has objects intermediate fields
between $L$ and $F$, and has morphisms as field morphisms which fix $F$.


# CubicalTT: sharpening thinking about indexed functions


```
-- | function from nat to nat defined by lambda abstraction
f1 : nat -> nat -> nat = \(b: nat) -> \(c : nat) ->  b
```

```
-- | function from nat, nat -> nat defined by case analaysis
f2 : nat -> nat -> nat =
  split
    zero -> split@(nat -> nat) with 
                zero -> zero
                suc b' -> zero
    suc a' -> split@(nat -> nat) with 
                zero -> a'
                suc b' -> b'
```

```
-- | parametrized family of nats, defined by definition.
g1 (b : nat) (c : nat) : nat = b
```



```
-- | Family of nat parameterized by `(x: nat), `(y: nat)
-- | cannot split on parameters, can only split on fn.
-- g2 (x : nat) (y : nat) : nat =
--   split
--     zero -> split@(nat -> nat) with 
--                 zero -> zero
--                 suc b' -> zero
--     suc a' -> split@(nat -> nat) with 
--                 zero -> a'
--                 suc b' -> b'
```

# Functors to motivate adjuntions

- Consider the category $Set^\partial$ of sets with partial functions
  as morphisms, and the category $Set^*$, the category of pointed sets and
  and basepoint-preserving functions as morphisms.
- The functor $F: Set^\partial \rightarrow Set^*$
  sends sets to set-with-basepoint. To be very precise about basepoint considerations,
  since this is where the non-inversion will lie, let us say that for a set $X$, we add a basepoint $\{X \}$.
  So, the functor $F$ sends a set $X$ to the set `a = {X} in (X U {a}, a)`, which 
  expanded out is $(X \cup \{ \{ X \} \}, \{ X \})$. The functor $F$ sends a partial function
  $f: A rightharpoonup B$ to based function by defining $F(f): F(A) \rightarrow F(B)$
  which sends undefined values $a$ to $\{B\} \in F(B)$, and is forced by definition sends the basepoint $\{ A \} \in F(A)$ to $\{ B \} \in F(B)$.
- The "inverse" functor $G: Set^* \rightarrow Set^\partial$ forgets the basepoints, and sends
  a function $h: (A, a) \rightarrow (B, b)$
  to the partial function $G(h): A \rightarrow B$ by not mapping those elements in the domain
  which were mapped to $b$ by $h$.
- Going from a partial function $f$ to a bottomed function $F(f)$ and then back again
  to partial function $G(F(f))$ forgets no information.
- On the other hand, going from a basepointed set $(A, \bot)$ for some arbitrary basepoint $\bot$
  will return a set with a _different_ basepoint, $(A/ \bot \cup \{ \{ A/\bot \} \}, \{ A/\bot \})$. Note that the sets
  $(A, \bot)$ and $A/\bot \cup \{ \{ A/\bot\} \}$ are isomorphic, but not equal!


```
G(F((A, a)))
= let x = remove A a in G(x)
= let x = remove A a;
      botnew = set([x]) in insert x botnew
-- | adds the set (A - a) as an element of (A - a)
= insert (remove A a) (remove A a)

```

Thus, we should come up with a weaker notion of equality : Adjoints!

# Madoka Magica: plot thoughts

- I wonder whether incubator ~ Kyubey ~ kyubii ~ nine-tails.
- Homura is such a tragic character. 


# Chain rule functorially

- The first category is $Euc^*$, whose objects are pointed subsets of Euclidean space.
   So, the objects are of the form $(U \subseteq \mathbb R^n, a \in U)$. Morphisms
  are based smooth functions between these opens: smooth functions $f: U \rightarrow V$
  such that $f(a) = b$.
- The second category is $M$
 whose objects are natural numbers and morphisms $n \to m$ are matrices of 
 dimension $n \times m$.
- Define a functor $d: Euc \to M$ which
  sends subsets to the dimension of the space they live in: $U \subseteq \mathbb R^n, a) \to n$,
  and sends smooth functions $f: (U, a) \rightarrow (V, b)$ to their Jacobian evaluated at the
  basepoint, $J_f|_a$.
- Functoriality asserts that the jacobian of the composition of the two functions is a matrix
  multiplication of the jacobians.

Let's think through the functoriality. It says that if we have two arrows which can be composed,
$(f, a)$ and $(g, f(a))$ -- note that it has to be $(g, f(a))$ because only compatible basepoint
functions can be composed. 


I feel like we shouldn't use natural numbers for $M$, but we should rather use real vector spaces.
And as for $Euc$, we should replace this with $ManOpen$ where we use based
"charted" opens of a differentiable manifold.  This makes the diffgeo clear!

# Lagrange multipliers by algebra

#### Constrained optimisataion: the first stab

We want to maximize $z = f(x, y)$ given the constraint that $g(x, y) = 0$.
Let us arbitrarily say that $x$ is independent and $y$ is dependent on $x$, so there
is some function $t$ such that $y = t(x)$. This lets us compute $dy/dx$ using:

$$
\begin{aligned}
& g(x, y) = 0\\
&\frac{d g(x, y)}{dx}  = d0 = 0\\
&\frac{\partial g}{\partial x} + \frac{\partial g}{\partial y}\frac{dy}{dx} = 0 \\
&\frac{dy}{dx} = - \frac{\partial g/\partial x}{\partial g/\partial y}
\end{aligned}
$$

Next, since $z$ is a function of $x$ alone (as $y$ is dependent on $x$ via $t$), the condition
$dz/dx = 0$ guarantees a maxima for $z$:

$$
\begin{aligned}
&\frac{dz}{dx} = 0 \\
&\frac{\partial f}{\partial x} + \frac{\partial f}{\partial y}\frac{dy}{dx} = 0 \\
&\frac{\partial f}{\partial x} + \frac{\partial f}{\partial y} \frac{\partial g/\partial x}{\partial g/\partial y} = 0 \\
\end{aligned}
$$

Solving the above condition along with $g(x, y) = 0$ to recover the value of $y$ gives us the optima.

#### Constrained optimisataion: equal footing


$$
F(x, y, \lambda) = f(x,y) + \lambda g(x, y)
$$

If we consider the stationary value of $F$, we get:

$$
\begin{aligned}
&\frac{\partial F}{\partial x} = \frac{\partial f}{\partial x} + \lambda \frac{\partial g}{\partial x} = 0 \\
&\frac{\partial F}{\partial y} = \frac{\partial f}{\partial y} + \lambda \frac{\partial g}{\partial y} = 0 \\
&\frac{\partial F}{\partial \lambda} = \frac{\partial f}{\partial x} + \lambda \frac{\partial g}{\partial x}
\end{aligned}
$$

to eliminate $\lambda$ from the above equations, we rearrange:


$$
\begin{aligned}
&\frac{\partial f}{\partial x}/\frac{\partial g}{\partial x}  = \lambda\\
&\frac{\partial f}{\partial y}/\frac{\partial g}{\partial y}  = \lambda \\
\end{aligned}
$$

This $\lambda$ can be eliminated to recover the previous equation:

$$
\begin{aligned}
&\frac{\partial f}{\partial x}/\frac{\partial g}{\partial x}  = &\frac{\partial f}{\partial y}/\frac{\partial g}{\partial y} \\
&\frac{\partial f}{\partial x} =  \frac{\partial g}{\partial x} \frac{\partial f}{\partial y}/\frac{\partial g}{\partial y} \\
&\frac{\partial f}{\partial x} - \frac{\partial g}{\partial x} \frac{\partial f}{\partial y})/\frac{\partial g}{\partial y}  = 0 \\
\end{aligned}
$$


The langrange multipler procedure is nice since it does not break the symmetry between the two variables.


# Specht module construction

#### $A[\lambda][t]$, and its image

Define 

$$
A[\lambda][t](x) \equiv \sum_{\pi \in C[t]} sgn(\pi) \pi(x).
$$

That is, $A[\lambda][t]$ creates a signed linear combination of $x$ by creating signed orbits of $x$ under the
column stablizier of $t$. 


First consider

$$
A[\lambda][t](t) = \sum_{\pi \in C[t]} sgn(\pi) \pi(t).
$$

We claim that $A[\lambda][t]$ is
a projection operator which projects onto the subspace spanned by $A[\lambda][t](t)$. To show this,
let's consider the action of $A[\lambda][t]$ on some other tabloid $s$. 


There is a predicate we are
interested in that determines whether $A[\lambda][t](x)$ is $0$ or $\pm t$: If $t$ has two elements $a, b$
that are in the same column of $t$, which are in the same row of $x$. If such elements $a, b$ exist, then 
the action of $\texttt{swap}(a, b)$ is trivial on $x$, as tabloids are invariant under row permutations. Furthermore,
$\texttt{swap}(a, b)$ is in the column stabilizer $C[t]$, since $a, b$ are in the same column of $t$. Exploiting
this, we write the group $C[t]$ as cosets of the subgroup $H \equiv \{ id, \texttt{swap}(a, b) \}$. Now the magic
happens: the action on $x$ via $H$ turns out to be zero:

$$
\begin{aligned}
&\sum_{\pi \in H} sgn{\pi} \pi(x) \\
&= id(s) - \texttt{swap}(a, b)(x) \\
&= x - x = 0
\end{aligned}
$$

Since $C[t]$ partitions as cosets of $H$, the entire action of $C[t]$ on $x$ becomes zero:

$$
\begin{aligned}
&\sum_{\pi \in C[t]} sgn{\pi} \pi(x) \\
&= \sum_{\pi \in C[t]/H} (\pi \cdot id)(x) - (\pi \cdot \texttt{swap}(a, b))(x) \\
&= \sum_{\pi \in C[t]/H} (\pi  \cdot id) (x) - (\pi \cdot \texttt{swap}(a, b))(x) \\
&= \sum_{\pi \in C[t]/H} \pi  \cdot (id(x) - \texttt{swap}(a, b)(x)) \\
&= \sum_{\pi \in C[t]/H} \pi (id(x) - \texttt{swap}(a, b)(x)) \\
&= \sum_{\pi \in C[t]/H} \pi (x - x) \\
&= \sum_{\pi \in C[t]/H} \pi (0) = 0
\end{aligned}
$$


On the other hand, let us assume that elements in the same column of $t$ are always in different rows $x$ [
if they are in the same row, then the action is zero as we saw before.] Let us focus on the $c$th column of $t$:
say the elements in this column are $t[1][c], t[2][c], \dots, t[n][c]$. These elements will be in different rows of $x$.
Since we can freely permute rows, we can move these elements $t[:][c]$ to the $c$th column _of_ $x$. This makes column $x[:][c]$
of $x$ be a permutation of the $t[:][c]$ column of $t$. Now, there is a unique permutation which permutes every column of $x$
to be like the columns of $t$. Thus, there is a unique permutation $\pi \in C[x]$ such that $\pi(x) = t$. We can invert this,
to find a permutation $\pi' \equiv \pi^{-1} \in C[t]$ such that $\pi'(t) = x$. This will force the value of $A[\lambda][t](x)$ to be
equal to $\pm A[\lambda][t](t)$, since $x$ differs from $t$ by a permutation:

$$
\begin{aligned}
&A[\lambda][t](x) = \\
&= A[\lambda][t](\pi' t) \\
&= \sum_{\sigma \in C[t]} sgn(\sigma) \sigma(\pi' t) \\
&= \sum_{\sigma \in C[t]} sgn(\sigma) (\sigma \circ \pi') t) \\
&= \sum_{\sigma \circ \pi \in C[t]} sgn(\sigma) sgn(\pi') sgn(\pi') (\sigma \circ \pi') t) \\
&=  sgn(\pi') \sum_{\sigma \circ \pi \in C[t]} sgn(\sigma \circ \pi) (\sigma \circ \pi') t) \\
&= sgn(\pi') \sum_{\sigma' \in C[t]} sgn(\sigma') \sigma'(t) \\
&= sgn(\pi') A[\lambda][t](t)
\end{aligned}
$$

Thus, we find that when $A[\lambda][t]$ acts on a tableaux $x$, the result is either $0$ [when $x$ cannot be obtained by a column permutation of $t$],
or is $\pm A[\lambda][t](t)$ [when $x$ can be ontained by a column permutation of $t$]. Thus, the image of $A[\lambda][t]$
is a 1-dimensional subspace spanned by $A[\lambda][t](t)$. So the important property that we have uncovered is that $A[\lambda][t](x)$
is non-zero iff $t$'s columns can be permuted to produce $x$: written formally, we have:

$$
\begin{aligned}
&A[\lambda][t](x) \neq 0 \iff \exists \pi \in C[t], \pi(t) = x \\
&A[\lambda][t](x) = 0 \iff \not \exists \pi \in C[t], \pi(t) = x \\
\end{aligned}
$$

#### Inner product and $A[\lambda][t]$ is self adjoint

We impose the "canonical" inner product on the space of vectors spanned by tabloids, given
by making all non-equal basis tabloids orthogonal:

$$
\langle \{t\} | \{t'\} \rangle \equiv 
\begin{cases}
1 & \{t \} \simeq \{ t' \} \\
0 & \text{otherwise}
\end{cases}
$$

Under this inner product, we claim that $A[\lambda][t]$ is self-adjoint:
we have that $\langle A[\lambda][t](x), y \rangle = \langle x, A[\lambda][t](y) \rangle$. The key idea is that $A[\lambda][t](y)$
is made up of permutations which are unitary, since they simply permute the orthogonal basis vectors,
and these permutations are arranged in $A[\lambda][t]$ such that the $A[\lambda][t]$ operator is self-adjoint:


$$
\begin{aligned}
&\langle A[\lambda][t](x) | y \rangle \\
&= \langle \sum_{\pi \in C[t]} sgn \pi  \pi(x) | y \rangle \\
&= \sum_{\pi \in C[t]} sgn \pi \langle  \pi(x) | y \rangle \\
&\text{($\pi^{-1}$ is a permutation of orthonormal basis, hence orthogonal)} \\
&\text{($\pi^{-1}$ preserves inner produce as orthogonal):} \\
&= \sum_{\pi \in C[t]} sgn \pi \langle \pi^{-1} \pi(x) | \pi^{-1} y \rangle \\
&= \sum_{\pi \in C[t]} sgn \pi \langle \pi^{-1} \pi(x) | \pi^{-1} y \rangle \\
&= \sum_{\pi \in C[t]} sgn \pi \langle x | \pi^{-1} y \rangle \\
&\text{(Sum over $\pi^{-1}$, is an automorphism:)} \\
&= \sum_{\pi^{-1} \in C[t]} sgn \pi^{-1} \langle x | \pi^{-1} y \rangle \\
&= \langle x | \sum_{\pi^{-1} \in C[t]} sgn \pi^{-1}   \pi^{-1} y \rangle \\
&= \langle x | A[\lambda][t](y) \rangle \\
\end{aligned}
$$


#### $S[\lambda]$ is a irreducible subspace of $M[\lambda]$

- Define the subspace spanned by $\{ A[\lambda][t] : t \in \texttt{tabloid}(\lambda) \}$ as $S[\lambda]$ (for Specht).
  Thus, the $A[\lambda][t]$ span $S[\lambda]$.
- $S[\lambda]$ is invariant under $S[n]$, since the action of $\pi \in S[n]$ on $A[\lambda][t]$ 
  sends $A[\lambda][t]$ to $A[\lambda][\pi(t)]$. Also, the full space $M[\lambda]$ is invariant under $S[n]$ by construction.
- The orbit of any $A[\lambda][t]$ under $S_n$ gives us the full set $\{ A[\lambda][t'] : t' \in \texttt{tabloid}$, since we can produce
   $A[t']$ from $A[t]$ by the action that permutes $t$ into $t'$.
- For all invariant subspace $U$, $U$ is either disjoint from $S[\lambda]$ or $U$ contains $S[\lambda]$. So it is impossible
  to reduce $S[\lambda]$ into a smaller invariant subspace $U$.
- Consider some invariant subsepace $U$. If it is disjoint from $S[\lambda]$, then we are done.
- Otherwise, assume there is some $x \in S[\lambda] \cap U$. 
- As $x \in S[\lambda]$ and $S[\lambda]$ is spanned by $\{ A[\lambda][t](t) : t \in \texttt{tabloid} \}$, there must be some $t'$ along which $x$ has a component:
  $\langle x | A[\lambda][t'](t') \rangle \neq 0$.
- Since $A[\lambda][t']$ is symmetric, I can write the above as $\langle A[\lambda][t'](x) | t' \rangle \neq 0$.
  Now since the image of $A[\lambda][t']$ is the subspace spanned by $t'$, since $U$ is invariant under $A[\lambda][t']$,
  and since $\langle A[\lambda][t'](x) | t' \rangle \neq 0$, we can say that $A[\lambda][t'](x) = \alpha t' \in U$ for $\alpha \neq 0$.
  This tells us that we have the vector $t' \in U$.
- Once we have a _single_ $t' \in U$, we win, since all the other $t$'s are obtained as permutations of $t'$, and $U$ is an invariant
  subspace of these permutations.
- TLDR: if we havs some common vector $x \in S[\lambda] \cap U$, then $\langle x | A[\lambda][t](t) \rangle \neq 0$. By
  self-adjoint, we get $\langle  A[\lambda][t](x) | t \rangle \neq 0$. But $A[\lambda][t](x) = k_{t, x} A[\lambda][t](t)$, hence $k_{t, x} \neq 0$.
  Further, $A[\lambda][t](x) \in U$ since $U$ is invariant and $x \in U$, hence $k_{t, x} A[\lambda][t](t) \in U$ for $k_{t, x} \neq 0$ hence $A[\lambda][t](t) \in U$.
  This forces all of $S[\lambda] \in U$, since $U$ is invariant and $S[\lambda]$ is generated by the various $\{ A[\lambda][t](t) : t \texttt{tabloid} \}$,
  which are obtained by permutation of of $A[\lambda][t](t)$ for a given $t$.

#### The argument, in the abstract

Let $V$ be a finite dimensional real vector space with inner product $\langle \cdot | \cdot \rangle$.
Let $H: V \rightarrow V$ be a symmetric operator with rank 1 image, eigenvector $h \in V$.
For simplicity, say that the eigenvalue of $h$ is $1$, so $H h= h$.
($H$ Hermitian is defined as $\langle Hx | y \rangle = \langle x | H y \rangle$)
Let $\mathcal O$ be a group of orthogonal matrices.  Define a subspace $S$ of $V$ given
by the $\mathcal O$-span of the image of $H$: $S \equiv span(\{ O h : O \in \mathcal O\})$.

We wish to show that $S$ is an irreducible $\mathcal O, H$-invariant subspace. By construction, $S$ is $\mathcal O, H$-invariant,
since it takes the subspace spanned by $h$ and makes it invariant under $\mathcal O$.
To show that this is irreducible, suppose we have some $\mathcal O, H$ invariant subspace $W$. We wish to show
that if $W$ contains a single vector from $S$, then it contains all of $S$: $W \cap  S \neq \emptyset \implies S \subset W$.

- Suppose that $x \in W \cap S$. Since $S$ is spanned the various $\mathcal O h$, there must be some $O \in \mathcal O$
  such that $\langle x | O h \rangle \neq 0$.
- Since $O$ is orthogonal, we can shift the rotation towards $x$ by rotating the entire frame by $O^{-1}$,
  giving us $\langle O^{-1} x | h \rangle \neq 0$. 
- Since $h$ is an eigenvector, we replace $h$ by $H h$ giving us $\langle O^{-1} x | H h \rangle \neq 0$.
- Since $H$ is hermitian, I rewrite the above as $\langle H O^{-1} x | h \rangle \neq 0$.
- Since $x \in W$ and $W$ is invariant under $\mathcal O$ and $H$, we have that $H O^{-1} x \in W$.
- Also, since the image of $H$ lies entirely along $h$, we have that $H O^{-1} x = \alpha_x h$. 
  Combining with $\langle H O^{-1} x | h \rangle \neq 0$ gives us $\langle \alpha_x h | h \rangle \neq 0$,
  or $\alpha \neq 0$.
- Thus, the **non-zero** vector $\alpha_x h \in W$ (non-zero as $\alpha_x \neq 0$). Hence, the vector $h \in W$.
  Since $W$ is closed under $\mathcal O$ and $S$ is generated as $\mathcal O h$, we have that $S \subseteq W$.

##### Showing that $H$ as thesigned linear combination of $\mathcal O$ is Hermitian

In the abstract, we define $H \equiv \sum_{O \in \mathcal O} |O| O$, which specializes
to $H_t \equiv \sum_{\pi \in C_t } \pi sgn(\pi)$ in the tableaux theory. Now consider
$H^T = \sum_{O \in \mathcal O} |O| O^T$ Since $O$ is orthogonal, $O^T = O^{-1}$. Furthermore,
we have that $|O| = |O|^{-1}$ since:

$$
\begin{aligned}
&|O| = \pm 1 \\
|O^{-1}|  = |O|^{-1} \\
&= (\pm 1)^{-1} = \pm 1
\end{aligned}
$$

Combined, this tells us that $H^{T} = \sum_{O \in \mathcal O} |O|^{-1} O^{-1}$. Since $\mathcal O$
is a subgroup, the sum can be re-indexed to be written as $H^{T} = \sum_{O' \in \mathcal O} |O'| O'$,
which is equal to $H$. Hence, we find that $H^T = H$, or $H$ defined in this way is hermitian.


##### Showing that $H$ is rank 1

In the symmetric group case, we consider:

$$A_x \equiv \sum_{\sigma \in C_t} sgn(\sigma) \sigma$$

Now say we have some other $y$. The two cases are:

- $y \in Orb(x, C_x)$. We have $y = \pi x$ for $\pi \in C_x$ In this case, the expression for $A_x y$ can be written as $A_x (\pi x)$
  which is equal to $sgn(\pi) A_x(x)$. So this belongs to the subspace of $A_x(x)$.
- $y \not \in Orb(x, C_x)$. This means that we cannot rearrange the columns of tabloid $x$ to get tabloid $y$ (upto row permutation).
- That is, we have:

```
xa -> 1
xb -> 1
xc -> 2
```

- where two elements in the same column of $x$ `(xa, xb)` want to go to the same row of $y$. If all elements
  in the same column of $x$ `(xa, xb, xc)` wanted to go to different rows of $y$ `(3, 1, 2)`, we could have
  permuted $x$ in a *unique* way as `(xb, xc, xa)` to match the rows. This tells us how to convert $x$ into $y$,
  for this column. If we can do this for all columns, we are done.
- The only obstruction to the above process is that we have two elements in the same column of $x$ `(xa, xb)` that
  want to go to the same row of $y$. Said differently, there is a permutation $p$ that swaps `xa <-> xb` that is in
  $C_x$ (since `(xa, xb)` are in the same column), whose action leaves  $y$ unchanged (since $y$ a tabloid has
  these elements in the same row; tabloid invariant under row permutation).
- Thus, we can write $C_t$ as cosets of the subgroup $\{e, p\}$ whose action of $y$ will be:

$$
\begin{aligned}
&(sgn(e) e +sgn(p) p)(y) \\
&(e - p)(y) \\
&y - y = 0
\end{aligned}
$$

- Thus, the action of the full $C_t$, written as cosets of $\{ e, p\}$ cancels out entirely and becomes zero, since every coset
  is of the form $h\{e, p\}$, ie $\{h, hp\}$. And the action of this will be:

$$
\begin{aligned}
&(sgn(h)h + sgn(hp)hp)y \\
&=sgn(h) hy + sgn(h)(-1) hp y \\
&=sgn(h) hy - sgn(h) hp y \\
&=sgn(h) hy - sgn(h) hy \\
&=0 
\end{aligned}
$$

- Thus, either an element $y$ is in the orbit $C_x$ or not. If it's in the orbit, we get answer $\pm A_x x$. If it's not, we get zero.


#### Have we found all the irreps?

Recall that the number of irreps is upper bounded by the number of conjugacy classes of the group. This follows
from character theory: (1) the characters of irreps are orthogonal in the space of class functions, and
(2) the dimension of the space of class functions is is equal to the number of conjugacy classes, since there
are those many degrees of freedom for a class function --- it must take on a different value per conjugacy class
[WIP: finish my character theory notes]. In our case, we have found one irrep per conjugacy class, since
conjugacy classes of $S_n$ is determined by cycle type, and the shape of a diagram encodes the cycle type of
a permutation. If we show that the irreps of different shapes/diagrams are inequivalent, we are done.


#### Characterizing Maps $M[\lambda]$ to $M[\mu]$ 

We wish to prove the key lemma, which is that if we have a non-zero map $f: M[\lambda] \rightarrow M[\mu]$,
then $\lambda \trianglerighteq \mu$. Let's consider the extreme cases with 3 elements:

```
λ = (1 1 1):
* * *
```

```
μ = 3:
#
#
#
```

- Let $l$ be a $\lambda$ tableau, $m$ be a $\mu$ tableau. 
- Let's consider $A[l](m)$ and $A[m](l)$.
- For $A_l(m)$ to be non-zero, we need a way to send elements of $m$ in the same column (`#; #; #`) to correct rows in $l$ (`* * *`)But see that $l$
  has only one row, and $m$ has no choice: it must send all its elements in all columns to that single row of $l$. Thus, the $C_l$ [WRONG]
  don't hinder us from doing the only thing we possibly can. 
- For $A_m(l)$ to be non-zero, we need a way to send elements of $l$ in the same column, of which there are three columns, `*`, `*`, `*`, to different rows of
  $m$. But if $l$ were feeling stubborn, it could say that it wants each of its `*`'s to end up in the first row of $m$. $m$ will be overcrowded, so this
  leads to the map becoming zero.
- In general, if $\lambda \triangleright \mu$, then the map $A[\lambda](\mu)$ can be nonzero, since we need to send elements in the same column of $\mu$ to different
  rows of $\lambda$, and $\lambda$ is "bigger", [WRONG?!]


Thus, we have found ALL irreps, since as argued before, there can be at most as many irreps as there are shapes/diagrams of $n$,
and we've shown that each irrep that corresponds to a shape is distinct.

#### All the $S[\lambda]$ are distinct irreps of $S_n$ by Schur's lemma

Suppose that $S[\lambda] \simeq S[\mu]$. Thus we have an invertible intertwining map $T: S[\lambda] \rightarrow S[\mu]$.
By Schur's lemma, since we know that $S[\lambda]$ and $S[\mu]$ are irreps,
we know that $T$ is a scalar multiple of the identity map. Let $m$ be a tabloid of shape $\mu$.
We know that $A[\mu][m](m) \in S[\mu]$. Now consider $T^{-1}(A[\mu][m](m))$. This must be
equal to $A[\mu][m](T^{-1}(m))$. This means that $T^{-1}(m)$ is not zero when acted upon
by $A[\mu][m](m)$, thus $T^{-1}(m)$, of shape $\lambda$ must dominate shape $\mu$
[Argue why this is the case by adapting the proof seen before about spaces].


Ruunning the argument is reverse, we get both directions of $\lambda \trianglerighteq \mu$ and $\mu \trianglerighteq \lambda$,
there by establishing $\lambda = \mu$.

#### Working it out for S3

##### `Tabloid(3)`

There's only one tabloid of shape `3`, which is `{1 2 3}`. Thus we get a 1D complex vector space with
basis vector `b{1, 2, 3}`. Every permutation maps `b{1, 2, 3}` onto itself, so we get the trivial
representation where each element of `S3` is the identity map.


##### `Tabloid(2, 1)`

There are three tabloids of shape `(2, 1)`, one for each unique value at the bottom. The top row can be
permuted freely, so the only choice is in how we choose the bottom. We get the tableaux
`{1 2}{3}` = `[1 2][3]` =  `[2 1][3]`, drawn as:

```
[1 2] = [2 1] = {1 2}
[3]     [3      {3}
```

And similarly we get `{1 3}{2}` and `{1 2}{3}`. So we have a three dimensional vector space.
Now let's look at the action of the `A` operator `A: Tableaux -> GL(V(Tabloid(mu))`. First of all,
we see that the `A` operator uses _tableaux_ and not _tabloids_ (because we
need to know which elements are in the same column).
Recall that the action of `A(t)` on a tabloid `x` is to sum up linear combinations of $sgn(\pi)\pi(x)$,
where $\pi$ is from the column stabilizer of `t`. 

$$
A(t)(x) \equiv \sum_{\pi \in \texttt{col-stab}(t)} sgn(\pi) \pi(x)
$$

So let's find the action! The tableaux `[1 2][3]`, ie:

```
[1 2]
[3]
```

has as column stabilizers the identity permutation, and the
permutation `(1 3)` obtained by swapping the elements of the columns `[1..][3]`
Thus, the action of `A([1 2][3])` on a tabloid `{k l}{m}` 
is the signed linear combination of the action
of the identity and the swap on `{k l}{m}`:

$$A([1 2][3])(\{ k l \}\{m \}) = 1 \cdot \{k l\}\{m\} + (-1) \cdot {m l}{k} $$


Recall that the basis of the Specht module is given by `A([t])({t})`, where we have the tableaux `t`
act on its own tabloid. In the case where `t = [1 2][3]` we get the output 

```
A([1 2][3])({1 2}{3}) = {1 2}{3} - {3 1}{2}
```

Similarly, we tabulate all of the actions of `A(x)({x})` below, where we 
pick the equivalence class representative of tabloids as the tabloid whose
row entries are in ascending order.


```
A([1 2][3])({1 2}{3})
  = (id - (1, 3))({1 2}{3})
  = {1 2}{3} - {3 1}{2}
  = {1 2}{3} - {1 3}{2}
```

```
A([2 1][3])({2 1}{3}) 
  = A([2 1][3])({2 1}{3})
  = A([2 1][3])({1 2}{3})
  = (id - (2, 3))({1 2}{3})
  = {1 2}{3} - {1 3}{2}
```


```
A([1 3][2])({1 3}{2}) 
  = (id - (1, 2))({1 3}{2})
  = {1 3}{2} - {2 3}{1}
```

```
A([3 1][2])({3 1}{2}) 
  = (id - (3, 2))({3 1}{2})
  = (id - (3, 2))({1 3}{2})
  = {1 3}{2} - {1 2}{3}
```

```
A([1 2][3])({1 2}{3}) 
  = (id - (1, 3))({1 2}{3})
  = {1 2}{3} - {3 2}{1}
  = {1 2}{3} - {2 3}{1}
```

```
A([2 1][3])({2 1}{3}) 
  = (id - (2, 3))({2 1}{3})
  = (id - (2, 3))({1, 2}{3})
  = {1 2}{3} - {1 3}{2}
```

If we now label the vector as `{2 3}{1} = a`, `{1 3}{2} = b`, `{1 2}{3} = c`, written
in ascending order of the element of their final row, we find that `A(x)(x)` gave us the vectors:

```
A([1 2][3])({1 2}{3})
  = {1 2}{3} - {1 3}{2} = c - b
A([2 1][3])({2 1}{3}) 
  = {1 2}{3} - {1 3}{2} = c - b
A([1 3][2])({1 3}{2}) 
  = {1 3}{2} - {2 3}{1} = b - a
A([3 1][2])({3 1}{2}) 
  = {1 3}{2} - {1 2}{3} = b - c = -(c-b)
A([1 2][3])({1 2}{3}) 
  = {1 2}{3} - {2 3}{1} = c - a
A([2 1][3])({2 1}{3}) 
  = {1 2}{3} - {1 3}{2} = c - b
```

where the subspace spanned by the vectors `(a-b)`, `(b-c)`, `(c-a)` is
two dimensional, because there a one-dimensional redundancy `(a-b) + (b-c) + (c-a) = 0`
between them. Furthermore, the basis vectors `(a - b)`, `(b - c)`, `(c - a)` are invariant
under all swaps, and are thus invariant under all permutations, since all permutations can be
written as a composition of swaps. So we have found a two-subspace of a three-dimensional
representation of `S3`. To see that this subspace is irreducible, notice that given any permutation
of the form `k - l`, we can swap the letters `k, l` and the third letter `m` to obtain the entire
basis. Hence, this subspace is indeed irreducible, and the representation of `Sn` that we have
is indeed an irreducible representation.


##### `Tabloid(1, 1, 1)`

There are 6 tabloids of shape `(1, 1, 1)`, given by the permutations of the numbers `{1, 2, 3}`.
If we write them down, they're going to be (a) `{1}{2}{3}`, (b) `{1}{3}{2}`, (c) `{2}{1}{3}`,
(d) `{2}{3}{1}`, (e) `{3}{1}{2}`, (f)`{3}{2}{1}`. This gives us a 6 dimensional vector
space spanned by these basis vectors. 


Let's now find out the value of `A([1][2][3])({1}{2}{3})` recall that we need to act
on `{1}{2}{3}` with all column stabilizers of `A([1][2][3])`.






##### `A` on tabloid instead of tableaux

I claim that the different `A_t` and `A_s` for `{t} = {s}` differ only by sign [Why?
Because we can reorder the elments of `t` and `s` to suffer a sign]. Thus, we can
directly define `A_{t}` on the *tabloids*, by defining it as first sorting the rows of `t`
and then using `A_t`. 


# Even and odd functions through representation theory

Consider the action of $\mathbb Z/ 2\mathbb Z$ on the space of functions $\mathbb R \to \mathbb R$.
given by $\phi(0)(f) = f$, and $phi(1)(f) = \lambda x. f(-x)$. How do we write this in terms of irreps? 

- On the even functions, since $e(x) = e(-x)$ for $e$ even, we have that,
  $\phi(0)(e) = e$ and $\phi(1)(e) = e$ [since $e(-x) = e(x)$], or $\phi(x)(e) = id(e)$,   hence the action
  of $\phi$ is that of the trivial representation on the subspace spanned by even functions.

- On the odd functions, since $o(-x) = -o(x)$, we have that $\phi(1)(o)(x) = o(-x) = -o(x) = sgn(o)(x)$ hence $\phi(1)(o) = -o$, hence $\phi(x)(o) = sgn(x)(o)$ where $sgn$
  is the sign representation!

Since the even and odd functions span the space of all functions, as we can write any function $f$ as the
sum of an even part $e_f(x) \equiv [f(x) + f(-x)]/2$ and an odd part $o_f(x) \equiv [f(x) - f(-x)]/2$. So, 
we have described the action of $\phi$ in terms of subspaces which span the space, so we've found the irrep decomposition.

# Greg egan: Orthogonal

I found the idea of writing a story about a universe with a closed loop of time fascinating.
Here are some of the sentences that really helped me "get" compatiblism as an idea thanks
to reading the book:

> Suppose we leave a piece of equipment behind on Esilio - say, a
> small spyglass. Over the eons, from our point of view, we'd expect it to become
> pitted by dust in the wind, and eventually break up completely and turn to
> sand. Our spyglass, our rules: that sounds fair, doesn't it? But if that sand
> stays on Esilio, what origin will it have from Esilio's point of view? Most
> likely, some ordinary Esilian rock will have broken down to make it - which to
> us, would look like erosion running backwards. But then, in Esilian time the
> remnants of that rock will eventually form themselves spontaneously into a
> spyglass, which lies on the ground until we come along to retrieve it.  So if
> you follow the history of the matter that makes up the spyglass far enough in
> both directions, it's clear that it's not committed to either side's rdes.' 
> 
> 'Swap the roles of Esilio and the Surveyor,' he replied, 'then tell the same
> story again. If something from Esilio takes the place of the spyglass, it must
> be with us already. We must have been carrying it, or the things that will
> become it, from the very start. Because according to Esilio's arrow of time
> we've already visited the planet, and it's almost certain that something
> remained with us when we departed.'
 

> 'Tell us one thing that you're sure won't happen,' he challenged her.  She
> said, 'Two objects in thermal contact will not maintain different
> temperatures over a long period of time.' 'Because ... ?' 'Because there are
> vastly more possibilities in which they share their thermal energy more
> equally. If you pick a possibility at random, it's likely to be one of those.
> Fundamental physics might make the entropy minimum necessary - but we still
> expect the cosmos to be as random as it can be.'


> There was fine red dust covering the grey hardstone walls of the airlock. He
> hadn't noticed it by the dimmer illumination of the safety light. He ran a
> gloved finger along the seal of the outer door, trying to find the point
> where it had been breached, but if there was a hole it wasn't apparent.  It
> hardly mattered now; however the dust had entered, he was about to let in a
> great deal more. But as he began to turn the crank, the realisation hit him:
> it hadn't corne from outside. They must have brought it with them all the way
> from the Peerless, scattered invisibly throughout the craft, with a little
> more accumulating inside the airlock each time the inner door was opened. Or
> in Esilio's terms: the Surveyor's visit had just ended, and this residue was
> something they would soon take away with them


> Twice, as she jumped out of some indentation in the sand, it vanished. She
> and Azelio hadn't actually made all the tracks that he'd attributed to them.
> Or not yet, they hadn't.  'Come and join us,' Azelio said. 'Some of these
> must be yours.'


> Each time Azelio lifted his feet, scattered sand unscattered itself, grains
> sliding in around the places where he'd stepped to settle more evenly -
> though not always smoothing the ground completely. After all, 197 Ramiro
> reasoned, it was possible to walk in someone else's footprints, or to step
> several times in your own. It would only be the last footfall on any given
> spot - prior to the next occasion on which the wind levelled everything -
> that would unmake the imprint completely.



> 'What happens if I try to walk on pristine ground?' he asked.  'Try it and
> see!' Agata taunted him.  Ramiro descended to the bottom of the ladder,
> intending to move quickly and get the ordeal over with, but then his resolve
> deserted him. When he willed his foot to land on unblemished sand, what
> exactly would intervene to stop him? A cramp in the muscle, diverting his leg
> to its proper, predestined target? A puppet-like manipulation of his body by
> some unseen force too strong to resist, or a trance-like suspension of his
> whole sense of self? He wasn't sure that he wanted to know the answer. And
> perhaps that was the simplest resolution: he would lack the courage to walk
> out across the surface of Esilio for the rest of the mission. He would cower
> in his room, leaving the work to the others, while he waited to return to the
> Peerless in disgrace.

> He'd scrutinised the ground beforehand, and he was sure there'd been no
> footprints at all where his feet now stood.  He lifted one foot and inspected
> the sand below. He had created an indentation that had not been there before.
> That was every bit as strange to Esilio as the erasures he'd witnessed were
> strange to him.


>'How?' he demanded, more confused than relieved.  'You
> really don't listen to me, do you?' Agata chided him. 'Did I ever tell you
> that the local arrow was inviolable? 'No.' What she'd stressed most of all
> was a loss of predictability but the sight of her and Azelio unmaking their
> footprints had crowded everything else out of his mind. Those disappearing
> marks 198 in the sand might be unsettling, but if he could ignore them and
> walk wherever he pleased then they were not the shackles he'd taken them to
> be.  


> 'What happens if there are footprints that no one gets around to
> before the next dust storm?' he asked Agata. 'Ones that were there
> straight after the last storm?'
> She said, 'There can't be a footprint untouched by any foot. I don't
> understand the dynamics of wind and sand well enough to swear to
> you that there won't be hollows in the ground that come and go of
> their own accord - but if you're talking about a clear imprint, if we
> could keep our feet away from it, it simply wouldn't be there.'


> Esilio was a world where a certain amount of nOiSY, partial - and
> predominantly trivial - information about the future would be strewn across
> the landscape. There had always been plenty of trivial things that could be
> predicted with near-certainty back on the Peerless, and perhaps as many of
> them would be lost, here, as these eerie new portents would be gained

> Emboldened, he strode out across the illuminated ground, pausing
> every few steps to kick at the sand. Sometimes he simply pushed the
> dust aside; sometimes the dust applied pressure of its own, as it
> moved in to occupy the space his foot vacated. But that pressure
> never came out of nowhere: his feet moved as and when he'd willed
> them to move, followed by the dust but never forced to retreat. Nor
> were they thrust without warning into the air

> Each time there was a dust storm the record of future movements would be
> erased, but even in a prolonged period of calm the footprints would overlap,
> conveying very little information.

> 'You already dug twelve holes!' he observed.
> 'And I thought you were messing around with Agata all morning.'
> Azelio made a noncommittal sound. 
> 'My plan is to dig up all these plants at the end of the trial and take
> them back to the Peerless for my colleagues to analyse,' Azelio mused.  'So I
> guess that's when I'll see the transition between cultivated and truly
> pristine ground. But right now, in Esilio's terms, we've just dug the plants
> up - so on our terms, we're about to do that. Backwards.' Ramiro said, 'You
> make it sound as if you've been practising timereversed agronomy all your
> life.' 'It's not that hard to see what's going on, if you think it through,'
> Azelio replied lightly.  'But you don't mind following markers like this?
> Evidence of acts you haven't performed yet?' 'It's a little disconcerting,'
> Azelio conceded. 'But I can't say that it fills me with claustrophobia to
> know that I'll carry out the experimental protocols I always planned to carry
> out.'


> He lowered the plant until its roots were in the hole, then
> he started adding soil from the surrounding mound. Some of the soil
> was scooped in with pressure from behind, in the ordinary manner.
> Some appeared to pursue the trowel, the way the dust sometimes
> pursued Ramiro's feet. What decided between the two? Azelio's own
> actions had to be consistent with the motion of the soil, but which
> determined which? Maybe there was no answer to that, short of the
> impossible act of solving in the finest detail the equations that Agata
> was yet to discover, revealing exactly which sequences of events
> were consistent with the laws of physics all the way around the
> cosmos. 


> Ramiro's left arm had grown tired from holding the plant in place over the
> hole. He shifted it slightly to make himself more comfortable, but as he
> shifted it back he saw soil rising and adhering to the roots. He stared at
> this bizarre result for a moment, then decided to stop wasting time delaying
> an outcome he had no wish to oppose.  He held the trowel to the side of the
> mound nearest the hole, then drew it closer. The sand followed the blade -
> not adhering to it and needing to be brought along, but gently pushing it. He
> lowered the trowel into the hole then withdrew it; the sand parted from the
> blade and packed itself between the roots of the plant and the side of the
> hole.

> He hesitated, groping for a clearer sense of his role in the task. But
> what could he actually do wrong? So long as he was committed to
> making whatever movements with the trowel were necessary until
> the plant was securely in place, that state of mind and the strictures
> of the environment ought to work it out between themselves.
> He scooped some soil straight into the hole; like the last delivery, it
> clung to the roots. In Esilio's terms, this soil had spent at least a few
> stints packed tightly around the plant; if he could have seen the
> action in reverse, it would have involved nothing stranger than a
> clump of sand finally coming loose. 

> But as she moved the broom across the floor, duly concentrating the dust
> ahead of it, other dust began to appear behind it - some of it falling from
> the air, some sliding over the stone to pile up against the bristles. Its
> entropy was decreasing too, as it accumulated from whatever scattered reaches
> of the Surveyor in which it had been lurking.  The net result was that the
> stretch of floor she'd swept remained as dusty as ever.

> But the plants' uptake of nutrients relied on interactions
> between their roots and the native soil at a microscopic level, and
> there was no guarantee that the two systems, left to themselves,
> would simply sort out their differences

> 'Because the test plots are failing,' Agata explained. 'So we need
> to take the explosive up into the hills, turn some rock into soil for
> ourselves - against the Esilian arrow - and see if that imbues the soil
> with the properties that it needs to support plant growth


> 'If we do set off this
> explosive,' he reasoned, 'shouldn't we be able to see some evidence of
> that already?'
> Agata said, 'You mean a crater?'
> 'Yes.'
> 'If we found a site like that, it would be useless to us. It would imply
> that after we set off the bomb, the crater would be gone and the sand
> around it would be rock again.'
> Ramiro scowled. 'Esilio doesn't care what's useful or useless, or it
> wouldn't have killed the plants, would it?'
> 'Esilio doesn't care,' Agata agreed, 'but why would we go ahead and
> set off the bomb there, knowing that it would do us no good?'
> 'Because the crater would prove that we did!' Ramiro replied heatedly.
> 'But as far as we know, there is no such crater.' Agata met his gaze
> openly, trying to reassure him of her Sincerity: she wasn't playing
> some verbal game just to annoy him. 'There is no crater, because if
> we saw it, we wouldn't choose to make it. Esilio can't force our hand;
> whatever happens has to be consistent with everything, including
> our motives. Ramiro said, 'It can't force our hand, but there could still be an
> accident.' 'That's true. But if we saw such a crater, we wouldn't even go near it
> with the explosive.' 

> He ran a hand over his face. 'If the plants can't
> bring their arrow to Esilio, why should a bomb do any better?'
> 'The roots of a plant aren't entirely passive,' Azelio replied, 'but
> they do rely on the state of the soil. I don't think the bomb going off
> will rely on anything like that.'
> 'But in Esilian time,' Ramiro protested, 'all the soil we're supposedly going to make with this bomb has to mesh perfectly with a
> backwards explOSion in such a way that it forms a solid rock. How
> likely is that?' 
> How likely are the alternatives?' Agata countered. 'How likely is
> it that the explOSive will fail to detonate? How likely is it that we'll
> allow it to explode in an existing crater instead - just to pander to
> Esilio's arrow?'



> She started swinging her pick into the rock face.
> Small chips of stone flew out from the point of impact, stinging her
> forearms, but the rush of power and freedom she felt at the sight of
> the growing excavation was more than enough to compensate.
> In Esilian time, the chips were rising from the ground, propelled into
> the air by conspiracies of time-reversed thermal diffusion, just to aid
> her as she rebuilt the rock. What stronger proof could there be that
> the cosmos had a place for her, with all her plans and choices? One
> day it would kill her, but until then the contract was clear: hardship
> and frustration and failure were all pOSSible, but she would never be
> robbed of her will entirely.


> the lines on the
> rock face formed symbols. The sides of the ridges appeared softened
> and eroded, as if a generation's worth of future dust storms had left
> their mark. But she could still make out most of the message.
> ' ... came here from the home world,' she read. 'To offer thanks
> and bring you ... courage.'
> Azelia said, 'Who thanks whom for what?'
> 'It's from the ancestors,' she said. 'They're going to come here and
> write this. They're going to come here to tell us that everything we've
> done and everything we've been through was worth it in the end.'


> But ever since he'd seen the writing for himself, he'd been unable to stop
> wondering if the message suited him too well. As far as he could recall, he'd
> never consciously planned to commit any kind of hoax.  What he didn't know was
> exactly what his lack of preparation meant. The words were there, nothing could
> change that now. But with every moment that passed it seemed more likely to him
> that the ancestors had nothing to do with it, and that he would find a way to
> write the message himself.


> To feel alive, he needed to feel himself struggling moment by
> moment to shape his own history. It was not enough to look down
> on events from above like a biologist watching a worm in a maze,
> content to note that this creature's actions had never actually gone
> against its wishes.

> nothing helped a plan run more smoothly than having a law of physics on its side


> How could he carve anything into the rock face, if the idea of doing
> it had only come to him after he'd seen the result? Even the choice
> of words hadn't sounded like his own. If he'd only selected them
> because he'd read them, who would have made the choice? No one.
> Agata had told him endlessly: a loop could never contain complexity
> with no antecedent but itself, because the probability would be far
> too low. There could be no words appearing on rocks for no other
> reason than the fact that they'd done so.


> 'We've all hit a dead patch,' Lila said sadly. 'Chemists, biologists,
> astronomers, engineers. Since they switched on the messaging
> system, there hasn't been a single new idea across the mountain.'
> 'You mean no one's been sending back new ideas?' Agata had
> predicted as much - but surely that self-censorship hadn't surprised
> anyone.
> 'Oh, the messages have contained no innovations,' Lila confirmed.
> 'But neither has the work itself.'
> 'I don't understand,' Agata admitted.
> Lila said, 'If people did innovate, the results would leak back to
> them one way or another. I know you believed that they'd be able
> to keep qUiet, so everything would go on as usual. But everything
> has not gone on as usual. We've had no new ideas since the system
> was turned on - because if we'd had them, we would have heard of
> them before we'd had a chance to think of them ourselves. The
> barriers to information flow are so porous now that the knowledge
> gradient has been flattened: the past contains everything the future
> contains ... which means the future contains nothing more than
> the past.'


> What would her own generation be famous for? Rendering
> the creation of new knowledge impossible. 

> 'I'm where I need to be.' 'In the administrative sense, or the teleological?'


> Azelio hummed with frustration. 'What's all this talk of replacement? If a
> meteor is going to hit us, it's going to hit us! You can devise as many
> ingenious plans as you like to try to sabotage the system at the very same
> moment, but if there's a rock on its way, nothing you do is going to make it
> disappear.' 'If there's a rock on its way, that's true,' Ramiro conceded.
> 'But until we know that there is, why should we assume that? The history of
> the next twelve stints ends with the messaging system failing; we're about as
> certain of that as we can be. Some sequence of events has to fill the gap
> between that certainty and all the other things we know. So which snippets
> would you rather the cosmos had on hand to complete the story? Just one,
> where a meteor hits the Peerless? Just two: a meteor, or a bomb? Making our
> own preferred version possible won't rule out everything else - but if we
> don't even try, we'll rule out our own best hope entirely.'



> Azelio was looking disoriented. 'I want this to work,' he said
> haltingly. 'But every time I stop and think about it, it feels as if all
> we're doing is playing some kind of game.


> Azelio glanced down at the pile of notes on her desk. 'And doesn't
> everything that could happen, happen? Isn't that what your diagram
> calculus says?'
> 'No.' Agata nodded at the pile. 'Por a start, you can only add up
> diagrams that begin and end in exactly the same way: they all take
> different paths, but their end pOints have to be identical. Getting
> to the disruption with benign sabotage leaves the mountain intact;
> getting there with a meteor strike hardly brings you to the same state.
> And even when the end points are identical, all the alternatives you
> draw for a process just help you find the probability that the process
> takes place. Those alternatives don't all get to happen, themselves.'
> 'Then what makes the choice?' Azelio pressed her. 'When a luxagen
> could end up in either of two places, how does just one get picked?

> Just because
> we don't know the cause of the disruption, that doesn't mean that every cause
> we can imagine will coexist. If you want history to unfold a certain way,
> forget about wave mechanics. What matters now are the usual things: who we are,
> what we do, and a certain amount of dumb luck.' 

> Azelio put the diagram down. 'So if there's a meteor coming, how
> do I stop it? Or avoid it?'
> 'You can't,' Agata replied. This was the sticking point they always
> reached. 'Not if the disruption is the proof that it hits us.'
> 'Then what difference does it make "who we are" and "what we
> do"?' Azelio asked bitterly. 'If I go through the motions of enacting
> something more benign ... how will that help? If there's a murderer
> trying to kill your family, you don't protect them by moving your
> own tympanum to match the threats being shouted through the
> door. Or do you really believe in safety through reverse ventriloquism?'
> Agata wrapped her arms around her head in frustration. 'We don't 
> know that there's a murderer at the door! We don't know that there's a
> meteor on its way!'


> 'This is your pass,' the woman
> explained, handing her a red disc. 'Please don't lose it.'
> 'Do I lose it?' Agata asked.
> 'Of course you don't,' the guard replied. 'Because I asked you not
> to.' 'Right.' Agata suppressed a shiver.

> 'I didn't make the inscription,' Tarquinia declared. 'I went out there to try,
> but nothing happened: no shards of stone rose from the ground to meet the
> chisel. I tried different tools, different movements ... but I couldn't unwrite
> those symbols. If anything, when I left they were sharper than I'd found them -
> as if all I'd done was make the message less clear for Agata and Azelio than if
> I'd stayed away completely. I wasn't the author of those words. Someone else
> must be responsible for them.'

> I wish I could talk to them,' she said. 'I wish I could thank
> them. I wish I could tell them that it wasn't for nothing, that it ended
> well.' Clara said, 'If that's what you want, then I believe you'll find a
> way.'

# Simplicial approximation: maps can be approximated by simplicial maps (TODO)

# Excision (TODO)



# Marshall: Andrej (TODO)

- [Marshall-lang](https://github.com/andrejbauer/marshall.git)


# Limit is right adjoint to diagonal

Suppose a category `C` possesses all small limits. This means that for any index category `J`
and functor `F: J -> C`, the limit `lim F:C` exists in C. We wish to show that the functor
`const: C -> (J -> C)` given by `const(c) = \j. c` has a right adjoint `lim: (F -> C) -> C`
which produces the limit of a diagram. So we are saying that `const |- lim`.  So we need
to provide a morphism `(const c -> diag) -> (c -> lim diag)`. A morphism
`const c: J -> C -> diag: J -> C` is a natural transformation between the `const c` functor
and the `diag` functor. This is, by definition, a cone with apex `c`. However, every cone
factors through the limit cone of the diagram `diag`. Thus, we get a morphism `(c -> lim diag)`,
from the fact that the cone with apex `c` factors through the cone with apex `lim diag`, as `lim diag`
is the universal cone.

This establishes that limit is right adjoint to diag. From this, can we get a cheap proof
that right adjoints preserve limits ? Suppose `L: C -> D`, `R: D -> C` are adjoint `L |- R`.
Now, consider limits in `D`. This can be considered by taking the category `(J -> D)`. 
We get an adjunction `const: D -> (J -> D) |- lim: (J -> D) -> C`.

```text
C<-g-D <-lim-   (J -> D)
C    D          (J -> D)
C-f->D -const-> (J -> D)
```

composing gives us:

```text
C <-g- D <-lim-   (J -> D) <-f._ -  (J -> C)
C      D          (J -> D)          (J -> C)
C -f-> D -const-> (J -> D)  -g._ -> (J -> C)
```

I'm not sure how to proceed further, but I feel that it must be possible to proceed! I lack
the technology, unfortunately, to make this go through.


# Working out why right adjoints preserve limits.

We have `L: C -> D` and `R: D -> C` adjoints functors,
so we have the condition:
1. Hom(L(a): D, b: D) ~= Hom(a: C, R(b): C)

We will also show that `Hom(A, -)` preserves limits:

```
Hom(a, lim (F: J -> C):C) : Set ~= lim ({Hom(a, -) . F}: J -> Set): Set
 Hom(a, lim (F: J -> C):C) : Set ~= lim (\j. Hom(a, F(j)): J -> Set): Set
```


The above statement, fully elaborated with all the types looks as follows:

```
lim :: (J -> K) -> K
Hom(a: C, {lim (F: J -> C)}:C ): Set ~= 
lim (\j. Hom(a, F(j)): J -> Set): Set
```

Furthermore, we also know from the Yoneda embedding, that `x ~= Hom(x, -)` for all `x`.
Given these two facts, we can speedily derive that a right adjoint preserves limits:

```
Hom_C(a:C , R(lim F: J -> D)): Set 
= Hom_D(L(a), lim F: J -> D) [Adjunction]
~= {lim (\j. Hom_D(L(a), F(j)): J -> Set}: Set [Hom lim = lim Hom]
~= {lim (\j. Hom_C(a, R(F(j)))): J -> Set}: Set [Adjunction inside lim]
~= Hom_C(a, {\j. R(F(j))}: J -> C): C [lim Hom = Hom lim]
~= Hom_C(a, R . F)
```



#### `Hom(a, -)` preserves limits:

We wish to show that the `Hom(a, -)` functor preserves limits. That is:

```
Hom(a, lim F: J -> C): Set ~= lim(\j. Hom(a, F(j)): J -> Set): Set
```

Let's start with `Hom(a, lim F: J -> C): Set`. An element of this
is a morhism `arr: a -> lim F` from `a` to the apex
of the limit cone `lim F`. We need to translate this into a `lim(\j. Hom(a, F(j)): J -> Set): Set`,
which is a family of morphisms from each `a` to each `{ F(j) : j in J}`. This is obtained
by composing the projection maps `pi(j): lim F -> F(j)` with `arr: a -> lim F` to 
get `pi(j) . arr : a -> F(j)` which lives in `Hom(a, F(j))`. We get the limit by considering
the family of these maps, as the Limit in `Set` is just a product with coherence conditions,
and an element of the limit is a tuple/family with coherence conditions.

To go the other way around, suppose we have an element in the limit
`lim(\j. Hom(a, F(j)): J -> Set): Set`. This means that we have a family of maps from `a` to `F(j)`
which obeys the coherence conditions. This means that `a` is the apex of some valid cone. But we
know that `lim F` is the universal cone, thus the `a` cone must factor through `lim F`. This gives
us a factoring map `factor: a -> lim F`. The map `factor` lives in `Hom(a, lim F)`. This gives the other
way round.


Thus, the two sets are equivalent, and hence `Hom(a, -)` preserves limits (almost by definition).


# Limit/Colimit/Cone/Cocone: the arrows are consistent!

I sometimes wonder if a product is a limit or a colimit (not really, because 
I remember that limits are product + equalizers, but it makes for a nice story
nonetheless). I realised that the arrows of a cone/co-cone are always consistent.
Since a cone has arrows _out_ of the apex, the universal cone is given by arrows _into_ the apex
to be able to compose arrows
Similarly, since a co-cone has arrows _into_ the apex, the universal co-cone must have arrows
_out_ of the apex into the apex of another co-cone. Thus a terminal object must be a limit/cone,
since we want arrows _into_ it (by universality), and that  is compatible if the cone itself has arrows
_out_ of the apex, ie, a limit, since a limit is a product and thus has projections out of it.



# Representable Functors

imagine image of functors $F: C \rightarrow D$, $G: C \rightarrow D'$ as lying in sheets.
Then a nautural transformation $\eta$ goes "perpendicular to these sheets. Often,
knowing the natural transformation at one point determines it at every other point, if the
category is rich-in-morphisms (eg. Set is very rich in morphisms). Now if we think of $[C, Set]$
(category of functors from $C$ to $Set$), we have all the Hom functors here, such as $Hom(x, -)$,
$Hom(y, -)$, $Hom(z, -)$ etc. We may have some other functor $F: C \rightarrow Set \in [C, Set]$.
If this functor $F$ is isomorphic to some Hom-functor $Hom(a, -)$, then the functor $F$ is said
to be a representable functor since it is represented by a single object $a$ through $Hom(a, -)$.
PArametric polymorphism in haskell, that forces us to write one formula for all types makes
these functions automatically natural transformations. So any implementation of a function
such as `foo :: Maybe a -> [a]` will automatically be a nautral transformation (?)


Let's try and check if the list functor is representable. If I pick `foo :: (Integer -> x) -> [x]`
this direction can be implemented as `foo f = fmap f [0,1..]`. On the other hand, the
other way round does not work: `foo:: [x] -> (Integer -> x)` can't always be implemented. It's
not representable (proof by haskell intuition).

```hs
{-# LANGUAGE ExplicitForAll #-}
{-# LANGUAGE RankNTypes #-}
{-# LANGUAGE TypeFamilies #-}
{-# LANGUAGE InstanceSigs #-}
type Hom a b = a -> b
type Nat f g = forall x. f x -> g x
class Representable f where 
    type Rep f :: * -- the representing object o whose Hom(o, -) ~= f
    -- tabulate :: Nat (Hom (Rep f)) f
    -- tabulate :: forall x. Hom (Rep f) x -> f x
    tabulate :: forall x. ((Rep f ->  x)) -> f x
    -- index :: Nat f (Hom (Rep f))
    -- index ::  forall x. f x ->  (Hom (Rep f) x)
    index ::  forall x. f x ->  (Rep f -> x)


```

`Stream` is representable:

```hs
data Stream a = Cons a (Stream a)
instance Representable Stream where
   type Rep Stream = Integer
   tabulate i2x = go i2x 0 where
      go :: (Integer -> x) -> Integer -> Stream x
      go f i = Cons (f i) (go f (i+1))

   index :: Stream x -> Integer -> x
   index (Cons x xs) n = case n of 0 -> x; not0 -> index xs (n-1)
```

In general, things that are products tend to be representable, while things
that are sums tend not to.

#### Every presheaf is a colimit of representables

Roughly, every presheaf $P: C \rightarrow Set$ can be written by "gluing" (union + equivalence relation/colimit)
functors of the form $Hom(a_i, -)$. Let $P$ be the presheaf. To say that it
can be written as a colimit of Hom-sets, this means that we have some (yet unknown)
diagram $dgrm: J \rightarrow [C, Set]$ such that $P$ is the colimit of such a
set. Unwrapping what this means, it means that we have a functor $dgrm: J \rightarrow [C, Set]$ such that
the image of $J$ is always a hom-set. That is, $dgrm(j \in J) = Hom(c_j, -) \in [C, Set]$. Furthermore,
since $P$ is a colimit, we have arrows of the form $dgrm(j) = Hom(c_j, -) \rightarrow P$. Recall that such an
arrow is a natural transformation between $Hom(c_j, -)$ and $P$. Also recall that by the Yoneda lemma,
such natural transformations $Hom(c_j, -) \rightarrow P$ are in natural bijection with elements in $P(c_j)$. So at some
point, we'll probably need to pick elements $P(c_j)$. We're not done yet, this is what one part of 
what it means to be a colimit; we also need all the diagrams to commute!  (1)
the embedding natural transformations $Hom(c_j, -) \rightarrow P$ arrows
commute with image of the arrows in $J$, of the form $Hom(c_j, -) \rightarrow Hom(c_{j'}, -)$.
(2) that $P$ is the universal object in $[C, Set]$ such that
this rats nest of hom-sets embeds perfectly into $P$. Now the problem boils
down to designing a $dgrm: J \rightarrow [C, Set]$ which picks out enough
hom-sets and relations between the hom-sets such that $P$ is the colimit of
such a $dgrm$.


The idea, once, again, goes back to (a) Yoneda, and (b) Grothendeick. It
appears that to be able to pick out such embedding arrows for the co-cone
$Hom(c_j, -) \rightarrow P$, we need elements $P(c_j)$. Soo let's build a
category that does exactly that; This new category called as a _Grothendieck construction_. 
Given a category $C$ and a presheaf $P: C \rightarrow Set$, this new category called $el(P)$ 
has as objects pairs of the form $(c \in C, u \in P(c))$. So we have a pair of an abstract object $c \in C$,
and an element of its set $u \in P(c)$, as $P(c) \in Set$, as $P$ is a presheaf, thus has the type $P: C \rightarrow Set$.
The arrows in this category $el(P)$ are derived from arrows in the original category $c \xrightarrow{a} d$.
Such an arrow lifts to a set-function thanks to the presheaf, $P(c) \xrightarrow{P(a)} P(d)$. If we now have
$u \in P(c)$, we can then build an arrow in $el(C)$ which takes $(c \in C, u \in P(c)) \xrightarrow{el(P)(a)} (d \in C, P(a)(u) \in P(d))$.


Picture speaks a thousand words:
```
C | c -a→ d
Set | P(c) -P(a)→ P(d)
Set | u ∈ P(c) -P(a)→ d ∋ P(a)(u)
el P | (c∈C, u∈P(c)) 
el P | (c∈C, u∈P(c)) -el a→ (d∈C, P(a)(u)∈P(d))
```

So, this category gives us a way to "locate ourselves" within the set $P(c)$, which will be instrumental
in creating the arrows (natural transformations) of the form $Hom(c_j, -) \rightarrow P(c_j)$, as asked of us by the cocone.
This also hints at why we use colimis and not limits: because the yoneda goes from the $Hom(c_j, -)$ to $P$, we can only conjure
arrows into $P$ via Yoneda, thereby forcing us to use a colimit.

We claim that we should choose the diagram category as $J\equiv el(P)$, with the diagram functor $dgrm: el(P) \rightarrow [C, Set]$ given
by $dgrm(c \in C, u \in P(c)) : el(P) \equiv Hom(c, -) : [C, Set]$. This embeds $(c, u \in P(C))$ where $u$ is a way to locate $P$'s
view of $C$ as a Hom-set $Hom(c -)$. To give the natural transformation from the image of the diagram to the apex of the cocone $P$,
we use Yoneda: We need an arrow $Hom(c, -) \rightarrow P$, which we know is in bijection with elements of $P(c)$ through yoneda.
Luckily, we have $u \in P(c))$ to invoke yoneda, so we build the arrows from $dgrm(c, u) = Hom(c, -)$ to $P$,
given by applying Yoneda to $u \in P(c)$. Thus, we can at least form a cocone. Whether the arrows of the base of
the cocone commute with the apex-pointing arrows, and whether this is universal is to be checked next.

Given some other cocone $Q \in [C, Set]$, with co-cone morphisms $\sigma_j: Hom(c_j, -) \rightarrow Q$, we need to 
create a natural transformation $\theta: P \rightarrow Q$. Let's do this pointwise. for some $c \in C$, 
we need to build a map $\theta_c: P(c) \rightarrow Q(c)$. Since the domain and codomain are pointwise,
let's pick some element $x \in P(c)$. See that this can be seen as an element $(c \in C, x \in P(c)$ which is
an element of the category $el(P)$. But, recall that this was our index category $el(P)$. Thus, there is going
to be an arrow $dgrm((c \in C, x \in P(c)) = Hom(c, -) \xrightarrow{q(c,x)} Q$ since $Q$ is a cocone. 
But since $q(c, x) \in [Hom(c, -), Q]$, it's an element of $Q(c)$. We have thus found a way to map $P(c)$ into $Q(c)$
by "pulling back" into the index category and then "pushing forward" via Yoneda. [What the fuck is actually happening here?]

- [Reference](https://mysite.science.uottawa.ca/phofstra/MAT5147/presheaves.pdf)
- [Density theorem proof](https://en.wikipedia.org/wiki/Density_theorem_(category_theory)#Proof)


# Why terminal object is a limit

1. Thinking in Set, the terminal object is `{*}`, which is the empty product of
   sets. Hence, the terminal is a type of product, which is a limit.
2. What does the terminal `{*}` project onto? It should project onto its
   components, since its a limit. But recall that it was the limit of ZERO
   objects. `{*}` vacuously projects into zero objects [ie, we're not obliged to
   construct a projection]
3. Think about products again. the product is universal such that any other
   "candidate for the product" must factor through a projection onto the
   product. Similarly, the terminal is universal such that any other "candidate
   for the terminal" (literally all other objects) must factor through the
   terminal [ie, must map into the terminal].



# Excluded middle is not false in intuitionistic logic

```hs
{-# LANGUAGE EmptyCase #-}

data Void
absurd :: Void -> a
absurd v = case v of
type NOT x = x -> Void
type FALSE x = x -> Void
type LEM x = Either x (NOT x)

type NOTFALSE a = NOT (FALSE a)
lemNotFalse :: NOTFALSE (LEM a)
-- lemNotFalse :: (LEM a -> Void) -> Void
-- lemNotFalse :: (Either a (a -> Void) -> Void) -> Void
lemNotFalse f = f $ Right $ \a -> f (Left a) 

lemFalseExplodes :: FALSE (LEM a) -> anything
-- lemFalseExplodes :: LEM a -> Void
lemFalseExplodes lem = absurd (lemNotFalse lem)
```

# Yoneda Lemma and embedding

```hs
type Hom a b = (a -> b)
type Nat f g = forall x. f x -> g x
```
Yoneda, which states that $[C, Set](F(-), Hom(a, -)) \simeq F(a)$:

```
type YonedaLHS f a = Nat (Hom a) f
```


```
rhs2lhs :: Functor g => g a -> YonedaLHS g a
-- rhs2lhs :: g a -> (Nat (Hom a) g)
-- rhs2lhs :: g a -> (forall x. (Hom a) x ->  g x)
-- rhs2lhs :: g a -> (forall x. (a -> x) -> g x)
rhs2lhs ga = (\a2x -> fmap a2x ga) :: g x
```

`rhs2lhs` is a lot like an enriched continuation, where
we are given a value `(g a)`, and we need to produce
an "enriched" continuation handler, which when given
a use `(a -> x)` produces not an `x`, but a `g x`.


```hs
lhs2rhs :: Functor g => YonedaLHS g a -> g a
-- lhs2rhs :: Nat (Hom a) g -> g a
-- lhs2rhs :: (forall x. (Hom a x) -> g x) -> g a
-- lhs2rhs :: (forall x. (a -> x) -> g x) -> g a
-- set x = a
-- lhs2rhs :: ((a -> a) -> g a) -> g a
lhs2rhs cont = (cont (id :: Hom a a)) :: g a
```

in `lhs2rhs`, given an enriched continuation handler
`forall x. (a -> x) -> g x`, and we need to produce a `g a`.
As with regular continuations, we feed in the `id` function
to recover the trapped continuation value.

```hs
type List a = [a]
type Nat f g = forall x. f x -> g x
listyo :: (Nat (Hom a) List) -> [a]
-- listyo :: (forall x. (Hom a x) -> List x) -> [a]
-- listyo :: (f: forall x. (g: a -> x) -> [x]) -> [a]
-- implement f, is to use g multiple times
-- f g = [g a1, g a2, ... g an] = fmap g [a1, a2, ... an]
-- f id = [id a1, id a2, ... id an] = [a1, a2, ... an]
listyo f = f id

-- F = [.]
listyo' ::  [a] -> (forall x. (a-> x) -> [x])
listyo' as = \f -> fmap f as
```

When we specialize Yoneda to lists, we are led to the idea
that a continuation of the form `(a -> x) -> [x]` must contain
`[a]`s which it uses to produce multiple `x`s.



```
-- F = (b -> .)
-- pick x = a
-- ((a -> a) -> (b -> a) -> (b -> a)
-- Nat(Hom(a, -), F) ~= F a
-- type Hom a b = (a -> b)
-- c -> Hom (c, -)
-- a, b. arrows ∈ Hom (a, b)
-- Hom (a, -), Hom(b, -). arrows ∈ Nat Hom (a, -) Hom(b, -)
--
-- a, b. arrows ∈ Hom (a, b)
-- Hom (-, a), Hom(-, b). arrows ∈ Nat Hom (-, a) Hom(-, b)
contrayo :: Nat (Hom a) (Hom b) -> Hom b a
contrayo :: (forall x. (a -> x) -> (b -> x)) -> (b -> a)
contrayo f = f id

contrayo' ::   (b -> a) -> (forall x. (a -> x) -> (b -> x))
contrayo' b2a = \a2x -> a2x . b2a
```

When we specialize Yoneda to `b -> -`, we are led to the idea
that a continuation of the form `(a -> x) -> (b -> x)` must contain
plumbing to turn `b`s into `a`s: ie, it must contain a function `b -> a` .

```
-- F = id .
type Id x = x
-- Nat(Hom(a, -), Id - ) ~= Id a
-- Nat(forall x. (a -> x), Id x) ~= Id a
-- Nat(forall x. (a -> x) -> x) ~= a
idyo :: (forall x. (a -> x) -> x) -> a
idyo k = k id

idyo' ::  a -> (forall x. (a -> x) -> x)
idyo' a = \k -> k a
```

specializing to `id` recovers usual continuations.

In total, Yoneda tells us that from every enriched continuation 
`ContF a g = Nat (Hom a) g = forall x. (a -> x) -> g x`,
we can recover a `g a`. Hence, there is a bijection between `g a` and
`ContF a g`

#### Yoneda embedding

The yoneda embedding follows from the lemma. The lemma tells us that `Nat(Hom(a, -), F) ~= F(a)`.
Pick `F = Hom(b, -)`. This gives `Nat(Hom(b, -), Hom(a, -)) ~= Hom(b,  a)` Thus, if
we consider the mapping `C -> [C, Set]` given by sending `a` to `F(a)`,
we also preseve the `Hom` sets as natural transformations, since `Hom(b, a)` is isomorphic
to `Nat(Hom(b, -), Hom(a, -))`. Thus, we get a full and faithful embedding of the original category
into the `Hom` category.


# GHCID

- [ghcid](https://hackage.haskell.org/package/ghcid) + tmux is a nice way to get a REPL/IDE
  like experience for haskell with minimal fuss.

# Character theory

I jot down the rough proof sketches of character theoretic facts for quick reference.
Fix a group $G$. A group representation of $G$ is a group homomorphism from the group
to the automorphism group of a complex vector space $V$: Formally,
$f: G \rightarrow Aut(V)$. A direct sum of representations $f: G \rightarrow Aut(V)$, $f': G \rightarrow Aut(W)$
is the obvious extension of the maps $f \oplus f': G \rightarrow Aut(V \oplus W)$,
given by $(f \oplus f')(g) = \lambda v. f(g)(v) \oplus f'(g)(v)$.
A representation is said to be irreducible if it cannot be written as the
direct sum of two non-trivial representations. A character is the trace of
a representation. An irreducible character is the trace of an irreducible representation.

#### All finite group representations are unitary representations

Given a representation $f: G \rightarrow Aut(V)$, we construct
an _invariant_ inner  product, that is, one where $\langle f(g)(v) | f(g)(w) \rangle = \langle v | w \rangle$.
This maps the representation unitary, since it preserves this special inner product.
The idea is to begin with some _arbitrary_ inner product $[v, w]$ which we can always
induce on $V$ (pick a basis). Then, we build an "averaged" inner product
given by $\langle v | w \rangle \equiv \sum_{h \in G} [ f(h)(v) | f(h)(w) ]$.
Intuitively, this inner product is invariant because on considering $\langle f(g)(v) | f(g)(w) \rangle$,
the definition will contain $[f(h)(f(g)(v)) | f(h)(f(g) w)] = [f(hg)(v) | f(hg)(w)]$,
which is a re-indexing of the original sum. 
Hence, the representation $f$ preserves this inner product,
and we can thus study only unitary representations (which are much simpler).
From now on, we assume all representations are unitary.

#### Representation has same value for the entire conjugacy classe

Since all representations are unitary, the image of $f(ghg^{-1}) = f(g) f(h) f(g)^{-1}$
is going to be a change-of-basis of $f(h)$, and thus does not
actually change the automorphism given by $f(h)$. Hence, representations are
the same for an entire conjugacy class. Such functions which are constant
on a conjugacy class is called as a _class function_.


#### Morphism between representations / intertwining

A map between two representations, $f: G \rightarrow V$, $f': G \rightarrow W$
is given by $\eta: V \rightarrow W$ if the natural diagram commutes:

```
V --f--→ V
|        |
η        η 
↓        ↓
W --f'-→ W
```
such a map $\eta$ is called called as an intertwining map or an equivariant map.


#### Schur's lemma

The only equivariant maps between irreducible representations is either the
zero map or a **scalar multiple** of the identity map. This is stronger than
saying that the equivariant map is a diagonal matrix; scalar multiple of
identity implies that all dimensions are scaled uniformly.

The main idea of the proof is to show that the kernel and image of the 
intertwining map is an irreducible subspace of $f, f'$ retrospectively. Since
the maps are irreducible, we must have the the intertwining is either the zero
map, or a map into the full group. This forces the map to be zero or a scalar
multiple of the identity.

One way to look at this is that for irreps $f: G \rightarrow V$ and
$f': G \rightarrow W$, the dimension of $Hom(V, W)$ is either 0 or 1 (scalings of identity).



#### Schur orthogonality relations


We consider representations "one matrix index" at a time, and show that
the matrix entries of irreducible representations is going to be orthogonal
The proof is to consider representations $\alpha: G \rightarrow \mathbb GL(V)$
$\beta: G \rightarrow \mathbb GL(W)$, and an intertwining map $T: V \rightarrow W$.

How do we involve all of $\alpha, \beta, T$ at once? Recall that since $T$ is an intertwining, we must have:

$$
T(\alpha(g)(v)) = \beta(g)(T(v))
$$

Now, since $\beta$ is invertible (it must be since it's a member of $GL(W)$), I can rewrite
the above as:

$$
\beta^{-1}(g)(T(\alpha (g)(v)) = T(v)
$$

This needs that $T: V \rightarrow W$ is an intertwining map. Can we generalize this
to any **linear map**? Suppose that $L: V \rightarrow W$ is a **linear map**, not
necessary intertwining. Let's induce an intertwining map from $L$:

$$
\begin{aligned}
&\overline{L}: V \rightarrow W \\
&\overline{L}(v) \equiv 1/|G|\sum_{g \in G} \beta(g)^{-1} T \alpha(g) v
\end{aligned}
$$

We average the intertwining condition of $T(v)$ to produce an appropriate $\overline{L}(v)$.
Is this an intertwining? Yes, because when we compute $\beta(h)^{-1} \overline L \alpha(h)$,
the averaging trick winds up shifting the index, exactly as it does for the inner product:

$$
\begin{aligned}
&\beta(h)^{-1} \overline L \alpha(h) \\
&=\beta(h)^{-1} \left( \sum_{g \in G} \beta(g)^{-1} L \alpha(g) \right) \alpha(h) \\
&=\sum_{g \in G} \beta(gh)^{-1} L \alpha(gh) \\
&=\sum_{g \in G} \beta(gh)^{-1} L \alpha(gh) \\
&=\sum_{kh^{-1} \in G} \beta(kh^{-1}h)^{-1} L \alpha(kh^{-1}h) \\
&=\sum_{kh^{-1} \in G} \beta(k)^{-1} L \alpha(k) \\
&= \overline{L}
\end{aligned}
$$

Thus, for every linear map $L: V \rightarrow W$, if the representation $\alpha$ is not
isomorphic to the representation $\beta$, then $\overline{L} = 0$, or:

$$
\begin{aligned}
&\sum_{g \in G} \beta(g)^{-1} L \alpha(g) = 0 \\
&\left( \sum_{g \in G} \beta(g)^{-1} L \alpha(g) \right)[i][j] = 0[i][j] \\
&\sum_{g \in G} \beta(g)^{-1}[i][p] L[p][q] \alpha(g)[q][j] = 0[i][j] \\
&\text{($\beta$ is unitary)} \\
&\sum_{g \in G} \beta(g)*[p][i] L[p][q] \alpha(g)[q][j] = 0[i][j] \\
\end{aligned}
$$

The above equality holds **for all** indexes $i, j$ and **for all** choices
of $L[p][q]$ (since $L$ can be **any linear map**). In particular,
we can choose $L[p][q] = \delta[p][r] \delta[q][s]$ for **arbitrary** $r, s$.
This gives us the equation:

$$
\begin{aligned}
&\sum_{g \in G} \beta(g)*[p][i] L[p][q] \alpha(g)[q][j] = 0[i][j] \\
&\sum_{g \in G} \beta(g)*[p][i] \delta[p][r] \delta[q][c] \alpha(g)[q][j] = 0[i][j] \\
&\sum_{g \in G} \beta(g)*[r][i] \alpha(g)[s][j] = 0[i][j] = 0\\
\end{aligned}
$$

This tells that we can choose any index $[r, i]$ and index $[i, j]$ and these will be orthogonal,
when viewed as vectors "along" the set of matrices.

<img src="./static/repr-theory/schur-orthogonality.png">

If the representation is a one-dimensional representation/character, then we have no freedom
in indexing, and the above becomes:


$$
\begin{aligned}
&\sum_{g \in G} \beta(g)* \alpha(g) = 0[i][j] = 0
\end{aligned}
$$

Thus, different characters are all orthogonal.

#### Inner product of class functions

we impose an inner product relation on the space of class functions (complex valued functions
constant on conjugacy classes) $G \rightarrow \mathbb C^\times$, given by
$\langle f | f' \rangle \equiv 1/|G| \sum_{g \in G} f(g) \overline{f'(g)}$
where $\overline{f'(g)}$ is the complex conjugate. 

Using the Schur orthogonality relations, we immediately deduce that the inner product
of two irreducible characters can be viewed as the schur orthogonality applied to their
(only) matrix entry at location (1, 1). Thus, irreducible characters will be orthogonal,
and equal characters will have inner product 1.


#### Regular representation

The "Cayley-style" representation one would naturally dream up. For a group $G$,
build a vector space $V$ whose basis is given by elements of $G$. Have $g \in G$
act on $V$ by seding $v_h$ to $v_{gh}$. Ie, act with $g$ as a permutation on $V$.
This gives us a "large" representation. For example, the permutation group of $n$
letters will have a regular representation of $n!$ basis vectors.

This representation contains every irrep. The idea is to show that the dot
product of the trace of the regular representation with every other irrep is
nonzero.  Furthermore, since the regular representation has finite dimension,
this tells us that there are only finitely many irreps: the irreps correspond
to subrepresentations, and a finite representation only has finitely many
subrepresentations. This makes the idea of classifying irreps a reasonable task.


##### Character of the regular representation

**Theorem:** The character $r_G$ of the regular representation is given by $r_G(1) = |G|$,
$r_G(s) = 0$ for $s \neq 1$. 

- The matrix for the identity element is the identity matrix, and the size
  of the matrix is the size of the vector space, which is $|G|$ since
  there's a basis vector for each element of $G$. Thus, $r_G(1) = |G|$. 
- For any other element $g \in G$, the regular representation will be a permutation matrix
  with no fixed points. Thus, the diagonal of the matrix is all zeros, and hence $r_G(g) = 0$.

##### Regular representation contains all other irreps

The inner product of the character of the regular representation with any other
irrep $\alpha$ is going to be:

$$
\begin{aligned}
& \langle r_G | \chi_\alpha \rangle  = 1/|G| \sum_{g \in G} r_G(g)* \chi_\alpha(g) \\
&= 1/|G| (r_G(1) \cdot \chi_\alpha(1)) \\
&= 1/|G| (|G| \cdot 1) \\
&= 1
\end{aligned}
$$

Thus, the regular rep contains the other irreps, since the character of the regular rep has non-zero
inner product with irrep, and irrep characters are all orthogonal.

#### Abelian groups are controlled by characters

Since abelian groups map to automorphism that all commute with each other, we can
simultaneously diagonalize these matrices. Thus, we only need to consider
the data along each diagonal, which is independent. This reduces the representation
to a direct sum of scalars / 1D representations / characters.


# Cofibration

```
A --gA[t]--> X
|           ^
i           |
|           |
v           |
B >-gB[0]---*
```

The data $(A, B, i)$ is said to be a cofibration  ($i$ like an inclusion $A \rightarrow B$)
iff given any homotopy $gA[t]: [0, 1] \times A \rightarrow X$, and a map
downstairs $gB[0]: B \rightarrow X$ such that $gB[0] \circ i = gA[t](0)$,
we can extend $gB[0]$ into $gB[t]$. We see that this is simply
the HEP (homotopy extension property), where we have a homotopy of subspace
$A$, and a starting homotopy of $B$, which can be extended to a full homotopy.


#### Number of irreducible representations

Recall that the characters of irreducible representations are orthogonal. Also,
the dimension of the space of class functions is equal to the number of
conjugacy classes of the group $G$, since a class function takes on a distinct
value over each conjugacy class, so there are those many degrees of freedom.
This tells us that the number of irreducible representations is at most
the number of conjugacy classes of the group.

#### Lemma: Cofibration is always inclusion (Hatcher)

#### Pushouts

```
A <-i- P -β-> B
```

The pushout intuitively glues $B$ to $A$ along $A$'s subspace $P$. For this
interpretation, let us say that $P$ is a subspace of $A$ (ie, $i$ is an
injection). Then the result of the pushout is a space where we identify
$\beta(p) \in B$ with $p \in A$.  The pushout in Set is  $A \cup B/ \sim$
where we generate an equivalence relation from $i(p) \sim \beta(p)$. In
groups, the pushout is amalgamated free product.

```hs
-- | HoTT defn
f :: C -> A
g :: C -> B
inl :: Pushout A  B C f g
inr ::  Pushout A B C f g
glue :: Π(c: C) inl (f(c)) = inr(g(c))
```

Suspension:

```
1 <- A -> 1
```

Suspension can "add homotopies". Example, `S1 = Susp(2)`.

```
A --f--> P
|       |
|i      |i'
v       v
B -----> B Uf P
```

We want to show that $P \xrightarrow{i'} B \cup_f X$
is a cofibration if $A \xrightarrow{i} B$ is a cofibration.



Reference: [F. Faviona, more on HITs](https://www.youtube.com/watch?v=zn0nAXtoMtU)
 
# Emily Riehl Contrability as uniqueness

- untyped lambda calc/simply typed is topology of computation.
- dependent lambda calc/topos theoretic interpretation gives extensional mltt. Diagonal is identity type.
- challenge: intensional in topological setting. Path space is the identity type.

# Cofactor as derivative of determinant

I saw this at [math.se](https://math.stackexchange.com/questions/4128999/does-taking-derivative-of-determinant-of-a-matrix-with-respect-to-an-entry-give),
that one can define the cofactor of index $A[i][j]$ of a matrix $A$ as $\frac{\partial A}{\partial A[i][j]}$ which I think is quite cool.




# Homology, the big picture

First, there was nothing. Then, we decided we want homology. We start out by baby-stepping with
simplicial homology. We rapidly abandon this in favour of singular homology, since it's easier to define
notions of chain morphisms with singular homology. We want to know when spaces have the same homology/chain complex.
A reasonable idea is to prove that when the map between spaces is homotopic to identity, the chain complex
is identical. During the course of the proof, we feel the need for a notion of "chain equivalence", and thus we
we are led to define the notion of [chain homotopy](https://en.wikipedia.org/wiki/Homotopy_category_of_chain_complexes), and
more generally, the homotopy category of chain complexes. 

Next, we want the long exact sequence of homology connecting a space to its
quotient. To get here, we first consider relative homology, connecting a space
to a subspace. Next, we are led to build the
machinery of excision which tells us that relative homlogy is unchanged on
removing a subspace. Finally, we craft "good pairs", which are spaces for whom
the relative homology sequence will be equivalent to the quotient long exact sequence.
Excision lets us prove that relative homology is equal to quotient homology for good pairs.

Once we have excision, we use it to show that show that (1) simplicial and singular
homology agree, and (2) construct the Mayer Viteoris sequence (the Kunneth of homology).


#### Chain equivalence

Two chains $C, D$ are chain equivalent if there's a prism operator betwen them `:)` More seriously,

#### Relative homology

Build sequence $C_n(X) \rightarrow C_n(A) \rightarrow C_n(X)/C_n(A)$. Snake lemma gives us
long exact sequence of relative homology.

#### Good pair

$(X, A)$ is a good pair if (1) $A$ is closed in $X$ (contains all its boundaries), (2) there is an open nbhd $U$ of $A$
($A \subseteq U \subseteq X$) such that $U$ deformation retracts onto $A$.

For example, $(D^2, S^1)$ is a good pair, because the subspace $U = D^2 - (0, 0)$ (annulus)
deformation retracts onto the boundary $S^1$. The subspace $U$ is open since
it is the complement of a closed set, the point. More generally,
given an attaching map $f: \partial D^2 \rightarrow X$ to attach a $D^2$ into a
space $X$, if we build $Y \equiv X \cup_f D^2$, then $(Y, X)$ is a good pair,
since we have an open $U$ which is $Y$ minus the origin of the disk that conatins $X$. That is,
set $U \equiv X \cup_f (D^2 - (0, 0))$. $U$ contains $X$, and deformation retracts onto $X$, since we can "deform" the
ball minus the origin $D^2 - (0, 0)$ back into the original space $X$. This, cellular attachments create a "chain of good spaces".



Also see this answer on [HEP versus good pair](https://math.stackexchange.com/questions/74528/homotopy-extension-property-vs-good-pairs?rq=1)


#### good pair + Excision => relative equals quotient homology

Let $(X, A)$ be a good pair. Consider the projection map which kills $A$, 
the map $\pi: (X, A) \rightarrow (X/A, [A])$ as a map of good pairs.
(Note that $(X/A, [A])$ is also a good pair). We claim this induces isomorphisms
$\pi^*: H_n(X, A) \rightarrow H_n(X/A, [A])$.



# Normaliztion by evaluation (TODO)

- [Reference NBE video for cubicaltt](https://www.youtube.com/watch?v=atKqqiXslyo&list=PL0OBHndHAAZrGQEkOZGyJu7S7KudAJ8M9&index=6)

  
# Legal Systems very different from ours

# Lefschetz fixed point theorem (TODO)

# Shrinking wedge of circles / Hawaiian earring (TODO)

I've been trying to make peace with the fact that countably infinite wedge of circles
is so different from the hawaiian earring. Here are some thoughts:

- Topology on the hawaiian earring is very different. Eg: small opens around the center of infinite
  wedge is contractible, while no small open around the origin of the hawaiian earring is contractible.
- We can take infinite products of group elements in the hawaiian earring, since the radii decrease.
  For example, we can take a loop at *each* circle of radius $1/n$ by making it traverse the circle
  of radius $1/n$ in the interval $t \in [(n-1)/n, n/(n+1)]$, and stay at $(0, 0)$ at $t=1$.

# Simplicial approxmation of maps (TODO)

#### What we want:

> every map $f: K \rightarrow L$ is homotopic to a simplicial map $f_\triangle: K \rightarrow L$:
> ie, a map that sends vertices to vertices,
> and sends other points through an extension of linearity.
> such that $f(st(v)) \subseteq st(f_\triangle(v))$ where $f_\triangle$ is the simplicial
> approximation of $f$.

Recall that $st(v)$ is the intersection of interiors of all simplices that
contain the vertex $v$. So on a graph, it's going to be a "star shaped" region
around the vertex of all the edges around the vertex.

#### Why this can't happpen

Consider a triangle as a simplex of a circle. We want to represent rotations of
the circle.  I can rotate around a circle once, twice, thrice, ... As many
times as I want. However, if all I have is a triangle, I can represent rotating
once as the map $1 \mapsto 2, 2 \mapsto 3, 3 \mapsto 1$ and rotating twice as
maybe $1 \mapsto 3, 3 \mapsto 2, 2 \mapsto 1$, but that's it. I've run out of
room! So I need to *subdivide* the simplex to get "more points" to represent
this map.

#### The correct statement

# Lebesgue number lemma (TODO)

for a compact space $X$ and an open cover $\{ U_\alpha \}$, there is a radius
$r > 0$ such that any ball of such a radius will be in some open cover: For all
$x \in X$, for all such balls $B(x, r)$, there exists a $U_x \in \{ U_\alpha \}$ such that
$B(x, r) \subseteq U_x$.  Intuitively, pick a point $x$. for
each open $U$, we have a ball $B(x, r)$ that sits inside it since $U$ is open.
Find the largest such radius, we can do so since $\{x\}$ is the closed subset of a compact set.
This gives us a function $f$ that maps a point $x$ to the largest radius of ball
that can fit in _some_ open cover around it. This function $f$ is a continuous function (why?)
on a compact set, and thus has a minimum. So, for all points $x \in X$, if you give a 
ball of radius $\min f$, I can find some open cover around it.

#### Lebesgue number lemma, Version 2:

for a compact space $X$ and an open cover $\{ U_\alpha \}$, there is a diameter $d > 0$ such that
set of smaller radius will be in some open cover: For all $x \in X$, for all
opens $x \in O$ such that $diam(O) < d$, there exists a $U_x \in \{ U_\alpha \}$ such that  $O \subseteq U_x$.

If we can find radius $B(x, r)$ that satisfies this, then if we are given a set of diameter less than $2r$,
there will be a ball $B(x, r)$ that contains the set $O$ of diameter at most $d = 2r$,
and this ball will be contained in some $U_x$.  So we will have the
containments $O \subseteq B(x, r) \subseteq U_x$.


#### Lebesgue number lemma, proof from Hatcher

TODO


# Big list of learning Lean internals

- [CIC page in Coq](https://web.mit.edu/jgross/Public/tmp/doc/sphinx/_build/html/language/cic.html)
- [`bollu/cubicaltt`](https://bollu.github.io/cubicaltt/Main.html): an annotated version of the cubicaltt sources.
- [CPDT (certified programming with dependent types) chapter on equality](http://adam.chlipala.net/cpdt/html/Cpdt.Equality.html)
  to learn about the various reduction rules.
- [Data structures to verify acyclicity of a graph on updates](https://dl.acm.org/doi/10.1145/2756553): A New Approach to
  Incremental Cycle Detection and Related Problems
- [Coq Coq correct](https://dl.acm.org/doi/pdf/10.1145/3371076): Paper on
  formally verifying the type checker for Coq, contains information about data structures used in the kernel.


# MicroUI

I love the implementation of [`microui`](https://github.com/rxi/microui), so I wrote
a [code walkthrough here](https://bollu.github.io/microui/microui-source.html). I feel I learnt
a nice design pattern for writing such an immediate-mode GUI library in the future.


# Proof of tree having (V-1) edges

I'm more comfortable with the proof where we link the vertex to the incoming
edge "all at once".  The proof of induction feels weird.  So sahiti suggested:
impose an ordering that makes the time feel better. So if I imagine the tree
losing leaves from the bottom up left to right, it feels a lot smoother.  So
sahiti also suggested: shake the tree! This feels better as well. In general, I think
I prefer thinking of it in terms of "applicative", instead of "monad, where the choices
are statically determined, and I am not forced to make an arbitrary choice at each step, since
the arbitrariness of the choice breaks my "flow".


# Creating PDFs to read code

1. Use [`vim-bruin`](https://git.sr.ht/~romainl/vim-bruin) for black and white printing
2. Use `more *.cpp *.h > consolidated.cpp` to create a single file. `ClangFormat` this file.
3. Open in vim, use `:toHTML` in vim to dump out an HTML.
4. Open HTML page in firefox, use `save as PDF` to generate a PDF.
5. Print!


# Bias and gain

Bias changes the "central tendency"/"hinge point" of the curve.

```cpp
float GetBias(float t, float b) {
  return (t / ((((1/b) - 2)*(1 - t))+1.0));
}
```

Gain changes how rapidly we reach the bias point.

```cpp
function GetGain(t,g) {
  if(t < 0.5)
    return GetBias(t * 2.0,g)/2.0;
  else
    return GetBias(t * 2.0 - 1.0,1.0 - g)/2.0 + 0.5;
}
```


# Barycentric subdivision: edge length decreases

For a edge $E$, subdiving the edges into two at the center produces two edges
both $1/2$ the original length.  Given a triangle $T$, we wish to prove that
subdividing the triangle by joining the barycenter to the vertices reduces edge
length by $2/3$ of the maximum length. More generally, we wish to show that the
edge length decreases to $n/(n+1)$ of the largest length for an $n$ dimensional
figure.

The barycenter is at the location $b \equiv 1/n \sum_i v_i$. The distance
from a vertex $v_k$ is $||v_j - b|| = ||v_k - (1/n \sum_i v_i)|| = ||1/n(\sum_i v_k - v_i)||$.
By Cauchy Schwarz, we have that $||v_j - b|| \leq 1/n ||\sum_i v_k - v_i||$. One of the terms,
where $k = i$ will be zero, and the other (n-1) terms are at most $l$, the length of the longest edge.
This gives $||v_j - b|| \leq (n-1)l/n$, hence the edge length decreases by a factor of $(n-1)/n$.


# Homotopic maps produce same singular homology: Intuition

Take two maps $f, g: X \rightarrow Y$ which are homotopic. We wish
to show that if $f$ is homotopic to $g$, then we will get the same
induced singular homology groups from $f$ and $g$. The idea is to take a chain
$c[n] \in C[n]$, then study the image $f\sharp(c[n])$ and $g\sharp(c[n])$. Since $f$ 
and $g$ are homotopic, we can build a "prism" that connects $f\sharp(c[n])$ and $g\sharp(c[n])$
by means of a prism operator, that sends a chain $c \in C[n]$
to the prism $p(c)$ produced by the chain which lives in $D[n+1]$. Next, we compute the
boundary of this prism, $\partial p(c)$. This boundary will contain a top portion,
which is $f\sharp(c)$, a bottom portion which is $g\sharp(c)$, and the boundary edges 
of the prism itself, which is the same as taking the prism of the boundary edges
$p(\partial c)$.  This gives the equation $\partial(p(c)) = p(\partial c) + g\sharp(c) - f\sharp(c)$.
Rearranging, this gives $g\sharp(c) - f\sharp(c) = \partial p(c) - p(\partial c)$. To inspect
homology, we wish to check that $f\sharp, g\sharp$ agree on elements of $\ker(\partial[n])/im(\partial[n+1])$.
So, we set $c \in \ker(\partial[n])$. This kills of $p(\partial c)$. Further, since we 
quotient by $\partial[n+1]$, the $\partial(p[c])$ also dies off. This means that
$g\sharp(c) - f\sharp(c) = 0$ when interpreted as an element of $H[Y][n]$. Philosophically,
living in $\ker(\partial[n])$ kills $- \circ \partial$, and quotienting
by $im(\partial[n+1])$ kills $\partial \circ -$. Thus, we get that $g\sharp$ and $f\sharp$ produce the same
homology element. Intuitively, we are saying that these can be connected by a prism in the space,
and thus produce the same element. Think of the 0D case in a path-connected
space, where all points become equivalent since we can connect them by paths.

To compute the boundary of the prism, we break the prism into an interplation from
$f\sharp$ into $g\sharp$ by raising $f\sharp$ into $g\sharp$ one vertex at a time. This then allows us
to induce cancellations and show that $\partial(p(c))$ contains the terms
$p(\partial(c))$, $f\sharp(c)$ and $g\sharp(c)$.


Let's consider a 1D line $l: \Delta^1 \rightarrow X$ in $X$, with vertices
$l[0], l[1]$. The image of this line under $f$ is $m \equiv f \circ l$  with $m[0], m[1]$ as vertices,
and under $g$ is $n$ with $n[0], n[1]$ as vertices. Let $H: [0, 1] \times [0, 1] \rightarrow X$
be the homotopy between $H(0) f$ and $H(1) = g$.  The prism is image of the function $p: [0, 1] \times \Delta^1$, defined
as $p(t, i) \equiv H(t, l(i))$. We see that $p(0, i) = H(0, l(i)) = f(l(i)) = m$, and $p(1, i) = g(l(i)) = n$.
So, we get a "prism" whose endpoints are $m = f \circ l$ and $n = g \circ l$.


# Singular homology: induced homomorphism 

The space of chains $C[i]$ of a topological space $X$
is defined as all functions $\Delta^i \rightarrow X$.
The boundary map is defined as:

$$
\begin{aligned}
&\partial[n]: C[n] \rightarrow C[n-1] \\
&\partial[n](\sigma) \equiv \sum_i (-1)^i \sigma|[v[0], v[1], \dots, \hat{v[i]}, \dots, v[n]]
\end{aligned}
$$

where $\hat{v[i]}$ means that we exlude this vertex, and $v[0], v[1], \dots$ are the vertices
of the domain $\Delta^i$.

Now, say we have a function $f: X \rightarrow Y$, and a singular chain complex $D[n]$ for $Y$.
In this case, we can induce a chain map $f\sharp: C[n] \rightarrow D[n]$, given by:

$$
\begin{aligned}
&f\sharp: C[n] \rightarrow D[n] \\
&f\sharp: (\Delta^n \rightarrow X) \rightarrow (\Delta^n \rightarrow Y) \\
&f\sharp(\sigma) = f \circ \sigma
\end{aligned}
$$

We wish to show that this produces a homomorphism from $H[n](X) \equiv \ker \partial[n]/ im \partial[n+1]$
to $H[n](Y) \equiv \ker \partial[D][n] / im \partial[D][n+1]$. To do this, we already have a map from  $C[n]$ to $D[n]$.
We need to show that it sends $\ker \partial[n] \mapsto \ker \partial[D][n]$ and.

The core idea is that if we have abelian groups $G, H$ with subgroups $M, N$, and a homomorphism
$f: G \rightarrow H$, then this descends to a homomorphism $f': G/M \rightarrow H/N$ iff
$f(M) \subseteq N$. That is, if whatever is identified in $G$ is identified in $H$, then our
morphism will be valid. To prove this, we need to show that if two cosets $g + M$, $h + M$
are equal, then their images under $f'$ will be equal. We compute $f(g+M) = f(g) + f(M) = f(g) + 0$,
and $f(h + M) = f(h) + f(M) = f(h) + 0$. Since $g + M = h+M$, we get $f(g) = f(h)$. Thus, the morphism
is well-defined.



# Demoscene tools

- [WaveSabre](https://github.com/bollu/WaveSabre). [Talk at DemoBit](https://youtu.be/JjFyHI1b_Tw?t=7246)
- [aDDIct](https://conspiracy.hu/release/tool/) --- This not helpful as it contains no sources.
- [bonzomatic](https://github.com/bollu/Bonzomatic) --- useful for livecoding shaders.
- [Buzz DAW](https://en.wikipedia.org/wiki/Jeskola_Buzz)
- [Supercollider](https://supercollider.github.io/)


# Binaural Beat

> The beating effect happens when sound waves physically mix together.  Believe
> it or not though, there is a part of your brain where it mixes (adds) the
> sounds from each ear together as well.  That means that if you play similar
> frequencies to different ears, they will mix INSIDE YOUR BRAIN, and you will
> perceive a different kind of beating effect.


# Low pass filter by delaying

 I don't understand this.  Full text with context:

> For example, at a sample rate of 10kHz, one sample delay is equal to the
> sample time of 0.0001 seconds. ... A signal at 1000Hz has a period of 0.001
> seconds and a one sample time delay is 1/10 of the period, or 36°. 

I understand the math upto this point. 0.001 seconds -> 360 degrees, so 0.0001
seconds -> 36 degrees. Thus, a sample delay of 0.0001 seconds corresponds to 36
degrees of phase shift.

What's the next bit? I don't understand this:

>  The larger phase difference results in a lower amplitude and the higher
>  frequency signal is attenuated more than the lower frequency signal. The
>  effect is that of a low-pass filter. 

1. Why does a large phase shift result in a lower amplitude?
2. Why is the higher frequence signal attenuated (= weakened, as far as I understand) more?


Wiki claims that this discrete process is the "same as" the low pass filter:

```cpp
function lowpass(real[0..n] x, real dt, real RC)
    var real[0..n] y
    var real α := dt / (RC + dt)
    y[0] := α * x[0]
    for i from 1 to n
        y[i] := α * x[i] + (1-α) * y[i-1]
    return y
```

One proof strategy that I can think of:
1. Split signal into fourier components
2. Notice that if the frequency is higher than some threshold, we will start introducing phase deltas larger
   than $\pi$. This will cause cancellation of a $\sin$ wave.
3. See that this makes sure that only low frequency signals live.

I'm now trying to understand why this doesn't "wrap around". I would naively
expect: (1) low frequency = minimal destructive interference (2) high frequency
(phase difference 180 degrees) = maximal destructive interference (3) EVEN
HIGHER frequency (phase difference greater than 180 degrees) = non-maximal
destructive interference?

I believe the resolution is to remember that we only build signals upto what
Niquist lets us, so we build at max a sin wave of frequency `fs/2` where the same
period is `fs`. Thus, when we phase shift, we will get a phase of at max 180 degrees.


As to why the Niquist ratio is `1/2`, imagine a circle. a `1/2` is how much
"ambiguity" we have in the phase. In that, if we jump by more that `pi`, (ie,
more than `1/2` of the circle), we will  ????


# Octaves are double frequency apart (TODO)

As I am reading `BasicSynth`, I learnt that:

> Each half-step between notes in the
> musical scale represents a frequency ratio of $2^{1/12} \simeq 1.059$. 

The $(\cdot)^{1/12}$ is reasonable, because an octave contains 12 semitones.
The base $2$ is quite mysterious! I wanted to know why this is.


a multiple oCochlea and why frequencies are 1:2

> https://physics.stackexchange.com/questions/44469/octave-equivalence-biological-or-more

# Bias and gain

- Bias lets us move the "mean" of the  plot.
- Gain lets us move "how quickly" we get to the mean.

# Show, don't tell

Think of effects, not causes.

- It was autumn -> the leaves crunched under her feet.
- She was blind -> She felt for the chair with her white cane.

- https://www.youtube.com/watch?v=YAKcbvioxFk

# Try and think of natural transformations as intertwinings

I'm comfrotable with elementary representation theory, but I feel far less at home manipulating
natural transformations. I should try and simply think of them as the intertwinig operators
in representation theory, since they do have the same diagram. Then the functors become
two representations of the same category (group), and the natural transformation is an
intertwining operator.

If one does this, then Yoneda sort of begins to look like Schur's lemma. Schur's
lemma tells us that intertwinings between irreducible representations are either zero
or a scaling of the identity matrix. That is, they are one-dimensional, and the space
of all intertwinings is morally isomorphic to the field $\mathbb C$. If we specialize
to character theory of cyclic groups $Z/nZ$, let's pick one representation to be
the "standard representation" $\sigma: x \mapsto e^{i 2 \pi x/n}$. Then, given some other
representation $\rho: Z/nZ \rightarrow \mathbb C^\times$, the intertwining between
$\sigma$ and $\rho$ is determined by where $\rho$ sends $1$. If $\rho(1) = k \sigma(1)$
for $k \in \mathbb R$, then the intertwining is scaling by $k$. Otherwise, the intertwining
is zero. This is quite a lot like Yoneda, where the natural transformation is fixed
by wherever the functor sends the identity element.


# Subobject classifier measures how much we need to pay to access fact

- Truths are free. We don't pay any of the monoid (given $A \rightarrow B$,
  subobj assigns full monoid to image of $A$ in $B$).
- We go bankrupt trying to prove really false things (subobj assigns emptyset)
- To things that are truth adjacent, we spend some of our monoid (by dividing the filter)
  to get to the element. So we "spend money" to "fix the lie" of the element in $B$ not being truthful,
  but close enough to the truth.


# Spectral norm of Hermitian matrix equals largest eigenvalue (TODO)

Define $||A|| \equiv \max \{ ||Ax|| : ||x|| = 1 \}$. Let $A$ be 
hermitian. We wish to show that $||A||$ is equal to the largest eigenvalue.
The proof idea is to consider the eigenvectors $v[i]$ with eigenvalue $\lambda[i]$
with largest eigenvalue $v^\star$ of eigenvalue $\lambda^*$ and claim that
$||Av^\star|| = \lambda^*$ is maximal.

# Penrose cohomology [TODO]

<img src="./static/penrose-triangle.png"/>

- [I should just reach Cech Cohomology for this!](https://en.wikipedia.org/wiki/%C4%8Cech_cohomology)


# Bicycle wheel proof of Gauss Bonnet (TODO)

https://personal.psu.edu/mxl48/Bicycle_papers_files/gauss-bonnet.bicycle.pdf


# What is Levi Cevita trying to describe (TODO)

https://mathoverflow.net/questions/376486/what-is-the-levi-civita-connection-trying-to-describe/376533


# Torsion as giving monodromy of path lifts (TODO)

https://mathoverflow.net/a/111198/123769

# Cartan's spiral staircase (TODO)

https://arxiv.org/pdf/0911.2121.pdf


# Dupin indicatrix (TODO)

- Hicks notes on diffgeo

# Rodrigues curvature formula (TODO)

- Hicks notes on diffgeo (TODO)

# Weingarten map (TODO)

- Hicks notes on diffgeo

# When maps cannot be lifted to the universal cover

-  https://math.stackexchange.com/questions/1734540/existence-of-a-lifting

# Nets from Munkres (TODO)

#### Directed set
A direct set is a partial order $J$ which has "weak joins".
That is, for every $a, b \in J$, there exists a $u \in J$ such that $a \leq u$ and $b \leq u$.
It's not a join since we don't need $u$ to be UNIQUE.

#### Cofinal subset

A subset $K$ of a partial order $J$ is said to be cofinal if loosely, $\forall J \leq \exists K$.
That is, for all $j \in J$, there is a $k \in K$ such that $j \leq k$. So intuitively, $K$
is some sort of portion of $J$ that leaves out a finite part of the bottom of $J$.

#### Cofinal subset is directed

#### Nets

Let $X$ be a topological space. a net is a function $f$ from a directed set $J$ into $X$.
We usually write this as $(x_j)$. 

#### Net eventually in a subset $A$

A net $(x_j)$ is eventually in a subset $A$ if there exists an $i \in I$ such that for all
$j \geq i$, $x_j \in A$.  This is an $\exists \forall$ formula.

#### Net cofinally/frequently in a subset $A$

The net $x[:]$ is cofinally in a subset $A$ if the set $\{ i \in I : x_i \in A \}$
is cofinal in $I$. This means that for all $j \in J$, there exists a $k$ such that
$j \leq k$ and $x_k \in A$. This is a $\forall \exists$ formula. So intuitively,
the net could "flirt" with the set $A$, by exiting and entering with elements in $A$.


#### Eventually in $A$ is stronger than frequently in $A$

Let $x[:]$ be a net that is eventually in $A$. We will show that such a net is also
frequently in $A$. As the net is eventually in $A$, there exists an $e \in I$ (for eventually), such that
for all $i$, $e \leq i \implies x[i] \in A$. Now, given an index $f$ (for frequently),
we must establish an index which $u$ such that $f \leq u \land x[u] \in A$.
Pick $u$ as the upper bound of $e$ and $f$ which exists as the set $I$ is directed. 
Hence, $e \leq u \land f \leq u$. We have that $e \leq u \implies x[u] \in A$.
Thus we have an index $u$ such that $f \leq u \land x[u] \in A$.

#### Not Cofinal/frequently in $A$ iff eventually in $X - A$

##### Not Frequently in $A$ implies eventually in $X - A$

Let the net be $x[:]$ with index set $I$. Since we are not frequently in $A$,
this means that there is an index $f$ at which we are no longer frequent.
That is, that there does not exist elements
$u$ such that $f \leq u \land x[u] \in A$. This means that for all elements
$u$ such that $f \leq u$, we have $x[u] \not \in A$, or $x[u] \in X - A$.
Hence, we can choose $f$ as the "eventual index", since all elements above $f$
are not in $A$.

##### Eventually in $X - A$ implies not frequently in $A$

Let the net be $x[:]$ with index set $I$.
Since the net is eventually in $X - A$, this means that
there is an index $e$ (for eventually) such that for all $i$ such that $e \leq i$ we have
$x[i] \in X - A$, or $x[i] \not \in A$.  Thus, if we pick $e$ as the
frequent index, we can have no index $u$ such that $e \leq u \land x[u] \in A$,
since all indexes above $e$ are not in $A$. 


#### Convergence of a net

We say a net $(x_j)$ converges to a limit $l\in X$, written as $(x_j) \rightarrow l$ iff
for each neighbourhood $U$ of $l$, there is a lower bound $j_U \in J$ such that for all $k$,
$j_U \leq k \implies x_k \in U$. That is, the image of the net after $j_U$ lies in $U$. In other words,
the net $(x_j)$ is eventually in every neighbourhood of $l$. This is a $\forall \exists \forall$
formula (for all nbhd, exists cuttoff, for all terms above cutoff, we are in the nbhd)

#### Limit point of a net

We say that a point $l$ is a **limit point** of a net if $x$ is
cofinally/frequently in every neighbourhood of $A$. That is,
for all neighbourhoods $U$ of $A$, for all indexes $j \in J$, there
exists an index $k[U, j]$ such that $j \leq k[U, j] \land x[j] \in U$.
This ia $\forall \forall \exists$ formula (for all nbhd, for all
indexes, there exists a higher index that is in the nbhd).

#### Converge of a net with net as $\mathbb N$


#### Product of nets

#### Convergenge of product nets iff component nets converge

#### Nets in Hausdorff spaces converge to at most one point

#### Point $p$ is in closure of $A$ iff net in $A$ converges to point $p$


#### Function is continuous iff it preserves convergence of nets

#### Subnets


#### Subnets of a net converge

#### Accumulation point of a net

#### Subnets converge iff point is accumulation point

#### Compact implies every net has convergent subnet

#### Compact implies every net has convergent subnet

#### Universal Net

#### Every net has universal subnet

#### Universal net converges in compact space

#### pushforward of universal net is universal


#### Tychonoff's theorem

Let $\{ X_\alpha : \alpha \in \Lambda \}$ is a collection of compact
topological spaces. Let $X \equiv \prod_{\alpha \in \Lambda} X_\alpha$ be the 
product space. Let $\Phi: D \rightarrow X$ be a universal net for $X$.
For each $\lambda \in \Lambda$, the push forward net $\pi_\lambda \circ \Phi: D \rightarrow X_\lambda$
is a universal net. Thus, it converges to some $x_\lambda \in X_\lambda$.
Since products of nets converge iff their components converge, and here all the components
converge, the original net also converges in $X$. But this means that $X$ is compact
as the universal net converges.

- [Pete Clark's notes on point set topology](http://alpha.math.uga.edu/~pete/pointset.pdf)
- [Tanuj Gupta: Tychonoff theorem](https://www.math.tamu.edu/~tanujgupta17/tychonoff.pdf)


# Limit point compactness from Munkres

Munkres calls "Bolzano Weirstrass" as limit point compactness. He defines a
space $X$ to be **limit point compact** if every infinite subset of $X$ has a
limit point.

#### Compact implies limit compact

We will prove the contrapositive. That is, let $X$ be a compact set. 
If $A \subseteq X$, does not have any limit point, then $A$ is finite.
If $A$ does not have any limit point, then $A$ vacuously contains all of its limit
points. Thus, $A$ is closed. Since $A$ is a closed subset of a compact set $X$, $A$ itself
is compact. Next, see that for each $a \in A$, we can find an open $U_a$ such that $U_a \cap A = \{ a \}$.
If we can't find such a $U_a$, then it means that $a$ is a limit point!
(Since all nbhd of $a$ intersect $A$ non-trivially). Clearly, these "isolating" $U_a$ cover $A$.
Since $A$ is compact, we have a finite subcover $U_{a_i}$. See that $A = \{ a_i \}$.
To show this, since the $U_i$ cover $A$, we have $A \subseteq \cup_i U_{a_i}$. Hence,
$A = (\cup_i U_{a_i}) \cap A$, which is equal to $\cup (U_{a_i} \cap A)$ which is $\cup_i a_i$.
Hence, $A$ has finitely many points, exactly the $a_i$.


#### Classical Proof Using Bisection

Let's prove this in $\mathbb R$.
Let $C$ be a compact set containing an infinite number of points. We know from
Heine Borel that $C$ is closed and bounded. Let the interval containing $C$ be $I[0] \equiv [l, r]$.
Bisect the interval into two sub-intervals: $J[0][0] \equiv [l, m]$ and $J[0][1] \equiv [m, r]$ for $m = (l+r)/2$.
One of these must contain an infinite number of points (suppose both contain a  finite number of points, then $I[0]$
itself must contain a finite number of points, contradiction). We can thus recurse, setting $I[1]$ to be the sub-interval
that has an infinite number of points. This gives us a nested sequence of intevals $I[0] \supset I[1] \supset \dots$.
The interval $J \equiv \cap_i I[i]$ is closed as it is the intersection of closed intervals. Also, $J$ has length zero
since we bisect the interval each time. Hence, $J$ is a single point, ie $J = \{ j \}$. We claim that $j$ is an accumulation
point of the original subsequence. Any open set around $O$ will contain some interval $I[o]$

# Proof of Heine Borel from Munkres (compact iff closed, bounded)

We wish to show that compact iff closed and bounded in $\mathbb R$.

- Let $S$ be closed and bounded. We wish to show that $S$ is compact. Since $S$ is bounded,
  $S$ is contained in some large closed interval $I$. (1) Closed intervals are compact in the order topology of a
  complete total order, and thus $I$ is compact ($\mathbb R$ is a complete total order).
  Then (2) $S$ is a closed subset of a compact set $I$, and is thus compact.
  Hence closed and bounded implies compact.
- Let $S$ be compact. We wish to show that $S$ is closed and bounded. Cover $S$ with open balls of increasing
  radii. This is an open cover; Extract a finite subcover. From the finite subcover, pick the largest open ball
  $I$. $S$ is entirely contained in $I$, and is thus bounded. (3) $S$ is closed, as it is a compact subset of a 
  Haussdorff space. Hence, we are done.

#### (1) Closed intervals are compact in the topology of a complete total order.

Let us work with a complete total order $T$ (in our case $T = \mathbb R$). We equip $T$
with the order topology (which matches the usual topology on $\mathbb R$).
Let $[l, r]$ be a closed interval. Let $\{ U_i \}$ be an open cover of $[l, r]$.
Let $M$ (for middle) be the set of points $m$ such that $[l, m]$ has a finite cover using $\{ U_i \}$
That is,

$$
M \equiv \{ m \in [l, r] : [l, m] \text{ has finite cover} \}
$$

- **CLAIM 1:** $lub(M) \in M$.
- Pick an open $lub(M) \in V \in \{ U_i \}$. 
- As $V$ is open, there is some $(c \in V) < (lub(M) \in V)$.
- if $c \in M$: the finite cover of $[l, c]$ along with $V$ give a finite cover for $lub(M)$. Thus $lub(M) \in M$.
- if $c \not \in M$, then $c < lub(M)$ and $c$ is an upper bound for $M$, which is absurd.
- Thus, $lub(M) \in M$.
- **CLAIM 2:** $lub(M) = r$. This implies that $r \in M$, and $[l, r]$ has a finite subcover using $U_i$.
- For contradiction of Claim 2, assume that $lub(M) \neq r$.
- Pick some open set $O$ in the cover that contains $lub(M)$: $lub(M) \in O \in \{ U_i \}_i$.
- As $O$ is open, $O$ contains some point $c$ (for contradiction) that is after $lub(M)$: $lub(M) < c$.
- Rewriting: $c \in O \land c > lub(M)$. So, the interval $[l, c]$ has the same cover as $[l, lub(M)]$.
- Hence, $[l, c]$ has a finite cover, thus $c \in M$.
- **CONTRADICTION:** $c \in M \land c > lub(M)$, which is absurd. We would have $c = lub(M)$.
- Thus, this means that $lub(M) = r$, and thus the entire interval $[l, r]$ has finite subcover.

<img src="./static/closed-intervals-compact-in-order-topology.png" />

#### (2) Closed subset of a compact set is compact

Let $B$ be a closed subset of a compact space $K$. Take an open cover $\{ U_i \}$ of $B$.
See that $\{ B^c, U_i \}$ is a cover of the full space $K$, and hence has a finite subcover.
This subcover will be of the form $\{B^c, U_j\}$. The $\{U_j\}$ are a finite subcover of $B$.
Thus, $B$ is compact as we have extracted a finite subcover of an open cover.


#### (3) Compact subset of Haussdorf space is closed

Morally, this is true because in a Haussdorff space, single point subsets are closed.
Compactness pushes this local property to a global property --- The entire compact set
itself becomes closed.

- Let $S$ be a compact subset of a haussdorf space $X$.
- For any point $q \not \in S$, we need to show the existence of an open set $q \in Q$ such that $S \cap Q = \emptyset$.
- For each point $s \in S$, use Haussdorf to find separating sets $s \in O(s; q)$, $q \in O(q; s)$ such that $O(s; q) \cap Q(q; s) = \emptyset$.
- See that the sets $\{ O(s; q) : s \in S \}$ are a cover of $S$. 
- Extract a finite subcover of this, say $\{ O(s_i; q) : s \in S \}$. 
- Use this finite subcover to separate $q$ from $S$. 
- Now, pick the open set $Q \equiv \cap \{ O(q; s_i) \}$, which is open since it's a finite intersection. 
- See that this $Q$ separates $q$ from $S$. 
- We have that $Q \cap O(s_i, q) = \emptyset$ for each $O(s_i, q)$. 
- Thus,$Q \cap (\cup O(s_i; q)) = \emptyset$, and thus $Q \cap S = \emptyset$ as $S \subseteq \cup O(s_i; q)$.
- if $q \not \in S$, we have an open $Q$ that separates $q$ from $S$,
  thus $q$ is NOT A LIMIT --- not every open nbhd of $Q$ has non-empty intersection with $S$.
- Contrapositive: All limit points of $S$ are in $S$. Thus, $S$ is closed. (4)

<img src="./static/compact-subset-of-haussdorf-is-closed.png"/>

#### (4) A set with all limit points is closed (complement of open)

Let $S$ be a set that has all its limit points. Consider the complement set $T$. We will
show that $T$ is open.

- all points in $T$: have open that separates them from $S$. Union of all of these opens is $T$.
  $T$ open: infinite union of opens. $S$: the complement of an open set, closed.

More elaborately:

- for all all $t \in T$, $t \not in S$ (by defn).
- $t$ is not a limit point of $S$ ($S$ has all limit points).
- Thus, there is an open $U_t$ such that $t \in U_t$ and $U_t \cap S  = \emptyset$.
- Define: $T' \equiv \cup_{t \in T} U_t$. Claim: $T' = T$.
- As $U_t$ contains no elements of $S$, $T'$ contains no element of $S$.
- As $U_t$ contains $t$, $T'$ contains all $t$.
- Thus $T'$ contains all $t \in T$, and no element of $S$. So $T'$ is a complement of $S$. $T' = T$.
- $T$ is a infinite union of opens. Thus $T$ is open.
- $S$ is complement of open set $T$. $S$ is closed.

# Alexandrov topology

These are the best generalizations of finite topological spaces.
I should study them for better intuition + comptutability properties.
This is a topology where the intersection of all families of open sets
is open, not just finite intersections. The minimal neighbourhood of a point $V(x)$
is the intersection of all opens containing $x$. 

- [Alexandrov Topology](https://en.wikipedia.org/wiki/Alexandrov_topology)
- [Paper on the systematic study of Alexandrov spaces](http://emis.impa.br/EMIS/journals/AMUC/_vol-68/_no_1/_arenas/arenas.pdf)



# Zeroth singular homology group: Intuition

We wish to show that for a path connected space $X$, the zeroth singular homology group is just $\mathbb Z$.
The intuition is that the zeroth homology group is given by consider $C[1] \xrightarrow{\partial_1} C[0]$,
$C[0] \xrightarrow{\partial_0} 0$, and then taking $H[0] \equiv ker(\partial_0) / im(\partial_1) = C[0] / im(\partial_1)$.
Recall that $C[0]$ is the abelian group generated by the direct sum of generators
$\{ \Delta^0 \rightarrow X \}$, where $\Delta^0$ is the $0$-simplex, that is,
a single point. So $C[0]$ is an abelian group generated by all points in $X$. Now, $C[1]$ contains all paths
between all points $p, q \in X$. Thus the boundary of $C[1]$ will be of the form $q - p$. Quotienting by $C[1]$
identifies all points with each other in $C[0]$. That is, we get $H[0] \equiv \langle x \in X | y = z \forall y, z \in X \rangle$,
which is isomorphic to $\mathbb Z$. Thus, the zeroth singular homology group is $\mathbb Z$.


# Examples of fiber products / pullbacks

#### Fiber products of sets

If we have a set $S$, we can form a category of bundles over $S$. These are pairs
$(X, \pi: X \rightarrow S)$. The morphisms between such objects $(X, \pi: X \rightarrow S)$
and $(X', \pi': X' \rightarrow S)$ are arrows $h: X \rightarrow X'$ that
make the obvious diagram commute:


```
X ---h--> X'
 \       /
 pi     pi'
   \   /
    v v
     S
```

The product of these objects is given by the fiber product or pullback:

$$
X \times_S Y \equiv \{ (x, y)  \in X \times Y: \pi_X(x) = \pi_Y(y) \}
$$

along with the map $\pi_{X \times Y}: X \times_Y \rightarrow S; \pi((x, y)) \equiv \pi_X(x)$.
See that for consistenty, we could also have defined this as $\pi((x, y)) \equiv \pi_Y(y)$.
Since our condition is that $\pi_X(x) = \pi_Y(y)$, it all works out.
Said differently, we consider the product of fibers over the same base-point.


###### Fiber products of arbitrary bundle over a single-point base space

If $S \equiv \{ * \}$, then the projections are always $\pi(-) \equiv *$, and the fiber
product is the usual product.


###### Fiber products of singleton bundle over arbitrary base space

If $S$ is arbitrary while $P \equiv \{ p \}$ (for Point),
then this bundle $P$ will lie over some point in $S$, given
by $\pi: P \rightarrow S$, where the special point
is chosen by $\pi(p) = s_p$. If we now consider some other bundle $X$ over $S$,
Then $P \times_S X$  will pick the element $(p \in P, \pi_X^{-1}(s_p) \subseteq X)$.
That is $P \times_S X \simeq \pi_X^{-1}(s_*)$, which is the fibre of $X$ over
the special point $s_p = \pi(p)$. This explains the name.


- [Notes on scheme theory](https://www.math.purdue.edu/~arapura/preprints/schemesgalois4.pdf)	



#### Fiber products of vector bundles

Consider a fiber bundle $E \xrightarrow{\pi} B$. Now consider a new base space $B'$
with a map $f: B' \rightarrow B$. So we have the data:

```
       E
     pi|
       v
B'-f-> B 
```

Given this, we would like to pullback the bundle $E$ along $f$ to get a new
bundle over $B'$.This is defined by:

$$
E'_f \equiv \{ (b', e) : f(b') = \pi(e) \} \subseteq B' \times E
$$

This is equipped with the subspace topology. We have the projection map
$pi': E'_f \rightarrow B$, $\pi'((b', e)) \equiv b'$. The projection into
the second factor gives a map $h: E'_f \rightarrow E$, $h((b', e)) \equiv e$.
This makes the obvious diagram commute:

```
E' -h-> E
|pi'    |pi
B' -f-> B
```

Any section $\sigma: B \rightarrow E$ of $E$ induces a section of $E'$
$\sigma': B' \rightarrow E'$, by producing the function (given as a relation):

$$
\begin{aligned}
\sigma': B' \rightarrow E' \\
\sigma(b') \equiv  (b', \sigma(f(b')) \in_? E'  \simeq B' \times E
\end{aligned}
$$

This has codomain $E'$. To check, if  $(b', \sigma(f(b'))$ is in $E'$,
we need $f(b') = \pi(\sigma(f(b'))$. But this is true since $\sigma$
is a section, and thus $\pi(\sigma(f(b')) = f(b')$. 

Moreover, we need to check that $\sigma'$ is indeed a section of $B'$. For this,
we need to check that $\pi'(\sigma'(b')) = b'$. Chasing definitions, we find
that this is:

$$
\begin{aligned}
&\pi'(\sigma'(b'))
&= \pi'(b', \sigma(f(b')))
&= b'
\end{aligned}
$$

Hence we are done, we have indeed produced a legitimate section.

#### Fiber products of Spec of affine scheme 

Let $R, A, B$ be rings. consider $A \otimes_R B$. What is $Spec(A \otimes_R B)$, in terms of
$Spec(A)$, $Spec(B)$, and whatever data you like about $R$? (Say I give you both $R$ and $Spec(R)$).

The answer is that apparently, it's exactly $Spec(A) \times_{Spec(R)} Spec(B)$.



# Covariant derivative

If $x_p \equiv a \partial_x + b \partial_y + c \partial_z$ is a vector at $p \in \mathbb R^3$ and $Y$ is a vector field,
then the covariant derivative of $Y$ in the direction $X$ is given by taking the directional derivative
of each component of $Y$ along $X$:

$$
x_p |- Y \equiv (x_p \cdot Y[1], x_p \cdot Y[2], x_p \cdot Y[3])
$$

The notation `|-` is meant to suggest that $X_p$ is acting on $Y$.
For a concrete example, if $X_p \equiv (a, b, c)$ and $Y \equiv (xy^2 + 4z, y^2 - x, x + z^3)$,
then the computation yields:

$$
\begin{aligned}
&x_p |- Y \equiv (x_p \cdot Y[1], x_p \cdot Y_2, x_p \cdot Y_3) \\
& ((a \partial_x + b \partial_y+ c \partial_z ) \cdot (xy^2 + 4z),
   (a \partial_x+ b \partial_y+ c \partial_z) \cdot (y^2 - x),
   (a \partial_x+ b \partial_y+ c \partial_z) \cdot (x + z^3)) 
&= (ay^2 + 2bxy + 4, -a + 2by, a + 3cz^2)
\end{aligned}
$$

#### Property 1: Linearity in RHS

We have that $x_p |- (Y + Z) = x_p |- Y + x_p |- Z$.  This is proven by the linearity of the partial derivative.

#### Property 2: Linearity in LHS: $(x_p + x'_p)|- Y = (x_p |- Y) + (x'_p |- Y)$.

This follows as vector addition is linear, and the action of the directional derivative is linear.

#### Property 3: Scaling of LHS

$(f(p) x_p) |- Y = f(p) (x_p |- y)$

#### Property 3: Scaling of RHS

$x_p |- (fY) = (x_p f(p)) Y + f (x_p |- Y)$


$$
\begin{aligned}
&x_p |- (fY) \equiv (x_p \cdot fY[1], x_p \cdot fY_2, x_p \cdot fY_3) \\
&= ((a \partial_x|_{p_x} + b \partial_y|_{p_y} + c \partial_z|_{p_z} ) \cdot (fY[1]), \dots, \dots)
&= ((a Y[1] \partial_x|_{p_x} f + af \partial_x|_{p_x} Y[1] + 
     b Y[1] \partial_y|_{p_y} f + b f \partial_y|_{p_y} Y[1] 
     c Y[2] \partial_z|_{p_z} f + c f \partial_y|_{p_z} Y[2], \dots, \dots) \\
&= ((fa \partial_x Y[1] + fb\partial_y Y[2] + fc \partial_z Y[3]) Y +  (Y[1] a \partial_x + Y[2] b \partial_y + Y[3] c \partial_z) \cdot f, 
    \dots, \dots) \\
&= (fx_p) |- Y + (Y(p) 
\end{aligned}
$$

#### Computing $x_p |- Y$

We can compute $x_p |- Y$ once we have a curve $\sigma$ that is compatible with $x_p$.  So if
we have a curve $\sigma(0) = p$, and $\sigma'(0) = x_p$, and we know $Y$, we can then compute
$x_p |- Y$ as:

$$
\begin{aligned}
\frac{d (Y \circ \sigma(t))}{dt}|_{t = 0} \\
&Y'(\sigma(t))|_{t=0} \cdot \sigma'(t)|_{t = 0} \\
&Y'(\sigma(0)) \cdot \sigma'(0) \\
&Y'(p) \cdot x_p \\
&x_p[1] \partial_x Y[1] + x_p[2] \partial_y Y[2] + x_p[3] \partial_y Y[3] \\
&x_p |- Y
\end{aligned}
$$

Realy, we only need to  know $Y$ **along** $\sigma$  to compute the derivative, no more. 
So it's enough to have (1) a curve $\sigma$ that is compatible with $x_p$, and (2)
knowledge of the vector field $Y$ along $\sigma$.


#### Parallel vector fields

Say that a curve $\sigma$ is tangent to a vector $t_p$ if $\sigma(0) = p$ and $\sigma'(0) = t$.
Then a vector field $Y$ defined a along $\sigma$ is **parallel along** $t$ iff $t_p |- Y = 0$.
Intuitively, this means that the vector field does not change in the direction of $t_p$, so it keeps 
its value constant along $t_p$. It is as if the values of $Y(0)$ have been transported "parallely"/
"with no distortion" along the tangent $t_p$.

#### Parallel vector fields

Let $\sigma$ be a $C^\infty$ curve.     


# Clackety sounds: `bucklespring`

I've taken to running [`bucklespring`](https://github.com/zevv/bucklespring) in the background when I code,
because it makes the experience of programming so much more tactile. Having left my mechanical keyboard
in college in the time of the plague, I feel like I was sorely missing this sort of auditory feedback!


# Submersions and immersions

Who in the world decided their names? I remember which is which based on the sound. "Submersion"
is "surjective", "immersion" is "injective". But really, the naming makes no sense. I can intuitively 
submerge a ring (a 1D object) into the ocean (a 3D object). so if anything, I'd expect submersions
to be locally injective. You can only submerge $X$ into $Y$ if $Y$ is "larger" than $X$. The definition
asks for the precise opposite!

# Ehrsmann connection

Here's my current understanding of how the Ehrsmann connection works.


We have a  $G$-bundle $G \xleftarrow{\triangleleft G} P \xrightarrow{\pi} M$.
Let's first think of it as globally trivial so $P \simeq M \times G$. Now at each point
$m \in M$, we have the fiber $\{ m \} \times G$ over $m$. We now consider the kernel
of the map $\pi^*: T_{m, g} M \times G \rightarrow T_m M$. What are the elements here?
We know that $T(M \times G) \simeq TM \oplus TG \simeq TM \oplus \mathfrak g$ where $\mathfrak g$
is the Lie algebra of the lie group $G$. So we know that $\pi^*$ maps $T_p M \oplus \mathfrak g \mapsto T_p M$.
Thus the kernel of $\pi^*$ is going to be $\mathfrak g$. 
This is called as the "vertical subspace" $V_p P \equiv ker(\pi^*) \subseteq T_p P$.

Now, we have a choice in how we pick $H_p P$ for each point $p \in P$ such that $H_p P \oplus V_p P = T_p P$.
This choice of $H_p P$ is the connection. We claim that this choice is equally well encoded by a lie-algebra
valued one form, $\omega : TP \rightarrow \mathfrak g$. That is, $\omega: TM \times TG \rightarrow \mathfrak g$,
which is $\omega: TM \times \mathfrak g \rightarrow \mathfrak g$. Intuitively, this tells us how much of the component
along $\mathfrak g$ is not covered by the $H_p P$. 


The idea is that since $V_p P \oplus H_p p = T_p P$, given any vector $t_p \in T_p P$, I can compute
$t^v_p \equiv t_p - H_p(t_p)$. Then I will have $v^p \in V_p P$ since I've killed the component in $H_p P$.
However, I know that $V_p P$ is the same as $\mathfrak g$. Thus, I spit out the value $t^v_p$, treated as an
element of $\mathfrak g$. This tells me how much of $V_p$ is *not* stolen away by $H_p P$ in the decomposition.

So we have the map $\pi_h: T_p P \rightarrow V_p P$ given by $pi_h(t_p) \equiv t_p - H_p(t_p)$. The kernel
of this map is $H_p P = ker(\pi_h)$. 

#### Generalizing to Non-trivial bundles

If we have a non-trivial bundle, then I need some way to link $\mathfrak g$ with $V_p P$ without splitting the bundle
as I did here. The idea is that element of $T_p P$ are basically curves  $c_p: I \rightarrow P$. We use the curves
to build derivations. For each lie algebra element $a \in \mathfrak g$, I can build the curve
$c^a_p: I \rightarrow P$ given by $c^a_p(t) \equiv p \triangleleft \exp(at)$. That is, the curve I get by pushing
the point $p$ along $a \in \mathfrak g$.  Note that all the points in the curve $a^p$ lie on the same point
in the base manifold, because the group only moves within fibers. So we have that $\pi(p) = \pi(c^a_p(t))$ for all $t$.
This means that when we push forward the curve $c^a_p(t)$, it represents the constant curve, which has zero derivative!
Thus, we have that all these curves are in the kernel $c^a_p(t) \in ker(\pi^*)$, and hence $\mathfrak g \subseteq V_p P$.
To show the other inclusion, pick some element $v_p \in V_p P \subseteq T_p P$. The group $G$ must be non-trivial,
otherwise the bundle will also be trivial. Let $p \in \pi^{-1}(m)$ for some $m$. Note that since the bundle is a principal
bundle, we have that the fiber $\pi^{-1}(m)$ is a $G$-torsor. I guess this is ismorphic as a group to $G$. Now, the
tangent space $T_p P$ is the tangent space the group $G$, which has the same dimension as the lie algebra $\mathfrak g$.
Hence, the function we defined above must be surjective.

NOTE TO SELF: there should be a more direct proof that uses the fact that the fiber is $G$-torsor!

# Quotes from the culture

> “Empathize with stupidity and you’re halfway to thinking like an idiot,”

> 'Absolutely not.  Common misconception that; that fun is relaxing.  If it is,
> you're not doing it right.  That's what the Hole's for; fun.  Fun and games.
> Cools down a bit during the day, but it can get pretty wild, too.  The drink
> festivals are usually the worst.  Shouldn't be any trouble tonight though.
> Fairly quiet.'


> Excuse me, rector,' Gurgeh said, rising.  The old apex's gaze followed him.
> 'Duty calls.' 'Obey,' Hamin said.

> The drums are made from human skin; you can see why each set is called a
> family.

> 'Absolutely not.  Common misconception that; that fun is relaxing.  

> As the adage said; falling never killed anybody; it was when you stopped…


> This is not a heroic age,' he told the drone, staring at the fire.  'The
> individual is obsolete.  That's why life is so comfortable for us. We don't
> matter, so we're safe

> Genetechnologically, it's been within their grasp for hundreds of years, but
> it's forbidden.  Illegal, if you remember what that means.' Gurgeh nodded



> As with all sentient Culture constructs, its precise character had not been
> fully mapped out before its construction, but allowed to develop as the
> drone's mind was put together.  The Culture regarded this unpredictable
> factor in its production of conscious machines as the price to be paid for
> individuality, but the result was that not every drone so brought into being
> was entirely suitable for the tasks it had initially been designed for.


> So it's false.' 'What isn't?' 'Intellectual achievement.  The exercise of
> skill.  Human feeling.'


> Just another belch in the darkness. Sound but not a word, noise without
> meaning.

> There seemed little point in telling the creature when; the Dra’Azon called
> every time “now” even though their language used tenses. 


> We are water falling, itinerant and vague, ever seeking the lowest level,
> trying to collect and connect. We are vapor, raised against our own devices,
> made nebulous, blown on whatever wind arises. To start again, glacial or not.

> the urge not to feel useless. The Culture’s sole justification for the
> relatively unworried, hedonistic life its population enjoyed was its good
> works; the secular evangelism of the Contact Section, not simply finding,
> cataloguing, investigating and analyzing other, less advanced civilizations
> but—where the circumstances appeared to Contact to justify so doing—actually
> interfering (overtly or covertly) in the historical processes of those other
> cultures.


> And if we tamper with our inheritance, so what? What is more ours to tamper with? 

> It was a young, unstable sort of bitterness, a kind of fake, something she
> assumed for a while, like a child trying on adult clothes. She luxuriated in
> the feeling of being old and disillusioned for a moment, then let it drop.

> Idir was never attacked, and technically never surrendered. Its computer
> network was taken over by effector weapons, and—freed of designed-in
> limitations—upgraded itself to sentience, to become a Culture Mind in all but
> name.


> The voice sounded like congealing fat being poured into a jug; 

> It would have helped if the Culture had used some sort of emblem or logo;
> but, pointlessly unhelpful and unrealistic to the last, the Culture refused
> to place its trust in symbols. It maintained that it was what it was and had
> no need for such outward representation.


> Just as it could not imprison itself with laws, impoverish itself with money
> or misguide itself with leaders, so it would not misrepresent itself with
> signs.

> There was something too about the inexactitude of it all that the Mind found
> almost frightening. It could look at some carefully machined piece of metal
> or some delicately molded bit of plastic, and know that to the people who had
> built the Command System—to their eyes—these things were exact and precise,
> constructed to fine tolerances with dead straight lines, perfect edges,
> smooth surfaces, immaculate right angles… and so on. But the Mind, even with
> its damaged sensors, could see the rough edges, the crudity of the parts and
> the components involved. They had been good enough for the people at the
> time, and no doubt they had fulfilled the most important criterion of all;
> they worked


> So it had effectively frozen its primary memory and cognitive functions,
> wrapping them in fields which prevented both decay and use. It was working
> instead on back-up picocircuitry, in real space, and using real-space light
> to think with (how humiliating).


> the most select group of rich psychotics in the human galaxy, here to play
> the game that is to real life what soap opera is to high tragedy.

> Originally Damage was played on such occasions because only during the
> breakdown of law and morality, and the confusion and chaos normally
> surrounding Final Events, could the game be carried out in anything remotely
> resembling part of the civilized galaxy; which, believe it or not, the
> Players like to think they’re part of. 




# Lie bracket commutator from exponentiation (TODO)

I thought this was quite cute. To make sense of $[a, b]$ we consider
the expression $e^{\epsilon a} e^{\epsilon b} e^{- \epsilon a} e^{- \epsilon b}$ which is equivalent to:

$$
\begin{aligned}
&(1 + \epsilon a + \epsilon^2 a^2/2)(1 + \epsilon b+ \epsilon^2 b^2/2)(1 - \epsilon a + \epsilon^2 a^2/2)(1 - \epsilon b + \epsilon^2 b^2/2)  \\
&[(1 + \epsilon a + \epsilon^2 a^2/2)(1 - \epsilon a + \epsilon^2 a^2/2)] [(1 + \epsilon b+ \epsilon^2 b^2/2)(1 - \epsilon b + \epsilon^2 b^2/2)]  \\
&[((1 +\epsilon^2 a^2/2) + \epsilon a)((1 + \epsilon^2 a^2/2) - \epsilon a)] [(1 + \epsilon^2 b^2/2+ )  \epsilon b) ((1 + \epsilon^2 b^2/2)  - \epsilon b)]  \\
&[((1 +\epsilon^2 a^2/2)^2 -  \epsilon^2 a^2)] [(1 + \epsilon^2 b^2/2^2 -  \epsilon^2 b^2)]  \\
\end{aligned}
$$

TODO

# Thoughts on proof of fundamental group of unit circle

#### Definition of covering space

It's important that when we say that $p^{-1}(U) = U \times F$, that the local
homeomorphisms of $U \times {i} \rightarrow U$ is given by $p|_{U \times \{ i \}}$:
it is not **some other map** that gives us the homeomorphism, but $p$ itself.
This makes $p$ locally bijective on a nbhd.


#### Path lifting

> A time varying embedding can be lifted for all time given a lift of initial conditions.
> A smoothly varying family of embeddings can be filted given an initial lift.

The fact that we work with intervals are of paramount importance. They are compact,
and we can thus use induction to path lift.

- [Kan extension condition](https://www.imsc.res.in/~kapil/geometry/topol/kan.html)


# Pasting lemma

Let $f: X \rightarrow Y$ be a function.
Let $A, B$ are closed subets of $X$ such that $X = A \cup V$. Then $f$ is continuous iff
$f|_A$ and $f|_B$ are continous.

#### Forward: $f$ continuous implies restriction continuous

This is clear from how restrictions work. Pick $i: A \rightarrow X$ to be the
function that embeds $A$ with the subspace topology into $X$. This is continuous by
the definition of the subspace topology. Now define $f|_A : A \rightarrow Y \equiv f \circ i$.
which is continous since it is the composition of continuous functions. 

#### Backward: restrictions continuous implies $f$ continuous.

Let $V \subseteq Y$ be closed. Then $f_A^{-1}(V)$ is closed in $A$ by the continuity of $f_A$
Now see that $f_A^{-1}(V)$ is closed in the subspace topology of $A$  means that
there is some closed $P \subseteq X$ such that $f|_A^{-1}(V) = A \cap P$.
Since both $A$ and $P$ are closed in $X$, this means that $f^{-1}(V)$ is closed
in $X$ (see that we have filted "closed in $A$" to "closed in $X$).
Similarly, we will have that $f|_B^{-1}(V) = B \cap Q$ for some closed $B$ and $Q$.
Then we can write:

$$
\begin{aligned}
&f^{-1}(V) \\
&= f|_A^{-1}(V) \cup f|_B^{-1}(B) \\
&= (A \cap P) \cup (B \cap Q) \\
&= \texttt{finite union of closed sets} \\
&= \texttt{closed} \\
\end{aligned}
$$

# Tensoring with base ring has no effect

If $0 \rightarrow M' \rightarrow M \rightarrow M''$ is an exact sequence of $A$ modules,
then so is $0 \rightarrow A \otimes M' \rightarrow A \otimes M \rightarrow A \otimes M''$.
(As an aside, the order is $M', M, M''$ since the middle term $M$ is somehow
put together from the other two. So $M$ is the primary. Then by human
convention, we choose the single prime on the left and the double prime on the
right).


# Seeing the semidirect product of the dihedral group.

Think of rigid motions of a hexagon. Let's focus on a single edge.
See that the movement of this edge determines everything else. 
So let's see where this edge can go to. There are six different
locations it can go to, by "rotating". Not only that, but we can 
also "flip" the edge (by flipping the entire hexagon!) This means
we have two types of transformations we can perform on this single
edge, that determines everything else: (1) rotating it, moving it to another
location, and (2) flipping the edge. We might naively decide to mathematically
encode the different moves we can make as `(angle, flip)`, which represents
(a) rotating by an angle, and (b) flipping the hexagon. The next question
one asks is how to write the result of performing one move after another?
- If we have two rotations, we can compose them into another rotation.
- If we have two flips, they compose to become no flip at all.
- What happens if we have `(angle1, flip=true)` followed by `(angle2, flip=False)`?

In fact, there is a subtlety here. What do we mean by "rotate by an angle"? How do
we determine "clockwise" and "anti-clockwise"? There are two choices:
- 1. Define these "from the top view", as viewing the hexagon as the face of a clock.
- 2. Define this "from the view of the edge", as rotating in the direction of the edge. 

We must make one of the two choices.

TODO: mathemagize this.

# Animating rotations with quaternion curves

- [Reference: classic paper](http://graphics.cs.cmu.edu/nsp/course/15-464/Fall05/assignments/p245-shoemake.pdf)
- [Comp.graphics usenet FAQ](http://www.faqs.org/faqs/graphics/algorithms-faq/)

# Mnemonic for hom-tensor and left-right adjoints 

- Remember the phrase `tensor-hom` adjunction, thus tensor is left adjoint.
- Remember that the type of an adjunction is `(f x -> y) -> (x -> g y)` and here,
  `f` is left adjoint, `g` is right adjoint. Then see that currying is
  `((p, x) -> y) ->(x -> (p -> y))`. Thus tensor is left adjoint, hom is right
  adjoint.
- Remember that RAPL (right adjoints preserve limits); Then recall that
  tensoring a direct limit (a colimit) preserves the tensor, as a colimit retains
  torsion (example: prufer group has torsion, its components also have torsion; tensor can detect this by
  tensoring with $\mathbb Q$).
  On the other hand, tensoring of an inverse-limit (a limit) is not preserved:
  think of p-adics. Each of the components have torsion, but the p-adics do not.
  Thus, tensor DOES NOT preserve limits (inverse limits). And so, tensor CANNOT
  be right adjoint; tensor must be left adjoint.
- Since tensor is right exact, because it kills stuff, and could this destroy
  injectivity, it is left adjoint.


# Construction of tensor product: Atiyah macdonald

I've only seen two ways of seeing the tensor product: (1) for vector
spaces, where one uses a basis, and (2) the universal property, that
describes the point of the tensor product.
This is the first hands-on-but-not-basis construction
of the tensor product I've seen, and so I record it here.
Let $R$ be the base ring. We are tensoring the modules $M$ and $N$.

- Create the free $R$ module $F \equiv R^{M \times N}$ whose elements are
  free linear combinations of tuples from $M$ and $N$.
- Let $K$ (for kill) be the submodule generated by the equations:
  (1) $(x + x', y) - (x, y) - (x', y)$,
  (2) $(x, y + y') - (x, y) - (x, y')$,
  (3) $(rx, y) - r \cdot (x, y)$
  (4) $(x, ry) - r \cdot (x, y)$
- Let $T \equiv F/K$. Denote the element of each $(x, y) \in F$ in the
  quotient $F/K$ as $x \otimes y$. Then $T$ is generated by such elements.
- From our quotients, we have the equation $(ax) \otimes y = a (x \otimes y) = x \otimes (ay)$,
  and $(x + x') \otimes y = x \otimes y + x' \otimes y$, and finally
  $x \otimes (y + y') = x \otimes y + x \otimes y'$.

Any $R$-module map map $f: M \times N \rightarrow O$ where $O$ is an $R$-module extends by
linearity into   $f_F: F \rightarrow O$ as $f_F(\sum_i r_i (x, y)) \equiv r_i f(x, y)$.
We also have a map $-/\sim : F \rightarrow T$

```
 F=R^{MxN} →fF→ MxN →f→ O
 ↓               ↑
 F/~             fT
 ↓               ↑
 T=M(x)N →→fT→→→→*
```

For this diagram to commute, we need the fibers of $(f \circ f_F): R^{MxN} \rightarrow O$ to take constant values for each $o \in O$.
Unwrapping that condition implies that $f$ is bilinear. So, the condition
$f_T(x \otimes y) = f(x, y)$ uniquely determines $f_T(x \otimes y)$ if $f(x, y)$ is bilinear. 
If not, the map $f_T$ is ill-defined, as we cannot "kan extend" $f_F$ along $f_T$.



# Recovering topology from sheaf of functions: Proof from Atiyah Macdonald

Let $X$ be a compact Haussdorff space. Such a space is normal (T4), so we can separate closed subsets
by open neighbourhoods. This also means that the space obeys the Urhyson lemma, so we can construct
continuous functions that take value $0$ at some point and $1$ at some other point. We will use this
to argue about zero sets of functions.

- We will first show a strong nullstellensatz like theorem, showing that every maximal ideal $m$ of 
   the ring of continuous functions $C(x)$ is in bijection with the set of functions that vanish at a point, $V(x)$.

- Let $C(X)$ be the ring of all continuous real valued functions on $X$. For each $x \in X$, define
  $I(x) \subseteq C(X)$ to be the set of functions that vanish at $x$. 
  This is a maximal ideal, because it is the kernel of the evaluation map $f \mapsto f(x)$.

- Given some maximal ideal $m \subseteq C(X)$, we will show that there is some point $p \in X$ such that
  $m = I(p)$. To show this, first consider the common zeros of functions in $m$, $V(m) \equiv \{ x \in X : f(x) = 0 \forall f \in m \}$.
  We first show that $V(m)$ is non-empty, and we then show that $V(m)$ contains exactly one point.

- To show $V(m)$ is non-empty, suppose for contradiction that $V(m)$ is empty. Thus, for each point $x \in X$,
   not all functions in $m$ vanish at $x$ (otherwise $x \in V(m)$).
   So, there is a function $f_x \in m$ that does not vanish at $x$, hence $f_x(x) \neq 0$. Since $f_x$
   is continuous, there is some open neighbourhood $x \in U_x$ where $f(U_x) \neq 0$. (A continuous function
   that does not vanish at a point cannot "suddenly" decay to zero. It will be non-zero over an open nbhd).
   Since the space $X$ is compact, we have a finite number of $U_{x_i}$ that cover $X$. Hence, we build a function
  $c \equiv \sum_i f_{x_i}^2$ ($c$ for contradiction) that vanishes nowhere. This means $c$ is a unit.
  But we must have $c \in m$ as $c$ is built out of functions  $f_{x_i} \in m$. This is a contradiction as a unit
  cannot belong to a maximal ideal. Thus, $V(m)$ contains at least one point.

- To show that $V(m)$ contains exactly one point, suppose that $V(m)$ contains a single point $x$.
   This means that all functions in $m$ vanish at $x$. Thus, $m \subseteq I(x)$, since $I(x)$ contains all functions
   (not just ones in $m$) that vanish at $x$. But $m$ is maximal, and hence $m = I(x)$. This tells us that
   every maximal ideal $m$ corresponds to some vanishing set $I(x)$.

- We will next show that every vanishing set $I(x)$ is distinct. We already know that it is maximal. This gives us an 
   injection. Let $I(p), I(q)$ be two vanishing sets for distinct points. Let $z_p$ be the function constructed from
   Urhyson's lemma that is zero at $p$ at nonzero at $q$. Thus, we have $z_p \in I(p)$ and $z_p \not \in I(q)$. Hence,
   $I(p) \neq I(q)$. This shows that the maximal ideals $I(p), I(q)$ will be distinct.

- We have thus established a **bijection** / **nullstellensatz** between zero sets maximal ideals $V(m)$ and 
   functions that vanish at a point $I(p)$.


- We will next show that this provides a homeomorphism. It suffices to consider basic open sets. We know that the
   sets $D_{spec}(f) = \{ m \in C(X) : f \not \in m \}$ is a basis for the maximal spectrum of the ring under zariski.
   We will show that $D_{top}(f) \equiv \{ x \in X: f(x) \neq 0 \}$ is a basis for the topology of $X$. Then the function
   that takes points to maximal ideals of functions that vanish at that point will provide a topological homeomorphism.
   Thus, we have shown that the maximal spectrum of the ring allows us to recover the topology of the underlying space!


- We wish to show that the open set $D_{top}(f)$ form a base for the topology on $X$. So consider an open set 
   $U \subseteq X$. Now think of $U^c$ which is closed. We build the function $d(x, U)$ such that $d(x, U)(x) = 1$
   and $d(x, U)(U^c) = 0$ by invoking Urhyson. Therefore, $x \in D_{top}(d(x, U)) \subseteq U$. So the set $U$ can be
   covered with $\{ D_{top}(d(x, U)): x \in U \}$, which means the sets $D(d(x, U))$ form a base of the topology on $X$.

- We wish to show that the open sets $D_{spec}(f)$ form a base for the topology on $maxSpec(C(X))$. Let $U$ be a
   closed  set in $maxSpec(C(X))$. 

-  We wish to show that the open set $D_{spec}(f)$ have homeomorphisms $D_{top}(f)$. This completes the isomorphism into a 
   homeomorphism, and we have thus completed the proof that we can recover the topology from the spectrum.

- Consider the function $zero: X \rightarrow mSpec(C(X))$  sending the point $x$ to the kernel of the evaluation map at $x$.
   Let $D_{spec}(f) \subseteq mSpec(C(X))$ be a basic open of $mSpec(C(X))$. Consider $zero^{-1}(D_{spec}(f))$.
   This will contain all those points $x \in X$ such that $zero(x) \in D_{spec}(f)$. This means that it will contain
   point $x \in X$ such that $f$ does not vanish at those points, as (1) $zero(x) \in D_{spec}(f)$ implies
   (2) $f \not \in zero(x)$ which implies $f(x) \neq 0$. Clearly, this is an open subset of $X$, as it is the
   complement of the closed set $f(x) = 0$ [zero sets are always closed]. Furthermore, the set $zero^{-1}(D_{spec}(f))$
   maps to what we would expect; it trades the algebraic definition of "does not vanish" to the geometric one,
   while describing the exact same phenomena.

# Urhyson's lemma 

We don't know any continuous functions on compact Haussdorf spaces; Let $X$ be a topological space. What functions
$X \rightarrow \mathbb R$ are continuous? We only have the constant functions!
If $X$ is a metric space, can we get more continuous functions? We can probably do something
like $f_p(x) \equiv d(p, x)$. But the compact Haussdorf spaces are very nice, we should know
*something* about them!

we often asumme we have an embedding (a homeomorphism) of a compact Haussdorff space $X$ into $\mathbb R^n$,
I then get so many continuous functions! I can take the polynomials on $\mathbb R^n$ and restrict to $X$.
Polynomials are dense in the compact-open topology! (Stone-Weirstrass)

### Normal space (T4)

A space where points are closed, and two disjoint closed subsets can be separated by open neighbourhoods. It's
stronger than haussdorf, because we can separate subsets, not just points.

### Urhyson lemma

If $X$ is normal and $A, B$ are closed disjoint subsets of $X$, there exists a continuous
function $f: X \rightarrow [0, 1]$ such that $f(A) = 0$ and $f(B) = 1$. This gives us
"interesting continuous function" on an arbitrary topological space.

We ask for normal, because compact Hausfdorff spaces are normal. So "good smooth manifolds"
for example, are normal.

### Lemma: Re-characterization of normality

If $X$ is normal and $C \subseteq O \subseteq X$ with $C$ closed, $O$ open, then there
exists a set $U \subseteq X$ that is open such that $C \subseteq U \subseteq \overline{U} \subseteq O$.
(In fact, this is iff!) See that we "reverse the direction"; We started with closed-open, we end with
closed-(open-closed)-open.

- Consider $C$ and $O^c$. These are two closed sets. Since $C$ is contained in $O$,
  $C$ does not meet $O^c$ ($C \subseteq O$, we have $C \cap O^c = \emptyset$). 
- By normality, we have two opens $P, Q$ such that $C \subseteq P$, $O^c \subseteq Q$, and $P \cap Q = \emptyset$.
- So we have $C \subseteq P$, and $P \subseteq Q^c$. This gives us $C \subseteq P \subseteq Q^c \subseteq O$.
- We have $\overline{P} \subseteq Q^c$ as $P \subseteq Q^c$ and $Q^c$ is closed, and thus contains all of its limit points.
- This together gives $C \subseteq P \subseteq \overline{P} \subseteq Q^c \subseteq O$.

### Proof: Intuition

- Suppse we succeeded. Then the only thing we know is that the space is normal, so it is
  rich in open sets. We're going to convert the existence of a continuous function into properties
  of open pre-images. We will then show that we have "enough opens" in $X$ to build the continuous
  function using the pre-image characterization.
- Suppose we succeeded. Then $[0, p) \subseteq [0, 1]$ is open in the subspace topology.
- Define $U_p \equiv f^{-1}([0, p)) \subseteq X$. Each of these $U_p$ are included in one another as we make $p$
  larger.
- In fact, we have 

$$U_p = f^{-1}([0, p)) \subseteq f^{-1}([0, p]) \subseteq f^{-1}([0, q)) \subseteq f^{-1}([0, q]])$$

- We have that $\overline{U_p} = f^{-1}([0, p]) \subseteq U_q = f^{-1}([0, q))$ for $p < q$.
- If we now think of the original sets, we needed $f(A) = 0$, $f(B) = 1$. So we must have that $A \subseteq f^{-1}([0, p))$
  for all $p > 0$. 
- Similarly, we have that $U_p \subseteq B^c$ for $p < 1$, as till $p$ reache $1$, we cannot get to $B$.
- This gives us $A \subseteq U_p \subseteq B^c$.
- This is the only properties we will use to reconstruct $f$!
- Really, I only need a dense subset of $U_p$. So let's say I pick $\{ U_p : p \in \mathbb Q \}$.
- I can reconstruct $f(x)$ by first thinking of $f(x)$. There are sets $U_p$ that reach towards $f(x)$.
  Consider the closest such
- So take $y = sup(\{ p \in \mathbb Q : p \leq f(x) \} \cup \{ 0 \})$. Because $\mathbb Q$
  is dense in $\mathbb R$, this works out and we get $y = f(x)$
- But if $p \leq f(x)$, this means $x \not \in U_p$ since $U_p$ covers $[0, p)$. So we write this as:
  $y = sup(\{ p \in \mathbb Q : x \not \in U_p \} \cup \{ 0 \})$. Because $\mathbb Q$
  is dense in $\mathbb R$, this works out and reconstructs for us us $y = f(x)$
  (see that we did not use $f$ in the definition of $y$).


### Claim 1

Claim: If $P \subseteq (0, 1)$ is dense, and $\{ U_p \}_{p \in P}$ is a collection of open subsets of $X$
indexed by $p$, such that:

1. $A \subseteq U_p \subseteq B^c$.
2. $\overline{U_p} \subseteq U_q$ whenever $p < q$

Then $f(x) = sup(\{ p \in P : x \not \in U_p \} \cup \{ 0 \})$ is continuous and $f(A) = 0$, $f(B) = 1$.
See that we don't even need normality! (Time: 29:30 in video)

- **Proof:** It's clearly well defined based on $sup$. If it's continuous, then it obeys the properties
  based on the containment assumptions (1) and (2).
- For $p \in P$, We claim $x \not \in U_p \implies f(x) \geq p$. If $x \not \in U_p$,
  then $p$ is in the set of points we take a $sup$ over. Hence, we have that $f(x) \geq p$
  since $f(x)$ is the $sup$.
- The contrapositive is that $f(x) < p \implies x \in U_p$. 
- To show $f: X \rightarrow [0, 1]$ is continuous, it suffices to show that preimages of open 
  sets are open for a basis. We know a basis consisting of intervals $\{ (p, q) : p, q \in P \}$.
  We need to show that $f^{-1}((r_0, s_0))$ is open for $r_0, s_0 \in P$ with $0 < r_0 < s_0 < 1$.
  [The cases where $r_0 = 0$ or $s_0 = 1$ are easy modifications].
- Choose a $x \in f^{-1}((r_0, s_0))$. Since $P$ is dense, we can find $r_x, s_x$ such that
  $r_0 < r_x < x < s_x < s_0$.
- We claim that $x \in \overline{U_{r_x}}^c \cap U_{s_x}$. $\overline{U_{r_x}}^c$ is open as it is 
  the complement of a closed set. Hence, we have shown that $x$ is in this open nbhd.
- Since $f(x) < U_s$, we must have $x \in U_s$ by our contrapositive.
- We claim that $x \not \in \overline{U_r}$. Proof by contradiction; suppose $x \in \overline{U_r}$,
  hence $r < f(x)$.
  Then, for any $r' \in P$ such that $r < r' < f(x)$, we would have $x \in U_r'$ (by 2).
  We claim that this is A CONTRADICTION.
- Since $f(x) = sup(\cdot)$, and $r < f(x)$ we have something in the $sup$ that is bigger than $r$.
  Let this thing be $r'$ such that $x \not \in U_{r'}$. But this is a contradiction to $x \in \overline{U_r}$.
- TODO: there is more to proof!

#### Claim: $P \equiv \mathbb Q \cap (0, 1)$

With $P \equiv \mathbb Q \cap (0, 1)$ there exists a collection $\{ U_p \}_{p \in P}$ as we need.

We will prove this by induction. Choose an bijection $\mathbb Q \cap (0, 1) \equiv \{ p_1, p_2, \dots \}$.
Let $P_n \equiv \{ p_1, p_2, \dots, p_n \}$. To define $U_{p_i}$ choose an open set such
that:

$$A \subseteq U_{p_1} \subseteq U_{p_1}^c \subseteq B^c$$

Such a set exists by our characterization of normality.
Now suppose $U_{p_1}, \dots U_{p_n}$ have been constructed such that $\{ U_p \}$
satisfies the claims (i), (ii). To construct $U_{p_{n+1}}$. Recall that the $p_i$
can be in arbitrary order, since we choose an arbitrary bijection. So let
$r$ be the index such that $p_r$ comes right before $p_{n+1}$, and $s$ comes
right after $p_{n+1}$. This gives us $r = \max \{ p_i | 1 \leq i \leq n \land p_i < p_{r+1} \}$,
$s = \min \{ p_i | 1 \leq i \leq n \land p_i < p_{r+1} \}$. Then $r \leq s$ and $\overline U_r \subseteq U_s$.
Thus by our characterization of normality, there exists an open $V$ such that:

$$
\overline U_r \subseteq V \subset \overline V \subseteq U_s
$$


#### Tietze Extension theorem


If $X$ is normal, $A \subseteq X$ is closed, given a continuous bounded function $f: A \subseteq \mathbb R$
then there exists and continuous and bounded function $F: X \rightarrow \mathbb R$ such that $F|A = f$.

#### Urhyson's Metrization theorem

A normal space with a countable basis is metrizable. We know that metrizable is normal. This says
that normal is not so far away from metrizable.

#### Embedding of topological manifolds

If $X$ is a compact topological $n$-manifold, then there exists an embedding into some $\mathbb R^m$.
That's saying that there are "m" very interesting continuous functions, the coordinate functions! So it
makes sense Urhyson's is involved.




#### References
- [Urhyson's Lemma video](https://www.youtube.com/watch?v=UQas4Cu89D0)
- [Urhyson's Lemma lecture notes](http://therisingsea.org/notes/mast30026/lecture22.pdf)

# Compact Hausdorff spaces are normal


Let $C, D$ be two disjoint closed subsets. We wish to exhibit disjoint opens
$U, V$ which separate $C, D$. Formally, we want $C \subseteq U, D \subseteq V, U \cap V = \emptyset$.


The crucial idea is to take all pairs of points in $C \times D$, and use
Hausdorffness to find opens $\{ (U_{cd}, V_{cd}) : (c, d) \in C \times D \}$
such that $c \in U_{cd}, d \in V_{cd}, U_{cd} \cap V_{cd} = \emptyset$.  which
separate all pairs $c$ and $d$, and then to use compactness to escalate this
into a real separating cover.

Now that we have the pairs, for a fixed $c_0 \in C$, consider the cover
$\cup_{d} V_{cd} $. This covers the set $D$, hence there is a finite subcover
$D \subseteq V_{cD} \equiv \cup_{d_i} V_{c {d_i}}$. Now, we go back, and build the set
$c \in U_{cD} \equiv \cap_{d_i} U_{c {d_i}}$. This is the intersection of a finite
number of opens, and is hence open. So we now have two sets $U_{cD}$ and $V_{cD}$
which separate $c$ from $D$. We can build such a pair $U_{cD}, V_{cD}$ that separates
each $c$ from all of $D$. Then, using compactness again, we find a finite subcover of
sets $U_{c_i D}, V_{c_i D}$ such that the $U_{CD} \equiv \cup_{i=0}^n U_{c_i D}$ cover $C$, each of the
$V_{c_i D}$ cover $D$ (so $V_{CD} \equiv \cap_{i=0}^n V_{c_i} D$ covers $D$). This gives
us our final opens $U_{CD}$ and $V_{CD}$. that separate $C$ and $D$.

# Stone representation theorem: Proof from Atiyah Macdonald

A boolean ring is one where for every element $r \in R$, we have $r^2 = r$. We first
study boolean rings abstactly and collect their properties. Secondly,
we show an isomorphism between complete lattices and boolean rings.
Thirdly, we use the topology from $Spec$ to import a topology on complete lattices,
which will be Haussdorf and completely disconnected. 

#### In a boolean ring, all prime ideals are maximal.

Let $p$ be a prime ideal, and let $x \in p$. One is tempted to use jacobson like arguments,
and thus one considers the element $(1 - x)$. Since in this ring, we have $x^2 = x$,
this means that $x(1 - x) = 0$. Hence, we have $x(1 - x) \in p$. This is not so
useful, until we notice that we never used the fact that $x \in p$!. So pick some **arbitrary**
element $y \in R$. To show $p$ a prime ideal is maximal, let $y \not \in p$. Then we know
that $1 - y \in p$. Thus, if $y$ we were added to $p$ (ie, we try to create a larger ideal $m = (y, p)$),
we get $1 - y + y = 1 \in p$. Thus, the ideal $m = (y, p) = 1$ when $y \not \in p$. Thus, $y$
is maximal.

#### In a boolean ring, $2 = 1 + 1 = 0$. More generally, $2x = 0$ for all $x$.

Showing $2x = 0$ is the same as showing $x = -x$. We know that $(-x) = (-x)^2 = x^2 = x$
as in this ring $x^2 = x$ for all $x$. Hence, we have that $x = -x$ or $1 = -1$ or $2 = 0$.


#### In the spectrum of a boolean ring, $D(f)$ for $f \in R$ is clopen

That is, the basic open sets of the prime spectrum of the ring are all clopen. The basic
open sets $D(f)$ (where $D$ stands for doesn't vanish on the prime spectrum)
are open by definition. To show that $D(f)$ is open, we need to find
an ideal $I$ such that $D(f) = V(I)$. Consider $g \equiv 1 - f$. We know
that $f(1 - f) = 0$ for all $f$ and we are considering the prime spectrum.
Thus, either $f$ or $(1 - f)$ must vanish at each point because $f(1 - f)$ vanishes
at each point: so $f(1 - f) = 0 \in p$ implies $f \in p$ or $(1 - f) \in p$.

- To see that $V(1 - f) \subset D(f)$, let $p \in V(1 - f)$. Hence, $1 - f \in p$. Thus, we have
  $f \not \in p$: if $f$ and $(1 - f)$ are both in $p$, then $1 \in p$ which is absurd as $p$ is a proper ideal.
  Hence, $p \in D(f)$. Thus, $V(1 - f) \subset D(f)$.
- To see that $D(f) \subset V(1 - f)$, let $p \in D(f)$, hence $f \not \in p$. But $f(1 - f) = 0 \in p$ since
  the ring is boolean. Hence $(1 - f) \in p$ by the primality of $p$ and since $f(1 - f) \in p$.
  Thus, $p \in V(1 - f)$. Hence, $D(f) \subset V(1 - f)$.

This shows us that each basic open set is clopen, as each basic open is both open and closed.

#### for all rings, The space $Spec(R)$ is quasi-compact: every open cover of $Spec(R)$ has a finite subcover of $Spec(R)$.

We generally only call Haussdorf spaces "compact". The covering property is called "quasi-compact"

Consider an open covering $C_i$ such that $\cup C_i = Spec(R)$. Since the base of the topology
is the doesn't vanish sets, we can write each $C_i$ as $C_i = \cup_j D(f_{ij})$. Hence we have that
$Spec(R) = \cup_{i, j} D(f_{i, j})$. This is the same as saying:

$$
\begin{aligned}
&\emptyset = Spec(R)^c \\
&= (\cup_{i, j} D(f_{i, j}))^c  \\
&= \cap_{i, j} D(f_{i, j})^c \\
&= \cap_{i, j} V(f_{i, j})^c \\
\end{aligned}
$$

Recall that intersecting vanishing sets is the same as building an ideal containing all those functions.
So we have an ideal $I \equiv (f_{11}, f_{12}, \dots, f_{21}, \dots, f_{ij})$. 
Saying that the intersection of all $V(f_{ij})$ is empty is saying that $I = R$. 
This is by strong nullstellensatz, which states that every maximal ideal (and hence, every ideal which is contained in some maximal ideal)
must have some solution. The only way to not have a solution (ie, to vanish nowhere) is to generate the entire ring.
Thus, we must have that $I \equiv (f_{ij}) = R$, and hence $1 \in R$ implies $1 \in I = (f_{ij})$.
In an ideal, we only ever take **finite sums**. So $1$ is a **finite** linear combination of some $f_{ij}$. So we have
the equation:

$$
1 = g_1 f_{i_1 j_1}  + g_2 f_{i_2 j_2} + \dots + g_n f_{1_n j_n}
$$

Thus we have that $1 \in (f_{i_1 j_1}, f_{i_2 j_2}, \dots f_{i_n j_n}$, and hence $\cap_{k=1}^n V(f_{i_k j_k}) = \emptyset$.
Complementing both sides, we get that $\cup_{k=1}^n D(f_{i_k j_k}) = Spec(R)$. We know that $D(f_{i_k j_k}) \subseteq C_{i_k}$, as
the basic open set $D(f_{i_k j_k})$ was used to cover $C_{i_k}$. Hence, we can "expand out" the finite covering by basic opens
to a finite overing by the covering given to us. So we get $Spec(R) = \cup_{k=1}^n C_{i_k}$.

#### for all rings, each $D(f)$ is quasi-compact

This is a generalization of the fact that $Spec(R)$ is quasi-compact, as $Spec(R) = D(1)$. Localize at $f$, so
build the ring $R_{(f)}$. Intuitively, $Spec(R_f) = D(f)$, as $Spec(R_f)$ only has ideals where $f$ does not vanish.
If $f$ vanishes at a prime $p$, then $f \in p$. But we localize at $f$, hence $f$ becomes a unit, so we get $1 \in p_{(f)}$,
and thus the ideal is no longer an ideal.

#### Topology: Closed subset $S$ of a quasi-compact space $T$ is quasi-compact

Let $S \subseteq T$ be closed. We wish to show that $S$ is quasi-compact; that is,
any cover of $S$ has a finite subcover. Let $C_i$ be an arbtirary cover of $S$.
Create a new cover $C'_i$ which is $C_i$ with $S^c$ added. We add $S^c$ so that
we can cover $T$ with $C'_i$, and from this extract a cover for $S$. This works
since $S^c$ covers no element of $S$; The subcover we get of $C'_i$ will have
to create a covering for $S$ using the sets of $C_i$. Ask for a finite subcover
$F_i$ of $C'_i$. The finite covering of $S$ is $F_i - S^c$.

#### In $Spec(B)$, a boolean ring, the sets $D(f)$ are closed under finite union

We want to show that for each family $D(f_i)$, we have a $g$ such that $D(g) = \cup_i D(f_i)$.
We will show it for two functions; recurse in general. The idea is that if we have $f, g$,
we want to build a function that does not vanish when either $f$ or $g$ vanish. Let's
pretend they are boolean functions. Then we are looking for $f \lor g$. We can realise
or in terms of and (multiplication) and xor(addition) as $h \equiv f \lor g \equiv f + g + fg$.
To re-ring-theory this, write $h = f + g + fg = f + g(1 - f)$. See that (1) if $f$ vanishes ($f = 0$)
then $h = g$, (2) if $g$ vanishes ($g = 0$) then $h = f$ which is as expected. If neither
$f$ nor $g$ vanish at $p$, then in this case, we must have $(1 - f)$ vanishes at $p$, since $f(1 - f) = f - f^2 = 0 \in p$.
Hence $f$ or $f^2$ belong to the prime ideal, and hence one of them must vanish. If $f$ 
does not vanish, then $(1 - f)$ vanishes, and hence $h = f$ does not vanish. So,
$h$ does not vanish when either $f$ or $g$ do not vanish, which means that $D(f) \cup D(g) = D(h) = D(f + g + fg)$.
Iterate for $n$.

#### In $Spec(B)$, for a boolean ring, the sets $D(f)$ are the **only** subsets that are clopen.

We know that all the $D(f)$ are clopen. We need to show that these are the only ones.
So pick some clopen set $A$ (for "ajar", a pun on clopen). Since $A$ is open, we must that $A$
is a (possibly infinite) union of basic opens $D(f_i)$.
Since $A$ is closed and $Spec(B)$ is quasi-compact, $A$ is also quasi-compact.
Thus, we can extract a finite subcover of $A$ to write $A = \cup_{k=1}^n D(f_{i_k})$.
The sets $D(f)$ are closed under finite union. So there exists some $g$ such that $A = D(g)$.
Thus, any clopen set $A$ can be written as $D(g)$ for some $g$.


#### $Spec(B)$, for a boolean ring, is Haussdorf

Intuitively, since every prime ideal is maximal, given two distint prime ideals $p, q$, we can find
functions $f, g$ such that $f$ vanishes only on $p$ and $g$ vanishes only on $q$. Since the
basic opens are clopen, we can then build opens that separate $p$ from $q$ by complementing
the vanishing sets of $f, g$.

Pick two points $p, q \in Spec(B)$, $p \neq q$.  These are maximal ideals (all prime ideals in $B$ are maximal).
Thus, neither contain the other; So we must have elements $f \in p - q$, and $g \in q - p$. So
we have that $V(f) = \{ p \}$ and $V(g) = \{ q \}$. Since $Spec(B)$ is clopen, we know that
$V(f)^c$ and $V(g)^c$ are also open. So we get neighbourhoods $N_p \equiv V(f) \cap V(g)^c$
and $N_q \equiv V(g) \cap V(f)^c$ such that $N_p \cap N_q = \emptyset$ and $p \in N_p$, and $q \in N_q$.
Thus we are able to separate the space.

#### $Spec(B)$, for a boolean ring, is compact

Compact is just a definition that asks for (1) Haussdorf, and (2) quasi-compact,
both of which we have shown above. Thus, $Spec(B)$ for a boolean ring is compact.

#### A boolean lattice $L$ can be converted into a boolean ring.

Take a boolean lattice $L$ define the zero of the ring to be bottom, so $0 \equiv \bot$,
and the one of the ring to be the top, so $1 \equiv \top$. The addition operation
is XOR, and the multiplication is intersection; So we define $a + b \equiv (a \land \lnot b) \lor (\lnot a \land b)$,
and multiplication as $a \cdot b \equiv a \land b$. It's easy to check that this does obey the
axioms of a commutative ring, and is boolean because $a^2 = a \land a = a$.

#### Boolean rings $B$ are boolean lattices of the clopen sets of the spectra $BRing(Clopen(Spec(B)))$

Take a boolean ring $B$, build its spectra $Spec(B)$. Take the set of all clopens. We have
seen that this is exactly the sets $D(f)$. Let us show that $D(fg) = D(f) \cap D(g)$ and 
$D(f + g) = D(f) \oplus D(g)$ where $\oplus$ is the exclusive or of the sets. This induces
a map from the ring operations to the lattice operations.


### Boolean lattices $L$ are the clopen sets of spectra of boolean rings $Clopen(Spec(R(L)))$.

Take a lattice $L$, treat it as a ring, and consider the clopens generated from the ring.
We know that for two elements $l, m$ we have that $lm = l \land m$. From the previous
argument, we know that $D(lm) = D(l) \cap D(m)$. This gies $D(l \land m) =  D(lm) = D(l) \cap D(m)$,
a lattie homomorphism. we get $D(l \lor m) = D(l) \cup D(m)$ by complementing; Since
every set is clopen, we can complement a clopen set $D(l)$ to get some clopen set $D(l)^c$.
But every clopen set can be written as $D(l')$ for some $l'$. 




#### Bonus: quotient ring $R/p$ for prime ideal $p$ is $F_2$


# Covariant Hom is left exact

Let's say we have the exact sequence:

$$
0 \rightarrow A \xrightarrow{i} B \xrightarrow{\pi} C \rightarrow 0
$$

Where the first arrow is $i$ for inclusion and the third is $\pi$ for projection.
We now want to consider what happens when we have $Hom(X, -)$ for some target space $X$.

The induced arrows are induced from composition; I will write $(f; g)(x) \equiv g(f(x))$
to mean "first do $f$, then do $g$". Hence, my arrows linking $Hom(X, A)$ to $Hom(X, B)$ will be
$-;i$: To first go from $X$ to $A$, and then apply $i$ to go from $A$ to $B$.

This gives us the sequence (which we are to check if it is exact, and which of the left
and right arrow exist):


$$
0 \xrightarrow{?} Hom(X, A) \xrightarrow{-;i} Hom(X, B) \xrightarrow{;-\pi} Hom(X, C) \xrightarrow{?} 0
$$


#### A particular example


As usual, we go to the classic exact sequence:


$$
0 \xrightarrow 2Z \rightarrow{\pi} Z \rightarrow{\pi} Z/2Z \rightarrow 0
$$

We now have three interesting choices for our $X$ in relation to the above sequence:
(a) $Z$, (b) $2Z$, (c) $Z/2Z$. Since $Z$ and $2Z$ are isomorphic as modules, let's study
the case with $Z$ and $Z/2Z$


#### $Hom(-; Z)$
#### $Hom(-; Z/2Z)$

# Internal versus External semidirect products

Say we have an inner semidirect product. This means we have subgroups $N, K$ such that $NK = G$,
$N$ normal in $G$ and $N \cap K = \{ e \}$. Given such conditions, we can realize $N$ and $K$
as a semidirect product, where the action of $K$ on $N$ is given by conjugation in $G$.
So, concretely, let's think of $N$ (as an abstract group) and $K$ (as an abstract group)
with $K$ acting on $N$ (by conjugation inside $G$). We write the action of $k$ on $n$
as $n^k \equiv knk^{-1}$.  We then have a homomorphism $\phi: N \ltimes K \rightarrow G$
given by $\phi((n, k)) = nk$. To check this is well-defined, let's take $s, s' \in N \ltimes K$, with
$s \equiv (n, k)$ and $s' \equiv (n', k')$. Then we get:

$$
\begin{aligned}
&\phi(ss') = \\
&=\phi((n, k) \cdot (n', k')) \\
&\text{definition of semidirect product via conjugation:} \\
&= \phi((n {n'}^k, kk')) \\
&\text{definition of $\phi$:} \\
&= n n'^{k} kk' \\
&\text{definition of $n'^k = k n' k^{-1}$:} \\
&= n k n'k^{-1} k k'  \\
&= n k n' k'  \\
&= \phi(s) \phi(s')
\end{aligned}
$$

So, $\phi$ really is a homomorphism from the external description (given in terms of the conjugation)
and the internal description (given in terms of the multiplication). 

We can also go the other direction, to start from the internal definition and get to the conjugation.
Let $g \equiv nk$ and $g' \equiv n'k'$. We want to multiply them, and show that the multiplication
gives us some other term of the form $NK$:

$$
\begin{aligned}
gg' \\
&= (n k) (n' k')  \\
&= n k n' k'  \\
&= \text{insert $k^{-1}k$: } \\
&= n k n' k^{-1} k k' \\
&= n (k n' k^{-1}) k k' \\
&= \text{$N$ is normal, so $k n' k^{-1}$ is some other element $n'' \in N$:} \\
&= n n'' k k' \\
&= N K
\end{aligned}
$$

So, the collection of elements of the form $NK$ in $G$ is closed. We can check that the other properties
hold as well.


# Splitting of semidirect products in terms of projections

Say we have an exact sequence that splits:

$$
0 \rightarrow N \xrightarrow{i} G \xrightarrow{\pi} K \rightarrow 0
$$

with the section given by $s: K \rightarrow G$ such that $\forall k \in K, \pi(s(k)) = k$.
Then we can consider the map $\pi_k \equiv s \circ pi: G \rightarrow G$. See that this firsts
projects down to $K$, and then re-embeds the value in $G$. The cool thing is that
this is in fact *idempotent* (so it's a projection!) Compute:

$$
\begin{aligned}
&\pi_k \circ \pi_k \\
&= (s \circ \pi) \circ (s \circ \pi ) \\
&= s \circ (\pi \circ s) \circ \pi ) \\
&= s \circ id \circ \pi \\
&= s \circ \pi = \pi_k \\
\end{aligned}
$$

So this "projects onto the $k$ value". We can then extract out the $N$ component as
$\pi_n: G \rightarrow G; \pi_n(g) \equiv g \cdot \pi(k)^{-1}$.



# Tensor is right exact

Consider an exact sequence

$$
0 \rightarrow A \xrightarrow{f} B \xrightarrow{g} C \rightarrow 0
$$

We wish to consider the operation of tensoring with some ring $R$.
For a given ring morphism $h: P \rightarrow Q$ this induces a new
morphism $R \otimes h: R \otimes A \rightarrow R \otimes B$ defined
by $h(r \otimes a) \equiv r \otimes h(a)$.

So we wish to contemplate the sequence:


$$
R \otimes A \xrightarrow{R \otimes f} R \otimes B \xrightarrow{R \otimes g} R \otimes C
$$


To see if it is left exact, right exact, or both. Consider the classic sequence of
modules over $\mathbb Z$:

#### A detailed example


$$
0 \rightarrow 2\mathbb Z \xrightarrow{i} \mathbb Z \xrightarrow{\pi} \mathbb Z / \mathbb 2Z \rightarrow 0
$$

Where $i$ is for inclusion, $\pi$ is for projection. This is an exact sequence, since it's of the form
kernel-ring-quotient. We have three natural choices to tensor with: $\mathbb Z, \mathbb 2Z, \mathbb Z/\mathbb 2Z$.
By analogy with fields, tensoring with the base ring $\mathbb Z$ is unlikely to produce anything of interest.
$\mathbb 2Z$ maybe more interesting, but see that the map $1 \in \mathbb Z \mapsto 2 \in 2 \mathbb Z$ gives us an 
isomorphism between the two rings. That leaves us with the final and most interesting element (the one with torsion),
$\mathbb Z / \mathbb 2Z$. So let's tensor by this element:

$$
\mathbb Z/2\mathbb Z \otimes  2\mathbb Z \xrightarrow{i'}
\mathbb Z/2\mathbb Z \otimes  \mathbb Z \xrightarrow{\pi'} 
\mathbb Z/2\mathbb Z \otimes  \mathbb Z / \mathbb 2Z
$$

- See that $\mathbb Z/2\mathbb Z \otimes 2 \mathbb Z$ has elements of the form $(0, *) = 0$,
  We might imagine that the full ring collapses since 
  $1 \otimes 2k) = 2(1 \otimes k) = 2 \otimes k = 0$ (since $2 = 0$ in $\mathbb Z/2\mathbb Z$). But this in fact
  incorrect! Think of the element $1 \otimes 2$. We *cannot* factorize this as $2(1 \otimes 1)$ since $1 \not \in 2 \mathbb Z$.
  So we have the element $1 \otimes 2 \in \mathbb Z/2\mathbb Z / \times 2 \mathbb Z$. 
- See that $\mathbb Z/2\mathbb Z \otimes \mathbb Z \simeq \mathbb Z/2\mathbb Z$: 
  Factorize $(k, l) = l(k, 1) = (kl, 1) \simeq \mathbb Z/2 \mathbb Z$.
- Similarly, see that $\mathbb Z/2\mathbb Z \otimes \mathbb Z/2\mathbb Z  \simeq \mathbb Z/2\mathbb Z$.
  Elements $0 \otimes 0, 0 \otimes 1, 1 \otimes 0 \simeq 0$ and $1 \otimes 1 \simeq 1$.
- In general, Let's investigate elements $a \otimes b \in \mathbb Z/n\mathbb Z \otimes \mathbb Z/m\mathbb mZ$ .
  We can write this as $ab 1 \otimes 1$. The $1 \otimes 1$ gives us a "machine" to reduce the number by $n$ and by $m$.
  So if we first reduce by $n$, we are left with $r$ (for remained) for some $ab = \alpha n + r$. We can then reduce
  $r$ by $m$ to get $ab = \alpha n + \beta m + r'$. So if $r' = 0$, then we get $ab = \alpha n + \beta m$. But see that
  all elements of the form $\alpha n + \beta m$ is divisible by $gcd(n, m)$. Hence, all multiples of $gcd(n, m)$ are sent
  to zero, and the rest of the action follows from this. So we effectively map into $\mathbb Z/ gcd(m, n) \mathbb Z$
- In fact, we can use the above along with (1) write finitely generated abelian groups as direct sum of cyclic groups,
  (2) tensor distributes over direct sum. This lets us decompose tensor products of all finitely generated 
  abelian groups into cyclics.
- This gives us another heuristic argument for why $\mathbb Z \times \mathbb Z/2\mathbb Z \simeq \mathbb Z/2 \mathbb Z$.
  We should think of $\mathbb Z$ as $\mathbb Z/\mathbb \infty Z$, since we have "no torsion" or "torsion at infinity".
  So we get the tensor product should have $gcd(2, \infty) = 2$.
- Now see that the first two components of the tensor give us a map from
  $\mathbb Z/2\mathbb Z \otimes \mathbb 2Z \xrightarrow{i} \mathbb Z/2\mathbb Z \otimes \mathbb Z$ which sends:

$$
\begin{aligned}
&x \otimes 2k \mapsto x \otimes 2k \in \mathbb Z/2\mathbb Z \otimes \mathbb Z \\
&= 2 (x \otimes k) \\
&= (2x \otimes k) \\
&=0 \otimes k = 0
\end{aligned}
$$

- This map is not injective, since this map kills everything! Intuitively, the "doubling" that is latent
  in $2\mathbb Z$ is "freed" when injecting into $\mathbb Z$. This latent energy explodes on contant
  with $\mathbb Z/2 \mathbb Z$ giving zero. So, the sequence is no longer left-exact, since the map is
  not injective!



- So the induced map is identically zero! Great, let's continue, and inspect the tail end
  $ \mathbb Z/2\mathbb Z \otimes  \mathbb Z \xrightarrow{\pi} \mathbb Z/2\mathbb Z \otimes  \mathbb Z / \mathbb 2Z$.
  Here, we sent the element $(x, y) \mapsto (x, y \mod 2)$. This clearly gives us all the elements: For example,
  we get $0 \otimes 0$ as the preimage of $0 \times 2k$ and we get $1 \otimes 1$ as the preimage of (predictably)
  $1 \otimes (2k+1)$. Hence, the map is surjective.

So finally, we have the exact sequence:

$$
\mathbb Z/2\mathbb Z \otimes  2\mathbb Z \xrightarrow{i'}
\mathbb Z/2\mathbb Z \otimes  \mathbb Z \xrightarrow{\pi'} 
\mathbb Z/2\mathbb Z \otimes  \mathbb Z / \mathbb 2Z \rightarrow 0
$$

We do NOT have the initial $(0 \rightarrow \dots)$ since $i'$ is no longer injective.
It fails injectivity as badly as possible, since $i'(x) = 0$. Thus, tensoring is
RIGHT EXACT. It takes right exact sequences to right exact sequences!


#### The general proof

Given the sequence:

$$
A \xrightarrow{i} B \xrightarrow{\pi} C \rightarrow 0
$$

We need to show that the following sequence is exact:

$$
R \otimes A \xrightarrow{i'} R \otimes B \xrightarrow{\pi'} R \otimes C \rightarrow 0
$$

- First, to see that $\pi'$ is surjective, consider the basis element $r \otimes c \in R \otimes C$.
  Since $\pi$ is surjective, there is some element $b \in B$ such that $\pi(b) = c$. So the element
  $r \otimes b \in B$ maps to $r \otimes c$ by $\pi'$; $\pi'(r \otimes b) = r \otimes \pi(b) = r \otimes c$ 
  (by definition of $\pi$, and choice of $b$). This proves that $B \xrightarrow{\pi'} R \otimes C \rightarrow 0$
  is exact.

- Next, we need to show that $im(i') = ker(\pi')$.
- To show that $im(i') \subseteq ker(\pi')$, consider an arbitrary $r \otimes a$. Now compute:

$$
\begin{aligned}
&\pi'(i'(r \otimes a))  \\
&= \pi'(r \otimes i(a)) \\
&= r \otimes \pi(i(a))
& \text{By exactness of $A \xrightarrow{i} B \xrightarrow{\pi} C$, $\pi(i(a)) = 0$:} \\
&= r \otimes 0  \\
&= 0
\end{aligned}
$$
So we have that any element in $i'(r \otimes a) \in im(i')$ is in the kernel of $\pi'$.

Next, let's show $ker(\pi') \subseteq im(i')$. This is the "hard part" of the proof. So let's 
try a different route. I claim that if $im(i') = ker(\pi')$ iff $coker(i') = R \otimes C$. This
follows because:

$$
\begin{aligned}
&coker(i) = (R \otimes B)/ im(i') \\
& \text{Since } im(i') = ker(\pi')
&= (R \otimes B)/ker(\pi') \\
& \text{Isomorphism theorem: } \\
&= im(\pi') \\
& \text{$\pi'$ is surjective: } \\
&= R \otimes C
\end{aligned}
$$

Since each line was an equality, if I show that $coker(i) = R \otimes C$, then I have that $im(i') = ker(\pi')$.
So let's prove this:


$$
\begin{aligned}
&coker(i) = (R \otimes B)/ im(i') \\
&= (R \otimes B)/i'(R \otimes A) \\
& \text{Definition of $i'$: } \\
&= (R \otimes B)/(R \otimes i(A)) \\
\end{aligned}
$$

I claim that the $(R \otimes B)/( R \otimes i(A)) \simeq R \otimes (B/i(A))$ (informally, "take $R$ common").
Define the quotient map $q: B \rightarrow B/i(A)$. This is a legal quotient map because $i(A) = im(i) \simeq ker(\pi)$
is a submodule of $B$.

$$
\begin{aligned}
q : B \rightarrow B/i(A) \\
f: R \otimes B \rightarrow  \rightarrow R \otimes (B / i(A)) \\
f(r \otimes b) = r \otimes  q(b) \\
r \otimes b  \in R \otimes B \xrightarrow{f = R \otimes q } r \otimes q(b) \in R \otimes B/i(A)
\end{aligned}
$$

Let's now study $ker(f)$. It contains all those elements such that $r \otimes q(b) = 0$.
But this is only possible if $q(b) = 0$. This means that $b \in i(A) = im(i) = ker(\pi)$.
Also see that for every element $r \otimes (b + i(A)) \in R \otimes (B/i(A))$, there is an inverse
element $r \otimes b \in R \otimes B$. So, the map $f$ is *surjective*. Hence, $im(f) \simeq R \otimes (B/i(A))$.
Combining the two facts, we get:

$$
\begin{aligned}
&domain(f)/ker(f) \simeq im(f) \\
&(R \otimes B)/(R \otimes (B/i(A))) \simeq R \otimes (B/i(A))
&coker(i) = (R \otimes B)/(R \otimes (B/i(A))) \simeq R \otimes (B/i(A)) = R \otimes C
\end{aligned}
$$

Hence, $coker(i) \simeq R \otimes C$.


- [Reference: Kyle Miller's notes on the exactness of the tensor product](https://math.berkeley.edu/~kmill/notes/tensor.pdf)



# Semidirect product as commuting conditions

Recall that in $N \ltimes K = G$, $N$ is normal. This is from the mnemonic
that it looks like $N \triangleleft G$, or from the fact that the acting/twisting subgroup
$K$ is a fish that wants to "eat"/act on the normal subgroup $N$.


So, we have $knk^{-1} \in N$ as $N$ is normal, thus $knk^{-1} = n'$. This can be
written as $kn = n'k$. So:

- When commuting, the element that *gets changed/twisted* in the normal subgroup.
  This is because the normal subgroup has the requisite constraint on it to be
  twistable.
- The element that remains invariant is the actor. 

In the case of translations and rotations, it's the translations that are normal.
This can be seen either by noticing that they are abelian, and are thus normal, while
rotations don't "look normal". Alternatively, one can try to consider translate-rotate
versus rotate-translate.


<img src="./static/semidirect-product/rotate-translate.png"/>
- First rotating by $r$ and then translating by $t$ along the x-axis
  has the same effect as first translating by $t'$ at 45 degrees to the x-axis,
  and then rotating by the **same** r. 

- This begs the question, is there some other
  translation `t''` and some other rotation `r''` such that `t''; r''` (`t''` first, `r''` next)
  has the same effect as `r;t` (`r` first, `t` next)?

<img src="./static/semidirect-product/translate-rotate.png"/>

- First let's translate by $t$ along the x-axis and then rotating by $r$.
  Now let's think, if we wanted to rotate and then translate, what rotation would
  we start with? it would HAVE TO BE $r$, since there's no other way to get the axis
  in such an angle in the final state. But if we rotate by $r$, then NO translation
  can get us to the final state we want. So, it's impossible to find a `rotation;translation`
  pair that mimics our starting `translation;rotation`.


# Exact sequences for semidirect products; fiber bundles

#### Fiber bundles

In the case of a bundle, we have a sequence of maps $F \rightarrow E \rightarrow B$ where 
$F$ is the fiber space (like the tangent space at the identity $T_eM$). $E$ is the total space (the bundle $TM$),
and $B$ is the base space (the manifold $M$). We require that the inverse of the projection
$\pi^{-1}: B \rightarrow E$ locally splits as product $\pi^{-1}(U) \simeq U \times F$.

#### Semidirect products

In a semidirect product $N \ltimes K$, we have that $N$ is normal (because the fish wants to eat
the normal subgroup $N$ / the symbol looks like $N \triangleleft G$ which is how we denote normality).
Thus, we can only quotient by $N$, leaving us with $K$. This is captured by the SES:

$$
0 \rightarrow N \rightarrow  N \ltimes K \xrightarrow{\pi} K \rightarrow 0
$$

- We imagine this as a bundle, with base space $M=K$, bundle $TM=N \ltimes K$,
  and fiber space (like, tangent space at the identity, say) $T_e M =  N$. 

- Furthermore, this exact sequence splits; So there is a map $s: K \rightarrow N \ltimes K$
  ($s$ for "section/split") such that $\forall k, \pi(s(k)) = k$. To see that this is true,
  define $s(k) \equiv (e, k)$. Since all actions of $K$  fix the identity $e \in N$, we have
  $s(k)s(k') = (e, k) (e, k') = (e, kk') = s(kk')$ so this is a valid map. To see that $\pi$
  is its inverse, just act $\pi$; $\pi(s(k)) = \pi(e, k) = k$. 


#### Viewing the semidirect product space as a G-bundle

Consider the space $E \equiv N \ltimes K$ as a bundle over $K$
given by the projection $E \equiv N \ltimes K \xrightarrow{\pi} K$. We can have $N$ act on the fibers
by a left and a right action. Let's consider both:

- $N$ acting on right: $(n, k) \triangleleft (n', e) \equiv (n n'^k, ke) \equiv (n n'^k, k)$
- $N$ acting on left: $(n', e) \triangleright (n, k) \equiv (n' n^e, k) = (n' n, k)$
   This is the "easier action" to interpret;
  it permutes fibers, keeping the base space the same. So this gives a principal bundle action.
- $K$ acting on right: $(n, k) \triangleleft (e, 'k) \equiv (n e^k, kk') = (ne, kk') = (n, kk')$.
  This action is easy, it permutes fibers.
- $K$ acting on left: $(e, k') \triangleright (n, k) \equiv (e n^{k'}, k'k) \equiv (n^{k'}, kk')$.


So we see that $N$ acting on the left gives us an action that permutes inside fibers,
and $K$ acting on the right gives us an action that permutes the fibers themselves.
So we can write this as $N \triangleright N \ltimes K \triangleleft K$ to capture
the base-space bundle-space relationship, perhaps.

Also, see that if we quotient $N \ltimes K$ by the action of $G\equiv N$ acting on
the left, with the quotient map called $[\cdot]$ for orbit equivalence classes,
we get $N\ltimes K \xrightarrow{[\cdot]} (N \ltimes K)/N = K$, which is isomorphic
to our starting picture $N \ltimes K \xrightarrow{\pi} K$. Hence, it is indeed true
that this bundle is a principal $G$-bundle.

- [Ref: Geometrical anatomy of theoretical physics, lecture 19, principal bundles](https://www.youtube.com/watch?v=vYAXjTGr_eM&list=PLPH7f_7ZlzxTi6kS4vCmv4ZKm9u8g5yic&index=19)


#### Relationship to gauges 

**NOTE**: this was written before I knew what a G-bundle is. This is perhaps
easier to read, but less useful in hindsight.

Let $X$ be the space of *all* states. Let $O$ be a group action whose orbits identify
equivalent states. So the space of "physical states" or "states that describe the same 
physical scenario" is the orbit of $X$ under $O$, or $X/O$.
Now, the physical space $X/O$ is acted upon by some
group $G$.  If we want to "undo the quotienting" to have $G$ act on all of $X$, then we need to construct $G \ltimes O$.
$G$ is normal here because $O$ already knows how to act on the whole space; $G$ does not, so $O$ needs to "guide" the action of
$G$ by acting on it.  The data needed to construct $G \ltimes O$ is a *connection*.
Topologically, we have $X \rightarrow X/O$ and $G \curvearrowright X/O$. We want to extend
this to $(G \ltimes O) \curvearrowright X$. We imagine this as:

```
*1| #1 | @1  X
*2| #2 | @2
*3| #3 | @3
  | |  |
  | v  |
* | #  | @ X/H
```

where the action of $H$ permutes amongst the fibers of `*, #, @`. Next, we have an action of $G$ on $X/H$:


```
*1| #1 | @1  X
*2| #2 | @2
*3| #3 | @3
  | |  |
  | v  |
* | #  | @ [X/H] --G--> # | @ | *
```

We need to lift this action of `H` the `H`-orbits. This is precisely the data a
connection gives us (why?) I guess the intuition is that the orbits of $X$ are like
the tangent spaces where $X \rightarrow X/O$ is the projection from the bundle
into the base space, and the $G$ is a curve that tells us what the "next point" we want to
travel to from the current point. The connection allows us to "lift" this to 
"next tangent vector". That's quite beautiful.

We want the final picture to be:

```
*1| #1 | @1  X          #2| @2|                    
*2| #2 | @2    --G-->   #1|   |   
*3| #3 | @3             #3|   | 
  | |  |                  |   | 
  | v  |                  |   |  
* | #  | @ [X/H] --G--> # | @ | *
```


#  Semidirect product is equivalent to splitting of exact sequence

Consider the exact sequence

$$
0 \rightarrow N \xrightarrow{\alpha} G \xrightarrow{\pi} H \rightarrow 0
$$

- We want to show that if there exists a map $s: H \rightarrow G$ such that
  $\forall h, \pi(s(h)) = h$ (ie, $\pi \circ s = id$), then G$ \simeq N \ltimes H$.
  So the splitting of the exact sequence decomposes $G$ into a semidirect product.
- The idea is that elements of $G$ have an $N$ part and a $K$ part. We can get the $K$
  part by first pushing into $K$ using $\pi$ and then pulling back using $s$. So define
  $k: G \rightarrow G; k(g) \equiv s(\pi(g))$. This gives us the "K" part. To get the $N$
  part, invert the "k part" to annihiliate it from $G$. So define a map
  $n: G \rightarrow G; n(g) \equiv g k(g)^{-1} = g k(g^{-1})$.
- See that the image of $n$ lies entirely in the kernel of $\pi$, or the image of $n$
  indeed lies in $N$. This is a check:

$$
\begin{aligned}
&\pi(n(g)) \\
= \pi(g k(g^{-1})) \\
= \pi(g) \pi(k(g^{-1})) \\
= \pi(g) \pi(s(\pi(g^{-1}))) \\
= \text{$\pi(s(x)) = x$:}\\
= \pi(g) \pi(g^{-1}) = e
\end{aligned}
$$

- Hence, the image of $n$ is entirely in the kernel of $\pi$. But the kernel of $\pi$ is isomorphic to $N$,
  and hence the image of $n$ is isomorphic to $N$. So we've managed to decompose an element of $G$ into a $K$
  part and an $N$ part. 
- Write $G$ as $N \ltimes K$, by the map $\phi: G \rightarrow N \ltimes K; \phi(g) = (n(g), k(g))$.
  Let's discover the composition law.

$$
\begin{aligned}
&\phi(gh) =^? \phi(g) \phi(h) \\
&(n(gh), k(gh)) =^? (n(g), k(g)) (n(h), k(h)) \\
&(ghk((gh)^{-1}), k(gh)) =^? (gk(g^{-1}), k(g)) (hk(h^{-1}), k(h)) \\
\end{aligned}
$$

We need the second to be $k(gh) = k(g) k(h)$, so that composes in an
entirely straightforward fashion. For the other component, we need:


$$
\begin{aligned}
&ghk((gh)^{-1})  =^? gk(g^{-1}) \cdot hk(h^{-1}) \\
&ghk((gh)^{-1})  =^? gk(g^{-1}) k(g) \cdot hk(h^{-1}) k(g^{-1}) \\
&ghk((gh)^{-1})  =^? g [k(g^{-1}) k(g)] \cdot h [k(h^{-1}) k(g^{-1})] \\
&ghk((gh)^{-1})  =^? g \cdot h k((gh)^{-1}) \\
&ghk((gh)^{-1})  = gh k((gh)^{-1}) \\
\end{aligned}
$$

So we need the $n$ of $h$ to be twisted by the $k$ component of $g$ by a conjugation. So we define the semidirect
structure as:

$$
\begin{aligned}
(n(g), k(g)) \cdot (n(h), k(h)) \equiv (n(g) k(g) n(h) k(g)^{-1}, k(g) k(h)) \\
&= (n(g) n(h)^{k(g)}, k(g) k(h))
\end{aligned}
$$

We've checked that this works with the group structure. So we now have a morphism $\phi: G \rightarrow N \ltimes K$.
we need to check that it's an isomorphism, so we need to make sure that this has full image and trivial kernel.

- Full image: Let $(n, k) \in N \ltimes K$. Create the element $g = \alpha(n) s(k) \in G$.
  We get $\pi(g) = \pi(\alpha(n)s(k)) = \pi(\alpha(n)) \pi(s(k)) = e k = k$.
  We get $n(g) = g k$

- [physics.se](https://physics.stackexchange.com/questions/13153/discrete-gauge-theories/13171#13171)





# Intro to topological quantum field theory

- Once again, watching a videos for shits and giggles.
- Geometrically, we cut and paste topological indices / defects.
- QFT in dimensions n+1 (n space, 1 time)
- Manifold: $X^n$. Can associate a hilbert space of states $H_x$.
- Space of wave functions on field space.
- Axioms of hilbert space: (1) if there is no space, the hilbert space $H_\emptyset$ for it is the complex numbers.
  (2) If we re-orient the space, the hilbert space becomes the dual $H_{-X} = H_X^\star$.
  (3) Hilbert space over different parts  is the tensor product: $H_{X \cup Y} = H_X \otimes H_Y$.
- We want arbitrary spacetime topology. We start at space $X$, and we end at a space $Y$.
  The space $X$ is given positive orientation to mark "beginning" and $Y$ is given negative orientation
  to mark "end". We will have a time-evolution operator $\Phi: H_X \rightarrow H_Y$.
- We have a composition law of gluing: Going from $X$ to $Y$ and then from $Y$ to $Z$ is the same as going from
  $X$ to $Z$. $\phi_{N \circ M} = \phi_N \circ \phi_M$.
- If we start and end at empty space, then we get a linear map $\Phi: H_\emptyset \rightarrow H_\emptyset$ which is a linear map
  $\Phi: \mathbb C \rightarrow \mathbb C$, which is a fancy way to talk about a complex number (scaling)
- If we start with an empty set and end at $Y$, then we get a function $\Phi: H_\emptyset \rightarrow H_Y \simeq \mathbb C \rightarrow \mathbb Y$. But this is the same as picking a state, for example, $\Phi(1) \in H_Y$ [everything else is determined by this choice].
- If a manifold has two sections $X$ and $-X$, we can glue $X$ to $-X$ to get the trace.
- Quantum mechanics is `0 + 1` TQFT (!)
- TQFT of 1+1 dimensions.
- Take a circle: $S^1 \rightarrow H$.  Let $H$ be finite dimensional.
- A half-sphere has a circle as boundary. So it's like $H_\emptyset \rightarrow H_{S^1}$. This is the ket $|0\rangle$.
- This is quite a lot like a string diagram...
- [Frobenius algebra](https://en.wikipedia.org/wiki/Frobenius_algebra)
- [Video: IAS PiTP 2015](https://www.youtube.com/watch?v=jEEQO-tcyHc)



# Non examples of algebraic varieties

It's always good to have a stock of non-examples.

#### Line with hole: Algebraic proof

The set of points $V \equiv \{ (t, t) : t \neq 42, t \in \mathbb R \} \subseteq mathbb R^2$ is not
a variety. To prove this, assume it is a variety defined by equations $I(V)$.
Let $f(x, y) \in I(V) \subseteq \mathbb R[x, y]$. Since $f$ vanishes on $V$, we must
have $f(a, a) = 0$ for all $a \neq 42$ (since $(a, a) \in V$ for all $a \neq 42$).
So create a new function $g(a) \equiv (a, a)$. Now $f \circ g: \mathbb R \rightarrow \mathbb R = f(g(a)) = f(a, a) = 0$.
This polynomial (it is a composition of polynomial, and is thus a polynomial)
has infinitely many zeroes, and is thus identically zero. So, $f(g(a)) = 0$, So $f(a, a) = 0$ for all
$a$. In particular, $f(42, 42) = 0$ for all equations that define $V$, hence $(42, 42) \in I(V)$. But this
does not give us the variety $V$. Hence $V$ is not a variety.

#### Line with hole: Analytic proof

The set of points $V \equiv \{ (t, t) : t \neq 42, t \in \mathbb R \} \subseteq mathbb R^2$ is not
a variety. To prove this, assume it is a variety defined by equations $I(V)$.
Let $f(x, y) \in I(V) \subseteq \mathbb R[x, y]$. Since $f$ vanishes on $V$, we must
have $f(a, a) = 0$ for all $a \neq 42$ (since $(a, a) \in V$ for all $a \neq 42$).
Since $f$ is continuous, $f$ preserves limits. Thus, $\lim_{x \to 42} f(x, x) = f(\lim_{x \to 42} (x, x))$.
The left hand side is zero, hence the right hand size must be zero. Thus, $f(42, 42) = 0$.
But this can't be, because $(42, 42) \not \in V$.

#### $\mathbb Z$

The set $\mathbb Z$ is not an algebraic variety. Suppose it is, and is the zero set 
of a collection of polynomials $\{ f_i \}$. Then for some $f_i$, they must vanish on at least
all of $\mathbb Z$, and maybe more. This means that $f_i(z) = 0$ for all $z \in \mathbb Z$. But a
degree $n$ polynomial can have at most $n$ roots, unless it is the zero polynomial.
Since $f_i$ does not have a finite number of roots, $f_i = 0$. Thus, all the polynomials
are identically zero, and so their zero set is not $\mathbb Z$; it is all of $\mathbb R$.


#### The general story

In general, we are using a *combinatorial* fact that a $n$ degree polynomial has at most $n$ roots.
In some cases, we could have used *analytic* facts about continuity of polynomials, but it suffices
to simply use *combiantorial* data which I find interesting.

# Nilradical is intersection of all prime ideals

#### Nilradical is contained in intersection of all prime ideals

Let $x \in \sqrt 0$. We must show that it is contained in all prime ideals.
Since $x$ is in the nilradical, $x$ is nilpotent, hence $x^n = 0$ for some $n$. Let $p$ be an
arbitrary prime ideal. Since $0 \in p$ for all prime ideals, we have
$x^n = 0 \in p$ for $x$. This means that $x^n = x \cdot x^{n-1} \in p$,
and hence $x \in p \lor x^{n-1} \in p$.  If $x \in p$ we are done.
If $x^{n-1} \in p$, recurse to get $x \in p$ eventually.


#### Proof 1: Intersection of all prime ideals is contained in the Nilradical

Let $f$ be in the intersection of all prime ideals. We wish to show that $f$
is contained in the nilradical (that is, $f$ is nilpotent). We know that $R_f$ ($R$
localized at $f$) collapses to the zero ring iff $f$ is nilpotent. So we wish to
show that the sequence:

$$
\begin{aligned}
0 \rightarrow R_f \rightarrow 0
\end{aligned}
$$

is exact. But exactness is a local property, so it suffices to check against each $(R_f)_m$ for
all maximal ideals $m$. Since $(R_f)_m = (R_m)_f$ (localizations commute), let's reason about $(R_m)_f$. 
We know that $R_m$ is a local ring as $m$ is prime (it is maximal), and thus $R_m$ has only a single
ideal $m$. Since $f \in m$ for all maximal ideal $m$ (since $f$ lives in the intersection of all prime
ideals), localizing at $f$ in $R_m$ blows up the only remaining ideal, collapsing us the ring to give
us the zero ring. Thus, for each maximal ideal $m$, we have that:


$$
\begin{aligned}
0 \rightarrow (R_f)_m \rightarrow 0
\end{aligned}
$$

is exact. Thus, $0 \rightarrow R_f \rightarrow 0$ is exact. Hence, $f$ is nilpotent, or $f$ belongs to the
nilradical.

#### Proof 2: Intersection of all prime ideals is contained in the Nilradical

- Quotient the ring $R$ by the nilradical $N$.
- The statement in $R/N$ becomes
  "in a ring with no ninpotents, intersection of all primes is zero".
- This means that every non-zero element is **not** contained in  **some** prime ideal. Pick
  some arbitrary element $f \neq 0 \in R/N$. We know $f$ is not nilpotent, so we naturally consider
  $S_f \equiv \{ f^i : i \in \mathbb N \}$.
- The only thing one can do with a  multiplicative subset
  like that is to localize. So we localize the ring $R/N$ at $S$.
- If all prime ideals contain the function $f$,
  then localizing at $f$ destroys all prime ideals, thus blows up all maximal ideals,
  thereby collapsing the ring into the zero ring (the ring has no maximal ideals, so the ring is the zero ring).
- Since $S^{-1} R/N = 0$, we have that $0 \in S$. So some $f^i = 0$. This contradicts the assumption that no element of $R/N$
  is nilpotent. Thus we are done.

#### Lemma: $S$ contains zero  iff  $S^{-1} R = 0$

- (Forward): Let $S$ contain zero. Then we must show that $S^{-1} R = 0$. Consider some element $x/s \in S^{-1} R$.
  We claim that $x = 0/1$.  To show this, we need to show that there exists an $s' \in S$ such that $xs'/s = 0s'/1$.
  That is, $s'(x \cdot 1 - 0 \cdot s) = 0$. Choose $s' = 0$ and we are done. Thus every element is $S^{-1}R$ is zero if $S$
  contains zero.

- (Backward): Let $S^{-1} R = 0$. We need to show that $S$ contains zero. Consider $1/1 \in S^{-1} R$. We have that $1/1 = 0/1$.
  This means that there is an $s' \in S$ such that $s'1/1 = s'0/1$. Rearranging, this means that
  $s'(1 \cdot 1 - 1 \cdot 0) = 0$. That is, $s'1 = 0$, or $s' = 0$. Thus, the element $s'$ must be zero for $1$ to be
  equal to zero.  Hence, for the ring to collapse, we must have $0 = s' \in S$. So, if $S^{-1}R = 0$, then $S$ contains zero.


# Exactness of modules is local


We wish to show that for some ring $R$ and modules $K, L, M$
a sequence $K \rightarrow L \rightarrow M$ is exact iff $K_m \rightarrow L_m \rightarrow M_m$
is exact for every maximal ideal $m \subset R$. This tells us that exactness is local.




# Quotient by maximal ideal gives a field

#### Quick proof

Use correspondence theorem. $R/m$ only has the images of $m, R$ as ideals which
is the zero ideal and the full field.

#### Element based proof

Let $x + m \neq 0$ be an element in $R/m$. Since $x + m \neq 0$, we have $x \not in m$.
Consider $(x, m)$. By maximality of $m$, $(x, m) = R$. Hence there exist elements $a, b \in R$
such that $xa + mb = 1$. Modulo $m$, this read $xa \equiv 1 (\text{mod}~$m$)$. Thus $a$
is an inverse to $x$, hence every nonzero element is invertible.


# Ring of power series with infinite positive and negative terms

If we allow a ring with elements $x^i$ for all $-\infty < x < \infty$, for notation's
sake, let's call it $R[[[x]]]$. Unfortunately, this is a badly behaved ring.
Define $S \equiv \sum_{i = -\infty}^\infty x^i$. See that $xS = S$, since
multiplying  by $x$ shifts powers by 1. Since we are summing over all of $\mathbb Z$,
$+1$ is an isomorphism. Rearranging gives $(x - 1)S = 0$. If we want our ring
to be an integral domain, we are forced to accept that $S = 0$. In the Barvinok
theory of polyhedral point counting, we accept that $S = 0$ and exploit this
in our theory.

# Mean value theorem and Taylor's theorem. (TODO)

I realise that there are many theorems that I learnt during my preparation for JEE
that I simply don't know how to prove. This is one of them. Here I exhibit
the proof of Taylor's theorem from Tu's introduction to smooth manifolds.

> Taylor's theorem: Let $f: \mathbb R \rightarrow \mathbb R$ be a smooth function,
> and let $n \in \mathbb N$ be an "approximation cutoff". Then there exists
> for all $x_0 \in \mathbb R$ a smooth function $r \in C^{\infty} \mathbb R$
> such that:
> f(x) = f(x_0) + (x - x_0) f'(x_0)/1! + (x - x_0)^2 f'(x_0)/2! + \dots + (x - x_0)^n f^{(n)'}(x_0)/n! + (x - x_0)^{n+1} r

We prove this by induction on $n$. For $n = 0$, we need to show that there exists an $r$ such that
$f(x) = f(x_0) + r$. We begin by parametrising the path from $x_0$ to $x$ as $p(t) \equiv (1 - t) x_0 + tx$.
Then we consider $(f \circ p)'$:

$$
\begin{aligned}
&\frac{f(p(t))}{dt} = \frac{df((1 - t) x_0) + tx)}{dt} \\
&= (x - x_0) \frac{df((1 - t)x_0) + tx)}{dx}
\end{aligned}
$$

Integrating on both sides with limits $t=0, t=1$ yields:

$$
\begin{aligned}
&\int_0^1 \frac{df(p(t))}{dt} dt = \int_0^1 (x - x_0) \frac{df((1 - t)x_0) + tx)}{dx} dt \\
f(p(1)) - f(p(0)) =  (x - x_0) \int_0^1 \frac{df((1 - t)x_0) + tx)}{dx} dt \\
f(x) - f(x_0) =  (x - x_0) g[1](x) \\
\end{aligned}
$$

where we define $g[1](x) \equiv \int_0^1 \frac{df((1 - t)x_0) + tx)}{dx} dt $ where the $g[1](x)$ witnesses
that we have the first derivative of $f$ in its expression. By rearranging, we get:

$$
\begin{aligned}
f(x) - f(x_0) =  (x - x_0) g[1](x) \\
f(x)  =  f(x_0) + (x - x_0) g[1](x) \\
\end{aligned}
$$

If we want higher derivatives, then we simply notice that $g[1](x)$ is of the form:

$$
\begin{aligned}
g[1](x) \equiv \int_0^1 f'((1 - t)x_0) + tx) dt \\
g[1](x) \equiv \int_0^1 f'((1 - t)x_0) + tx) dt \\
\end{aligned}
$$


# Cayley Hamilton

I find the theorem spectacular, because while naively the vector space $M_n(F)$
has dimension $n^2$, Cayley-Hamilton tells us that there's only $n$ of $M^0, M^1, \dots$
are enough to get linear dependence.  However, I've never known a
proof of Cayley Hamilton that sticks with me; I think I've found one now.

For any matrix $A$, the adjugate has the property:

$$
A adj(A) = det(A) I
$$

Using this, Consider the matrix $P_A \equiv xI - A$ which lives in $End(V)[x]$,
and its corresponding determinant $p_A(x) \equiv det(P_A) = det(xI - A)$.

We have that 

$$
P_A adj(P_A) = det(P_A) I \\
(xI  - A) adj(xI - A) = det(xI - A) I = p_A(x) I \\
$$

If we view this as an equation in $End(V)[x]$, it says that $p_A$ has a factor $xI - A$. This means that
$x = A$ is a zero of $p_A(X)$. Thus, we know that $A$ satisfies $p_A(x)$, hence $A$ satisfies
its own characteristic polynomial!

The key is of course the  adjugate matrix equation that relates the adjugate matrix
to the determinant of $A$.


#### Adjugate matrix equation

- Let $A'(i, j)$ be the matrix $A$ with the $i$ th row and $j$ column removed.
- Let $C[i, j] \equiv (-1)^{i+j} det(A'(i, j))$ be the determinant of the $A'(i, j)$ matrix.
- Let define $adj(A) \equiv C^T$ to be the transpose of the cofactor matrix.
  That is, $adj(A)[i, j] = C[j, i] = det(A'(j, i))$.
- Call $D \equiv A adj(A)$. We will now compute the entries of $Z$ when $i = j$ and when $i \neq j$.
  We call it $D$ for diagonal since we will show that $D$ is a diagonal matrix with entry $det(A)$
  on the diagonal.
- First, compute $D[i, i]$ (I use einstein summation convention where repeated indices are implicitly
  summed over):

$$
\begin{aligned}
= D[i, i] = (A adj(A))[i, i] \\
&= A[i, k] adj(A) [k, i] \\
&= A[i, k] (-1)^{i+k} det(A'[k, i]) \\
&= det(A)
\end{aligned}
$$

The expression $A[i, k] det(A'[k, i])$ is the determinant of $A$ when expanded along the row $i$ using
the [Laplace expansion](https://en.wikipedia.org/wiki/Laplace_expansion). 

Next, let's compute $D[i, j]$ when $i \neq j$:

$$
\begin{aligned}
D[i, j] = (A adj(A))[i, j] \\
&= A[i, k] adj (A)[k, j] \\
& = A[i, k] (-1)^{k+j} det(A'[k, j]) \\
& = A[i, k] (-1)^{j+k} det(A'[k, j]) \\
& = det(Z)
\end{aligned}
$$

This is the determinant of a new matrix $Z$ (for zero), such that the $j$th row of $Z$ is the $i$th
row of $A$. More explicitly:

$$
\begin{aligned}
Z[l, :] \equiv
\begin{cases}
A[l, :] & l \neq j \\
A[i, :] & l = j \\
\end{cases}
\end{aligned}
$$

Since $Z$ differs from $A$ only in the $j$th row, we must have that
$Z'[k, j] = A'[k, j]$, since $Z'[k, j]$ depends on what happens on all
rows and columns **outside** of $j$.

If we compute $det(Z)$ by expanding along the $j$ row, we get:

$$
\begin{aligned}
&det(Z) = (-1)^{j+k} Z[j, k] det(Z'[k, j]) \\
&det(Z) = (-1)^{j+k} A[j, k] det(Z'[k, j]) \\
&det(Z) = (-1)^{j+k} A[j, k] det(A'[k, j]) \\
&= D[i, j]
\end{aligned}
$$

But $Z$ has a repeated row: $A[j, :] = A[i, :]$ and $i \neq j$. Hence, $det(Z) = 0$.
So, $D[i, j] = 0$ when $i \neq j$.

Hence, this means that $A adj(A) = det(A) I$. 

- We can rapidly derive other properties from this reuation. For example, $det(A adj(A)) = det(det(A) I) = det(A)^n$,
  and hence $det(A) det(adj(A)) = det(A)^n$, or $det(adj(A)) = det(A)^{n-1}$.
- Also, by rearranging, if $det(A) \neq 0$, we get $A adj(A) = det(A) I$, hence $A (adj(A)/det(A)) = I$,
  or $adj(A)/det(A) = A^{-1}$.


#### Determinant in terms of exterior algebra

For a vector space $V$ of dimension $n$, Given a linear map $T: V \rightarrow V$, define
a map $\Lambda T: \Lambda^n  V \rightarrow \Lambda^n V$ such that
$\Lambda T(v_1 \wedge v_2 \dots \wedge v_n) \equiv T v_1 \wedge T v_2 \dots \wedge T v_n$.
Since the space $\Lambda^n V$ is one dimension, we will need one scalar $k$ to define
$T$: $T(v_1 \wedge \dots \wedge v_n) = k v_1 \wedge \dots \wedge v_n$. It is either a theorem
or a definition (depending on how one starts this process) that $k = det(T)$.


If we choose this as a definition, then let's try to compute the value. Pick orthonormal
basis $v[i]$. Let $w[i] \equiv T v[i]$ (to write $T$ as a matrix). Define the $T$ matrix to be defined
by the equation $w[i] = T[i][j] v[j]$. If we now evaluate $\Lambda_T$, we get:

$$
\begin{aligned}
\Lambda T(v_1 \wedge \dots v_n) \\
&= T(v_1) \wedge T(v_2) \dots \wedge T(v_n) \\
&= w_1 \wedge w_2 \dots w_n \\
&= (T[1][j_1] v[j_1]) \wedge (T[1][j_2] v[j_2]) \wedge (T[1][j_n] v[j_n]) \\
&=  (\sum_{\sigma \in S_n} (\prod_i T[i][\sigma(i)] sgn(\sigma))  v[1] \wedge v[2] \dots \wedge v_n
\end{aligned}
$$

Where the last equality is because:
- (1) Repeated vectors get cancelled, so we must have unique $v[1], v[2], \dots v[n]$ in the terms we collect.
  So all the $j_k$ must be distinct in a given term.
- A wedge of the form $T[1][j_1] v[j_1] \wedge T[2][j_2] v[j_2] \dots T[n][j_n] v[j_n]$, where all the
  $j_i$ are distinct (see (1)) can be rearranged by a permutation that sends $v_{j_i} \mapsto v_i$.
  Formally, apply the permutation $\tau(j_i) \equiv i$. This will reorganize
  the wedge into $T[1][j_1] T[2][j_2] \dots T[n][j_n] v[1] \wedge v[2] \wedge v[3] \dots v[n] (-1)^{sgn(\tau)}$,
  where the sign term is picked up by the rearrangement.
- Now, write the indexing into $T[i][j_i]$ in terms
  of a permutation $\sigma(i) \equiv j_i$. This becomes $\prod_i T[i][\sigma(i)] (-1)^{sgn(\tau)} v[1] \wedge v[2] \dots \wedge v[n]$.
- We have two permutations $\sigma, \tau$ in the formula. But we notice that $\sigma = \tau^{-1}$, and hence
  $sgn(\sigma) = sgn(\tau)$, so we can write the above as $\prod_i T[i][\sigma(i)] (-1)^{sgn(\sigma)} v[1] \wedge v[2] \dots \wedge v[n]$.
- Thus, we have recovered the "classical determinant formula".

#### Laplace expansion of determinant


From the above algebraic encoding of the determinant of $T[i][j]$ as $\sum_{\sigma \in S_n}sgn(\sigma)\prod_i T[i][\sigma(i)]$,
we can recover the "laplace expansion" rule, that asks to pick a row $r$, and then compute the expression:
as

$$
L_r(T) \equiv \sum_c T[r, c] (-1)^{r+c} det(T'(r, c))
$$

Where $T'(r, c)$ is the matrix $T$ with row $r$ and column $c$ deleted.
I'll derive this concretely using the determinant definition for the 3 by 3 case. The general
case follows immediately. I prefer being explicit in a small case as it lets me see what's going on.

Let's pick a basis for $V$, called $b[1], b[2], b[3]$. We have the relationship
$v[i] \equiv Tb[i]$. We want to evaluate the coefficient of $v[1] \wedge v[2] \wedge v[3]$.
First grab a basis expansion of $v[i]$ as $v[i] = c[i][j] b[j]$. These uniquely define
the coefficients $c[i][j]$. Next, expand the wedge:

$$
\begin{aligned}
& v[1] \wedge v[2] \wedge v[3] \\
&= (c[1][1]b[1] + c[1][2]b[2] + c[1][3]b[3]) \wedge 
   (c[2][1]b[1] + c[2][2]b[2] + c[2][3]b[3]) \wedge 
   (c[3][1]b[1] + c[3][2]b[2] + c[3][3]b[3]) 
\end{aligned}
$$

I now expand out only the first wedge, leaving terms of the form $c[1][1]b[1] (\cdot) + c[1][2]b[2](\cdot) c[1][3]b[3] (\cdot)$.
(This corresponds to "expanding along and deleting the row" in a laplace expansion when finding the determinant)
Let's identify the $(\cdot)$ and see what remains:


$$
\begin{aligned}
& v[1] \wedge v[2] \wedge v[3] \\
&= c[1][1]b[1] \wedge (c[2][1]b[1] + c[2][2]b[2] + c[2][3]b[3]) \wedge (c[3][1]b[1] + c[3][2]b[2] + c[3][3]b[3]) 
 + c[1][2]b[2] \wedge(c[2][1]b[1] + c[2][2]b[2] + c[2][3]b[3])  \wedge(c[3][1]b[1] + c[3][2]b[2] + c[3][3]b[3]) 
 + c[1][3]b[2] \wedge(c[2][1]b[1] + c[2][2]b[2] + c[2][3]b[3])  \wedge(c[3][1]b[1] + c[3][2]b[2] + c[3][3]b[3]) 
\end{aligned}
$$

Now, for example, in the first term $c[1][1]b[1] \wedge (\cdot)$, we lose anything inside that contains a $b[1]$,
as the wedge will give us $b[1] \wedge b[1] = 0$ (this corresponds to "deleting the column" when considering the submatrix).
Similar considerations have us remove all terms that contain $b[2]$ in the brackets of $c[1][2]b[2]$, and terms that
contain $b[3]$ in the brackets of $c[1][3]b[3]$. This leaves us with:

$$
\begin{aligned}
& v[1] \wedge v[2] \wedge v[3] \\
&= c[1][1]b[1] \wedge (c[2][2]b[2] + c[2][3]b[3]) \wedge (c[3][2]b[2] + c[3][3]b[3]) 
 + c[1][2]b[2] \wedge(c[2][1]b[1] + c[2][3]b[3])  \wedge(c[3][1]b[1] +  c[3][3]b[3]) 
 + c[1][3]b[2] \wedge(c[2][1]b[1] + c[2][2]b[2] )  \wedge(c[3][1]b[1] + c[3][2]b[2]) 
\end{aligned}
$$

We are now left with calculating terms like $(c[2][2]b[2] + c[2][3]b[3]) \wedge (c[3][2]b[2] + c[3][3]b[3])$ which
we can solve by recursion (that is the determinant of the 2x2 submatrix). So if we now write the "by recursion" terms
down, we will get something like:

$$
\begin{aligned}
& v[1] \wedge v[2] \wedge v[3] \\
&= c[1][1]b[1] \wedge (k[1] b[2] \wedge b[3])
 + c[1][2]b[2] \wedge(k[2] b[1] \wedge b[3])
 + c[1][3]b[2] \wedge(k[3] b[1] \wedge b[2])
\end{aligned}
$$




Where the $k[i]$ are the values produced by the recursion, and we assume that the recursion will give
us the coefficients of the wedges "in order": so we always have $b[2] \wedge b[3]$ for example, not $b[3] \wedge b[2]$.
So, we need to ensure that the final answer we spit out corresponds to $b[1] \wedge b[2] \wedge b[3]$. If we simplify
the current step we are at, we will get:

$$
\begin{aligned}
& v[1] \wedge v[2] \wedge v[3] \\
&= k[1] c[1][1]b[1] \wedge b[2] \wedge b[3]
 + k[2] c[1][2]b[2] \wedge b[1] \wedge b[3]
 + k[3] c[1][3]b[2] \wedge b[1] \wedge b[2]
\end{aligned}
$$


We need to rearrange our terms to get $b[1] \wedge b[2] \wedge b[3]$ times some constant.
On rearranging each term into the standard form $b[1] \wedge b[2] \wedge b[3]$, we are forced to pick up the correct sign factors:

$$
\begin{aligned}
& v[1] \wedge v[2] \wedge v[3] \\
&= k[1] c[1][1]b[1] \wedge b[2] \wedge b[3]
  -k[2] c[1][2]b[1] \wedge b[2] \wedge b[3]
 + k[3] c[1][3]b[1] \wedge b[2] \wedge b[3] \\
&= (c[1][1]k[1] - c[1][2]k[2] + c[1][3]k[3])(b[1] \wedge b[2] \wedge b[3])
\end{aligned}
$$

We clearly see that for each $c[i]$, the factor is $(-1)^i k[i]$ where $k[i]$ is the answer
gotten by computing the determinant of the sub-expression where we delete the vector $b[i]$ (ignore the column)
and also ignore the entire "row", by not thinking about $c[j](\cdot)$ where $j \neq i$.
So, this proves the laplace expansion by exterior algebra.


#### Deriving Cayley Hamilton for rings from $\mathbb Z$

I'll show the idea of how to prove Cayley Hamilton for an arbitrary commutative ring $R$
given we know Cayley Hamilton for $\mathbb Z$. I describe it for 2x2 matrices.
The general version is immediate from this. Pick a variable matrix
and write down the expression for the characteristic polynomial So if:

```
M = [a b]
    [c d]
```

then the characteristic polynomial is:

```
ch
= |M - xI|
=
|a-x b|
|c   d-x|
```

that's $ch(a, b, c, d, x) \equiv (a-x)(d-x) - bc = x^2 +x (a + d) + ad - bc$. This equation has $a, b, c, d, x \in R$
for some commutative ring $R$. Now, we know that if we set $x = M$, this equation will be satisfied. But what does
it mean to set $x = A$? Well, we need to let $x$ be an arbitrary matrix:

```
x = [p q]
    [r s]
```

And thus we compute `x^2` to be:

```
x^2 
= [p q][p q]
  [r s][r s]
= [p^2 + qr; pq + qs]
  [rp + sr; rq + s^2]
```

So now expanding out $ch(a, b, c, d, x)$ in terms of $x$ on substituting for $x$ the matrix
we get the system:


```
[p^2 + qr; pq + qs] + (a + d) [p q] + (ad - bc)[1 0] = [0 0]
[rp + sr; rq + s^2]           [r s]            [0 1]   [0 0]
```

We know that these equations hold when $x = M$, because the Cayley-Hamilton theorem
tells us that $ch(M) = 0$! So we get a different system with `p = a, q = b, r = c, s = d`,
still with four equations, that we know is equal to zero! This means we have four
intederminates `a, b, c, d` and four equations, and we know that these equations are true
for all $\mathbb Z$. But if a polynomial vanishes on infinitely many points, it must
identically be zero. Thus, this means that `ch(A)` is the zero polynomial, or `ch(A) = 0`
for *all* `R`. This seems to depend on the fact that the ring is infinite, because otherwise
imagine we send $\mathbb Z$ to $Z/10Z$.  Since we don't have an infinite number
of $\mathbb Z$ elements, why should the polynomial be zero? I imagine that this
needs zariski like arguments to be handled.


#### Cramer's rules

We can get cramer's rule using some handwavy manipulation 
[or rigorizing the manipulation using geometric algebra](https://arxiv.org/pdf/1205.5935.pdf).

Say we have a system of equations:

$$
\begin{aligned}
a[1] x + b[1] y = c[1] \\
a[2] x + b[2] y = c[2] 
\end{aligned}
$$

We can write this as:

$$
\vec a x + \vec b y = \vec c
$$

where $\vec a \equiv (a_1, a_2)$ and so on. To solve the system, we wedge with $\vec a$ and $\vec b$:

$$
\begin{aligned}
\vec a \wedge (\vec a x + \vec b y) = \vec a \wedge \vec c \\
\vec a \wedge \vec b y = \vec a \wedge \vec c \\
y = \frac{\vec a \wedge \vec c}{\vec a \wedge \vec b} \\
y =
\frac{\begin{vmatrix}
a[1] & a[2] \\
c[1] & c[2] 
\end{vmatrix}}{
\begin{vmatrix}
a[1] & b[1] \\
a[2] & b[2] 
\end{vmatrix}
}
\end{aligned}
$$

Which is exactly cramer's rule.


#### The formula for the adjugate matrix from Cramer's rule (TODO)


#### References

- [More abstract proof of Cayley Hamilton](https://math.stackexchange.com/questions/605590/is-there-a-simpler-more-abstract-proof-of-the-cayley-hamilton-theorem-for-matri)
- [PlanetMath: proof of Cayley Hamilton for commutative rings](https://planetmath.org/proofofcayleyhamiltontheoreminacommutativering)


# Nakayama's lemma

I read the statement as $IM = M \implies M = 0$, when $I$ is in the jacobson radical.
1. Essentially, it tells us that if a module $M$ "lives by the $I$", then it also "dies by the $I$". 
2. Alternatively, we factor the equation as $M(I - 1) = 0$. Since our ideal $I$
   is a member of the jacobson radical, $(1 - I)$ is "morally" a unit and thus $M = 0$.
   This is of course completely bogus, but cute nontheless.
3. We can think of a graded ring, say $R[x]$ acting on some graded module $M$ (say, a subideal, $M = (x^2)$). When we compute $IM$,
   this will bump up the grading of $M$. If $IM = M$, then $M$ could not have had non-trivial elements in the first place, since the
   vector of, say, "non-zero elements in each grade" which used to look like $(v_0, v_1, v_2, \dots)$ will now look like $(0, v_0, v_1, \dots)$.
   Equating the two, we get $v_0 = 0, v_1 = v_0 = 0, v_2 = v_1 = 0$ and so on, collapsing the entire ring.

# Vector fields over the 2 sphere

We assume that we already know the hairy ball theorem, which states that
no continuous vector field on $S^2$ exists that is nowhere vanishing. Using
this, we wish to deduce (1) that the module of vector fields over $S^2$ is
not free, and an *explicit* version of what the
[Serre Swan theorem](https://en.wikipedia.org/wiki/Serre%E2%80%93Swan_theorem)
tells us, that this module is *projective*

#### 1. Vector fields over the 2-sphere is projective

Embed the 2-sphere as a subset of $\mathbb R^3$. So at each point, we have
a tangent plane, and a normal vector that is perpendicular to the sphere:
for the point $p \in S^2$, we have the vector $p$ as being normal to $T_p S^2$ at $p$.
So the normal bundle is of the form:

$$
\mathfrak N \equiv \{ \{ s \} \times \{ \lambda s : \lambda in \mathbb R \}  : s \in \mathbb S^2 \}
$$
- If we think of the trivial bundle, that is of the form $Tr \equiv \{ s \} \times \mathbb R : s \in \mathbb S^2 \}$.
- We want to show an isomorphism between $N$ and $T$.
- Consider a map $f: N \rightarrow Tr$ such that $f((s, n)) \equiv (s, ||n||)$. The inverse
  is $g: Tr \rightarrow N$ given by $g((s, r)) \equiv (s, r \cdot s)$. It's easy to check that these
  are inverses, so we at least have a bijection.
- To show that it's a vector bundle morphism, TODO.
- (This is  hopelessly broken, I can't treat the bundle as a product. I can locally I guess by taking charts;
   I'm not sure how I ought to treat it globally!)



#### 1. Vector fields over the sphere is not free

- 1. Given two bundles $E, F$ over any manifold $M$, a module isomorphism
  $f: \mathfrak X(E) \rightarrow \mathfrak X(F)$ of vector fields as 
  $C^\infty(M)$ modules is induced by a smooth isomorphism of vector bundles $F: E \rightarrow F$.
- 2. The module $\mathfrak X(M)$ is finitely generated as a $C^\infty$ module over $M$.
- Now, assume that $\mathfrak X(S^2)$ is a free module, so we get that
  $\mathfrak X(S^2) \simeq \oplus_i C^\infty(S^2)$.
- By (2), we know that this
  must be a finite direct sum for some finite $N$: $mathfrak X(S^2) = \oplus_i=1^N C^\infty(S^n)$.
- But having $N$ different independent non-vanishing functions on $\mathbb S^2$ is the same as
  clubbing them all together into a vector of $N$ values at each point at $S^2$.
- So we get a smooth
  function $S^2 \rightarrow \mathbb R^n$, AKA a section of the trivial bundle
  $\underline{\mathbb R^n} \equiv S^2 \times \mathbb R^n$.
- This means that we have managed to trivialize the vector bundle over the sphere if vector fields over $S^2$ were a free module.
- Now, pick the element $S^2 \times \{ (1, 1, 1, 1, \dots) \} \in S^2 \times \mathbb R^n$. This is a nowhere
  vanishing vector field over $S^2$. But such an object cannot exist, and hence vector fields over the
  sphere cannot be free.



#### References

- [Smooth vector fields over $S^2$ is not a free module](https://math.stackexchange.com/questions/4052994/smooth-vector-fields-over-the-2-sphere-is-not-a-free-module/)
- [Smooth vector fields over $S^2$ is a projective module](https://math.stackexchange.com/questions/4053091/explicitly-exhibit-that-vector-fields-over-the-2-sphere-is-a-projective-module)


# Learning to talk with your hands

I was intruged by [this HN thread](https://news.ycombinator.com/item?id=26382528)
about learning to talk with your hands. I guess I'm going to try and do this more often now.

# Lovecraftisms

I recently binged a lot of Lovecraftian horror to get a sense of
his writing style. Here's a big list of my favourite quotes:

> His madness held no affinity to any sort recorded in even the latest and most
> exhaustive of treatises, and was conjoined to a mental force which would have
> made him a genius or a leader had it not been twisted into strange and
> grotesque forms. 


> seething vortex of time

> Snatches of what I read and wrote would linger in my memory. There were
> horrible annals of other worlds and other universes, and of stirrings of
> formless life outside of all universes

> clinging pathetically to the cold planet and burrowing to its horror-filled
> core, before the utter end.

> appalled at the measureless age of the fragments

> fitted darkly into certain Papuan and Polynesian legends of infinite
> antiquity

> The condition and scattering of the blocks told mutely of vertiginous cycles
> of time and geologic upheavals of cosmic savagery.

> uttermost horrors of the aeon-old legendry

> The moon, slightly past full, shone from a clear sky, and drenched the
> ancient sands with a white, leprous radiance which seemed to me somehow
> infinitely evil.

> with the bloated, fungoid moon sinking in the west

> how preserved through aeons of geologic convulsion I could not then
> and cannot now even attempt to guess.

> gently bred families of the town

> could not escape the sensation of being watched from ambush on every hand by
> sly, staring eyes that never shut.

> and there was that constant, terrifying impression of other sounds--perhaps
> from regions beyond life--trembling on the very brink of audibility.

> little garden oasis of village-like antiquity where huge, friendly cats
> sunned themselves atop a convenient shed.


> Better it be left alone for the years to topple, lest things be stirred that ought to rest forevrr in the black abyss

> It clearly belonged to some settled technique of infinite maturity and
> perfection, yet that technique was utterly remote from any--Eastern or
> Western, ancient or modern--which I had ever heard of or seen exemplified. It
> was as if the workmanship were that of another planet.


> intricate arabesques roused into a kind of ophidian animation. 

> never was an organic brain nearer to utter annihilation in the chaos that
> transcends form and force and symmetry.


> away outside the galaxy and possibly beyond the last curved rim of
> space. 


> It was like the drone of some loathsome, gigantic insect ponderously shaped
> into the articulate speech of an alien species

> In time the ruts of custom and economic interest became so deeply cut in
> approved places that there was no longer any reason for going outside them,
> and the haunted hills were left deserted by accident rather than by design


> There were, too, certain caves of problematical depth in the sides of the
> hills; with mouths closed by boulders in a manner scarcely accidental, and
> with more than an average quota of the queer prints leading both toward and
> away from them

> he fortified himself with the mass lore of cryptography

> As before, the sides of the road showed a bruising indicative of the
> blasphemously stupendous bulk of the horror

> The dogs slavered and crouched close to the feet of the fear-numbed family. 

> an added element of furtiveness in the clouded brain which subtly transformed
> him from an object to a subject of fear


> fireflies come out in abnormal profusion to dance to the raucous, creepily
> insistent rhythms of stridently piping bull-frogs.

> a seemingly limitless legion of whippoorwills that cried their endless
> message in repetitions timed diabolically to the wheezing gasps of the dying
> man

> pandemoniac cachinnation which filled all the countryside

> the left-hand one of which, in the Latin version, contained such monstrous
> threats to the peace and sanity of the world

> Their arrangement was odd, and seemed to follow the symmetries of some cosmic
> geometry unknown to earth or the solar system

> faint miasmal odour which clings about houses that have stood too long

> I do not believe I would like to visit that country by night--at least not when the sinister stars are out

> there was much breathless talk of new elements, bizarre optical properties,
> and other things which puzzled men of science are wont to say when faced by
> the unknown..

> stealthy bitterness and sickishness, so that even the smallest bites induced a lasting disgust

> plants of that kind ought never to sprout in a healthy world.


>  everywhere were those hectic and prismatic variants of some diseased,
>  underlying primary tone without a place among the known tints of earth.
> 
> In her raving there was not a single specific noun, but only verbs and
> pronouns..


> great bare trees clawing up at the grey November sky with a studied malevolence

> There are things which cannot be mentioned, and what is done in common
> humanity is sometimes cruelly judged by the law.


> monstrous constellation of unnatural light, like a glutted swarm of corpse-fed
> fireflies dancing hellish sarabands over an accursed marsh,


> No traveler has ever escaped a sense of strangeness in those deep ravines, and
> artists shiver as they paint thick woods whose mystery is as much of the
> spirits as of the eye. 


> We live on a placid island of ignorance in the midst of black seas of infinity,
> and it was not meant that we should voyage far. The sciences, each straining in
> its own direction, have hitherto harmed us little; but some day the piecing
> together of dissociated knowledge will open up such terrifying vistas of
> reality, and of our frightful position therein, that we shall either go mad
> from the revelation...



> form which only a diseased fancy could conceive

> ... dreams are older than brooding Tyre, or the contemplative Sphinx, or
> garden-girdled Babylon

> iridescent flecks and striations resembled nothing familiar to geology or
> mineralogy. 



> miserable huddle of hut

> Only poetry or madness could do justice to the noises heard by Legrasse's men
> as they ploughed on through the black morass.

> In his house at R'lyeh dead Cthulhu waits dreaming

> all the earth would flame with a holocaust of ecstasy and freedom.

> The aperture was black with a darkness almost material.

# Hairy ball theorem from Sperner's Lemma (TODO)

- Let $\Delta$ be an n-dimensional simplex with vertices $v_0, v_1, \dots, v_n$.
- Let $\Delta_i$ be the face opposite to vertex $v_i$. That is, $\Delta_i$ is the face with all vertices except $v_i$. 
- The boundary $\partial \Delta$ is the union of all the $n+1$ faces of $\Delta_i$ (i is from $0$ to $n$).
- Let $\Delta$ be subdivided into smaller simplicies forming a simplciial complex $S$. 
- **Sperner's lemma**: Let the vertices of $S$ be labelled by $\phi: S \rightarrow \Delta$ (that is,
   it maps all vertices of the simplicial complex $S$ to one of the vertices of the simplex $\Delta$),
   such that $v \in \Delta_i  \implies \phi(v) \neq i$. Then there is at least one $n$-dimensional simplices
   of $S$ whose image is $\Delta$ (That is, there is at least one n-dimensional-sub-simplex $T \subseteq S$
   such that vertices of $T$ are mapped to $\{0, 1, \dots, n\}$). More strongly, the number of such
   sub-simplices is *odd*.
- We can see that the map $\phi$ looks like some sort of retract that maps the complex $S$ to its boundary $\Delta$.
  Then Sperner's lemma tells us that there is one "region" $T \subseteq S$ that gets mapped onto $\Delta$.

#### 1D proof of Sperner's: Proof by cohomology

- For 1D, assume we have a line with vertex set $V$ and edges $E$. Let the vertex at the
  beginning be $v_0$ and the vertx at the end be $v_1$. That is, $\Delta \equiv \{v_0, v_1\}$
  and $S \equiv (V, E)$ is a subcomplex of $\Delta$ --- that is, it subdivides the line $\Delta$
  into smaller portions. Let $\phi: S \rightarrow \Delta$ be the labelling function.
- create a function $f: \Delta \rightarrow \mathbb F_2$ that assigns $0$ to
  $v_0$ and $+1$  to $v_1$: $f(v_0) \equiv 0; f(v_1) \equiv 1$. Use this to generate a
  function on the full complex $F: S \rightarrow F_2; F(v) \equiv F(\phi(v))$.

- From $F$, generate a function on the edges
  $dF: E \rightarrow F_2; dF(\overline{vw}) = F(w) + F(v)$. See that this scores such that
  $dF(AB) = +1$, $dF(BA) = +1$, $dF(AA) = dF(BB) = 0$. (Recall that the arithmetic is over $F_2$)
  So, $dF$ adds a one every time we switch from $A$ to $B$ or from $B$ to $A$.
- However, we also see that $dF$ is generated from a "potential function "f". Hence we
  have the identity $\sum_{e \in E} dF(e) = f(v_1) - f(v_0) = 1 - 0 = 1$. Hence,
  we must have switched signs an odd number of times.
- Since we start from $A$, that means we must have switched from $A$ to $B$ an odd number of times.


#### 2D proof of Sperner's: Proof by search

- Start from an edge in the bottom $ef$ labeled $BC$. We are looking for a simplex labeled $ABC$.
- To start: Pick some vertex above $ef$, say $g$. If this is labeled $A$, we are done. If not, say this is
  labeled $B$. So we get triangle $efg=ABB$. Launch our search procedure from this triangle $efb$.
- Find the triangle adjacent to $efg$ along the edge $eg=AB$ (the other $AB$ edge, not the one we started with).
  If this adjacent triangle $egh$ has $h=A$ we are done. If not, move to the triangle $egh$.
- See that we will either find a triangle labeled $ABC$, or we will keep running into triangles labeled $ABB$.
- We cannot ever *repeat* a triangle in our path; to repeat a triangle is to start with some edge $xy$
  and then to pick a vertex $z$ such that $xyz=efg$ where $efg$ was already picked. This must mean that the
  edge $ef$ was already picked. [TODO]

#### Proof of hairy ball by sperner's lemma [TODO]


#### Why hairy ball is interesting: Projective modules 

The reason I care about the hairy ball theorem has to do with vector fields.
The idea is to first think of smooth vector fields over a smooth manifold.
What algebraic structure do they have? Indeed, they are a vector space over $\mathbb R$.
However, it is difficult to exhibit a basis. Naively, for each point $p \in M$, we would
need a basis $T_p B \subset T_p M$ as a basis. This brings in issues of smoothness, etc.
Regardless, it would be uncountable in dimension.

On the other hand, let's say we allow ourselves to consider vector fields as *modules*
over the ring of smooth functions on a manifold. That is, we can scale the vector
field by a different value at each point.

We can hope the ""dimension"" of the module is much smaller.
So, for example, if we think of $\mathbb R^2$, given some vector field $V \equiv v_x \hat x + v_y \hat y$,
the functions $v_x$ and $v_y$ allow us to write  basis! Create the vector fields $V_x \equiv \hat x$
and $V_y \equiv \hat y$. Then any vector field $V$ can be written as $V = v_x V_x + v_y V_y$
for functions $v_x, v_y$ in a unique way!


However, as we know, **not all modules are free**. A *geometric* example of such
a phenomenon is the module of vector fields on the _sphere_. By the hairy ball theorem,
any vector field must vanish at at least a single point. So if we try to build a vector
field pointing "rightwards" (analogous to $\hat x$) and "upwards" (analogous $\hat y$),
these *will not be valid smooth vector fields*, because they don't vanish! So,
we will be forced to take more than two vector fields. But when we do that,
we will lose uniqueness of representation. However, all is not lost.
The [Serre Swan theorem](https://en.wikipedia.org/wiki/Serre%E2%80%93Swan_theorem) 
tells us that any such module of vector fields will be a *projective* module.
The sphere gives us a module that is not free. I'm not sure how to show that it's projective.

#### Simple example of projective module that is not free.

- Let $K$ be a field. Consider $R \equiv K \times K$ as a ring, and let $M \equiv K$
  be a module on top of $R$.
- $M$ is a projective module because $M \oplus K \simeq R$
  (that is, we can direct sum something onto it to get the some $\oplus_i R$)
- On the other hand, $M$ itself is not free because $M \neq \oplus_i R$ for any $i$. Intuitively,
  $M$ is "half an $R$" as $M \simeq K$ while $R \simeq K\times K$.
- The geometric picture is that we have a space with two points $\{p, q\}$. We have a bundle
  on top of it, with $M$ sitting on $p$ and $0$ (the trivial module) sitting on top of $q$.
  When we restrict to $p$, we have a good bundle $M$.
- But in total over thr space, we can't write the bundle as $M \times \{p, q\}$ because the
  **fibers have different dimensions**! The dimension over $p$ is $dim(M) = 1$ while over $q$
   is $dim(0) = 0$.
- What we can do is to "complete" the bundle by adding a copy of $M$ over $q$, so that we can
  then trivialise the bundle to write $M \times \{p, q\}$.
- So, a projective module corresponds to a vector bundle because it locally is like a vector space,
  but may not be trivialisable due to a difference in dimension, or compatibility, or some such.

- [Sperner's lemma, Brower's fixed point theorem, and cohomology](https://arxiv.org/pdf/0906.5193.pdf)

# CS and type theory: Talks by vovodesky

- [Talk 1: Computer Science and Homotopy Theory](https://www.youtube.com/watch?v=UvDeVqzcw4k)
- Think of ZFC sets as rooted trees. Have two axioms:
- (1) all branches of all vertices are non-isomorphic (otherwise a set would have two copies of the same element)
- (2) Each leaf must be at finite depth from the root.
- This is horrible to work with, so type theory!
- [Talk 2: What if foundations of math is inconsistent?](https://www.youtube.com/watch?v=O45LaFsaqMA)
- We "know" that first order math is consistent. We can prove that it is impossible
  to prove that first order math is consistent!
- Choice 1: If we "know" FOL is consistent, then we should be able to transform
  this knowledge into a proof, then 2nd incompleteness is false.
- Choice 2: Admit "transcendental" part of math, write dubious philosophy.
- Choice 3: Admit that our sensation that FOL +arithmetic is consistent is an illusion
  and admit that FOL arithmetic is inconsistent.
- Time to consider Choice 3 seriously?

#### First order arithmetic

Mathematical object which belongs to class of objects called  formal theories.
Has four pieces of data:

1. Special symbols, names of variables.
2. Syntactic rules.
3. Deduction rules: Construct new closed formulas from old closed formula.
4. Axioms: collection of closed formulas. 

Anything that is obtainable from these deduction rules is called a theorem.
First order logic have symbols: `∀, ∃, ⇒, !(not)` and so on. First order theory is
inconsistent if there a closed formula $A$ such that both $A$ and $!A$ is a
theorem.

- Free variables describe subsets. 
  Eg: `∃ n: n^2 = m` describes the set `{ m : ∃ n: n^2 = m }`.
- It's possible to construct subsets (formulae with one free variable) whose
  membership is undedicable. So you can prove that it is impossible to say
  anything whatsoever about these subsets.


#### Gentzen's proof and problems with it

Tries to reason about trees of deduction. Show that proofs correspond to
combinatorial objects. Show that inconsistency corresponds to an infinite
decreasing sequence that never terminates. Then he says that it is 
"self evident" that this cannot happen. But it is not self evident!

#### What would inconsistency of FOL mean for mathematicians?

- Inconsistency of FOL implies inconsistency of many other systems
  (eg. set theory).
- Inconsistency of FOL implies inconsistency of *constructive* (intuitionistic)
  mathematics! (WTF?) shown by Godel in 1933. Takes a proof of contradiction
  in classical and strips off LEM.
- We need foundations that can create *reliable proofs* **despite** being
  inconsistent!
- Have systems that react to inconsistency in less drastic ways.
  One possible candidate is constructive type theories.
  A proof of a formula in such a system is itself a formula in the system.
  There are no deduction rules, only syntactic rules. So a proof is an object
  that can be studied in the system. If one has a proof of contradiction,
  then such a proof can be detected --- they have certain properties that can
  be detected by an algorithm (what properties?)

#### New workflow

- Formalize a problem.
- Construct creative solution.
- Submit proof to a "reliable" verifier. If the verifier terminates, we are 
  done. If the verifier does not terminate, we need to look for other proofs that
  can terminate.
- our abstract thinking cancels out by normalisation :P 


#### Summary
- Correct interpretation of 2nd incompleteness is a step of proof of inconsistency
  of FOL (Conjecture).
- In math, we need to learn how to use inconsistent theories to obtain reliable
  proofs. Can lead to more freedom in mathematical workflow.

#### Univalent Foundations: New Foundations of Mathematics
- [Talk 3: Univalent foundations --- New Foundations of Mathematics](https://www.youtube.com/watch?v=E9RiR9AcXeE)


- Was uncertain about future when working on 2-categories and higher 
  math. No way to ground oneself by doing "computations" (numerical experiments).
  To make it worse, the existing foundations of set theory is bad for these
  types of objects.
- Selected papers on Automath.
- Overcoming category theory as new foundations was very difficult for vovodesky.
- Categories are "higher dimensional sets"? NO! Categories are "posets in the next dimension".
  Correct version of "sets in the next dimension" are groupoids (WHY?)
  [MathOverflow question](https://mathoverflow.net/questions/309515/why-did-voevodsky-consider-categories-posets-in-the-next-dimension-and-groupo)
- Grothendeick went from isomorphisms to all morphisms, this prevented him from
  gravitating towards groupoids.
- Univalent foundations is a complete foundational system.
- [Sets are groupoids on the next dimension](https://mathoverflow.net/questions/309515/why-did-voevodsky-consider-categories-posets-in-the-next-dimension-and-groupo)




#### Vovodesky's univalence principle --- Joyal

- [Talk 5: Vovodesky's univalence principle --- Joyal](https://www.youtube.com/watch?v=HRBShaxIblI)

- Univanent type theory is arrived at by adding univalence to MLTT.
- Goal of univalent foundations is to apply UTT to foundations.
- Univalence is to type theory what induction principle is to peano arithmetic
- Univalence implies descent. Descent implies Blakers Massey-theorem, which
  implies Goodwille calculus.

- The syntactic system of type theory is a **tribe**.
- A clan is a category equipped with a class of _carrable maps_ called fibrations.
  A map is carrable if we can pull it back along any other map.
- A clan is a category along with maps called "fibrations", such that (1) every
  isomorphism is a fibration, (1) closed under composition, (3) fibrations are
  carrable, (4) base change of fibration is a fibration, (4) Category has a terminal
  object, and map into the terminal object is a fibration.
- A map $u: A \rightarrow B$ is **anodyne** if it does something good with respect
  to fibrations.
- A **tribe** is a clan such that (1) base chnge of anodyne along fibration is anodyne,
  (2) every map factorizes as anodyne followed by fibration.
- Kan complexes form a tribe. A fibration is a Kan fibration. A map is anodyne
  here if it is a monomorphism and a homotopy equivalence.
- Given a tribe $E$, can build a new tribe by slicing $E/A$ (this is apparently
  very similar to things people do in Quillen Model categories).
- A tribe is like a commutative ring. We can extend by adding new variables to get
  polynomial rings. An elementary extension is extending the tribe by adding a new
  element.
- If $E$ is a tribe, an object of $E$ is a type. We write `E |- A : Type`.
- If we have a map $a: 1 -> A$, we regard this as an element of A: `E |- a : A`.
- A fibration is a family of objects. This is a dependent type `x : A |- E(x): Type`.
  `E(x)` is the fiber  of `p: E -> A` at a variable element `x : A`.
- A section of a fibration gives an element of the fibration. We write this as 
  `x : A |- s(x) : E(x)`. `s(x)` denotes the value of `s: A -> E` of a variable
   element `x : A`. (Inhabitance is being able to take the section of a fiber bundle?!)
- change of parameters / homomorphism is substitution. 

```
y : B |- E(y) : Type
--------------------
x : A |- E(f(x)) : Type
```

This is pulling back along fibrations.

- Elementary extension `E -> E(A)` are called as context extensions.

```
|- B : Type
-----------
x : A |- B : Type
```

- A map between types is a variable element `f(x) : B` indexed by `x : A`

```
x : A |- f(x) : B
```

- Sigma formation rule: The total space of the union is the sum of all fibers(?)

```
x: A |- E(x): Type
------------------
|- \sum{x : A}E(x): Type
```


```
x: A |- E(x): Type
------------------
y : B |- \sum{x : f^{-1}(y)}E(x): Type
```

- Path object for $A$ is obtained by factorial diagonal map `diag: a -> (a, a)` as an anodyne
  map `r: A -> PA` followed by a fibration `(s, t) : PA -> A x A`.

- A homotopy `h: f ~ g` between two maps `f, g : A -> B` is a map`h: A -> PB` 
  such that `sh = f` and `th = g`. homotopy is a congruence.
- `x: A, y : A |- Id_A(x, y) : Type` called the identity type of A.
- An element `p: Id_A(x, y)` is a proof that `x =A y`.
- Reflexivity term `x : A |- r(x) : Id_A(x, x)` which proves `x =A x`.
- The identity type is a path object
- $\gamma(x, y): Id_A(x, y) -> Eq(E(x), E(y))$. $\gamma$ is some kind of
  connection: given a path from $x$ to $y$, it lets us transport $E(x)$ to $E(y)$,
  where the $Eq$ is the distortion from the curvature?

# Hilbert basis theorem for polynomial rings over fields (TODO)

**Theorem:** Every ideal $I$ of $k[x_1, \dots, x_n]$ is finitely generated.

First we need a lemma:

#### Lemma:
Let $I \subseteq k[x_1, \dots, x_n]$ be an ideal. (1) $(LT(I)) \equiv $ is
a **monomial ideal**. An ideal $I$ is a monomial ideal if there is a subset
$A \subseteq \mathbb Z^n_{\geq 0}$ (possibly infinite) such that $I = (x^a : a \in a)$.
That is, $I$ is generated by monomials of the form $x^a$. Recall that since we 
have 

#### Proof of hilbert basis theorem

- We wish to show that every ideal $I$ of $k[x_1, \dots, x_n]$ is finitely generated.
- If $I = \{ 0 \}$ then take $I = (0)$ and we are done.
- Pick polynomials $g_i$ such that $(LT(I)) = (LT(g_1), LT(g_2), \dots, LT(g_t))$.
  This is always possible from our lemma.
  We claim that $I = (g_1, g_2, \dots, g_t)$.
- Since each $g_i \in I$, it is clear that $(g_1, \dots, g_t) \subseteq I$.
- Conversely, let $f \in I$ be a polynomial. 
- Divide $f$ by $g_1, \dots, g_t$ to get $f = \sum_i a_i g_i + r$ where no term
  of $r$ is divisible by $LT(g_1), \dots, LT(g_t)$. We claim that $r = 0$.



#### References

- Cox, Little, O'Shea: computational AG.


# Covering spaces

#### Covering spaces: Intuition

- Consider the map $p(z) = z^2 : \mathbb C^\times \rightarrow \mathbb C^\times$. This is a
  2-to-1 map. We can try to define an inverse regardless.
- We do define a "square root" if we want. Cut out a half-line $[0, -infty)$
  called $B$ for branch cuts. We get two functions on 
  $q_+, q_-: \mathbb C - B  \rightarrow \mathbb C^\times$, such that $p(q_+(z)) = z$.
  Here, we have $q_- = - q_+$.
- The point of taking the branch cut is to preserve simply connectedness. $\mathbb C^\times$
  is not simply connected, while $\mathbb C/B$ is simply connected! 
  (This seems so crucial, why has no one told me this before?!)
- Eg 2: exponential. Pick $exp: \mathbb C \rightarrow \mathbb C^\times$. This is
  surjective, and infinite to 1. $e^{z + 2 \pi n} = e^{iz}$.
- Again, on $\mathbb C / B$, we have $q_n \equiv \log + 2 \pi i n$, such that 
  $exp(q_n(z)) = z$.                                                        
- A covering map is, roughly speaking, something like the above. It's a map that's
  n-to-1, which has n local inverse defined on simply connected subsets of 
  the target. 
- So if we have $p: Y \rightarrow X$, we have $q: U \rightarrow Y$ (for $U \subseteq X$)
  such that $p(q(z)) = z, \forall z \in U$.


#### Covering spaces: Definition

- A subset $U \subset X$ is a called as an **elementary neighbourhood**
  if there is a discrete set $F$ and a homeomorphism $h: p^{-1}(U) \rightarrow U \times F$
  such that $p|_{p^{-1}(U)}(y) = fst(h)$ or $p|_{p^{-1}(U)} = pr_1 \circ h$.
- [Alternative definition](https://www.math.wisc.edu/~maxim/751f14w6.pdf)
  A subset $U \subset X$ is called as **evenly covered/elementary nbhd** if 
  $p^{-1}(U) = \sqcup \alpha V_\alpha$ where the $V_\alpha$ are disjoint and open, and
  $p|_{V_\alpha} : V_\alpha \rightarrow U$ is a homeomorphism for all $\alpha$.
- An elementary neighbourhood is the region where we have the local inverses
  (the complement of a branch cut).
- We get for each $i \in F$ , a map $q_i : U \rightarrow U \times F; q_i(x) = (x, i)$
  and then along $h^{-1}$ sending $h^{-1}(x, i) \in p^{-1}(U)$.
- We say $p$ is a covering map if $X$ is covered by elementary neighbourhoods.
- We say $V \subseteq Y$ is an elementary sheet if it is path connected and $p(V)$
  is an elementary neighbourhood. 
- So, consider $p(x) = e^{ix}: \mathbb R \rightarrow S^1$.  If we cut the space
  at $(0, 0)$, then we will have elementary neighbourhood $S^1 - \{(0, 0)\}$
  and elementary sheets $(2 \pi k,  2 \pi+1)$.
- The point is that the inverse projection $p^{-1}$ takes $U$ to some object of the form $U \times F$:
  a local product! So even though the global covering space $\mathbb R$ does not look
  like a product of circles, it locally does. So it's some sort of fiber bundle?


> Slogan: Covering space is locally disjoint copies of the original space.


#### Path lifting and Monodromy

- Monodromy is behaviour that's induced in the covering space, on moving in a loop in a base. 
- Etymology: Mono --- single, drome --- running. So running in a single loop /
  running around a single time.
- Holonomy is a type of monodromy that occurs due to parallel transport in a loop, **to detect curvature**
- Loop on the base is an element of $\pi_1(X)$.
- Pick some point $x \in X$. Consider $F \equiv \pi^{-1}(x)$ ($F$ for fiber).
- Now move in a small loop on the base, $\gamma$. The local movement will cause
  movement of the elements of the fiber.
- Since $\gamma(1) = \gamma(0)$, the elements of the fiber at the end of the movement
  are equal to the original set $F$.
- So moving in a loop induces a permutation of the elements of the fiber $F$.
- Every element of $\pi_1(X)$ induces a permutation of elements of the fiber $F$.
- This lets us **detect non-triviality** of $\pi_1(X)$. The action of $\pi_1(X)$ on the fiber
  lets us "detect" what $\pi_1(X)$ is.
- We will define what is means to "move the fiber along the path".


#### Path lifting lemma

**Theorem**:Suppose $p: y \rightarrow X$ is a covering map. Let $\delta: [0, 1] \rightarrow X$
be a path such that $\delta(0) = x$, and let $y \in p^{-1}(x)$ [$y$ is in the fiber of $x$].
Then there is a **unique** path $\gamma: [0,1] \rightarrow Y$ which "lifts" $\delta$.
That is, $\delta(p(y)) = \gamma(y)$, such that $\gamma(0) = Y$. 


> Slogan: Paths can be lifted. Given how to begin the lift, can be extended all the way.

- Let $N$ be a collection of **elementary neighbourhoods** of $X$.
- $\{ \delta^{-1}(U) : U \in N \}$ is an open cover (in the compactness sense) of $[0, 1]$.
- By compactness, find a finite subcover. Divide interval into subintervals $0 = t_0 < t_1 < \dots t_n = 1$
  such that $\delta|k = \delta|_{[t_k, t_{k+1}]}$ lands in $U_k$, an elementary neighbourhood.
- Build $\gamma$ by induction on $k$.
- We know that $\gamma(0)$ should be $y$.
- Since we have an elementary neighbourhood, it means that there are a elementary
  sheets living over $U_0$, indexed by some discrete set $F$. $y$ lives in one
  of thse sheets. We have local inverses $q_m$. One of them lands on the sheet
  of $y$, call it $q$.  So we get a map $q: U_0 \rightarrow Y$ such that $q(x) = y$.
- Define $\gamma(0) \equiv q(\delta(0)) = q(x) = y$.
- Extend $\gamma$ upto $t_1$.
- Continue all the way upto $t_k$.
- To get $\gamma$ from $(t_k, t_{k+1}$, there exists a $q_k: U_k \rightarrow Y$
  such that $q_k(\delta(t_k)) = \gamma(t_k)$.
  Define $\gamma(t_k \leq t \leq t_{k_1}) \equiv q_k(\delta(t_k))$.
- This is continuous because $\delta$ continuous by definition, $q_k$ continuous
  by neighbourhood, $\gamma$ is pieced together such that endpoints fit,
  and is thus continuous.
- Can check this is a lift! We get $p \circ \gamma = p \circ q_k \circ \delta_k$.
  Since $q_k$ is a local inverse of $p$, we get $p \circ \gamma = \delta_k$
  in the region.

#### 7.03: Path lifting: uniqueness

If we have a space $X$ and a covering space $Y$, for a path $gamma$ that 
starts at $x$, we can find a path $\gamma'$ which starts at $y \in p^{-1}(x)$
and projects down to $\gamma$: $\gamma(t) = p(\gamma'(t))$. We want to show
that this path lift is **unique**

##### Lemma                                               

Let $p: Y \rightarrow X$ be a covering space. Let $T$ be a connected space
Let $F: T \rightarrow X$ be a continuous map (for us, $T \simeq [0, 1]$).
Let $F_1, F_2: T \rightarrow Y$ be lifts of $F$ ($p \circ F_1 = F$, $p \circ F_2 = F$).
We will show that $F_1 = F_2$ iff the lifts are equal for some $t \in $T.


> Slogan: Lifts of paths are unique: if they agree at one point, they agree at all points!

<img src="./static/cw/path-lifting-uniqueness-setup.png"/>

- We just need to show that if $F_1$ and $F_2$ agree somewhere in $Y$, they agree 
  everywhere. It is clear that if they agree everywhere, they must agree somewhere.
- To show this, pick the set $S$ where $F_1, F_2$ agree in $Y$: $S \equiv \{ t \in T : F_1(t) = F_2(t) \}$.
- We will show that $S$ is open and closed. Since $T$ is connected, $S$ must
  be either the full space or the empty set. Since $S$ is assumed to be non-empty,
  $S = T$ and the two functions agree everywhere.
- (Intuition: if both $S$ and $S^c$ are open, then we can build a function that colors $T = S \cup S^c$
  in two colors continuously; ie, we can partition it continuously; ie the spaces
  must be disconnected. Since $T$ is connected, we cannot allow that to happen,
  hence $S = \emptyset$ or $S = T$.)
- Let $t \ in T$. Let $U$ be an evenly covered neighbourhood/elementary neighbourhood of $F(t)$ downstairs (in $X$).
  Then we have $p^{-1}(U) = \sqcup_\alpha V_\alpha$ such that $p|_V{\alpha}: V_\alpha \rightarrow U$ 
  is a local homeomorphism.
- Since $F_1, F_2$ are continuous, we will have opens
  $V_1, V_2$ in $V_\alpha$, which contain $F_1(t), F_2(t)$ upstairs 
  (mirrroring $U$ containing $F(t)$ downstairs).
- The pre-images of $V_1$, $V_2$ along $F_1, F_2$ give us open sets $t \in T_1, T_2 \subseteq T$.
- Define $T* = T_1 \cap T_2$.  If $F_1(t) \neq F_2(t)$, then $V_1 \neq V_2$
  and thus $F_1 \neq F_2$ on all of $T*$. So, $S^c = T*$ is open.
- If $F_1(t) = F_2(t)$, then $V_1 = V_2$ and thus $F_1 = F_2$ on $T*$
  (since $p \circ F_1 = F = p \circ F_2$, and $p$
  is injective within $U$, ie within $V_1, V_2$). So $S$ is open.
- Hence we are done, as $S$ is non-empty and clopen and is thus equal to $T$.
  Thus, the two functions agree on all of $T$.

#### Homotopy lifting, Monodromy

- Given a loop $\gamma$ in $X$ based at $x$ ,
  the **monodromy around $\gamma$** is a permutation
  $\sigma_\gamma : p^{-1}(x) \rightarrow p^{-1}(x)$,
  where $\sigma_{\gamma}(y) \equiv \gamma^y(1)$
  where $\gamma^y$ is the unique lift of $\gamma$ staring at $y$.
  We have that $\sigma_{\gamma} \in Perm(p^{-1}(x))$.
- Claim: if $\gamma_1 \simeq \gamma_2$ then $\sigma_{\gamma_1} = \sigma_{\gamma_2}$.
- We need a tool: homotopy lifting lemma.


> Slogan: permutation of monodromy depends only on homotopy type

#### Homotopy lifting lemma/property of covering spaces

Suppose $p: Y \rightarrow X$ is a covering map and $\gamma_s$ is a homotopy
of paths rel. endpoints ($\gamma_s(0)$ and $\gamma_s(1)$ are independent of $s$ /
endpoints are fixed throughout the homotopy). Then there exists for each 
lift $\gamma'_0 : [0, 1] \rightarrow Y$ of $\gamma_0:[0,1] \rightarrow X$
(ie, $p \circ \gamma'_0 = gamma_0$), a completion
of the lifted homotopy $\gamma'_s: [0, 1] \rightarrow Y$ (ie, $p \circ gamma'_s = gamma_s$).
Moreover, this lifted homotopy is rel endpoints: ie, the endpoints of $gamma'$ are
independent of $s$.

> Slogan: homotopy lifted at 0 can be lifted for all time

- Let $H: [0, 1] \times [0, 1] \rightarrow X$ be the homotopy in $X$ such that 
  $H(s, t) = \gamma_s(t)$. Subdivide the square into rectangles $R_{ij}$  such that
  $H(R_{ij})$ is contained in $U_{ij}$ for some elementary neighbourhood $U_{ij}$.
  We build $H': [0, 1] \times [0, 1] \rightarrow Y$ by building local inverses
  $q_{ij} : U_{ij} \rightarrow Y$ such that $p \circ q_{ij}  = R_{ij}$.
  We then set $H'|_{R_{ij}}  = q_{ij} \circ H$.


- [Reference video](https://www.youtube.com/watch?v=3CuQ3yfh0eA&list=PLN_4R2IuNuuTWD00k9BAB1fo0UldBHnME&index=31)
- [Notes for uniqueness of path lifting](https://www.math.wisc.edu/~maxim/751f14w6.pdf)




# Wedge Sum and Smash Product

I sometimes forget which is which. I now remember this as folows:

- First, these work on based spaces so we always need to think of based points.
- Wedge is a sum, so it's going to be some type of union. It needs to identify
  things, so it better be $A \cup B / \sim$ where $\sim$ identifies based points.
- Smash is a product, so it's going to be some type of product. It needs to 
  identify things, so it better be $A \times B / \sim$, where $\sim$ crushes together
  anything that has a based point. So $(*, a), (a, *), (*, *)$ are all crushed.
- If we don't remember the "sum" and "product" bit, and only remember "wedge"
  and "smash", then "wedge" starts with a "w" which looks like `\/`so it should
  be a union.

# Quotient topology

I watched this for shits and giggles. I don't know enough topology at all, but it's
fun to watch arbitrary math videos.

#### Quotient topology: Defn, examples
- Intended to formalise identifications.

Given space $X$ and equivalence relation $\sim$ on $X$, the quotient set
$X/\sim$ inherits a topology. Let $q : X \rightarrow X/\sim$ send point to
equivalence class.  Quotient topology is the most **refined** topology
on $X/\sim$ such that $q$ is continuous. That is, it has the most open sets
for which this map is continuous.

- More explicitly, a set $U \subset X/\sim$ (which is a collection of equivalence
  classes) is open iff $q^{-1}(U)$ is open in $X$.
- Even more explicitly, $V \subseteq X/\sim$ is open iff $U_V \equiv \{ x \in U : [x] \in V \}$
  is open in $X$.
- Even more explicitly, we can write $U \equiv \cup_{v \in V} v$, because the elements of 
  $v$ are equivalence classes.

#### Claim: quotient topology is a topology

- The preimage of the empty set is the empty set, and thus is open.
- The preimage of all equivalence classes is the full space, and thus open.
- Preimage of union is union of preimages: $\cup_i q^{-1}(V_i)$ extend $h$ to get a new homotopy $H$: $H_0 = id_X$ and $H_t|A = h_t$.


#### $(X, A)$ have HEP and $A$ is contractible, then $X \simeq X/A$
- Pick $q: X \rightarrow X/A$. We need another map such that their compositions are
  homotopic to the identities of $X$ and $X/A$.
- Define $s: X/A \rightarrow X$ as a section of $q$, given by $s([a]) \equiv a, s([x]) \equiv x$.
  This is a section of $q$ since $q \circ s = id_{X/A}$ (That is, $s$ maps entirely within the fibers of $q$).
- Consider $s_t : H_t \circ s : X/A \rightarrow X$. That is, lift from $X/A$ to $X$ using $s$ and then perform $H_t$ on $X$.
  We claim that The map $(H_1 \circ s)$ is the homotopy inverse of $q$. 
- (1a) $(H_1 \circ s) \circ q : X \rightarrow X$ is equal to $H_1$, as $H_1(s(q(A))) = H_1(s([a])) = H_1(a) = a  = H_1(A)$, and $H_1(s(q(x))) = H_1(s([x])) = H_1(x)$.
- (1b) So we have $(H_1 \circ s) \circ q = H_1 \simeq H_0 = id_X$, as $H_0 = id_X$ is from defn, and $H_1 \simeq H_0$ is from homotopy. So we are done
  in this direction.
- (2a) Consider $q \circ (H_1 \circ s) : X \rightarrow X/A$. We wish to show that this is continuous. Let's show that it lifs to a continous
  map upstairs. So consider $q \circ (H_t \circ s) \circ q : X \rightarrow X/A$. We claim that this is equal to $q \circ H_t$,
  which is continuous as it is a composition of continuous maps.
- This relationship is hopefully intuitive:
  $q \circ (H_t \circ s) \circ q$ asks us to treat all of $A$ as if it were $a$ before applying $H_t$.
  Since $q$ kills whatever $H_t$ does after, and $H_t$ guarantees to keep $A$ within $A$, it's fine if we treat all of $A$ as just $a$.
  $q \circ H_t$ asks us to treat $A$ as $A$ itself, and not $a$. Since $q$ kills stuff anyway, we don't really care.
  The real crux of the argument is that $q \circ stab_A = q \circ stab_A \circ s \circ q$ where $stab_A$ is a map that stabilizes $A$.
- (2b) Consider $(q \circ (H_t \circ s) \circ q)(A) = (q \circ H_t \circ s)([a]) = (q \circ H_t)(a)$  --- Since $H_t(a) = h_t(a) = a' \in A$,
  we crush all data regardless of what happens. This is the same as the value $(q \circ H_t)(A) = [a]$ as $H_t(A) \subseteq A$ and $q(A) = [a]$.
  For the other set, we get $(q \circ (H_t \circ s) \circ q)(x) = q \circ H_t \circ s([x]) = q \circ H_t(x)$ and hence we are done.
- (2c) Now since $q \circ (H_t \circ s))$ is continuous, and that $q \circ (H_0 \circ s) : X/A \rightarrow X/A = id_{X/A}$, we are done
  since we can homotope from $q \circ H_1 \circ s \simeq q \circ H_0 \circ s = id_{X/A}$.


> Slogan: Use HEP to find homotopy $H$. Use $H_1 \circ s$ as inverse
> to quotient.


# CW Complexes and HEP

If $X$ is a CW complex and $A$ is a closed subcomplex, then it has the HEP.
A closed subcomplex is a union of closed cells of $X$ such that $X$ is obtained
by adding more cells to $A$.


##### Lemma

If $e$ is a disk, then there is a continuous map from $e \times [0, 1]$ to
$\partial e \times [0, 1] \cup (e \times \{ 0 \})$.

<img src="./static/cw/hep-project-disk.png"/>

##### Lemma

If $X$ is obtained from $A$ by attaching one $k$-cell, then $(X, A)$ has HEP.


Given a homotopy $h_t: A \times [0, 1] \rightarrow Y$ and a new homotopy 
$F_0: X \rightarrow Y$ such that $F_0|A = h_t$, we want to complete $F$ 
such that $F_t|A = h_t$. 

The only part I don't know where to define $F$ on is the new added $e$ portion.
So I need to construct $H$ on $e \times [0, 1]$. Use the previous map to get to
$e \times [0, 1] \cup (e \times \{0\})$. This is in the domain of $F_0$ or $h_t$,
and thus we are done.

##### CW Complexes have HEP

Induction on lemma. base case is empty set.

##### Connected 1D CW Complex

**Theorem:** any connected 1D CW complex is homotopic to wedge of circles.

- Find a contractible subcomplex $A$ of $X$ that passes through all $0$ cells.
- By HEP, $X \simeq X/A$. $X/A$ has only one zero-cell and other one cells.
  One cells are only attached to zero cells. Hence, is a wedge of circles.
- The idea to find a contractible subcomplex is to put a partial order on the
  set of *all* contractible cell complexes by inclusion.
- Pick a maximal element with respect to this partial order.
- Claim: maximal element must contain all zero cells. Suppose not. Then I 
  can add the new zero cell into the maximal element (why does it remain contractible? Fishy!)


# Stable homotopy theory

We like stable homotopy groups
because of the [Freudenthal suspension theorem](https://en.wikipedia.org/wiki/Freudenthal_suspension_theorem)
which tells us that homotopy groups stabilise after many suspensions. 

The basic idea seems to be something like a tensor-hom adjunction. We have
the loop spaces which are like $S^1 \rightarrow X$ and the suspension which
is like $S^1 \wedge X$. The theory begins by considering the tensor-hom-adjunction
between these objects as fundamental.  So curry stuff around to write things as
`(S^1, A) -> B` and `A -> (S^1 -> B)`, which is `Suspension(A) -> B` and `A -> Loop(B)`.
This gives us the adjunction between suspension and looping.


- We then try to ask: how can one invert the suspension formally? One tries
  to do some sort of formal nonsense, by declaring that maps between $\Sigma^{-n}X$
  and $\Sigma^{-m} Y$ , but this doesn't work due to some sort of grading issue.
- Instead, one repaces a single object $X$ with a family of objects $\{ X_i \}$
  called  as the spectrum. Then, we can invert the suspension by trying to invert
  maps between objects of the same index.

#### References

- [Homotopy Extension](http://www.homepages.ucl.ac.uk/~ucahjde/tg/html/cw-02.html)
- [CW complexes](https://www.youtube.com/watch?v=XWg4LVbmm3M&list=PLN_4R2IuNuuTWD00k9BAB1fo0UldBHnME&index=21)
- [Stable homotopy theory 1](https://www.youtube.com/watch?v=neC3HUyqlV0)


# Simply connected spaces

- A space is simply connected iff fundamental group at all points is trivial.
- We usually don't want to talk about basepoint, so we assume that the space
  is path-connected. This means we can move the basepoint around, or not 
  take about the basepoint.
- So, a path-connected space is simply connected iff the fundamental group is
  trivial.

#### Simply connected => all paths between two points are homotopic.

If $x, y$ are two points, then there is a single unique homotopy class of 
points from $x$ to $y$. Consider two paths from $x$ to $y$ called $\alpha, \beta$.
Since $\beta^{-1} \circ \alpha \in \pi_1(x, x) = 1$, we have that 
$\beta^{-1} \circ \alpha \simeq \epsilon_x$. [ie, path is homotopic to trivial
path]. compose by $\beta$ on the left: This becomes $\alpha \simeq \beta$.

- This is pretty cool to be, because it shows that a simply connected space is forced
  to be path connected. Moreover, we can imagine a simply connected space as one we can
  "continuously crush into a single point".


# Finitely generated as vector space v/s algebra:

- To be finitely generated as a vector space over $K$ from a generating
  set $S$ means that we take elements of the form $\sum_i k_i s_i$, or abbreviated,
  elements of the form $\sum KS$
- To be finitely generated as a $K$ algebra from a generating set $S$, 
  we take elements of the form 
  $\sum_i k_i s_i + \sum_{ij} k_{ij} s_i s_j + \dots$. To abbreviate, elements
  of the form $\sum C + CS + CS^2 + CS^3 \dots = C/(1-S)$.

As a trivial example, consider $K[X]$. This is not finitely generated as a 
vector space since it doesn't have a finite basis: the obvious choice of
generating set $\{ 1, X, X^2, \dots \}$ is not finite. It *is* finitely
generated as a $K$-algebra with generating set $\{ X \}$.

# Weak and Strong Nullstllensatz


#### Weak Nulstellensatz: On the tin

For every maximal ideal $m \subset k[T_1, \dots, T_n]$ there is a unique
$a \in k^n$ such that $ m = I(\{ a \})$. This says that any maximal ideal
is the ideal of some point.

#### Weak Nullstellensatz: implication 1 (Solutions) 
every ideal, since it is contained in a maximal ideal, will have zeroes.
Zeroes will always exist in all ideas upto the maximal ideal.

- It simply says that for all ideals $J$ in $\mathbb C[X_1, \dots, X_n]$, we have $I(V(J)) = sqrt J$
- Corollary: $I$ and $V$ are mutual inverses of inclusions between algebraic sets and radical ideals.


#### Weak Nullstellensatz: Implication 2 (Non-solutions)

If an ideal does not have zeroes, then it must be the full ring. Hence, 1 must
be in this ideal. So if $I = (f_1, f_2, \dots, f_n)$ and the system has
no solutions, then $I$ cannot be included in any maximal ideal, hence $I = \mathbb C[X_1, \dots, X_n]$.
Thus, $1 \in I$, and there exist $c_i \in \mathbb C[X_1, \dots, X_n]$ such that
$1 = sum_i f_i c_i$.


#### Strong Nullstellensatz: On the Tin


For every ideal $J$, we have that $I(V(J)) = |_0^\infty\sqrt J$. I am adopting 
the radical (heh) notation $|_0^\infty \sqrt x$ for the radical, because this matches
my intuition of what the radical is doing: it's taking *all roots*, not just *square roots*.
For example, $\sqrt{(8)} = (2)$ in $\mathbb Z$.


#### Strong Nullstellensatz: Implication 1 (solutions)

Let $J = (f_1, \dots, f_m)$. If $g$ is zero on $V(J)$ , then $g \in \sqrt J$. 
Unwrapping this, $\exist r \in \mathbb N, \exists c_i \in \mathbb C[X_1, \dots,  X_n], \sum_i f_i c_i = g^r$.



#### Weak Nullstellensatz: Proof

- Let $m$ be a maximal ideal. 
- Let $K$ be the quotient ring  $K \equiv \mathbb C[X_1, \dots, X_n] / m$.
- See that $K$ is a field because it is a ring quotiented by a maximal ideal. 
- Consider the map $\alpha: \mathbb C[X_1, \dots, X_n] \rightarrow K$, or $\alpha : \mathbb C [X_1, \dots, X_n] \rightarrow \mathbb C[X_1, \dots, X_n] / m$ by sending
  elements into the quotient.
- We will show that $\alpha$ is an evaluation map, and $K = \mathbb C$. So we will get a function
  that evaluates polynomials at a given point, which will have a single point as a solution.
- Core idea: See that $\alpha(\mathbb C) = \mathbb C \subset K$. Hence $K$ is a field that contains 
  $\mathbb C$. But $\mathbb C$ is algebraically closed, hence $K = C$.
- First see that $\mathbb C \subset K$, or that $\alpha$ preserves $\mathbb C$ [ie, $\alpha(\mathbb C) = \mathbb C$].
  note that no complex number can be in $m$.
  If we had a complex number $z$ in $m$, then we would need to have $1 = 1/z \cdot z$ in $m$ 
  (since an ideal is closed under multiplication by the full ring), which means $1 \in m$, due to which
  we get $m$ is the full ring. This can't be the case because $m$ is a proper maximal ideal.
- Hence, we have $\mathbb C \subseteq K$ or $K = \mathbb C$.
- Thus the map we have is $\alpha: \mathbb C[X_1, X_2, \dots, X_n] \rightarrow \mathbb C$.
- Define $z_i = \alpha(X_i)$. Now we get that $\alpha(\sum_{ij} a_{ij} X_i^j) = \sum_{ij} a_{ij} z_i^j$. That is,
   we have an evaluation map that sends $X_i \mapsto z_i$. 
- CLAIM: The kernel of an evaluation map $\alpha$ is of the form $(X_1 - z_1, \dots, X_n - z_n)$.
- PROOF OF CLAIM:TODO 
- The kernel is also $m$. Hence, $m = (X_1 - z_1, \dots, X_n - z_n)$, and point that corresponds to the
  maximal ideal is $(z_1, z_2, \dots, z_n)$.


#### Strong Nullstellensatz: Proof

We use the [Rabinowitsch trick](https://en.wikipedia.org/wiki/Rabinowitsch_trick).
- Suppose that wherever $f_1, \dots, f_m$ simultaneously vanish, then so does $g$. [that is, $g \in I(V(J))$
  where $J = (f_1, \dots, f_m)$].
- Then the polynomials $f_1, \dots, f_m, 1 - Yg$ have no common zeros where $Y$ is a new 
  variable into the ring. 
- Core idea of why they can't have common zeros: Contradiction. assume that $1 - Yg$, and all the $f_i$
  vanish at some point.
  Then we need $1 - Yg = 0$ which mean $Y = 1/g$, so $g$ cannot vanish, so $g \neq 0$.
  However, since all the $f_i$ vanish, $g$ also vanishes as $g \in (V(J))$. This is contradiction.
- Now by weak Nullstellensatz, the ideal $J = (f_1, \dots, f_m, (1-Y)g)$ cannot be contained
  in a maximal ideal (for then they would simultaneously vanish). Thus, $J = R$ and $1 \in J$.
- This means there are coefficients $c_i(Y, \vec x) \mathbb C[X_1, \dots , X_n, Y]$ such that 

$$
1 = c_0(Y, \vec x) (1 - Yg(\vec x)) \sum_{i=1}^m c_i(Y, \vec x) f_i(\vec x)
$$

Since this holds when $\vec x, Y$ are arbitrary variables, it continues to hold
on substituting $Y = 1/g$, the coefficient $c_0(1-Yg) = c_0(1 - g/g) = c_0(1 - 1) = 0$ disappears. This gives:
$1 = \sum_{i=1}^m c_i (Y, \vec x) f_i(\vec x) $

since $Y = 1/g$, we can write $c_i(Y=1/g, \vec x) = n_i(\vec x)/g^r_i(\vec x)$.  By clearing denominators, we get:

$$
1 = \sum{i=1}^m n_i(\vec x) f_i(\vec x)/ g^R(\vec x) 
$$

This means that $ g^R(\vec x) = \sum_{i=1}^m n_i(\vec x) f_i(\vec x)$

#### Strong Nullstellensatz: algebraic proof

- We have $g \in I(V(J))$.
- We want to show that $g \in \sqrt{J}$ in $R$.
- This is the  same as showing that $g \in \sqrt{0}$ in $R/J$. ($J \mapsto 0$ in the quotient ring).
- If $g$ is nilpotent in $R/J$, then the $(R/J)_g$ becomes the trivial ring $\{ 0 \}$. 
  [Intuitively, if $g$ is nilpotent and a unit, then we will have $g^n = 0$, that is  unit raised to some
   power is 0, from which we can derive $1 = 0$].
- Localising at $g$ is the same as computing $R[Y]/(1 - Yg, J)$.
- But we have that $V(1 - Yg, J) = \emptyset$. Weak Nullstellensatz implies that $(1 - Yg, J) = (1)$.
- This means that $R[Y]/(1 - Yg,J) = R[Y]/(1) = \{ 0 \}$. Thus, $(R/J)_g$ has $g$ as nilpotent, 
  or $g \in \sqrt J$ in $R$.

#### Relationship between strong and weak

Strong lets us establish what functions vanish on a *variety*. Weak let us establish
what functions vanish at a *point*.

#### Strong Nullstellensatz in scheme theory

- Same statement: $I(V(J)) = \sqrt J$.
- $V(J)$ is the set of points on which $J$ vanihes. Evaluation is quotienting. So it's going to be
  set of prime ideals $p$ such that $J \xrightarrow{R/p} 0$. So $J \subset p$. This means that
  $V(J) = \{ p \text{prime ideal in } R, J \subseteq p \}$.
- $I(V(J))$ is the set of functions that vanish over every point in $V(J)$. The functions that vanish
  at $p \in V(J)$ are the elements of $p$. So the functions that vanish over all points is 
  $I(V(J)) = \cap V(J)$.
- Unwrapping, this means that $I(V(J))$ is the intersection of all ideals in $V(J)$, which is the intersection
  of all primes that contains $J$, which is the radical of $J$.

Holy shit, scheme theory really does convert Nullstellensatz-the-proof into
Nullstellensatz-the-definition! I'd never realised this before, but this.. is crazy.

Not only do we get easier proofs, we also get more power! We can reason about generic
points such as $(x)$ or $(y)$ which don't exist in variety-land. This is really really cool.

- [Reference video](https://www.youtube.com/watch?v=GyWiyR0vULE)

# Screen recording for kakoune pull request

I wanted to show what keys I was pressing to demonstate the change I was 
proposing. So I used:
- `SimpleScreenRecorder` to record my screen.
- `screenkey` to show the keystrokes I press.

This was used the create the PR that
[improves the page up/page down to mimic vim behaviour](https://github.com/mawww/kakoune/pull/4074)

# Intuition for why finitely presented abelian groups are isomorphic to product of cyclics

- If we have a finitely presented group, we can write any element as a product
  of the generators.. Say we have two genetors $g, h$ and some relations between
  them, we can have elements $gh$, $ghgh$, $gghh$, $ghg^{-1}$, and so on.
- If the group is abelian, we can rearrange the strings to write them as $g^a h^b$.
  For example, $ghgh = g^2h^2$, and $ghg^{-1} = g^0h^1$ and so on.
- Then, the only information about the element is carried by the powers of $g, h$.
- If $g$ has order $n$ and $h$ has order $m$, then the powers live in $Z/nZ, Z/mZ$.
- Thus, the group above is isomorphic to $Z/nZ \times Z/mZ$ by rearranging and
  collecting powers.
- The same argument works for any finitely generated abelian group.


# Euler characteristic of sphere

Pick two antipodal points and connect them into a great circle. We have two points.
To connect them, we need two edges. The great circle divdies the spere into two
faces. This gives $2-2+2=2$.


# John Conway: The symmetries of things

Original way to classify wallpaper groups: think of geometric transforms
that fix the pattern. Thurston's orbifold solution: think of quotients of $\mathbb R^2$
by groups --- this gives you an *orbifold* (orbit manifold).


Take a chair, surround it around by a sphere.  The symmetries of a physical
object fixes the center of gravity. So we pick the center of the sphere  to
be the center of gravity. The "celestial sphere" (the sphere around the chair)
is a nice manifold (We only have the surface of the sphere). The vertical
line that divides the chair also divides the sphere into two parts.

- The points of the orbifold are orbits of the group.
- So now the orbifold gives us a hemisphere in this case.
- The topology of the orbifold determines the group.
- This is astonishing, because the group is a metrical object: elements of the group
  preserve the inner product of the space.
- And yet, geometrical groups are determined by the *topology* of their orbifolds!
- Thurston's metrization conjecture: certain topological problems reduce to geometrical ones.

Conway came up with his notation for wallpaper groups/orbifolds. There are only
four types of features.

-  The hemisphere orbifold is `*`. (group of order 2). `*` denotes the effect on
   the orbifold. `*` really means: what is left out of a sphere when I cut out a 
   hemispherical hole. `*` is the name for a disk, because a hemisphere is a disk
   topologically. It has metrical information as well, but we're not going to
   speak about it, because all we need is the topological information.
-  One-fourth of a sphere (symmetry group of rectangular table)
   is denoted by `* 2 2`. The `*` for the hemisphere, and `2, 2`
   for the angles of `pi/2`.
-  If the table is a sphere, then we have diagonal symmetry as well. In this case,
   the orbifold has angle `pi/4`. So the table is `* 4 4`.
-  If we take a cube, then we have an even more complicated orbifold. The "fundamental region"
   of the cube has 2, 3, and 4 mirrors going through them. So in the orbifold, we get
   triangles of angles `pi/2, pi/3, pi/4`. This would be `* 4 3 2`.
-  Draw a swastika. This has no reflection
   symmetry. This has a *gyration*: a point about which the figure can be rotated,
   but the point is NOT on a line of reflection. We can tear the paper and make
   it into a cone. This gives us a *cone point*. The angle around the cone point
   is `2pi/4`. This is the orbifold of the original square with a swastika on it.

An orbifol can be made to carry some amount of metrical information. The cone
point only has 90 degrees, so it is in some sense, "a quarter of a point".

-  Draw a cube with swastikas marked on each face. This has no reflection
   symmetry. Once again, we have a gyration, and again, only the gyration/singularities
   matter. This group is again `4, 3, 2` , but in **blue**. In this notation,
   **red** is reflection, **blue** is "true motion" (?).

Let us try to work out the euler characteristic of the rectangular table
orbifold by using $V - E + F$. The orbifold as one face.
The **wrong thing** to say is that the orbifold has two edges and two vertices.
It is untrue because the edge of the orbifold is only half an edge --- let's
say that lines have thickness. In this case, we will have $V = 2/4$, $E = 2/2$,
and $F = 1$.  The euler characteristic works out to be a half. This is appropriate,
because the orbifold is a type of divided manifold.

- If we work this out for a cube, we get $2/48$. This is because the sphere gets
  divided into 48 pieces, and the sphere has an euler characteristic of 2!
- Alternatively, we can think that we started out with 2 dollars, and we are then
  buying the various features of our orbifold. `*` costs `1$`, a blue number
  after a star, for example: `2` costs `1/2` a dollar. `3` costs `2/3` of a dollar,
  `4` costs `3/4` of a dollar. In general, `n` costs `1 - 1/n`.
  The red numbers are children, so they cost half an much: `n` consts `1/2(1 - 1/n) = (n-1)/2n`.


Now, see that we started with positive euler characteristic (2), and we divide
it by some `n` (the order of the group). So we end up with a positive euler characteric.
By a sort of limiting argument, the euler characteristic of the wallpaper groups, 
which are infinite, is zero. However, see that we must get to the zero by starting
with two dollars and buying things off the menu! If we try and figure out what
all the possible ways are to start with 2 dollars and buy things till we are 
left with exactly 0 dollars, we get that there are 17 possible ways of buying
things on the menu! Thus, this the reason for there being 17 wallpaper groups.


- To buy more than two dollars, you are buying symmetries from the hyperbolic
  plane!

Because we can completely enumerate 2-manifolds, we can completely enumerate
2-orbifolds, which are essentially the same thing as symmetry groups. The real
power is in the 3D case. We don't have a full classification of 3-manifolds. But
we maybe able to go the other way. This is the metrization theorem.

- [Video lecture](https://www.youtube.com/watch?v=8z6T-7ovA5Q)

# Semidirect product mnemonic

I just learnt that when we write the semidirect product $N \ltimes K$, the
$\ltimes$ is to look like a combination of $N \triangleleft G$ ($N$ is normal in $G$)
and the $\times$ operator; This tells us that it is the $N$ part that is normal.
in $N \ltimes K$.

- A good example to remember is $\mathbb R^3 \ltimes SO(3)$, where we define
  a group element $(t, r)$ by the action: $(t, r) v = rv + t$ [$t$ for translation and $r$ for rotation].

- Let's compose these. We find that:

$$
\begin{aligned}
&(t2, r2)((t1, r1)(v))  \\
&= (t2, r2)(r1v + t1) \\
&= r2(r1v + t1) + t2\\
&= (r2 r1) v + (r2 t1 + t2) \\
&= (r2 t1 + t2, r2 21) v
\end{aligned}
$$

- Here, we have the rotation $r_2$ act non-trivially on the translation $t_1$.
- We need the translation to be normal, since we are messing with the translation
  by a rotation. 
- We want the translations to be closed under this messing about by the rotation action;
  The action of a rotation on a translation should give us another translation.
  Thus, the translations $(t_1, id)$ ought to be normal in the full group $(t_2, r_2)$.

Another mnemonic for the semidirect product:

> my thesis adviser told me that the acting group (the non-normal subgroup)
> opens its mouth and tries to swallow / "act on" the group it acts upon (the normal subgroup).
> The group that is acted on must be normal, because we act "by conjugation". Alternatively,
> being normal is "tasty", and thus needs to be eaten.


# Non orthogonal projections

Consider the matrix 

$$
P = \begin{bmatrix} 1 & 1 \\ 0 & 0 \end{bmatrix}
$$
- $P^2 = P$, so it's a projection. It projects the vector `[x;y]` to the
  vector `[x+y;0]`. Clearly, applying it twice will result in 0. `[x; y]`,
  1. `[x+y; 0]`, 2. `[x+y; 0]`.
- It projects the value `(x+y)`onto the `x` axis,and kills the `y` axis. 
- It's **not** a projection onto the coordinate axis. 


# Why did maxwell choose his EM wave to be light?

- We Knew gravity as fields
- dalton/thompson atomic model that had particles: protons, neutrons, electron
- Knew electricity and magnetism as fields
- Maxwell wrote down laws, said that the wave solution to his laws was light. (why?)
- Michaelson morly proved speed of light was constant, matched maxwell prediction 
- Einstein found photo electric effect. Posited “light particle” (photon). [why light?]
- De Broglie 
- [who connected photon to EM wave through gauge?]
- Weyl created U(1) symmetry for Maxwell’s equations / photon
- Yang-mills wrote down how photon occurs as particle associated to EM field
- what is the field that electron corresponds to?  Electron field? Why no wiki page? Dirac spinor field! Dirac spinor
- How do we get fermi/bose statistics out of the field equation?  In QM, when
  we perform second quantization, ie, solve for single particle and claim that
  multi particle is the tensoring of single particle, we “choose the
  statistics” arbitrarily.


# Fast string concatenation in python3

Apparently, the correct way to do this, in a way that's not `O(n^2)` is to
use the `io.StringIO` module. The API is:

- `x = io.StringIO()`: create a string buffer
- `x.write(stuff_to_append)`: append into string buffer with correct `realloc()` 
   doubling semantics for `O(1)` amortized per character
- `out = x.getvalue()`: pull data out of `StringIO`.
- `x.close()`: tell the `StringIO` that we are done and it can free its buffer.

It took quite a bit of trawling the API docs to find this while I was
helping a friend speed up some data munging.

# Split infinitive

```
to safely remove %v
```

The infinite "to remove" has been split by "safely".

```
to remove %v safely.
```

# Yoneda from string concatenation

I'm trying to build intuition for Yoneda (again) this time from the perspective
of strings and concatenation. The idea is that the identity function behaves
like the empty string, and "free arrow composition" behaves like string
concatenation. So can we understand yoneda from this model?

- First, let's think of `Hom(X, X)`. What are the elements here? Well, for one,
  we need the identity arrow `idX` in `Hom(X, X)`. Maybe we have other elements
  called `a, b, c` in `Hom(X, X)`. So our picture of `Hom(X, X)` looks like this:


<img src="./static/yoneda/hom-x-x-1.png"/>

- what does it *mean* to have an element `a` in `Hom(X, X)`? It means that there's
  an arrow from `X` to `X` in the category. But this also means that we have
  a map from `Hom(X, X)` *to* `Hom(X, X)`, given by composing with `a`! That is,
  we have a map `- . a :: Hom(X, X) -> Hom(X, X)`. 

<img src="./static/yoneda/hom-x-x-2.png"/>

- If we have such a map of "composition with a", then we need to know where this
  map `-.a` maps all the elements of `Hom(X, X).` Thinking about this,
  we see that we need to add new elements to `Hom(X, X)`, which are the
  composition of the current elements (`idX`, `a`, `b`, `c`) with `a`. This
  gives us the elements
  `idX.a = a, a.a = aa, b.a = ba, c.a = ca`.

<img src="./static/yoneda/hom-x-x-3.png"/>

- Similarly, we need to know where *these* new elements `aa`, `ba`, `ca` map to,
  but let's hold off on that for now, for that simply demands an extrapolation of
  imagination. Let's imagine having another object `Y` and an arrow `g: X -> Y`.
  This will give us a new hom-set `Hom(X, Y) = Hom(X, X) . g`

<img src="./static/yoneda/hom-x-y-1.png"/>

- In `Hom(X, Y)` we will have as elements all the arrows from `X` to `Y`. 
  Let's say there's some arrow `h: X -> Y`. Then, we will find this arrow `h` in `Hom(X, Y)`
  as the image of `idX` under `-.h` . So really, for *any* arrow, we can find
  what element it maps to as long as know (a) `idX` and (b) `-.h`.


 Now that we understand the "internal" structure, let's imagine we're representing
 this collection of objects and arrows by some other collection of objects
 and arrows. So we have a functor `F` that takes these sets to other sets,
 and takes these objects to other objects.

         
# Right Kan extensions as extending the domain of a functor

#### First over functions (fake category fluff)

Given a function $g: C \rightarrow E$ and an embedding $j: C \rightarrow D$,
then the Right Kan extension of $g$ along $j$, denoted $g/j$ is a new function 
$g/j: D \rightarrow E$.
So we are extending the *domain* of $g$, along the extender $j$. Informally,
we write the new function as $g/j$ because:

```
C---
|   \-g---*
j         |
|         |
v         v
D--g/j--->E
```
```
foo(j(c)) = g(c)
foo = (g/j)(c) 
g/j(j(c)) = g(c)
```

#### Next over preorders (real category stuff)

The kan extension provides us a bijection, for
any function `f: D -> E`

```
C---
|   \-g---*
j         |
|         |
v         v
D--g/j--->E
D------f->E

hom(f.j, g) ~= hom(f, g/j)
```

That is, if we have some way to make congruent `f.j` with `g`, then we can
"split" the congruence to have `f.j` congruent with `(g/j).j`. Cancelling `j`,
we can have `f` congruent with `g/j`.

Consider a preorder with a ordering `≤`. Equip with a monoidal structure `<>`,
which is  a monotone map with a neutral element. (For example, integers with
multiplication and `≤`).

The bijection of hom-sets is equivalent to saying

```
m*k <= n iff m <= n/k
```

(how? I have no idea; I gotta work this out!)


#### Question: What happens in the context of vector spaces?

Since linear algebra is probably the nicest thing we have in math, I really
want to understand what happens in the linear algebra case. I don't really
understand how to make the correct version of a kan extension inside $Vect$,
though. A kan extension seems to fundamentally be a 2 categorical construct,
than a 1 categorical construct.


- [Art and dan explain an old trick](https://www.cs.ox.ac.uk/ralf.hinze/Kan.pdf)

# Non standard inner products and unitarity of representations


I stumbled across [this questions about non-standard inner products](https://math.stackexchange.com/questions/4021023/visualization-of-length-and-orthogonality-under-non-standard-inner-product). Can I use this to visualize the weyl 
averaging trick in represention theory?

# take at most 4 letters from 15 letters.

Trivial: use $\binom{15}{0} + \binom{15}{1} + \binom{15}{3} + \binom{15}{4}$.
Combinatorially, we know that $\binom{n}{r} + \binom{n}{r-1} = \binom{n+1}{r}$.
We can apply the same here, to get $\binom{15}{0} + \binom{15}{1} = \binom{16}{1}$.
But what does this *mean*, combinatorially? We are adding a dummy letter, say $d_1$,
which if chosen is ignored. This lets us model taking at most 4 letters by adding
4 dummy letters $d_1, d_2, d_3, d_4$ and then ignoring these if we pick them up; we
pick 4 letters from 15 + 4 dummy = 19 letters.


I find it nice how I used to never look for the combinatorial meaning behind
massaging the algebra, but I do now.            

# Flat functions

Define 

$$
f(x) \equiv
\begin{cases}
0 & x <= 0 \\
e^{-1/x} & x > 0
\end{cases}
$$

This is smooth, but is badly non-analytic. Any taylor expansion around $x=0$
is going to be identically zero. So we're going to prove that it possesses
all derivatives. This implies that the derivative at zero is equal to zero,
because the left derivative is always equal to zero.

- $f(x) \equiv e^{-1/x}$. Differentiate to get $f'(x) = e^{-1/x}/x^2$. Change
  $y \equiv 1/x$ to get $y^2 e^{-y}$. As $y \mapsto \infty$, $e^{-y}$
  decays more rapidly than $y^2$ increases, thus the limit is zero.
  Hence, $f'(x) = 0$.
- For higher derivatives, let $f^{(n)}(x) \equiv p_n(1/x) e^{-1/x}$ for some polynomial $p_n$.
  See that $f^{(n+1)}(x) = d/dx [p_n(1/x) e^{-1/x})]$. To compute this, set $y \equiv 1/x$
  and compute $d/dy [p_n(y) e^{-y}] dy/dx$ which is:

$$
\begin{aligned}
& = d/dy [p_n(y) e^{-y}] dy/dx \\
& = p_n'(y) e^{-y} + p_n(y) (- e^{-y}) \cdot 1/x^2 \\
& = e^{-1/x} (p_n'(1/x) - p_n(1/x)) 1/x^2 \\
& = e^{-1/x} (q_n'(1/x) - q_n(1/x)) \\
& \text{let $r_{n+1}(x) (\equiv q_n'(t) - q_n(t))t^2$} \\
& = r_{n+1}(1/x) e^{-1/x}
\end{aligned}
$$

- So we can write higher derivatives too as $poly(1/x)$ times $exp(-1/x)$ which also decays 
  rapidly to $0$.

- Philosophically, what's going on is that a non-zero polynomial can only have a finite number of zeroes.
  Since this function has an infinite number of zeroes around it's neighbourhood at $(x = 0)$,
  any polynomial that agrees with this function in any neighbourhood must be identically zero everywhere.

- [Flat functions on wikipedia](https://en.wikipedia.org/wiki/Flat_function)

# Hopf Algebras and combinatorics

> Started from algebraic topology in the 40s. In late 70s, Rota 
> figured out that many combinatorial objects have the structure of a Hopf
> algebra.

A hopf algebra is a vector space $H$ over a field $K$. together with $K$ linear
maps $m: A \rightarrow A \otimes A$ (multiplication),
$U: A \rightarrow K$ (unit), $\Delta: H \rightarrow H \otimes H$ (comultiplication)
$S: A \rightarrow A$ (co-inverse/antipode). Best explained by examples!


- [Hopf algebra and combinatorics](https://www.youtube.com/watch?v=FzVhjCRuXus&list=PL-XzhVrXIVeRLeezwY9h4M68k6yB3yOo-)
- [Hopf algebras and rooted trees](http://www.math.ubc.ca/~thomas/TeXthings/HopfAlgebras-1.1.pdf)


- [Hopf algebra 1](https://www.youtube.com/watch?v=fqirLhXLoXM)

> The idea is that groups act by symmetries. Hopf algebras also act,
> we can think of as providing quantum symmetries.


#### Eg 1: Group algebra: $A = kG$

$G$ is a group, $kG$ is a group algebra. $\delta(g) \equiv g \otimes g$, 
$\epsilon(g) = 1$, $s(g) = g^{-1}$.




# Butcher group

I really want to read the math about the [butcher group](https://en.wikipedia.org/wiki/Butcher_group),
which was introduced to study numerical solutions of ODEs using RK, and
then had far-reaching theoretical applications. Connes remarked:

> We regard Butcher’s work on the classification of numerical integration
> methods as an impressive example that concrete problem-oriented work can lead
> to far-reaching conceptual results.



# Neovim frontends

- [veonim](https://glitchtron.org/veonim/): Rendered an utterly glitched UI.
- [uivonum](https://github.com/smolck/uivonim): NPM based, so wasn't my thing.
- [neovide](https://github.com/Kethku/neovide): rust based, feels very fluid,
  has cool cursor animations that make it "fun" to type with!
- [goneovim](https://github.com/akiyosi/goneovim)

# A semidirect product worked on in great detail

We work out the semidirect product structure of the collection of real 2x2 matrices

$$
\begin{bmatrix}
1 & a \\ 0 & b
\end{bmatrix}
$$

We first see that the multiplication rule is:


$$
\begin{bmatrix}
1 & a \\ 
0 & b
\end{bmatrix}
\begin{bmatrix}
1 & p \\ 
0 & q
\end{bmatrix}
= 
\begin{bmatrix}
1 &  p + bq \\
0 & bq
\end{bmatrix}
$$

so  these are closed under matrix multiplication. The identity matrix
is one among these matrices and thus we have the identity. The inverse
of such a matrix  can also be seen to be of such a kind.

##### Diagonal transforms



We have two subgroups of matrices in this set of 2x2 matrices.
The first of these I shall call _diagonal_ and denote with $D$:

$$
\begin{bmatrix}
1 & 0 \\ 
0 & b
\end{bmatrix}
\begin{bmatrix}
1 & 0 \\ 
0 & q
\end{bmatrix}
= 
\begin{bmatrix}
1 & 0 \\ 
0 & bq
\end{bmatrix}
$$

<img src="./static/semidirect-product/diagonal.png"/>

Hopefully clearly, this is isomorphic
to $\mathbb R^*$ since the only degree of freedom is the bottom right entry,
which gets multiplied during matrix multiplication. These transform
a vector $(x, y)$ into the vector $(x, \delta y)$.
Informally, the $D$ matrices are responsible for scaling the $y$-axis.

<img src="./static/semidirect-product/diagonal-composition.png"/>

##### Shear transforms

Next, we have the other subgroup of matrices, which I shall call _shear_ 
and denote by $S$:

$$
\begin{bmatrix}
1 & a \\ 
0 & 1
\end{bmatrix}
\begin{bmatrix}
1 & p \\ 
0 & 1
\end{bmatrix}
= 
\begin{bmatrix}
1 & (a+p) \\ 
0 & 1
\end{bmatrix}
$$


<img src="./static/semidirect-product/shear.png"/>

These are isomorphic to $\mathbb R^+$, since the only degree of freedom is
their top-right entry, which gets added on matrix multiplication. These
matrices transform a vector $(x, y)$ into $(x + \delta y, y)$. 

<img src="./static/semidirect-product/shear-composition.png"/>


#### Generating all transforms with diagonal and shear transforms

we can write any transform of the form

$$
T \equiv
\begin{bmatrix}
1 & a \\ 
0 & b
\end{bmatrix}
$$


#### Semidirect product: Conjugations

We need to check whether the subgroup $D$ or the subgroup $S$ is normal.
For this, take two arbitrary elements:

$$
[d] \equiv 
\begin{bmatrix}
1 & 0 \\ 
0 & d
\end{bmatrix}; ~~~
[s] \equiv 
\begin{bmatrix}
1 & s \\ 
0 & 1
\end{bmatrix}
$$


##### Conjugating $D$ by $S$:

Let's to conjugate a diagonal with a shear:

$$
\begin{aligned}
&[s^{-1}][d][s](x, y) \\
&= [s^{-1}][d] (x+sy, y) \\
&= [s^{-1}](x+sy, dy) \\
&= (x+sy-sdy, dy) \\
\end{aligned}
$$

This doesn't leave us with another diagonal transform. 

<img src="./static/semidirect-product/sinv-d-s.png" />

#####  Conjugating $S$ with $D$

Now let's compute the action of $dsd^{-1}$, and $sds^{-1}$ on some general $(x, y)$:

$$
\begin{aligned}
&[d^{-1}][s][d](x, y) \\
&= [d^{-1}][s] (x, dy) \\
&= [d^{-1}](x + dy, dy) \\
&= [d^{-1}](x + dy, dy \times 1/d \\
&= (x + dy, y)
\end{aligned}
$$

See that the final result we end up with is a shear transform which
shears by $y/d$. So, we can write the equation $DSD^{-1} = S$: conjugating
a shear by scaling leaves us with a shear.

<img src="./static/semidirect-product/dinv-s-d.png" />

##### The connnection to partial  fractions

Recall that any matrix of the form `[a b; c d]` can be viewed as taking
the fraction `x/y` to `(ax+by)/(cx+dy)`. In our case, we have:


- Diagonal: `[1 0; 0 b]` which take `x/y` to `x/by`.
- Shear: `[1 a 0 1]` which take `x/y` to `(x + ay)/y`.

It's clear that diagonals and shears compose. What is unclear is how they
interact. A little thought shows us:

```
x/y -diagonal->
x/dy -shear->
(x+sdy)/dy
(x+sy')/y'
```

```
x/y -shear->
(x+sy)/y -diagonal->
(x+sy)/dy
= (x+(s/d)y')/y'
```

So, when we compse shears with diagonals, we are left with "twisted shears".
The "main objects" are the shears (which are normal), and the "twists" are
provided by the diagonal.

The intuition for why the twisted obect (shears) should be normal
is that the twisting (by conjugation) should continue to give us twisted
objects (shears). The "only way" this can resonably happen is if the twisted
subgroup is normal: ie, invariant under all twistings/conjugations.


##### How the semidirect product forms

From the above computations, we can see that it is the shear transform $S$ that
are normal in the collection of matrices we started out with, since
$D^{-1}SD = S$. Intuitively, this tells us that it is the diagonal
part of the transform composes normally, and the shear part of the transform is
"twisted" by the diagonal/scaling part. This is why composing a shear
with a diagonal (in either order --- shear followed by diagonal or vice versa)
leaves us with a twisted shear. This should give a visceral sense of "direct
product with a twist".

##### Where to go from here

In some sense, one can view 
[all semidirect products as notationally the same as this example](http://bollu.github.io/the-cutest-way-to-write-semidirect-products.html)
so this example provides good intuition for the general case.

# Direct and Inverse limits

#### Direct limit: definition

A direct limit consists of _injections_ $A_1 \rightarrow A_2 \rightarrow \dots$.
It leads to a limit object $L$, which as a set is equal to the union of all
the $A_i$. It is equipped with an equivalence relation. We can push data "towards"
the limit object, hence it's a "direct" limit.

So each element in $A_i$ has an equivalence class representative in $L$.


#### Direct limit: prototypical example


###### $S_n$

We can inject the symmetric groups $S_1 \rightarrow S_2 \rightarrow \dots$.
However, we cannot project back some permutation of $S_2$ (say) to $S_1$:
if I have $(2, 1)$ (swap 2 and 1), then I can't project this back into $S_1$.

This is prototypical; in general, we will only have injections into the limit,
not projections out of the limit.


##### Prufer group

Here, the idea is to build a group consisting of all the $p^n$th roots
of unity. We can directly """define""" the group as:

$$
P(q)^\infty \equiv \{ \texttt{exp}(2\pi k /q^n) : \forall n, k \in \mathbb N, ~ 0 \leq k \leq q^n \}
$$

That is, we take $q^1$th roots of unity, $q^2$th roots of unity, and so
on for all $n \in \mathbb N$.

To build this as a direct limit, we embed the group $Z/q^n Z$ in $Z/q^{n+1}Z$ by sending:
the $q^n$ th roots of unity to $q^{n+1}$th roots of unity raised to the power $q$.
An example works well here.

- To embed $Z/9Z$ in $Z/27Z$, we send:
- $2 \pi 1 /9$ to $2 \pi 1/9 \times (3/3) = 2 \pi 3 / 27$.
- $2 \pi 2 /9$ to $2 \pi 6/27$
- $2 \pi 3 /9$ to $2 \pi 9 / 27$
- $2 \pi k / 9$ to $2 \pi (3k)/27$
- This gives us a full embedding.


The direct limit of this gives us the prufer group. We can see that the prufer group
is "different" from its components, since for one it has cardinality $\mathbb N$.
For another, all subgroups of the prufer group are themselves infinite. The idea
is to see that:
- Every subgroup of the prufer group is finite.
- By Lagrange, `|prufer|/|subgroup| = |quotient|`. But this gives us something like 
  `infinite/finite = infinite`.

To see that every subgroup $H$ of the prufer group is finite, pick an element $o$ outside of
the subgroup $H$. This element $o$ will belong to some $Z/q^kZ$ for some $k \in \mathbb Z$
(since the direct limit has an elements the union of all the original elements modulo
some equivalence). If the subgroup $H$ does not have $o$ (and thus does not contain $Z/q^kZ$),
then we claim that it cannot contain any of the larger $Z/q^{k+\delta}Z$. If it did
contain the larger $Z/q^{k + \delta}$, then it would also contain $Z/q^k$ since we inject
$Z/q^k$ into $Z/q^{k+\delta}$ when building the prufer group. Thus, at MAXIMUM,
the subgroup $H$ can be $Z/q^{k-1}Z$, or smaller, which is finite in size.  Pictorially:

```
...         < NOT in H
Z/q^{k+1}Z  < NOT IN H
Z/q^kZ      < NOT IN H
---------
...         < MAYBE IN H, FINITE
Z/q^2Z      < MAYBE IN H, FINITE
Z/qZ        < MAYBE IN H, FINITE
```

The finite union of finite pieces is finite. This $H$ is finite.

##### Stalks

Given a topological space $(X, T)$ and functions to the reals
on open sets $F \equiv \{ U \rightarrow \R \}$, we define the restricted
function spaces $F|_U \equiv \{ F_U : U \rightarrow \mathbb R : f \in F \}$.


Given two open sets $U \subseteq W$, we can restrict functions on $W$
(a larger set) to functions on $U$ (a smaller set). So we get maps
$F|_W \rightarrow F|_U$.

So given a function on a larger set $W$, we can inject into a smaller set $U$.
But given a function on a smaller set, it's impossible to uniquely extend
the function back into a larger set. These maps really are "one way".

The reason it's a union of all functions is because we want to "identify"
equivalent functions. We don't want to "take the product" of all germs of
functions; We want to "take the union under equivalence".

###### Finite strings / `A*`

Given an alphabet set $A$, we can construct a finite limit of strings of length
$0$, strings of length $1$, and so on for strings of any given length
$n \in \mathbb N$.  Here, the "problem" is that we can also find projection maps that
allow us to "chop off" a given string, which makes this example not-so-great.
However, this example is useful as it lets us **contrast** the finite and infinite
string case. Here, we see that in the final limit $A*$, we will have all
strings of _finite_ length.  (In the infinite strings case, which is an 
inverse limit, we will have all strings of _infinite_ length)

##### Vector Spaces over $\mathbb R$

consider a sequence of vector spaces of dimension $n$: $V_1 \rightarrow V_2 \dots V_n$.
Here, we can also find projection maps that allows us to go down from $V_n$
to $V_{n-1}$, and thus this has much the same flavour as that of finite strings.
In the limiting object $V_\infty$, we get vectors that have a finite number of
nonzero components. This is because any vector in $V_{\infty}$ must have come
from some $V_N$ for some $N$. Here, it can have at most $N$ nonzero components.
Further, on emedding, it's going to set all the other components to zero.

###### Categorically

Categorically speaking, this is like some sort of union / sum (coproduct).
This, cateogrically speaking, a **direct limit** is a **colimit**.

#### Inverse limit: definition

An inverse limit consists of _projections_ $A_1 \leftarrow A_2 \leftarrow \dots$.
It leads to a limit object $L$, which as a set is equal to a subset of the
product of all the $A_i$, where we only allow elements that "agree downwards"
.Formally, we write this as:

$$
L \equiv \{ a[:] \in \prod_i A_i : \texttt{proj}(\alpha \leftarrow \omega)(a[\omega]) = a[\alpha] ~ \forall \alpha \leq \omega \}
$$

So from each element in $L$, we get the projection maps that give us the component $a[\alpha]$.


> These 'feel like' cauchy sequences, where we are refining information at each
> step to get to the final object.

#### Inverse limit: prototypical example

##### infinite strings

We can consider the set of infinite strings. Given an infinite string,
we can always find a finite prefix as a projection. However, it is impossible
to *canonically* inject a finite prefix of a string into an infinite string!
Given the finite string `xxx`, how do we make it into an infinite string?
do we choose `xxxa*`, `xxxb*`, `xxxc*`, and so on? There's no canonical choice!
Hence, we only have *projections*, but no *injections*.

##### P-adics

Consider the 7-adics written as infinite strings of digits in $\{0, 1, \dots, 6\}$.
Formally, we start by:

1. Having solutions to some equation in $\mathbb{Z}/7\mathbb{Z}$
2. Finding a solution in $\mathbb{Z}/49\mathbb{Z}$ that restricts to the same solution in
   $\mathbb{Z}/7\mathbb{Z}$
3. Keep going.


The point is that we define the $7$-adics by projecting back solutions
from $\mathbb{Z}/49\mathbb{Z}$. It's impossible to correctly _embed_
$\mathbb{Z}/7\mathbb{Z}$ into $\mathbb{Z}/49\mathbb{Z}$: The naive map
that sends the "digit i" to the "digit i" fails, because:

- in $\mathbb{Z}/7\mathbb{Z}$ we have that $2 \times 4 \equiv 1$.
- in $\mathbb{Z}/49\mathbb{Z}$ $2 \times 4 \equiv 8$. 

So $\phi(2) \times \phi(7) \neq \phi(2 \times 7) = \phi(4)$. Hece, we
**don't have injections**, we **only have projections**.

##### Partitions

Let $S$ be some infinite set. Let $\{ \Pi_n \}$ be a sequence of partitions
such that $\Pi_{n+1}$ is finer than $\Pi_n$. That is, every element of $\Pi_n$
is the union of some elements of $\Pi_{n+1}$. Now, given a finer partition,
we can clearly "coarsen" it as desired, by mapping a cell in the "finer space"
to the cell containing it in the "coarser space". The reverse has no canonical
way of being performed; Once again, we only **have projections**, we have
**no injections**.


The inverse limit is:

$$
\{ (P_0, P_1, P_2, \dots) \in \prod_{i=0}^n \Pi_n : P_a = \texttt{proj}_{a \leftarrow z}(P_z) \forall a \leq z  \}.
$$

But we only care about "adjacent consistency", since that generates the other
consistency conditions; So we are left with:

  
$$
\{ (P_0, P_1, P_2, \dots) \in \prod_{i=0}^n \Pi_n : P_a = \texttt{proj}_{a \leftarrow b}(P_b) \forall a +1 = b  \}.
$$

But unravelling the definition of $\texttt{proj}$, we get:

$$
\{ (P_0, P_1, P_2, \dots) \in \prod_{i=0}^n \Pi_n : P_a \supseteq P_b) \forall a +1 = b  \}.
$$

So the inverse limit is the "path" in the "tree of partitions".

##### Vector Spaces

I can project back from the vector space $V_n$ to the vector space
$V_{n-1}$. This is consistent, and I can keep doing this for all $n$. The thing
that's interesting (and I believe this is true), is that the final object we get,
$V^\omega$, can contain vectors that have an infinite number of non-zero components!
This is because we can build the vectors:

$$
\begin{aligned}
&(1) \in V_1 \\
&(1, 1) \in V_2 \\
&(1, 1, 1) \in V_3 \\
&(1, 1, 1, 1) \in V_4 \\
&\dots
\end{aligned}
$$

Is there something here, about how when we build $V_\infty$, we build it as a
direct limit. Then when we dualize it, all the arrows "flip", giving us $V^\omega$?
This is why the dual space can be larger than the original space for infinite
dimensional vector spaces?



###### Categorically

Categorically speaking, this is like some sort of product along with equating
elements.  This, cateogrically speaking, a **inverse limit** is a **limit**
(recall that categorical limits exist iff products and equalizers exist).

### Poetically, in terms of book-writing.

- The direct limit is like writing a book one chapter after another. Once we
  finish a chapter, we can't go back, the full book will contain the chapter,
  and what we write next must jive with the first chapter. But we only control
  the *first chapter* (existential).

- The inverse limit is like writing a book from a very rough outline to a more
  detailed outline. The first outline will be very vague, but it controls the
  *entire narrative* (universal). But this can be refined by the later drafts
  we perform, and can thus be "refined" / "cauchy sequence'd" into something
  finer.

### Differences

- The direct limit consists of taking unions, and we can assert that any element in $D_i$
  belongs in $\cup_i D_i$. So this lets us assert that $d_i \in D_i$ means that $d_i \in L$,
  or $\exists d_i \in L$, which gives us some sort of existential quantification.
- The inverses limit consists of taking $\prod_i D_i$. So given some element $d_i \in D_i$,
  we can say that elements in $L$ will be of the form $\{d_1\} \times D_2 \times D_3 \dots$.
  This lets us say $\forall d_1 \in D_1, \{d_1\} \times D_2 \dots \in L$. This is
  some sort of universal quantification.


<!-- - [Grab me a coffee](https://ko-fi.com/bollu) -->
# LEAN 4 overfrom from LEAN together 2021
- add `unsafe` keyword.
- allow people to provide unsafe version of any opaque function if the 
  type is inhabited. Type inhabited => proofs are fine. (Do we need to assume UIP for this to work?)
- mimalloc, custom allocator.
- counting immutable beans for optimising refcounting. (related work: Perceus: Grabage free refcounting with reuse.)
- hash tables and arrays are back (thanks to linearity?)
- Tabled typeclass resolution for allowing diamonds in typeclass resolution
  (typeclasses no longer need to form a semilattice for resolution).
- Discrminiation trees.
- LEAN4 elaborator for adding custom syntax related to monads, tactics.
- Beyond notation: hygenic macro expansion for theorem proving languages.
- Kernel can have external type checker.

> during wartime, you do not study the mating ritual of butterflies

- Collaboration: Optimising tensor computations.
- Collaboration: Rust integration.
- Collaboration: DSLs for LEAN.
- Collaboration: SAT/SMT integration

#### Metaprogramming in LEAN4

- macro expansion, elaboration. First expand all macros, elaborate, repeat.

#### Verified decompilation

- We want assured decompilation.
- Check equivalence of BBs using solvers; compcert approach is too complex.

- [Lean together 2021](https://www.youtube.com/watch?v=UeGvhfW1v9M&list=PLlF-CfQhukNnO8z3TcFcoKozif9gbl7Yt&index=5)

# BLM master thesis

- [link here](https://tspace.library.utoronto.ca/bitstream/1807/101595/3/Khogali_Yusra_201806_MA_thesis.pdf)

# Hololive subculture

- hololive artists
- 

# RSK correspondence for permutations

##### Tableaux

Tableaux of size $n$ first needs a partition of size $n$ in decreasing
order. Write it as $\lambda$, such that $\lambda[i] \geq 0$ and $\sum_i \lambda[i] = n$
and $\lambda[i]$ is weakly decreasing: $\lambda[1] \geq lambda[2] \geq lambda[n]$.
For example, a partition of $9$ is $4, 2, 2, 1$. This is drawn as:

```
* * * *
* *
* *
*
```

Next, we fill the tableau with numbers from $[n] \equiv \{1,\dots,n\}$ such
that the rows are weakly increasing and columns are strictly increasing
(gravity acts downwards, and we always want to get bigger). These
are called **Standard tableay** For example,
a valid Standard tableau corresponding to the partition above is:

```
1 3 4 6
2 5 
7 9
8
```

(Sidenote: here both rows and columns are strictly increasing because we have
unique numbers. If we did not, then by convention, the rows will be weakly
increasing and columns strictly increasing. I always repeat the chant
"rows weakly, columns strictly" to burn it into my brain).

##### Insertion

Say we start with some tableau $T$. Can we add an element $x$ into it such that
$T' = ins(T, x)$ is a valid tableau? Yes, and this process is called insertion.

##### Deletion


This is the reverse of insertion. Say we start with a tableau $T$. Can we delete
a location $(i, j)$, such that we get a smaller tableau $T'$, and an element $x$
such that $ins(T', x) = T$? Yes we can, and this process is called deletion.

##### Misoncentions about deletion

Deletion does not mean that we lose the _value_ at $(i, j)$. Rather, we 
_change the shape_ of the tableau to lose the _cell_ $(i, j)$. consider
the tableau:

```
1
2
3
```

If we ask to delete the cell $(r=1,c=3)$ (that is, the cell containing $3$),
we will be left with the tableau:

```
2
3
```

and the element $1$. So, when we insert $1$ into $[2; 3]$ we get $[1; 2; 3]$.

We **did not get**

```
1
2
```

and the element $3$. This is because if we insert $3$ into $[1;2]$, then we
get the tableau $[1,3;2]$:

```
1 3
2
```

##### Bijection between permutations and pairs of standard tableau

Given a permutation $p: [n] \rightarrow [n]$, we define two tableau
corresponding to it: the insertion tableau $P$ and the recording tableau $Q$.
Informally, the insertion tableau is obtained by inserting $p[1], p[2], \dots, p[n]$
in sequence into an empty tableau. The recording tableau at step $i$ records
where the number $i$ was stored in the tableau. So the recording tableau
at step $i$, $Q_i$ has the same shape as the insertion tableau at step $i$,
$P_i$, and contains the value $i$ at the cell where $i$ was stored in $P$.
That is, $P_i[Q_i[i]] = i$.

##### Properties of the insertion and recording tableau

We consider the set of points $(i, p(i))$. This is called as the
[Viennot's geometric construction](https://en.wikipedia.org/wiki/Viennot%27s_geometric_construction),
where we reason about the graph. We will reason about the graph here, but couch
the formal arguments in terms of partial orders to be precise.

At each point $(i, p(i))$, imagine a rectangle with $(i, p(i))$ as the lower left
corner. Next, shine a flashlight from the point $(0, 0)$ towards the upper right
quadrant; the boundary that is cast by the rectangles are called as the
shadow lines. 

Formally, we consider a dominance relationship where $(x, y) \lhd (p, q) \equiv x \leq p \land y \leq q$.
Then, we get the "points on the shadow lines" by considering the Hasse diagram 
of the points $(i, p(i))$ under the relationship $\lhd$. Each level of
the hasse diagram becomes one of the shadow lines.  The collection of all of
these shadow lines is called as the _first order shadow lines_.

Next, for each anti-chain, pick the element with the smallest $x$-coordinate.
These points _will form a chain_. This chain will be first row of
the permutation tableau $P$. 

Funnily enough, it is also one of the longest increasing subsequences of the
sequence $i \mapsto p(i)$ because the length of the longest chain (the longest increasing
subsequence) is equal to the number of antichains (the number of shadow lines)

##### Duality theory of $\lhd$

<!-- lhd = left hand delta -->

Note that $\lhd$ as a relation is symmetric in $x$ and $y$. Thus, any order
theoretic result we prove for $x$ will hold for $y$. But note that $(i, p(i))$
is the permutation $p$, while $(p(i), i)$ is the inverse permutation $(p^{-1})$.
Thus, we should expect a "duality" between the order theoretic properties of
$P$ and $p^{-1}$.





# Djikstra's using a segtree

> keep min segtree of distances. Now just have to run n-1 interations.
> You like segtrees right :P


# Markov and chebyshev from a measure theoretic lens

I've been idly watching [Probability and Stochastics for finance: NPTEL](https://www.youtube.com/watch?v=qTg0mqxuGeA&list=PLEYrMI37wMbplhGJmqhlYv0VUSwC6zMsU&index=8), and I came across this nice way to
think about the markov and chebyshev inequality. I wonder whether Chernoff
bounds also fall to this viewpoint.

#### Markov's inequality

In markov's inequality, we want to bound $P(X \geq A)$. Since we're in measure land,
we have no way to directly access $P(\cdot)$. The best we can do is to integreate
the constant function $1$, since the probability is "hidden inside" the measure.
This makes us compute:

$$
P(X \geq A) \equiv = \int_{\{X \geq A\}} 1 d \mu
$$

Hm, how to proceed? We can only attempt to replace the $1$ with the $X$ to get
some non-trivial bound on $X$. But we know that $X \geq A$. so we should perhaps
first introduce the $A$:


$$
P(X \geq A) \equiv = \int_{\{X \geq A\}} 1 d \mu = 1/A \int_{\{X \geq A\}} A d \mu
$$

Now we are naturally led to see that this is always less than $X$:

$$
\begin{aligned}
&P(X \geq A) \equiv = \int_{\{X \geq A\}} 1 d \mu = \\
& 1/A \int{\{X \geq A\}} A d \mu < 1/A \int_{\{X \geq A\}} X d \mu = 1/A \mathbb{E}[X]
\end{aligned}
$$

This completes marov's inequality:

$$
P(X \geq A) \leq \mathbb{E}[X]/A
$$

So we are "smearing" the indicator $1$ over the domain $\{X \geq A\}$ and attempting
to get a bound.



# Among any 51 integers, that are 2 with squares having equal value modulo 100
# $1^n + 2^n + \dots + (n-1)^n$ is divisible by $n$ for odd $n$
# $10^{3n+1}$ cannot be written as sum of two cubes

https://hackage.haskell.org/package/contravariant-1.5.3/docs/Data-Functor-Contravariant-Divisible.html



# Coq-club: the meaning of a specification

> When I was doing my PhD, I faced questions similar to yours. It emerged from my
> encounter of HOL4 for completing a project after having used Coq for another.
> 
> Given your question is on the meaning of a word, I would like to refer to a
> philosophical doctrine on how words acquire their meaning in a system of signs.
> Using that doctrine, I put forward  how I came to an answer for myself!
> 
> So turns out that a text can be perceived as a construct made around elemental
> "oppositions". Accordingly, textual constructs only produce meaning through
> their interplay of DIFFERENCES (mostly emergingin in form of binary contrasts)
> inside a system of distinct signs. This doctrine was first introduced by
> Ferdinand Saussure on which J. Derrida drew for introducing his notion of
> difference.
> 
> Considering the above explanation, instead of hard wiring the words
> "specification" and "implementation" to predetermined functionality or
> referents, we can perceive them in a contrasting interplay whose connection is
> established via the proof game. The "specification" is something used by a
> "proof" to demonstrate "the correctness " of an "implementation ". 
> 
> Now going for the Saussurian doctrine, there is no problem for an _expression_
> to be specification for an implementation,  but itself being an implementation
> for something else. Therefore, I would definitely hesitate to say it is
> meaningless (or even misguiding) to use the word specification in the context
> of formal verification. 
> 
> Hopefully that was useful!


- [Link to coq-club discussion](https://sympa.inria.fr/sympa/arc/coq-club/2021-01/msg00103.html)

# SQLite opening

```
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
```


# Old school fonts

I've been rolling with the  `Px437 ToshibaSat 8x14` font as my daily driver purely for nostalgia reasons; It is to be honest quite a good font! Otherwise, I use `Iosevka Fixed Expanded`, or the "agda font", `mononoki`.

- [I love the old school fonts website](https://int10h.org/oldschool-pc-fonts/fontlist/?2#toshiba)

# Stalking `syzigies` on hackernews

He's the author of Macaulay; I learnt quite a bit by [stalking him on hackernews](https://news.ycombinator.com/threads?id=Syzygies)

- Schreier–Sims algorithm for computing with permutations.

- Our phones should learn a private language with us. My dog learns after one
  repetition; Zoom should learn to arrange my windows as I like, at least after
  47 repetitions.

- [The bayer filter](https://en.wikipedia.org/wiki/Bayer_filter)

- Our extrapolations always take the form of moving along a tangent vector out
  from prior experience. Prior to relativity, Newtonian physics was the belief
  that we actually lived in that tangent space. Surprises come when the
  deviations are large enough for reality to curve away from our models

- Like flipping through for the soft porn in a friend's "romance" novel, I must
  confess I searched straight for this guideline.

 - Lisp's signature 17 car pileup at the end of every expression.

- I look for the `$` or equivalent in any proposal out there, to see if the
  author has written lots of code or is just talking. It's like looking for
  bone marrow in beef stew, evaluating a cookbook. Marrow is central to the
  story of Lisp; we got our start being able to wield tools to crack open bones
  after lions and jackals had left a kill. The added nutrition allowed our
  brains to increase in size. Soon we mastered fire, then Lisp.

-  I spent the first few months outside doing woodworking; I've been struggling
   with an overwhelming urge to center my consciousness in my hands. This is of
   course the history of our species, a biological urge as profound as our sex
   drive. We figured out how to make very sharp hunting tools from unruly
   rocks, or we died.

- [spider webs on drugs](http://thirdmonk.net/high-culture/spiders-drugs-affect-webs.html)

-  The first chapter of Berstel and Reutenauer's "Noncommutative Rational
   Series with Applications" presents Schützenberger's theorem that every
   noncommuting rational power series is representable, and conversely. The
   idea is NOT painfully abstract, but makes twenty minutes work of a semester
   of undergraduate automata theory (an assertion I've tested multiple times in
   my math office hours).

- You don't want sync software going off and "thinking" about what a symlink
  really means, anymore than you'd want sync software going off and "thinking"
  after finding porn on your computer

- Luckily, I was trained far enough down the street from MIT to escape their
  Lisp world view, so we coded our computer algebra system in C, and it was
  fast enough to succeed and bring us tenure. Today, we'd choose Haskell.


His LISP language with inferred parens:

```
define | edge? g e
  let
    $ es | edges g
      e2 | reverse e
    or (member e es) (member e2 es)
```

```
(define (edge? g e)
  (let
    ( (es (edges g))
      (e2 (reverse e)))
    (or (member e es) (member e2 es))))
```


# Conditional probability is neither causal nor temporal

I found this insightful:

> `P(A|B)` means the probability of A happening given B already
> happened. Not so! `P(A|B)` doesn’t specify the time ordering of A and B. It
> specifies the order in which YOU learn about them happening. So P(A|B) is the
> probability of A given you know what happened with B.

This makes sense from the information theoretic perspective; I'd never meditated
on this difference, though.

I'd seen things like: 

> `P(sunrise | rooster-crow) = large` even though rooster crowing does not *cause*
> the sunrise to happen. 

but I'd never seen/actively contemplated an example of `P(A|B)` where they 
are temporally reversed/ambiguous.

# Hook length formula

Truly remarkable formula that tells us the number of standard young tableaux
for a given partition $\lambda$ of $n$. Recall the definitions:
- A partition $\lambda$ of the number $n$.
- An assignment of numbers $\{1, 2, \dots n\}$ onto the diagram of the partition
  such that the assignment is (a) weakly increasing in the rows, and
  (b) strictly increasing in the columns. It is strictly increasing in the columns
  because gravity acts downwards.
- Formally, a partition is written as $\lambda \equiv [\lambda_1, \lambda_2, \dots, \lambda_m]$, 
  where $\lambda_i \geq 0$ and $\sum_i \lambda_i = n$, and that they
  are weakly decreasing ($\lambda_1 \geq \lambda_2 \geq \dots$). 
- Formally, to define the tableaux, we first define the diagram $dg(\lambda) \equiv \{ (i, j) : 1 \leq j \leq \lambda[i] \}$
  which are the "locations" of the cells when visualizing $\lambda$ as a Ferrers diagram.
- Finally, the actual assignment of the numbers to the tableaux is given by a bijection
  $asgn: dg(\lambda) \rightarrow [n]$ such that $f$ is weakly increasing in the rows
  and strictly increasing in the columns.


#### The formula
Now, we want to count the number of young tableaux (formally, the data $n, \lambda, asgn$)
for a given partition $\lambda$. The formula is:

$$
n!/\left(\prod_{\texttt{cell} \in \lambda} hooklen(\texttt{cell})\right)
$$

where $hooklen$ is the largest "hook shape":

```
* * *
*
*
...
```

at the cell $(i, j)$ that is in the partition $\lambda$.

#### The structure of hooks

say we have a hook shape


```
a b c d
e
f
```

And the numbers $\{1, 2, 3, 4, 5, 6\}$. How many ways can we assign the numbers
to the above hook shape such that its a legal young tableaux?

- First, see that $a = 1$ is a must. Proof by contradiction. Assume $1$
  is not placed at $a$. Whenever it is placed, it will be less than the number
  placed at $1$. But this is wrong, because a young tableaux must be weakly
  increasing in the rows and strictly increasing in the columns.
- Next, see that after placing $a = 1$, the other numbers can be placed "freely":
  If we take a subset of $\{2, 3, 4, 5, 6\}$ of the size of the leftover row,
  ie, $|b~c~d| = 3$, then there is only one way to place them such that they are
  in ascending order. Similarly, the leftover numbers go to the column where there
  is only one way to place them.
- Hence, after $a = 1$ is fixed, for every $5C3$ subset, we get a legal hook.
- In general, if we have $n=r+c+1$ nodes, with $r+1$ nodes in the row, and $c+1$
  nodes in the column (the top-left node is counted twice), then we have $\binom{r+c}{r}$
  number of legal hooks; Once we pick the lowest number for the top left node,
  every $r$-subset will give us a hook.

- This result matches the hook-length formula. According to the hook length
  formula, we need to fill in for each node the length of the hook, and divide
  the full product by $n!$. So for
  the hook:

```
a b c d
e
f
```

This becomes:

```
6 3 2 1
2
1
```

$$
6!/(6\times 3!\times 2!) = 5!/(3! 2!) = 5C3 = \binom{r+c}{r}
$$

where $r=3, c=2$.


#### Knuth's heuristic

- Consider the hook shape. The only constraint we have is that the top-left
  number ought to be the smallest. For the hook $H$ to be legal, if we distribute
  numbers into it uniformly at random, then there is a
  $1/(\texttt{hook-length}(H))$ probability that the hook will be legal.


- The tableaux will be legal iff **all the hooks in the tableaux are legal**


- Thus, the probability of getting a legal tableaux is:

$$
\begin{aligned}
&\texttt{num}(\lambda)/n! =  \prod_\{h \in \texttt{hook}(\lambda) 1/\texttt{hook-length}(h) \\
&\texttt{num}(\lambda) =  n!/\prod_\{h \in \texttt{hook}(\lambda)\texttt{hook-length}(h) \\
\end{aligned}
$$


#### The relationship to representation theory

The RSK correspondence gives us a bijection between the permutation group $S_n$
and pairs of standard young tableaux: 

$$
RSK \equiv \bigcup_{\lambda \in \texttt{partition}(n)} SYT(\lambda) \times SYT(\lambda)
$$

given by the pair of insertion tableaux and the recording tableaux for each partition
$\lambda$ of $n$.

If we look at this in terms of set sizes, then it tells us that:

$$
\begin{aligned}
&|S_n| = |\bigcup_{\lambda \in \texttt{partition}(n)} SYT(\lambda) \times SYT(\lambda) \\
&n! = \sum_{\lambda \in \texttt{partition}(n)} |SYT(\lambda)|^2 \\
&n! = \sum_{\lambda \in \texttt{partition}(n)} |\texttt{hook-length-formula}(\lambda)|^2 \\
\end{aligned}
$$

This looks very suspicious, almost like the representation theoretic formula of:

$$
\texttt{group-size} = \sum_{\texttt{irrep} \in Repr(G)} dim(\texttt{irrep})^2
$$

and it is indeed true that $\texttt{hook-length-formula}(\lambda)$ corresponds
to the dimension of an irreducible representation of $S_n$, and each $\lambda$
corresponds to an irrep of $S_n$.



# The tyranny of light

> More information may
> lead to less understanding; more information may undermine trust; and more
> information may make society less rationally governable.

# Muirhead's inequality

We denote by $\sum_! F(x[1], \dots, x[n])$ the sum ov $F$ evaluated over all
permutations. Formally:

$$
\sum_! F(x[1], \dots, x[n]) \equiv \sum_{\sigma \in S_n} F(x[\sigma[1]], \dots, x[\sigma[n]])
$$


We write

$$
[a[1], \dots a[n]] \equiv 1/n! \sum_! x_1^{a[1]} \dots x[n]^{a[n]} = \sum_{\sigma \in S_n} \prod_{j} x[\sigma[j]]^{a[j]}
$$

For example,we have:
- $[1, 1] = 1/2! (xy + yx) = xy$
- $[1, 1, 1] = xyz$
- $[2, 1, 0] = 1/3! (x^2y + x^2z + y^2z + y^2x + z^2x + z^2 y)$
- $[1, 0, 0] = 1/3! (x^{[1, 0, 0']} + x^{[1, 0', 0]} + x^{[0, 1, 0']} + x^{[0', 1, 0]} + x^{[0, 0', 1]} + x^{[0', 0, 1]})$.
  This is equal to $2!(x + y + z)/3! = (x + y + z)/3$.
- In general, $[1, 0, 0, 0, \dots, 0]$ ($n$ zeroes) is $(n-1)!/n!(\sum_i x_i)$ which is the AM.
- Also, $[1/2, 1/2] = 1/2!(x^{1/2}y^{1/2} + y^{1/2}x^{1/2}) = \sqrt{xy}$.
- In general, $[1/n, 1/n, \dots, 1/n]$ is the GM $\sqrt{n}{x[1] x[2] \dots x[n]}$.

#### Majorization

Let $(a), (b) \in \mathbb R^n$ be two non-decreasing sequences: $a[1] \geq a[2] \dots \geq a[n]$,
and $b[1] \geq b[2] \dots \geq b[n]$.  We will say that $(b)$ is majorized by
$(a)$  (written as $(b) \prec (a)$) when we have that:

1. $a[1] \geq a[2] \geq \dots a[n]$, $b[1] \geq b[2] \geq \dots b[n]$.
2. $\sum_i b[i] = \sum_i a[i]$.
3. $\sum_{i=1}^u b[i] \leq \sum_{i=1}^u a[i]$ for $1 \leq i \leq n$.

It is clear that this is a partial order. The below figure shows majorization
in terms of partitions. For two sequences $f, g$, define $F$ to be their "integral"
(partial sums) and $f', g'$ to be their "derivatives" (finite differences).
Then the condition that $f \prec g$ states that $F$ is upper bounded by $G$,
and that $F, G$ are concave functions.

<img src='./static/majorization-partitions.png'>


The other lens of viewing majorization is to think of a number as some sort
of fixed length $l$, and we are allowed to make some progress to reach the goal
($f(x) > 0$) as long as we progress less at each each timestep ($f''(x) < 0$).
In this viewpoint, the majorization condition asserts that $f \prec g$ is that
$g$ will always be ahead of/not fall behind $f$.


<img src='./static/majorization-fixed-length.png'>

#### Majorization and step 

We can show that if $(b) \prec (a)$ , then we can get from $(b)$ to $(a)$
in a finite number of discrete steps, that "borrow" from higherlocations in $b$
and "give" to lower locations. Formally, define a step operator $S(l, r)$ where
$l < r$ such that:

$$
S(l, r)(b)[k] = 
\begin{cases}
 b[l]+1 & k = l \\
 b[r]-1 & k = r \\
 b[k] & \texttt{otherwise}
\end{cases}
$$

That is, this borrows a single value from $b[j]$ and gives it to $b[i]$. We can see
that $(b) \prec S(l, r)(b)$.

For a given $(b) \prec (a)$, we can find a sequence of step operations
$S(l[i], r[i])$ such that we transform $(b)$ into $(a)$; That is, it is possible
to "single-step" the translation from $(b)$ to $(a)$.

#### Muirhead's theorem statement

for non negative numbers $x[]$, we have:

$$[b] \leq [a] \iff (b) \prec (a)$$

Expanding it out, this means that:

$$
1/n! \sum_! x^{[b]} \leq 1/n! \sum_! x^{[a]} \iff (b) \prec (a) \\
\sum_! x^{[b]} \leq \sum_! x^{[a]} \iff (b) \prec (a) \\
$$



# Rearrangement inequality

If $a[i]$ is a non-decreasing sequence: $a[1] \leq a[2] \leq \dots a[n]$, and 
similarly $b[i]$ is a non-decreasing sequence: $b[1] \leq b[2] \leq b[n]$ then
we have that:

$$
\sum_i a[i] b[i] \geq \sum_i a[\sigma[i] b[i]
$$

for any permutation $\sigma \in S_n$. 

> insight: the greedy strategy is the best. Think of $b[n]$ as the max. number of times
> we are allowed to pick some $a[i]$.
> It is best to be greedy and pick the value $\max_i a[i]$  $b[n]$ number of times.
> $\max_i a[i] = a[n]$. Thus having $a[n]b[n]$ will beat all others.  

#### Proof

The proof strategy is to: show what happens for a transposition. Every
permutation can be broken down into transpositions and thus we are done.

Let $S = \sum_i a[i] b[i]$. Let $T$ be $S$ with us picking the value $a[r]$ $b[s]$ times,
and picking the value $a[s]$ $b[r]$ times. This gives

$$
T = \sum_{i \neq r, s} a[i] b[i] + a[r]b[s] + a[s]b[r]
$$


Since we wish to show $S > T$, let's consider $S - T$:

$$
\begin{aligned}
&S - T = \sum_i a[i]b[i] - (\sum_{i \neq r, s} a[i]b[i] + a[r]b[s] + a[s]b[r]) \\
&=\sum_{i \neq r, s} a[i]b[i] + a[r]b[r] + a[s]b[s]  - (\sum_{i \neq r, s} a[i]b[i] + a[r]b[s] + a[s]b[r]) \\
&= a[r]b[r] + a[s]b[s] - a[r]b[s] - a[s]b[r] \\
&= a[r](b[r] - b[s]) + a[s](b[s] - b[r]) \\
&= a[r](b[r] - b[s]) - a[s](b[r] - b[s]) \\
&= (a[r] - a[s])(b[r] - b[s])
\end{aligned}
$$

Since $r < s$ we have $b[r] \leq b[s]$, hence $b[r] \leq b[s] < 0$. For the product
to be greater than zero, we need $a[r] \leq a[s]$, or $a[s] \geq a[r]$ when $s > r$.

Hence, for a transposition, we are done. Thus we are immediately done
for any permutation:

#### Application: AM-GM

Say we wish to show $(p + q)/2 \geq \sqrt{pq}$. Let WLOG $p \leq q$.
Pick the sequences:

$$
a = [p, q]; a' = [q, p]; b = [p, q]
$$

Then the rearrangement inequality gives us:

$$
\begin{aligned}
&a[1]b[1] + a[2]b[2] \geq a'[1]b[1] + a'[2]b[2] \\
&p^2 + q^2 \geq qp + pq \\
&(p^2 + q^2)/2 \geq pq
\end{aligned}
$$

Pick $p = \sqrt{r}, q = \sqrt{s}$ to arrive at:

$$
(r + s)/2 \geq \sqrt{rs}
$$

and thus we are done.

#### References
- Inequalities: a mathematical olympiad approach

# Triangle inequality

We can write this as:

```
   *A
 b/ |
C*  | 
 a\ | c
   *B
```

The classical version one learns in school:
$$
c \leq a + b
$$

The lower bound version:

$$
|a - b| \leq c
$$

This is intuitive because the large value for $a - b$ is attained when $b = 0$.
(since lengths are non-negative, we have $b \geq 0$. if $b = 0$, then the point $A = C$
and thus $a = CB = AB = c$.

```
A/C (b=0)
|
| a=c
|
B
```

Otherwise, $b$ will have some length that will cover $a$ (at worst), or cancel $a$ (at best).
The two cases are something like:

```
 A
 ||b
 ||
c|*C
 ||a
 ||
 ||
 B
```

In this case, it's clear that $a - b < c$ (since $a < c$) and
$a + b = c$. In the other case, we will have:

```
 C
b||
 ||
 A|
 ||
 ||a
c||
 ||
 ||
 ||
 B
```

Where we get $a - b = c$, and $c < a + b$. These are the extremes when the triangle has
zero thickness. In general, because the points are spread out, when we
project everything on the $AB=c$ line, we will get less-than(`<=`) 
instead of equals (`=`).

# The Heather subculture
- And finally, [the sweater's perspective](https://www.youtube.com/watch?v=c_PT91SqVX8)

# Frobenius Kernel

#### Some facts about conjugates of a subgroup

Let $H$ be a subgroup of $G$. Define $H_g \equiv \{ g h g^{-1} : h \in H \}$.

- We will always have $e \in H_g$ since $geg^{-1} = e \in H_g$.
- Pick $k_1 k_2 \in H_g$. This gives us $k_i = gh_ig^{-1}$. So, 
  $k_1 k_2 = g h_1 g^{-1} g h_2 g^{-1} = g (h_1 h_2) g^{-1} \in H_g$.
- Thus, the conjugates of a subgroup is going to be another subgroup 
  that has nontrivial intersection with the original subgroup.
- For inverse, send $k = ghg^{-1}$ to $k^{-1} = g h^{-1} g^{-1}$.


#### Frobenius groups



# Galois theory by "Abel's theorem in problems and solutions"

I found the ideas in the book fascinating. The rough idea was:

- Show that the $n$th root operation allows for some "winding behaviour"
  on the complex plane.
- This winding behaviour of the $n$th root is controlled by $S_n$, since we are
  controlling how the different sheets of the riemann surface can be permuted.
- Show that by taking an $n$th root, we are only creating solvable groups.
- Show tha $S_5$ is not solvable.



# Galois theory perspective of the quadratic equation

I found this quite delightful the first time I saw it, so I wanted to record
it ever since.

Let $x^2 + bx + c$ be a quadratic. Now to apply galois theory, we first
equate it to the roots:

$$
\begin{aligned}
&x^2 + bx + c = (x - p)(x-q)
&x^2 + bx + c = x^2 - x(p + q) + pq
&-(p + q) = b; pq = c
\end{aligned}
$$

We want to extract the values of $b$ and $c$ from this. To do so, consider
the symmetric functions:

$$
(p + q)^2 = b^2
(p - q)^2 = (p + q)^2 - 4pq = b^2 - 4c
$$

Hence we get that

$$
p - q = \pm\sqrt{b^2 - 4c}
$$

From this, we can solve for $p, q$, giving us:

$$
p = ((p + q) + (p - q))/2 = (-b \pm \sqrt{b^2 - 4c})/2
$$

#### Galois theory for cubics
#### Galois theory for bi-quadratics
#### Galois theory for quintics

#### References
- [Abel and the insolubility of the quintic](http://www.math.caltech.edu/~jimlb/abel.pdf)

# Burnside lemma by representation theory.

Recall that burnside asks us to show that given a group $G$
acting on a set $S$, we have that the average
of the local fixed points $1/|G|(\sum_{g \in G} |\texttt{Fix}(g)|)$ is
equal to the number of orbits (global fixed points) of $S$, $|S/G|$.

Let us write elements of $g$ as acting on the vector space $V_S$, which is
a complex vector space spanned by basis vector $\{ v_s : s \in S \}$. Let
this representation of $G$ be called $\rho$.

Now see that the right hand side is equal to 

$$
\begin{aligned}
&1/|G| (\sum_g \in G Tr(\rho(g))) \\
&= 1/|G| (\sum_g \in G \chi_\rho(g) ) \\
&\chi \rho \cdot \chi_1
\end{aligned}
$$

Where we have:
- $\chi_1$ is the charcter of the trivial representation $g \mapsto 1$
- The inner product $\langle \cdot , \cdot \rangle$ is the $G$-average inner
   product over $G$-functions $G \rightarrow \mathbb C$:

$$
\langle f , f' \rangle \equiv \sum_{g \in G} f(g) \overline{f'(g)}
$$

So, we need to show that the number of orbits $|S/G|$ is equal to the
multiplicity of the trivial representation $1$ in the  current representation
$\rho$, given by the inner product of their characters $\chi_1 \cdot \chi_\rho$.



let $s* in S$ whose orbit we wish to inspect. Build
the subspace spanned by the vector $v[s*] \equiv \sum_{g \in G} \rho(g) v[s]$.
This is invariant under $G$ and is 1-dimensional. Hence, it corresponds
to a 1D subrepresentation for all the elements in the orbit of $s*$. 
(TODO: why is it the **trivial** representation?)


# Contributing to SAGEmath


#### Development

- The first time, run `make build`. DO NOT RUN `make`, as this performs a `make doc`
  as well which burns cycles building docs for no reason.
- Normally, if you just change Python code in the library, it suffices to run `./sage -br`
  to update Python.
- Only if you changed docs, and want to test that they still work,
  you'd need to run `make`, or `make doc-html`
- To run doctests, can run `./sage -t <filepath>`. [More info on the sage doctesting page](https://doc.sagemath.org/html/en/developer/doctesting.html)
- `make build && ./sage -n=jupyter ./test-ddg-notebook.ipynb` is reasonably fast.

- [SAGE developer index](https://doc.sagemath.org/html/en/developer/index.html)
- [Baby's first Trac ticket: #31248 --- Make tableaux error messages more precise](https://trac.sagemath.org/ticket/31248#comment:1)

#### Git the hard way for SAGE

- [Git the hard way](https://doc.sagemath.org/html/en/developer/manual_git.html)

git with SAGE uses different URLs for fetch and push.

```
[user@localhost sage]$ git remote add trac git://trac.sagemath.org/sage.git -t master
[user@localhost sage]$ git remote set-url --push trac git@trac.sagemath.org:sage.git
trac        git://trac.sagemath.org/sage.git (fetch)
trac        git@trac.sagemath.org:sage.git (push)
```

- I use my github account to develop for SAGE.
- [Linking your SSH key with sage-trac](https://doc.sagemath.org/html/en/developer/trac.html#linking-your-public-key-to-your-trac-account)

#### Getting the commit merged

The release manager (Volker Braun) takes care of it.
A number of people can close tickets for invalidity/duplicate etc,
but the actual merging is done by one person only (and a number of
bots/scripts that help).

A positively reviewed ticket with green bots and all fields filled in will
usually be merged in a week or two or rejected (merge conflict, issues
with specific architectures, failing bots). But it might take longer (too
many positively review tickets waiting, end of release cycle).


#### Tending to the garden

- Fix typos
- Fix `pep8`, `pyflakes`, lint warnings. Try to simplify code that's
  marked very compliated by `radon`.
- Fix code that's marked by [lgtm](https://lgtm.com/query)

# Shadow puppet analogy for entanglement

I found [this answer on quantumcomputing.stackexchange](https://quantumcomputing.stackexchange.com/a/15525/14471)
to be a visceral example of "something like entanglement":

Imagine making shadow puppets. However in this setup, instead of one you have
two screens and two torches  pointing 90 degrees apart so
that the image formed by torch 1 is projected onto screen 2 and the image
formed by torch 2 is simultaneously projected onto screen 1.

```
 screen 1       screen 2
   /               \
  /                 \
 /                   \
          mm              <-  hand
      \         /
   torch 1   torch 2
```

Now any movement of your hand changes both images in a correlated way. In a
sense, the images are entangled - if you observe image 1 to have a certain
configuration, then only a small subset of possibilities in the total
configuration space of image 2 are valid, and vice versa.



# Books for contest math

A personal list of books I wish to study this year, to get better at 
"problem solving". This is ranked in order of difficulty
I wish to spend this year learning nuts and bolts type things.

- Inequalities: an olympid approach --- Nice book, has an axiomatic/algebraic bent.
- Mathematical circles: Russian experience
- The art and craft of problem solving
- Basics of Olympiad Inequalities: Samin Riasat --- quickly covers the big 12.
- [Evan chen: A Brief Introduction to Olympiad Inequalities ](https://web.evanchen.cc/handouts/Ineq/en.pdf)
- Pham Kim Hung: Secrets in Inequalities 
- Edwin Beckenback: Introduction to Inequalities
- Nicholas D. Kazarinoff : Geometric inequalities
- Introduction to Functional Equations: Theory and problem-solving strategies for mathematical competitions and beyond
- [Combinatorics: Introduction to counting and probability](https://artofproblemsolving.com/store/item/intro-counting)
- [Combinatorics: Intermediate counting and probability](https://artofproblemsolving.com/store/item/intermediate-counting?gtmlist=Bookstore_AoPS_Side)
- Algebra: 101 Problems in Algebra by Titu Andreescu
- Number Theory Structures, Examples and Problems
- Combinatorics: 102 Combinatorial problems
- Combinatorics: Pablo Soberon’s Problem Solving Methods in Combinatorics
- Geometry: [Yufi Zhao: handouts](https://yufeizhao.com/olympiad/)
- Geometry: Trig bashing / Barycentric bashing (evan cheng)
- Problem-solving Strategies In Mathematics: From Common Approaches To Exemplary Strategies
- Problems from the Book
- Straight From the Book
- [AoPS list of past problems](https://artofproblemsolving.com/community/c13_contests)
- [AoPS list of books](https://artofproblemsolving.com/wiki/index.php?title=Math_books)
- [Mathematical problem solving: MIT course](https://yufeizhao.com/a34/)

# Analysing simple games

I found the clear articulation of these ideas quite nice. 

1. In a game with symmetry, a symmetric move can be blocked or prevented **only**
   by the previous move an opponent has **just made**.
2. The symmetry in many games can be written as some kind of equality, where
   at each turn, one first player breaks the symmetry, and the other player
   (who has the winning strategy) restores it.

#### Example game

Consider a game where two players take turns placing bishops on a chessboard,
so that the pieces cannot capture each other. The player who cannot win
loses.

#### Winning strategy

place the bishop symmetrically about the line passing between the fourth and
fifth column (file). Note that the only way this bishop could be blocked is
if the move just made by the other player can block it.



#### References
- [Mathematical circles: Russian experience](https://bookstore.ams.org/mawrld-7)

# Linear algebraic proof of the handshaking lemma

We wish to show that the number odd vertices is even. Let $A$ be the adjacency
matrix of the undirected graph $G$. Since $G$ is undirected, $A = A^T$. Now
move everything to $F_2$, including $A$. This means that $A$ has entries $\{0, 1\}$.
Now, denote the vector of all ones by $o \equiv (1, 1, \dots 1)$. See that
$Ao$ counts the partities of the degrees of each vertex, and $o^T(Ao)$ counts the
sum of parities of the degrees of each vertex.


Note that the vertices of even degree with add $0$ to the sum $o^TAo$, while
odd vertices will add a $1$. Thus, $o^TAo$ will equal the parity of
the number of odd vertices. As we wish to show that the number of odd vertices
is even, we want to prove that $o^TAo = 0$.


We will now algebraically simplify $o^TAo$ (does anyone have a cleaner proof?)
giving us:


$$
\begin{aligned}
&o^TAo = \sum_{ij} o_i A_{ij} o_j \\
&= \sum_{i=j} o_i A_{ij} o_j + \sum_{i < j} o_i A_{ij} o_j + o_j A_{ji} o_i \\
&\text{($A$ is symmetric; $A_{ji} = A_{ij}$)} \\
&= \sum_{i=j} o_i A_{ij} o_j + \sum_{i < j} o_i A_{ij} o_j + o_j A_{ij} o_i \\
&= \sum_{i=j} o_i A_{ij} o_j + \sum_{i < j} 2 \cdot o_i A_{ij} o_j  \\
&\text{($F_2$ has characteristic zero, so $2 = 0$)} \\
&= \sum_{i=j} o_i A_{ij} o_j + 0 \\
&\text{(replace $i = j$ with $k$)} \\
&= \sum_{k} o_k A_{kk} o_k  \\
&\text{($A_{kk} = 0$ since graph has no self loops)} \\
&= \sum_{k} 0 \cdot o_k^2  = 0
\end{aligned}
$$

So, the number of vertices of odd degree is even.


I want to avoid this computation with respect to the basis, but I'm not
sure how to do that.

#### A simplification from arjun

Since $A_{kk} = 0$, we have that $A = B + B^T$ for $B$ lower triangular.
This allows us to simplify:

\begin{aligned}
& o^T A o = o^T (B + B^T) o = \\
& =o^T B o + o^T B^T o = \langle o, Bo \rangle + \langle Bo, o \rangle \\
& = 2 \cdot \langle o, Bo \rangle = 0
\end{aligned}




# Historical contemporaries

I continue to be delighted at how connected arbitrary parts of history are.
Here's a list of contemporaries I would not have guessed:

- Rembrandt sketched Shah jahan
- Greek ambassador in the Ashoka court
- "Bhaeatha's kingdom" for Bharat as known by the Chinese
- Aurangzeb had rockets when fighting his brother 
- Aurangzeb had a French physician (Francois bernier)
- Picasso was against the Korean war (1950) and painted about it.

# Rota's twelvefold way

- Count functions from $I \rightarrow O$.
- See that any such function is a subset of $O^I$.
- We can write such a function as $(o_1, o_2, \dots, o_{|I|}) \in O^I$
- if we have $S_I \circ f$, this means that we can permute images.
- If we have $f \circ S_O$, this means that we can permute fibers.

#### f any function

- we count $O^I$        

#### f injective

- We count $O^{(I)} = O(O-1)\dots(O-I+1)$ as given by the falling factorial.

#### f surjective, with equivalence $S_I \circ f$.

- For each element $o \in O$, pick some subset $I_o \subseteq I$. We need the
  subsets $I_o$ to be disjoint, and all $I_o$ to be non-empty.
- We can permute the fibers $I_o$, so we can place them by weakly decreasing order of size.
- Then this is the same as counting partitions of $I$ into $O$ subsets, given by 
  $S(n, x)$/${n\brace m}$ (stirling numbers of the second kind).


#### f surjective

- For each element $o \in O$, pick some subset $I_o \subseteq I$. We need the subsets $I_o$ to be disjoint,
  and all $I_o$ to be non-empty.
- We get partway there by counting **compositions** of $I$: the number of ways to 
  split $|I|$ into $(a_1, a_2, \dots, a_k)$ such that each $(a_i > 0)$ and $\sum_i a_i = |I|$.
  Note that ordering matters here, since we write a **tuple** $(a_1, a_2, \dots a_k)$.
- For example, the compositions of $3$ are $(1, 1, 1)$, $(1, 2)$ and $(2, 1)$.
  See that we have both $(1, 2)$ and $(2, 1)$.
- Contrast this with partitions, which I write in weakly decreasing: $(1, 1, 1)$, $(2, 1)$.
- This can be counted by the stars and bars method:

```
1 _ 2 _ 3 _ 4 _ ... _  |I|
```

- We want to fill the $|I|-1$ blanks (`_`) with $k$ bars if we want a $k$-composition (remember that compositions
  can't have zeros). So we can count this by $\binom{|I|-1}{k}$.

#### f surjective, with equivalence $S_I \circ f \circ S_O$:






# Counting necklackes with unique elements

Count number of ways to form a necklace with $\{1, 2, \dots, n\}$

- Method 1: This is equivalent to counting $|S_5|$ modulo the subgroup generated by
  $(12\dots)$. That subgroup has size $5$. So the size is $S_5/5$.
- Method 2: A cycle is an equivalence class of elements $(a,b,c,d,e)$ along with
 all of its cyclic shifts ($(b,c,d,e,a)$, $(c,d,e,a,b)$, $(d,e,a,b,c)$, $(e,a,b,c,d)$).
  We are to count the number of equivalence classes. First pick a canonical element
  of each equivalence class of the form $(1, p, q, r, s)$. 


# Decomposition of projective space

Projective space $\mathbb P^{n+1} = \mathbb P^n \cup \mathbb R^n$. The
current way I think about this is as follows (specialize to $n=3$)

- Consider a generic point $[x : y : z]$. Either $x = 0$ or $x \neq 0$.
- If $x = 0$, then we have $[0 : y : z]$ which can be rescaled freely:
  $[0: y: z] = (0, y, z, 1) = (0, \lambda y, \lambda z, \lambda) = [0: y: z]$.
  So, we get a component of $\mathbb P^2$ from the $[y: z]$.
- If $x \neq 1$, we have $[x : y : z]$. Spend the projectivity to get $(1:y:z) = (x, y, z, x)$.
  Now we have two free parameters, $(y, z) \in \mathbb{R^2}$. This gives us the $\mathbb R^2$.

There's something awkward about this whole thing, notationally speaking. Is there
a more natural way to show that we have spent the projectivity to renormalize
$[x: y: z]$ to $(1, y, z)$ ?


#### Projective plane in terms of incidence

We can _define_ $\mathbb P^2$ to be an object such that:
1. Any two lines are incident at a single point.
2. Two distinct points must be incident to a single line. (dual of (1))


#### The points at infinity
This will give us a copy of $\mathbb R^2$, along with "extra points" for parallel
lines. 

- Consider two parallel lines $y = mx + 0$ and $y = mx + 1$. These don't traditionally
  meet, so let's create a point at infinty for them, called $P_m(0, 1)$.
- Now consider two more parallel lines, $y = mx + 0$ and $y = mx + 2$. These don't
  traditionally meet either, so let's create a point at infinite for them, called
  $P_m(0, 2)$.
- Finally, create another point $P_m(0, 3)$ as the point of intersection between
   $y = mx + 0$ and $y = mx + 3$.

- Now, consider $P_m(0, 1), P_m(0, 2), P_m(0, 3), dots$. We claim that they must all be equivalent.
  Assume not. Say that $P_m(0, 1) \neq P_m(0, 2)$.
- Then there must a line that joins $P_m(0, 1)$ an $P_m(0, 2)$. Call it $L_m(0, 1, 2)$.
  Now, what is the intersection between $L_m(0, 1, 2)$ and the line $y = mx + 0$?
  The points $P_m(0, 1)$ and $P_m(0, 2)$ *both* lie on the line $L_m(0, 1, 2)$.
  But this is a contradiction: two lines must be incident at a single unique point.
- So we must have $P_m(0, 1) = P_m(0, 2) = P_m$. So, for each direction, we must
  have a unique point where all lines in that direction meet.

We can make a definition: the **point at infinity for a given direction** is the
equivalence class of all lines in that direction.

<img src='./static/projective-plane-incidence-points.png'/>

#### The line at infinity

This now begs the question: what lines to different points at infinity lie on?
Let's consider $P_q, P_r, P_s, P_t$ as four points at infinity for four different
slopes.

- Consider the lines $L(q, r)$ that is incident on $P_q$ and $P_r$, and then
  the line $L(s, t)$ that is incident on the lines $P_s$ and $P_t$.
- This begs the question: where do these lines meet? If we say that the meet at _more new_
  points of intersection, like $P(q, r, s, t)$ this process will never end.
- So we demand that _all points at infinity_ lie on a _unique_ line at infinity.



# Childhood: Playing pokemon gold in japanese

I just recalled this very off memory of how back when I was a kid, somehow the
only version of pokemon (gold) that was circulating amongst folks was the one
in _japanese_. So we freaking played gold in _japanese_. I can't believe I got
through so many levels with no clue of what in the actual fuck I was doing. I
remember being stuck at the point where you need to use cut to cross a barrier
or something, and figuring it out by accident.

Pretty sure I got blocked someplace because I lost the surf HM.

This memory just resurfaced, and I spent a solid five minutes thinking about
just how _insane_ the whole thing is. A kid's determination to play a game
knows no bounds, indeed.

# Tensor is a thing that transforms like a tensor

There are two ways of using linear maps in the context of physics. One is
as a thing that acts on the _space_. The other is a thing that acts on the
_coordinates_. 

So when we talk about transformations in tensor analysis, we're talking
about _coordinate transformatios_, not _space transformations_.

# Tensor Hom adjunction

- `(- X A)` witnesses `A` as an output, while `Hom(A, -)` witness A as input.
- Similarly, we know that we can contract `A` with `A*` so it makes sense that the
  "dual" of multiplying by `A` (ie, how to divide out `A`) is to invert it by
  allowing a contraction with `A*`.


# Schur's lemma 

#### Statement

if $r_v : G \rightarrow GL(V), r_w: G \rightarrow GL(W)$ are two irreducible
representations of the group $G$, and $f: V \rightarrow W$ is an equivariant map
(that is, $f\forall g \in G, \forall v \in V, (r_v(g)(v)) = r_w(g)(f(v))$),
then we have that either $f = 0$ or $f$ is an isomorphism.

- Said differently, this implies that either $r_v$ and $r_w$ are equivalent, and $f$
  witnesses this isomorphism, or $V$ and $W$ are not isomorphic and $f$ is the zero map.

#### Proof

- First, note that $ker(f)$ and $im(f)$ are invariant subspaces of $G$.
- Let $k \in ker(f)$. hence:

$$
\begin{aligned}
&r_w(g)(f(k)) = 0 \\
&f(r_v(g)(k) =  r_w(g)(f(k)) = 0 \\
&r_v(g)(k) \in ker(f) \\
\end{aligned}
$$
So if $k \in ker(f)$ then so does $r_v(g)(k)$ for all $g$. Hence, the kernel
is an invariant subspace.

- Next, let $w \in im(f)$, such that $w = f(v)$ hence:

$$
\begin{aligned}
&f(v) = w \\
&r_w(g)(w) = r_w(g)(f(v)) = f(r_v(g)(v)) \\
&r_w(g)(w) \in im(f) \\
\end{aligned}
$$

So if $w \in im(f)$ then $r_w(g)(w) \in im(f)$ for all $g$. Hence, image
is an invariant subspace.


- Since $V$ is irreducible, we must have that either $ker(f) = 0$ or $ker(f) = V$.
  If this were not the case, then we could write $V = ker(f) \oplus ker(f)^\perp$
  non-trivially. This contradicts the irreducible nature of $V$. Thus, either $f$
  sends all of $V$ to $0$ (ie, $f$ is the zero map), or $f$ has trivial kernel
  (ie, $f$ is injective).
- Since $W$ is irreducible, we must have that either $im(f) = 0$ or $im(f) = W$
  by the exact same argument; $im(f)$ is an invariant subspace, and $W$ is
  irreducible thus has non non-trivial invariant subspaces. Thus either $im(f) = 0$
  ($f$ is the zero map), or $im(f) = W$ ($f$ is surjective).
- Thus, either $f$ is the zero map, or $f$ is both injective and surjective; that is,
  it is bijective.
- The real star of the show is that (1) we choose irreducible representations,
  and (2) kernel and image are invariant subspaces for the chosen representations,
  thus we are forced to get trivial/full kernel/image.


#### Strengthing the theorem: what is $f$?

We can additionally show that if $f$ is not the zero map, then $f$ is
constant times the identity. That is, there exists a $\lambda$ such that $f = \lambda I$.

- $f$ cannot have two eigenvalues. If it did, the eigenspaces of $\lambda_1$ and
  $lambda_2$ would be different subspaces that are stabilized by $f$. This can't
  happen because $V$ is irreducible. So, $f$ has a single eigenvalue $\lambda$.
- Thus, if $f$ has full spectrum, it's going to be $f = \lambda I$.
- $f$ has full spectrum since we tacitly assume the underlying field is $\mathbb C$
  and $f$ has full rank.



# Daughters of destiny

Captures the microcosm of what it means to live in India.

- [Shanti Bhavan](https://www.shantibhavanchildren.org/)

# Stuff I learnt in 2020

- MLIR
- unification
- GRIN
- demand analysis
- tabled typeclass resolution
- ZX
- pwn.college
- semantics of general relativity
- mathemagic
- oripa and FOLD
- tensegrity
- uncivilization
- CSES
- USACO
- rete
- number theory / amalgam
- sampleraytracer
- bijective combinatorics
- [Why do people stay poor?](https://news.ycombinator.com/item?id=25568800)
- Talk: p-adics
- Talk: smallpt-hs


# Line bundles, a high level view as I understand them today

- What is a line bundle?
- What does it mean to tensor two line bundles?
- Why are line bundles invertible?
- Can we draw pictures?

#### Why are bundles invertible?

Because locally, they're locally modules. This leads us to


#### Why are modules invertible?

All modules are invertible when tensored with their dual.


To simplify further, let's move to linear algbera from ring theory; consider the field $\mathbb R$.
Over this, we have a vector space of dimension $1$, $\mathbb R$. Now, if we consider $\mathbb R \otimes \mathbb R^*$,
this is isomorphic to $\mathbb R$ since we can replace $(r, f) \mapsto f(r)$. This
amounts to the fact that we can contract tensors.

So, $\mathbb R \otimes \mathbb  R^* \simeq \mathbb R$. Generalize to bundles.

#### References

- [Fiber bundles at physics travel guide](https://physicstravelguide.com/advanced_tools/fiber_bundles#tab__concrete)

# Conversations with a wood carver

There's a wood carver who lives close to home, whose name is Harish.
I went to speak to him, asking if he would be willing to teach me woodcarving.
It was a very interesting converstaion.

- He argued that wood carving was his caste, and it was impossible for him
  to teach me this, since he learnt it "by practice from birth".
- He also mentioned that his skills were learnt by practice, and not through
  training and were thus un-teachable.
- He felt that it was impossible to pick up the skill anymore since I ddn't
  learn it as a kid.
- His feeling is that the art of wood carving is not respected, and it makes
  much more sense to go learn how to use a CNC .
- We spoke about how the traditional style of woodcarving provided more 
  control, and led to better construction. He said that consumers don't care,
  and resent him for the extra time.
- He oft repeated how he was poor; He wakes up in the morning, takes care 
  of his cows, then begins carving. He might stay up late if there's an urgent
  order.
- None of his children learnt woodcarving either. They seem to be learning
  things like commerce and graphic design. It seems likely that woodcarving
  will die with him.
- He also mentioned how he no longer carves for the local temples, who one would
  expect would be his largest customer base since he specializes in carving
  paraphranelia for idols. It turns out that temples only provide "blessings",
  and no payment.
- When carving beds for gods, one must arrange the bed to be along the natural
  direction of the tree. The feed of the god must be in the direction of the 
  roots, and the head must be towards the sky. Otherwise, the god will not
  accept the tree.
- Towards this, there are many interesting principles of how to learn the
  direction of wood.
- For one, one can use knots in the wood to identify the
  direction of growth.  See the knot in the front and back of a block of wood.
  There will be a directionality to this knot. See that branches grow from low
  to high; So the knot indicates the direction of growth of the tree.
- For another, we can cut a think horizontal slice from the block of wood.
  In the two halves, the splinters will "point upwards" in the slice.

In general, this conversation left me quite dejected about the state of arts
in India. It seems like traditional carpentry in India is dead, and the
"replacements" are of terrible quality. I was also saddened that he so adamantly
believes that it is fundamentally impossible for people to learn carpentry.


# Discrete Riemann Roch

#### Divisors
Function $V \rightarrow \mathbb Z$. We think of this as formal linear combination
of vertices.


#### Degree of a divisor

$deg(D) \equiv \sum_{v \in V} D(v)$.

#### Borrowing and lending at a vertex $v_\star$

- Lending: $v$ gives 1 unit of money to all its neighbours

$$
f' = f + \sum_{vw \in E} -v + w
$$

- Borrowing: $v$ takes 1 unit of money from all its neighbours

$$
f' = f + \sum_{vw \in E} + v - w
$$

#### Borrowing and lending on a set $S$:

- Lending on a set $S$: every vertex $v \in S$ gives 1 unit of money to all its neighbours

$$
f' = f + \sum_{v \in S}\sum_{vw \in E} -v + w
$$

- Borrowing defined similarly.
- See that borrowing at a vertex $v$ is the same as lending from $V / v$.
  The reason being, the lending between vertices of $V/v$ will cancel, and only
  lends into $v$ will be counted. This is the same as $v$ borrowing.


#### Linear equvivalence

Two divisors $D_1, D_2$ are linearly equivalent iff there is a sequence of
borrowing or lending moves that leads from $D_1$ to $D_2$. This is an
equivalence relation on the space of divisors.  Equivalence class of $D_1$
is represented by $[D_1]$.

#### Partial ordering of divisors

We say that $D_1 < D_2$ if for all $v$, $D_1(v) < D_2(v)$. 

#### Effective divisors

A divisor such that $\forall v, D(v) \geq  0$ is called as an effective divisor. Sometimes written
as $D \geq 0$.

Our goal is given a divisor $D$, to check if it is linearly equivalent to
a divisor $D'$ such that $D \geq 0$. If we can do so, then no one is in debt,
and we have won the game.


#### Addition of divisors

We add divisors pointwise: $(f + g)(v) \equiv f(v) + g(v)$.
This respects linear equivalence. Hence, $[D_1] + [D_2] \equiv [D_1 + D_2]$.
This makes divisors, and their equivalence classes an abelian group

#### The Picard Class Group (group of divisor classes)

The group of equivalence classes of divisors  under pointwise addition is
the picard group.

#### Jacobian Class group (divisor classes of degree 0).

- Subgroup of picard group of degree 0.
- That is, all equivalence class elements of degree 0.
- This is well defined because all linearly equivalent divisors (divisors that can be 
  gotten by lending/borrowing) all have the same degree (total money). This is because
  lending/borrowing does not change the total amount of money in the market,
  only redistributes it.


#### Picard group decomposition in terms of Jacobian group

For each $q \in V$, there is an isomorphism of groups $\phi_q: Pic(G) \rightarrow \mathbb Z \times Jac(G)$,
where we send a divisor class $[D]$ to $\phi_q([D]) \equiv (deg(D), [D - deg(D)q]$.

- Clearly, the new divisor $[D - deg(D)q]$ has total degree $0$, since $deg(D)$
  has been subtracted off at $q$.
- We can recover the original divisor since we know $deg(D)$.



#### Complete linear system $[D]_{\geq 0}|$

The complete linear system of $D$ is the set of all winning configurations from $D$.
That is:

$$
[D]_{\geq 0} \equiv \{ E \in [D] : E \geq 0 \}
$$

We win the game if $[D]_{\geq 0}$ is nonempty.


#### The discrete laplacian

The laplacian is the map $L: (V \rightarrow \mathbb Z) \rightarrow (V \rightarrow \mathbb Z)$
defined by:

$$
L(f)(v) \equiv \sum_{vw \in E} (f(v) - f(w))
$$

That is, $L(f)(v)$ is the total **deviation** of $v$ from all of its neighbours $w$.

#### Firing script

A firing script is a function $s: V \rightarrow \mathbb Z$ ($s$ for script) that
tells us how many times $v$ lends money to its neighbours).


- The collection of all firing scripts form an abelian group, and is denoted
  by $M(G)$. [TODO: why $M$?]


- Set lending by a subset $W \subset V$ is denoted by $\chi_W$, where $\chi_W(v) \equiv 1$ if $v \in W$
 and $\chi_W(v) \equiv 0$ otherwise. Written in iverson notation, we have $\chi_W(v) \equiv [v \in_? W]$.


- The effect of running a firing script $s$ on a divisor $D$ to get a divisor $D'$ is:


$$
\begin{aligned}
D' \equiv D + \sum_{v \in V} s(v) (-v+ w) \\
\end{aligned}
$$


if $s: V \rightarrow \mathbb Z$ is a firing script, then the divisor of the
firing script $s$ is:

$$
div(s) \equiv  \sum_{v \in V} s(v) (-v+ w)
$$

- The effect of running a firing script is to replace a divisor $D$ by a new
  divisor $D' = D + div(s)$. We denote this by $D \xrightarrow{s} D'$ and call
  this as **script-firing**

#### `div` is a group homomorphism

We see that `div` is a function from $M(G) =  V \rightarrow \Z$ to  $Div(G) = V \rightarrow \Z$
under the map:

$$
div(s) \equiv  \sum_{v \in V} s(v) (-v+ w)
$$

We show that $div(s_1 - s_2) = div(s_1) - div(s_2)$ thereby checking the homomorphism
property.

$$
\begin{aligned}
&div(s_1 - s_2) =  \sum_{v \in V} (s_1 - s_2)(v) (-v+ w) \\
&= \sum_{v \in V} (s_1(v) - s_2(v)) (-v+ w)  \\
&= \sum_{v \in V} s_1(v) (-v+ w)  - \sum_{v \in V} s_2(v) (-v+ w)  \\
&= div(s_1) - div(s_2)
\end{aligned}
$$

and is hence a group homomorphism.


#### `div` produces divisors of degree 0: `deg(div(s)) = 0`.

See that $div$ is balanced, in that for every $-v$ we have a $+w$. This makes
the total degree zero.

#### Principal divisors: $Prin(G) \equiv div(M(G))$.

- Divisors of the form `div(s)` are called as **Principal divisors**. They are a 
  subgroup of the degree 0 divisors.

- Moreover, if $D'$ is obtainable from $D$ by a series of lending and borrowing 
  moves, then $D' - D \in Prin(G)$.
- This means that linear equivalence is a coset of the principal divisors: $[D] = D + Prin(G)$.

#### Picard, Jacobian Class group  as quotients

- $Pic(G) = Div(G)/Prin(G)$.
- $Jac(G) = Div^0(G)/Prin(G)$.
- $Pic(G), Jac(G)$ are class groups because we get equivalence classes of divisors,
  equivalent upto principal divisors.


#### `div` is same as laplacian

<img src='./static/discrete-riemann-roch/laplacian-lending.png'>

#### Picard group is cokernel of L

Recall that `Pic(G) = Div(G)/Prin(G)`, where `Prin(G)` was the collection of
divisors that could be realised from a firing script.  That is,

$$
Prin(G) \equiv \{ div(s) : s \in V \rightarrow \mathbb Z \}
$$

```
M(G) -div→ Div(G) -quotient→ Pic(G) → 0
|          |
f          g
|          |
v          v
Z^n  -L→   Z^n   -quotient'→ cok(L) ~= Z^n/Im L → 0
```

- The quotient map `quotient` is surjective.
- The map `quotient'` is also surjective

#### Dollar game in terms of laplacian

given a divisor $D$, does there exist a vector $x \in \mathbb Z^V$
such that $D + Lx \geq 0$?

Clearly, this is some sort of linear inequality. So, we expect polytopes
to show up! Since $x$ is an integer point, we want integer points in polytopes.

#### Kernel of laplacian in connected graph: all 1s vector
                                                    
- first of all, see that lending by everyone in $V$ has no effect:
  everyone lends to all their neighbours, and all their neighbours lend to them,
  having zero net effect.

- Stated in terms of the firing script, this means that $s_1 + s_2 + \dots s_n$
  is in the kernel of $div$: the firing script creates a zero divisor. If we 
  choose a basis, this is the all 1s vector.

- In terms of the laplacian, this is stating that the all ones vector is in
  the kernel of the laplacian.


#### Kernel of laplacian in connected graph: constant functions (TODO)

Suppose we have a script $s: V \rightarrow \mathbb Z$ such that $div(s) = 0$.

**TODO **


> This feels sheafy to me, in terms of "locally constant".


#### Reduced laplacian: Configurations on $G$

We build reduced laplacians to relate the jacobian (degree zero elements of divisor class group)
and the laplacian.

Fix a vertex $q \in V$. Define $\tilde{V} \equiv V /\{q\}$. A configuration 
on $G$ with respect to $q$ is an element of the subgroup

$$
Config(G, q) \equiv \mathbb Z \tilde{V} \subseteq ZV = Div(G)
$$

so we simply forget the value at $q$. Alternatively, we set the value of $q$
to zero and continue will our divisor definitions.

We can perform lending and borrowing on a configuration divisor, by simply
not tracking data at $q$.

#### 3: Winning

#### q-reduced configurations

We wish to solve the game by benelovence: have vertices lend to adjacent vertices.
Here are the steps to convert such an intuition to a real algorithm:

1. Start with a divisor $D$ we want to find an effective divisor $E \geq 0$
   that $D$ is linearly equivalent to (ie, there exists a series of moves to convert $D$ to $E$).
2. Pick some benelovent vertex $q \in V$. Call $q$ the source. Let $V' = V/q$ be the non
   source vertices.
3. Let $q$ lend so much money to the non-source-vertices, such that the non-source-vertices,
   sharing amongst themselves, are out of debt. 
4. Now only $q$ is in debt from this giving. $q$ makes no lending or borrowing moves.
   The non-source-vertices must get $q$ out of debt. Find a $S \subseteq V'$ such that if
   everyone in $S$ lends, then no one in $S$ go into debt. Make the corresponding set-lending
   move. Repeat until no such $S$ remains. The resulting divisor is said to be $q$-reduced.

In the end, if $q$ is no longer in debt, we win. Otherwise, $D$ is unwinnable.



#### Superstable configuration

Let $c \in Config(G, q)$. It is called superstable if $c \geq 0$ and has
no legal non-empty set firings. That is, for each non-empty $S \subseteq V/q$,
we have some $v \in S$ such that firing $v$ would cause $v$ to go into debt;
that is, $c(v) < outdeg_S(v)$.

#### Decomposition of divisor into superstable configuration

Every divisor can be written as $D = c + kq$ where $c \in Config(G, q) \geq 0$.
In this form, $D$ is $q$-reduced iff $c$ is superstable! This follows
from the definition of $q$-reduced: there is no subset $S$ which can be fired such
that $S$ stays out of debt. Now, if $q \geq 0$, then we win, from what we know
of $q$-reduced configurations.


  
#### 4: Acylic orientations
#### Orientations

An orientation of a graph makes each edge directed. We think of edges now as 
tuples $e \equiv (u, v)$ as an edge from $u$ to $v$. We denote $e^- = u$ and
$e^+ = v$ to be the source and sink vertices of the orientation.


#### Acylic orientations

An orientation is acyclic if there are no cycles. Every acylic orientation
must have at least one sink and a source. It must have **at least one source**.
Assume the acyclic orientation does not have any sources. 

#### Acylic orientation has at least one source

Pick any vertex . If it is a source, done. If it is not a source, it has a parent.
Go to parent that has NOT BEEN PICKED YET, repeat check. We will eventually:

- Find a source  vertex (vertex with no parent)
- All parents of current vertex have been picked  (ie, we find a cycle). Can't
  happen.

Thus all acyclic orientations have at least one source.


#### Indegree sequence of an acyclic orientation.

If $O$ is an orientation, define 

$$
indeg_O(u) \equiv |\{ e \in O : e^+ = u \}|
$$

That is, to each $u$, associate the number of edges whose end is at $u$.

#### WRONG: Acylic orientation determined by indegree sequence?

The book claims that acyclic orientation is determined by the indegree sequence.
I don't believe this. Consider the graph $G$:

```
--a--
|   |
v   v
b   c
```

- This has indegrees  $(a=0, b=1,c=1)$. 

Now consider $H$:

```
a
|
v
b
|
v
c
```

- This has indegrees  $(a=0, b=1, c=1)$ but the graphs are not equal!

#### Acylic orientation determined by indegree sequence

OK, the above is not what the book claims. The book claims that two orientations
$O_G$, $O'_G$ **of the same graph** are equal if their indegree sequences
are equal. 

This is believeable, because if the orientations point differently, their
indegrees will change.

- Proof strategy: induction on number of vertices + forcing sources to be the same + creating new  sources
  by removing current sources.

- Theorem is immediate with only one vertex. Assume holds for $n$. Now we have
  a graph with $(n+1)$ vertices. Find source in acyclic orientation $O_G$. This has
  no incoming edges, so has indegree zero. This must be the same in $O'_G$ since
  $O_G$ and $O'_G$ have the same indegree sequence. 

- Now remove the sources that are structurally equal. We get a graph of $H$ of
  (n-1) vertices, and we get $O_H$ and $O'_H$ by removing the sources 
  from $O_G, O_G'$. Since $O_G = O_G'$ we must have that $O_H = O_H'$ since removing
  the same source from both graphs modifes the orientations the same way. Recurse
  into $O_H, O_H'$.

#### Divisor for an orientation

For an orientation $O$ we define a divisor $D(O)$ as:

$$
D(O) \equiv \sum_{v \in V}(indeg_O(v) - 1) v
$$

#### 5: Riemann roch

#### The rank function

In one sense, the “degree of winnability” of the dollar game is measured by the size
of complete linear systems: $D$ is “more winnable” than $D'$ if 
$[D]_{\geq 0} > [D']_{\geq 0}$. Instead of measuring $[D]_{\geq 0}$, we choose to
define another function, the rank, that measures "stability/robustness of winnability"

- Fist, $r(D) \equiv -1$ if $D$ is unwinnable: $r(D) \equiv 0$ iff $[D]_{\geq 0} = \emptyset$
- Next, $r(D) = 1$ if $D$ is barely winnable.  That is, $D$ is winnable, but 
  there is *some* vertex $v$ such that $D - v$ is unwinnable. That is, $r(D)$
  is barely winnable if the ability to win at $D$ can be destroyed by a single
  vertex losing a dollar.

- In general, for $k \geq 0$, define that $r$ is at least $k$ winnable if the dollar
  game is winnable strating from all divisors obtained from $D$ by removing $k$
  dollars. Formally, this becomes:

$$
r(D) \geq k \iff |D - E| \neq \emptyset \text{for all $E \geq 0$ ($E$ effective) of degree $k$}
$$

This means that $r(D) = l$ if there is some divisor $E$ of degree $l+1$ such that $D - E$ is
not winnable.

#### $r(D)$ is upper bounded by degree: $r(D) \leq deg(D)$
#### if $D$ is of degree 0, then rank is 0 iff $D$ is principal
#### $r(D) \leq r(D + v) \leq r(D) + 1$: adding a dollar can increase rank by at most 1
#### $r(D + D') \geq r(D) + r(D')$: rank is super-linear.
#### Lower bound on rank: $r(D) \geq deg(D) - g$

Won't prove this here, depends on other results (if $deg(D) \geq g$, then $D$ is winnable)



                                                
#### Canonical divisor

For any orientation $O$, define $O_{rev}$ to be the reversed orientation. Now
define the canonical divisor $K$ to be $K \equiv D(O) + D(O_{rev})$. See that
for every $v \in V$:

$$
\begin{aligned}
K(V) = indeg_O(v) + outdeg_O(v) = deg_G(v)
\end{aligned}
$$

#### References

- [This answer on mathoverflow that asks about how to understand divisors of elliptic curves](https://mathoverflow.net/a/322850/123769)
- [Specialization of linear systems from groups to graphs](https://arxiv.org/pdf/math/0701075.pdf)
- [riemann-roch and abel-jacobi theory on a finite graph](https://arxiv.org/pdf/math/0608360v3.pdf)
- [Divisors and Sandpiles: An Introduction to Chip-Firing](https://bookstore.ams.org/mbk-114/)


# Conversation with Olaf Klinke

> do you have reading you'd recommend to gain your viewpoint of
> computation-as-topology-as-computation?

I am a topologist, a domain theorist to be more precise. I had the
privilege to meet many founders of this relatively young field of
mathematics. Domain theory is a denotational semantics (there are
others) of lambda calculus. For reading, there is the old testament and
the new testament, as I call it. The old testament is 
"A compendium of continuous lattices"
ISBN 3-540-10111-X                                          
ISBN 0-387-10111-X
The new testament is
"Continuous lattices and domains"
ISBN 0-521-80338-1

Domain theory makes sense once one stops disregarding bottom _|_, or
undefined. Think of domains as triangular objects, e.g. the type Bool

```
False   True
    \   /
     _|_
```

How does one compute a real number? Think of a horizontal real
interval, and draw a triangle underneath:

```
---[---]---
\   \ /   /
 \   .   /
  \     /
   \   /
    _|_
```

Every point in the triangle represents a closed interval. At the top is
a copy of the real numbers in the form of singleton intervals, the
"total" elements. Every point underneath is a proper interval,
representing everything reachable by "fanning out" upward from that
point. This may be a model for e.g. interval arithmetic, where
computing a more precise result means moving up in the triangular
domain of intervals. Directed suprema (results of recursive
computations) in this domain are nested intersections of intervals.
Existence of these directed suprema is equivalent to the uniqueness and
non-emptyness of the nested intersections, which again is guaranteed by
the two topological properties "Hausfdorff" and "compactness" of the
closed real interval.

A treasure trove of smart little Haskell programs is 
[Martín Escardó's so-called Barbados notes, number 46 in `https://www.cs.bham.ac.uk/~mhe/papers/index.html`](https://www.cs.bham.ac.uk/~mhe/papers/index.html)


# Topological groups and languages

[MonoidNull](http://hackage.haskell.org/package/monoid-subclasses/docs/Data-Monoid-Null.html) is a monoid
that allow us to test for `mempty`. So it obeys the law:

```hs
class Monoid m => MonoidNull m where
    null :: Monoid m => m -> Bool
    -- null x == x == mempty
```

There are `MonoidNull`s that don't have an `Eq` instance. For example, consider
`Maybe (Int -> Int)`, where the monoid over `(Int -> Int)` adds them pointwise.
Clearly, we can't tell when two functions are equal, so there's no way we can
give an `Eq` instance to `Maybe (Int -> Int)`. But we can definitely tell
when it's `Nothing`! So we have a `MonoidNull` instance without an `Eq`
instance.


Now the interesting thing is that if we have a group that has `MonoidNull`,
then it automatically has `Eq`! Witness:

```hs
instance (Group g, MonoidNull g) => Eq g where
   x == y = null (x <> inv y)
```

See that this is a transport principle: we're able to transport the test
of equality at the origin/`mempty` provided by `null` to any point in the
group.


Olaf Klinke remarked:

> A beautiful example of topological groups: Their topology is completely
> determined by the neighbourhoods of the identity element. If the
> identity element is isolated, the entire group is discrete. 

I found this very interesting, because he's vieweing this from the
"topology of computation" lens, where the existence of `null` means that
the identity element is isolated. Now since it is a topological group (group
operations are continuous since everything is computable!),
the isolatedness of the identity transports to all points, giving us a discrete
object where equality is decidable! Below is an illustration of how I imagine
the situation.


<img src='./static/olaf-topological-groups.png' />



#### References
- [Post on haskell-cafe by Olaf Klinke](https://mail.haskell.org/pipermail/haskell-cafe/2020-December/133264.html)


# The mnemonica stack (TODO)

```
4  c♣
2  h♡ 
7  d♢
3  c♣
4  h♡
6  d♢
A  s♠
5  h♡
9  s♠
2  s♠
Q  h♡
3  d♢
Q  c♣
8  h♡
6  s♠
5  s♠
9  h♡
K  c♣
2  d♢
J  h♡
3  s♠
8  s♠
6  h♡
10 c♣
5  d♢
K  c♣
2  s♠
3  h♡
8  d♢
5  c♣
K  s♠
J  d♢
8  c♣
10 s♠
K  h♡
J  c♣
7  s♠
10 h♡
A  d♢
4  s♠
7  h♡
4  d♢
A  c♣
9  c♣
J  s♠
Q  d♢
7  c♣
Q  s♠
10 d♢
6  c♣
A  h♡
9  d♢
```


- [YouTubevideo with chant](https://www.youtube.com/watch?v=-QXy489NocE)



# Conversation with Alok about how I read

Alok Debnath, a friend of mine claims he understood "how I read" based on 
reading infinite jest and setting me experiments that allowed him to observe
how I read.

In his words:

> Alok: I have seen you spasm on your cursor trying to read text (TODO: get a longer
> quote form alok about what this means)


He said that he never understood what the fuck I was doing until he read
Infinite Jest by David Foster Wallace (a phenomenal book, I loved it and recommended it to him, 
which were enough recommendations to get him to read it, it seems).

#### Infinite jest

> Alok: It took me reading that book twice to understand how you process text.
> Let's deep dive.  You don't read sentences, from what I remember. You have a
> different model of chunking text.  For what it's worth, I tried to remember
> what you spasm between when skimming vs when reading. There does not seem to
> be much difference between those modes for you, which was interesting. So I
> tried to note why you would sometimes go BACK rather than read sentence to
> sentence. I figured it was one of three things:


The three things are:

> 1. You went from verb to verb or action to action, or event to event, and
>   then determined the significance of that event. You would move backwards
>   only if the verb was significant enough to warrant its arguments being
>   understood
> 2. You went from topic to topic, and would only go BACK if you think you
>    missed a timestep in the movement between topics.
> 3. You read from line to line, regardless of the sentence, phrase, clause or
>    syntactic structure, and would only go back if an item caught your
>    attention.

According to him, I do a combination of 1 and 2, in contrast to others who
might do (3).

#### Why this works for me

> you are uniquely adaptive to reading style, based on very little information.
> This is a good thing when there is a unique, singular style to the entire
> article, it is easy to templatize and then retrofit into how you want to get
> that information. 

#### His take on my take on why SEP is trash

> I ran a series of experiments to figure this out. I'd ask you to read a
> paper, a textbook chapter or something in front of me, and after you'd read a
> paragraph, ask you to explain it. Some times you were already reading
> something (mostly philosophy related) and that's ambush.  Lastly, I used SEP as
> bait .SEP has not been written for people like you. And I was thoroughly
> surprised at your vehement disapproval to some of the articles
> (for their content ofc), but your veiled stylistic inputs as well.

> you mentioned that the text [of the SEP article on Derrida]() was malformed,
> which is a stylistic input, rather than a content issue.

He figured out that the SEP entry has been written in two merged styles - one is
a list of topics that Derrida talks about The other is a list of events which
weave together how those topics became tenets of his philosophy.  The style of
writing generally based on the modern notion of "set-inductive" introductions
to topics Which doesn't work well with you. Because I then noticed how you read
code And I figured that you need to have a trace of the topics talked about in
case they appear again in the code, and you parse blocks, retrieve need, GC,
and move on to the next block. So order of arguments and the state of these
topics remains in your mind, along with significant events.
debnatak: You read text in a similar way, which is why set inductive writing is
the worst way to write for you.



##### Inductive writing
 Apparently, this is a common philosophy of teaching where one is exposed
to a topic by "forewarning" them of all the subtopics, then a narrative is
weaved exploring the relationship between each subtopic, explaining them as
they come.  It's the style in which school textbooks are written.  So it is
neither ordered by event, nor ordered by topic. It's the job of the teacher to
guide the student across the text.


> Now, the Derrida SEP article is written in a very similar manner, albeit a
> bit more well formed in narrative The text is not written in a manner where
> you can parse things by topic(i.e.  first deconstructionism, then
> universality, then sovereignty) or by event (publishing book1 , then 2, then
> 3 or whatever). Therefore, this writing style is completely adverserial to
> your reading style!


##### Why I enjoy DFW and infinite jest

> Infinite Jest, and DFW in general, clearly does not write like this. It is the antithesis, almost
> Your insane experience in garbage collection works when there are a large
> number of interconnected stories, people and threads being referenced in the
> same sentence.Given that you chunk differently, parse differently, and
> organise mental notes on what you have read differently than I do, it is not
> surprising that you understood DFW fairly well.
> DFWs writing style almost wholeheartedly abandons prescriptivist notions of
> punctuation and syntactic structure beyond the meager subject verb agreement,
> Which I think is also abandoned in some monologues.
> That would not be a large issue for someone who does not use punctuation as a
> mechanism of parsing sentence information, or even as an anchor of "begin
> here" and "end here".

##### Inference from me reading code?

According to him, this is similar to how I read code:

> I saw you read word2vec.c in front of me And I was mindfucked at how you
> abstract information on the go Like you read bracket to bracket (I think),
> and keep track of "important" variables, especially function arguments and
> return values, and just summarize the rest debnatak: Not every operation
> needs to be understood, of course. But it is noted regardless. Functions are
> skipped over if not called, variables are ignored if not used.  debnatak: You
> were never confused about the program flow debnatak: Idk, it seemed clean for
> code, and math ofc because representations


##### eye tracking data


# KMP (Knuth, Morris, Pratt) (TODO)

#### References
- [KMP in haskell](https://chaoxuprime.com/posts/2014-04-11-the-kmp-algorithm-in-haskell.html)
- [String algorithms: Borders, KMP: video](https://www.youtube.com/watch?v=-YdOWEpZEfc)
- [Geometric point pattern matching](http://www.jucs.org/jucs_16_14/geometric_point_pattern_matching/jucs_16_14_1902_1911_ukkonen.pdf)

# Reading C declarations

> The real rule turns out to be simple (although non-obvious): "Declaration
> matches usage." So, for example, if you want a pointer to a function
> returning a pointer to an array of 3 integers, you'd want

```
(*(*f)())[3 - 1]
```

> to evaluate to an int, so the declaration would be

```cpp
int (*(*f)())[3];
```



# Make mnemonics

- `$@`: target, since it looks like a target.
- `$<`: the 1st prereq, since `<` points to the left.
- `$^`: all prereqs, since `^` looks like an "upward grouping flower bracket".
- `$?`: prereqs that are *newer* than the target, since `?` is stuff you don't know / haven't looked at.
- `$*`: target with *suffix deleted*, since we generally grep for `*.c|h|`, we want the `*` part of `$@`.
   Alternatively, `*` is also like a target, but only the bull's eye with the extra stuff like the suffix
   stripped out.

- [The POSIX makefile page which is WAY more readable](https://pubs.opengroup.org/onlinepubs/9699919799/utilities/make.html)
- [notes for new make users](http://gromnitsky.users.sourceforge.net/articles/notes-for-new-make-users/#4b6d995-automatic-variables)

# Vandermonde and FFT


FFT lets you do the following:

You are given two sequences: `a0,...,an` and `b0,...,bm` Compute sequence `c0,…,c[n+m]` such that
$$c[i]=a[0]b[i]+a[1]b[i−1]+ \dots +a[i−1]b[1]+a[i]b[0]$$

This is exactly what I needed here, where $a[i]= \binom{n}{i}$ and $b[i]= \binom{m}{i}$.
If I thought for a little longer I would realize that $c[i]=\binom{n+m}{i}$
instead of computing it using FFT.

#### References

- [Codeforces contest comment by Swistakk)[https://codeforces.com/blog/entry/85348?#comment-730898]

# Thoughts on blitz chess: 950 ELO

I plan on summarizing my current thoughts on chess at different stages of ELO
on Lichess.  This should be fun to look back on. Currently, I found that the
thing that helps me the *most* when it comes to winning is this simple kernel:

> Attack. 

With the somewhat useful addendum:

> With a plan.

That's it. That's literally all I need to do. I generally try to focus on the
weak `f` pawn, get my Queen out early (people at my ELO rating don't really know
how to punish an early roaming queen. I don't know either!), at just attack.

If there's an attack on your pieces, *don't defend, counter-attack*. Of course,
there are situations where one _must_ defend. Only defend then. 

Getting into this frame of reference stopped me from languishing at ~800 ELO. 
I used to
- get anxious about the *game* and the prospect of conflict.
- get anxious about the clock.
- get anxious about leaving pieces hanging.

It seems that "getting over" these anxieties took ~20 games, after which I could
focus on the mechanics. This is a good reference point, since I have the same
problem with competitive programming --- the exact same anxieties, in fact.

# Periodic tables and make illegal states unrepresentable

The periodic table of elements succeeded because the "gaps" in the table
consisted of only legal atoms --- thus, by making illegal states unrepresentable,
a table of the current state of knowledge becomes valuable because all the
*gaps* are legal states. The exact same thing happened with juggling and
juggling notattion.


# Big list of questions on the structure of graphs

I've been trying to get more of a feeling for graphs lately, so I'm collecting
sources of "structural" questions of graphs and answers for these questions.

> Q. Is it possible in an unweighted graph, there is exactly one unique shortest
> path tree for a node u but more than one such shortest path tree for some
> other node v ?

> Q. Can I orient the edges of a bridge-less undirected bipartite graph with even
> no. of nodes such that all the nodes are in a cycle ?  


# Combinations notation in bijective combinatorics

They explicitly write $nCr$ as $[n]C[r, n-r]$. This makes it better for
"future uses", where it explicitly allows us to think of $[n]C[x, y]$ as
breaking $n$ into $x$ things we choose and $y$ things we don't choose.

This makes the recurrence:

$$
[n]C[r] = [n-1]C[r-1] + [n-1]C[r]
$$

look as:

$$
[n]C[r,n-r] = [n-1]C[r-1,n-r] + [n-1]C[r, n-r-1]
$$

That is, we are reducing on either the first component ($r-1$) or on the
second component ($n-r-1$), in the smaller set ($n-1$).



# Arguments for little endian
Say we wish to store `<MSB> 100 200 300 400 <LSB>`. In little endian, this would be
stored as:

```
ix:   0   1   2   3
val:  400 300 200 100
```

An interesting theory for why this is good is if we want to treat this 4-bit
data as 1-bit data, we want the subarray `[400]`. It's easier to *directly*
acess in little endian as just `data[0]`, instead of in big endian where
it would be `data[3]`. So, storing stuff backwards makes it easier to chop off
the LSBs data, since that's the _suffix_. 

# Expectiles


Mean is a minimiser of $L_2$ norm: it minimizes the loss of penalizing your
'prediction' of (many instances of) a random quantity. You can assume that the
instances will be revealed after you have made the prediction. 

If your prediction is over/larger by $e$ you will be penalized by $e^2$.
If your prediction is lower by $e$
then also the penalty is $e^2$. This makes mean symmetric. It punishes
overestimates the same way as underestimates.  


Now, if you were to be punished
by absolute value $|e|$ as opposed to $e^2$ then median would be your best
prediction.

Lets denote the error by $e_+$ if the error is an over-estimate and
$e_-$ if its under. Both $e++$ and $e_-$ are non-negative. Now if the penalties were to
be $e_+ + a e+-$ that would have led to the different quantiles depending on
the values of $a > 0$. Note $a \neq 1$ introduces the asymmetry.  

If you were to do introduce a similar asymmetric treatment of $e_+^2$ and
$e_-^2$ that would have given rise to expectiles.



# Depth first search through linear algebra (TODO)


#### References
- [Talk Video](https://www.youtube.com/watch?v=fKim6IKdr8U)
- [Link to paper](https://dl.acm.org/doi/pdf/10.1145/3315454.3329962)

# 2-SAT

First break into SCC's. Each SCC represents equivalence: since there is a
path from every variable to every other variable, they must take on the
exact same value. Hence if $x$ and $\lnot x$ are in the same SCC, we don't
have a solution, because this means that $\texttt{true} = \texttt{false}$
or $\texttt{false} = \texttt{true}$. 

Let's say we find SCC's where this does not happen. Now, zoom out and think of
the condensation DAG. We want to assign true/false to each node in the SCC DAG.
How should we assign true/false? Say that $x$ and $\lnot x$ are in two
different components. So this means that we have the possible orderings
- $x \implies \lnot x$: $\texttt{true} \implies \texttt{false}$ (Inconsistent!)
- $x \implies \lnot x$: $\texttt{false} \implies \texttt{true}$ (Consistent, principle of explosion)

Hence, if $x$ implies $\lnot x$, we should set $x$ to $\texttt{false}$. The other
assignment is _inconsistent_.

# Longest increasing subsequence, step by step (TODO)
- [The science of Programming by Gries](https://www.cs.cornell.edu/gries/July2016/The-Science-Of-Programming-Gries-038790641X.pdf)

# On reading how to rule (TODO)
#### The prince

#### Arthashastra

#### The book of lord shang


# Strongly Connected Components via Kosaraju's algorithm

We know that a directed graph can be written as two-levels, a top-level dag,
with each node in the DAG being a condensation of the original graph. So 
we wish to discover the DAG, and then each condensation. We wish to
view Kosaraju's algorithm as a "stronger topological sort" that works
for general graphs, and not just DAGs.

#### Step 1: Discover the tree/DAG

Run a bog standard DFS on the graph and record entry and exit times,
because that tell us everything we need to know about the DFS. Let's decide
what to keep and throw away next.

#### Step 2: Think

If we had a DAG, then we would be done; We sort the nodes according
to descending order of exit times, and we get the topological order
of the DAG. However, this is incorrect for our purposes, as this
only gives us the components if we don't have cycles.

#### Step 3: Mix in cycle detection/single SSC


Pick the first node according the topological sort heurstic --- the node
that's earliest according to exit time. We now need to discover cycles.
Recall that we built the DAG according to DFS order, so if we run a DFS
again, we'll get the entire subtree in the DAG! Rather, we want the
"anti DFS": whatever can reach the 'root' of the 'DAG'. To find this,
we reverse the DAG and find the component reachable from here.

#### SCC's as adjunction
I learnt this from Benjamin Pierce's  "Category theory for computer scientists":

> The strong components of a graph themselves form an acyclic graph
> that is a quotient of the original graph-that is, each node corresponds
> to an equivalence class of strongly connected nodes in the original. The
> mapping taking a graph to the acyclic graph of its strongly connected
> components may be expressed as a left adjoint to the inclusion functor
> from AcyclicGraph to Graph


#### References
- [CS Cornell lecture notes](https://www.cs.cornell.edu/courses/cs410/1998su/Lectures/lect24.txt)


# Articulation points

I find DFS fascinating, and honestly insane for how much structral
information of the graph it manages to retain. 

> A vertex $v$ is an articulation point of a graph $G$ if the removal
> of $v$ disconnects the induced subgraph.

#### Tactic 1 - Inductively

We first solve the super easy case with the root, and then try to see
if we can treat other cases like the root node case, then we're good.
Here, we are given an graph $G$, and we are thinking about a DFS tree 
$T_G$ of the graph $G$.

#### Thinking about the root

When is the root an articulation point? If the root has multiple children,
then it is an articulation point; If we remove the root, then it disconnects
the children. This is because we have an undirected graph, where we only have
back edges, and no cross edges. A back edge can only go from a node to its
ancestor. If we remove the root, the back edges cannot save us, for there is
no ancestor _higher than the root_ to act as an alternate path

#### Non root vertex

When is a non root vertex $v$ an articulation point? When there is *some* child
$w$ of $v$ such that the subtree of $w$ cannot escape the subtree of $v$.
That is, all back edges from $w$ do not go above $v$. If we were to now
remove $v$, then $w$ would be disconnected from the rest of the graph.

> Alternate phrasing: When all cycles in the subtree of $w$ are within the
> subtree of $v$. This means that the backedges cannot go above $v$.
> If $w$ could build a cycle that goes above $v$, then $v$ would not be an
> articulation point, because it'll be involved in some cycle 
> $v \mapsto  w \mapsto \mapsto p \mapsto v$, which gives us an alternative path
> to reach $w$ even if $v$ is removed.


One way to imagine this maybe to imagine $v$ as the new root, and the other
stuff that's above $v$ to be to the left of $w$. That way, if we could go to $w$,
we get a cross edge from the "new root"(v) and the "other section" (the part
that's connected by a cross edge). If we prevent the existence of these 
"fake cross edges", we're golden, and $v$ is then an articulation point.

#### Tactic 2 - Structurally / Characterization

Next we follow a "mathematical" development, where we build theorems
to characterize k-connectedness and use this to guide our algorithm design

#### Menger's theorem

Let $G$ be a connected undirected graph. Let $u, v$ be two non-adjacent
vertices.  The minimum number of vertices whose removal from $G$ disconnects
$u$ and $v$ is equal to the **maximal number of vertex disjoint paths** from $v$
to $u$.

#### Whitney's theorem (corollary)

An undirected graph is $k$ connected iff $k$ vertices must be removed to
disconnect the graph.

#### Biconnected components

Menger's theorem tells us that a graph is not biconnected **iff** we can find a vertex
whose removal disconnected the graph. Such a vertex is an articulation vertex.

> A biconnected component is a maximal subset of edges, such that the induced
> subgraph is biconnected. Vertices can belong to many components;
> Indeeed, articulation vertices are those that belong to more than one component.

<img src="./static/structure-of-non-biconnected-graph.png"/>


#### Lemma: Characterization of biconnected components

> Two edges belong to the same biconnected component iff there is a cycle
> containing both of them.
> [This lemma is silent about biconnected components of single edges]

We show that a cycle is always contained in a single binconnected component.
If a cycle contains edges from more than one biconnected component, then we can
"fuse" the biconnected components together into a single, larger, biconnected
component.


#### Lemma: Each edge belongs to exactly one biconnected component


#### Tactic 3 - 'Intuitively'

We look at pictures and try to figure out how to do this.

#### DFS for articulation vertices - undirected:

<img src="./static/articulation-vertex-undirected.png"/>
                                                                                                                        
- The connectivity of a graph is the smallest number of vertices that need to
  be deleted to disconnect the graph.
- If the graph has an articulation vertex, the connectivity is 1. More robust
  graphs that don't have a single point of failure/articulation vertex are
  said to be *binconnected*.
- To test for an articulation vertex by brute force, delete each vertex,
  and check if the graph has disconnected into components. this is $O(V(V+E))$ time.

> Joke: an articulate vertex is one that speaks very well, and is thus important
> to the functioning of the graph. If it is killed, it will disconnect society,
> as there is no one to fulfil its ability to cross barriers with its eloquent
> speech.

#### Articulation vertices on the DFS tree - undirected

- If we think of only the DFS tree for a moment of an undirected graph 
  and ignore all other edges, then
  all interneal non-leaf vertices become articulation vertices, because they
  disconnect the graph into two parts: the part below them (for concreteness,
  think of a child leaf), and the root component. 

- Blowing up a leaf has no effect, since it does not connect two *components*, 
  a leaf only connects itself to the main tree.


- The root of the tree is special; If it has only one child, then it acts like
  a leaf, since the root connects itself to the only component. On the other
  hand, if there are multiple components, then the root acts like an internal
  node, holding these different components together, making the root an
  articulation vertex.

#### Articulation vertices on the DFS graph - undireced

- DFS of a general undirected graph also contains *back edges*. These act as
  security cables that link a vertex back to its ancestor. The security
  cable from `x` to `y` ensures that none of the nodes on the path `[x..y]`
  can be articulation vertices.

- So, to find articulation vertices, we need to see how far back 
  the security cables go.

```cpp
int anc[V]; int dfs_outdeg[V];
void processs_vertex_early(int v) { anc[v] = v; }
void process_edge(int x, int y) {
  if (dfsedge[x][y].type == TREE) { dfs_outdeg[x]++; }
  // y <-*
  //     |
  //     BACK
  //     |
  // x --*
  if (dfsedge[x][y].type == BACK && (parent[y] != x)) { 
     if(entry_time[y] < entry_time[anc[x]]) {
       anc[x] = y;
     }
  }
}
```


<img src="./static/articulation-vertices-undirected-3-cases.png"/>

> In a DFS tree, a vertex v (other than the root) is an articulation
> vertex iff v is not a leaf and some subtree of v has no back edge incident
> until a proper ancestor of v.

#### References

- Udi Manber: Introduction to algorithms: A creative approach.
- Steven Skeina: The algorithm design manual.
- [Codeforces: problems to solve](https://codeforces.com/blog/entry/23617)
- [A2OJ articulation point problems](https://a2oj.com/category?ID=64)
- [INOI advanced graph algorithms](https://www.iarcs.org.in/inoi/online-study-material/topics/articulation-points.php)

# Disjoint set union

#### intuition for correctness of `rank`:

Assume that we had to re-point pointers of all our children to the
new root when we decide to make another node the root. That is,
we would have:

```
void mkroot(int newroot, int prevroot) {
   for (int child : children[prevroot] {
        parent[child] = newroot;
   }
   parent[prevroot] = newroot];
   children[prevroot] = {}; // this has no children anymore
}
```

- In this setting, we ought to make the *smaller* subtree the `prevroot`
  and the *larger* subtree the `newroot`: It is better to loop over
  fewer children.

- When we perform the `rank` based union, we are using the *same heuristic*,
  even though we don't actually loop over all our children.


# Making GDB usable

- Use [GEF](https://github.com/hugsy/gef)

# Bouncing light clock is an hourglass

I've always disliked the "clocks" that are used in special relativity,
because a clock attempts to measure something absolute, rather than something
relative. So, we should rather use hour glasses. In an hour glass, we can 
only measure *intervals* of time. 

<br/>

Now, when we have such an hourglass, we should fill the hourglass with
*photons*, because their speed of falling is invariant for all reference frames.
So, what we need is the ability to create an hourglass worth of photons which
we keep dripping down, once the photon at the funnel has reached the bottom.

<br/>

This is *exactly* what the two mirror photon clock does --- it bounces a photon
between two mirrors. We can look at this as us "flipping" the hourglass
once the photon reaches the bottom of the hourglass. 

# Euler tours 

#### Tucker's proof: undirected graph with all even degree has an euler tour

I find this proof much more intuitive because it's extremely clear where
the even condition is used.

1. For each vertex $v$, arbitrarily pair edges incident at $v$ to get
   chains `u --- v --- w`.
2. Connect chains to get cycles.
3. Find a spanning tree of cycles to get an euler tour, where we have an
   edge between two cycles if they share a common vertex.

It's super clear why we need all vertices to be even degree; You can't pair
up vertices otherwise! 

#### References
- [Video on euler tour](https://www.youtube.com/watch?v=8MpoO2zA2l4)
- [Notes from Emory course on graph theory](http://www.mathcs.emory.edu/~rg/book/chap5.pdf)
- [CSTheory.stackexchange question on euler tours](https://cstheory.stackexchange.com/questions/31538/runtime-of-tuckers-algorithm-for-generating-a-eulerian-circuit)


# Representation theory of the symmetric group (TODO)

- [Video lectures: Representation theory, a combinatorial viewpoint](https://www.youtube.com/watch?v=QqJIOnTDbLM&list=PLFE2F2CDA55A9EBB6)

# Maximum matchings in bipartite graphs

It turns out that the best way to do this is to simply implement Dinic's with
scaling. That seems to meet the desired Hopcroft-Karp complexity. I was quite
disappointed to learn this, since I was hoping that Hopcroft-Karp would have
new ideas.



#### References

- [Bipartite Graphs/Matching (Intro)-Tutorial 12 D1 Edexcel](https://www.youtube.com/watch?v=JpapV5DrBek)
- [Maximum Matching Algorithm - Tutorial 13 D1 Edexcel A-Level](https://www.youtube.com/watch?v=gbasc4F-7hk)
- [Slides on matroid intersection](http://swoh.web.engr.illinois.edu/courses/ie512/handout/matching.pdf)


# p-adics, 2's complement, intuition for bit fiddling

Consider the equation $x \& (-x)$ which enables us to find the largest
power of 2 that divides $x$. One can prove this relatively easily from the
definitions:

$$
\begin{aligned}
&a = \langle x 1 0^r \rangle \\
&-a = \lnot a + 1 = x01^r + 1 = \overline{x}10^r \\
&a \& (-a) = a \& (\lnot a + 1) = (x 10^r) \& (\overline{x}10^r) = 0^{|\alpha|}10^r = 2^r
\end{aligned}
$$

That is, if we state that $a = \langle x 1 0^r \rangle$ for some arbitrary $r$,
we then find that $a \& (-a) = 2^r = \langle 1 0^r \rangle$, which is precisely what we need to subtract
from $a$ to remove the rightmost/trailing $1$. However, I don't find
this insightful. So I'm going to spend some time dwelling on $2$-adics, to find
a more intuitive way to think about this.

#### 2-adics and negative numbers

In the 2-adic system, we have that:

$$
\begin{aligned}
&-1 = \dots 1 1 1 1 \\
&-2 = -1 + -1 = \dots 1 1 1 1 + \dots 1 1 1 1 = \dots 1 1 1 0 \\
&-4 = -2 + -2 = \dots 1 1 1 0 + \dots 1 1 1 0 = \dots 1 1 0 0 \\
&-8 = -2 + -2 = \dots 1 1 0 0 + \dots 1 1 0 0 = \dots 1 0 0 0 \\
\end{aligned}
$$

Of course, these agree with the 2's complement representation, because the 2's
complement representation simply truncates the 2-adic representation. At any
rate, the point of interest is that if we now want to know how
to write $-3$, we start with the "lower" number $-4$ and then add $1$ to it,
giving us:

$$
-3 = -4 + 1 = \dots 1 1 0 0 + \dots 0 0 0 1 = \dots 1 1 0 1
$$

Which once again agrees with the 2's complement definition. 

#### $x \& (-x)$ for powers of 2:

If we now think strictly about powers of 2, we know that, for example,
$8 = \langle \dots 0 0 1 0 0 \rangle$ while $-8 = \langle \dots 1 1 1 0 0 \rangle$.
Hence, $x \& (-x) = \langle 0 0 1 0 0 \rangle$.  This will hold for any power of 2,
so our claim that $x \& (-x)$ gives us the location of the LSB will work for
any power of 2.

#### Alternative explanation for 2's complement

Start with the fact that we choose a single representation for zero:

```
0 ~= b0000000
```

Now, when we subtract 1, ask "are we in signed world or unsigned world"? If
in signed world, we want the answer to be `-1`. If in unsigned world
we want the answer to be 255.

```
0 - 1 
= b0000000 - b00000001
= b11111111 
=unsigned= 255
```

If we wanted to interpret the answer as *signed*, then we are free to do so.
This *automatically tell us that*

```
0 - 1
=unsigned= b11111111
=signed= -1
```

So, the advantage is that our operations don't care about whether the
number is signed/unsigned.



# Diameter of a tree


## Key property of the diameter

- Let $p$ be a path of maximum diameter, which starts at $p$ and ends at $q$.
 Consider a tree where the diameter is shown in golden:

<img src='./static/diameter/tree-diam-spread.png' />

- We claim that a node at distance $d$ from the left can have a subtree of
  height at most $d$:

<img src='./static/diameter/tree-diam-straight-example.png' />

- Suppose this were not the case. Then, we can build a *longer* diameter (in pink)
  that is longer than the "supposed diameter" (in gold):

<img src='.static/diameter/tree-diam-straight-counterexample.png' />

## Algorithm to find the diameter:

First perform DFS to find a vertex "on the edge", say $v$. Then perform DFS again
starting from this vertex $v$. The farthest vertex from  $v$, say $w$ gives
us the diameter (the distance from $v$ to $w$)

#### Proof by intuition/picture:

- first imagine the tree lying flat on the table. 

<img src="./static/diameter/tree.png" />

- Hold the tree up at node $c$. It's going to fall by gravity and arrange as
  shown below. This is the same as performing a DFS.

<img src="./static/diameter/tree-dfs-1.png" />

- Pick one of the lowest nodes (we pick $g$). Now hold the entire tree from
  this lowest node, and once again allow gravity to act. 

<img src="./static/diameter/tree-dfs-2.png" />

- This will give us new lowest nodes such as $b$. This node $b$ is going to be
  diameter, "because" it's the distance from a lowest node to another lowest
  node.

# Catalan numbers as popular candidate votes (TODO)

- Usually, folks define catalan numbers as paths that go up or right from $(1, 1)$
  to $(n, n)$ in a way that never goes below the line $y = x$.

- The catalan numbers can be thought to model two candidates $A$ and $B$ such
  that during voting, the votes for $A$ never dip below the votes for $B$.

I quite like the latter interpretation, because we really are counting
two different things (votes for $A$ and $B$) and then expressing a relationship
between them. It also allows us to directly prove that `catalan(n)` is equal
to $1/(n+1) \binom{2n}{n}$ by reasoning about seqences of votes, called as
*ballot sequences*

#### Ballot sequences

#### References
- [Richard Stanley's slides](https://math.mit.edu/~rstan/transparencies/china.pdf)

# The chromatic polynomial (TODO)

I've been on a combinatorics binge lately, so I'm collecting cool facts about
the chromatic polynomial. We first define the chromatic function of a graph,
which is a generating function:

$$
f[G](x) \equiv \texttt{number of ways to color $G$ with $x$ colors} \cdot x^n
$$

If we have a single vertex $K_1$, then $f[K_1](x) =  n x^n$, since we can color
the single vertex with the $n$ colors we have.

#### Composition of chromatic funcions of smaller graphs


#### The chromatic function is a polynomial



# Structure theory of finite endo-functions 

We study functions $f: V \rightarrow V$ and their properties by thinking of them as a
graph with vertex set $V$ and directed edges $(v, f(v))$. This gives us insight into
permutations, rooted trees, and a bunch of counting principles. Such a structure is
called as *functional digraph*

#### Principle 1: Structure theory

every functional digraph uniquely decomposes into disjont rooted trees which feed into
one or more disjoint cycles. We think of nodes as pointing from the leaves towards the
root. The root of the tree lies in a cycle.

#### Existence of tree implies not bijection

If we have a tree, we can keep walking backwards using edges from the root towards
the leaves. Now this leaf does not have an incoming edge. This means that this leaf
is not in the image of $f$. Hence $f$ cannot be surjective. 

#### Rooted Trees: a single cycle

in a rooted tree, only the root node $r$ is such that $f(r) = r$. All other nodes point to
other nodes without cycles.

#### Permutations: no rooted tree, only cycle

In a permutation, all we have are cycles. There are no trees that hang from the cycles.

#### Counting number of rooted trees: $n^{n-2}$: (TODO)

Say we have a function $f: V \rightarrow V$ where $|V| = n$ and $f(1) = 1$, $f(n) = n$.


#### References
- [USACO: functional graphs](https://usaco.guide/silver/func-graphs)

# Number of paths in a DAG

Given the adjacency matrix $A$ of a DAG, this  must be nilpotent. This is because
$A^k[i][j]$ will tell us the number of paths from $i$ to $j$ with $k$ edges in the path.
In a DAG, since there are no cycles, there is an upper bound on the number of edges
a path can have: the longest path is $|V| - 1$, when the DAG is a straight line. Thus,
we must have that $A^|V| = 0$.

- Let $A^n = 0$.
- Now, we know that $(I - A)^{-1} = I + A + A^2 + \dots$
  which will terminate as a finite sum, with $(I - A)^{-1} = I + A + A^2 + \dots + A^{n-1}$.
- But note that $(I + A + A^2 + \dots A^{n-1})[i][j]$ will count number of paths from 
  $i$ to $j$ with $0$ edges, $1$ edge, $2$ edges, etc. so we will get the _total_ number of
  paths from $i$ to $j$!. 


# Set partitions

Let $X$ be a set. A breakup of $X$ into pairwise disjoint sets $A[i]$ such that $\cup_i A[i] = X$
is called a partition $P$ of the set $X$.

#### Stirling numbers of the second kind: $S(n, k)$

These count the number of ways to break an $n$ element set into $k$ partitions/equivalence classes.


The recurrence is:

$$
S(n, k) \equiv S(n-1, k-1) + kS(n-1, k)
$$

- For the $n$th element, I either build a new equivalence class $\{ n \}$
  and then make $k-1$ equivalence classes from $\{1\dots (n-1)\}$.
- Alternatively, I have $k$ equivalence classes from $\{1 \dots (n-1)\}$, say $P[1], P[2], \dots, P[k]$
  I decide into which $P[i]$ the $n$ should go, which gives me $k$ choices. 
- Initial conditions: $S(0, 0) = 1$, $S(0, k \neq 0) = S(n \neq 0, 0) = 0$.

#### Stirling numbers and surjections

> Interesting interpretation: The number of ways to surject an $n$ element set into a $k$
> element set, since a surjection breaks a set up into a known number of fibers (in this case, $k$ fibers).

This is not entirely true, because we only get $k$ equivalence classes of the set $\{1, \dots, n\}$. We need to
decide where to map each equivalence class. So the correct count of $\{ [n] \xrightarrow{onto} [k] \}$
is $k!S(n, k)$: there are $k!$ ways to map equivalence classes of $n$ to elements of $k$


#### Rook theory(!)

Turns out we can provide a crazy relationship betweeen ferrers diagrams, and rooks (as in the chess piece)
and stirling numbers of the second kind.

We define $\Delta(n)$ to be the board consisting of the integer partition
$[n-1, n-2, \dots, 1]$. For example, we think of $\Delta(4)$ as:

```
Delta(4):
+--+
|  |
+--+--+
|  |  |
+--+--+--+
|  |  |  | 
+--+--+--+--+
```

Hopefully, this looks like a staircase with 4 stairs starting from the ground.
We have filled in squares of $[3, 2, 1]$ blocks stacked above one another.


We define $r(n, k)$ to be the number of legal rook placements on a board $\Delta(n)$
with $k$ free rows. That is, we have $(n-k)$ rooks to place on the board $\Delta(n)$,
with one on each row, such that no rook attacks another rook.

- Boundary condition: $r(0, 0) = 0$ 0 free rows on a $\Delta(0)$ board counts as 
  one configuration.
- Recurrence: $r(n, k) \equiv r(n-1, k-1) + k r(n-1, k)$

-  $r(n-1, k-1)$ term: 
   We don't place a rook on the bottom row. This means we have used up a free row,
   and need to place rooks with $(k-1)$ free rows on an $(n-1)$ board:

```
+--+
|  |
+--+--+
|  |  |  r(n-1, k-1)
+--+--+--+

+--+--+--+
|  |  |  |  BLANK
+--+--+--+--+
```

- $k r(n-1, k)$: We fill out $\Delta(n-1)$ with rooks such that we have 
  $k$ free rows. Then, we add the final row. Note that since we have rooks,
  $k$ free rows is equivalent to $k$ free columns! Now, we can't leave the final row
  free, since we have already exhausted our $k$ free rows in the recursion. We have $k$
  free columns for the rook in the final row to inhabit. So we get $k r(n-1, k)$.


#### Bijection between rooks and Stirling numbers of the second kind

Finally, note that $S(n, k) = r(n-k, k)$, as $S(n, k) = S(n-1, k-1) + k S(n-1, k)$
which is equivalent to asking:

$$
\begin{aligned}
&S(n, k) = S(n-1, k-1) + k S(n-1, k) \\
&r(n-k, k) =_? r(n-1 - (k-1), k-1) + k r(n-1 - k, k) \\
&r(n-k, k) =_? r(n-k, k-1) + k r(n-k-1, k) \\
&\text{set $m = n-k$: } \\
&r(m, k) = r(m, k-1) + k r(m, k) \\
\end{aligned}
$$

#### Directly reading off the bijection between set partitions and rook placements

I found this very cool. The idea is to treat each rook as a "bouncer" that bounces light
rays. All elements hit by a light ray belong to an equivalence class.

<img src="./static/rooks-equivalence-classes.png"/>


#### Wrooks and signless stirling numbers

Similar to the rooks, we define a _wrook_ (a weak rook) as one that only attacks
on its row. Here $w(n, k)$ denotes a placement of wrooks on $\Delta(n)$ with $k$
free rows.

$$
\begin{aligned}
&w(n, k) \equiv \\
&~ w(n-1, k-1)~ \text{Leave bottom row free: uses up a free row} + \\
&~n w(n-1, k)~ \text{Place a wrook on bottom row: $n$ possible positions}
\end{aligned}
$$

The corresponding "counting" object is called as the signless stirling numbers:

TODO


# Integer partitions: Recurrence

An integer partition of an integer $n$ is a sequence of numbers $p[1], p[2], \dots p[n]$ which
is weakly decreasing: so we have $p[1] \geq p[2] \dots \geq p[n]$. For example, these
are the integer partitions of $5$:

- [5]
- [4, 1]
- [3, 2]
- [3, 1, 1]
- [2, 2, 1]
- [2, 1, 1, 1]
- [1, 1, 1, 1, 1]

Thus, $P(5) = 7$. We denote by $P(n, k)$ the number of partitions of $n$ into $k$ parts.
So we have $P(5, 1) = 1$, $P(5, 2) = 2$, $P(5, 3) = 2$, $P(5, 4) = 1$, $P(5, 5) = 1$.

The recurrence for partitions is:

$$P(n, k) = P(n-1, k-1) + P(n-k, k)$$

The idea is to consider a partition $p[1], p[2], \dots, p[k]$ of $n$ based on the final element:
- if $p[k] = 1$, then we get a smaller partition by removing the $k$th part, giving us a partition of $(n-1)$  
  as $[p[1], p[2], \dots, p[k-1]]$. Here the number decreases from $n \mapsto (n-1)$ and the number of parts
  decreases from $k \mapsto (k-1)$.
- if $p[k] \neq 1$ (that is, $p[k] > 1$), then we get a partition of $n-k$ by knocking off a $1$ from *each* partition, giving us
  $[p[1] - 1, p[2] - 1, \dots, p[k]-1]$. Here we decrement on the number $n \mapsto n - k$ while still keeping
  the same number of parts.

#### References

- Bijective Combinatorics
- [Slides by Brian Miceli](http://ramanujan.math.trinity.edu/bmiceli/research/TXState04-09-10.pdf)

# Stars and bars by direct bijection

We know that the number of $k$ element multisets using letters from $\{1, \dots, n\}$
is $\binom{k+n-1}{k}$.  That is, we are allowed to pick elements from $\{1, \dots, n\}$
repeatedly, and we want $k$ such elements.

#### The usual proof: stars and bars

The usual proof involves creating $k$ "stars" ($\star$) which need to be placed in $n$
buckets. These buckets are created by having $(n-1)$ "bars" ($|$). For example, if we 
wish to consider all $k=3$ element multisets of the letter $n=4$: $\{w, x, y, z\}$:

$$
\begin{aligned}
&[w, w, w] \mapsto \star \star \star \vert \vert \vert  \\
&[w, x, y] \mapsto \star \vert \star \vert \star \vert \\
&[x, x, x] \mapsto \vert \star \star \star \vert \vert  \\
&[x, z, z] \mapsto \star \vert \vert \star \star \\
\end{aligned}
$$

#### Direct bijection.

To build a direct bijection, map a $k$ multiset of $n$ into a $k$ **subset** of $n+k-1$, which 
is counted by $\binom{n+k-1}{k}$.


- We are first given a $k=6$ multiset of $n=3$, say $m = \{3, 1, 2, 1, 3, 3\}$ ($m$ for multiset).
- We make the representation unique by imposing an ascending order,  so we write $M = [1, 1, 2, 3, 3]$, where each $M[i] \leq M[i+1]$.
- Now, we map the above sequence to a set of  *unique* values, by mapping $N[i] = M[i] + i$. Since $M[i] \leq M[i+1]$ we have that
  $M[i] + i < M[i+1] + (i+1)$.
- This gives us the set $M' = \{ 1+0, 1+1, 2+2, 3+3, 3+4 \} = \{ 1, 2, 3, 6, 7 \}$.
- See that this process is reversible. Given some set, say $N = \{ 4, 3, 2, 6, 7, 8 \}$, order in ascending order to get
  $N' = [2, 3, 4, 6, 8]$ and then subtract $i$ from $N'[i]$ to get $[2-0, 3-1, 4-2, 6-3, 7-4, 8-5] = [2, 2, 2, 3, 3, 3]$. 


I found this very elegant, because it "de-multisets" the multiset by adding just enough to make each element unique,
and then simply counts the unique subset. Very slick! We need to add $k-1$ to the final index, and the largest number
we can have is $n$ so we need $n + (k-1)$ values. We need a size $k$ multiset, making us need $\binom{n+(k-1)}{k}$. 

- Reference: Bijective Combinatorics

# DFS and topological sorting

The proper way to solve a maze is to keep breadcrumbs! Use recursion.
Recursively explore the graph, backtracking as necessary.

#### DFS on a component:

```py
parent = { s: None}
dfs-visit(adj, s):
  for v in adj[s]:
    if v not in parent:
      parent[v] = s
      dfs-visit(adj, v)
```

#### visit all vertices:

```py
dfs(vs, adj):
  parent = {}
  for s in vs:
    if s not in parent:
    parent[s] = None
    dfs-visit(adj, s)
```

#### Complexity

We call `dfs-visit` once per vertex $V$. Per vertex, we pay `adj(v)` per
vertex `v`. In total, we visit `|E|`. 

#### Shortest paths?

DFS **does not take the shortest path** to get to a node. If you want shortest
paths (in an unweighted graph), use BFS.

#### Edge classification

1. **Tree edges**: visit a new vertex via that edge. Parent pointers track
                   tree edges.
2. **forward edges**: goes from node `n` to descendant of node `n`.
3. **backward edges**: goes from a node `n` to an ancestor of node `n`.
4. **cross edges**: all other edges. Between two non-ancestor-related nodes.


How do we know forward, back, cross edges?

#### Computing edge classifications

- **backward edges**: mark nodes being processed. if we see an edge towards a
                      node still being processed, it's a backward edge.
- **forward edges**/**cross edges**: use time.

#### Which of these can exist in an undirected graph?

- Tree edges do exist. They better! That's how we visit new nodes.
- Forward edges: can't happen, because we will always traverse "backwards".

```
A ----> B
  ----> C
```

`A -> C` is a forward edge! 
If we made the above undirected, then we will have `A -> B` tree edge and `B -> C`
back-edge.

- Back-edges: can exist in an undirected graph as shown above; `B -> C` is a back edge.
- Cross-edges: once again, cross edges can only come up from "wrongly directed"
  edges. But we don't have directions in an undirected graph.

#### Cycle detection

$G$ has a cycle iff $G$'s DFS has a back-edge.

##### Proof: DFS has a back edge => $G$ has a cycle

```
  tree
A -...-> X
^         |       
---back---*
```

By definition, `A -> X` is connected using tree edges, and a back edge
`X -> A`. gives us the cycle.

#### Proof: $G$ has a cycle => DFS has a back edge

Say we have a cycle made of `k` vertices `x, y, z, ...`.
assume `v[0]` is the first vertex in the cycle visited by the DFS.
Keep labeling based on how DFS visits then as `v[1], v[2], ... v[k]`.
The we claim the edge `v[k] -> v[0]` will be a backedge.

- We know that when we're recursing on `v[0]`, we will visit `v[1]` before we 
  finish `v[0]`.
- Similarly, `v[i]` will be visited before `v[i-1]`.
- Chaining, we will finish `v[k]` before we finish `v[0]`. 
- In terms of balanced parens, it's like `{0 (k; k) 0}`.
- So, when we look at the edge `v[k] -> v[0]`, we have not yet finished `v[0]`.
  Thus, we get a backedge.

#### Topological sort

Given a DAG, order vertices so that all edges point from lower order to 
higher order. The algorithm is to run DFS and output the reverse order of
finishing time of vertices. Why does this work?

#### Proof that topological sort works

We want to show that for an edge $(u, v)$ that $v$ finishes before $u$, so that $v$
is ordered _after_ $u$.
Remember that we sort based on _reverse_ of finishing order.

##### Case 1: `u` starts before `v`

We will eventually visit `v` in the recursion for `u` because `u -> v`
is an edge.  So, we will have
the bracketing `{u (v; v) u}` so we're good: we finish `v` before we finish `u`.

##### Case 2: `v` starts before `u`

We have the bracketing `(v ... {u`. If we were to finish `u` before finishing `v`, then 
`v` is an ancestor of `u`, and this gives the bracketing
`(v .. {u .. u} .. v)` and thus the edge $(u, v)$ is a back-edge. But this is 
impossible because the graph cannot have cycles! Thus, we will still have that
`v` finishes beofre `u`, giving the bracketing `(v v) .. {u u}`.


- [MIT introduction to algorithms: Lecture 14, DFS and topological sorting](https://www.youtube.com/watch?v=AfSk24UTFS8)


# Tournaments

- Tournament graph: either $U$ beats $V$, so we have $U \rightarrow V$ or we have $V$ beats $U$ so we 
  have the edges $V \rightarrow U$ for every $U, V$

[image at 49:00 from video math for comp sci lecture 10]

- Example:  `A -> B -> D -> E -> C`. Wait, `C -> A`. It's unclear how to talk about
  the best player!

#### directed Hamiltonian path

A directed walk that visits every vertex exactly once.

#### Theorem: every tournament graph contains a directed hamiltonian path

Induction on the number of nodes. When we start thinking of the problem,
we have both nodes and edges as parameters. But edges are directly related to nodes,
so it makes sense we induct on nodes.

##### Induction
If $n=1$ we are done.  In the inductive step, assume it holds for $n=n$.  For
$n=n+1$, let's take out one node $v$ and see what happens. In the remaining
graph, we still have a tournament graph on $n$ nodes. By the induction
hypothesis we have a directed hamiltonian path $v_1 v_2 \dots v_n$. We want to
create a bigger path that includes $v$.

##### Case 1
If $v \rightarrow v_1$ then we will get a path $v v_1 \dots v_n$.
                         
##### Case 2
If $v_1 \rightarrow v$, then it is harder! Now what do we do?
Ideally we want to plug $v$ somewhere in the sequence $v_1 v_2 \dots v_n$.
Let's consider the smallest $i$ such that $v \rightarrow v_i$. We know that $i \neq 1$
as we are in case 2.

```
v1 -> ...v[i-1] -> v[i] -> ... vn
                   ^
                   v
```

If we have $v[i-1] \rightarrow v$ we are done because we get to insert $v$
into the path as $v[i-1] \rightarrow v \rightarrow v[i]$. Because $v[i]$ is the
smallest index that $v$ beats, we must that $v[i-1]$ beats $v$ --- otherwise $i$
is no longer the smallest index!


#### Chicken tournament

Either a chicken $u$ pecks a chicken $v$ then $u \rightarrow v$ or the other
direction, $v \rightarrow u$. We say that $u$ *virtually* pecks $v$ if there's
a patch of pecking for $u$ to peck $v$.
                                                                            
> The chicken king is the chicken that virtually pecks all other chickens.

We can have multiple king chickens. We want to find at least one chicken king.
We may want to show that the vertex with the most number of outgoing edges  
is going to be a king.

#### Theorem: chicken with highest out degree is the king

Proof by contradiction: assume $u$ has highest out degree and is not the king.
So there is some vertex $v$ such that $\not u \rightarrow v$. Hence we have
that $v \rightarrow u$. In the other case, we have that $\not u \rightarrow w \xrightarrow{\star} v$.

- [Reference: Math for computer science, lecture 10](https://www.youtube.com/watch?v=DOIp5D7VMS4)

# Matching problems (TODO)

Given a graph $G = (V, E)$ a matching is a collection of edges of $G$ where every
node has degree 1. 

#### Perfect matching

A matching is perfect if it has size $|V|/2$, or no vertex is left
isolated. That is, everyone is matched with someone.

#### Weighted (Perfect) Matching

Some matchings maybe more preferable than orders, by giving weights.Usually,
lower weights are more desirable. We may want to find the minimum weight matching.                                                          n
The weight of a matching is the sum of the weights on the edges of $M$. In this
context, we usually always ask for a **perfect matching**. Otherwise, one can
trivially *not match anyone* to get a min-weight matching of weight 0.
So the definition of a min-weight matching for the graph $G$ is a perfect
matching with minimum weight. 

We don't see these in `6.042`. Will have to read flows/hungarian to study this.

#### Preference matching

Given a matching, $(x, y)$ form a **rogue couple** if they both prefer each
other over their matched mates. Ie, they both wish to defect from their
'matched mates'. A matching is **stable** if there aren't any rogue couples.
The goal is to find a perfect stable matching. That is, get everyone married
up, and make it stable!


The point is, not everyone has to become happy! It's just that we don't allow
rogue couples who can mutually get a benefit.

#### Bad situation for preference matching

If boys can love boys as well as girls, then we can get preference orderings
where no stable marriage is possible. The idea is to create a love triangle.

- Alex prefers Bobby over Robin
- Bobby prefers Robin over Alex
- Robin prefers Alex over Bobby.
- And then there is mergatoid, who is the third choice for everyone.
  mergatoid's preferences don't matter

##### Theorem: there does not exist a stable matching for this graph

Proof: assume there does exist a stable matching, call it $M$. Mergatoid
must be matched with someone. WLOG, assume mergatoid is matched to Alex by
symmetry. If mergatoid is matched to alex, then we must have Robin matched
to Bobby

- Alex and Bobby are not rogue, because Bobby  likes Robin more than Alex.
- Alex and Robin are the rogue, because (1) Robin prefers Alex over Bobby, and 
  (2) Alex prefers Robin over Mergatoid.

Hence, we found a rogue couple. So $M$ was not stable.

#### Stable Marriage Problem: success in some cases!

We have $N$ boys and $N$ girls [need the same number of each]. Each boy
has his own ranked preference list of all the girls. Each gil has her own
ranked preference list of all the boys. The lists are complete and there
are no ties. We have to find a perfect matching with no rogue couples.

#### Mating algorithm / Mating ritual

The ritual takes place over several days.
- In the morning, the girl comes out to the balcony.
- Each boy goes to his favourite girl who hasn't been crossed off in his list
  and serenades her.
- In the afternoon, if a girl has suitors, she tells her favourite suitor
  "maybe I'll marry you, come back tomrrow". Girls don't make it too easy. For
  all the lower priority boys, she says "now way I'm marrying you".
- In the night, all the boys who heard a no cross that girl off from their list.
  If the boy heard a maybe, he will serenade her.
- If we encounter a day where every girl has at **most** one suitor, the algorithm
  terminates. So we don't have two or more boys under one balcony.


#### Things to prove

- Show that the algorithm terminates.
- Show that everyone gets married.
- Show that there are no rogue couples.
- We may want to show it runs quickly.
- Fairness? is this good for girls, or for boys?

#### Termination, terminates quickly: N^2 + 1 days

Proof by contradiction. suppose TMA does not terminate in $N^2+1$ days. 

**Claim** If we don't  terminate on a day, then that's because a girl had
two or more boys under her balcony. Thus, at least one boy crosses the girl
off of his list. We measure progress by the cross-out. In $N^2$ days, all boys
would have crossed out all girls.

#### Invariant

- `P` is that if a girl $G$ every rejected a boy $B$ then she has a suitor who
  she prefers to $B$.

- To prove that this is indeed an invariant, induction on time. 
  At the beginning, no girl has rejected any boy, so it's vacuously true.

- Assume `P` holds at the end of day $d$. At the end of day $d+1$, there's two cases.
- If $G$ rejects $B$ on day $d+1$, there must be a better boy, hence `P` is true.
- If $G$ rejected $B$ on day less than $d+1$, then $G$ must have had a better suitor $B'$
  on day $d$ by the induction hypothesis. Now on day $d+1$, she either has $B'$
  or someone even better, $B''$ came along.

#### Everyone is married

Proof by contradiction. Assume not everyone was married. Assume that some boy $B$ is
not married. (If there is no boy who is not married then everyone is married).
- If we was not married at the end, then he must be rejected by *everyone*.
- If he were not rejected by everyone, then he would be under someone's balcony
  trying to serenade them. That he is unmatched means that all the girls have
  rejected him.
- This means that every girl has somebody better than $B$, which is not possible,
  because that would mean that every girl was married. That's not possible as there
  are an equal number of boys and girls.

> Sid note: I don't buy this! we need to show that in the course of the algorithm,
> it's impossible for a girl to end up empty handed. I'd prove this by noticing that
> at each round, a girl acts like some kind of "gated compare and swap" where only
> the highest value is allowed to be put into the mutex, and all of the others
> are rejected. Thus, if there is a girl who has multiple writes, she will
> only allow one of the writes to happen, and permanently disallow the other writes.
> Thus, the other writes have to move to other girls. 

#### No rogue couples

Contradiction: assume that there is a pair that are not married, call them bob and gail. 
We need to show that they will not go rogue. Since bob and gail are not
married, either (1) gail rejected bob, or (2) gail did not reject bob because
bob never serenaded her. If bob had serenaded her *and* was not rejected, then they
would have been married!.


- (1) If gail rejected bob, then gail has marries someone she likes better than bob
  since she's rejected bob. Thus, gail and bob can't be a rogue couple because she
  likes her spouse more than bob. 

- (2) bob never serenaded gail. This means that he married someone who he prefers
  more than gail, cause he never reached gail.

#### Fairness

- The girls get to pick the best ones who come to them.
- The boys get to go out and try their first choice though. A girl may wait
  for her Mr. Right who will never come along, and thus satisfice.
- Which is better? proposors or acceptors? Sociological question! Here it turns
  out that **boys have all the power**.
- Let $S$ be the set of all stable matchings. We know that $S$ is not empty
  because the algorithm is able to produce at least one stable matching.
- For each person $P$, we define the **realm of possibility** for $P$ to be the
  set $Q$ of people that they can be matched to in a stable matching. So
  $Q_p \equiv \{ q : (p, q) \in M, M \in S \}$. That is, there's a stable marriage
  where you're married to them.
- A person's **optimal mate** is their most favourite in the realm of possibility. Their
  **pessimal mate** is their least favourite in the realm of possibility.

#### Theorem: No two boys can have the same optimal mate. 

Assume two boys do have the same optimal mate. Say $(b^\star, g)$ and $(b, g)$. WLOG
let $g$ prefer $b^\star$ over $b$. Now, there exists some "stable matching" where
$g$ is matched with $b$, because $g$ is the optimal mate, hence in the realm
of possibility of $b$. However, this matching is unstable because $(b^\star, g)$
is a rogue couple: $g$ likes $b^\star$ more than $b$, and $b^\star$ likes $g$ best!

#### Theorem: No two girls can have the same optimal mate

Redo previous proof by switching girl and boy. It's not a proof about the *algorithm*,
but about the *structure of stable matches* themselves.


#### Theorem: The algorithm matches every boy with his optimal mate

Proof by contradiction.  Assume that Nicole is optimal for Keith, but Keith winds
up not marrying Nicole. This means he must have crossed off Nicole in some day (bad day).

Note that he must have **gotten to Nicole**, because no girls he prefers over nicole
would have led to a stable marriage, and would thus not be an output generated
by the algorithm. This, all girls he prefers above nicole must reject him 
at *some* step of the algorithm till he reaches Nicole.

We assume that in this instance of the algorithm, he does not get Nicole, thus
Nicole too must have rejected him.

Let us assume that Keith gets rejected by Nicole on the **earliest bad day**.

When Nicole rejects Keith, this means that Nicole had a suitor she likes better
than Keith. Call him Tom. `Tom >Nicole Keith`. Furthermore, since this is the
earliest bad day, tom has not crossed off his optimal girl, and thus nicole
must be the "best girl" for tom --- either out of his league, or the optimal
feasible math. Thus, `Nicole >Tom optimal-feasible-mate-for-tom`.


But this means that in a stable marriage with `(Nicole, Keith)`, we would have
`(Nicole, Tom)` be a rogue couple! This contradicts the fact that nicole is optimal
for keith.



- Proof from Optimal Stable Matching Video, MIT 6.042J Mathematics for Computer Science, Spring 2015.

#### We match every girl with her pessimal mate

TODO

#### Theorem: matchings form a lattice

Let $M = ((b_1, g_1), (b_2, g_2), \dots (b_n, g_n))$  and $M' = ((b_1, g'_1), (b_2, g'_2), \dots, (b_n, g'_n))$
be two stable matchings. Then.

$$
M \lor M' \equiv ((b_1, \max_{b_1}(g_1, g_1'), \dots, (b_n, \max_{b_n}(g_n, g_n')))
$$

is a stable matching.

##### Step 1: This is  a matching
First we show that it is indeed a matching: the marriages are all monogamous.
Assume that we had $g_1 = \max_{b_1}(g_1, g_1') = \max_{b_2}(g_2, g_2') = g_2'$.


Since $(b_2, g_2')$ is the match in $M'$ and $g_1 = g_2'$, we have that $(b_2, g_1)$
is the match in $M'$. We also know that $g_1 >_{b_1} g_1'$ from the assumption.
Since the matching $M'$ is stable, we need to ensure that $(g_1, b_1)$ is not a
rogue couple; $b_1$ prefers $g_1$ over $g_1'$. Thus, we must have that $b_2 >_{g_1} b_1$
to ensure that $(b_2, g_1)$ is stable.

However $M$ is stable, and $(b_1, g_1) \in M$.  Since we have that $b_2 >_{g_1} b_1$,
for $(b_1, g_1)$ to be stable, we must ensure that $(b_2, g_1)$ is not
a rogue couple, since $g_1$ prefers $b_2$ over $b_1$. This we must have
that $g'_1 >_{b_2} g_1$.

But this contradicts the equation $\max{b_2}(g_2, g_2') = g_2' = g_1$ (?)

#### Sid musings

> the girls are monotonic filters, where they only allow themselves to match higher.
> The propogate (in the kmett/propogators sense of the word) information to all
> lower requests that they will not match. The boys are in some kind of atomic
> write framework with conflict resolution, where a girl allows a boy to "write"
> into her 'consider this boy' state if the boy is accepted by her filter.

#### References

- [MIT OCW Math for comp sci: lecture 7 --- matching](https://www.youtube.com/watch?v=5RSMLgy06Ew)
- [SPOJ problem](https://www.spoj.com/problems/STABLEMP)
- [Knuth: Stable matching and its relation to other combinatorial problems](https://www-cs-faculty.stanford.edu/~knuth/ms.html)
- [Math for Comp Sci: Optimal stable matching](https://www.youtube.com/watch?v=n4KKgKpp--0)

# Four fundamental subspaces

- Column space / Image: $C(A)$, since it corresponds to $C(A) \equiv \{ y : \exists x, y = Ax \}$
- Null space $N(A) \equiv \{ k : Ak = 0 \}$.
- Row space: row spans the row space, so it's all linear combinations of the rows
    of $A$. This is the same as all combinations of the columns of $A^T$.
  Row space is denoted by $C(A^T)$.
- Null space of $A^T$: $N(A^T)$, also called as the "left null-space of $A$".

Let $A$ be $m \times n$. The Null space of $A$ is in $\mathbb R^n$. The column
space is in $\mathbb R^m$. The rows of $A$  are in $\mathbb R^n$. The nullspace
of $A^T$ is in $\mathbb R^m$.


We want a basis for each of those spaces, and what are their dimensions?
- The dimension of the column space is the rank $r$.
- The dimension of the row space is also the rank $r$. 
- The dimension of the nullspace is $n - r$.
- Similarly, the left nullspace must be $m - r$.


#### Basis for the column space

The basis is the pivot columns, and the rank is $r$.

#### Basis for the row space

$C(R) \neq C(A)$. Row operations do not preserve the column space, though
they have the same row space. The basis for the row space of $A$ and $R$
since they both have the space row space, we just read off the first $r$
rows of $R$.

#### Basis for null space

The basis will be the special solutions. Lives in $\mathbb R^n$


#### Basis for left null space

It has vectors $y$ such that $A^T y = 0$. We can equally write this as
$y^T A = 0$. Can we infer what the basis for the left null space is 
from the process that took us from $A$ to $R$? If we perform gauss-jordan,
so we compute the reduced row echelon form of $[A_{m\times n} I_{m \times m}]$,
we're going to get $[R E]$ where $E$ is whatever the identity matrix became.

Since the row reduction steps is equivalent to multiplying by some matrix $M$,
we must have that:

$$
\begin{aligned}
&M [AI] = [RE] \\
&MA = R; MI = E \implies M = E
\end{aligned}
$$

So the matrix that takes $A$ to $R$ is $E$! We can find the basis for the left
nullspace by lookinag at $E$, because $E$ gives us $EA = R$.

#### Reference
- [Gilbert strang, lecture 10: four fundamental subspaces](https://www.youtube.com/watch?v=nHlE7EgJFds)


# WHO list of essential medicines (TODO)
- [Wikipedia reference](https://en.wikipedia.org/wiki/WHO_Model_List_of_Essential_Medicines)

# why is `int i = i` allowed in C++?

This bizarre program:

```cpp
struct Foo { explicit Foo() {}; }
int main() { Foo foo = foo; cout << "works!"; return 0; }
```

actually works! Why is this allowed? The only real use-case I know for this is
to write:

```cpp
const int ARRSIZE = 200;
int *ptr = malloc(sizeof(ptr) * ARRSIZE);
```

Still, this seems awfully dodgy. It feels like the C speficiation could allow
the use of the left-hand-side name in expression that only need *type* information
while emitting compile time errors for expressions that use the left-hand-side-name
as a *value*.


# Kakoune cheatsheet

- `/`: search for some text. `n`: go to next occurence. `Shift-n`: goto next occurence with a multi cursor.
- `Shift-X`: select multiple lines in sequence. `s`: make a multi-cursor a word in the current selection
- `space`: remove multiple cursors
- `Alt+i <key>`: select `<object>` of some type. Example: `Alt+i w`: select word.  `Alt+i s`: select sentence.
- `Shift-c`: create multiple cursor in line below
- `X`: select line. 


# Assembly IDE

I've wanted to "learn assembly" properly, in the sense of write small to
medium programs to feel like a native. Scouting around for IDE's, I couldn't
find much. However, it seems like `emacs` has a rich ecosystem for
assembly! I had no idea if it's a *good* ecosystem --- my experience with
`emacs` has been hit and miss. I decided to take the dive.

- [`http://ref.x86asm.net/`](http://ref.x86asm.net/)
- [`nasmshell`](https://github.com/fishstiqz/nasmshell)
- [`nasm-mode`](https://nullprogram.com/blog/2015/04/19/)
- [`x86-lookup`](https://nullprogram.com/blog/2015/11/21/)
- [blog post](https://vishnudevtj.github.io/notes/assembly-in-emacs)
- [link to volume 2](/https://software.intel.com/content/www/us/en/develop/download/intel-64-and-ia-32-architectures-sdm-combined-volumes-2a-2b-2c-and-2d-instruction-set-reference-a-z.html)
- [Link](https://software.intel.com/content/www/us/en/develop/articles/intel-sdm.html)
  to general page with download link called as Intel 64 and IA-32 architectures software
  developer's manual combined volumes 2A, 2B, 2C, and 2D: Instruction set reference, A-Z.
- [`cgasm`](https://github.com/bnagy/cgasm) to quickly lookup assembly.

# Cohomology is like holism

A shower thought, but Cohomology is indeed like holism. It describes precisely
how the whole is greater than the sum of its parts, in terms of capturing a
"global defect" that is oftentimes "locally trivial".

# Flows (TODO)

- [Srinivas Devdas: Flows](https://www.youtube.com/watch?v=VYZGlgzr_As)

#### Canonical Transformation

- No self loops.
- No loops of the form `s -> u -> s`. (ie, no 2-vertex loops).
- This allows us to conflate "positive flow" and "net flow".

#### Notation: Net flow / flow

- A flow on $G$ is a function $f: V \times V \rightarrow \mathbb R$ such that
  $f(u, v) \leq c(u, v)$ for all vertices $u, v$.
- **Flow conservation**: for all vertices $u$, $\sum_v f(u, v) = 0$.
- **anti-symmetry**: $f(u, v) = -f(v, u)$.

#### Implicit summation notation

The value of a flow $f$ denoted as $|f|$ (cardinality of $f$), is denoted as:

$$
|f| \equiv f(s, V) = \sum_v f(s, v)
$$

#### Properties of flow

- $f(X, X) = 0$. $f(a, a) = 0$ because self loops are not allowed. for two 
 different vertices, we're going to get $f(a, b) + f(b, a) = 0$ by skew symmetry.
 In general, $f(X, Y) = -f(Y, X)$.
- $f(X \cup Y, Z) = f(X, Z) \cup f(Y, Z)$ if $X \cap Y = \emptyset$.

#### Theorem: $|f| equiv f(s, V) = f(V, t)$

Recall that $|f| = f(s, V)$. We want to show that $|f| = f(s, V) = f(V, t)$.
So whatever gets pushed out gets pushed in.

$$
\begin{aligned}
&|f| \equiv f(s, V) \\
& f(s, V) + f(V - s, V) = f(V, V) = 0 \\
&  f(s, V) = f(V - s, V) \\
&  f(s, V) = f(V - s - t, V) + f(t, V) \\
&  f(s, V) = f(t, V) - f(V - s - t, V)\\
& [\text{any vertex in $V - s - t$ is an intermediate vertex, which has 0 net flow}] \\
&  f(s, V) = f(t, V) - 0 \\
&  f(s, V) = f(t, V) \\
\end{aligned}
$$

#### Cut:

A partition of the network into two parts, such that the source is in one
part and sink in the other. $(S, T)$ is a cut of a flow network $G$ is
a partition of $V$ such that $s \in S, t \in T$. If $f$ is a flow on $G$
then the flow across the cut is $f(S, T)$.


#### Capacity of a cut and its relationship to flow

$$c(S, T) = \sum_{s \in S, t \in T} c(s, t)$$
See that we only get
**positive coefficents** here. There is no "negative capacity", only "negative flow".

#### Theorem: upper bound flow across a cut

Value of _any_ flow is upeer bounded by the capacity of _any_ cut. We need
more tools to prove this, as this is basically max-flow-min-cut

#### A different characterization of flow value

Lemma: for any flow $f$ and any cut $(S, T)$ we have that $|f| = f(S, T)$.
It's because we have the source on one side, and the sink on the other side.
That gives us the flow! Everything else cancels by conservation.

$$
\begin{aligned}
&f(S, T) = f(S, V) - f(S, S) \\
&f(S, T) = f(S, V) - 0 \\
&f(S, T) = f(s, V) + f(S - s, V) \\
\end{aligned}
$$

As $S - s$ does not contain $t$, by flow conservation, we must have that $f(S - s, V) = 0$.
Thus we get:

$$
\begin{aligned}
f(S, T) = f(s, V) = |f|
\end{aligned}
$$

So, I can know the capacity of any cut $(S, T)$ bounds the flow of the network!
So if I go look at the min-cut, then I can bound the max flow. We don't know
how to find these min-cuts. That's what we'll need to figure out.

#### Residual network

Network that points us to locations with leftover capacity where we can 
push flow. $G_f(V, E_f)$ contains all those edges that have positive (greater than zero)
residual capacity. Edges in $E_f$ admit more flow. If $(v, u) \not \in E$, then
$c(v, u) = 0$, but $f(v, u) = -f(u, v)$. So we will have extra edges in the
residual network that don't exist in the original network.

If I have a flow $-1$ due to a back-edge with capacity $0$, I can in fact
send more flow to make it $0$! So I can have "back edges" in the residual network
for edges whose flow has to shrink.

#### Augmenting path in $G_f$

> **Sid question:** A path from $s$ to $t$ in $G_f$. Why does the existence of
> an augmenting path in $G_f$ actually mean that we can increase the flow? even
> when we have "back edges"? **Sid answer**: Because at the end of the day,
> we are picking a path from $s$ to $t$ which tells us how to change our flow
> in a way that we still respect capacity constraints.


# Amortized analysis

- [Erik Demaine: amortization --- amortized analysis](https://www.youtube.com/watch?v=3MpzavN3Mco)

#### Table doubling
- Expected cost of hash lookup: $O(1 + n/m)$ where $n$ items in table of size $m$
  ($n/m$ is the load factor)
- Total cost for $n$ insertions: $2^0 + 2^1 + \dots + 2^{\log n} \simeq O(n)$.
- Amortized cost per operation is $O(1)$.

#### Aggregate method

We do some sequence of $k$ operations. Measure the total cost of the $k$
operations and divide by $k$. This **defines the amortized cost** (Weak definition).

#### Generalized definition (amortized cost)

- assign **some cost** for each operation, called the amortized cost, such that it
  "preserves the sum" of the cost for all operation sequences `op[i]`.

$$
\begin{aligned}
\sum \texttt{amortized-cost}(op[i]) \geq \sum \texttt{real-cost}(op[i]) 
\end{aligned}
$$

-  The cost that obeys this inequality is called as the **amortized cost**.


#### 2/3 trees:

- `O(1)` to create
- `O(log n)` to insert  (amortized)
- `O(0)` to delete? (amortized) We can bound the deletion cost by the insertion cost,
  because we can't delete more items than we have inserted! We can bound the
  **delete cost** by the **insert cost**. 

- `c` creation time, `i` insertions, `d` deletions. 
- Let $n^\star$ be the largest size of the tree we've encountered in this
  sequence of operations. This way, we are really bounding the worst case.
- The real cost is $(c  + i \log n^\star + d \log n^\star)$. Let's try to show
  an amortized bound with `O(0)` to delete!.

$$
\begin{aligned}
&O(c  + i \log n^\star + d \log n^\star) \\
&= O(c + (i + d) \log n^\star) \\
&[\text{$d \leq i$ since we can delete at most number of items}] \\
&\leq O(c + 2i \log n^\star) \\
&\leq O(c + i \log n^\star)
&\leq O(c + i \log n^\star + 0d)
\end{aligned}
$$

#### Accounting method

Define a time bank account. An operation can store time credit in that bank account.
Bank account must always have **non-negative** time balance. Performing operations
costs time. So we can either directly pay for operations, or we can pull money
from the time bank account. We can pay for time using the stored credit in the
bank.


##### Sid note

On the whole I always find this confusing; Why would I have a bank account
if I can also simultaneously pay with an infinite amount of money? So I prefer
to think of it as me having (1) an infinitely large, slow, reservoir of gold, (2)
a quick cache of gold [which replaces the "bank"]. To pay for an operation,
I can only access money from my quick cache, because pulling money from my slow
reservoir is slow. I can transfer money from my infinitely large reservoir
to my quick cache of gold. The amortized method calculates the total amount of
gold that was pulled from the reservoir and stored into the cache.
We might have leftover gold in the quick cache (upper bound).
We can't have "negative gold" in the cache.
We define the **amortized cost** to be the total number of gold coins
**pulled out of infinite reservoir** by an operation.


#### Accounting example: 2/3 trees

When we insert, I pull $2 \log(n^\star)$ from my reservoir. I use $1 \log(n^\star)$
to pay for the insertion, and keep a reserve of $\log(n^\star)$ in the bank.
Then when we delete an element, we use the $\log(n^\star)$ extra we had kept
in the cache from the insert.

##### Better bounds: removing the star

We want to say that we pay $\log(n)$ for insert and delete 
where $n$ is the size of the tree when we perform the insert or delete.

Per insert, we pull in two gold coins worth $\log(n)$ from the reservoir
into the cache. When we delete, we use the $\log(n)$ in the cache from 
the money that was withdrawn when we created that element. See that the $n$
changes as the size of the data structure changes.

#### Table doubling via accounting

- When we insert a item into a table, withdraw $c + O(1)$ value from the reservoir.
  Keep gold coin worth $c$ that was in the cache _on the item that was inserted_.
  So imagine a real gold coin worth $c$ floating above the item.

- When we double the size of the table, use up as many old coins as possible,
  and then withdraw the rest of the cost from the infinite gold reservoir. Also
  withdraw to keep coins on the newly inserted items.

- So by the time we double, half of the elements have coins, other half don't.
  At the end, I'm going to have $n/2$ coins. The amortized cost of **doubling**
  is going to be $O(n) - cn/2$ which is going to be zero if $c$ is large. since I 
  will have $cn/2$ coins in my cache of gold.

- Insert costs $O(1 + c) = O(c)$ since we need to pull out those many coins from
  the infinite gold reservoir.


#### Charging method

Time travel/blame the past for your mistakes. We allow operations to charge
their cost retroactively to their past (not to their future!). An operation
can withdraw more value that it immediately needs from the infinite reservoir
into the gold cache, and it keeps it "for itself" for future-itself.

- amortized cost = total gold pulled out of infinite reservoir.


#### Charging example: Table doubling

After we double the table, the table is half-full, we need to perform $n/2$
insertions to get the table to be full. When we double the array next time,
we charge the doubling to the insertions since the last doubling!
There are $n/2$ items since the last doubling (I had `2` items, I doubled to `4` items, 
so there are `n/2` new items. Now I want to double and add `4` more items).
I have a cost of `O(n)` for the doubling. So I can charge `O(1)` cost to
all the new items since the last doubling. Note that I only charge once; after
I've charged items, I've doubled the array, so they are now "old".


#### Potential method (Most powerful) / Defining karma:

We define a potential function $\phi$ mapping a **data-structure-configuration**
to an natural number pile of gold coins. It tries to measure how bad the datastructure
is right now. We can pull money out of the pile of money in the potential.
Amortized cost is the actual cost plus the change in the amount of money in the
data structure configuration after and before:

$$
\texttt{amortized(op)} = \texttt{real(op)} + \phi(\texttt{after(op)})  - \phi(\texttt{before(op)})
$$

Adding up all the amortized costs, the sum telescopes, giving us 

$$
\texttt{amortized(total)} = \texttt{real(total)} + \phi(\texttt{end}) - \phi(\texttt{begin})
$$

- We really like to have $\phi(\texttt{begin}) = 0$.



#### Potential example: binary counter

flipping a bit is $O(1)$. How much will increment cost? An increment is going
to cost 1 + the number of trailing ones. We want to make this **constant**.


- What is making this bad? the number of trailing ones? Consider `11110` which has
  zero trailing ones.  If I increment it I get `11111`, which has 5 trailing ones.
  So I need to pull on 5 gold coins, which is `O(n)`. No good, I want `O(1)`.
  Though this is the natural thing to try, it doesn't quite work.

- Rather, we can define $\phi$ to be the total number of 1 bits. Whenever I increment,
  at maximum, I can add one `1`. If a number has `t` trailing bits, then on incrementing,
  I destroy `t` one bits, and add a single one-bit. eg: `0110 + 1 = 1000`. 

- The amortized cost is: `1 + t` (actual cost). The change
  in potential is: `t - 1` [lost `t` 1s, gained `1` one]. So the amortized cost is
  total cost - change in potential, which is `1 + t - (t - 1) = 2`, a constant. 



# Shelly Kegan: death --- Suicide and rationality (TODO)

How does the fact that we will die affect the way we live? previous 
chapter! The fact our mortality raises the question of whether or not
we should put an end to our life. It's the extra feature --- the variability
of death, the fact that we can control how long we live, and thus we face
the possibility of ending our life earlier than it would otherwise. Under what
circumstances is it a good thing to do?

You must be either crazy or immoral is the knee jerk. The very first thing
to do is to distinguish questions of rationality from morality. 

#### Rationality of suicide

1. When if ever would it be true that you are better off dead?
2. Assume that the answer to the first question is "under circumstance X, 

   you would be better off dead", can you trust your judgement that this is one
   of those cases X?

In those circumstances that life is terrible, you can't think clearly. So perhaps
you ought not attempt to make "rational decisions" under duress. Non existence
is not a state because it depends on existence.

Dying would be bad because it would deprive us of the good things in life ---
the deprivation requirement.  If we believe in the two state requirement, how
can we say this?  The two state argument can't even tell us that it's
better off to be alive for the happiest person! So the two state requirement
**is not a genuine requirement**. We simply have to say that the life you would
have had is a great life; I don't need to say anything about how death is going
to be inferior. The "loss of a good state" is enough, without needing to know
what we are transitioning _into_.

But if so, we can flip the argument by symmetry. If a person's life was full
of suffering and misery and disappointment, then for their life to go
longer would be bad.

What goes into making someone's life worthwhile? people disagree about the
ingredients of the best kind of life. Going back to hedonism (add all pleasure,
subtract all pain), if this number comes out negative, then your life is not
worth living. The longer you live, the more the balance shifts to the negative
(say).

Is life itself worth having? Neural container theory: life is a container
in which good/bad is filled up. Valuable container theories: the very fact
that you are alive gave you some positive value. Fantastic continer theories:
doesn't matter how bad the contents get, even so the grand total is still
positive. What's so incredible about life itself? They argue that being
alive itself is valuable. But most people don't really mean life, they mean
life as a person. For example, they would not agree that being alive as a 
blade of grass is a "good life".


What about a life where the person's functioning has decayed, but they can still
feel pain? In that case perhaps, their life's quality can degrade. 

We can probably find sympathy with the perspective that here on out, their
life is going to be net negative; someone who has terminal cancer and is in
great pain.

There could be a person where they're suffering from a degenerative diesease,
but are still able to think and have a life worth living while slowly losing
motor control. One day there comes a time when their life is not worth living,
but by that point, they don't have control over their body.

It's easy to mistake a low point with a global minima; Even if life is
*less worth living* than you hope it would be, it might feel terrible in
the position.

#### Deciding under uncertainty



##### Could it ever be true that you're better off dead?

The very claim that "jones would be better off dead" can't make any sense. In
order to make comparisons we need to be able to talk about states before
and after. Call this the two state requirement.

#### Morality of suicide

- [Shelly Kegan: death, 24. Suicide, Part 1](https://www.youtube.com/watch?v=MajfZIyHP8U&list=PLEA18FAF1AD9047B0&index=24)

# Sam harris and jordan peterson: Vancouver 1 (TODO)

> Is there a difference between religious and non-religious totalitarian states?
> Yes, dogma is the commonality. In the case of stalin / north korea, they
> are almost religions that are not branded as "religions". ~ Sam

> the problem with dogmas is that they do not allow revision. The moment someone
> has a better idea you have to shut it down. ~ Sam

> Free speech elevates error correction of dogmas above dogmas. So 
> Free speech must be on the pinnacle in the hierarchy of values ~ Peterson

> The only problem with the religion is the dogmatism. I've got no problem
> with the buildings and the music and ... ~ Sam Harris.

> What is the phenomenology of spiritual experience? That phenomenology is
> real! This phenomenology seems to confirm the dogma.

> The core element of tribal alliance is independent of the religious 
> substrate? Religion can allow clearly good people who are not captured
> by tribalism are able to perform atrocities. This suffering is not from a
> "ape like" urge. If you buy the claim that quran is the perfect word, then
> human rationality is bounded pathologically  which leads to worrying
> outcomes.

> Christians were the ones in egland who were against slavery ~ Petersen
> Yes, because they were the only ones around, so they must have done everything
> then ~ Sam
> Don't forget that the christians *used their christian faith* as an argument
> against slavery ~Petersen
> Well then it's unfortunate that they were on the losing side of an argument. 
> If only the bible had said "don't keep slaves" imagine how much easier their
> movement would have been ~Sam.

> Rise of postmodern interpretations of literature. Take a complex narrative,
> there are many ways of interpreting it. For example, consider a movie with
> a twist at the end. The twist changes the emaning of the entire movie. So while
> the bible may contain, sentence by sentence, things that are "just wrong"
> from a modern lens, perhaps it's not so when viewed holistically. 
> Everything in a narraitve is conditioned on the entire text. While you
> may argue that some sentences in the bible are so horrific that it's impossible
> to use context to massage them, you have to give the devil his due. The
> Christian bible is a narrative. 

> OK, what does this do to Moses' laws of war and doctrines?


> the notion of revelation and prophecy destroys a whole bunch of 
> soceity. I've read to the end of the book, it's scary to the end as well!

> there is an idea in the bible, that things are always going to be falling
> apart, there is an apocalyptic crux to everything touched by humanity.
> Hero is born in the darkest point in the journey. When things fall apart,
> that is the time of the hero.

> You can read into any story psychological insights ~ Sam. But you can do that
> with any set of facts too ~ Peterson. This why fundamentalim has an edge
> over modern theology. Modern theology concedes that we can't read it literally.
> But the more you get away from the literal you can broadcast whatever you want.

> This notion that redemption is to be found in truthful speech is embodied
> as a person. you want to ground values in something that is true. But the
> problem is that i can't see how you can inerpret the world of facts without
> an a priori structure.

> Kant identified time and space as a priori intuitions. I claim that stories
> are another kind of a priori intuition. You can write down stories of utpoia
> and dystopia; When you do, you're already two thirds your way to heaven and
> hell. Why not go all the way?

> Literal versus metaphorical truth. There are some truths that are literally
> false but if you behave as if they were true you come out ahead. 

> Imagine a universe where every possible mind is tuned to the worst possible
> experience that they can. If anything is bad, that's bad. If the word bad
> is going to mean anything, it's bad. I claim that this is a "factual claim".
> Every claim we make about anything, turtles all the way down, gets us to
> something that's bedrocked on intuition [Perhaps even math, in terms of
> the axioms _we choose_? Mh, I'm not very convinced, but sure]. If we are
> going to use the word bad and good, there will be an implicit acknowledgement
> that the worse possible misery for everyone is *bad*. It's *built in*. ~ Sam
> Jordan disagrees that this is a factual claim.


> Why did people do the worst things 

- [Sam harris and jordan peterson: Vancouver 1](https://www.youtube.com/watch?v=jey_CzIOfYE)

# Correctness of binary search


#### Closed-closed intervals


```cpp
// search in interval [l, r] for value `val`
int binsearch(int l, int r, int val, int *xs) {
  if (l == r) { return l; }
  int mid = (l+r)/2;
  if (xs[mid] <= val) { 
    return binsearch(l, mid, val, xs);
  } else {
    return binsearch(mid+1, r, val, xs);
  }
}
```

We have `(l <= mid < r)` since floor division of the form `(l+r)/2`
will pull values "downward". The length of the interval `[l, mid]` is smaller
than the interval `[l, r]` as `mid < r`. The length of the interval
`[mid+1, r]` is smaller than the interval `[l, r]` as `l < mid+1`. We
are monotonically decreasing on the quantity "length of interval", and terminate
the recursion when the length is zero.


#### Closed-open intervals

```cpp
// search in interval [l, r) for value `val`
int binsearch(int l, int r, int val, int *xs) {
  // [l, l+1) = { l }
  if (r == l + 1) { return l; }
  int mid = (l+r)/2;
  if (xs[mid] <= val) { 
    return binsearch(l, mid, val, xs);
  } else {
    return binsearch(mid, r, val, xs);
  }
}
```

We have `(l <= mid < r)` since floor division of the form `(l+r)/2`
will pull values "downward". Furthermore, if `r = l + 1` we end the
recursion. Thus, we are guaranteed that we will have that `r >= l + 2`.
Hence, `mid = (l+r)/2 >= (l + l + 2)/2 >= l + 1`. Thus, we have that:
`l` is to the left of `mid=l+1` is to the left of `r>=l+2`. So the
intervals `[l, mid)` and `[mid, r)` will be smaller, as we cleanly "separate"
out `l`, `mid`, and `r`.

# `readlink -f <path>` to access file path

To get the full path of a file, use

```
$ readline -f file
/path/to/file
```

This is useful to `scp`/`rsync` stuff.

# rank/select as compress/decompress

I haven't found a good naming convention so far for describing order
statistics. I'm taking about the common implementation:

```cpp
vector<int> xs(n);
vector<int> order2ix(n);
for(int i = 0; i < n; ++i) { order2ix[i] = i; }

sort(order2ix.begin(), order2ix.end(),
     [](int i, int j) {
        return make_pair(xs[i], i) < make_pair(xs[j], j);
     };
```

where `order2ix[o]` gives us the element with that order statistic. So,
`order2ix[0]` contains the smallest element, `order2ix[n-1]` contains the
largest element, etc. I've previously tried the naming conventions:

#### rank/select

`rank: ix -> order`, `select: order -> ix`. The pro of this is that it
uses the [rank/select](http://bitmagic.io/rank-select.html) naming convention.
This leads into the Galois connection aspect of it, but is otherwise not so
useful.
#### order2ix/ix2order

The signatures are `order2ix: order -> ix`, `ix2order: ix -> order`. This uses
the [order statistic](https://en.wikipedia.org/wiki/Order_statistic) naming
convention, and thereby makes it clear what the query is: you tell me the
kth order, I give you the index in the array in `order2ix(k)`. Alternatively,
you tell me the index `i`, and I'll tell you its order statistic in `ix2order(k).`


However, I found implementing this kind of odd. In particular, I need to
pause for a second and think about what maps to what in the `ix2order[order2ix[o]] = o;`.

```cpp
vector<int> xs(n);
vector<int> order2ix(n);
for(int i = 0; i < n; ++i) { order2ix[i] = i; }

sort(order2ix.begin(), order2ix.end(),
     [](int i, int j) {
        return make_pair(xs[i], i) < make_pair(xs[j], j);
     };

// REVERSE BIJECTION
vector<int> ix2order(n);
for(int o = 0; o < n; ++o) { ix2order[order2ix[o]] = i; }
```

For me, the major source of disconnect is that this "order" feels somewhat
disconnected from the original array `xs`. So I feel like I'm trying to reason
about these three

- The indexes `0, 1,..,n`
- The orders `0th,1st,2nd,..(n-1)th`
- The array values `xs[0],xs[1],xs[2],..xs[n]`

and it's unlclear to me how the two arrays `order2ix` and `ix2order` 
relate to each other.

#### `compressed`/`decompressed`:

Now for the new convention that I hope works better: `compressed`/`decompressed`:

The idea is that `compressed` maps the original numbers to their compressed variants.
So it's going to have a signature `compressed: ix -> smalluniv`, where it
compresses the element `xs[i]` into `[0..n-1]`. `decompressed` is the inverse
function, which takes a number in the smaller universe, and returns its
index in the original array. So we have `decompressed: smalluniv -> ix`.


##### Why I like this better

I feel this convention is superior, because it's intuitive to me at a glance
as to what `compressed`/`decompressed` do and why they should be inverses.  I feel
it also matches **the deep reason** for why kth order statistic exists: it
lets us perform universe reduction, to go from a large space of a total order
to a small space `[0..(n-1)]`. 

Furthermore, the very **name** implies that 
`compressed` is the compressed version of _something_ (the original array `xs`)
and that `decompressed` is the decompressed version of _something_ 
(the compressed universe `[0..(n-1)]`). This makes it clear how they're reated
to the original array linguistically, which I quite like.

  
# Remembering Eulerian and Hamiltonian cycles

I used to keep forgetting the difference. Here's how I remember it now. 
We know that an _euler tour_ always exists for a tree. Indeed, it's
a [handy data structure](https://en.wikipedia.org/wiki/Euler_tour_technique) 
that can be used to convet LCA (lowest common ancestor) into RMQ(range minimum query).

So, the "Euler tour" must exist for a tree. See that when we perform a tour
on the tree, we **definitely** walk a vertex twice (once when entering, once when
exiting). It seems like we walk the (undirected) edges twice as well.
However, if we consider the edges as **directed edges**, then we're only walking
the edges once. 

- So an euler tour must correspond to a tour where we walk over each edge
  exactly once.
- A hamiltonian tour must (by complementarity) correspond to a tour where we
  over each vertex exactly once.

# Nice way to loop over an array in reverse

```cpp
const double n = sizeof(spheres) / sizeof(Sphere), inf = t = 1e20;
for (int i = int(n); i--; ) { } //chad
for (int i = n-1; i >= 0; i--) { // simp
```


# Dynamic Programming: Erik Demaine's lectures

I realized I'd never bothered to ever formally learn dynamic programming,
so I'm watching Erik Demaine's lectures and taking down notes here.

## DP 1: Fibonacci, shortest paths

- [Video lecture here](https://www.youtube.com/watch?v=OQ5jsbhAv_M&list=PLcDimPvbmfT8qAxD6JH_kmXiQwTNcoK78)

1. DP ~= careful brute force.
2. DP ~= subproblems + "recurse"


#### Fibonacci

```
F(1) = F(2) = 1; F(n) = F(n-1) + F(n-2)
```

##### Naive: 

```py
fib(n):
  if n <= 2: f = 1
  else f = fib(n-1) + fib(n-2)
  return f
```

EXPONENTIAL time! `T(n) = T(n-1) + T(n-2) + O(1)`. Since it's the fibonacci
recurrence, the solution is rougly $\phi^n$ where $\phi$ is the golden
ratio. Alternate, `T(n) >= 2T(n-2) ~ 2^(n/2)`

##### Memoized DP:

```py
memo = {}
fib(n):
  # vvv 
  if n in memo: return memo[n]
  if n <= 2: f = 1
  else f = fib(n-1) + fib(n-2)
  # ^^^
  memo[n] = f
  return f
```

- We can think about it in terms of the recursion tree, where this allows
  us to not have to recompute some of the data.
- The alternative way of thinking about it is that there are **two ways**
  of calling `fib`: the first time, it's non-memoized, which recurses. Every
  other time, we're doing **memoized calls** that are constant time.
- The number of non memoized calls in `n`. These we have to pay for. The non
  recursive work per call is constant.
- Therefore, the running time is linear! Linear because there are `n` non
  memoized calls, and each of them cost **constant time**.
- In general, in DP, we _memoize_  (remember) solutions to **subproblems** that
  help us solve the actual problem. So, `DP = recursion + memo`.
- `Running time = number of different subproblems x time per subproblem`.
  When we measure **time per subproblem**, we ignore recursive calls!
  (don't count recursions). 

##### Bottom up DP algorithm

```py
fib = {}
 -- | some thought for the loop
for k in range(1, n+1): 
  if k <= 2: f = 1
  else: f = fib[k-1] + fib[k-2]
  fib[k] = f
```

Order based on any topo sort of dependency DAG. From the bottom up perspective,
we can decide how much we need to store based on how much state we need.

```
  *------------*
  |            v
f(n-2) f(n-1) f(n)
          |    ^
          *----*
```


#### Single Source Shortest paths (`s-v` path)

- Tool to find answers: *guessing*. Suppose you don't know it. how do you find the
  answer? guess! Don't try any guess, try *all* guesses! (then take the best one).
- DP = recursion + memoization + guessing.


There is some hypothetical path from `s` to `v`. We don't know what the first
edge of this hypothetical path is, so we guess. We try all of the paths from
`s->s'`. This changes `s`, but we really care about **single source** shortest
path. So rather, we choose to guess `v`. We guess the last edge `u? -> v`.
Recursively compute the path from `s` to `u?`, and then add the path to `v`.

```
\delta(s, v) = \min_{(u,v) \in E} \delta(s, u) + w(u, v)
```

Subpaths of shortest paths are shortest paths! Memoize to make it fast? Why
is it faster on memoization?


```
*---a----*
v   ^    v
s   |    w
|   |    |
*-->b<---*
```

```
δ(s, w) 
  δ(s, a)
     δ(s, b)
       δ(s, s)
       δ(s, w) <- INFINITE
```

- Infinite time on graphs with cycles.
- For a DAG, it runs on V+E. Number of subproblems = `V`. Time we spend per
  subproblem at a vertex is the number of incoming edges.
  we can't take product, because the time per subproblem can vary wildly. So we restate our "time formula" as

```
total time = sum over times of all subproblems (modulo recursion)
```


This gives us:


```
total time = sum indeg(v) + O(1) = O(E) + O(1)
```

- **LESSON LEARNT: subproblem dependencies should be acyclic!**

- Claim: can use same approach for graphs! Explode a cycle over time. This makes
  any graph acyclic.

> **Sid question**: Can we derive Djikstras using the same "cycle explosion"
> trick?

We define $\delta_k(s, v)$ to be weight of shortest path that uses at most `k` edges.


```
\delta_k(s, v) = \min_{(u, v) \in E} \delta_{k-1}(s, u) + w(u, v)
```

We've increased the number of subproblems. We know that the longest path
possible can have $|V| - 1$ edges. So the `k` parameter goes from `[0..|V|-1]`
while the vertex `v` can be any vertex. Per vertex `v` we spend `indeg(v)` time.
So we get the total recurrence as:

$$
\begin{aligned}
&\sum_{(k \in [|V|-1], v \in V)} T(k, v) =  \\
&\sum_{k \in [|V|-1]} \sum_v indeg(v) = \sum_{k \in [|V|-1]} E = VE
\end{aligned}
$$

##  DP 2: Text Justification, Blackjack

- [Video Lecture](https://www.youtube.com/watch?v=ENyox7kNKeY&list=PLcDimPvbmfT8qAxD6JH_kmXiQwTNcoK78&index=2)

#### 5 "easy" steps to a DP

1. Define subproblems; analysis - number of subproblems
2. Guess (part of solution); analysis - number of choices for the guess
3. Relate subproblem solutions [with a recurrence]; analysis - time per subproblem (ignoring recursion)
4. Build an algorithm: [recursion/memo, or tabling]; check recurrence is acyclic 
5. solve original problem;  total time: total time across all subproblems (ignoring recursion).
   In simple cases, total time = number of subproblems x time per subproblem.
6. Check that the original problem actually gets solved!


#### Recap: Fibonacci
1. subproblems: `F(1)...F(n)`
2. guess: nothing
3. relate: `F(n) = F(n-1) + F(n-2)`; `O(1)` time
4. F(n). constant time to find 

#### Recap: Shortest path
1. subproblems: $\delta_k(s, v)$. $V^2$ subproblems.
2. guess: last edge; edge into $v$.
3. relate: $\delta_k(s, v) = \min_u \delta_{k-1}(s, u) + w(u, v)$; `indegree(v)` time
4. <blank>
5. $\delta_{v-1}(s, v)$ for all $v$. This takes $\Theta(V)$.

#### Text Justification

split text into "good lines". can only cut between word boundaries. Text is
a list of words. `badness(i, j)`: how bad is it to use `words[i:j]` in a line.
They may fit, or they may not fit. If they don't fit, then badness is `∞`.
Otherwise, it's going to be `(pagewidth - total width)^3`.
We want to minimize the sum of badnesses of the lines.

1. subproblems: the hard part! exponential: Guess for every word, whether a line
   begins or not. What is the natural thing to guess? guess how long the first
   line is / guess where the second line begins. After I guess where the second line
   is, I now have the remaining words to text justify. So the subproblems are
   going to be suffixes of the array: `words[i:]`. If we have `n` words, we have
   `n` suffixes. We're going to only remember *one line* [forget the past!],
   not *all the lines!* [this is exponential!]
2. Guess: where to start the second line. If we are at location `i`, there are `n-i`
   choices which we will think of as `O(n)`.
3. Recurrence: $dp[i] = \min{i+1 \leq j \leq n} \texttt{badness}(\texttt{words[i:j]}) + dp[j]$.
   Time per subproblem is `constant x [i+1..n]` which is `O(n)`.
4. Check recurrence is acyclic/topo order: `n, n-1, ... 1`
5. Total time: `number of subproblems x time per subproblem = O(n^2)`
6. Original problem: `dp[0]`.


#### Parent pointers

Remember which guess was best. Find actual solution, not just the cost of the

##### fiat

> fiat lux.

Let there be light
solution.


n suffixes | exp many sybsets. dont need to know history!





#### Blackjack

> whatever, I don't particularly care about the game

## DP 3: Paranthesization, Edit distance,  knapsack

#### Sequences

Good choices of objects to perform DP on:

- Suffixes: `x[i:]` for all `i`. `O(n)`.
- Prefixes: `x[:j]` for all `j`. `O(n)`.
- Substrings: `x[i:j]` for all `i` and `j`. `O(n^2)`.

#### Parenthesiztion

optimal order of associative expression.: `A[0] . A[1] ... A[n-1]`. Order
matters for matmul!
- What should we guess? There are exponentially many parenthesizations!
  Guess the outermost/last multiplication. Ie, we want to know:

```
(A[0] ... A[k-1]) * (A[k] ... A[n-1])`
```

- We can't just use prefixes and suffies, because when we recurse into
  `A[0]...A[k-1]`, we're going to get splits of the form `A[0]...A[k']`
  and `A[k']...A[k-1]`. In general, if we feel we need *both* prefixes AND suffixes, we likely
  need the full power of substrings.
- So our choice of subproblem is: `dp[i][j]` is the optimal outermost split for
  `A[i]...A[j-1]` The number of choices is `O(j-i+1) = O(n)`.

```py
dp[i][j] = min{
  for k in range(i+1, j):
    dp[i][k] + dp[k][j] + cost of (A[i:k] * A[k:j])
}
```
- Time is polynomial. `O(n)` time for subproblem ignoring recursions. 
  We have `O(n^2)` subproblems (substrings). So the running time is `O(n^3)`.
- Topological order: in general, if we have prefixes, we go left to right.
  have suffixes, we go right to left. If we have substrings, we
  evaluate based on **increasing substring lengths**, since when we split,
  we get substrings with smaller lengths.

#### Edit distance
Given two strngs `x` and `y`. Find the cheapest way to convert `x` into `y`. 
We allow _character edits_ to turn `x` into `y`: We can (1) insert a character 
anywhere in `x`, (2) delete a character anywhere in `x`, (3) edit any character in `x`.
We have custom costs for each insert and delete.

- Can also solve longest common subsequence. `HIEROGLYPOHOLOGY`, `MICHAELANGELO`.
  Drop any set of letters from x and y, we want them to be equal. Model it as
  edit distance. Cost of insert/delete is `1`, cost of replacement is `0` if
  characters are equal, `∞` otherwise.
- We will look at suffixes of `x` and `y` at the subproblem. Subproblem is
  edit distance on `x[i:]` AND `y[j:]`. Number of subproblems is $O(|x| |y|)$.
- We need to guess! Not so obvious. Look at the first characters. What can I 
  do with the first character of `x`? (1) I can replace the first characters.
  (2) I can insert the character `y[j]` into `x`.
  (3) I can delete the character `x[i]`. So we have:

1. Replace `x[i]` with `y[j]`.
2. Insert `y[j]`.
3. Delete `x[i]`.


```py
dp[i][j] = min{
  cost of replace x[i] with y[j] + dp[i+1, j+1],
  cost of insert y[j] + dp[i][j+1],
  cost of delete x[i] + dp[i+1][j],
}
```

The topological order is going to have smaller to larger suffixes.


> What I found really interesting is the offhand remark that longest common
> substring is **just edit distance** where we are allowed to only delete
> or keep characters.

#### Knapsack

List of items, each of size `s[i]` and a desire/value `v[i]`.  The sizes
are integers. We have a backpack of total size `S`. We want to choose a subset
of the items which maximize the value, and also fit into the backpack: $\sum s[i] \leq S$.


- Even though it seems like we don't have a sequence, we have a set of items
  we can put in *any* sequence. We can look at sequences of items.  At the item
  `i`, we should guess if item `i` is included or not.

```py
# v WRONG
dp[i] = ... max(dp[i+1], dp[i+1] + v[i])`
```

We don't keep track of the sizes! Rather, we choose our subproblem to be the suffix
AND the remaining capacity $x \leq S$. We have $O(n S)$ subproblems

```py
# v correct
dp[i][s] = max(dp[i+1][s], dp[i+1][s-s[i]] + v[i])
```

To be polynomial in the input, it would have to be $\theta(n \log S)$ because
$S$ is given as a number. It would not be $nS$; $S$ is exponential in the 
input encoding $\log S$.


## R21: DP: Knapsack

We have `n` decisions: `d[i]` is do I take item `i`. What do we need to keep
track of? I need to know how much weight I have left. This is equivalent to
knowing the sum of the items. The edge is an arbitrary item, the weight is `-v[i]`
since we're trying to phrase the problem in terms of shortest path. The state
in the node is item I'm looking at, and weight of the items I've taken so far.


$$
\begin{matrix}
\end{matrix}
$$


#### DP4: Guitar fingering, tetris, super mario bros

A second kind of guessing. Guessing usually which subproblem to use to solve
a bigger subproblem. Another way of guessing is to add more subproblems to guess
or remember more features of the solution. 

##### Mapping to knapsack

obvious solution was suffix in knapsack. So we needed to know how many units
of the knapsack we've used up; we're remembering something about the *prefix*
(but not the full prefix itself). On the other hand, in the forward direction,
we were solving more _types_ of subproblems, for varying sizes of knapsacks.

#### Piano and guitar fingering: Take 1

Given some musical piece to play: a sequence of `n` notes we want to play.
We want to find a fingering for each note. We have fingers `1` upto `f`. We want
to assign a finger to each note. We have a difficulty measure `d(p, f, p', f')`:
how hard is to transition from note `p` (p for pitch) with finger `f` to note
`p'` with finger `f'`?

- Subproblems: prefixes? suffixes? substrings? Suffixes are kind of fine. How to
  play notes `n[i:]`.
- Guess: Which finger to put on note `i`?
- Recurrence: 

```py
dp[i] = min({ 
   for f in fingers:
      dp[i+1] + d(i, f, i+1, ?) # WRONG: don't know ?
})
```

- Add more subproblems! how to play `notes[i:]` when using finger `f` for `notes[i]`.
- What to guess? finger `g` for note `(i+1)`

```py
dp[i][f] = min({
  for g in fingers:
      dp[i+1][g] + d[notes[i], f, notes[i+1], g]
}
```

- Topological order: 

```py
for i reversed(range(n)):
   for f in range(F): ...
```

- Original problem: we don't know what finger to use for `dp[0]`. So we can take
  a `min` over all fingers. `min([ dp[0][f] for f in range(F)])`


#### guitar chords:

Generalize the notion of "finger" to "finger(F) + string(S)". This gives
us $O(N((F+S)^2)) = O(NF^2S^2)$.  Multiple notes: `notes[i] = list of F notes` for
a piano.

- state: we need to know about the assignment of fingers to notes (or no note).
  So that's $(N+1)^F$. Generalize the rest.

#### Tetris

We know the entire sequence of pieces that's going to fall. For each, we must
drop the piece from the top. Also, full rows don't clear. 
The width of the board is small. The board is initially emoty.
Can you survive?


The subproblems are how to play suffixes of `pieces[i:]`. We need to know
what the board looks like. If the board doesn't clear and we always drop from
the top, then all we need to know is the skyline.

```


1| ###
2| #
3|####
4|####
5|####
```

- So we also store the board skyline. We have `h` different choices for each
  column. There are `w` columns. So we have `(h+1)^w` number of choices for
  skylines. Total number of subproblems is `n.(h+1)^w`.
- Guess: what do I do with piece `i`? I can rotate it `0, 1, 2, 3` times, and the
  where to drop it. I can guess where to drop the piece. This is `4w` choices ---
  `4` for rotation, `w` for where we drop.

- Here the answer is a boolean: survive (1) or not (0). we want to survive, so
  we can just use `max` on a boolean.

#### Super Mario Bros

Recall that in the original super mario bros, if something moves out of the
screen it's lost forever; We can't move back in the old mario. We're given
the level, and a small $w\times h$ screen. The configuration of the game is
everything on the screen! Total info is going to be $c^{wh}$ where `c` is some
constant. We also need Mario's velocity, the score, and time. score can be S
big, time can be T big. The number of configurations is the product of all of
these. We also need to know how far to the right we have gone, which is another
`W`. Draw a graph of all configurations, and then use DP

## Lecture 10: Advanced DP by Srinivas

- [Video](https://www.youtube.com/watch?v=Tw1k46ywN6E&list=PLcDimPvbmfT8qAxD6JH_kmXiQwTNcoK78&index=10)

#### Longest palindromic sequence

Find palindrome inside longer word. Given a string `X[1..n]`. Find longest
palindrome that is a subsequence.

```
character
c arac
```

answer will be greater than or equal to 1 in length because a single letter
is a palindrome.

```
turboventilator
  r o   t  ator
```

- `L[i, j]`: length of longest palindromic subsequence in string `xs[i:j]` where `i<=j`.

```py
def L(i, j): # closed interval
  if i > j: return 0 # no letters
  if i == j: return 1 # single letter palindrome
  if x[i] == x[j]: 
    return 2 + l(i+1, j-1)
  return max(L(i+1, j), L(i, j-1))
```
- number of subpbroblems: $O(n^2)$. Time per subproblem assuming recursion is free: $O(1)$.
  Hence, total time is $O(n^2)$.

#### Optimal binary search trees

Find most balanced BST for a set of keys. We have weights for the keys, which
are search probabilities. Find a BST T (there are exponential number of BSTs)
that minimizes $\sum_i w_i (depth_T(k_i) + 1)$. Depth of root is 0. Depth
of a node is distance from the root. This minimizes expected search cost.

##### Enumeration


We have exponentially many trees. 

##### Greedy soltution / Why doesn't greedy work?

Assume the keys are sorted.
Pick `K[i]` in some greedy fashion (max.weight).
This immediately splits the set of keys into the left and right.
If we define `e(i, j)` to be the cost of the optimal BST on keys `k[i], ..., k[j]` .

```
greedy:
-------
        2|w=10
1|w=1           4|w=9
           3|w=8
```


```
optimal:
-------
         3|w=8
    2|w=10    4|w=9
1|w=1         
```

##### DP

- Guess all possible root nodes. The greedy algorithm doesn't try to guess the
  root node, that's the only difference.

```py
-- e(i, j): cost of tree with keys k: i <= k <= j
def e(i, j):
  if i == j: return w[i]
  # | WRONG
  return min([e(i, r-1) + e(r+1, j) + w[r] 
              for k in range(i, j+1)])
```

The weights are going to change when we increase depth, so we actually need
to add all the weights from `i` to `j`! So we write:

```py
-- e(i, j): cost of tree with keys k: i <= k <= j
def e(i, j):
  if i == j: return w[i]
  # | WRONG
  return min([e(i, r-1) + e(r+1, j) + weight(i, j)
                 for k in range(i, j+1)])
```

##### Alternating coins
Have a list of coins. We have an even number of coins.
Can only pick coins from the outside.

First player can always not lose in the game.  What the first player does
is compute `v[1] + v[3] + ... v[n-1]` versus `v[2] + v[4] + ...` which is even.
If the odd values win, the he picks `v[1]`. P2 can pick `v[2]` or `v[n]`. 
P1 can pick either `v[3]` or `v[n-1]` depending on if P2 picked `v[2]` or `v[n]`.

- We now want to **maximize** the amount of money.

```py
v(i, j) = max([ range is(i+1, j) with P2 + v[i],
                range is (i, j-1) with P2 + v[j] ])
```

If we have `v(i+1, j)` subproblem with the opponent picking, we are guaranteed
that the opponent plays `min(v(i+1, j-1), v(i+2, j))`. So we can unfold this,
to get the full DP:


```py
v(i, j) = max([  min(v(i+1, j-1), v(i+2, j)) + v[i],
                  min(v(i, j-1), v(i+1, j)) + v[j],
```

##### DP: All pairs shortest paths.



# Accuracy vs precision

<img src="./static/accuracy-vs-precision.png"/>

I had a hard time remembering which is which, so here's how I do it now.
First, I think of it from a probabilistic lens, where one of them is the
mean, and the other is variance of a gaussian distribution as shown above.
We don't yet know whether accuracy is the mean or the variance. 

Next, recall that it's linguistically correct to say:

> you're precisely wrong

but not

> you're accurately wrong.

Thus, we can be precise about something wrong. That is, we can
be very "precise" about "hitting the wrong target". So, precision ought
not care about the *true value*, just about *how well we hit something*.
This is exactly what the variance attempts to capture: how "spread out"
we are, or "how well we hit the mean".


The accuracy itself is the distance between the mean of our distribution and
the true reference value we want to hit.

# Why is the gradient covariant?

- [expanation of gradient being covariant in terms of the integral version](https://physics.stackexchange.com/a/127534/129278)

# Politicization of science

- [Reference](https://en.wikipedia.org/wiki/Politicization_of_science)

# Multi ꙮ cular O: ꙮ / Eye of cthulu

- [Multiocular O](https://en.wikipedia.org/wiki/Multiocular_O)

# You can't measure the one way speed of light

- [Veritasium video](https://www.youtube.com/watch?v=pTn6Ewhb27k)

# Show me the hand strategy

So, how do you surface covert-aggressions and covert-criticism?  Enter the:
Show Me The Hand Strategy The "show me the hand strategy" can be applied with
several techniques, including: Pretend you don't understand: if you don't
understand and they did want to make their point across, they will be forced to
be more direct in their aggression / offense Ask them what exactly do they
mean: you can use the broken record technique here, where you keep repeating
"what do you mean by that", "OK, but it does sound like you were trying to
criticize my work. It's OK if you do", "then, if you didn't want to criticize,
what did you mean" Go meta: explain them what they were doing, and tell them
that you prefer direct talk because "you can take it" (invite criticism into
the open), because you "expect better from them" (big judge power move), or
because "it's so much better for both" (leader-like win-win approach) Reframe
their aggression as support: nice power move and you will possibly get under
their skin when they wanted to get under yours. They wanted to hurt you, or to
harm your status, so when you reframe their attack as support, they will feel
compelled to come out in the open and be more direct


# Words that can be distinguished from letters if we know the sign of the permutation

```py
#!/usr/bin/env python3
with open("google-10000-english.txt", "r") as f:
    words = [w.strip() for w in f.readlines()]


sorted = {}
for w in words:
    wsort = list(w)
    wsort.sort()
    wsort = "".join(wsort)
    if wsort in sorted:
        sorted[wsort].append(w)
    else:
        sorted[wsort] = [w]

collisions = 0
for wk in sorted:
    if len(sorted[wk]) == 1: continue
    collisions += 1
    print(sorted[wk])
    print("---")

print(collisions, len(words), 100.0 * float(collisions) / len(words))


collisions = 0
for wk in sorted:
    collidews = sorted[wk]
    for i in range(len(collidews):
            for j in range(i+1, len(collidews))
    collisions += 1
    print(sorted[wk])
    print("---")
```

# Easy times don't create weak people, they just allow weak people to survive.

Easy times doesn't weaken the _generator_ side of things, it simply weakens
the _adverserial_ side of things allowing weak people to survive.

# Multiplicative weights algorithm (TODO)

# How to fairly compare groups
                                                                                              
> Why is this a key argument? It’s really quite simple. Let’s say I have two
> groups, A and B. Group A has 10 people, group B has 2. Each of the 12 people
> gets randomly assigned a number between 1 and 100 (with replacement). Then I
> use the highest number in Group A as the score for Group A and the highest
> number in Group B as the score for Group B. On average, Group A will score
> 91.4 and Group B 67.2. The only difference between Groups A  and B is the
> number of people. The larger group has more shots at a high score, so will on
> average get a higher score. The fair way to compare these unequally sized
> groups is by comparing their means (averages), not their top values. Of
> course, in this example, that would be 50 for both groups – no difference!


- [Chessbase article about men v/s women in chess](https://en.chessbase.com/post/what-gender-gap-in-chess)

# Z algorithm (TODO)

The `Z` algorithm, for a given string $s$, computes a function $Z: [len(s)] \rightarrow [len(s)]$.
$Z[i]$ is the length of the longest common prefix between $S$ and $S[i:]$.
So, $S[0] = S[i]$, $S[1] = S[i+1]$, $S[2] = S[i+2]$, and so on till 
$S[Z[i]] = S[i + Z[i]]$, and then $S[Z[i]+1] \neq S[i + Z[i] + 1]$.


If we can compute the `Z` function for a string, we can then check if pattern `P`
is a substring of text `T` by constructing the string `P#T$`. Then, if we
have an index such that `Z[i] = len(P)`, we know that at that index, we have
the string `P` as a substring.

Note that the `Z`-algorithm computes the `Z` function in **linear time**.


```cpp
const int N = 1000;
int z[N];
char s[N] = "hello, world";
int n;

// write the z array into the array z for the string s
void mkz(const char *s, int *z) {
    const int N = strlen(s);
    int curi = 0;
    while(s[curi]) {
        int matchlen = 0; 
        while(curi + matchlen < N) {
            if (s[curi + matchlen] == s[matchlen]) { matchlen++; }
            else { break; }
        }
        z[curi] = matchlen;

        for(int i = 0; i < matchlen && i < curi; ++i) { z[curi + i] = z[i]; }
        curi += matchlen;
    }
}

int main() {
in
}
```

- Reference: Algorithms on strings, trees, and sequences.


# Bijection from `(0, 1)` to `[0, 1]`

<img src="./static/bijection-between-closed-01-open-01.png">

# Rene Girard

- [Link where I first heard of him](https://alexdanco.com/2019/04/28/secrets-about-people-a-short-and-dangerous-introduction-to-rene-girard/)

# Noam Chomsky on anarchism (TODO)

- [Video of interview](https://www.youtube.com/watch?v=totmHrIJzK8)
- Emma Goldman Archives

#### Interview


What do we do with people who don't want to work or those with crimimal tendencies?
What do we do with people's interests, do they deserve to interchange jobs?

There would a general agreement between people who call themselves anarchists
should maximise people's abilities to fulfil their potential.

Another problem is that at any point in human history, people have not understood
what is opression. Chomsky's grandmother didn't think she was opressed while
being in a patriarchial family.

#### What is anarchism

- [What is anarchism](https://www.youtube.com/watch?v=yccBBzSHFAM)

Start with Rudolf Rocker.

> Anarchism is not a fixed social system with fixed answers, but a trend
> in mankind that drives for free unhindered unfolding 

These derive from the Enlightenment. Thus institutions that constrain
such development are illegitimate unless they can justify themselves. Adam 
Smith extolls the wonder of division of labour. Deeper into the book,
he argues that in any civilized society, the government must not allow division of labour
for it makes a human as stupid as they can be.

Anarchism seeks to identify structures of domination, authority, etc that constrain
human development. It then challenges them to justify themselves. If you 
cannot meet the challenge, the structure should be dismantled and reconstructed
from below.

Anarchism is basically 'truism', which has the merit, at least, of being true.
It's an interesting category of principles that are universal and doubly
universal: universally accepted, and universally rejected in practice!



# Slavoj Zizek: Violence

- [Video talk at google](https://www.youtube.com/watch?v=_x0eyNkNpL0)

What does violence react to? What is the everyday texture of our lives? Ideology
in the sense of complicated networks of social, political prejudices determines
the way we functions and structures our life. What is ideology?

Donald Rumsfield, gulf war, spoke about known knows (saddam is a dictator),
known unknowns ('WMD that saddam surely had'), and unknown unknowns 
('even worse WMD that saddam may have').

What about unknown knowns? Things we don't know that we know? This is ideology.
The texture into which we are embedded.

European trinity: France (revolutionary, political), 
German (conservative, poets, thinkers), 
Anglo saxon (liberal, economy).

Bohr had a horsheshoe above his house. 'Do you believe in it? Aren't you a scientist?'
'Of course I don't believe in it! But I was told that it works regardless of my belief in it!'.


What is ideology today? It seems very shallow, things of the form 'go achieve',
and whatnot. However, there is a lot more that is tacit.

'Interpassivity': we transpose onto the other our passive reaction. Others are
passive for us. Canned laughter on TV. Literally, the TV set laughs for you.
You feel relief as if you have laughed. 

Similarly it's not that we believe. We need someone else to believe for us.
For example, santa Claus. The parent's don't believe, they do it to not let down
the kids. The kids don't believe, they pretend for presents and to not let
down the parents. The whole system of belief functions.

The first person to do this politically is the isareli prime minister
Golda Meir. When asked 'do you believe in god'. Her answer was 'no. I believe in 
jewish people, and they believe in God'. But atheism is ~70% of israel.


When different cultures are thrown together (globalism) we should break the 
spell of liberalism: we cannot understand each other, we don't even
understand ourselves. I don't want to understand all cultures. We need a code
of discretion. How do we sincerely politely ignore each other? We need proper
distance to treat others in a non-racist, kind manner.

He upholds that we don't even miss anything deep in this way. Do I really understand
you? Do I really understand myself? 

> We are the stories we are telling ourselves about ourselves. The basic
> freedom is to tell your side of the story.

The motto of tolerance:

> An enemy is someone whose story I have not yet heard.

Living libraries, people can visit minorities and talk to them. It works at a
certain level. But it stops working at some level. Because we would not say
the same of Hitler.  'The X files insight'. Truth is _out there_. It's not
in what you are telling yourself about yourself. The story you are telling
yourself is a lie.

Two extreme examples. One from Europe, one from far east.
- Grey Eminence
- Zen at War


Corruption is prohibited officially, and it is exactly codified in a communist
country. Holidays in Japan. You are given 40 days. It's very impolite to take
more than 20 days. This creates a link between people, the link of politeness.
This is ideology. Prohibition is is prohibited to be stated publicly.

Nazi germany without glasses is 'sacrifice your country'. With glasses, it is
'do this, pretend to do this, we can have some fun, beat the jews'. Ideology
always offers you some bribery.


When hitler finishes giving a talk, the people clap. In a communist speech,
at the end of the speech, the speaker claps with the people. This is a 
crystallization of the difference between fascism and communism.


'Nice to meet you, how are you?' is a sincere lie. From the very beginning
we entered into language, we enter into requiring one for whom we can 
create appearances.

- [Zizek interview at BBC](https://www.youtube.com/watch?v=xN2ZGSX0cIE)

> The light at the end of the tunnel is an oncoming train

Embracing hopelessness means to accept that there are no easy solutions. We should
accept the hopelessness and start a paradigm shift.  Our tragedy is death. 
Something will have to change fundamentally. We do not yet have the formula of
what to do. We can now only get ready for a global crisis.



> The problem with Hitler was that he wasn't violent enough. In the same way
> that Gandhi was more violent than Hitler, in terms of 'systemic change'.
> Hitler killed millions to save the system. Gandhi killed no one to setup
> a radical change. Change will hurt.

We tend to forget the violence of keeping things the same, and we only consider
the violence of change. Sometimes the gratest violence is to not participate.

Modi, China, Russia: Global market, Cultural narrowness.


> Polyamory is instrumental.
> True love is where you cannot be without someone else.


It is a sign of progress that some things are considered ideology. For example,
''is it right to kill?'' will be laughed at. The problem with current societies
is that we are eroding the set of things we can laugh at due to dangerous
ideas of relativism.

- [Zizek v/s Petersen](https://www.youtube.com/watch?v=lsWndfzuOc4)

Petersen: truths of the communist manifesto:

- History is to be viewed as an economic class struggle.
- Hierarchical structure is not attributable to capitalism.
- We're also in odds with nature, which never shows up in Marx.
- Hierarchical structures are necessary to solve complicated problems.
- Human hierarchy is not based on power. Power is a very unstable means of
  exploiting people.
- History comes off as a 'binary' class struggle in Marx.
- 'Dictatorship  of the proleteriat': Race to bottom of wages. The fact that we
  assume that all the evil could be attributed to the bourgouise itself
  setup the seeds for revolution.
- How will the replacement of the bourgouise happen? Why wouldn't the proleteriat
  become as or more corrupt than the capitalists?
- What makes you believe that you can take a complicated system like the free
  market and then centralize this?
- A capitalist who is running a business as a manager does add value.
- The criticism of profit. What's wrong with profit? Profit is theft is the
  marxist principle. If the capitalist adds value to the corporation, then they
  do deserve profit. Profit sets a constraint on wasted labour. There are forms
  of stupidity you cannot engage in because the market will punish you for it.
- 'The dictatorship of the proleteriat' would become hyper-productive. How?
  The theory seems to be that once we eradicate the profit motive and the
  bourgouise allows them to become hyper productive.
- We need hyper productivity for the dictatorship of the proleteriat to create
  enough goods for everyone. When this happens, everyone will engage in meaningful
  creative labour, which they had been alienated from in capitalism. Then this
  will create a utopia.
- Does this utopia really be the right utopia for everyone?
- The Dostovyeskian observation: what shallow take on people do you need to believe
  that if you hand people everything they need, they'll be happy? We were built
  for trouble. Hanging out on the beach is a vacation, not a job. We would
  destroy things just so something can happen just so we can have the adventure
  of our lives.
- Marx and Engels admit that there has not been a system that's capable to produce
  materials in excess as capitalism.

Zizek:
- The irony of how Petersen and him are both marginalized by the academic
  community.
- China today: strong authoritarian state, wild capitalist dynamics. It's managed
  to uplift hundreds of millions of people out of poverty. They want the
  Cofuscian ideal of harmonious society.
- Happiness as goal of life is problematic. Humans are creative in sabotaging
  pursuit of happiness. We have to find a meaningful cause beyond the mere
  struggle for pleasurable survival. Modernity means that we should carry the
  burden of freedom of choice.
- Never presume that your sufferring is in itself a proof of authenticity.
  Renunciation of pleasure can turn into the pleasure of renunciation.
- 

# Poverty: Who's to blame?

- [Video](https://www.youtube.com/watch?v=jAaCpyuwRIw)

#### First blame countries
- Third world countries have terrible economic policies
- Administrations in third world countries are dysfunctional.
- First world countries *block* workers from immigrating for which we can blame
  first world countries.

#### Secondly blame individuals: The trifecta
- work at a stable job even if the job is not fun
- don't have kids if you can't afford it

#### Blame matters
- Blame affects wheher something is a social issue. For example, is the opioid
  epidemid a social behaviour? or should we just blame individuals?
- Blame affects who should be shamed for failing to change their
  behaviour.


#### Books to read
- Doing the best I can
- Promises I can keep

# Learn Zig in Y minutes


- imports:

```
const std = @import("std");
```


- globals:

```
// global variables.
const x = 1234;
```


- comments:

```
//! Top level comments are setup using //!
//! This module provides functions for retrieving the current date and
//! time with varying degrees of precision and accuracy. It does not
//! depend on libc, but will use functions from it if available.
```

- main:

```
pub fn main() !void {
    const stdout = std.io.getStdOut().writer();
    try stdout.print("Hello, {}!\n", .{"world"});
    // Comments in Zig start with "//" and end at the next LF byte (end of line).
    // The below line is a comment, and won't be executed.
```

- ints:

```
    // integers
    const one_plus_one: i32 = 1 + 1;
    print("1 + 1 = {}\n", .{one_plus_one});
```
- floats:

```
    // floats
    const seven_div_three: f32 = 7.0 / 3.0;
    print("7.0 / 3.0 = {}\n", .{seven_div_three});
```

- bools:


```
    // boolean
    print("{}\n{}\n{}\n", .{
        true and false,
        true or false,
        !true,
    });
```

- optionals:


```
    // optional
    var optional_value: ?[]const u8 = null;
    assert(optional_value == null);

    print("\noptional 1\ntype: {}\nvalue: {}\n", .{
        @typeName(@TypeOf(optional_value)),
        optional_value,
    });

    optional_value = "hi";
    assert(optional_value != null);

    print("\noptional 2\ntype: {}\nvalue: {}\n", .{
        @typeName(@TypeOf(optional_value)),
        optional_value,
    });
```

- errors:

```
    // error union
    var number_or_error: anyerror!i32 = error.ArgNotFound;
    print("\nerror union 1\ntype: {}\nvalue: {}\n", .{
        @typeName(@TypeOf(number_or_error)),
        number_or_error,
    });
    number_or_error = 1234;
    print("\nerror union 2\ntype: {}\nvalue: {}\n", .{
        @typeName(@TypeOf(number_or_error)),
        number_or_error,
    });
    // It works at global scope as well as inside functions.
    const y = 5678;
}

```



- Top level ordering:

```
// Top-level declarations are order-independent:
pub fn g() { f(); }
pub fn f() {}
```

- strings:

```
test "string literals" {
    const bytes = "hello";
    assert(@TypeOf(bytes) == *const [5:0]u8);
    assert(bytes.len == 5);
    assert(bytes[1] == 'e');
    assert(bytes[5] == 0);
    assert('e' == '\x65');
    assert('\u{1f4a9}' == 128169);
    assert('💯' == 128175);
    assert(mem.eql(u8, "hello", "h\x65llo"));
}
```


# The algebraic structure of the 'nearest smaller number' question

The [nearest smaller number](https://cses.fi/problemset/task/1645) problem
can be solved by using a stack along with an observation of monotonicity.
This is explained in the [USACO guide to stacks in the Gold section](https://usaco-guide.netlify.app/gold/stacks).

What I find interesting is that we need a *stack*. Why does a stack show up?
Stacks are usually related to a DFS on some appropriate object. What's that object?
And can we gain insight into when we need to use a stack based on this?


The idea is that we are trying to construct the Hasse diagram of the
original array, treated as a poset with ground set $P \equiv \{ (val, ix) : \texttt{arr}[ix] = val \}$
with the ordering $(a_1, a_2) < (b_1, b_2) \iff a_1 < b_1 \land a_2 < b_2$.

So we have this hasse diagram, which interestingly is going to be a tree.
this need not always be the case! consider the divisiblity poset with the 
elements $3, 5, 15$.

Then the answer is to print the parent of each node in the tree as the parent
in the Hasse diagram is going to be closest number that is smaller than it.


Why does this Hasse diagram show up? What is the relationship between this problem,
and that of [Graham Scan](https://en.wikipedia.org/wiki/Graham_scan) which also
uses a similar technique of maintaining a stack. Does this also have a hasse
diagram associated to it? or a DFS tree?

<img src="./static/nearest-smaller-number.png">



# Why loss of information is terrifying: Checking that a context-free language is regular is undecidable

This comes from applying [Greibach's theorem](https://en.wikipedia.org/wiki/Greibach%27s_theorem#Applications).
I find myself thinking about this theorem once in a while, and its repercussions.
If we once had access to God who tabulated for all all regular languages
described as context free grammars, and we lost this tablet, we're screwed.
There's no way to recover this information decidably.

It shows that moving to higher models of computation (From regular to context free)
can sometimes be irreversably damaging.



# Sciences of the artificial

> A bridge under its usual conditions of service, behaves simply as a
> relatively smooth level surface. Only when it has been overloaded do we 
> learn the physical properties of the  materials from which it is built.

> Ohm's law was suggested to its discovered by its analogy with some simple
> hydraulic phenomena. 

Why simulation is useful:

- 1. (obvious): while the axioms maybe obvious, their raminifactions may not.

> A NASA launched satellite is surely an artificial object, but we usually
> do not think of it as simulating the moon; It simply obeys the same laws.

- 2. (subtle) Each layer only depends on an abstraction of the previous. Airplanes
  don't need the correctness of the Eightfold Way.

> Babbage introduced the words "Mill" and "Store"

> The focal concern of Economics is allocation of scarce resources.

> We can use a theory (say a theory of profit-loss) either positively,
> as an explaiation, or normatively, as a way to guide how we should run a 
> firm.



# Numbering nodes in a tree

If we consider a tree such as:

```
      a
b         c
        d   e
```

The "standard way" of numbering,  by starting with a `0` and then appending a `0`
on going to the left, appending a `1` on going to the right doesn't make a great
deal of sense. On the other hand, we can choose to number them as follows:

- Consider the root to have value `1`
- Every time we go right, we add `1/2^{height}`. When we go left, we subtract `1/2^{height}`. 
- This gives us the numbers:

```
      1
0.5       1.5
       1.25     1.75
```

- This also makes intuitive why to find the node to replace `1.5` when we delete
  it is to go to the left child `1.25` and then travel as much to the right as 
  possible. That path corresponds to:

$$
\begin{aligned}
&1 + 1/2 - 1/4 + 1/8 + 1/16 + \dots \\
&=  1 + 1/2 - 1/4 + 1/4 \\
&= 1.5
\end{aligned}
$$

- So in the limit, the rightmost leaf of the left child of the parent 
  *has the same value* as the parent itself. In the non-limit, we get as close as
  possible.

- This also may help intuit hyperbolic space? Distances as we go down in the
  three shrink. Thus, it's easier to "escape" away to the fringes of the space,
  rather than retrace your step. Recall that random walks in hyperbolic space
  almost surely move away from the point of origin. It feels to me like this
  explains why. If going towards the root / decreasing heighttakes distance 
  $d$, going deeper into the tree / increasing the height
  needs distance $d/2$. So a particle would "tend to" travel the shorter distance.

# Number of vertices in a rooted tree

Make sure the edges of the tree are ordered to point away from the root $r$.
So, for all edges $(u, v) \in E$, make sure that $d(r, v) = d(r, u) + 1$.

Create a function $terminal$ which maps every outward arc
to its target. $terminal: E \rightarrow V$, $terminal((u, v)) = v$.

This map gives us an almost bijection from edges to all vertices other than
the root. So we have that $|E| + 1 = |V|$. Each of the edges cover one non-root
vertex, and we then $+1$ to count the root node.

I found this much more intuitive than the inductive argument. I feel like I
should attempt to "parallelize" inductive arguments so you can see the entire
counting "at once".

# Median minimizes L1 norm

Consider the meadian of $xs[1..N]$. We want to show that the median minimizes
the L1 norm $L_1(y) = \sum_i |xs[i] - y|$. If we differentiate $L_1(y)$ with
respect to $y$, we get:

$$
d L_1(y)/y = \sum_i - \texttt{sign}(xs[i] - y)
$$


Recall that $d(|x|)/dx = \texttt{sign}(x)$

Hence, the best $y$ to minimize the $L_1$ norm is the value that makes the sum
of the signs $\sum_i \texttt{sign}(xs[i] - y)$ minimal. The median is perfect
for this optimization problem.

1. When the list has an odd number of elements, say, $2k + 1$, $k$ elements
  will have sign $-1$, the middle element will have sign $0$, and the $k$ elements
  after will have sign $+1$. The sum will be $0$ since half of the $-1$ and the $+1$
  cancel each other out.
2. Similar things happen for even, except that we can get a best total sign distance of $+1$
  using either of the middle elements.


#### Proof 2:
Math.se has a nice picture proof abot walking from left to right.

#### Proof 3:
Consider the case where $xs$ has only two elements, with $xs[0] < xs[1]$.
Then the objective function to minimize the L1 norm, ie, to minimize
$|xs[1] - y| + |xs[2] - y|$. This is satisfied by any point in
between $xs[1]$ and $xs[2]$.

In the general case, assume that $xs[1] < xs[2] \dots < xs[N]$. Pick the smallest
number $xs[1]$ and the largest number $xs[N]$. We have that any $y$ between $xs[1]$
and $xs[N]$ satisfies the condition. Now, drop off $xs[1]$ and $xs[N]$, knowing
that we must have $y \in [xs[1], xs[N]]$. Recurse.


At the end, we maybe left with a single element $xs[k]$. In such a case, we need
to minimize $|xs[k] - y|$. That is, we set $xs[k] = y$.

On the other hand, we maybe left with two elements. In this case, any point between
the two elements is a legal element.


We may think of this process as gradually "trapping" the median between the
extremes, using the fact that that any point $y \in [l, r]$ minimizes 
$|y - l| + |y - r|$!



- [Taken from `math.se`](https://math.stackexchange.com/questions/113270/the-median-minimizes-the-sum-of-absolute-deviations-the-ell-1-norm)

  


# LISP quine

I learnt how to synthesize a LISP quine using MiniKanren. It's quite magical,
I don't understand it yet.

```lisp
((lambda (x)            
   `(,x (quote ,x)))    
 (quote                 
   (lambda (x)          
     `(,x (quote ,x)))))

```

# A slew of order theoretic and graph theoretic results

I've been trying to abstract out the [activity selection problem](https://en.wikipedia.org/wiki/Activity_selection_problem)
from the lens of order theory. For this, I plan on studying the following
theorems/algebraic structures:

- Intransitive indifference with unequal indifference intervals
- Mirsky's theorem
- Dilworth's theorem
- Gallai–Hasse–Roy–Vitaver theorem
- Dirac's theorem
- Ore's theorem
- [Course on discrete math](https://www.coursera.org/learn/discrete-mathematics#syllabus)
- [`cs.stackexchange`: Finding longest chain in poset in sub-quadratic time](https://cs.stackexchange.com/questions/67847/finding-longest-chain-in-poset-in-subquadratic-time)


Naively, the solution goes as follows, which can be tested against 
[CSES' movie festival question](https://cses.fi/problemset/task/1629)

```cpp
// https://cses.fi/problemset/task/1629
int main() {
    int n;
    cin >> n;
    vector<pair<int, int>> ms(n);
    for (int i = 0; i < n; ++i) {
        cin >> ms[i].first >> ms[i].second;
    }

    std::sort(ms.begin(), ms.end(), [](pair<int, int> p1, pair<int, int> p2) {
        return (p1.second < p2.second) ||
               (p1.second == p2.second && p1.first < p2.first);
    });

    int njobs = 0;
    int cur_end = -1;
    for (int i = 0; i < n; ++i) {
        if (cur_end <= ms[i].first) {
            cur_end = ms[i].second;
            njobs++;
        }
    }
    cout << njobs << "\n";
    return 0;
}
```

#### Explanation 1: exchange argument

- The idea is to pick jobs *greedily*, based on *quickest finishing time*.
- The argument of optimality is strategy stealing. Think of the first job
  in our ordering `O` versus the optimal ordering `O*`.
- If we both use the same job, ie, `O[1] = O*[1]`, recurse into the second job.
- If we use different jobs then `O[1] != O*[1]`.
- Since  `O[1]` ends *quickest* [acc to our algorithm],
  we will have that `end(O[1]) < end(all other jobs)`, hence
  `end(O[1]) < end(O*[1])`.
- Since `O*` is a *correct* job schedule, we have that `end(O*[1]) < start(O*[2])`.
- Chaining inequalities, we get that `end(O[1]) < end(O*[1]) < start(O*[2])`.
- Thus, we can create `O~` which has `O~[1] = O[1]` and `O~[rest] = O*[rest]`.
  (`~` for "modified").
- Now recurse into `O~` to continue aligning `O*` with `O`. We continue to have the
  same length between `O~`, `O` and `O*`.

#### Explanation 2: posets and interval orders



# Thebes
- [BBC in our time]()

# Beethoven
- [BBC in our time]()

# Neko to follow your cursor around

```
$ oneko -idle 0 -speed 100 -time 5120 -bg blue -fg orange -position +20+20
```

This is useful for screen sharing tools that can't display the mouse
pointer, [like Microsoft Teams](https://docs.microsoft.com/en-us/answers/questions/3222/mouse-pointer-not-visible-when-sharing-screen.html)

# Non commuting observables: Light polarization

- [physics.se](https://physics.stackexchange.com/questions/240543/is-there-something-behind-non-commuting-observables)


# Statement expressions and other GCC C extensions

This seems really handy. I've always loved that I could write

```
let x = if y == 0 { 1 } else { 42}
```

in Rust. It's awesome to know that the C equivalent is

```cpp
const int x =  ({ if (y == 0) { return 1; } else { return 42; });
```

#### [Conditions (`?:`) with omitted operands](https://gcc.gnu.org/onlinedocs/gcc/Conditionals.html#Conditionals)

```c
x ?: y =defn= x ? x : y
```

#### [variable length arrays](https://gcc.gnu.org/onlinedocs/gcc/Variable-Length.html#Variable-Length)

```c
FILE *
concat_fopen (char *s1, char *s2, char *mode)
{
  char str[strlen (s1) + strlen (s2) + 1];
  strcpy (str, s1);
  strcat (str, s2);
  return fopen (str, mode);
  // str is freed here.                                
}

```

#### [Designated array initializers: A better way to initialize arrays](https://gcc.gnu.org/onlinedocs/gcc/Designated-Inits.html#Designated-Inits)

- initialize specific indexes

```c
// initialize specific indexes
int a[6] = { [4] = 29, [2] = 15 };
// a[4] = 29; a[2] = 15; a[rest] = 0
```


- initialize ranges:

```c
// initialize ranges
int widths[] = { [0 ... 9] = 1, [10 ... 99] = 2, [100] = 3 };
```

- initialize struct fields:

```
//initialize struct fields
struct point { int x, y; };
struct point p = { .y = yvalue, .x = xvalue };
```


- initialize union variant:

```c
//initialize union variant
union foo { int i; double d; };
union foo f = { .d = 4 };
```

- Neat trick: lookup for whitespace in ASCII:

```c
int whitespace[256]
  = { [' '] = 1, ['\t'] = 1, ['\h'] = 1,
      ['\f'] = 1, ['\n'] = 1, ['\r'] = 1 };
```

#### [Cast to union](https://gcc.gnu.org/onlinedocs/gcc/Cast-to-Union.html#Cast-to-Union)

```c
union foo { int i; double d; };
int x = 42; z = (union foo) x;
double y = 1.0; z = (union foo) y;
```

#### [Dollar signs in identifier names]( https://gcc.gnu.org/onlinedocs/gcc/Dollar-Signs.html#Dollar-Signs)

```c
int x$;
int $z;
```


#### [Unnamed union fields](https://gcc.gnu.org/onlinedocs/gcc/Unnamed-Fields.html#Unnamed-Fields)

```c
struct {
  int a;
  union { int b; float c; };
  int d;
} foo

// foo.b has type int
// foo.c has type float, occupies same storage as `foo.b`.
```

- [GCC manual: statement expressions](https://gcc.gnu.org/onlinedocs/gcc/Statement-Exprs.html)
- [GCC manual: C extensions](https://gcc.gnu.org/onlinedocs/gcc/C-Extensions.html#C-Extensions)



# A quick look at impredicativity

I found this video very helpful, since I was indeed confused about the two
meanings of impredicativity that I had seen floating around. One used by haskellers,
which was that you can't instantiate a type variable `a` with a  (`forall t`).
Impredicative in Coq means having `(Type : Type)`. 

- polymorphic types:

```hs
forall p. [p] -> [p] -- LEGAL
Int -> (forall p. [p] -> [p])  -- ILLEGAL
(forall p. [p] -> [p])  -> Int -- ILLEGAL
[forall a. a -> a] -- ILLEGAL
```

- Higher rank types: `forall` at the outermost level of a let-bound function,
  and to the left and right of arrows!

```hs
Int -> (forall p. [p] -> [p])  -- LEGAL
(forall p. [p] -> [p])  -> Int -- LEGAL
runST :: (forall s. ST s a) -> a -- LEGAL
[forall a. a -> a] -- ILLEGAL
```

- Impredicative type:

```hs
[forall a. a -> a]
```

- We can't type `runST` because of impredicativity:

```hs
($) :: forall a, forall b, (a -> b) -> a -> b
runST :: forall a, (forall s, ST s a) -> a -- LEGAL
st :: forall s. ST s Int
runST st -- YES
runST $ st -- NO 
```

- Expanding out the example:

```hs
($) runST st
($) @ (forall s. ST s Int) @Int  (runST @ Int) st
```

- Data structures of higher kinded things. For example. we might want to have `[∀ a, a -> a]`
- We have `ids :: [∀ a, a -> a]`. I also have the function `id :: ∀ a, a -> a`. I want
  to build `ids' = (:) id ids`. That is, I want to cons an `id` onto my list `ids`.
- How do we type infer this?

#### How does ordinary type inference work?

```hs
reverse :: ∀ a. [a] -> [a]
and :: [Bool] -> Bool
foo = \xs -> (reverse xs, and xs)
```

- Start with `xs :: α` where `α` is a type variable.
- Typecheck `reverse xs`. We need to instantiate `reverse`. With what type?
  **that's what we need to figure out!**
- (1) Instantiate: Use variable `β`. So we have that our occurence of `reverse` has type 
  `reverse :: [β] -> [β]`.
- (2) Constrain: We know that `xs :: α` and `reverse` expects an input argument of
   type `[β]`, so we set `α ~ [β]` due to the call `reverse xs`.
- We now need to do `and xs`. (1) `and` doesn't have any type variables, so we don't need
  to perform instantiation. (2) We can constrain the type, because `and :: [Bool] -> Bool`,
  we can infer from `and xs` that `α ~ [Bool]`
- We solve using [**Robinson unification**](https://en.wikipedia.org/wiki/Robinson%27s_unification_algorithm).
  We get `[β] ~ α ~ [Bool]` or `β = Bool`

#### Where does this fail for polytypes?

- The above works because `α` and `Β` only stand for **monotypes**.
- Our constraints are **equality constraints**, which can be solved by 
  **Robinson unification**
- And we have only **one solution** (principal solution) 
- When trying to instantiate reverse, how do we instantiate it?
- Constraints become subsumption constraints
- Solving is harder
- No principal solution
- Consider `incs :: [Int -> Int]`, and `(:) id incs` versus `(:) id ids`.

#### But it looks so easy!

- We want to infer `(:) id ids`
- We know that the second argument `ids` had type `[∀ a, a -> a]`
- we need a type `[p]` for the second argument, because `(:) :: p -> [p] -> [p]`
- Thus we must have `p ~ (∀ a, a -> a)`
- We got this information **from the second argument**
- So let's try to treat an application `(f e1 e2 ... en)` as a whole.

#### New plan

- Assume we want to figure out `filter g ids`.
- start with `filter :: ∀ p, (p -> Bool) -> [p] -> Bool`
- Instatiate `filter` with **instantiation variables** `κ` to get 
  `(κ -> Bool) -> [κ] -> Bool`
- Take a "quick look" at `e1, e2` to see if we know that `κ` should be
- We get from `filter g ids` that `κ := (∀ a, a -> a)`.
- Substitute for `κ`  (1) the type that "quick look" learnt, if any, and 
  (2) A **monomorphic** unification variable otherwise.
- Typecheck against the type. In this case, we learnt that `κ := (∀ a, a -> a)`,
  so we replace `κ` with `(∀ a, a -> a)`.
- Note that this happens at each **call site**!

#### The big picture

Replace the idea of:
- instantate function with unficiation variables, with the idea.
- instantiate function with a quick look at the calling context. 
- We don't need fully saturated calls. We take a look at whatever we can see!
- Everything else is completely unchanged.

#### What can QuickLook learn?

- [Video](https://www.youtube.com/watch?v=ZuNMo136QqI)


# Data oriented programming in C++

- Calcuating entropy to find out if a variable is worth it! Fucking amazing.
- [Video](https://www.youtube.com/watch?v=rX0ItVEVjHc)


# Retro glitch

<img src=static/retro-glitch.jpg />

- There's something great about the juxtaposition of the classic Christian scene
  with the glitch aesthetic. I'm unable to articulate _what_ it is that I so 
  thoroughly enjoy about this image. 

- Fuck me, it turns out this is fascist art, goes by the genre of `fashwave`.
  Pretty much everything else in this genre is trash, this is the sole 'cool looking'
  picture of the lot.


# SSA as linear typed language

- Control flow is linear in a basic block: ie, we can have a sea of nodes
  representation, where each terminator instruction produces _linear_ control
  flow tokens: `br: token[-1] --> token[1]`. `brcond: token[-1] -> -> (token[1], token[1])`,
  `return: token[-1] -> ()`. This ensures that each branching only happens once,
  thereby "sealing their fate. On the other hand, reguar instructions also
  take a "control token", but don't _consume it_. so for example, `add: token[0] -> (name, name) -> name`.

- Next question: is dominance also somehow 'linear'?
- Answer: yes. We need quantitative types. When we branch from basic block `A`
  into blocks `B, C`, attach `1/2A` to the control tokens from `(%tokb, %tokc) = br cond %cond0 B, C`.
  Now, if someone builds a token that's at a basic block `D` that is merged
  into by both `B, C`, they will receive a "full" `A` that they can use.
  Pictorially:

```
       A
       ...

   B        C  
[1/2A]     [1/2A]
       D
       1A
```

# Nix weirdness on small machines

```
floobits@pixel-druid:~$ nix-env -iA nixpkgs.hello                                                                                    
+ nix-env -iA nixpkgs.hello                                                                                                          
installing 'hello-2.10'                                                                                                              
these paths will be fetched (0.04 MiB download, 0.20 MiB unpacked):                                                                  
  /nix/store/w9yy7v61ipb5rx6i35zq1mvc2iqfmps1-hello-2.10                                                                             
copying path '/nix/store/w9yy7v61ipb5rx6i35zq1mvc2iqfmps1-hello-2.10' from 'https://cache.nixos.org'...                              
error: unable to fork: Cannot allocate memory                                                                                        
floobits@pixel-druid:~$ gdb --args nix-env -iA nixpkgs.hello                                                                         
+ gdb --args nix-env -iA nixpkgs.hello                                                                                               
GNU gdb (Ubuntu 7.11.1-0ubuntu1~16.5) 7.11.1                                                                                         
Copyright (C) 2016 Free Software Foundation, Inc.                                                                                    
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>                                                        
This is free software: you are free to change and redistribute it.                                                                   
There is NO WARRANTY, to the extent permitted by law.  Type "show copying"                                                           
and "show warranty" for details.                                                                                                     
This GDB was configured as "x86_64-linux-gnu".                                                                                       
Type "show configuration" for configuration details.                                                                                 
For bug reporting instructions, please see:                                                                                          
<http://www.gnu.org/software/gdb/bugs/>.                                                                                             
Find the GDB manual and other documentation resources online at:                                                                     
<http://www.gnu.org/software/gdb/documentation/>.                                                                                    
For help, type "help".                                                                                                               
Type "apropos word" to search for commands related to "word"...                                                                      
Reading symbols from nix-env...(no debugging symbols found)...done.                                                                  
(gdb) run                                                                                                                            
Starting program: /nix/store/d6axkgf0jq41jb537fnsg44080c4rd52-user-environment/bin/nix-env -iA nixpkgs.hello                         
warning: File "/nix/store/danv012gh0aakh8xnk2b35vahklz72mk-gcc-9.2.0-lib/lib/libstdc++.so.6.0.27-gdb.py" auto-loading has been declin
ed by your `auto-load safe-path' set to "$debugdir:$datadir/auto-load".                                                              
To enable execution of this file add                                                                                                 
        add-auto-load-safe-path /nix/store/danv012gh0aakh8xnk2b35vahklz72mk-gcc-9.2.0-lib/lib/libstdc++.so.6.0.27-gdb.py             
line to your configuration file "/home/floobits/.gdbinit".                                                                           
To completely disable this security protection add                                                                                   
        set auto-load safe-path /                                                                                                    
line to your configuration file "/home/floobits/.gdbinit".                                                                           
For more information about this security protection see the                                                                          
"Auto-loading safe path" section in the GDB manual.  E.g., run from the shell:                                                       
        info "(gdb)Auto-loading safe path"                                                                                           
warning: File "/nix/store/xg6ilb9g9zhi2zg1dpi4zcp288rhnvns-glibc-2.30/lib/libthread_db-1.0.so" auto-loading has been declined by your
 `auto-load safe-path' set to "$debugdir:$datadir/auto-load".                                                                        
warning: Unable to find libthread_db matching inferior's thread library, thread debugging will not be available.                     
^[[A[New LWP 21466]                                                                                                                  
GC Warning: Failed to expand heap by 128045056 bytes                                                                                 
installing 'hello-2.10'                                                                                                              
building '/nix/store/k3kz3cwyqdwi5bmwcbl1fzv2b2wkqrl6-user-environment.drv'...                                                       
created 43 symlinks in user environment                                                                                              
[LWP 21466 exited]                                                                                                                   
[Inferior 1 (process 21462) exited normally]                                                                                         
(gdb) run                                                                                                                            
```

### All nix subcommands are just symlinks

```
floobits@pixel-druid:~/idfk/nix-master$ ls -al /nix/store/4vz8sh9ngx34ivi0bw5hlycxdhvy5hvz-nix-2.3.7/bin/                            
total 1784                                                                                                                           
dr-xr-xr-x 2 floobits bollu    4096 Jan  1  1970 .                                                                                   
dr-xr-xr-x 9 floobits bollu    4096 Jan  1  1970 ..                                                                                  
-r-xr-xr-x 1 floobits bollu 1816768 Jan  1  1970 nix                                                                                 
lrwxrwxrwx 1 floobits bollu       3 Jan  1  1970 nix-build -> nix                                                                    
lrwxrwxrwx 1 floobits bollu       3 Jan  1  1970 nix-channel -> nix                                                                  
lrwxrwxrwx 1 floobits bollu       3 Jan  1  1970 nix-collect-garbage -> nix                                                          
lrwxrwxrwx 1 floobits bollu       3 Jan  1  1970 nix-copy-closure -> nix                                                             
lrwxrwxrwx 1 floobits bollu       3 Jan  1  1970 nix-daemon -> nix                                                                   
lrwxrwxrwx 1 floobits bollu       3 Jan  1  1970 nix-env -> nix                                                                      
lrwxrwxrwx 1 floobits bollu       3 Jan  1  1970 nix-hash -> nix                                                                     
lrwxrwxrwx 1 floobits bollu       3 Jan  1  1970 nix-instantiate -> nix                                                              
lrwxrwxrwx 1 floobits bollu       3 Jan  1  1970 nix-prefetch-url -> nix                                                             
lrwxrwxrwx 1 floobits bollu       3 Jan  1  1970 nix-shell -> nix                                                                    
lrwxrwxrwx 1 floobits bollu       3 Jan  1  1970 nix-store -> nix                                                                    
```

It seems the way this works is that the `nix` tool figures out from what
_symlink_ it's being invoked to decide what to do. God, that's ugly? brilliant?
I don't even know.

### How does `writeFile` work?

- `cowsay` in nixpkgs
- `writeFile` in nixpkgs
- `runCommand'` in nixpkgs
- `mkDerivation` in nixpkgs
- `derivation` in nixpkgs
- `src/libexpr/primops/derivation.nix` in nixos
- `prim_derivationStrict` in nixos c++
- `derivationArg` in nixos c++
- `writeDerivation` in nixos c++

# Autodiff over derivative of integrals

- [Reynolds transport theorem](https://en.wikipedia.org/wiki/Reynolds_transport_theorem)
- [Physics based differential rendering](https://shuangz.com/courses/pbdr-course-sg20/)

# Proof of projective duality

In projective geometry, we can interchange any statement with "points" and
"lines" and continue to get a true statement. For example, we have the
dual statements:

- Two non-equal lines intersect in a unique point (including a point at infinty
  for a parallel line).
- Two non-equal points define a unique line.

The proof of the duality principle is simple. Recall that any point in
projective geometry is of the from $[a : b : c] \simeq (b/a, c/a)$. A projective
equation is of the form $px + qy + rz = 0$ for coefficients $p, q, r \in \mathbb C$.

- if we have a fixed point $[a : b : c]$, we can trade this to get a
  line $ax + by + cz = 0$. 
- If we have a line $ax + by + cz = 0$, we can trade this to get a point $[a:b:c]$.
- The reason we need projectivity is because this correspondence is only well
  defined upto scaling: the line $x + 2y + 3$ is the same as the line $2x + 3y + 6$.
- In using our dictionary, we would get $[1:2:3]$, $[2:4:6]$. Luckily for us,
  projectivity, these two points are the same! $(2/1, 3/1) = (4/2, 6/2)$.
- The "projective" condition allows us to set points and lines on equal footing:
  lines can be scaled, as can points in this setting. 

# Preventing the collapse of civilization

- [video by Jonathan Blow](https://www.youtube.com/watch?v=ZSRHeXYDLko)
- [The year civilization collapsed](https://www.youtube.com/watch?v=bRcu-ysocX4)
- [The thirty million line problem](https://caseymuratori.com/blog_0031#:~:text=The%20Thirty%2DMillion%2DLine%20Problem%20(2015))
- [Civilizations: Institutions, Knowledge, and future](https://www.youtube.com/watch?v=OiNmTVThNEY)
- [Dark mountain](https://dark-mountain.net/)

I am very sympathetic to the perspective that software has gotten far
less reliable than it used to be.

# Violent deaths in ancient societies (TODO)

### Kanun in albania

### Honor societies and Revence

### Law codes: Code of Hammurabi

#### References

- [Ethnographic and Archaeological Evidence on Violent Deaths](https://ourworldindata.org/ethnographic-and-archaeological-evidence-on-violent-deaths)
- [Kanun](https://en.wikipedia.org/wiki/Kanun_(Albania))

# An elementary example of a thing that is not a vector

Consider the tripe (temperature, pressure, humidity) at a point. If we rotate
the picture by 60 degrees, the triple _does not change_.


Now consider the direction of wind at a point. If we rotate the picture by
60 degrees, the components of the wind vector _change_ with our rotation.

Thus:

> a vector is something that transforms like a vector.

To be more precise, I can phrase it as:

> A vector iss (is and only is) something that transforms like a vector.

Generalization to tensors is left as an exercise for the reader.

# Elementary probability theory (TODO)

I've never learnt elementary probability theory "correctly". This is me
attempting to fix it.

#### Defn: Sample space

set of all possible outcomes / things that could happen. 

#### Defn: Outcome / Sample point / atomic event

An outcome consists of all the information about the experiment
*after it has been performed* including the values of all random choices.

##### NOTE: Keeping straight event v/s outcome

It's easy to get confused between 'event' and 'outcome' (linguistically). I
personally remember that one of them is the element of the sample space and
another the subsets, but I can't remember which is which. Here's how I
recall which is which:

> every experiment has an *outcome*. We write an outcome section when we
> write a lab manual/lab record for a given experiment.


Now, we when perform an expriment, or something random happens, sometimes,
the result (ie, the outcome) can be _eventful_; it's not linguistically
right to say that some events can be _outcomeful_.

So, an event is a predicate over the set of outcomes; `event: outcome -> bool`.
This is the same as being a subset of outcomes (the event is identified
with the set of outcomes it considers eventful), so we have `event ~= 2^outcomes`.



## Example: Monty hall

An outcome of the monty hall game **when the the contestant switches** consists of:
- the box with the prize.
- the box chosen by the contestant.
- the box that was revealed.

Once we know the three things, we know everything that happened.

For example, the sample point $(2, 1, 3)$:
- the prize is in box 2
- the player first picks box 1
- the assistant, Carol, reveals box 3.
- The contestant wins, because we're assuming the player switches. Hnce, they
  will switch from their initial choice of (1) to (2).

Note that not all 3-tuples correspond to sample points. For example,
- $(1, 2, 1)$ is not a sample point, because we can't reveal the box with the prize.
- $(2, 1, 1)$ is not a sample point, because we can't reveal the box the player chose.
- $(1, 1, 2), (1, 1, 3)$ is OK. The player chooses the correct box, carol reveals some box,
  and then the player switches.

## Constructing the sample space: tree method

We build a decision tree. 

#### where is the prize?

```
(prize 1)
(prize 2)
(prize 3)
```

#### player's choice


```
(prize 1
   (choice 1)
   (choice 2)
   (choice 3))
(prize 2
   (choice 1)
   (choice 2)
   (choice 3))
(prize 3
   (choice 1)
   (choice 2)
   (choice 3))

```

#### Which box is revealed


```
(prize 1
   (choice 1 
      (reveal 2)
      (reveal 3))
   (choice 2
      (reveal 3))
   (choice 3)
      (reveal 2))
(prize 2
   (choice 1
     (reveal 3)
   (choice 2
     (reveal 1)
      (reveal 3))
   (choice 3)
     (reveal 1))
(prize 3
   (choice 1
     (reveal 2))
   (choice 2
     (reveal 1))
   (choice 3)
     (reveal 1)
     (reveal 2))
```


#### Win/Loss

```
(prize 1
   (choice 1 
loss  (reveal 2)  
loss  (reveal 3)) 
   (choice 2
win   (reveal 3))
   (choice 3)
win   (reveal 2))
(prize 2
   (choice 1
win  (reveal 3)
   (choice 2
loss (reveal 1)
loss  (reveal 3))
   (choice 3)
win  (reveal 1))
(prize 3
   (choice 1
win  (reveal 2))
   (choice 2
win  (reveal 1))
   (choice 3)
loss (reveal 1)
loss (reveal 2))
```

This seems like it's 50/50! But what we're missing is the *likelihood* of an
outcome.

#### Defn: Probability space

A probability space consists of a sample space (space of al outcomes) and a
probability function $P$ that maps the sample space to the real numbers, such that:
- For every outcome, the probability is between zero and one.
- The sum of all the probabilities is one.

**Interpretation**: For every outcome, the $P(outcome)$ is the probability of
that outcome happening in an experiment.


#### Assumptions for monty hall

- Carol put the prize uniformly randomly. Probability 1/3.
- No matter where the prize is, the player picks each box with probability 1/3.
- No matter where the prize is, the box that carol reveals will be picked 
  uniformly randomly. Probability 1/2.

#### Assigning probabilities to each edge

```
(prize 1 [1/3]
   (choice 1 [1/3]
l  (reveal 2)   [1/2]
l  (reveal 3))  [1/2]
   (choice 2 [1/3]
w   (reveal 3)) [1]
   (choice 3) [1/3]
w   (reveal 2)) [1]
(prize 2 [1/3]
   (choice 1
w  (reveal 3)
   (choice 2
l (reveal 1)
l  (reveal 3))
   (choice 3)
w  (reveal 1))
(prize 3  [1/3]
   (choice 1
w  (reveal 2))
   (choice 2
w  (reveal 1))
   (choice 3)
l (reveal 1)
l (reveal 2))
```

#### Assigning probabilities to each outcome

- Probability for a sample point is the product of probabilities leading
  to the outcome

```
(prize 1 [1/3]
   (choice 1 [1/3]
l  (reveal 2)   [1/2]: 1/18
l  (reveal 3))  [1/2]: 1/18
   (choice 2 [1/3]
w   (reveal 3)) [1]: 1/9
   (choice 3) [1/3]
w   (reveal 2)) [1]: 1/9
...
```

So the probability of winning is going to be $6 \times 1/9 = \frac{2}{3}$.

#### Defn: Event

An event is a *subset* of the sample space.

- For example, $E_l$ is the event that the person loses in Monty Hall.

#### Probability of an event

The probability that an event $E$ occurs is the sum of the probabilities of the 
sample points of the event: $P(E) \equiv \sum_{e \in E} P(e)$.



#### What about staying?

I win $2/3$rds of the time when I _switch_. If I don't switch, I must have lost.
So if I choose to stay, then I _lose_ $2/3$rds of the time. We're using that

- $P(\texttt{win with switch}) = P(\texttt{lose with stick})$.

#### Gambing game

- Dice $A$: $\{2, 6, 7\}$.

```
\ 2  /
 \  /
6 \/ 7
  ||
```
it's the same on the reverse side. It's a fair dice. So the probability of
getting $2$ is a third. Similarly for $6, 7$.

- Dice $B$: $\{1, 5, 9 \}$.
- Dice $C$: $\{3, 4, 8 \}$.

- We both dice. The higher dice wins. Loser pays the winner a dollar.

#### Analysis: Dice A v/s Dice C

- Dice $A$ followed by dice $C$:

```
(2
  (3
   4
   8))
(6
  (3
   4
   8))
(7
  (3
   4
   8))
```

- Assign winning

```
(2
  (3    C
   4    C
   8))  C
(6
  (3    A
   4    A
   8))  C
(7
  (3    A
   4    A
   8))  C
```

Each of the outcomes has a probability $1/9$, so dice $C$ wins.

#### Lecture 19: Conditional probability


`P(A|B)` where both `A` and `B` are events, read as probability of `A`
given `B`.

$$
P(A|B) \equiv \frac{P(A \cap B)}{P(B)}
$$

We know $B$ happens so we normalize by $B$. We then intersect $A$ with $B$
because we want both $A$ and $B$ to have happened, so we consider all outcomes
that both $A$ and $B$ consider eventful, and then reweigh the probability such
that our definition of "all possible outcomes" is simply "outcomes in $B$".

- A quick calculation shows us that $P(B|B) = P(B \cap B)/Pr(B) =1$.

#### Product Rule

$$
P(A \cap B) = P(B) P(A|B)
$$

follows from the definition by rearranging. 

#### General Product Rule

$$
P(A_1 \cap A_2 \dots A_n) = P(A_1) P(A_2 | A_1) P(A_3 | A_2 \cap A_1) P(A_4 | A_3 \cap A_2 \cap A_1) \dots P(A_n | A_1 \cap \dots \cap A_{n-1})
$$

#### Example 1:

In a best two out of three series, the probability of winning the first
game is $1/2$. The probability of winning a game immediately after a victory is $2/3$.
Probability of winning after a loss is $1/3$. What is the probability of winning
given that we win in the first game?

Tree method:

```
(W1
  (W2) 
   (L2 
      (W3
      L3)))
(L1
  (W2) 
   (L2 
      (W3
      L3)))
(L1)
```

The product rule sneakily uses conditional probability! $P(W_1W_2) = P(W_1) P(W_2|W_1)$.
Etc, solve the problem.

#### Definition: Independence

events $A$, $B$ are independent if $P(A|B) = P(A)$ or $P(B) = 0$.

#### Disjointness and independence

Disjoint events are never independent, because $P(A|B) = 0$ while $P(A)$ need not
be zero.

#### What do indepdent events look like?

We know that we need $P(A|B) = P(A)$. We know that $P(A|B)$ is how much of $A$
is within $B$. So we will have $P(A|B) = P(A)$ if the space that $A$ occupies
in the sample space is the same proprtion of $A$ that occupies $B$. Euphimistically,
$A/S = (A \cap B)/B$.

#### Independence and intersection

If $A$ is independent of $B$ then $P(A\cap B) = P(A) P(B)$. 

$$
\begin{aligned}
P(A) = P(A|B) \text{(given)} \\
P(A) = P(A \cap B) / P(B) \text{(defn of computing $P(A|B)$)} \\ 
P(A) P(B) = P(A \cap B) \text{(rearrange)} \\ 
\end{aligned}
$$

#### Are these two independent?

- A = event coins match
- B = event that the first coin is heads.

Intuitively it seems that these should be dependent because knowing something
about the first coin should tells us if the coins match.
$P(A|B)$ is the probability that (second coin is heads) which is  $1/2$.
$P(A) = 1/2$.

But our intuition tells us that these should be different!

#### Be suspect! Try general coins

Let prob. of heads is $p$ and tails is $(1-p)$ for both coins.

$P(A|B) = p$, while $P(A) = p^2 + (1-p)^2$.

#### Mutual independence

Events $A_1, A_2, \dots A_n$ are mutually independent if any knowledge
about any of the rest of the events tells us anything about the $i$th event.


#### Random variables

A random variable $R$ is a function from the sample space $S$ to $\mathbb R$. We can 
create equivalence classes of the fibers of $R$. Each of this is an event,
since it's a subset of the sample space. Thus, $P(R = x)$ = $P(R^{-1}(x)) = \sum_{w: R(w) = x} P(w)$

#### Independence of random variables

$$
\forall x_1, x_2 \in \mathbb R, P(R_1 = x_1 | R_2 = x_2) = P(R_1 = x_1)
$$

> Slogan: No value of $R_2$ can influence any value of $R_1$.

####  Equivalent definition of independence:

$$
P(R_1 = x_1 \land R_2 = x_2) = P(R_1 = x_1) P(R_2 = x_2)
$$


#### References

- [Lec 18: math for computer science; elementary probability](https://www.youtube.com/watch?v=SmFwFdESMHI)
- [Lec 19: math for computer science; elementary probability](https://www.youtube.com/watch?v=SmFwFdESMHI)
- [Lec 21: math for computer science; random variables](https://www.youtube.com/watch?v=MOfhhFaQdjw)
- [Problem set 10](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-042j-mathematics-for-computer-science-fall-2010/assignments/MIT6_042JF10_assn10.pdf)
- [Problem set 11](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-042j-mathematics-for-computer-science-fall-2010/assignments/MIT6_042JF10_assn11.pdf)
- [Problem set 12](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-042j-mathematics-for-computer-science-fall-2010/assignments/MIT6_042JF10_assn12.pdf)

# The handshaking lemma

### Concrete situation:

Let's take a graph $G \equiv (V, E)$. We can imagine that each edge has a potential
of $2$. We can redistribute this potential, by providing a potential of $1$
to each of the vertices incident on the edge. This gives us the calculation
that the total potential is $2|E|$. But each vertex is assigned a potential of $1$
for each edge incident on it. Thus, the total potential is $\sum_v \texttt{degree}(v)$.
This gives the equality $\sum_i \texttt{degree}(v) = 2|E|$.

Thus, if each of the degrees are odd, considering modulo 2, the LHS becomes
$\sum_v 1 = |V|$ and the RHS becomes $0$. Thus we have that $|V| = 0$ (mod 2), or 
the number of vertices remains even.

I learnt of this nice way of thinking about it in terms of potentials when
reading a generalization to simplicial
complexes.

#### References
- [The amazing world of simplicial complexes](https://arxiv.org/pdf/1804.08211.pdf)


# Git for pure mathematicians

What is `git`? It's not a version control system. It's an interface to work
with _torsors_. We have a space of files. We can manipulate "differences of
files", which are represented by patches/diffs. `git`'s model provides us tools
to work with this space of files.

We have two spaces, and a rooted DAG that connects to two spaces:

- A space of *files*.
- A space of *diffs* which forms a monoid with a monoid action on the space of files.
- A DAG where each node is a diff. The root note in the DAG is the empty diff.

# Mutorch

```py
#!/usr/bin/env python3

# x2, w1, w2 are Leaf variables
# x1 = f(w1, w2)
# y = g(x1, x2)
# loss = h(y)


# BACKPROP [reverse mode AD]
# ==========================
# t is a hallucinated variable.
# y = f(x)
# GIVEN: dt/dy
# TO FIND: dt/dx
# dt/dx = dt/dy * dy/dx
# dt/dloss 
# t = loss
# dt/dloss = dloss/dloss = 1


# y1 = f(x1, x2, x3)
# y2 = g(x1, x2, x3)

# FORWARD MODE: [Tangent space] ---- objects of the does nothing at all :$\texttt{form (partial f/partial x)
# total gradient of x1: df/dx1 + dg/dx1
# total gradient of x2: df/dx2 + dg/dx2
# total gradient of x3: df/dx3 + dg/dx3

# l = r cos(theta)
# dl = dr cos(theta) + rsin(theta) dtheta 
# dl/dtheta = dr/dtheta cos(theta) + rsin(theta) dtheta/dtheta
# dl/dtheta =   0       * .......  + rsin(theta) * 1

# dl/dr = dr/dr cos(theta) + rsin(theta) dtheta/dr
# dl/dr = cos(theta) +      .............*0

# REVERSE MODE: [CoTangent space] --- objects of the form df
# total gradient of y1: dy1 = (df/dx1)dx1 + (df/dx2)dx2  + (df/dx3)dx3 
# total gradient of y2: dy2 = (dg/dx1)dx1 + (dg/dx2)dx2  + (dg/dx3)dx3
# HALLUCINATED T:
#    y1 = f(x1, x2, x3)
#    GIVEN:   dt/dy1 [output]
#    TO FIND: dt/dx1, dt/dx2, dt/dx3 [inputs]
#    SOLN:    dt/dxi = dt/dy * dy/dxi 
#                    = dt/dy * df/dxi 
import pudb

class Expr:
    def __mul__(self, other):
        return Mul(self, other)
    def __add__(self, other):
        return Add(self, other)

    def clear_grad(self):
        pass

class Var(Expr):
    def __init__(self, name, val):
        self.name = name
        self.val = val
        self._grad = 0
    def __str__(self):
        return "(var-%s | %s)" % (self.name, self.val)
    def __repr__(self):
        return self.__str__()

    def clear_grad(self):
        self._grad = 0

    def backprop(self, dt_doutput):
        self._grad += dt_doutput

    def grad(self):
        return self._grad

class Mul(Expr):
    def __init__(self, lhs, rhs):
        self.lhs = lhs
        self.rhs = rhs
        self.val = self.lhs.val * self.rhs.val
    def __str__(self):
        return "(* %s %s | %s)" % (self.lhs, self.rhs, self.val)
    def __repr__(self):
        return self.__str__()

    #         -------- input1
    #   S    /
    #  ---> v 
    #  <--output *
    #      ^
    #       \_________ input2
    # think in terms of sensitivity.
    # - output has S sensitivity to something,
    # - output = input1 + input2
    # - how much sensitivity does input1 have to S?
    # - the same (S), because "sensitivity" is linear [a conjecture/axiom]
    # output = f(input1, input2); f(input1, input2) = input1 + input2 
    def backprop(self, dt_output):
        # dt/dinput1 = dt/doutput * ddoutput/dinput1 = 
        #            = dt/doutput * d(f(input1, input2))/dinput1
        #            = dt/doutput * d(input1 * input2)/dinput1
        #            = dt/doutput * input2
        self.lhs.backprop(dt_output * self.rhs.val)
        self.rhs.backprop(dt_output * self.lhs.val)

# a = ...   ^
# b = ...   ^
# c = a + b ^
# 
class Add(Expr):
    def __init__(self, lhs, rhs):
        self.lhs = lhs
        self.rhs = rhs
        self.val = self.lhs.val + self.rhs.val
    def __str__(self):
        return "(+ %s %s | %s)" % (self.lhs, self.rhs, self.val)
    def __repr__(self):
        return self.__str__()

    #         -------- input1
    #   S    /
    #  ---> v 
    #  <--output
    #      ^
    #       \_________ input2
    # think in terms of sensitivity.
    # - output has S sensitivity to something,
    # - output = input1 + input2
    # - how much sensitivity does input1 have to S?
    # - the same (S), because "sensitivity" is linear [a conjecture/axiom]
    # output = f(input1, input2); f(input1, input2) = input1 + input2 
    def backprop(self, dt_output):
        # dt/dinput1 = dt/doutput * ddoutput/dinput1 = 
        #            = dt/doutput * d(f(input1, input2))/dinput1
        #            = dt/doutput * d(input1 + input2)/dinput1
        #            = dt/doutput * 1
        self.lhs.backprop(dt_output * 1)
        self.rhs.backprop(dt_output * 1)

class Max(Expr):
    def __init__(self, lhs, rhs):
        self.lhs = lhs
        self.rhs = rhs
        self.val = max(self.lhs.val, self.rhs.val)
    def __str__(self):
        return "(max %s %s | %s)" % (self.lhs, self.rhs, self.val)
    def __repr__(self):
        return self.__str__()

    def backprop(self, dt_output):
        # dt/dinput1 = dt/doutput * doutput/dinput 1 
        #            = dt/doutput *d max(input1, input2)/dinput1
        #            = |dt/doutput *d input1/dinput1 [if input1 > input2] = 1
        #            = |dt/doutput *d input2/dinput1 [if input2 > input1] = 0
        if self.val == self.lhs.val:
            self.lhs.backprop(dt_output * 1)
        else:
            self.rhs.backprop(dt_output * 1)

x = Var("x", 10)
print("x: %s" % x)
y = Var("y", 20)
p = Var("p", 30)
print("y: %s" % y)
z0 = Mul(x, x)
print("z0: %s" % z0)
z1 = Add(z0, y)
print("z1: %s" % z1)

# z1 = x*x+y 
# dz1/dx = 2x 
# dz1/dy = 1
# dz1/dp = 0
# z1.clear_grad()
z1.backprop(1) #t = z1
print("dz/dx: %s" % x.grad())
print("dz/dy: %s" % y.grad())
print("dz/dp: %s" % p.grad())

x.clear_grad()
y.clear_grad()
z1.backprop(1) #t = z1
print("dz/dx: %s" % x.grad())
print("dz/dy: %s" % y.grad())
```

# Computing the smith normal form


```py
#!/usr/bin/env python3.6
# Smith normal form
import numpy as np
from numpy import *
import math

def row_for_var(xs, vi: int):
    NEQNS, NVARS = xs.shape
    for r in range(vi, NVARS):
        if xs[r][vi] != 0: return r
# return numbers (ax, ay) such that ax*x - ay*y = 0
def elim_scale_factor(x: int, y: int): return (y, x)

def smith_normal_form(xs, ys):
    NEQNS, NVARS = xs.shape
    assert(NEQNS == ys.shape[0])


    # eliminate variable 'vi' by finding a row 'r' and then using the row
    # to eliminate.
    for vi in range(NVARS):
        ri = row_for_var(xs, vi)
        if ri is None: 
            return (f"unable to find non-zero row for variable: {vi}")
        print(f"-eliminating variable({vi}) using row ({ri}:{xs[ri]})")
        # eliminate all other rows using this row
        for r2 in range(NEQNS):
            # skip the eqn ri.
            if r2 == ri: continue
            # eliminate.
            (scale_ri, scale_r2) = elim_scale_factor(xs[ri][vi], xs[r2][vi])

            print(f"-computing xs[{r2}] = {scale_r2}*xs[{r2}]:{xs[r2]} - {scale_ri}*xs[{ri}]:{xs[ri]}")
            xs[r2] = scale_r2 * xs[r2] - scale_ri * xs[ri]
            ys[r2] = scale_r2 * ys[r2] - scale_ri * ys[ri]
        print(f"-state after eliminating variable({vi})")
        print(f"xs:\n{xs}\n\nys:{ys}")

    sols = [None for _ in range(NVARS)]
    for vi in range(NVARS):
        r = row_for_var(xs, vi)
        if r is None:
            print(f"unable to find row for variable {vi}")
            return None
        assert(xs[r][vi] != 0)
        if ys[r] % xs[r][vi] != 0:
            print(f"unable to solve eqn for variable {vi}: xs:{xs[r]} = y:{ys[r]}")
            return None
        else:
            sols[vi] = ys[r] // xs[r][vi]

    # now check solutions if we have more equations than solutions
    for r in range(NEQNS):
        lhs = 0
        for i in range(NVARS): lhs += xs[r][i] * sols[i]
        if lhs != ys[r]:
            print(f"-solution vector sols:{sols} cannot satisfy row xs[{r}] = ys[{r}]:{xs[r]} = {ys[i]}")
            return None
        

    return sols

# consistent system
# x = 6, y = 4
# x + y = 10
# x - y = 2
xs = np.asarray([[1, 1], [1, -1]])
ys = np.asarray([10, 2]) 
print("## CONSISTENT ##")
out = smith_normal_form(xs,ys)
print("xs:\n%s\n\nys:\n%s\n\nsoln:\n%s" % (xs, ys, out,))


# consistent, over-determined system
# x = 6, y = 4
# x + y = 10
# x - y = 2
# x + 2y = 14
xs = np.asarray([[1, 1], [1, -1], [1, 2]])
ys = np.asarray([10, 2, 14]) 
print("## CONSISTENT OVER DETERMINED ##")
out = smith_normal_form(xs,ys)
print("xs:\n%s\n\nys:\n%s\n\nsoln:\n%s" % (xs, ys, out,))

# consistent, under-determined system
# x = 6, y = 4, z = 1
# x + y + z = 11
# x - y + z = 3
xs = np.asarray([[1, 1], [1, -1], [1, 2]])
ys = np.asarray([10, 2, 14]) 
print("## CONSISTENT UNDER DETERMINED ##")
out = smith_normal_form(xs,ys)
print("xs:\n%s\n\nys:\n%s\n\nsoln:\n%s" % (xs, ys, out,))


# inconsistent system
# x = 6, y = 4 
# x + y = 10
# x - y = 2
# x + 2y = 1 <- INCONSTENT
xs = np.asarray([[1, 1], [1, -1], [1, 2]])
ys = np.asarray([10, 2, 1]) 
print("## INCONSISTENT (OVER DETERMINED) ##")
out = smith_normal_form(xs,ys)

# inconsistent system
# x + y = 10
# x - y = 2
xs = np.asarray([[1, -1], [1, 2], [1, 1]])
ys = np.asarray([10, 2, 1]) 
print("## INCONSISTENT (OVER DETERMINED) ##")
out = smith_normal_form(xs,ys)


# consistent system over Q, not Z
# x = y = 0.5
# x + y = 1
# x - y = 0
xs = np.asarray([[1, 1], [1, -1]])
ys = np.asarray([1, 0]) 
print("## INCONSISTENT (SOLVABLE OVER Q NOT Z) ##")
out = smith_normal_form(xs,ys)
```

# Laziness for C programmers

#### Side node: nonsrict versus lazy (This section can be skipped)

I will use the word `non-strict` throughout, and not `lazy`.
Roughly speaking, `lazy` is more of an implementation detail that guarantees
that a value that is once computed is cached. (operational semantics)

`non-strict` is a evaluation order detail that guarantees that values are
not evaluated until there are truly required. (denotational semantics).

`lazy` is one way to _implement_ `non-strict`.

This is pure pedantry, but I'd like to keep it straight, since there seems to be
a lot of confusion involving the two words in general.

#### Showing off non-strictness:
We first need a toy example to work with to explain the fundamentals of
non-strict evaluation, so let's consider the example below. I'll explain the `case` construct which is explained below. Don't worry if ato lazy evaluation "looks weird", it feels that way to everyone till one plays around with it for a while!

We will interpret this example as both a strict program and a non-strict program.
This will show us that we obtain different outputs on applying different
interpretations.

We distinguish between primitive values (integers such as `1`, `2`, `3`) and boxed values
(functions, data structures). Boxed values can be evaluated non-stricly. Primitive values
do not need evaluation: they are primitive.

##### Code

```hs
-- Lines starting with a `--` are comments.
-- K is a function that takes two arguments, `x` and `y`, that are both boxed values.
-- K returns the first argument, `x`, ignoring the second argument, `y`.
-- Fun fact: K comes for the K combinator in lambda calculus.
kCombinator :: Boxed -> Boxed -> Boxed
kCombinator x y = x

-- one is a function that returns the value 1# (primitive 1)
one :: PrimInt
one = 1

-- Loopy is a function that takes zero arguments, and tries to return a boxed value.
-- Loopy invokes itself, resulting in an infinite loop, so it does not actually return.
loopy :: Boxed
loopy = loopy

-- main is our program entry point.
-- main takes no arguments, and returns nothing
main :: Void
main = case kCombinator one loopy of -- force K to be evaluated with a `case`
            kret -> case kret of  -- Force evaluation
                    i -> printPrimInt i -- Call the forced value of `kret` as `i` and then print it.
```

#### A quick explanation about `case`:
`case` is a language construct that *forces* evaluation. In general, no value
is evaluated unless it is *forced* by a case.

#### Analysing the example: The strict interpretation

If we were coming from a strict world, we would have assumed that the expression
`K one loopy` would first try to evaluate the arguments, `one` and `loopy`.
Evaluating `one` would return the primitive value `1`, so this has no problem.

On trying to evaluate `loopy`, we would need to re-evaluate `loopy`, and so on
ad infitum, which would cause this program to never halt.

This is because, as programmers coming from a strict world, we assume that
*values are evaluated as soon as possible*.

So, the output of this program is to have the program infinite-loop for ever,
under the strict interpretation.

#### Analysing the example: The non-strict interpretation:

In the non-strict world, we try to evaluate `K(1, loopy)` since we are asked the result
of it by the `case` expression. However, we do not try to evaluate `loopy`, since 
no one has asked what it's value is!

Now, we know that

```hs
kCombinator x y = x
```

Therefore, 

```hs
kCombinator one loopy = one
```

regardless of what value `loopy` held.

So, at the case expression:
```hs
main = case K(one, loopy) of -- force K to be evaluated with a `case`
>>>         kret -> ...
```

`kret = one`, we can continue with the computation.

```hs
main :: () -> Void
main = case kCombinator one loopy of -- force K to be evaluated with a `case`
            kret -> case kret of  -- Call the return value of K as `x`, and force evaluation.
                       i -> printPrimInt i -- Call the vreturn value of `x` as `primx` and then print it.
```

Here, we force `kret` (which has value `one`) to be evaluated with `case kret of...`.
since `one = 1`, `i` is bound to the value `1`.
Once `i` is returned, we print it out with `printPrimInt(primx)`.
 
The output of the program under non-strict interpretation is for it to print out `1`.

#### Where does the difference come from?

Clearly, there is a divide: strict evaluation tells us that this program should
never halt. Non-strict evaluation tells us that this program will print an output!

To formalize a notion of strictness, we need a notion of `bottom` (`_|_`).

A value is said to be `bottom` if in trying to evaluate it, we reach an
undefined state.

Now, if a function is *strict*, it would first evaluate its arguments and then
compute the result. So, if a strict function is given a value that is `bottom`,
the function will try to evaluate the argument, resulting in the computation
screwing up, causing the output of the whole function to be `bottom`.

Formally, a function `f` is strict iff (if and only if) `f(bottom) = bottom`.

Conversely, a *non-strict* function does not need to evaluate its arguments if it
does not use them, as in the case of `K 1 loopy`. In this case, `f(bottom)` need
not be equal to bottom.

Formally, a function `f` is non-strict iff (if and only if) `f(bottom) /= bottom`.

As Paul Halmos says

> "A good stack of examples, as large as possible, is indispensable for a
> thorough understanding of any concept, and when I want to learn something
> new, I make it my first job to build one.". Let us consider some examples.

- `id`

```hs
id x = x

id (3) = 1
id (bottom) = bottom
```

`id` is strict, since `id(bottom) = bottom`.


- `const`


```hs
const_one x = 1

const_one(bottom) = 1
const_one(3) = 1
```

`const_one` is not strict, as `const_one(bottom) /= bottom`.

- `K`

```hs
K x y = x

K 1 2 = 1
K 1 bottom = 1
K bottom 2 = bottom
```

Note that `K(bottom, y) = bottom`, so K is *strict in its first argument*, and
`K(x, bottom) /= bottom`, so K is *non-strict in its second argument*.

This is a neat example showing how a function can be strict and lazy in different
arguments of the function.


### Compiling non-strictness, v1:

#### How does GHC compile non-strictness?

`GHC` (the Glasgow haskell compiler) internally uses multiple intermediate
representations, in order of original, to what is finally produced:

- Haskell (the source language)
- Core (a minimal set of constructs to represent the source language)
- STG (Spineless tagless G-machine, a low-level intermediate representation that accurately captures non-strict evaluation)
- C-- (A C-like language with GHC-specific customization to support platform
  independent code generation).
- Assembly


Here, I will show how to lower simple non-strict programs from a **fictitous** `Core` like language down to `C` , while skipping `STG`, since it doesn't
really add anything to the high-level discussion at this point.

#### Our example of compiling non-strictness

Now, we need a *strategy* to compile the non-strict version of our program.
Clearly, `C` cannot express laziness directly, so we need some other
mechanism to implement this. I will first code-dump, and then explain as we go along.


###### Executable `repl.it`:
<iframe height="400px" width="100%" src="https://repl.it/@bollu/Compiling-non-strict-programs-on-the-call-stack?lite=true" scrolling="no" frameborder="no" allowtransparency="true" allowfullscreen="true" sandbox="allow-forms allow-pointer-lock allow-popups allow-same-origin allow-scripts allow-modals"></iframe>

###### Source code
```
#include <assert.h>
#include <stdio.h>

/* a boxed value is a function that can be executed to compute something.
* We make the return value `void` on purpose. This needs to be typecast to a concrete
* Boxed type to get a value out of it: eg, typecast to BoxedInt.
*/
typedef void (*Boxed)();

/* A boxed int, that on evaluation yields an int*/
typedef int (*BoxedInt)();

/* one = 1# */
int one() {
    return 1;
}

/* bottom = bottom */
void bottom() {
    printf("in function: %s\n", __FUNCTION__);
    bottom();
}

/* K x y = x */
Boxed K(Boxed x, Boxed y) {
  return x;
}

/*
main :: () -> Void
main = case K(one, loopy) of -- force K to be evaluated with a `case`
            kret -> case kret of  -- Call the return value of K as `x`, and force evaluation.
                    i -> printPrimInt(i) -- Call the vreturn value of `x` as `primx` and then print it.
*/
int main() {
    Boxed kret = K((Boxed)one, (Boxed)bottom);
    int i = (*(BoxedInt)kret)();
    printf("%d", i);
    return 1;
}

```

We convert every possibly lazy value into a `Boxed` value, which is a function pointer that knows how to compute the
underlying value. When the lazy value is forced by a `case`, we call the `Boxed` function to compute the output.

This is a straightforward way to encode non-strictness in C. However, do note that this is not *lazy*, because a value could get
recomputed many times. *Laziness* guarantees that a value is only computed once and is later memoized.


#### Compiling with a custom call stack / continuations

As one may notice, we currenly use the native call stack every time we *force*
a lazy value. However, in doing  so, we might actually run out of stack space,
which is undesirable. Haskell programs like to have "deep" chains of values
being forced, so we would quite likely run out of stack space.

Therefore, GHC opts to manage its own call stack on the heap. The generated
code looks as you would imagine: we maintain a stack of function pointers +
auxiliary data ( stack saved values), and we push and pop over this "stack".
When we run out of space, we `<find correct way to use mmap>` to increase our
"stack" size. 

I've played around with this value a little bit, and have found that the modern
stack size is quite large: IIRC, It allowed me to allocate ~`26 GB`. I believe
that the amount it lets you allocate is tied directly to the amount of physical
memory + swap you have. I'm not too sure, however. So, [for my haskell compiler, `sxhc`](https://github.com/bollu/simplexhc-cpp.git), I am considering
cheating and just using the stack directly.

Code for the same example (with the K combinator) is provided here.

##### Executable `repl.it`:
<iframe height="1000px" width="100%" src="https://repl.it/@bollu/Compiling-programs-with-continuations?lite=true" scrolling="no" frameborder="no" allowtransparency="true" allowfullscreen="true" sandbox="allow-forms allow-pointer-lock allow-popups allow-same-origin allow-scripts allow-modals"></iframe>


##### Source code

```c
#include <assert.h>
#include <stdio.h>
#define STACK_SIZE 50000

/* a boxed value is a function that can be executed to compute something. */
typedef void (*Boxed)();

/* a return continuation that receives a boxed value. */
typedef void (*BoxedContinuation)(Boxed);

/* A return continuation that receives an int value. */
typedef void (*IntContinuation)(int);

/* Custom stack allocated on the .data section*/
void *stack[STACK_SIZE];

/* Stack pointer */
int sp = 0;

/* Push a continuation `cont` */
void pushContinuation(void *cont) {
    assert(sp >= 0);
    assert(sp < STACK_SIZE);
    stack[sp] = cont;
    sp++;
}

/* Pop a continuation frame. */
void *popContinuation() {
    assert(sp < STACK_SIZE);
    assert(sp >= 0);
    sp--;
    void *cont = stack[sp];
    return cont;
}

/* one = 1# */
void one() {
    printf("in function: %s\n", __FUNCTION__);
    void *f = popContinuation();
    (*(IntContinuation)(f))(1);
}

/* bottom = bottom */
void bottom() {
    printf("in function: %s\n", __FUNCTION__);
    bottom();
}

/* K x y = x */
void K(Boxed x, Boxed y) {
    printf("in function: %s\n", __FUNCTION__);
    void *f = popContinuation();
    (*(BoxedContinuation)(f))(x);
}

void XForceContinuation(int i) {
    printf("in function: %s\n", __FUNCTION__);
    printf("%d", i);
}

void KContinuation(Boxed x) {
    printf("in function: %s\n", __FUNCTION__);
    pushContinuation((void *)XForceContinuation);
    x();
}

int main() {
    printf("in function: %s\n", __FUNCTION__);
    pushContinuation((void *)KContinuation);
    K(one, bottom);
    return 0;
}
```

we maintain our own "call stack" of continuations. These continuations are precisely the
parts of the code that deal with the return value of a case. ever

```hs
case x of
    xeval -> expr
```

compiles to:

```c
pushContinuation(XEvalContinuation);
x()
```

That is, push a continuation, and then "enter" into `x`.

One might have a question: does this still not use the call stack? There is a
function call at the end of most functions in the source code, so in theory, we
_are_ using the call stack, right? The answer is no. It's thanks to a neat
optimisation technique called _tail call elimination_. The observation is that
_after the call_, there is no more code to execute in the caller. So, by
playing some stack tricks, one can convert a _call_ to a _jump_. 

Remember, a _`call`_ instruction uses the stack to setup a stack frame, under
the assumption that we will _`ret`_ at some point.  But, clearly, under our
compilation model, we will never `ret`, simply call more functions. So, we
don't *need* the state maintained by a `call`. We can simply `jmp`.

#### Wrapping up

I hope I've managed to convey the _essence_ of how to compile Haskell. I skipped a couple of things:
- haskell data types: sum and product types. These are straightforward, they just compiled to tagged structs.
- `let` bindings: These too are straightforward, but come with certain retrictions in STG. It's nothing groundbreaking,and
   is well written in the paper.
- Black holes: Currently, we are not truly _lazy_, in that we do not update values once they are computed.
- GC: how to weave the GC through the computation is somewhat non-trivial.

All of this is documented in the excellent paper:
[Implementing lazy languages on stock hardware](https://www.dcc.fc.up.pt/~pbv/aulas/linguagens/peytonjones92implementing.pdf).


I am considering extending this blog post that expands on these ideas. If there
is interest, please do e-mail me at `siddu.druid@gmail.com`.

# Exact sequence of pointed sets

This was a shower thought. I don't even if these form an abelian category.
Let's assume we have pointed sets, where every set has a distinguished 
element $*$. $p$ will be analogous to the zero of an abelian
group. We will also allow multi-functions, where a function can have
multiple outputs. Now let's consider two sets, $A, B$ along with their
'smash union' $A \vee B$ where we take the disjoint union of $A, B$ with a
smashed $*$. To be very formal:

$$
A \vee B = \{0\} \times (A - \{ * \}) \cup \{1\}\times (B - \{ * \}) \cup \{ * \}
$$

We now consider the exact sequence:

$$
(A \cap B, *) \xrightarrow{\Delta} (A \vee B, *) \xrightarrow{\pi} (A \cup B, *)
$$

with the maps as:
$$
\begin{aligned}
&ab \in A \cap B \xmapsto{\Delta} (0, ab), (1, ab) \in A \vee B \\
&(0, a) \in A \vee B \xmapsto{\pi}
\begin{cases}
 * & \text{if } a \in B \\
 a  &\text{otherwise} \\
\end{cases} \\
&(1, b) \in A \vee B \xmapsto{\pi}
\begin{cases}
 * & \text{if } b \in A \\
 b  &\text{otherwise} \\
\end{cases} \\
\end{aligned}
$$

- We note that $\Delta$ is a multi-function, because it produces as output both
  $(0, ab)$ and $(1, ab)$.
- $\ker(\pi) = \pi^{-1}(*) = \{ (0, a) : a \in B \} \cup \{ (1, b) : b \in A \}$
- Since it's tagged $(0, a)$, we know that $a \in A$. Similarly, we know that $b \in B$.
- Hence, write $\ker(\pi) = \{ (0, ab), (1, ab) : ab \in A \cap B \} = im(\Delta)$

This exact sequence also naturally motivates one to consider
$A \cup B - A \cap B = A \Delta B$, the symmetric difference. It also gives
the nice counting formula $|A \vee B| = |A \cap B| + |A \cup B|$, also known
as inclusion-exclusion.

I wonder if it's possible to recover incidence algebraic derivations from this
formuation?

#### Variation on the theme: direct product

This version seems wrong to me, but I can't tell what's wrong. Writing it down:

$$
\begin{aligned}
(A \cap B, *) \xrightarrow{\Delta} (A \times B, (*, *)) \xrightarrow{\pi} (A \cup B, *)
\end{aligned}
$$

with the maps as:

$$
\begin{aligned}
&ab \in A \cap B \xmapsto{\Delta} (ab, ab) \in A \times B \\
&(a, b) \in A \times B \xmapsto{\pi}
\begin{cases}
 * & \text{if } a = b \\
 a, b  &\text{otherwise} \\
\end{cases} \\
\end{aligned}
$$

One can see that:
- $A \cap B \xrightarrow{\Delta} A \times B$ is injective
- $A \cap B \xrightarrow{\pi} A \cup B$ is surjective
- $ker(\pi) = \pi^{-1}(*) = \{ (a, b) : a \in A, b \in B, a = b \} = im(\Delta)$

Note that to get the last equivalence, we do not consider elements like
$\pi(a, *) = a, *$ to be a pre-image of $*$, because they don't _exact_ ly map
into $*$ [pun intended].



# What is a syzygy?

Word comes from greek word for "yoke" . If we have two oxen pulling, we yoke
them together to make it easier for them to pull.

#### The ring of invariants

Rotations of $\mathbb R^3$: We have a group $SO(3)$ which is acting on a vector space
$\mathbb R^3$. This  preserves the length, so it preserves the
polynomial $x^2 + y^2 + z^2$. This polynomial $x^2 + y^2 + z^2$ is said to be
the invariant polynomial of the group $SO(3)$ acting on the vector space
$\mathbb R^3$.

- But what does $x, y, z$ even mean? well, they are linear function $x, y, z: \mathbb R^3 \rightarrow \mathbb R$.
  So $x^2 + y^2 + z^2$ is a "polynomial" of these linear functions.

#### How does a group act on polynomials?

- If $G$ acts on $V$, how does $G$ act on the polynomial functions $V \rightarrow \mathbb R$?
- In general, if we have a function $f: X \rightarrow Y$ where $g$ acts on $X$ and $Y$
  (in our case, $G$ acts trivially on $Y=\mathbb R$), what is $g(f)$?
- We define $(gf)(x) \equiv g (f(g^{-1}(x)))$.
- What is the $g^{-1}$? We should write
  $(gf)(gx) = g(fx)$. This is like $g(ab) = g(a) g(b)$. We want to get
  $(gf)(x) = (gf)(g(g^{-1}x) = g(f(g^{-1}x))$.
- If we miss out $g^{-1}$ we get a mess. Let's temporarily define $(gf)(x) = f(g(x))$. Consider
   $(gh)f(x) = f(ghx)$. But we
  can also take this as $(gh)(f(x)) = g((hf)(x)) = (hf)(gx) = f(hgx)$. This is
  absurd as it gives $f(ghx) = f(hgx)$.

#### Determinants

We have $SL_n(k)$ acting on $k^n$, it acts transitively, so there's no interesting non-constant
invariants. On the other hand, we can have $SL_n(k)$ act on $\oplus_{i=1}^n k^n$. So if $n=2$
we have:

$$
\begin{bmatrix}
a & b \\ c & d
\end{bmatrix}
$$

acting on:

$$
\begin{bmatrix}
x_1 & y_1 \\ x_2 & y_2
\end{bmatrix}
$$

This action preserves the polynomial $x_1 y_2 - x_2 y_1$, aka the determinant. anything that
ends with an "-ant" tends to be an "invari-ant" (resultant, discriminant)

#### $S_n$ acting on $\mathbb C^n$ by permuting coordinates.

Polynomials are functions $\mathbb C[x_1, \dots, x_n]$. Symmetric group
acts on polynomials by permuting $x_1, \dots, x_n$. What are the invariant
polynomials?

- $e_1 \equiv x_1 + x_2 + \dots x_n$
- $e_2 \equiv x_1 x_2 + x_1 x_3 + \dots + x_{n-1} x_n$.
- $e_n \equiv x_1 x_2 \dots x_n$.

These are the famous elementary symmetric functions. If we think of
$(y - x_1) (y - x_2) \dots (y - x_n) = y^n - e_1 y^{n-1} + \dots e_n$.

- The **basic theory of symmetric functions** says that every invariant polynomial
  in $x_1, \dots x_n$ is a polynomial in $e_1, \dots, e_n$.

#### Proof of elementary theorem

Define an ordering on the monomials; order by lex order.
Define $x_1^{m_1} x_2^{m_2} > x_1^{n_1} x_2^{n_2} \dots$ iff either
$m_1 > n_1$ or $m_1 = n_1 \land m_2 > n_2$ or $m_1 = n_1 \land m_2 = n_2 \land m_3 > n_3$ and so on.

Suppose $f \in \mathbb C[x_1, \dots, x_n]$ is invariant. Look at the biggest monomial in $f$.
Suppose it is $x_1^{n_1} x_2^{n_2} \dots$. We subtract:

$$
\begin{aligned}
P \equiv 
&(x_1 + x_2 \dots)^{n_1 - n_2} \\
&\times  (x_1 x_2 + x_1 x_2 \dots)^{n_2 - n_3} \\
&\times  (x_1 x_2 x_3 + x_1 x_2 x_4 \dots)^{n_3 - n_4} \\
\end{aligned}
$$

This kills of the biggest monomial in $f$. If $f$ is symmetric, 
Then we can order the term we choose such that $n_1 \geq n_2 \geq n_3 \dots$.
We need this to keep the terms $(n_1 - n_2), (n_2 - n_3), \dots$ to be positive.
So we have now killed off the largest term of $f$.  Keep doing this to kill of $f$ completely.

This means that the invariants of $S_n$ acting on $\mathbb C^n$ are a finitely generated
algebra over $\mathbb C$. So we have a finite number of generating invariants such that every invariant
can be written as a polynomial of the generating invariants with coefficients in $\mathbb C$. This is
the first non-trivial example of invariants being finitely generated.


The algebra of invariants is a **polynomial ring** over $e_1, \dots, e_n$. This means that there
are no **non-trivial-relations** between $e_1, e_2, \dots, e_n$. This is unusual; usually
the ring of generators will be complicated.  This simiplicity tends to happen if $G$ is
a reflection group. We haven't seen what a syzygy is yet; We'll come to that.

#### Complicated ring of invariants

Let $A_n$ (even permutations). Consider the polynomial $\Delta \equiv \prod_{i < j} (x_i - x_j)$
This is called as the discriminant.
This looks like $(x_1 - x_2)$, $(x_1 - x_2)(x_1 - x_3)(x_2 - x_3)$, etc. When $S_n$ acts on $\Delta$,
it either keeps the sign the same or changes the sign. $A_n$ is the subgroup of $S_n$ that
keeps the sign fixed.

What are the invariants of $A_n$? It's going to be all the invariants of $S_n$, $e_1, \dots, e_n$,
plus $\Delta$ (because we defined $A_n$ to stabilize $\Delta$). There are no relations between
$e_1, \dots, e_n$. But there are relations between $\Delta^2$ and $e_1, \dots, e_n$ because $\Delta^2$
is a symmetric polynomial.

Working this out for $n=2$,we get $\Delta^2 = (x_1 - x_2)^2 = (x_1 + x_2)^2 - 4 x_1 x_2 = e_1^2 - 4 e_1 e_2$.
When $n$ gets larger, we can still express $\Delta^2$ in terms of the symmetric polynomials,
but it's frightfully complicated.

This phenomenon is an example of a Syzygy. For $A_n$, the ring of invariants is finitely generated
by $(e_1, \dots, e_n, \Delta)$. There is a non-trivial relation where $\Delta^2 - poly(e_1, \dots, e_n) = 0$.
So this ring is not a polynomial ring. This is a first-order Syzygy. Things can get more complicated!


#### Second order Syzygy

Take $Z/3Z$ act on $\mathbb C^2$. Let $s$ be the generator of $Z/3Z$. We define
the action as $s(x, y) = (\omega x, \omega y)$ where $\omega$ is the cube root of unity. 
We have $x^ay^b$ is invariant if $(a + b)$ is divisible by $3$, since we will just get $\omega^3 = 1$.

So the ring is generated by the monomials $(z_0, z_1, z_2, z_3) \equiv (x^3, x^2y, xy^2, y^3)$.
Clearly, these have relations between them. For example:
- $z_0 z_2 =  x^4y^2 = z_1^2$. So $z_0 z_2 - z_1^2 = 0$.
- $z_1 z_3   x^2y^4 = z_2^2$. So $z_1 z_3 - z_2^2 = 0$.
- $z_0 z_3 = x^3y^3 = z_1 z_2$. So $z_0 z_3 - z_1 z_2 = 0$.

We have 3 first-order syzygies as written above. Things are more complicated than that. We can
write the syzygies as:

- $p_1 \equiv z_0 z_2 - z_1^2$.
- $p_2 \equiv z_1 z_3 - z_2^2$.
- $p_3 \equiv z_0 z_3 - z_1 z_2$.

We have $z_0 z_2$ in $p_1$. Let's try to cancel it with the $z_2^2$ in $p_2$. So we consider:

$$
\begin{aligned}
& z_2 p_1 + z_0 p_2 \\
&= z_2 (z_0 z_2 - z_1^2) + z_0 (z_1 z_3 - z_2^2) \\
&= (z_0 z_2^2 - z_2 z_1^2) + (z_0  z_1 z_3 - z_0 z_2^2) \\
&= z_0 z_1 z_3 - z_2 z_1^2 \\ 
&= z_1(z_0 z_3 - z_1 z_2) \\
&= z_1 p_3
\end{aligned}
$$

So we have non-trivial relations between $p_1, p_2, p_3$! This is a second order syzygy, a sygyzy between syzygies.


We have a ring $R \equiv k[z_0, z_1, z_2, z_3]$. We have a map $R \rightarrow \texttt{invariants}$.
This has a nontrivial kernel, and this kernel is spanned by $(p_1, p_2, p_3) \simeq R^3$. But this itself
has a kernel $q = z_1 p_1 + z_2 p_2 + z_3 p_3$. So there's an exact sequence:

$$
\begin{aligned}
0 \rightarrow R^1 \rightarrow R^3 \rightarrow R=k[z_0, z_1, z_2, z_3] \rightarrow \texttt{invariants}
\end{aligned}
$$

In general, we get an invariant ring of linear maps that are invariant under the group action.
We have polynomials $R \equiv k[z_0, z_1, \dots]$ that map onto the invariant ring. We have
relationships between the $z_0, \dots, z_n$. This gives us a sequence of syzygies. We have many
questions:

1. Is $R$ finitely generated as a $k$ algebra? Can we find a finite number of generators?
2. Is $R^m$ finitely generated (the syzygies as an $R$-MODULE)? To recall the difference, see that $k[x]$
   is finitely generated as an ALGEBRA  by $(k, x)$ since we can multiply the $x$s. It's not finitely generated as a
   MODULE as we need to take all powers of $x$: $(x^0, x^1, \dots)$.
3. Is this SEQUENCE of sygyzy modulues FINITE?
4. Hilbert showed that the answer is YES if $G$ is reductive and $k$ has characteristic zero. We will
   do a special case of $G$ finite group.

We can see why a syzygy is called such; The second order sygyzy "yokes" the first order sygyzy. It ties together
the polynomials in the first order syzygy the same way oxen are yoked by a syzygy.



#### Is inclusion/exclusion a syzygy?

I feel it is, since each level of the inclusion/exclusion arises as a "yoke" on the previous level.
I wonder how to make this precise.


#### References
- [Richard E Borcherds: Commutative Algebra, lecture 3](https://www.youtube.com/watch?v=RYPt7kGdo7s&list=PL8yHsr3EFj53rSexSz7vsYt-3rpHPR3HB&index=3)



# Under the spell of Leibniz's dream

- [Link to the article by djikstra](http://www.cs.utexas.edu/users/EWD/transcriptions/EWD12xx/EWD1298.html)
- [`monochrom`'s favourite work on djikstra](http://www.vex.net/~trebla/ewd.html)

I found it very quotable. I'm posting some quotes below.

- On applied versus pure mathematics:

> An important side-effect of the hard times was the creation of a spiritual
> climate in which the distinction between pure and applied science had
> vanished: of all the things you could do, you just did the most urgent one,
> and the development of some urgently needed theory was often the most
> practical thing to do.

- On 'applied institutes':

> The worst thing with institutes explicitly devoted to applied science is that
> they tend to become institutes of second-rate theory. 

- On the artificial divide between theory and applied sections of university:

> These days there is so much obsession with application that, if the
> University is not careful, external forces, which do make the distinction,
> will drive a wedge between "theory" and "practice" and may try to banish the
> "theorists" to a ghetto of separate departments and separate buildings. A
> simple extrapolation will tell us that in due time the isolated practitioners
> will have little to apply; this is well-known, but has never prevented the
> financial mind from killing the goose that lays the golden eggs.

- On programming as typing:

> Needless to say, this confusion between the score and the composition led to
> an underestimation of the intellectual challenges programming presents

- On hilbert and axiomatics:

>  Hilbert's revolution was in any case to redefine "proof" to become a
>  completely rigorous notion, totally different from the psycho/sociological
>  "A proof is something that convinces other mathematicians."





# Normal operators: Decomposition into Hermitian operators

Given a normal operator $A$, we can always decompose it $A = B + iC$
where $B = B^{\dagger}$, $C = C^\dagger$, and $[B, C] = 0$.


This means that we can define 'complex measurements' using a normal operator,
because a normal operator has full complex spectrum. Since we can always
decompose such an operator $A$ into two hermitian operators $B, C$
that commute, we can diagonalize $B, C$ simultaneously and thereby measure
$B, C$ simultaneously.

So extending to "complex measurements" gives us no more power than staying
at "real measurements"

### Decomposing a normal operator

Assume we have a normal operator $A$. Write the operator in its eigenbasis $\{ |a_k \rangle \}$.
This will allow us to write $A = \sum_k |a_k \rangle \langle a_k|$.
with each $a_k = b_k + i c_k$. Now write this as:

$$
\begin{aligned}
& A = \sum_k (b_k + i c_k)|a_k \rangle \langle a_k| \\
& A = \sum_k b_k  |a_k \rangle \langle a_k| + i c_k |a_k \rangle \langle a_k|  \\
& A = B + iC \\
\end{aligned}
$$

$B, C$ are simultaneously diagonalizable in the eigenbasis $\{ |a_k \rangle \}$
and hence $[B, C] = 0$.


# Readable pointers

I recently had to debug a whole bunch of code that manipuates pointers, so I
need to stare at random things like `0x7f7d6ab2c0c0`, like so:

```
mkClosure_capture0_args0 (0x7f079ae2a0c0:) -> 0x556b95a23350:
mkClosure_capture0_args0 (0x7f079ae2a0e0:) -> 0x556b95a3f3e0:
mkClosure_capture0_args2 (0x7f079ae2a000:, 
  0x556b95a23350:, 0x556b95a3f3e0:) -> 0x556b95a232e0:
evalClosure (0x556b95a232e0:)
  ⋮evalClosure (0x556b95a23350:)
  ⋮  ⋮mkConstructor1 (MkSimpleInt, 0x1) -> 0x556b9596c0b0:
  ⋮=>0x556b9596c0b0:
  ⋮isConstructorTagEq (0x556b9596c0b0:MkSimpleInt, MkSimpleInt) -> 1
  ⋮extractConstructorArg  0 -> 0x1:
  ⋮evalClosure (0x556b95a3f3e0:)
  ⋮  ⋮mkConstructor1 (MkSimpleInt, 0x2) -> 0x556b95a23190:
  ⋮=>0x556b95a23190:
  ⋮isConstructorTagEq (0x556b95a23190:MkSimpleInt, MkSimpleInt) -> 1
  ⋮extractConstructorArg  0 -> 0x2:
  ⋮mkConstructor1 (MkSimpleInt, 0x3) -> 0x556b95902a30:
=>0x556b95902a30:
```

 I got annoyed because it's hard to spot differences across numbers. So I wrote
 a small '''algorithm''' that converts this into something pronounceable:

```cpp
char *getPronouncableNum(size_t N) {
     const char *cs = "bcdfghjklmnpqrstvwxzy";
     const char *vs = "aeiou";

     size_t ncs = strlen(cs); size_t nvs = strlen(vs);

     char buf[1024]; char *out = buf;
     int i = 0;
     while(N > 0) {
         const size_t icur = N % (ncs * nvs);
         *out++ = cs[icur%ncs]; *out++ = vs[(icur/ncs) % nvs];
         N /= ncs*nvs;
         if (N > 0 && !(++i % 2)) { *out++ = '-'; }
     }
     *out = 0;
     return strdup(buf);
};
```

which gives me the much more pleasant output:

```
mkClosure_capture0_args0 (0x7fbf49b6d0c0:cisi-jece-xecu-yu) 
  -> 0x561c5f11f9d0:suje-zoni-ciho-ko
mkClosure_capture0_args0 (0x7fbf49b6d0e0:qosi-jece-xecu-yu) 
  -> 0x561c5f12f1b0:leda-guni-ciho-ko
mkClosure_capture0_args2 (0x7fbf49b6d000:ziqi-jece-xecu-yu, 
  0x561c5f11f9d0:suje-zoni-ciho-ko, 
  0x561c5f12f1b0:leda-guni-ciho-ko) 
    -> 0x561c5f11f960:kuhe-zoni-ciho-ko
evalClosure (0x561c5f11f960:kuhe-zoni-ciho-ko)
  ⋮evalClosure (0x561c5f11f9d0:suje-zoni-ciho-ko)
  ⋮  ⋮mkConstructor1 (MkSimpleInt, 0x1) -> 0x561c5f129c10:qifa-duni-ciho-ko
  ⋮=>0x561c5f129c10:qifa-duni-ciho-ko
  ⋮isConstructorTagEq (0x561c5f129c10:MkSimpleInt, MkSimpleInt) -> 1
  ⋮extractConstructorArg  0 -> 0x1:ca
  ⋮evalClosure (0x561c5f12f1b0:leda-guni-ciho-ko)
  ⋮  ⋮mkConstructor1 (MkSimpleInt, 0x2) -> 0x561c5f120200:nuhi-zoni-ciho-ko
  ⋮=>0x561c5f120200:nuhi-zoni-ciho-ko
  ⋮isConstructorTagEq (0x561c5f120200:MkSimpleInt, MkSimpleInt) -> 1
  ⋮extractConstructorArg  0 -> 0x2:da
  ⋮mkConstructor1 (MkSimpleInt, 0x3) -> 0x561c5f100010:kuqi-koni-ciho-ko
=>0x561c5f100010:kuqi-koni-ciho-ko
```

The strings of the form `ziqi-jece-xecu-yu` makes it way easier to see control flow.
I can also see if two pointers are close, based on shared suffixes: ciho-ko is
shared, which means the numbers are themselves close.

- It turns out there's a system called [proquints](https://arxiv.org/html/0901.4016)
  that allows for such a thing already!


<!-- - [Support me in making more visualizations!](https://www.patreon.com/bollu) -->
# The grassmanian, handwavily

The grassmanian is a manifold consisting of, roughly, $k$ dimensional subspaces
of an $n$ dimensional vector space. 

Here, I'll record derivations of how we represent grassmanians, the exponential
map, logarithm map, and the parallel transport with "physicist style"
reasoning. Really, one needs to be careful because the grassmanian is a
quotient of the non-compact steifel manifold, so we need to be careful about
choosing representatives and whatnot. However, nothing beats physicist
reasoning for intuition, so I'm going to do all the derivations in that style.

[TODO]


# Lie bracket as linearization of conjugation

Let us have $Y = GXG^{-1}$ with all of these as matrices. Let's say that $G$
is very close to the identity: $G = I + E$ with $E^2 = 0$ ($E$ for epsilon).
Note that now, $G^{-1} = (I + E)^{-1}$, which by abuse of notation
can be written as $1/(I + E)$, which by taylor expansion is equal to 
$I - E + E^2 - E^3 + \dots$. Since $E$ is nilpotent, we truncate at $E^2$
leaving us with $(I - E)$ as the inverse of $(I+E)$. We can check that this is correct, by computing:

$$
\begin{aligned}
&(I+E)(I - E) = \\
&= I - E + E - E^2 \\
&= I - E^2 = \\
&= I - 0 = I
\end{aligned}
$$

This lets us expand out $Y$ as:

$$
\begin{aligned}
&Y = GXG^{-1} \\
&Y = (I + E)X(I + E)^{-1} \\
&Y = (I + E)X(I - E) \\
&Y = IXI -IXE + EXI - EXE \\
&Y = X - XE + EX - EXE 
\end{aligned}
$$

Now we assert that because $E$ is small, $EXE$ is of order $E^2$ and will therefore
vanish. This leaves us with:

$$ GXG^{-1} = Y = X + [E, X] $$

and so the lie bracket is the Lie algebra's way of recording the effect of the
group's conjugacy structure.

# Computational Origami

- [RabbitEar: library for building origami visualizations in the browser](https://rabbitear.org/docs/)
- [ORIPA: tool for visualizing flat folded origami](https://github.com/oripa/oripa)
- [TreeMaker:]()
- [Origami Simulator: Tool to simulate origami, going from flat shaped to folded shaped](https://origamisimulator.org/)

# Katex in duktape

Here's some code to use `duktape`, a lightweight JavaScript interpreter
to run `katex` when implementing a custom static site generator [as I
am doing for this website]. This seems to be *way more lightweight*
than relying on Node, since we don't need to pay for inter-procedure-calls.


I haven't benchmarked my static site generator against others, but I would
be surprised if it is much faster, since it is written entirely in C, and
avoids anything 'expensive'.

```c
#include "duktape.h"
#include <stdio.h>
#include <assert.h>
typedef long long ll;

void vduk_print_stack(duk_context *ctx, const char *fmt, va_list args){
    char *outstr = nullptr;
    vasprintf(&outstr, fmt, args);
    assert(outstr);

    printf("\nvvv%svvv\n", outstr);
    printf("[TOP OF STACK]\n");
    const int len = duk_get_top(ctx);
    for(int i = 1; i <= len; ++i) {
        duk_dup(ctx, -i);
        printf("stk[-%2d] = %20s\n", i, duk_to_string(ctx, -1));
        duk_pop(ctx);
    }
    printf("^^^^^^^\n");
}


void duk_print_stack(duk_context *ctx, const char *fmt, ...) {
    va_list args;
    va_start(args, fmt);
    vduk_print_stack(ctx, fmt, args);
    va_end(args);
}
int main() {
    const char *latex_to_compile = "\\int_0^\\infty f(x) dx";
    const char *broken_latex_to_compile = "\\int_0^\\infty \\foobar f(x) dx";


    // FILE *fkatex = fopen("/home/bollu/blog/katex/katex.min.js", "rb");
    FILE *fkatex = fopen("/home/bollu/blog/katex/katex.min.js", "rb");
    if (fkatex == nullptr) { assert(false && "unable to open katex.min.js"); }

    fseek(fkatex, 0, SEEK_END);
    const ll len = ftell(fkatex); fseek(fkatex, 0, SEEK_SET);
    char *js = (char *)calloc(sizeof(char), len + 10);

    const ll nread = fread(js, 1, len, fkatex);
    assert(nread == len);
    duk_context *ctx = duk_create_heap_default();
    duk_push_string(ctx, "katex.min.js"); // for error message
    if (duk_pcompile_string_filename(ctx, 0, js) != 0) {
        fprintf(stderr, "===katex.min.js compliation failed===\n%s\n===\n", 
                duk_safe_to_string(ctx, -1));
        assert(false && "unable to compile katex.min.js");
    } else {
        fprintf(stderr, "===katex.min.js successfully complied===\n");

        duk_print_stack(ctx, "Stack afer compilation", __LINE__);
        duk_call(ctx, 0);   
        printf("program result: %s\n", duk_safe_to_string(ctx, -1));

    }



    // https://wiki.duktape.org/howtofunctioncalls
    duk_print_stack(ctx, "%d", __LINE__);
    if(duk_peval_string(ctx, "katex") != 0) {
        printf("eval failed: %s\n", duk_safe_to_string(ctx, -1));
        assert(0 && "unable to find the katex object");
    }  else {
        duk_print_stack(ctx, "%d", __LINE__);
    }

    duk_print_stack(ctx, "%d", __LINE__);
    duk_push_string(ctx, "renderToString");
    duk_push_string(ctx, latex_to_compile);

    duk_print_stack(ctx, "%d", __LINE__);
    if(duk_pcall_prop(ctx, -3, 1) == DUK_EXEC_SUCCESS) {
        printf("===katexed output:===\n%s\n", duk_to_string(ctx, -1));
    } else {
        printf("unable to katex: %s\n", duk_to_string(ctx, -1));
        assert(false && "unable to katex input");
    }
 
    return 0;
}
```

# Kebab case

[I learnt from the Nu shell blog](https://www.nushell.sh/blog/2020/08/23/year_of_nushell.html)
that `this-style-of-writing` variables is called as `kebab-case`. Very
evocative.

# Localization: Introducing epsilons (TODO)

We can think of localization at a zero divisors
as going from a regime of having divisors of zero into a
regime of having $\epsilon$. I'll explore this perspective by consider
$R = \mathbb Z/12 \mathbb Z$.


# NaN punning: Storing integers in doubles in JavaScript

This is a technique that allows us to store data inside a `double` by
punning the value of a `NaN`. This is used inside javascript engines
to represent all possible user types as a single NaN.
[This is well explained at the SpiderMonkey internals page](https://developer.mozilla.org/en-US/docs/Mozilla/Projects/SpiderMonkey/Internals)

```cpp
#include <assert.h>
#include <iostream>
#include <limits>
using namespace std;
// https://en.wikipedia.org/wiki/NaN
union PunDouble { 
    double d;
    struct { 
        uint64_t m      : 51;
        uint32_t qnan: 1;
        uint32_t e      : 11;
        uint32_t s      : 1;
    } bits;
    PunDouble(double d) : d(d) {};
    PunDouble(uint32_t s, uint32_t e, uint64_t m) {
        bits.s = s;
        bits.e = e;
        bits.qnan = 1;
        bits.m = m;
    }
};

union PunInt {
    int32_t i;
    uint32_t bits;
    PunInt(int32_t i): i(i) {};
};

using namespace std;
struct Box {

    inline bool is_int() const { 
        auto pd = PunDouble(d);
        return pd.bits.e == 0b11111111111 && pd.bits.qnan == 1;
    }
    inline bool isdouble() const {
        auto pd = PunDouble(d);
        return (pd.bits.e != 0b11111111111) || (pd.bits.qnan == 0); 
    }
    int32_t get_int() const { 
        assert(is_int());
        uint64_t m = PunDouble(d).bits.m; return PunInt(m).i;
    }
    double get_double() const { assert(isdouble()); return d; }
    Box operator +(const Box &other) const;

    static Box mk_int(int32_t i) { 
        return Box(PunDouble(1, 0b11111111111, PunInt(i).bits).d);
    }
    static Box mk_double(double d) { return Box(d); }
    double rawdouble() const { return d; }
    private:
    double d; Box(double d) : d(d) {}
};

// = 64 bits
Box Box::operator + (const Box &other) const {
    if (isdouble()) { 
        assert(other.isdouble());
        return Box::mk_double(d + other.d);
    }
    else { 
        assert(is_int());
        assert(other.is_int());
        return Box::mk_int(get_int() + other.get_int());
    }
}

ostream &operator << (ostream &o, const Box &b) {
    if (b.isdouble()) { return o << "[" << b.get_double() << "]"; }
    else { return o << "[" << b.get_int() << "]"; }
}

int32_t randint() { return (rand() %2?1:-1) * (rand() % 100); }
                    
int32_t main() {

    // generate random integers, check that addition checks out
    srand(7);
    for(int32_t i = 0; i < 1000; ++i) {
        const int32_t i1 = randint(), i2 = randint();
        const Box b1 = Box::mk_int(i1), b2 = Box::mk_int(i2);
        cout << "i1:" << i1 << "  b1:" << b1 << "  b1.double:" << b1.rawdouble() << "  b1.get_int:" << b1.get_int() << "\n";
        cout << "i2:" << i2 << "  b2:" << b2 << "  b2.double:" << b2.rawdouble() << "  b2.get_int:" << b2.get_int() << "\n";
        assert(b1.is_int());
        assert(b2.is_int());
        assert(b1.get_int() == i1);
        assert(b2.get_int() == i2);
        Box b3 = b1 + b2;
        assert(b3.is_int());
        assert(b3.get_int() == i1 + i2);
    }

    for(int32_t i = 0; i < 1000; ++i) {
        const int32_t p1 = randint(), q1=randint(), p2 = randint(), q2=randint();
        const double d1 = (double)p1/(double)q1;
        const double d2 = (double)p2/(double)q2;
        const Box b1 = Box::mk_double(d1);
        const Box b2 = Box::mk_double(d2);
        cout << "d1: " << d1 << " | b1: " << b1 << "\n";
        cout << "d2 " << d2 << " | b2: " << b2 << "\n";
        assert(b1.isdouble());
        assert(b2.isdouble());

        assert(b1.get_double() == d1);
        assert(b2.get_double() == d2);;
        Box b3 = b1 + b2;
        assert(b3.isdouble());
        assert(b3.get_double() == d1 + d2);
    }
    return 0;
}
```



# Offline Documentation

I'm collecting sources of offline documentation, because my internet
has been quite unstable lately due to the monsoon. I realized that when it
came to C, I would always `man malloc`, or `apropos exit` to recall
the `calloc` API, or to learn about `atexit`. I wanted to get offline docs
for all the languages I use, so I'm building a list:

- C: man pages
- [C++: cppman](https://github.com/aitjcize/cppman)
- [C++: synth](https://github.com/Oberon00/synth)
- [python: pydoc](https://docs.python.org/3/library/pydoc.html)
- haskell: haddock


# Using Gurobi

I've been trying to learn how to use Gurobi, the industrial strength 
solver for linear and quadratic equation systems.

- [compile the C+ bindings](https://stackoverflow.com/questions/46779850/cannot-compile-gurobi-examples-in-version-7-5-1)

```text
$ cd /path/to/gurobi90/linux64/src/build/ && make
```

# [osqp: convex optimizer in 6000 LoC](osqp-an-industrial-strength-convex-optimizer-in-6000-loc)

- [Here's the github link to their repo](https://github.com/oxfordcontrol/osqp)

It's written by heavyweights like Boyd himself, the author of the famous
convex optmization textbook and course.


```
╰─$ cloc .
     343 text files.
     329 unique files.
     163 files ignored.
---------------------
Language         code
---------------------
C                6483
C/C++ Header     3215
CMake            1930
make             1506
Python            701
C++               496
JSON              232
Markdown          213
Bourne Shell      186
DOS Batch         140
CSS               121
YAML              105
HTML               19
---------------------
SUM:            15347
---------------------
```


I find it amazing that all of the code lives in around 6500 lines. They're
supposedly industrial strength, and can handle large problems. Reading this
code should provide a lot of insight into how to write good convex optimizers!
I would love to take a course which explains the source code.


# stars and bars by generating functions

Say I have `C` colors of objects, and `S` slots to put these objects in. In
how manys can I put objects into slots, without regard to order? For example,
say we have 4 colors `c, m, y, k` and `2` slots `_ _`. The number of colorings
that I want to count is:

```
cc cm cy ck
mc mm my mk
yc ym yy yk
kc km ky kk
```

Everything coloring on the lower diagonal (say, `mc`) is equivalent to one on
the upper diagonal (`cm`). So in total, there are 10 colorings:

```
cc cm cy ck
*  mm my mk
*  *  yy yk
*  *  *  kk
```

One can solve this using stars-and-bars. Take the number of slots `S` to be the
number of stars. Take the number of colors `C` to be the number of bars. The
answer to the stars-and-basrs is the same as the coloring question.

I don't like stars and bars for this, because it seems to force an ordering of
the colors `c1 < c2 < .. < cn`. [which bar cooresponds to which color]. Is
there some way to not have to do this?

Is there some other way to show the `(n + k - 1)Ck` without imposing this
ordering, or some other way to count this quantity?

One other way you can look at this is using multinomial expansion, but its
computation is slightly more involved. Its advantage is that it ignores
ordering of the objects, which is what you desire.

In this case, we represent each color as the polynomial 1 + x + x^2, here the
power of x represents the number of instances you are taking of that color. 

So, if you take (1 + x + x^2)^4, you have found the number of ways to arrange
four colors, for different numbers of slots. If you take coefficient of x^2
from that polynomial, you get the answer to your question 

Why does this set of shady manipulations not work?


```
answer = coeff. of x^2 in (1 + x + x^2)^4
[We can add higher powers, won't change coeff of x^2]
answer = coeff. of x^2 in (1 + x + x^2 + x^3)^4
answer = coeff. of x^2 in (1 + x + x^2 + ...)^4
answer = coeff. of x^2 in (1/(1-x))^4

Call f(x) = (1/(1-x))^4
f(x) =taylor= f(0) + f'(x) x + f''(0) x^2/2 + f'''(0) x^3 / 6 + ...

1/(1-x)^4 =taylor= ... + (1/(1-x)^4)''(0) x^2/2 + ...

so:

answer = coeff. of x^2 in ... + (1/(1-x)^4)''(0) x^2/2 + ...
```

Now compute `(1/(1-x)^4)''` evaluated at `0` and divide
by `2`. This gives:


```
(1/(1-x)^4)'' (0)
= (-4/(1-x)^5)' (0)
= (20/(1-x)^6) (0)
= (20/(1-0)^6)
= (20)
```

so we get the answer as `answer = 20/2! = 10`. 

# This is not a place of honor

- [Long term nuclear waste](https://en.wikipedia.org/wiki/Long-time_nuclear_waste_warning_messages)

# Topological proof of infinitude of primes

- [On an exotic topology of the integers](https://arxiv.org/pdf/1008.0713.pdf)

We take the topological proof and try to view it from the topology as
semidecidability perspective.

- Choose a basis for the topology as the basic open sets
  $S(a, b) = \{ a n + b : n \in \mathbb Z \} = \{ mathbb Z + b \}$.
  This set is indeed semi-decidable. Given a number $k$, I can check if
  $(k - b) % a == 0$. So this is our basic decidability test.
- By definition, $\emptyset$ is open, and $\mathbb Z = S(1, 0)$. Thus it is
  a valid basis for the topology. Generate a topology from this. So we are
  composing machines that can check in parallel if for *some* $i$,
  $(k - b[i]) % a[i] == 0$ for some index.
- The basis $S(a, b)$ is clopen, hence the theory is decidable.
- Every number other than the units $\{+1, -1\}$ is a multiple of
  a prime.
- Hence, $\mathbb Z \setminus \{ -1, +1 \} = \cup_{p \text{prime}} S(p, 0)$.
- Since there a finite number of primes [for contradiction], the right hand side
  must be must be closed.
- The complement of $\mathbb Z \setminus \{ -1, +1 \}$ is $\{ -1, +1 \}$. This
  set cannot be open, because it cannot be written as the union
  of sets of the form $\{ a n + b \}$: any such union would have infinitely
  many elements. Hence, $\mathbb Z \setminus \{ -1, +1 \}$ cannot be closed.


# Burnside Theorem


For a finite group $G$ acting on a set $X$, burnside's lemma equates
(i) the number of equivalence classes of $X$ under $G$'s action,
that is, the number of orbits of $X$ with (ii) the average number
of stabilized elements for each $g \in G$. Formally, it asserts:

$$
|Orb(X, G)| = 1/|G|\sum_{g \in G} |Stab(g)|
$$

#### As local/global principle

See that the right-hand-side measures "local fixed points" in terms of $|Stab(g)|$.
The left hand side measures "global fixed points": an orbit $O \subseteq X$
is a set such that $G \cdot O = O$. So it's a sort of "global fixed point of $G$".

The burnside lemms tells us that we can recover the size of the set of
global fixed points (the number of orbits) by averaging the size of the set
of local fixed points (the average of the sizes of the stabilizers).

#### As space/time average

The left hand size is a time average: If we consider $X, GX, \dots G^{n}X$,
we will finally be left with the images as the orbits. All other elements
would have been ``smashed together''.

On the right hand side, we are averaging the group over space. Yes,
but how does one perform averaging? One needs to have a measure! 

#### A rephrasing in terms of integrators

Consider a system of a particle in a well. We consider two energy levels:
that with `E = 0`, and `E = 1`. This gives us the following five
states:

<img src="./static/burnside/setup.png" >

now I want to simulate this system, like a good computer scientist. So let's
write the stupdiest one possible, `Δ0`, that doesn't simulate anything
at all, and `Δ+1`, which steps the system forward by a single step.
These look like this:


<img src="./static/burnside/simulation-1.png" >

But why only these? Why privilege these time-scales? We should at least
have `Δ-1`, for the arrow of time is fiction:
<img src="./static/burnside/intergrator-minus-1.png">

We should also have coarser integrators. Hence we contemplate `Δ+2` and `Δ-2`.
Turns out these are equivalent:

<img src="./static/burnside/integrator-plus-2-minus-2.png">


We can also consider `Δ + 3`. We also see that `Δ + 4 = Δ`:
<img src="./static/burnside/integrator-3-4.png">


So in conclusion, the calculation gives us:

<img src="./static/burnside/conclusion.png" >


# The Ise Grand shrine

> The shrine buildings at Naikū and Gekū, as well as the Uji Bridge, are
> rebuilt every 20 years as a part of the Shinto belief of the death and
> renewal of nature and the impermanence of all things and as a way of passing
> building techniques from one generation to the next.

I really enjoy this philosophy. I feel I should reflect on this, and update
how I think about, say, code rewrites, and pouring billions into new
supercolliders simply to keep the knowledge of how to build it alive.


> The shrine has evolved throughout the years in its reconstruction, while
> maintaining some of its key features. The shrine was not originally
> constructed with gold copper adornments, however, because of advancements in
> technology as well as Buddhist influence, it gained them over the years.


# Edward Kmett's list of useful math

- I use Bayesian statistics constantly for probabilistic programming and neural
  networks. Calculus gave me access to understand automatic differentiation,
  which gets used in everything I do. Real analysis doesn't come up often, but
  intermediate value thm. style arguments are handy.
- I don't use classic geometry, but I when I was doing graphics I used projective
  geometry, and that served as a gateway to understand category theory's duality
  principle, and I use category theory to organize most of the code I write.

- I took one course on differential geometry. The knowledge I gained from it
  probably led to about half of my income to date. I've made a career out of
  weaponizing "obscure" math, e.g. using toric varieties of rational functions of
  Zhegalkin polynomials to schedule instructions...
- Differential equations? Physics? Well, I use Hamiltonian methods for most of
  the sampling I do in the world of probabilistic programming. So understanding
  symplectic integrators is a big step, and I have to move frictionless particles
  subject to a Hamiltonian, so there's diff eq.
- Fourier analysis, heat equations? Well, if I want to approximate a
  space/distribution, http://ddg.math.uni-goettingen.de/pub/GeodesicsInHeat.pdf
- Learning group theory "bottom up" from monoids and the like has been useful,
  because I use monoids basically everywhere as a functional programmer to
  aggregate data. It led to the work I did at S&P Capital IQ, and later to
  basically my entire niche as a functional programmer.
- But understanding more of the surrounding landscape has been useful as well, as
  I use all sorts of lattices and order theory when working with propagators. And
  I use regular and inverse semigroups (note, not groups!) when working with all
  sorts of fast parsing techniques.
- Complex analysis? Understanding Moebius transformations means I can understand
  how continued fractions work, which leads to models for computable reals that
  don't waste computation and are optimally lazy. Knowing analytic functions lets
  me understand complex step differentiation.
- Linear algebra is in everything I've done since highschool. Learning a bit of
  geometric algebra, and playing around with Plucker coordinates led to me
  licensing tech to old game companies for computational visibility back before
  it was a "solved" problem.
- Wandering back a bit, Gröbner bases wind up being useful for comparing circuits
  modulo 'don't care' bits for impossible situations, and all sorts of other
  simplification tasks.
- Let's go obscure. Pade approximants? Good rational approximations, not
  polynomial ones. Sounds academic, but computing exp and log is expensive, and
  fast rational approximations can be conservative, monotone and have nice
  derivatives, speeding NN-like designs a lot.
- Weird number systems => Data structures.  Category theory acts as a rosetta
  stone for so many other areas of math it isn't even funny. You can understand
  almost all of the essential bits of quantum computing just knowing by category
  theory.
- Logic. Well, which logic? You run into a modal logic in a philosophy class
  some time and think of it as a clever hack, but monads in FP are basically a
  modality. Modal logics for necessity/possibility model effect systems well.
  Substructural logics to manage resource usage...
- I don't use a lot of number theory. There. Mind you, this is also one of those
  areas where I'm just standing on weak foundations, so I don't know what I
  don't know. I just know it's hard to do all sorts of things that sound easy
  and try to muddle through w/ my limited background.


# Cokernel is not sheafy

I wanted to understand why the Cokernel is not a sheafy condition.
I found an [explanation in Ravi Vakil's homework solutions](https://math.mit.edu/~mckernan/Teaching/07-08/Spring/18.726/model2.pdf)
which I am expanding on here.

#### Core idea

We will show that there will be an exact sequence which is surjective
at each stalk, but not globally surjective. So, locally, we wil have
trivial cokernel, but globally, we will have non-trivial cokernel.

#### Exponential sheaf sequence


$$
\begin{aligned}
0  
\rightarrow 2\pi i \mathbb Z 
\xrightarrow{\alpha: \texttt{incl}} \mathfrak O 
\xrightarrow{\beta:exp(\cdot)} \mathfrak O^* 
\rightarrow 0
\end{aligned}
$$

- $\mathfrak O$ is the sheaf of the additive group of holomorphic functions. 
  $\mathfrak O^*$ is the sheaf of the group of non-zero holomorphic functions. 
- $\alpha$, which embeds $2\pi n \in 2\pi i \mathbb Z$ as a constant function $f_n(\cdot) \equiv  2 \pi i n$ is
  injective.
- $\beta(\alpha(n)) = e^{2 \pi i n} = 1$. So we have that the composition of the two maps $\beta \circ \alpha$ is
  the zero map (multiplicative zero), mapping everything in $2\pi i \mathbb Z$ to the identity of $\mathfrak O^*$.
  Thus, `d^2 = 0`, ensuring that this is an exact sequence.
- Let us consider the local situation. At each point `p`, we want to show
  that $\beta$ is surjective. Pick any $g \in \mathfrak O^*_p$. We have an open neighbourhood $U_g$
  where $g \neq 0$, since continuous functions are locally invertible.
  Take the logarithm of $g$ to pull back $g \in O^*_p$ to $\log g \in O_p$.
  Thus, $\beta: O \rightarrow O^p$ is surjective at each local point $p$, since every element 
  has a preimage.
- On the other hand, the function $h(z) \equiv z$ cannot be in $O^*$ If it were,
  then there exists a homolorphic function called $l \in O$ [for $\log$] such that
  $\exp(l(z)) = h(z) = z$ everywhere on the complex plane. 
- Assume such a function exists. Then it must be the case that
  $d/dz exp(l(z)) = d/dz(z) = 1$. Thus, $exp(l(z)) l'(z) = z l'(z) = 1$
  [use the fact that $exp(l(z)) = z$]. This means that $l'(z) = 1/z$.
- Now, by integrating in a closed loop of $e^{i \theta}$. we have $\oint l'(z) = l(1) - l(1) = 0$.
- We also have that $\oint l'(z) = \oint 1/z = 2\pi i$.
- This implies that $0 = 2\pi i$ which is absurd.
- Hence, we cannot have a function whose exponential gives $h(z) = z$ everywhere.
- Thus, the cokernel is nontrivial globally.


# Von neumann: foundations of QM

- I wanted to understand what von neumann actually did when he
  "made QM rigorous", what was missing, and why we need $C^\star$ algebras for
  quantum mechanics, or even "rigged hilbert spaces".
- I decided to read Von Neumann: Mathematical foundations of quantum mechanics.
- It seems he provides a rigorous footing for QM, without any dirac
  deltas. In particular, he proves the Reisez representation theorem,
  allow for transforming bras to kets and vice versa. On the other hand,
  it does not allow for dirac delta as bras and kets.
- The document [The role of rigged hilbert spaces in QM](https://arxiv.org/pdf/quant-ph/0502053.pdf)
  provides a gentle introduction on how to add in dirac deltas. 
- Rigged hilbert spaces (by Gelfand) combine the theory of distributions
  (by Schwartz), developed to make dirac deltas formal, and the theory of
  hilbert spaces (by Von Neumann) developed to make quantum mechanics formal.
- To be even more abstract, we can move to $C^\star$ algebras, which allow
  us to make QFT rigorous.
- So it seems that in total, to be able to write, say, a "rigorous shankar"
  textbook, one should follow Chapter 2 of Von Neumann, continuing with the
  next document which lays out how to rig a hilbert space.
- At this point, one has enough mathematical machinery to mathematize all of
  Shankar.

#### References

- Von neumann: Mathematical foundations of quantum mechanics.
- [The role of rigged hilbert spaces in QM](https://arxiv.org/pdf/quant-ph/0502053.pdf)

# Discrete schild's ladder

If one is given a finite graph $(V, E)$, which we are guaranteed came
from discretizing a grid, can we recover a global sense of orientation?

- More formally, assume the grid was of dimensions $W \times H$. So we have
  the vertex set as $V \equiv \{ (w, h) 1 \leq w \leq W, 1 \leq h \leq H \}$.
  We have in the edge set all elements of the form $((w, h), (w \pm 1, h \pm 1))$
  as long as respective elements $(w, h)$ and $(w \pm 1, h \pm 1)$ belong to $V$.

- We lose the information about the grid as comprising of elements of the
  form $(w, h)$. That is, we are no longer allowed to "look inside". All we
  have is a pile of vertices and edges $V, E$.

- Can we somehow "re-label" the edges $e \in E$ as "north", "south", "east",
  and "west" to regain a sense of orientation?

- Yes. Start with some corner. Such a corner vertex will have degree 2. Now,
  walk "along the edge", by going from a vertex of degree 2 to an neighbour
  of degree 2. If we finally reach a vertex that has unexplored 
  neighbours of degree 3 or 4, pick the neighbour of degree 3. This will give
  us "some edge" of the original rectangle.

- We now arbitrary declare this edge to be the North-South edge. We now need
  to build the perpendicular East-West edge.

- This entire construction is very reminisecent of
  [Schild's Ladder](https://en.wikipedia.org/wiki/Schild%27s_ladder)


# Derivative of step is dirac delta

I learnt of the "distributional derivative" today from my friend, Mahathi.
Recording this here.

#### The theory of distributions

As far as I understand, in the theory of distributions, A distribution
is simply a linear functional $F: (\mathbb R \rightarrow \mathbb R) \rightarrow \mathbb R$.
The two distributions we will focus on today are:
- The step distribution, $step(f) \equiv \int_0^\infty f(x) dx$
- The dirac delta distribution, $\delta(f) = f(0)$.
- Notationally, we write $D(f)$ where $D$ is a distribution, $f$ is a function as
 $\int D(x) f(x) dx$.
- We can regard any function as a distribution, by sending $f$ to $F(g) \equiv \int f(x) g(x) dx$.
- But it also lets us cook up "functions" like the dirac delta which cannot actually
  exist as a function. So we move to the wider world of distributions

#### Derivative of a distribution

Recall that notationally, we wrote $D(f)$ as $\int D(x)f(x) dx$. We now want
a good definition of the derivative of the distribution, $D'$. How? well,
use chain rule!

$$
\begin{aligned}
&\int_0^\infty U dV = [UV]|_0^\infty - \int_0^\infty V dU \\
&\int_0^\infty f(x) D'(x)  dx \\
&= [f(x) D(x)]|_0^\infty - \int_0^\infty D f'(x)
\end{aligned}
$$



Here, we assume that $f(\infty) = 0$, ahd that $f$ is differentiable at $0$.
This is because we only allow ourselves to feed into these distribtions
certain classes of functions (test functions), which are "nice". The test
functions $f$ (a) decay at infinity, and (b) are smooth.

The derivation is:

$$
\begin{aligned}
&\int_0^\infty U dV = \int_0^\infty f(x) \delta(x) = f(0) \\
&[UV]|_0^\infty - \int_0^\infty V dU = [f(x) step(x)]|_0^\infty - \int_0^\infty step(x) f'(x) \\
&= [f(\infty)step(\infty) - f(0)step(0)] - step(f') \\
&= [0 - 0] - (\int_0^\infty f'(x) dx) \\
&= 0 - (f(\infty) - f(0)) \\
&= 0 - (0 - f(0)) \\
&= f(0)
\end{aligned}
$$

- Thus, the derivative of the step distribution is the dirac delta distribution.

# Extended euclidian algorithm

#### Original definition 

I feel like I only understand the extended euclidian algorithm algebraically,
so I've been trying to understand it from other perspectives. Note that
we want to find $gcd(p, p')$. WLOG, we assume that $p > p'$.
We now find a coefficient $d$ such that $p = d p' + r$ where $0  \leq r < p'$.
At this stage, we need to repeat the algorithm to find $gcd(p', r)$. We
stop with the base case $gcd(p', 0) = p'$. 

#### My choice of notation

I dislike the differentiation that occurs between $p$, $p'$, and $r$
in the notation. I will notate this as $gcd(p_0, p_1)$. WLOG, assume
that $p_0 > p_1$. We now find a coefficient $d_0$ such that $p_0 = p_1 d_1 + p_2$
such that $0 \leq p_2 < p_1$. At this stage, we recurse to find 
$gcd(p_1, p_2)$. We stop with the base case $gcd(p_{n-1}, p_n) = p_n$ iff
$p_{n-1} = d_n p_n + 0$. That is, when we have $p_{n+1} = 0$, we stop
with the process, taking the gcd to be $p_n$.

#### Matrices

We can write the equation $p_0 = p_1 d_1 + p_2$ as the equation
$p_0 = [d_1; 1] [p_1;  p_2]^T$. But now, we have lost some state. We used
to have both $p_1$ and $p_2$, but we are left with $p_0$. We should always
strive to have "matching" inputs and output so we can iterate maps. This
leads us to the natural generalization:

$$
\begin{bmatrix} p_0 \\ p_1 \end{bmatrix} = 
\begin{bmatrix}
d_1  & 1 \\ 1 & 0 
\end{bmatrix}
\begin{bmatrix} p_1 \\ p_2 \end{bmatrix}
$$

So at the first step, we are trying to find a $(d_1, p_2)$ such that the
matrix equation holds, and $0 \leq p_2 < d_1$.

#### Extended euclidian division

When we finish, we have that $gcd(p_{n-1}, p_n) = p_n$. I'll call the GCD
as $g$ for clarity. We can now write the GCD as a linear combination
of the inputs $g = p_n = 0 \cdot p_{n-1} + 1 \cdot p_n$. We now
want to backtrack to find out how to write $g = \omega_{n-2} p_{n-2} + \omega_{n-1} p_{n-1}$.
And so on, all the way to $g = \omega_0 p_0 + \omega_1 p_1$.


- We can begin with the general case:

$$
g = 
\begin{bmatrix} \omega' & \omega'' \end{bmatrix}
\begin{bmatrix} p' \\ p'' \end{bmatrix}
$$

- We have the relationship:

$$
\begin{bmatrix} p \\ p' \end{bmatrix} = 
\begin{bmatrix}
d'  & 1 \\ 1 & 0 
\end{bmatrix}
\begin{bmatrix} p' \\ p'' \end{bmatrix}
$$

- We can invert the matrix to get:


$$
\begin{bmatrix} p' \\ p'' \end{bmatrix} = 
\begin{bmatrix}
0  & 1 \\ 1 & - d' 
\end{bmatrix}
\begin{bmatrix} p \\ p' \end{bmatrix}
$$

- now combine with the previous equation to get:

$$
\begin{aligned}
&g = 
\begin{bmatrix} \omega' & \omega'' \end{bmatrix}
\begin{bmatrix} p' \\ p'' \end{bmatrix} \\
&g = 
\begin{bmatrix} \omega' & \omega'' \end{bmatrix}
\begin{bmatrix}
0  & 1 \\ 1 & - d' 
\end{bmatrix}
\begin{bmatrix} p \\ p' \end{bmatrix} \\
&g = 
\begin{bmatrix} \omega'' & \omega - d' \omega'  \end{bmatrix}
\begin{bmatrix} p \\ p' \end{bmatrix} \\

\end{aligned}
$$

#### Fractions

- GCD factorization equation: $p/p' = (\alpha p' + p'')/p' = \alpha + p''/p'$.
- Bezout equation: $\omega' p' + \omega'' p'' = g$.
- Bezout equation as fractions $\omega' + \omega'' p''/p' = g/p'$.


# In a PID, all prime ideals are maximal, geometrically

Assume $R$ is Noetherian.
 
- By [Krull's principal ideal theorem](https://en.wikipedia.org/wiki/Krull%27s_principal_ideal_theorem),
  we have that given a principal ideal $I = (\alpha)$, all minimal prime
  ideals $\mathfrak p$ above $I$ has height at most 1.

- Recall that a minimal prime ideal $\mathfrak p$ lying over an ideal $I$
  is the minimal among all prime ideals containing $I$. That is, if
  $I \subseteq \mathfrak q \subseteq \mathfrak p$, then $\mathfrak q = I$
  or $\mathfrak q= \mathfrak p$.

- In our case, we have that $R$ is a PID. We are trying to show that all prime
  ideals are maximal. Consider a prime ideal $\mathfrak p \subseteq R$.
  It is a principal ideal since $R$ is a PID. It is also
  a minimal prime ideal since it contains itself. Thus by Krull's PID 
  theorem, has height at most one.
- If the prime ideal is the zero ideal ($\mathfrak p = 0$),
  then it has height zero.
- If it is any other prime ideal $(\mathfrak p \neq (0))$, then it has height
  at least 1, since there is the chain $(0) \subsetneq \mathfrak p$. Thus
  by Krull's PID theorem, it has height exactly one.
- So all the prime ideals other than the zero ideal, that is, all the points
  of $Spec(R)$ have height 1.
- Thus, every point of $Spec(R)$ is maximal, as there are no "higher points"
  that cover them.
- Hence, in a PID, every prime ideal is maximal.

In a drawing, it would look like this:

```
NO IDEALS ABOVE  : height 2
(p0)  (p1) (p2)  : height 1
      (0)        : height 0
```

So each `pi` is maximal.

This is a geometric way of noting that in a principal ideal domain, prime
ideals are maximal.

#### References

- [Andreas Gathmann's notes](https://www.mathematik.uni-kl.de/~gathmann/class/commalg-2013/commalg-2013-c11.pdf)

# Prime numbers as maximal among principal ideals

I learnt of this characterization from benedict gross's lectures, [lecture 31](https://www.youtube.com/watch?v=l1OWAasmBLI&list=PLelIK3uylPMGzHBuR3hLMHrYfMqWWsmx5&index=31).

We usually define a number $p \in R$ as prime iff the ideal generated by
$p$, $(p)$ is prime. Formally, for all $a, b \in R$, if 
$ab \in (p)$ then $a \in (p)$ or $b \in (p)$.

This can be thought of as saying that among all principal ideals, the
ideal $(p)$ is maximal: no other principal ideal $(a)$ contains it.

#### Element based proof

- So we are saying that if $(p) \subseteq (a)$ then either $(p) = (a)$
- Since $(p) \subseteq (a)$ we can write $p = ar$. Since $(p)$ is prime,
  and $ar = p \in (p)$, we have that either $a \in (p) \lor r \in (p)$.
- Case 1: If $a \in (p)$ then we get $(a) \subseteq (p)$. 
  This gives $(a) \subseteq (p) \subseteq (a)$,
  or $(a) = (p)$.
- Case 2: Hence, we assume $a \not \in (p)$, and $r \in (p)$.
  Since $r \in (p)$, we can write $r = r'p$ for some $r' \in R$.
  This gives us $p = ar$ and $p = a(r'p)$. Hence $ar' = 1$. Thus $a$
  is a unit, therefore $(a) = R$.


# Axiom of Choice and Zorn's Lemma

I have not seen this "style" of proof before of AoC/Zorn's lemma
by thinking of partial functions $(A \rightarrow B)$ as monotone functions                                 
on $(A \cup \bot \rightarrow B)$.

#### Zorn's Lemma implies Axiom of Choice

If we are given Zorn's lemma and the set $A_i$, to build a choice 
function, we consider the collection of functions $(f: \prod_i A_i \rightarrow \rightarrow A_i \cup \bot)$
such that either $f(A_i) = \bot$ or $f(A_i) \in A_i$. This can be endowed with
a partial order / join semilattice structure using the "flat" lattice, where
$\bot < x$ for all $x$, and $\bot \sqcup x = x$.

For every chain of functions, we have a least upper bound, since a chain
of functions is basically a collection of functions $f_i$ where each function
$f_{i+1}$ is "more defined" than $f_i$. 

Hence we can always get a maximal element $F$, which has a value defined
at _each_ $F(A_i)$. Otherwise, if we have $F(A_i) = \bot$, the element
is not maximal, since it is dominated by a larger function which is defined
at $A_i$.

Hence, we've constructed a choice function by applying Zorn's Lemma. 
Thus, Zorn's Lemma implies Axiom of Choice.


# Local ring in terms of invertibility

Recall that a local ring $R$ is a ring with a unique maximal ideal $M$.
This is supposedly equivalent to the definition:

> A local ring is a ring $R$ such that $1 \neq 0$ and for all $x, y$ in $R$,
> $x + y \text{ invertible} \implies x \text{ invertible} \lor y \text{ invertible}$



#### Stepping stone: If $(R, M)$ is a local ring then set of all units of $R$ is equal to $R - M$

##### All elements of $(R - M)$ are units:

- Let $R$ be a local ring with unique maximal ideal $M$.
- Let $u \in R - M$. [$u$ for unit].
- If $u$ is a unit, we are done. 
- Otherwise, consider the ideal generated by $u$, $(u)$. 
- $(u)$ must live in some maximal ideal. Since 
- $M$ is the only maximal ideal, we have that $u \in (u) \subseteq M$. 
- This is a contradiction, since $u$ cannot be both in $M$ and $R - M$.
- Hence all elements $u \in R - M$ are units.

##### All units are in $(R - M)$:

- Let $u$ a unit.
- We cannot have $u \in M$ since $M$ is a maximal ideal, $M \neq R$. 
- If $u \in M$ then $u^{-1} u = 1 \in M$, hence $M = R$.
- Contradiction.

#### Part 1: Local ring to to invertible:

- Let $R$ have a unique maximal ideal $M$.
- We have already shown that all invertible elements are in $R - M$.
- Hence if $x + y$ is invertible, it belongs to $R - M$. 
- We must have either $x$ or $y$ invertible. 
- Suppose not: $x, y \in M$ while $x + y \not \in M$. 
- This is impossible because $M$ is an ideal and is thus closed under addition.
- So, we must have that if $x + y$ is invertible then either $x$ or $y$ is invertible.

#### Part 2: Invertible to Local ring.

- Let $R$ be a ring such that if $x + y$ is invertible then either $x$ or $y$ is invertible.
- Conversely, if neither $x$ nor $y$ are invertible then $x + y$ is not invertible.
- Hence the set of non-invertible elements form an ideal $I$, as $0 \in I$, sum of
  non-invertibles are not invertible (assumption),
  product of non-invertibles is not invertible (easy proof).
- This ideal $I$ is contained in some maximal ideal $M$.
- This maximal ideal $M$ is such that every element in $R - M$ is invertible,
  since all the non-invertible elements were in $I$ from which $M$ was built.
- Formally, assume not: Some element $s \in R - M$ is not invertible. Then $s \in I \subseteq M$.
  This contradicts assumption that $s \in R - M$.
- Hence $M$ is a unique maximal ideal and $R$ is a local ring.

#### References

- [Using the internal language of toposes in algebraic geometry](https://rawgit.com/iblech/internal-methods/master/notes.pdf)

# Nullstellensatz for schemes

#### System of equations

Consider a set of polynomials $\{F_1, F_2, \dots F_m\}$ subset $K[T_1, \dots, T_n]$.
A system of equations $X$ for unknowns $T$ is the tuple 
$(K[T_1, \dots, T_n], \{ F_1, F_2, \dots F_m \} \subset K[T_1, \dots, T_n])$.
We abbreviate this to $(K[\mathbf T], \mathbf F)$ where the bolded version
implies that these are vectors of values.

#### Solutions to system of equations

Note that we often define equations, for example $x^2 + 1 = 0$ over a ring
such as $\mathbb Z$. But its solutions live elsewhere: In this case, the solutions
live in $\mathbb C$, as well as in $\mathbb Z/2Z$. Hence, we should not restrict
our solution space to be the ring where we defined our coefficients from!


Rather, as long as we are able to _interpret_ the polynomial $f \in K[\mathbf T]$
in some other ring $A$, we can look for solutions in the ring $A$. Some thought
will tell us that all we need is a ring homomorphism $\phi: K \rightarrow L$.
Alternatively/equivalently, [we need $L$ to be a $K$-algebra](https://math.stackexchange.com/questions/3756749/an-a-algebra-b-carries-the-same-data-as-a-ring-map-a-rightarrow-b).


Let us consider the single-variable case with $K[T]$. This naturally
extends to the multivariate case. 
Using $\phi$, we can map $f \in K[T]$ to $\phi(f) \in L[T]$ by taking
$f = \sum_i k_i T^i$ to $\phi(f) = \sum_i \phi(k_i) T^i$. This clearly extends
to the multivariate case. Thus, we can interpret solutions $l \in L$ to an equation
$f \in K[T]$  as $f(l) = \sum_i \phi(k_i) l^i$.


Formally, the solution to a system $X \equiv (K[\mathbf T], \mathbf F)$
in ring $L$, written as $Sol(X, L)$ is a set of elements $ls \subseteq L$
such that $F_i(l) = 0$ for all $l$ in $ls$ and for all $F_i$ in $\mathbf F$.


#### Equivalent systems of equations

Two systems of equations $X, Y$ over the **same ring $K$** are said to be
equivalent over $K$ iff for all $K$-algebras $L$, we have
$Sol(X, L) = Sol(Y, L)$.

#### Biggest system of equations

For a given system of equations $X \equiv (K[\mathbf T], \mathbf F)$ over the ring $K$,
we can generate the largest system of equations that still has the same solution: 
generate the ideal $\mathbf F' = (\mathbf F)$, and consider the system
of equations $X' \equiv (K[\mathbf T], \mathbf F' = (\mathbf F) )$.

#### Varieties and coordinate rings

Let $g \in K[T_1, \dots T_n]$. The polynomial is also a function which maps
$\mathbf x \in K^n$ to $K$ through evaluation $g(\mathbf x)$.


Let us have a variety $V \subseteq k^n$ defined by some set of polynomials
$\mathbf F \in K[T_1, \dots, T_n]$. So the variety is the vanishing set of $\mathbf F$,
and $\mathbf F$ is the **largest** such set of polynomials.

Now, two functions $g, h \in K[T_1, \dots, T_n]$ are equal on the variety $V$
iff they differ by a function $z$ whose value is zero on the variety $V$. Said
differently, we have that $g|V = h|V$ iff $h - g = z$ where $z$ vanishes on $V$.
We know that the polynomials in $\mathbf F$ vanish on $V$, and is the
largest set to do so. Hence we have that $z \in \mathbf F$.

To wrap up, we have that two functions $g, h$ are equal on $V$, that is,
$g|V = h|V$ iff $g - h \in \mathbf F$.

So we can choose to build a ring where $g, h$ are "the same function". We do
this by considering the ring $K[V] \equiv K[T_1, \dots, T_n] / \mathbf F$.
This ring $K[V]$ is called as the **coordinate ring of the variety $V$**.


#### An aside: why is it called the "coordinate ring"?

We can consider the ith coordinate function as one that takes $K[T_1, \dots, T_n]$ to $T_i$
So we have $\phi_i \equiv T_i \in K[T_1, \dots, T_n]$ which defines a function
$\phi_i: K^n \rightarrow K$ which extracts the $i$th coordinate. 

Now the quotienting from the variety to build $K[V]$, the coordinate ring
of the variety $V$ will make sure to "modulo out" the coordinates that
"do not matter" on the variety.

#### Notation for coordinate ring of solutions: $Coord(X)$

For a system $X \equiv (K[\mathbf T], \mathbf F)$, we are interested in the
solutions to $\mathbf F$, which forms a variety $V(\mathbf F)$. Furthermore,
we are interested in the algebra of this variety, so we wish to talk about
the coordinate ring $k[V(\mathbf F)] = K[\mathbf T] / (\mathbf F)$. We will
denote the ring $k[\mathbf T] / (\mathbf F)$ as $Coord(X)$.

#### Solutions for $X$ in $L$: $K$-algebra morphisms $Coord(X) \rightarrow L$
Let's simplify to the single variable case. Multivariate
follows similarly by recursing on the single
variable case. $X \equiv (K[T], \mathbf F \subseteq K[T])$.

There is a one-to-one coorespondence between solutions to $X$ in $L$ and
elements in $Hom_K(Coord(X), L)$ where $Hom_K$ is the set of $K$-algebra
morphisms.

Expanding definitions, we need to establish a correspondence between
- Points $l \in L$ such that $eval_l(f) = 0$ for all $f \in F$.
- Morphisms $K[T] / (\mathbf F) \rightarrow L$.

##### Forward: Solution to morphism

A solution for $X$ in $L$ is a point $\mathbf l \in L$ such that $F$
vanishes on $l$. Thus, the evaluation map $eval[l]: K[T] \rightarrow L$
has kernel $(\mathbf F)$. Hence, $eval[l]$ forms an honest to god morphism
between $K[T] / (\mathbf F)$ and $L$.


##### Backward: morphism to solution

Assume we are given a morphism $\phi: Coord(X) \rightarrow L$. Expanding
definitions, this means that $\phi: K[T]/ (\mathbf F) \rightarrow L$.
We need to build a solution. We build the solution $l\star = \phi(T)$.

Intuitively, we are thinking of $\phi$ as $eval[l\star]$.
If we had an $eval[l\star]$, then we would learn the point $l\star \in L$
by looking at $eval[l\star](T)$, since $eval[l\star](T) = l\star$.


We can show that this point exists in the solution as follows:
$$
\begin{aligned}
&eval[l\star](f) = \sum_i a_i (l\star)^i \\
&= \sum_i a_i \phi(T)^i \\
&\text{Since $\phi$ is ring homomorphism:} \\ 
&= \sum_i a_i \phi(T^i)  \\ 
&\text{Since $\phi$ is $k$-algebra homomorphism:} \\ 
&= \phi(\sum_i a_i T^i)  \\ 
&= \phi(f) \\
\text{Since $f \in ker(\phi)$:} \\ 
&= 0
\end{aligned}
$$

- [This is also asked by me on this `math.se` question](https://math.stackexchange.com/questions/3766418/proof-verification-bijection-between-solutions-to-a-system-of-equations-and-k-a)


#### Consistent and inconsistent system $X$ over ring $L$

Fix a $K$-algebra $L$. The system $X$ is **consistent** over $L$ iff
$Sol(X, L) \neq \emptyset$. the system $X$ over $L$ is **inconsistent** iff
If $Sol(X, L) = \emptyset$.


#### Geometric Language: Points

Let $K$ be the main ring, $X \equiv (K[T_1, \dots T_n], \mathbf F)$ a system of
equations in $n$ unknowns $T_1, \dots, T_n$.

For any $K$-algebra $L$, we consider the set $Sol(X, L)$ as a collection
of points in $L^n$. These points are solutions to the system $X$.


#### The points of $K$-algebra


#### References

- [Manin, theory of schemes](https://sites.icmc.usp.br/grossi/Sasha/galg/manin.pdf)
- [Notes coordinate rings of affine varieties](http://pi.math.cornell.edu/~dmehrle/notes/old/alggeo/34CoordinateRingonAffineVariety.pdf)
- [Why is this called the coordinate ring](https://math.stackexchange.com/questions/2397249/the-coordinate-ring-its-etymology)

# Perspectives on Yoneda

We can try to gain intuition for Yoneda by considering a finite category
where we view arrows as directed paths. 

The "interpretation" of a path is taken by going from edges to labels and then
concatenating all edge labels. We "interpret" the label `id_x` as `""` (the
empty string), and we "interpret" all other arrows `a` as some unique string
associated to each arrow. Composition of arrows becomes concatenation of
strings. This obeys all the axioms of a category. We are basically of a
category as a free monoid.


Let's being our consideration of the covariant functor `Hom(O, -): C → Set`.
Note that the objects of this category are **sets** of arrows `Hom(O, P)`.
To every arrow `a: P → Q` we associate the set function
`a': Hom(O, P) → Hom(O, Q)`. `a'(op) = pq . op`.

Now, to apply Yoneda, we need another covariant functor `G: S → Set`. We now
need to show that the set of natural transformations `η: F → G`  are in bijection
with the set `G[O] ∈ Set`.


We do this by the following consideration. Recall that for the natural transformation,
we have the commuting diagram:

```
x -p-> y

Hom(o, x) -p'-> Hom(o, y)
|                |
ηx               ηy
|                |
v                v
G[x] -G[p] --> G[y]
```

```
∀ x y ∈ C,
  o2x ∈ Hom(o, x),
  p ∈ Hom(x, y),
    G[p](ηx(o2x)) = ηy(p'(o2x))
```

Which on using the definition of `p'` becomes:

```
∀ x y ∈ C,
  o2x ∈ Hom(o, x),
  p ∈ Hom(x, y),
  G[p](ηx(o2x)) = ηy(o2x . p')
```

Now pick the magic `x = o` and `o2x = o2o = id_o`. This gives:

```
x = o, y ∈ C
o2x = id_o

∀ y ∈ C, 
  p ∈ Hom(o, y),
  G[p](ηo(id_o)) = ηy(id_o . p')
  G[p](ηo(id_o)) = ηy(p') [By identity arrow]
  [assume we fix ηo(id_o) ∈ G[o] ]
  ηy(p') = G[p](ηo(id_o)) [ηy is now forced.
                          everything on the RHS is known]
```

Hence, we learn how to map every other arrow `ηy(p)`. If we know how to map
the arrows, we can map the objects in the hom-sets as images of the arrows,
since we know what `ηo[id_o]` maps to. Concretely:

##### Images `ηo(q)` for `q ∈ Hom(o, o)` after `ηo(id_o)` is fixed:


We have the relation `id_o . q = q`. So we get that the arrow `q': Hom(o, o) → Hom(o, o)`
takes `id_o` to `q`. By the structure of the natural transformation, we have that:

```
∀ x y ∈ C,
  o2x ∈ Hom(o, x),
  p ∈ Hom(x, y),
    G[p](ηx(o2x)) = ηy(p'(o2x))
```

- Pick `x = y = o`, `o2x = id_o`, `p = q`. This gives:

```
    G[q](ηo(id_o)) = ηo(q'(id_o))
    G[q](ηo(id_o)) = ηo(q' . id_o)
    G[q](ηo(id_o)) = ηo(q')
    ηo(q') = G[q](ηo(id_o))
```

Hence, we've deduced `ηo(q')`, so we know what element `q` gets mapped to.
The same process works with _any_ arrow!

#### A shift in perspective: Yoneda as partial monoid.

Since we're considering the sets $Hom(o, -)$, note that we can always
pre-compose any element of $Hom(o, o)$ to every $Hom(o, p)$. More-over,
if we know the value of $id_o$, then we have the equation that $id_o \circ a = a$.
since $id_o$ is the identity. Moreover, $id_o$ is the **only** identity arrow
we possess across all $Hom(o, -)$: We can only access the identity arrow
inside $Hom(o, o)$. For all other $Hom(o, p)$ where $p \neq o$, we do
not have the identity arrow $id_o$ or $id_p$. So we have a sort of _partial monoid_,
where we have a unique identity element $id_o$, and arrows that compose _partially_
based on domain/codomain conditions.


From this perspective, we can read the commutative diagram laws as a sort
of "Cayley's theorem". We have as elements the elements of the set $Hom(o, -)$.
For every arrow $a: p \rightarrow q$, we have the action
$Hom(o, p) \xrightarrow{a} Hom(o, q)$.


From this perspective, it is trivial to see that:
- Every monoid can be embedded into its action space (Cayley's theorem).
- This mapping of yoneda from $Hom(o, -)$ to arbitrary sets is like a "forgetful"
  functor from a monoid into a semigroup.
- If our monoid is "well represented" by a semigroup, then once we know what
  the identity maps to, we can discover all of the other elements by using the
  relation $f(ex) = f(e) f(x)$. The only "arbitrariness" introduced by forgetting
  the monoid structure is the loss of the unique identity. **NOTE**: This is handwavy,
  since the data given by a natural transformation is somehow "different", in a way
  that I'm not sure how to make precise.

# Germs, Stalks, Sheaves of differentiable functions

I know some differential geometry, so I'll be casting sheaves in terms
of tangent spaces for my own benefit

- **Presheaf:** Data about restricting functions.
- **Germ:** Equivalence class of functions in the neighbourhood at a point,
  which become equivalent on restriction. Example: equivalence classes of curves with the same directional derivative.
- **Stalk:** An algebraic object worth of germs at a point.

Next, to be able to combine germs together, we need more.
- **Sheaf:** Adds data to a presheaf to glue functions.

#### A presheaf that is not a sheaf: Bounded functions

Consider the function $f(x) \equiv x$. This is bounded on every open interval
$I \equiv (l, r)$: $l \leq f(I) \leq f(r)$ But the full function $f(x)$ is unbounded.


#### Holomorphic function with holomorphic square root.

Our old enemy, monodromy shows up here. 
Consider the identity function $f(z) = z$. Let's analyze its square root
on the unit circle. $f(e^{i \theta}) = e^{i \theta/2}$. This can only be defined
continuously for _half_ the circle. As we go from $\theta: 0 \rightarrow 2 \pi$,
our $z$ goes from $0 \rightarrow 0$, while $f(z)$ goes $0 \rightarrow -1$. This
gives us a discontinuity at $0$.
                                                                
#### Formalisms

- **Sections of a presheaf $F$ over an open set $U$:**
  For each open set $U \subseteq X$, we have a set $F(U)$, which are generally sets of functions.
  The elements of $F(U)$ are called as the **Sections of $F$ over $U$**.
  More formally, we have a function $F: \tau \rightarrow (\tau \rightarrow R)$ 
  $(\tau \rightarrow R)$ is the space of functions over $\tau$.
- **Restriction Map:** For each inclusion $U \hookrightarrow V$, ($U \subseteq V$)
  we have a restriction map $Res(V, U): F(V) \rightarrow F(U)$.
- **Identity Restriction:** The map $Res(U, U)$ is the identity map.
- **Restrictions Compose:** If we have $U \subseteq V \subseteq W$, we must have 
  $Res(W, U) = Res(W, V) \circ Res(V, U)$.
- **Germ:** A germ of a point $p$ is any section over any open set $U$ containing $p$.
  That is, the set of all germs of $p$ is formally $Germs(p) \equiv \{ F(U_p) : U_p \subseteq X, p \in U, U \text{ open} \}$.
  We sometimes write the above set as $Germs(p) \equiv \{ (f, U_p) : f \in F(U_p), U_p \subseteq X, p \in U, U \text{ open} \}$.
  This way, we know both the function $f$ and the open set $U$ over which it is defined.
- **Stalk:** A stalk at a point $p$, denoted as $F_p$,
  consists of equivalence classes of all germs at a point, where two germs are
  equivalent if the germs become equal over a small enough set.
  We state that $(f, U) \sim (g, V)$ iff there exists a $W \subseteq U \cap V$ such that
  the functions $f$ and $g$ agree on $W$: $Res(U, W)(f) = Res(V, W)(g)$.
- **Stalk as Colimit:** We can also define the stalk as a colimit. We take the
  index category $J$ as a filtered set. Given any two open sets $U, V$, we have a smaller
  open set that is contained in $U \cap V$. This is because both $U$ and $V$ cannot
  be non-empty since they share the point $p$.
- If $p \in U$ and $f \in F(U)$, then the image of $f$ in $F_p$, as in, the value
  that corresponds to $f$ in the stalk is called as the germ of $f$ at $p$.
  **This is really confusing! What does this mean?**
  [I asked on `math.se`](https://math.stackexchange.com/questions/3761451/confusion-about-definition-of-germ-in-the-rising-sea-which-seems-circular).

#### References
- The rising sea by Ravi Vakil.


# Connectedness in terms of continuity

This was a shower thought. 

- We usually define a topological space $X$ as connected
  iff there are disjoint open sets $U, V$ such that $U \cup V = X$. Since
  they are disjoint, we have that $U \cap V = \emptyset$.
- An alternative way of stating this is to consider two colors `C = {red, blue }` with
  the discrete topology.
- We use the discrete topology on `C` since we want the two
  colors to be "separate".
- Now, a space $X$ is connected iff there is a continuous
  surjective function $f: X \rightarrow C$. That is, we can color the whole space
  continuously with both colors.

This is equivalent to the original definition by setting $U = f^{-1}(red)$
and $V = f^{-1}(blue)$: 

- Pre-images of a function must be disjoint. Hence, $U \cap V = \emptyset$.
- Preimages of $red$ and $blue$ must be open sets since $\{red\}$ and $\{blue\}$
  are open and $f$ is continuous: continuous functions have pre-images of open
  sets as open. Hence $U$ and $V$ are open.
- Since $f$ is surjective, we must have that the pre-images cover the entire set $X$.
  Hence $U \cup V = X$.

I find this to be appealing, since it's intuitively obvious to me that if a space
is disconnected, I can color it continuously with two colors, while if a space
is connected, I should be unable to color it continuously with two colors ---
there should be a point of "breakage" where we suddenly switch colors.


# Intuition for limits in category theory

#### A characterization of limits

The theorem that characterizes limits is this: 
> A category has Finite Limits iff it has all finite products and equalizers.
> limits have maps *out* of them.


#### Ravi Vakil's intuition for limits: Take sub things.
- An element of a limit gives one of each of its ingredients. For example,
 $K[[X]] = \lim_n \text{degree}~n~\text{polynomials} $, since we can get
 a degree n polynomial for all n, from any power series by truncation.
- limits have maps *out* of them.
- **RAPL**: right adjoints preserve limits.
- Limits commute with limits.
- These are mentioned in "Algebraic geometry in the time of Covid: Pseudolecture 2"
- Also, recalling that kernels are limits allows one to remember that we have
  maps that **go out** of a limit.

#### Limits are things you get maps *out* of.

- product has projections going out of it.
- `gcd` is less than the things that build it: 
  `gdb(a, b) -> a, b` since `gcd(a, b) < a` and `gcd(a, b) < b`.
- single point set can be mapped out of.
- `type Limit f = forall a. f a`

#### Limits in Haskell

```hs
{-# LANGUAGE ExplicitForAll #-}
{-# LANGUAGE RankNTypes #-}
{-# LANGUAGE KindSignatures #-}
{-# LANGUAGE GADTs #-}
data Limit (f :: * -> *) where
  MkLimit :: (forall a. f a) -> Limit f

projectOut :: Limit f -> f a
projectOut (MkLimit fa)  = fa

data Colimit (f:: * -> *) where
  MkCoLimit :: f a -> Colimit f

projectIn :: f a -> Colimit f
projectIn = MkCoLimit
```



# Finite topologies and DFS numbering

In this great math overflow question on
[How to think about non hausdorff topologies in the finite case](https://mathoverflow.net/questions/44109/how-should-one-think-about-non-hausdorff-topologies/44135#44135), there's an answer that encourages us 
to think of them as preorders, which are basically graphs. I wanted to understand
this perspective, as well as connect it to DFS numbers, since they provide a
nice way to embed these topologies into $\mathbb R$.

### Closure axioms of topology
We can axiomatize a topology using the kurotawski closure axioms. We need an
idempotent monotonic function $c: 2^X \rightarrow 2^X$ which satisfies some
technical conditions. Formally:

1. $c(\emptyset) = \emptyset)$ [$c$ is a strict function: it takes bottoms to bottoms]
2. $A \subseteq c(A)$. [monotonicity]
3. $c$ is idempotent: $c(c(A)) = c(A)$. [idempotence]
4. for all $A, B$ in $X$, $c(A \cup B) = c(A) \cup c(B)$.

Under this, a set is closed if it is a fixed point of $c$: That is, a set $A$
is closed iff $c(A) = A$.

##### Slight weakening into Single axiom version

Interestingly, this also gives a single axiom version of topological axioms,
something that maybe useful for machine learning. The single axiom is that
for all $A, B \subseteq X$, $A \cup c(A) \cup c(C(B)) \subseteq c(A \cup B)$.
This does not provide that $c(\emptyset) = \emptyset$, but it does provide
the other axioms [2-4].


###### Continuous functions

A function is continuous iff $f(c(A)) \subseteq c'(f(A))$ for every $A \in X$.

**TODO:** give examples of why this works, and why we need $(\subseteq)$ and not just $(eq)$.

### Finite topologies as preorders
We draw an arrow $x \rightarrow y$ iff $x \in Closure(y)$. Alternatively stated,
draw an arrow iff $Closure(x) \subseteq Closure(y)$. That is, we have an injection
from the closure of $x$ into the closure of $y$, and the arrow represents
the injection. Alternatively, we can think of
this as ordering the elements $x$ by "information". A point $x$ has less information
than point $y$ if its closure has fewer points.                         

### T0 in terms of closure:
- $X$ is $T_0$ iff for points $p, q \in X$, we have an open set $O$ which contains
  one of the points but not the other. Formally,
  either $p \in O \land q \not \in O$, or $p \not \in O \land q \in O$.
- **Example** of a $T_0$ space is the [sierpinski space](https://en.wikipedia.org/wiki/Sierpi%C5%84ski_space).
  Here, we have the open set $\{ \bot \}$ by considering the computation
  `f(thunk) = force(thunk)`. For more on this perspective, see [Topology is
  really about computation ](#topology-is-really-about-computation--part-1).
  This open set contains only $\bot$ and not $\top$.
- **Closure definition:** $X$ is $T_0$ iff $x \neq y \implies c(\{x\}) \neq c(\{y\})$

### T1 in terms of closure:
- $X$ is $T_1$ iff for all $p, q$ in $X$, we have open sets $U_p, U_q$ such that
  $U_p, U_q$ are open neighbourhoods of $p, q$ which do not contain the "other point".
  Formally, we need $p \in U_p$ and $q \not \in U_p$, and similarly $q \in U_q$ and $p \not \in U_q$.
  That is, $U_p$ and $U_q$ can split $p, q$ apart, but $U_p$ and $U_q$ need not
  be disjoint. 
- **Example** of $T_1$ is the zariski/co-finite topology on $\mathbb Z$, where
  the open sets are complements of finite sets. Given two integers $p, q$, use the
  open sets as the complements of the closed finite sets $U_p = \{q\}^C = \mathbb Z - q$, 
  and $U_q = \{p\}^C = \mathbb Z - p$. These separate $p$ and $q$,
  but have _huge_ intersection: $U_p \cap U_q = Z - \{ p, q\}$.
- **Closure definition:** $X$ is $T_1$ iff $c(\{x\}) = \{x\}$.
- [T1 has all singleton sets as closed](https://mathoverflow.net/a/337/123769)

### Haussdorf (T2) in terms of closure
-  $X$ ix $T_1$ iff for all $p, q$ in $X$, we have open set $U_p, U_q$ such that
   they are disjoint ($U_p \cap U_q = \emptyset$) and are neighbourhoods of $p$, $q$:
   $p \in U_p$ and $q \in U_q$.
- **Example** of a $T_2$ space is that of the real line, where any two points $p, q$
  can be separated with epsilon balls with centers $p, q$ and radii $(p - q) / 3$.
- **Closure definition**: $X$ is $T_2$ iff $x \neq y$ implies there is a set $A \in 2^X$ such that
  $x \not \in c(A) \land y \not \in c(X - A)$ where $X - A$ is the set complement.

### Relationship between DFS and closure when the topology is $T0$

If the topology is $T0$, then we know that the relation will be a poset,
and hence the graph will be a DAG. Thus, whenever we have $x \rightarrow y$, we 
will get 

### DFS: the T0 case
### DFS: the back edges
    
# Categorical definition of products in painful detail

I feel like I have incorrectly understood, then un-understood, and re-understood
in a slightly less broken way the definition of the product in category theory
around 5 times. I'm documenting the journey here.

### The definition

Given two objects $a, b$, in a category $C$, any 3-tuple
$(p \in C, \pi_a \in Hom(p, a), \pi_b \in Hom(p, b))$ is called their _product_, if for any
other 3 tuple $(q \in C, \pi'_a \in Hom(q, a), \pi'_b \in Hom(q, b))$, we have a
**unique** factorization map $f \in Hom(q, p)$ such that $\pi'_a = \pi_a \circ f$,
$\pi'_b = \pi_b \circ f$.

(Note that I did not say **the** product. This is on purpose). We claim that
the product is unique up to unique isomorphism.

Let's choose the category to be the category of sets. Let's try and figure out
what a product of the sets $a = \{ \alpha, \beta \}$ and $b = \{ \gamma, \delta \}$
is going to be. 


#### Non-example 1: product as $\{ 1 \}$
Let's try to choose the product set as simply $\{ 1 \}$, with the maps
being chosen as $\pi_a(1) = \alpha; \pi_b(1) = \gamma$:

```text
     πb
p{1}--->{ γ }
  |     { δ }
  |
πa|
  v 
{ α , β }
```

In this case, it's easy to see the failure. I can build a set $q = \{ 2 \}$ with
the maps $\pi'_a(2) = \alpha; \pi'_b(2) = \delta$:

```text
     πb
q{2}-+  { γ }
  |  |  {   }
  |  +->{ δ }
  |
πa|
  v 
{ α , β }
```

There is a single, unique map which takes $q$ to $p$, which is the function $f: 2 \mapsto 1$.
See that $\pi'_b(2) = \delta$, while $\pi_b(f(2)) = \pi_b(1) = \gamma$. Hence
the universal property can never be satisfied. 

Thus $(\{ 1 \}, 1 \mapsto \alpha, 1 \mapsto \gamma)$ is not a
product of $\{ \alpha, \beta \}$ and $\{ \gamma, \delta \}$ as it is
**unable to represent** a pair $(\alpha, \delta)$.

#### Non-example 2: product as $\{ 1, 2, 3, 4, 5 \}$

In this case, we shall see that we will have *too much freedom*, so this will
violate the "unique map" aspect. Let's pick some choice of $\pi_a$ and $\pi_b$.
For example, we can use:

$$
\begin{aligned}
(&p = \{ 1, 2, 3, 4\}, \\
&\pi_a = 1 \mapsto \alpha, 2 \mapsto \alpha, 3 \mapsto \beta, 4 \mapsto \beta, 5 \mapsto \beta\\
&\pi_b = 1 \mapsto \gamma, 2 \mapsto \delta, 3 \mapsto \gamma, 4 \mapsto \delta, 5 \mapsto \delta)
\end{aligned}
$$

Now let's say we have a set $q = \{ 42 \}$ such that $\pi'_a(42) = \beta, \pi'_b(42) = \delta$.

If we try to construct the map $f: q \rightarrow p$, notice that we get \emph{two}
possible legal maps. We can set $f(42) = 4$, or $f(42) = 5$, because both $4$
and $5$ map into $(\beta, \delta)$.

This violates the **uniqueness** condition of the product. Thus, the set $\{1, 2, 3, 4, 5\}$
is not a product of $\{\alpha, \beta \}$ and $\{\gamma, \delta \}$ because it does not
provide a **unique** map from $q$ into $p$. Alternatively, it does not provide
a **unique** representation for the tuple $(\beta, \delta)$. Thus it can't be a product.

#### Checking an example: $\{ \alpha, \beta \} \times \{ \gamma , \delta \}$ as $\{1, 2, 3, 4\}$

I claim that a possible product of $a$ and $b$ is:

$$
\begin{aligned}
(&p = \{ 1, 2, 3, 4\}, \\
&\pi_a = 1 \mapsto \alpha, 2 \mapsto \alpha, 3 \mapsto \beta, 4 \mapsto \beta,\\
&\pi_b = 1 \mapsto \gamma, 2 \mapsto \delta, 3 \mapsto \gamma, 4 \mapsto \delta)
\end{aligned}
$$


```
p       πa            a
   1------------*--->{α}
   |  2--------─┘    { }
   |  | 3-------*--->{β}
   |  | | 4----─┘
   +----* |
πb |  |   |
   |  *---+
   |      |
   v      v
b {γ      δ}
```

Now given a 3-tuple $(q, \pi'_a \in Hom(q, a), \pi'_b \in Hom(q, b))$, we construct
the factorization map $f: q \rightarrow p$, where:
$$
f: q \rightarrow p; \quad
f(x) \equiv
\begin{cases}
1 & \pi'_a(x) = \alpha \land \pi'_b(x) = \gamma \\
2 & \pi'_a(x) = \alpha \land \pi'_b(x) = \delta \\
3 & \pi'_a(x) = \beta  \land \pi'_b(x) = \gamma \\
4 & \pi'_a(x) = \beta  \land \pi'_b(x) = \delta \\
\end{cases}
$$

That is, we build $f(x)$ such that on composing with $\pi_a$ and $\pi_b$, we will
get the right answer. For example, if $\pi'_a(x) = \alpha$, then we know that
we should map $x$ to an element  $y \in p$ such that $\pi(y) = \alpha$. So 
we need $y = 1 \lor y = 2$. Then looking at $\pi'_b(x)$ allows us to pick a
**unique** y. There is zero choice in the
construction of $f$. We need _exactly_ 4 elements to cover all possible ways
in which $q$ could map into $a$ and $b$ through $\pi'_a, \pi'_b$ such that
we cover all possibilities with no redundancy. 

This choice of product is _goldilocks_: it does not have too few elements such
that some elements are not representable; it also does not have too many
elements such that some elements are redundant.

#### Non uniqueness: product as $\{10, 20, 30, 40\}$

Note that instead of using $p = \{1, 2, 3 4\}$, I could have used 
$p = \{10, 20, 30, 40 \}$
and nothing would have changed. 
I have never depended on using the _values_ $1, 2, 3, 4$.
Rather, I've only used them as \emph{labels}.

#### Non uniqueness: product as  $\{ (\alpha,  \gamma), (\alpha, \delta), (\beta, \gamma), (\beta, \delta) \}$

Indeed, our usual idea of product also satisfies the product, since it is 
in unique isomorphism to the set $\{1, 2, 3, 4\}$ we had considered previously.
But this might be strange: Why is it that the categorical definition of product
allows for so many other "spurious" products? Clearly this product of tuples 
is the **best** one, is it not?

Of course not! Inside the category of sets, anything with the same cardinality 
is isomorphic. So nothing inside the category can distinguish between the
sets $\{1, 2, 3, 4\}$ and  $\{ (\alpha,  \gamma), (\alpha, \delta), (\beta, \gamma), (\beta, \delta) \}$.
Hence, the _usual product_ we are so used to dealing with is not privileged.

This should make us happy, not sad. We have removed the (un-necessary)
privilege we were handing to this one set because it "felt" like it was
canonical, and have instead identified what actually makes the product of sets
tick: the fact that their cardinality is the product of the cardinalities of
the individual sets!


#### How to think about the product

Since we are specifying the data of $(p, \pi_a, \pi_b)$, we can simply think of
elements of $p$ as being "pre-evaluated", as $(x \in p, \pi_a(x), \pi_b(x))$.
So in our case, we can simplify the previous situation with $(p = \{ 10, 20, 30, 40 \}, \pi_a, \pi_b)$
by writing the set as 
$p = \{ (10, \alpha, \gamma), (20, \alpha, \delta), (30, \beta, \gamma), (40, \beta, \delta) \}$.
This tells us "at a glance" that every element of $a \times b$ is represented,
as well as what element it is represented by.


#### Proof of uniqueness upto unique isomorphism

- Assume we have two products $(p, \pi_a, \pi_b)$ and $(q, \pi_a, \pi_b)$, which
  are products of $a$ and $b$
- By the universality of $p$ wrt $q$, we get a unique! map $q2p$ such that the diagaram commutes.
- By the universality of $q$ wrt $p$, we get a unique! map $p2q$
- We get a map $q2p \cdot p2q : p \rightarrow p$. by the universality of $p$ with
  respect to $p$, we get a unique! map that makes the diagram commute.But we have
  two such maps: $id_p$ as well as $q2p . p2q$. Hence we must have $id_p = q2p \cdot p2q$. In pictures:

```
          ∃!id(p)
          +---+
          |   |
          |   v
+---------ppppp--------+
| πa      |   ^     πb |  
v      ∃!p2q  |        v
a         |   |        b
^         |  ∃!q2p     ^
| π'b     v   |    π'b |
+---------qqqqq--------+
```

- The full diagram commutes.
- By definition of identity/commutativity of the diagram, $\pi_a \circ id_p  = \pi_a$.
- By definition of identity/commutativity of the diagram, $\pi_b \circ id_p  = \pi_b$.
- By the commutativity of the diagram, we have $\pi_a \circ (q2p \circ p2q) = \pi_a$.
- By the commutativity of the diagram, we have $\pi_b \circ (q2p \circ p2q) = \pi_b$.
- We can consider the universal property of the product, where we have
  $(p, \pi_a, \pi_b)$ as one product, and $(p, \pi_a , \pi_b)$ as another
  product.
- This gives us a **unique map** $h$ such that $\pi_a \circ h = \pi_a$, and
  $\pi_b \circ h = \pi_b$.
- We have two candidates for $h$: $h = id_p$ and $h = p2q \circ q2p$.
  Hence, by the uniqueness of $h$, we have that $id_p = p2q \circ q2p$.

#### Wrapping up

- [Link to a misconception of the proof I had carried around for ages](https://math.stackexchange.com/questions/3756610/flaw-in-a-proof-of-uniqueness-of-products-in-a-category/3756693#3756693)

# Why is the spectrum of a ring called so?

I've been watching Ravi Vakil's excellent "pseudolectures" on algebraic geometry,
aptly titled
[AGITTC: Algebraic geometry in the time of Covid](https://www.youtube.com/channel/UCy3u23mZE4TyW88yr6JLx9A).
In lecture 3, there was a discussion going on in the sidebar chat where a user
said that the name "prime sprectrum" came from something to do with quantum
mechanics. To quote:

> letheology: spectrum of light -> eigenvalues of the hamiltonian operator ->
> prime ideal of the polynomial ring of the operator

I don't know what the prime ideal of the polynomial ring of the operator is,
so let's find out!  [I got a somewhat incomplete answer on `math.se`](https://math.stackexchange.com/questions/3754152/what-is-the-prime-ideal-of-the-polynomial-ring-of-an-operator)


Another user said:

> Lukas H: I like the definition of Spec A that doesn't include the word
> prime ideal, by a colimit of Hom(A, k) where k run over all fields and the
> maps are morphisms that make the diagrams commute.

That's a pretty crazy definition. One can apparently find this definition
in Peter Schloze's notes on AG. [I got an answer for this on `math.se`](https://math.stackexchange.com/questions/3754159/categorical-definition-of-spectrum-of-a-ring-as-a-colimit)

# Ergo proxy

I've been watching the anime "Ergo Proxy". I'll keep this section updated
with things I find intriguing in the anime.


- `bios` stood for both bow and life in greek, supposedly. Both lead to death.
  This is an interesting fact. I wonder if the `BIOS` of our computers is also
  from this, and was they backronymed into basic input/output system.

- "the white noise that reverberates within the white
  darkness is life itself". I have no idea what this means. It's a great
  sentence for sure.


#  [Satisfied and frustrated equations](#satisfied-and-frustrated-equations)

I found [this interesting terminology on a wiki walk](https://en.wikipedia.org/wiki/Gain_graph)
- An edge is satisfied if some equation `y = f(x)` is **satisfied**.
- Otherwise, the edge is said to be **frustrated**.

This is far more evocative terminology than UNSAT/unsatisfied, and also
makes for good haskell like variable names. `ss` for satisfied equations,
`fs` for frustrated equations!

# Combinatorial intuition for Fermat's little theorem

We wish to show that $x^p \equiv x (\mod p)$ _combinatorially_. Let's take
$2^3 (\mod 3)$ for simplicity. The general case follows. Let's first write
down strings which enumerate $2^3$:

```
000
001
010
011
100
101
110
111
```

To make use of $\mod 3$, we're going to treat our strings as _necklaces_. So,
for example, the string `011` looks like:

```
*-→ 0 -*
|      |
|      ↓
1 ←--- 1
```

So we have three possible rotations of the string `011`:

```
011
110
101
```

- Each of these rotations are unique, since they can be totally ordered using
  lexicographic ordering. Indeed, for **any string** other than `000`, `111`,
  all of its rotations are unique.

- So we can count the above 7 strings with equivalence class representatives.
  These representatives are those strings that are the lex smallest in their
  cyclic shifts. (Why are cyclic shifts _so important_?) 

```
Cyclic subshifts of strings:
---------------------------
000, 000, 000
001, 010, 100
011, 110, 101
111, 111, 111
```

- We've written the strings along with their cyclic subshifts, with the
  representative of the equivalence class as the first element. So the
  representatitives are `000, 001, 011, 111`. Note that two of these (`000, 111`)
  are equal to their cyclic subshifts. All of the others are distinct, and generate
  3 elements.

- So we can count the above strings as:

```
all strings   = {shifts of 001, 011}U{000, 111}
|all strings| = |{shifts of 001, 011}|+|{000, 111}|
no. of shifts = 3*(no. of representatives)
2^3 = 3 * (no. of representatives) + 2
2^3 = 3 * (no. of representatives) + 2
2^3 % 3 = 2
```

In general, for `x^p % p`, we will get `x` strings that contain the same letter.
These will not have elements in their cyclic shift equivalence classes. The
other strings will be generated as the smallest cyclic subshift of some
string.

#### Why does this not work when `p` is not prime?

Let `p = 4`. In this case, I can pick the string `s = 0101`. It has shifts:

```
0101 <-
1010
0101 <-
1010
```

so two of its shifts overlap, hence we will double-count the string `0101`
if I counted its equivalence class as having size `4`.

#### Relationship to group theory?

- How does this relate to group theory? Well, what we are doing is providing
  an action of the group `Z/pZ` into the set of strings `X^p` where `X` is
  some set. Our group action for a number `n ∈ Z/pZ` takes a
  string `s ∈ X^p` to its cyclic shift by `n` characters.

- We are then using the fact that the orbits of an action when `p` is prime
  has size either `1` or `p`, since the size of the orbit divides the
  size of the group `Z/pZ`, which is `p`, a prime. The divisors of
  `p` are only `1` and `p`. Therefore, the size of the orbit is either `1` 
  or `p`.

- Only necklaces that have identical elements like `000` and `111` have
  orbits of size `1`. We have `|X|` such necklaces.

- All other necklaces have size `p`.

- The rest of the proof follows similarly as before.


#### References

- [A string of pearls: proofs of Fermat's little theorem](https://ts.data61.csiro.au/publications/nicta_full_text/6061.pdf)
- [Algorithms thread 1: division under mod](https://www.youtube.com/watch?v=KfTcd0dg0DI&feature=youtu.be&t=815)

# An incorrect derivation of special relativity in 1D

I record an _incorrect_ derivation of special relativity, starting from the
single axiom "speed of light is constant in all inertial reference frames".
I don't understand why this derivation is incorrect. Help figuring this out
would be very appreciated.

### The assumption

We assume that the velocity of light as measured by any inertial frame
is constant. Thus if $x, x'$ are the locations of light as measured by
two inertial frames, and $t, t'$ is the time elapsed as measured by two
inertial frames, we must have that $dx/dt = dx'/dt'$. This ensures
that the speed of light is invariant.

### The derivation


- Our coordinate system has an $x$ space axis and a $t$ time axis.
- We have observer (1) standing still at the origin, and measures time
  with a variable $t$.
- We have observer (2) moving to the left with a constant velocity $v$.
- Observer (1) who is at rest sees a photon starting from the origin
  travelling towards the right with constant velocity $c$. The position of the
  photon at time $t$ is $x = c t$.
- Observer (2) also sees this photon. At time $t$, he sees the position
  of the photon as $x' = vt + ct$.
- From our rule of invariance, we have that $dx/dt = c = dx'/dt'$.

We calculate $dx'/dt' = (dx'/dt)(dt/dt')$ [chain rule], giving:

$$
\begin{aligned}
&c = \frac{dx}{dt} = \frac{dx'}{dt'} = \frac{dx'}{dt} \frac{dt}{dt'}  \\
&c = \frac{d(vt + ct)}{dt}\frac{dt}{dt'} \\
&c = (v + c) \frac{dt}{dt'} \\
&\frac{c}{v+c} = \frac{dt}{dt'} \\
&dt' = (v+c)dt/c \\
&t' = (v+c)t/c = (1 + v/c) t
\end{aligned}
$$

So we get the relation that time elapsed for observer (2) is related
to observer (1) as $t' = (1 + v/c) t$. 

- This checks out: Assume our observer is moving leftward at $v = c$. He will
  then see the photon move rightward at $x' = 2ct$. So if his time slows down 
  to have $t' = 2t$, we will have that $x/t' = 2ct/2t = c$.

- However, this forumla allows us to go faster than the speed of light with
  no repercurssions! (It is also not the correct formula as anticipated by
  the usual derivation). This can be fixed.

- Now assume that Observer 2 was moving _rightward_, not _leftward_. That is,
  we simply need to set $v = -v$, since this change of sign accomplishes
  flipping the direction of motion in 1D. This gives us the equation
  $t' = (1 - v/c)t$.

- According to this new equation, we are not allowed to approach the speed of
  light. If we attempt to do so, we will need to elapse zero time; and if
  we exceed the speed of light, we will need to elapse _negative time_.

- However, these formulae lead to an absurdity. If our observer 1 and observer 2
  witness two photons, one moving leftward and one moving rightward, one will
  need to write down the equations $t' = (1 \pm v/c)t$, which plainly leads
  one to contradiction.

### What's the issue?

The issue is the equation $x' = vt + ct$. 
- It is true that _as per observer (1) standing at the origin_, the distance
  between observer (2) and the photon is $vt + ct$.
- It is _not_ true that observer(2) sees the distance between them and 
  the photon  as $vt + ct$.
- Intuitively, this equation of $x' = vt + ct$ completely ignores length
  contraction, and hence cannot be right.
- Alternatively, the equation of $x' = vt + ct$ imposes galilean relativity, 
  where I am attempting to naively connect reference frames, which cannot be
  correct.


#  [The geometry and dynamics of magnetic monopoles](#the-geometry-and-dynamics-of-magnetic-monopoles)

I found this cool document written by Sir Atiyah, called as 
["The geometry and dynamics of magnetic monopoles"](https://www.jstor.org/stable/j.ctt7zv206)
which contains
a nice exposition of electromagnetism from the differential viewpoint.
I'll record what I read here.


# Sanskrit and Sumerian

#### Sanskrit's precursors 

The oldest known sanskrit text that has been found is the Rig Veda. Eveyrthing
after is the study of sanskit proper. This is quite problematic because the
Rig Veda is a complete and consistent textbook with respect to language. It's
a black-box in terms of language evolution.

The question "what is the precursor" asks for a method of study to determine
the precursor. We just don't know because we have no writings, text, etc.

##### Archaeological data

Archaeological data is problematic as well. We don't know where the people who
knew sanskrit came from. Sanskrit was spoken in the northen part of
Hindusthan [what they originally called Bhrahma-nagar (?)]. While we can
try to undersatnd where it comes from, it's hard. The script is Brahmi / Devanagiri,
which means used by Brahma or god. The name "sanskrit" is a compound that stands
for "well-formed". It's really clean-slate in that sense. The study of Indo-Aryan
languages in the Indian subcontinent has only one possible known history, which
stops at the Rig Veda. We don't know the relationship between 2400BC when
Rig Veda was written to anything before it.

##### Non Vedic sanskrit

Studies in non-vedic sanskrit is known to be the "true" proto-Indo-Europoean (PIE)
language. The conjecture is that this Indo European language ought to be
able to cover middle greek, hittite, and sanskit. 

##### Prakrit and its relationship to this story

Prakrit evolved as a vernacular of Sanskrit in the north pahadi region. Hindi
as we know toady evolved from Hindusthani, which came from languages in 
northern india. Languages like Marathi, Marvadi, Gujurathi, etc. came a lot
before Hindi did.

##### TLDR on Sanskrit v/s Hindi

There is a huge gap of time between Sanskit, Prakrit, Pali, and Hindi. 
Hindi evolved around the 1600s due to the Mughals who used to speak a 
vernacular of Hindusthani. Kabir also wrote in Hindusthani. There was also
some Farsi and Urdu mixed in. 

> Hindi is more of a political exploit than an actual language ~ Alok 2020


##### The relationship to Sumerian

We don't know what the relationship to sumerian is. Social expectations that
was setup is sumerian has become more stringent in Sanskrit. 


# Writing Cuneiform

I've been reading about the Sumerian people, and I've gotten fascinated with
the question of how to write in Cuneiform, which is their script. I wanted
to learn how to write cuneiform. It appears that it was originally written
down by pressing reed styluses into clay. The script is syllabic in nature.
We have three components:

1. Vertical wedge `𐏑`
2. Horizontal wedge `𐎣`
3. Diagonal `𐏓`




##### References

- [Getty museum: Writing cuneiform](https://www.youtube.com/watch?v=HbZ2asfyHcA)
- [Irving Finkel teaches how to write cuneiform](https://www.youtube.com/watch?v=XVmsfL5LG90)
- [CLDI: Cuneiform Digital library initiative](http://cdli.ox.ac.uk/wiki/doku.php?id=cuneiform_writing_techniques)
- [Font: Old persian block](https://www.compart.com/en/unicode/block/U+103A0)

# The code of hammurabi

I've wanted to read the code of hammurabi since it was name dropped in
[Snow Crash by Neal Stephenson](https://en.wikipedia.org/wiki/Snow_Crash).
I finally got around to it. Here's some excerpts I found fascinating. The
numbers are according to 
[this translation of the Code of Hammurabi](http://www.general-intelligence.com/library/hr.pdf).
Some helpful hints were found from the
[Avalon ancient law codes page of the Yale law school](https://avalon.law.yale.edu/ancient/).

- (5) If a judge try a case, reach a decision, and present his judgment in
  writing; if later error shall appear in his decision,and it be through his
  own fault, then he shall pay twelve times the fine set by him in the case, and
  he shall be publicly removed from the judge’s bench, and never again shall he
  sit there to render judgement. (**Commentary**: These are steep penalties for
  getting a case wrong. I suppose this encouraged innocent until proven guilty
  quite a bit.)

- (23) If the robber is not caught, then shall he who was robbed claim under
  oath the amount of his loss; then shall the community, and...on whose
  ground and territory and in whose domain it was compensate him for the goods
  stolen (**Commentary**: This rule appears to setup some sort of insurance where
  someone who is robbed is guaranteed recompence)

- (108) If a tavern-keeper (feminine) does not accept corn according to gross
  weight in payment of drink, but takes money, and the price of the drink is
  less than that of the corn, she shall be convicted and thrown into the water.
  (**Commentary**: I wonder why this rule specifically singles out women)

- (120) If any one store corn for safe keeping in another person’s house, and
  any harm happen to the corn in storage, or if the owner of the house open the
  granary and take some of the corn, or if especially he deny that the corn was
  stored in his house: then the owner of the corn shall claim his corn before God
  (on oath), and the owner of the house shall pay its owner for all of the corn
  that he took. (**Commentary**: I wonder whether there were many 'owners of corn'
  who swore false oaths. I suppose not, if this rule was enshrined into law.
  It is interesting that they held oaths to god as a mechanism to prevent lying)

- (137) 137. If a man wish to separate from a woman who has borne him children,
  or from his wife who has borne him children: then he shall give that wife her
  dowry, and a part of the usufruct offield, garden, and property, so that she
  can rear her children.When she has brought up her children, a portion of all
  that is given to the children, equal as that of one son, shall be given to her.
  She may then marry the man of her heart. (**Commentary**: their society
  seems egalitarian, and provides both a mechanism of divorce, and rights
  and property to the wife after divorce).

- (168) If a man wish to put his son out of his house, and declare before the
  judge: “I want to put my son out,” then the judge shall examine into his
  reasons. If the son be guilty of no great fault, for which he can be
  rightfully put out, the father shall not put him out; (169). If he be guilty of a
  grave fault, which should rightfully deprive him of the filial relationship,
  the father shall forgive him the first time; but if he be guilty of a grave
  fault a second time the father may deprive his son of all filial relation.
  (**Commentary**: I find this notion of 'forgive once' being encoded into law
  very interesting. I don't know of other law codes that have such a thing).

- (188). If an artizan has undertaken to rear a child and teaches him his
  craft, he can not be demanded back; (189) If he has not taught him his craft,
  this adopted son may return to his father’s house. (**Commentary**: I find it
  interesting that this notion of 'taking a son' is intertwined with caring
  for the son and teaching them a craft to become a future productive member
  of society)

- (196) If a man put out the eye of another man, his eye shall be put out.
  [ An eye for an eye ].  (**Commentary**: Fascinating that 'eye for an eye' comes from the code).

- (202). If any one strike the body of a man higher in rank than he,he shall
  receive sixty blows with an ox-whip in public. 
  (**Commentary**: Neat how one can glean the existence of a social hierarchy
  from a law code. I wonder how this hierarchy was defined.)


- (215) If a physician make a large incision with an operating knife and cure
  it, or if he open a tumor (over the eye) with an operating knife, and saves
  the eye, he shall receive ten shekels in money.
  (**Commentary**: (i) It is weird that things like doctor's procedures are covered
  in the law code. How often is the code revised? What happens when a doctor
  comes up with a new treatment? (ii) It is weird that the prices are recorded
  in the law code. What about inflation?)

- (249) If any one hire an ox, and God strike it that it die, the man who hired
  it shall swear by God and be considered guiltless. (**Commentary**: Once again,
  their belief in the truthfulness of oaths sworn to God. Also, it's nice to
  know that they do understand and account for truly random events that one
  has no control over)

- Epilogue: In future time, through all coming generations, let the king,who may be in the
  land, observe the words of righteousness which I have written on my monument;
  let him not alter the law of the land which I have given, the edicts which I
  have enacted; my monument let him not mar. If such a ruler have wisdom, and
  beable to keep his land in order, he shall observe the words which I have
  written in this inscription (**Commentary**: This advice for future kings is
  interesting, and appears to imply that the rules and all the prices in the
  rules ought to be immutable. I really do wonder how they dealt with their 
  society changing, new inventions, and inflation)

- [Taken from this introduction to the code of hammurabi from Yale](https://avalon.law.yale.edu/ancient/hammint.asp):
  An accused person was allowed to cast himself into "the river," the Euphrates.
  Apparently the art of swimming was unknown; for if the current bore him to the
  shore alive he was declared innocent, if he drowned he was guilty. So we learn
  that faith in the justice of the ruling gods was already firmly, though
  somewhat childishly, established in the minds of men

# The implicit and inverse function theorem

I keep forgetting the precise conditions of these two theorems. So here
I'm writing it down as a reference for myself.

### Implicit function: Relation to function
- Example 1: $x^2 + y^2 = 1$ to $y = \sqrt{1 - x^2}$.

If we have a function $y = g(p, q)$, we can write this as $y - g(p, q) = 0$.
This can be taken as an implicit function $h(y; p, q) = y - g(p, q)$. We then
want to recover the explicit version of $y = g'(p, q)$ such that
$h(g'(p, q); p, q) = 0$. That is, we recover the original explicit formulation
of $y = g'(p, q)$ in a way that satisfies $h$.

#### The 1D linear equation case

In the simplest possible case, assume the relationship between $y$ and $p$
is a linear one, given implicitly. So we have $h(y; p) = \alpha y + \beta p + \gamma = 0$.
Solving for $h(y,p) = 0$, one arrives at: $y = -1/\alpha (\beta p + \gamma)$.
- Note that the solution exists iff $\alpha \neq 0$. 
- Also note that the the existence of the solution is equivalent to asking that
  $\partial h / \partial y = \alpha \neq 0$.


#### The circle case

In the circle case, we have $h(y; p) = p^2 + y^2 - 1$. We can write
$y = \pm \sqrt{p^2 - 1}$. These are _two_ solutions, not one, and hence
a relation, not a function.

- We can however build two functions by taking two parts. $y+ = +\sqrt{p^2 - 1}$;
  $y- = -\sqrt{p^2 - 1}$.

- In this case, we have $\partial h / \partial y = 2y$, which changes sign
  for the two solutions. If $y^\star > 0$, then $(\partial h / \partial y)(y^\star = 0)$.
  Similarly for the negative case.

#### Assuming that a solution for $h(y, p)$ exists

Let us say we wish to solve $h(y; p) = y^3 + p^2 - 3 yp - 7 = 0$. Let's assume
that we have a solution $y = sol(p)$ around the point $(y=3, p=4)$. Then we 
must have: $sol(p)^3 + p^2 - 3 sol(p) p - 7 = 0$. Differentiating by $p$, 
we get: $3 sol(p)^2 sol'(p) + 2p - 3 sol'(p) p - 3 sol(p) = 0$. This gives
us the condition on the derivative:

$$
\begin{aligned}
&3 sol(p)^2 sol'(p) + 2p - 3 sol'(p) p - 3 sol(p) = 0 \\
&sol'(p)\left[ 3 sol(p)^2 - 3p \right] = 3 sol(p) - 2p \\
&sol'(p) = [3 sol(p) - 2p] / \left[ 3(sol(p)^2 - 3p) \right]  \\
\end{aligned}
$$

The above solution exists  if $3(sol(p)^2 - 3p \neq 0)$. This quantity is again
$\partial h / \partial y$.

#### Application to economics

- We have two inputs which are purchaed as $x_1$ units of input 1, $x_2$ units of input $2$.
- The price of the first input is $w_1 BTC/unit$. That of the second input is $w_2 BTC/unit$.
- We produce an output which is sold at price $w BTC/unit$.
- For a given $(x_1, x_2)$ units of input, we can produce  $x_1^a x_2^b$  units of output where
  $a + b < 1$.
  [The Coob-douglas function](https://en.wikipedia.org/wiki/Cobb%E2%80%93Douglas_production_function).
- The profit is going to be $profit(x_1 x_2, w_1, w_2, w) = w(x_1^a x_2^b) - w_1 x_1 - w_2 x_2$.
- We want to select $x_1, x_2$ to maximize profits.
- Assume we are at break-even: $profit(x_1, x_2, w_1, w_2, w) = 0$.
- The implicit function theorem allows us to understand how any variable changes
  with respect to any other variable. It tells us that locally, for example,
  that the number of units of the first input we buy ($x_1$) is a function
  of the price $w_1$. Moreover, we can show that it's a _decreasing function_
  of the price.



### Inverse function: Function to Bijection

- Given a differentiable function $f$, at a point $p$, we will have a continuous inverse
  $f^{-1}(p)$ if the derivative $f'(p)$ is locally invertible.

- The intuition is that we can approximate the original function with a linear
  function. $y = f(p + \delta) = f(p) + f'(p) \delta$. Now since $f'(p)$ is
  locally invertible, we can solve for $\delta$. $y = f(p) + f'(p) \delta$
  implies that $\delta = 1/f'(p) [y - f(p + \delta) ]$.
  This gives us the pre-image $(p + delta) \mapsto y$.

- The fact that $1/f'(p)$ is non-zero is the key property. This generalizes
  in multiple dimensions to saying that $f'(p)$ is invertible.


One perspective we can adopt is that of Newton's method. Recall that Newton's
method allows us to find $x^*$ for a fixed $y^*$ such that $y^* = f(x^*)$. It follows
the exact same process! 

- We start with some $x[1]$.
- We then find the tangent $f'(x[1])$.
- We draw the tangent at the point $x[1]$ as $(y[2] - y[1]) = f'(x[1])(x[2] - x[1])$.
- To find the $y^*$ we set $y[2] = y^*$.
- This gives us $x[2] = x[1] - (y^* - y[1])/f'(x[1])$.
- Immediately generalizing, we get $x[n+1] = x[n] - (y^* - y[n]) / f'(x[n])$.

##### Idea of proof of implicit function theorem (from first principles)


- Let $F(x, y) \neq 0$, point $p$ be the point where we wish to implicitize.
- To apply implicit fn theorem, take $\partial_y|_pF(x, y) \neq 0$. 
  Say WLOG that $\partial_y|_p F(x, y) > 0$,
  since $F$ is assumed to be continuously differentiable.
- Since $\partial_y F$ is continuous and positive at $p$,
  it's positive in a nbhd of $p$ by continuity.
- Consider $F(p_x, y)$ as a single variable function of $y$. Its derivative with
  respect to $y$ is positive; it's an increasing function in terms of $y$.
- Since $F(x_0, y_0)$ and is an increasing function of $y_0$, we must have 
  two $y$ values $y_-, y_+$ such that $F(p_x, y_+)$ is positive, and $F(p_x, y_-)$
  is negative.
- Since $F$ is zero and continuous, we have that for all $x$ near $x_0$, that 
 $F(x_0, y_+) > 0 \implies F(x, y_+) > 0$ and $F(x_0, y_-) < 0 \implies F(x, y_-) < 0$. 
 We have released $x_0$ into a wild $x$ in the neighbourhood! 
- Now pick some $x_*$ near $x$. Since we have that $F(x_*, y_+) > 0$ and $F(x_*, y_-) < 0$,
  there exists a **unique** $y_*$ (by MEAN VALUE THEOREM) that $F(x_*, y_*) = 0$
- Since the $y_*$ is unique, we found a function: $x_* \xmapsto{f} y_*$. 
- We are not done. We need to prove the formula for $f'(x)$ where $f$ is the 
  implicit mapping.
- $F(x, f(x)) = 0$ by defn of $f(x)$. Apply chain rule!

\begin{aligned}
&F(x, f(x)) = 0 \\
&dF = 0 \\
&\frac{\partial F}{\partial x} \cdot \frac{\partial x}{\partial x}  + \frac{\partial F}{\partial y} \frac{df}{dx} = 0 \\
&\frac{\partial F}{\partial x} \cdot 1  + \frac{\partial F}{\partial y} \frac{df}{dx} = 0 \\
&\frac{df}{dx} = \frac{- \frac{\partial F}{\partial y}}{\frac{\partial F}{\partial x} \cdot 1} \\
\end{aligned}

#### Idea of proof of inverse function theorem (from implicit function theorem)

- Given the implicit function, say we want to locally invert $f(x)$.
- Pick the implicit function $F(x, y) = f(y) - x$. If we consider the level set $F(x, y) = 0$,
  the implicit function theorem grants us a $g(x)$ such that $F(x, y=g(x)) = 0$.
  That is, we get $f(g(x)) - x = 0$, or $f(g(x)) = x$.
- To show that it's also a right inverse, consider $F(f(k), k) = f(k) - f(k) = 0$.
  Since $y = g(x)$, we have that $k = g(f(k))$.
- Hence, $g$ and $f$ are both left and right inverses, and hence bijections.

#### Idea of proof of implicit function theorem (from inverse function theorem)

- We are given a function $F(x, y)$. We wish to find a formula $y = g(x)$ such that
 $F(x, g(x)) = 0$.
- The idea is to consider a function $f(x, y) = (x, F(x, y))$. 
- Since this is invertible, we get a local inverse function $g$ such that $g(f(x, y)) = (x, y)$.
  That is, $g(x, F(x,y)) = (x, y)$.
- Now, for a given $x$, set  $y := snd(g(x, 0))$. This gives us a $(x, y)$ such that 
  $g(x, F(x,y)=0) = (x, y)$. That is, we get a $y$ such that $F(x, y) = 0$ and 
  this a bijection from $x$ to $y$ since $g$ is a bijection.

#### Idea of proof of inverse function theorem (from newton iterates)

We know that $F(x + \delta x) = F(x) + J \delta x + \eta$ where $J$ is the jacobian,
$\eta$ is error term. Upto first order, this works. We take iterates of this
process to get the full inverse.


#### References

- [Mathematics for economics, Natalia Lazzati](https://people.ucsc.edu/~nlazzati/Courses/Math519/Notes/Note%203.pdf)
- [Inverse function theorem via Newton's method](http://mtaylor.web.unc.edu/files/2018/04/invfn.pdf)

# Whalesong hyperbolic space in detail

We can build a toy model of a space where velocity increases with depth.
Let the x-y axis be: left-to-right (→) is positive x, top-to-bottom (↓) is positive y.
Now let the velocity at a given location $(x^\star, y^\star)$ be $(y^\star+1, 1)$.
That is, velocity along $y$ is constant; the velocity along $x$ is an increasing
function of the current depth. The velocity along $x$ increases linearly with depth.
Under such a model, our shortest paths will be 'curved' paths.


#### References

- Very funnily, the wikipedia page on Whale vocalization has a 'selected discograpy'
  section: [Whalesong, selected discography](https://en.wikipedia.org/wiki/Whale_vocalization#Selected_discography)


# Motivating Djikstra's

Usually I've seen Djikstra's algorithm presented as a greedy algorithm,
and then an analogy given to "fire" for the greediness. We can reverse
this presentation start with the "fire", and the discretize the "fire" solution
to arrive at Djikstra's

#### The fire analogy

- Assume we want to find the shortest path from point $A$ to point $B$. We
  should find the path that fire travels. How do we do this? Well, we simply
  simulate a fire going through all paths from our initial point,
  and then pick the shortest path (ala Fermat). We interpret the graph
  edges as distances between the different locations in space.

- So we write a function $simulate :: V \times T \rightarrow 2^{V \times T}$, which
  when given a starting vertex $v : V$ and a time $t : T$, returns the set
  of vertices reachable in at most that time, and the time it took to reach them.

- Notice that we are likely repeating a bunch of work. Say the fire
  from $x$ reaches $p$, and we know the trajectory of the fire from $p$. The
  next time where a fire from $y$ reaches $p$, we don't need to _recalculate_
  the trajectory. We can simply cache this.

- Notice that this time parameter being a real number is pointless;
  really the only thing that matters are the _events_ (as in computational geometry),
  where the time crosses some threshold.


- By combining the two pieces of information, we are led to the
  usual implementation: Order the events by time using a queue, and then
  add new explorations as we get to them.




# Intuitions for hyperbolic space

- [Combinatorial group theory](https://math.stackexchange.com/questions/689257/topics-in-combinatorial-group-theory-for-a-short-talk/692534#692534)
- [Van Kampen diagrams: an intuition](https://math.stackexchange.com/questions/330531/algebra-best-mental-images/331135#331135)
- [DIY Hyperbolic geometry](https://math.berkeley.edu/~kpmann/DIYhyp.pdf)
- [Hyperbolic Embeddings with a Hopefully Right Amount of Hyperbole](https://dawn.cs.stanford.edu/2018/03/19/hyperbolics/)
- [Notes on Hyperbolic geometry by Canon](library.msri.org/books/Book31/files/cannon.pdf)
- A question on `math.se` that attempts to describe hyperbolic space: [What hyperbolic space really looks like](https://math.stackexchange.com/questions/1407550/what-hyperbolic-space-really-looks-like)
- [Another question about what hyperbolic space feels like](https://math.stackexchange.com/questions/3520395/what-does-hyperbolic-space-feel-like)
- [Notes On Hyperbolic and Automatic Groups: Michael Batty](https://www.math.ucdavis.edu/~kapovich/280-2009/hyplectures_papasoglu.pdf)
- [The geometry of the word problem by Martin R Bridson](https://people.maths.ox.ac.uk/bridson/papers/bfs/bfs.pdf)
- [Living in Hyperbolic space](http://www.stevejtrettel.com/living-in-hyperbolic-space.html)
- [We can embed euclidian space into hyperbolic space](https://math.stackexchange.com/questions/1347/studying-euclidean-geometry-using-hyperbolic-criteria)
- [Amsler surface: A surface with constant negative gaussian curvature](https://math.stackexchange.com/questions/289716/hyperbolic-diameter-of-amslers-surface)
- [Hyperbolic distance naturally measures distance as paths of light with varying refractive index](https://math.stackexchange.com/questions/1887685/hyperbolic-distance-confusion)
- [The pseudosphere, another surface with constant negative curvature](https://mathworld.wolfram.com/Pseudosphere.html)
- [Whalesong, selected discography](https://en.wikipedia.org/wiki/Whale_vocalization#Selected_discography)

# Product of compact spaces in compact

<img src="./static/product-of-compact-is-compact.png">

# Hyperbolic groups have solvable word problem

I have never seen an elementary account of this in a 'trust these facts, now
here is why hyperbolic groups have a solvable word problem'. I am writing
such an account for myself. It's an account for building intuition, so no
proofs will be provided except for the final theorem. All facts will be backed
by intuition. Since most of it is geometric, it's easy to convey intuition.

### Graphs of groups, quasi-isometry.
- **NOTE:** I will consistently denote the inverse of $g$ by $g^{-1}$.

We can convert any group into a graph by using the cayley graph of the group.
We characterize hyperbolic space as a space where we can build 'thin triangles'.
We also think of hyperbolic space as where geodesics from a given point
diverge (in terms of angle) exponentially fast. 

The choice of generators for the cayley graph gives different graphs. We can
assign a **unique** geometric object by considering cayley graphs upto quasi
isometry. The cayley graph of a group with respect to different generating sets
are quasi-isometric. We can now try to study properties that are invariant
under quasi-isometry, since these are somehow 'represented faithfully by the geometry'.

### Hyperbolicity enters the picture
We now say that a graph is hyperbolic if the cayley graph of the group is
hyperbolic. We can show that hyperbolicity is preserved by quasi-isometry.
So this property does not depend on the generating set.

### Isoperimetric Inequality

If we have a finitely presented group $G = \langle S | R \rangle$, and $w$
is a word in the free group $Free(S)$, if $[[w]] = 1$, we will have 

$$
w = \prod_{i=1}^n u_i r_i^{\pm 1} u_i' 
$$

This follows almost by definition. Since we have quotiented by $r$ we can have
elements of $r$ in between $u u'$. We will need to have a $u'$ since there's
nothing else to cancel off the $u$.

##### Area of a word
Let $G = \langle S | R \rangle$. Let $w$ be a word in $S$ such that $[[w]] = e$.
The area of the word $w$ is the minimal number of such $u r u'$ components
we need to write it down. Formally:

$$
Area(w) = \min { n | \prod_{i=1}^n u_i r+i^{\pm 1} u_i'}
$$

I don't understand the geometric content of this definition. I asked
[on mathoverflow](https://mathoverflow.net/questions/363455/geometric-content-of-area-of-a-word-in-geometric-group-theory).


##### Isopermetric function for a group

$f: \mathbb N \rightarrow \mathbb N$ is a Dehn function or isoperimetric function
if the area of the word is upper bounded by $f(|word|)$. In some sense, the
length of the word is the perimeter to the area, and this gives us a form
of the isoperimetric inequality. Formally, $f$ is a Dehn function if for all
words $w \in F(S)$ such that $[[w]] = e$, we have $A(w) \leq f(|w|)$. depending
on the growth of $f$, we say that $G$ has linear, quadratic, exponential etc.
Dehn function. 

##### Geometric content of Area

We define a map to be aninite, planar, oriented, connected and simply connected
simplicial2-complex (!).  A map $D$ is a diagram over an alphabet $S$ iff every
edge $e \in D$ has a label $lbl(e) \in S$ such that $lbl(e^{-1}) = (lbl(e))^{-1}$.
Hang on: what does it mean to invert an edge?  I presume it
means to go backwards along an edge. So we assume the graph is directed, and we
have edges in both directions.

A Van Kampen diagram over a group $G = \langle S | R \rangle$  is a diagram $D$
over $S$ such that for all faces of $D$, the label of the boundary of $f$
is labelled by some $r^{\pm} : r \in R$. The area of such a diagram
is the number of faces.


### Hyperbolic iff Linear Isopermetric Inequality is satisfied
A finitely presented group is hyperbolic if and of if its cayley grah
satisfies the linear isoperimetric inequality. 

### Deciding if elements are conjugate to each other

- If we can answer the question of whether two elements are conjugate to each
  other (does there exist a $g$ such that $ghg' =?= k$), we can solve
  that an element is equal to the identity:
-   Pick $k = e$. Then if we have $ghg' = k = e$, then $gh = g$ hence $h = e$.

- If we can check that an element is equal to the identity, we can check for
  equality of elements. two elements $k, l$ are equal iff $kl' = e$.

- So solving conjugacy automatically allows us to check of equality.


### Proof that conjugacy is solvable for hyperbolic groups

Consider a solution to the problem of finding an $x$ such that $xgx^{-1} = h$.
We claim that due to the hyperbolicity of the space, such an $x$ cannot be
"too long". 





### References
- [Notes On Hyperbolic and Automatic Groups: Michael Batty](https://www.math.ucdavis.edu/~kapovich/280-2009/hyplectures_papasoglu.pdf)
- [The geometry of the word problem by Martin R Bridson](https://people.maths.ox.ac.uk/bridson/papers/bfs/bfs.pdf)
- [My math.stackexchange question asking about why delta thin triangles help to solve conjugacy](https://math.stackexchange.com/questions/3789681/delta-thin-trianges-implies-solvable-conjugacy-problem-for-hyperbolic-groups)

# Elementary uses of Sheaves in complex analysis

I always wanted to see sheaves in the wild in a setting that was both
elementary but 'correct': In that, it's not some perverse example
created to show sheaves (DaTaBaSeS arE ShEAvEs). Ahlfors has a great example
of this which I'm condensing here for future reference.

### Sheafs: Trial 1

- We have function elements $(f:  \Omega \rightarrow \mathbb C, \Omega \subseteq \mathbb C)$.
  $f$ is complex analytic, $\Omega$ is an open subset of $\mathbb C$.
- Two function elements $(f_1, \Omega_1), (f_2, \Omega_2)$ are said to be analytic
  continuations of each other iff $\Omega_1 \cap \Omega_2 \neq \emptyset$, and
  $f_1 = f_2$ on the set $\Omega_1 \cap \Omega_2)$.
- $(f_2, \Omega_2)$ can be called as the continuation of $(f_1, \Omega_1)$ to
  region $\Omega_2$.
- We will have that the analytic continuation of $f_1$ to $\Omega_2$ is unique.
  If there exists a function element $(g_2, \Omega_2)$, $(h_2, \Omega_2)$ such that
  $g_2 = f_1 = h_2$ in the region $\Omega_1 \cap \Omega_2$, then by analyticity,
  this agreement will extend to all of $\Omega_2$.
- Analytic continuation is therefore an equivalence relation (prove this!)
- A chain of analytic continuations is a sequence of $(f_i, \Omega_i)$ such that
  the adjacent elements of this sequence are analytic continuations of each other.
  $(f_i, \Omega_i)$ analytically continues $(f_{i+1}, \Omega_{i+1})$.
- Every equivalence class of this equivalence relation is called as a global
  analytic function. Put differently, it's a family of function elements
  $(f, U)$ and $(g, V)$ such that we can start from $(f, U)$ and build
  analytic continuations to get to $(g, V)$.

### Sheafs: Trial 2

- We can take a different view, with $(f, z \in \mathbb C)$ such that $f$
  is analytic at some open set $\Omega$ which contains $z$. So we should
  picture an $f$ sitting analytically on some open set $\Omega$ which contains $z$.
- Two pairs $(f, z)$, $(f', z')$ are considered equivalent if $z = z'$ and
  $f = f'$ is some neighbourhood of $z (= z')$.
- This is clearly an equivalence relation. The equivalence classes are called as _germs_.
- Each germ $(f, z)$ has a unique projection $z$. We denote a germ of $f$ with projection $z$
  as $f_z$.
- A function element $(f, \Omega)$ gives rise to germs $(f, z)$ for each $z \in \Omega$.
- Conversely, every germ $(f, z)$ is determined by some function element $(f, \Omega)$
  since we needed $f$ to be analytic around some open neighbourhood of $z$: Call
  this neighbourhood $\Omega$.
- Let $D \subseteq \mathbb C$ be an open set. The set of all germs $\{ f_z : z \in D \}$ 
  is called as a _sheaf_ over $D$. If we are considering analytic $f$ then
  this will be known as the _sheaf of germs of analytic functions over $D$_. This
  sheaf will be denoted as $Sh(D)$.
- There is a projection $\pi: Sh(D) \rightarrow D; (f, z) \mapsto z$. For a fixed $z0 \in D$,
  the inverse-image $\pi^{-1}(z0)$ is called as the _stalk over $z0$_. It is
  denoted by $Sh(z)$.
- $Sh$ carries both topological and algebraic structure. We can give _the sheaf_
  a topology to talk about about continuous mappings in and out of $Sh$.
  It also carries a pointwise algebraic structure at each stalk: we can
  add and subtract functions at each stalk; This makes it an abelain group.

#### Sheaf: Trial 3

A sheaf  over $D$ is a topological space $Sh$ and a mapping $\pi: Sh \rightarrow D$
with the properties:
- $\pi$ is a local homeomorphism. Each $s \in S$ has an open neighbourhood $D$
  such that $\pi(D)$ is open, and the restriction of $\pi$ to $D$ is a homeomorphism.
- For each point $z \in D$, the stalk $\pi^{-1}(z) \equiv S_z$ has the structre of an abelian
  group.
- The group operations are continuous with respect to the topology of $Sh$.

We will pick $D$ to be an open set in the complex plane; Really, $D$ can
be arbitrary.

### Germs of analytic functions satisfy (Sheaf: Trial 3)

<img src="./static/sheaf.png">

# Snake lemma

## Why homomorphisms for chain maps?

First of all, to define a mapping between simplicial complexes $\{ G_i \}$
and $\{ H_i \}$, one might naively assume that we can ask for _functions_
$\{ f_i: G_i \rightarrow H_i \}$:

```
       ∂    ∂
    G3 → G2 → G1 → 0
    |    |    |
    f    g    h
    ↓    ↓    ↓  
0 → H3 → H2 → H1
      ∂    ∂
```


Unfortunately, to be able to use the
machinery of Homology, we need the $\{ f_i \}$ to be abelian group homomorphisms.
However, this is no great loss. Intuitively, when we want to map complexes,
we first say where the _generators_ of the abelian group ($\mathbb Z$-module)
maps to; Everything else is determined by the generators. This aligns
nicely with our intuition of what a map between complexes should look like:
we tell where the geometry goes ("this edge goes there"), and the algebra
is "dragged along for the ride". This gives us the diagram:

```
    G3--∂-→G2--∂-→G1 
    |      |      |
    f3     f2     f1
    ↓      ↓      ↓
0 →H3--∂-→H2--∂-→H1
```

where the `fi` are _homomorphisms_. So, this means we can talk about kernels and
images!

```
    Ker(f3)----→Ker(f2)--→Ker(f1)
       |         |          |
       ↓         ↓          ↓
       G3--∂----→G2----∂---→G1--→ 0 
       |         |          |
       f3        f2         f1
       ↓         ↓          ↓  
    Im(f3)--∂--→Im(f2)--∂-→Im(f1)
```

```
F → E → V → {0}
{0} → {e} → {v} → {0} 
```

The _Snake Lemma_ gives us a mapping $d: Ker(f1) \rightarrow Im(f3)$ such that
this long exact sequence is saatisfied:


## What do we wish to compute?

- Now that we've agreed that this family of maps $\{ f_i : G_i \rightarrow H_i \}$
  ought to be structured maps, the next question is "OK, now what? What does
  one want to determine"? Ideally, we would get a _new_ chain complex which
  I tacitly denote as $\{ f(G_i) \}$, consisting of the image of $G_i$ inside
  $H_i$ and the ability to determine its structure.

- However, this is the boring bit. We don't _really_ care about the _chain complex_ $\{ f(G_i) \}$ per se.
  What we _actually_ care about are the homology groups! So we would really like a tool
  that allows us to compute $H_i(f(G))$ in some convenient fashion.


# Kernel, cokernel, image

Consider a linear map $T: X \rightarrow Y$. we want to solve for $\{ x : T(x) = y0 \}$. 
- If we have an $x0$ such that $T(x0) = y0$, then see that $T(x0 + Ker(T)) = T(x0) + T(Ker(T)) = y0 + 0 = y0$.
  So the kernel gives us our degrees of freedom: how much can we change around without
  changing the solution.
- Now consider the cokernel: $Coker(T) = Y / Im(T)$. If we want to find 
  a solution $\{ x : T(x) = y0 \}$. If we have $y0 \neq 0 \in Coker(T)$, then
  the solution set is empty. The cokernel tells us the _obstruction_ to a 
  solution.

# The commutator subgroup

Define the commutator of $g, h$ as $[g, h] \equiv ghg^{-1}h^{-1}$.
The subgroup **generated** by all commutators
in a group is called as the commutator subgroup. Sometimes denoted as
$[G, G]$.

- We need to consider generation. Consider the free group on 4 letters
  $G = \langle a, b, c, d \rangle$. Now $[a, b] \cdot [c, d]$ has no
  expression in terms of $[\alpha, \beta]$. 

- In general, the elements of the commutator subgroup will be products
  of commutators. 

- It measures the degree of non-abelian-ness of the group. $G/[G, G]$ is
  the largest quotient of $G$ that is abelian. Alternatively, $[G, G]$
  is the smallest normal subgroup we need to quotient by to get an abelian
  quotient. This quotienting is called abelianization.


# Simplicity of A5 using PSL(2, 5)

#### Presentation of A5

We take as faith A5 has the presentation:

```
<a, b | a^2 = b^3 = (ab)^5 = 1>
```

If I find a nice proof of this isomorphism, or some other way to derive
the fact that `PSL(2, 5)` is isomorphic to `A5`, I will fill this up.

#### Step 1: `PSL(2, 5)` is isomorphic to `A5`

PSL(2, 5) consists of projective Mobius transformations with function composition
as the group operation. Here, we freely use the linear algebraic relationship
between transformations of the form `(az + b)/(cz + d)` and matrices `[a b; c z]`.


$$
\begin{aligned}
&a, b, c, d \in \mathbb Z5, ad - bc = 1 \\
&f: \mathbb Z5 \cup \{ \infty \} \rightarrow \mathbb Z5 \cup \{ \infty \} \\
&f(z) \equiv (az + b)/(cz + d) \\
\end{aligned}
$$

- We allow coefficients for the Mobius transform to be from $\mathbb Z5$,
  and we allow the domain and codomain of the function to be projectivized: so we
  add a point at infinity to $\mathbb Z5$.

- We construct a map from $PSL(2, 5)$ to $A5$ and then show that this map is
  an isomorphism. We exploit the presentation of $A5$ to find elements
  $a, b \in PSL(2, 5)$ such that $p^2 = q^3 = (pq)^5 = I$. We can link this
  to the presentation of A5 which requires precisely those relations.

- For an element of order 3, we pick `q(z) = 1/(1-z)`. 

$$
\begin{aligned}
&q(z) = 1/(1-z) \\
&q(q(z)) = \frac{1}{1 - \frac{1}{1-z}}  \\
&         = \frac{1}{\frac{(1-z) - 1}{1-z}} \\
&         = \frac{(1-z)}{-z} = \frac{(z-1)}{z}  \\
&         = 1 - \frac{1}{z} \\
&q(q(q(z))) = 1 - \frac{1}{q(z)} = 1 - (1 - z) = z
\end{aligned}
$$

- I don't know of a principled way to arrive at this choice of `q(z)`, except
  by noticing that `az + b` does not work, and neither does `1/z`. The next
  simplest choice is things of the form `1/(1-z)`. If there is a nicer way,
  I'd love to know.

- For a function of order $5$, we have to use the structure of the finite field
  somehow. We can consider the function `r(z) = 1 + z`. On repeating this 5
  times, we wil get `5 + z = z`. However, it is hard to connect `r(z) = 1 + z`
  to the  previous choice of `q(z) = 1/(1-z)`. 

- We use the same idea for `r(z)`, and pick `r(z) = z - 1`. This will allow
  us to accumulate `-1`s till we hit a `-5 = 0`.

- To get `r(z) = (z - 1)`, we need to compose `q(z) = 1/(1-z)` with `p(z) = -1/z`.
  This `p(z)` is of order 2.

To recap, we have achieved a set of functions:

```
p(z) = -1/z [order 2]
q(z) = 1/(1-z) [order 3]
r(z) = (z - 1) [order 5]
r = -1/[1/(1-z)] = p . q
```


That is, we have found a way elements in `PSL(2, 5)` such that `p^2 = q^3 = (pq)^5 = 1`.
This gives us the [surjective] map from `PSL(2, 5)` into `A5`.


- By a cardinality argument, we know that the size of `PSL(2, 5)` is 60. Hence,
  since `PSL(2, 5)` and `A5` have the same number of elements, this map
  must be a bijection.

#### Step 2: PSL(2, 5) is simple

TODO! I'm still reading Keith Conrad's notes.

#### References

- [Keith Conrad, Simplicity of PSL](https://kconrad.math.uconn.edu/blurbs/grouptheory/PSLnsimple.pdf)
- [Math.se: isomorphism from PSL to A5](https://math.stackexchange.com/questions/2051241/showing-psl2-5-is-isomorphic-to-a-5)


# A5 is not solvable

There are many accounts of why A5 is not solvable on the internet. I'm recording my
version here, because the proof involves certain ad-hoc choices which I want
to make sure I can find off-hand in the future.
We'll show that `[A5, A5] = A5`, thereby proving that `A5` not solvable.
This is useful for Galois theory, where we want to show tha `A5` cannot be
built as extensions of smaller cyclic groups. 

### Notation

I'll be using non-standard notation: `(12);(34)` means 'perform `(12)` then perform `(34)`'.
I find this notation makes permutation composition intuitive for me. The `;` 
is evocative of C-style languages, where we are ending a statement. I will
be consistently using $[g, h] \equiv ghg^{-1}h^{-1}$ to denote the commutator.

### permutations in A5

First, recall that `A5` only has the _even_ permutations in `S5`. So it can
have zero, two, four, involutions that build it up. There can't be more after
simplification, since `S5` ony has `5` elements --- the largest sequence
of transpositions we can do is `(12)(23)(34)(45)`. So, in `A5`, we have:

- The identity permutation `()`.
- The transpositions `(ij)(kl)` where `{i, j}` and `{k, l}` do not overlap.
  From these, we get the 2-cycles.
- The transpositions `(ij)(kl)` where `{i, j}` and `{k, l}` overlap. Here we
  cannot have `{i, j} = {k, l}` since then we will just have a single transposition.
  So, let us assume that we have `j = k`. If we have any other equality, we
  can always flip the transpositions around to get to the normal form `j = k`:

```
(23);(12)
= (32);(12) [(23) = (32)]
= (32);(21) [(12) = (21)]
```

- In this case, we can show that such a transposition _must_ be a cycle:

```
[a b c] -(32)->
[a c b] -(21)->
[c a b]
```

- Intuitively, we are pushing the element `c` backward, and allowing the
  other elements to take its place using the permutation `(23);(12)`.

- So, from the transpositions of the form `(ij)(kl)` where `{i, j}` and
  `{k, l}` intersect, we get the 3-cycles.

- Finally, we can have the transpositions of the form `(12)(23)(34)(45)`. 
  It must be of this form, or some permutation of this form. Otherwise,
  we would have repeated elements, since these transpositions are packed
  "as close as possible". These generate the 5-cycles.

### A5 is generated by 3-cycles.

We claim that we can write any element of $A5$ in terms of 3-cycles.

- The disjoint transpositions of the type `(34)(12)` can be written as
  `(34)(23)(23)(12)`, because `(23)(23) = e`. This can be further
  broken down into `((34)(23)) ((23)(12))` which is two 2-cycles: 
  `(234); (123)`.

- The non-disjoint transpositions of the type `(32)(21)` _are_ 3-cycles:
  `(32)(21) = (123)`.

- 3-cycles are 3-cycles.

- Any 5-cycle an be written as two 3-cycles: `(45)(34)(23)(12)` can be written
  as `((45)(34))((23)(12))` which is two 3-cycles: `(345); (123)`.

So, if we figure out how to write 3-cycles in terms of commutators, we win.
Because the commutator subgroup of $A_n$ is generated by elements that
can be written as $[g, h]$. If we can show that 3-cycles can be written
as $[g, h]$, then every other element has a representation in terms of
these 3-cycles, and are therefore elements of the commutator subgroup.


### 3-cycles can be generated as commutators of 2-cycles:

- We saw how we can write a 3-cycle of the form `C = (123)` as `(32)(21)`.
  We wish to write this as the commutator of two elements `g, h`: $C = [g, h]$.

- The idea is that we have the leftover elements `4, 5` that are unsused by `C` in `A5`
  [here is where `5` is important: `3 + 2 = 5`, and we need two leftover elements].

- We can use these two leftover elements `4, 5` to build elements `g, h`
  which cancel off, leaving us with `(32)(21)`. We start with `g = (32)___`,
  `h = (21)___` where the `___` is to be determined:


```
(32)___||(21)___||___(32)||___(21)
  g        h        g^-1    h^-1
```

- It is important that `g` and `h` contain another tuple, because they are
  members of `A5`! We need them to be permutations having `2, 4, 6` transpositions.
- We insert `(4 5)` everywhere. These `(4 5)` can slide over the `(2 1)` and thereby
  harmlessly cancel:


```
(32)(45)||(21)(45)||(45)(32)||(45)(21)
  g        h           g^-1       h^-1
```

- Simplify the above expression by moving the `(45)` over `(21), (32)`:

```
(32)||(21)(45)(45)||(32)||(45)(45)(21)
  g      h          g^-1    h^-1
```

- cancel the `(45)(45) = e`:

```
(32)||(21)||(32)||(21)
  g   h    g^-1   h^-1
```

                                                
So we are left with `(32);(21);(32);(21)`. This is the _square_ of what
we really wanted, `C = (32);(21)`. However, since `C` is a 3-cycle, we know
that $C = C^{-2}$. So, we can start with $C^{-1}$, use our trick to generate
$C^{-2}$ which is equal to $C$. Since this works for any $C$, we have shown
that we can generate 3-cycles from commutators of `A5`.

### Alternate viewpoint on above proof

We have a 3-cycle `s = (a b c)`. We first first a square root `t` such 
that `t*t=s`. To do this, we make `t` have the cycles of `s` spread out
in gaps of 2:

```
t = (a _ _)
t = (a _ b) [+2]
t = (a c b) [+2, modulo]
```

It is hopefully clear that `t*t = s`:

```
t = (a c b)
t*t: apply the cycle twice.
t*t = a -(skip c) -> b
      b -(skip a) -> c
      c ->(skip b) -> a
    = (a b c) = s
```

Now, we will write `s = t*t` and then find the commutator decomposition from
it:

```
s = t*t
  = (abc)(abc)
  = (cb)(ba)(cb)(ba)
  = (cb)|(ba)|(cb)|(ba)
  = (cb)|(ba)|(cb)|(ba)
     g     h   g-1   h-1
```

But there's a problem: this `g` and `h` do not belong to `A5`, they belong
to `S5`. This is fixed by using a random `(pq)` which we know _will exist_.

### Recap: How have we shown that A5 is not solvable?

what have we shown?

- 3-cycles can be written as $[g, h]$ for $g, h \in A_5$. Alternatively,
  we can say that 3-cycles belong to the commutator subgroup of $A_5$,
  since they can be written as commutators.
- any element in $A5$ can be written as the composition of 3-cycles.
- Hence, any element in $A5$ can be written as the composition of commutators.


In my mind, I think of it as:

```
arbitrary g
= (3-cycle-1)(3-cycle-2)....(3-cycle-n)
= [g, h][g2, h2]....[gn, hn]
= member of [A5, A5]
```

Recall that $[A5, A5]$ is **generated** by commutators. It not only contains
elements of the form $[g, h]$, but also all products of the form $[g, h][g', h']$.
So we don't need to exhibit how to write a 5-cycle as some $[g, h]$. We just
need to exhibit how to write as the product of commutators, which we have
now shown.


### Solvable implies simple  

We can consider the other definition of simple. Let there be a
chain of normal subgroups $G = N[0] \leq N[1] \leq N[1] \leq \dots \leq N[m] = e$,
such that each quotient $N[i] / N[i+1]$ is abelian. Then, if $G$ is 
simple, this chain can only be $G = N[0] \leq N[1] = e$.

- If we want the quotient $G/N$ to be abelian, then we need the commutator
  subgroup $[G, G]$ to be a a subset of $N$.

- In our case, $[A_5, A_5] = A_5$. So if we want to remove the non-abelian-ness
  of A5, we need to quotient by the _whole_ of $A5$. 

- This means that any such chain will immediately collapse to $e$.

- So, it's impossible to build $A5$ using 'cycling components' starting from $\{e\}$.
  Viewed from the field theoretic perspective, this means that it's impossible
  to reach a polynomial whose splitting field has galois group A5 by simply 
  appending cycles.

### Nagging doubt: Did we depend on our numbering of cycles?

In all my proofs, I had used _one_ 3-cycle, or 5-cycle, or 2-cycle to
argue that it all works out. Is this really legal? Perhaps the argument
written for the 3-cycle `C = (123)` will break down for `D = (321)`. Fear not!

- We will show that all 3-cycles are conjugate to each other. So, we can always
  relabel a 3-cycle within A5.
- It is easy to note that $g[k, l]g^{-1} = [gkg^{-1}, glg^{-1}]$. This shows
  that the commutator subgroup is closed under conjugation. It better be,
  because it ought to be normal for us to take quotients from it.
- Combining these facts, if we show that `(123)` is in `[A5, A5]`, then some
  other cycle `(ijk)` can be conjugated to `(123)`. Since the commutator
  subgroup is closed under conjugation, we have that `(ijk)` is a member
  of `[A5, A5]`.


### All 3-cycles are conjugate to each other in A5.

- Given two 3-cycles `C=(abc)` and `D=(pqr)`, at least one of `a, b, c` must
  be equal to one of `p, q, r`. Since each `a, b, c` is unique, and each
  `p, q, r` is unique, for them to not overlap, we would need 6 elements. 
  But we only have 5, so there must be some overlap:

```
a   b   c
1 2 3 4 5
  p   q r
```

So, we will perform our proof assuming there is 1 overlap, 2 overlap, 3 overlap.
Recall that if `C = (a b c)` is a cycle and `s` is a permutation, then the action
of conjugating `C` with `s` produces a permutation `(s(a) s(b) s(c))`. We will
prove our results by finding an `s`, and then **making `s` even**. This is
the difficult part of the proof, since we need to show that all 3-cycles are
conjugate _in A5_. We will write `s` as two distinct transpositions, which will
guarantee that it belongs to `A5`.

                    
- Case 1: `(abx)` and `(pqx)` have a single element `x` in common:

```
C = (abx)
D = (pqx)

s: send a to p, b to q
s = (ap)(bq)
C = (abx) -conj s-> (pqx) = D
```

- Case 2: `(axy)` and `(pxy)` have two elements in common, `x` and `y`. Naively,
  we would pick `s: send x to y`. But this is odd, so this isn't a member of
  `A5`. To make it even, we rearrange `D = (pxy)` as `D = (yxp)`. This lets us
  go from `C` to `D` by relabelling `a` to `y`, `y` to `p`. This permutation
  is even since it has two distinct transpositions.

```
C = (axy)
D = (pxy) = (yxp) [cyclic property]

s: send a to y, y to p
s = (ay)(yp)

C = (axy) -conj s-> (yxp) = D
```

- Case 3: `(xyz)` and `(xyz)` have all three elements in common, `x`, `y`, `z`.
  Here we can conjugate by identity and we are done.

### Why do we care about solvable?

- Roughly, we can look at the solvability criterion as giving us a way to build
  our group $G$ from a series of extensions $N[1], N[2], \dots$. This extension
  is special, because at each step, we are adding a cyclic group.

- When we want to write a solution using nth roots, we can only add the
  nth roots of unity, a "cyclic" component. So, any element we can reach
  by using nth roots ought to be able to be written down as an extension of
  cyclic elements. 

### SAGE code to play around with commutators of `A5`:

- Create a dictionary `m` which maps each element of `A5` to the commutators
  that create it.

```py
from collections import defaultdict
m = defaultdict(set)
A5 = AlternatingGroup(5)
S5 = SymmetricGroup(5) # if necessary
for g in A5:
    for h in A5:
        m[g * h * g^(-1) * h^(-1)] |= { (g, h) }

# all 60 elem can be written in terms of commutators
print("number of elem generated as commutator: " + str(len(m.keys())))

# Show how to access elements of A5 and their commutator representation
cyc5 = A5("(1, 2, 3, 4, 5)")
cyc3 = A5("(1, 2, 3)")
cyc2disj = A5("(1, 2) (3, 4)")

print(m[cyc5])
print(m[cyc3])
print(m[cyc2disj])
```

### Writing each element in `A5` directly as a commutator

We have shown how to write 3-cycles as the commutator of 2-cycles. We will now
show how to do this for disjoint 2-cycles and 5-cycles as a matter of
enlightenment.

### Writing disjoint 2-cycles as commutator


First, we will write a two disjoint two cycles as the square root of
a 4-cycle. We will then show how to write this 4-cycle as two
3-cycles.

```
s = (12)(34) 
```

Note that if we choose `t = (abcd)`, then `t*t` will exchange the first
and third elements `a <-> c`, and the second and fourth elements `b <-> d`.
So, if we choose:

```
t = (1324)
t*t = (12) (34)
```

Next, we need to write this `t*t` as `[g, h]` for `g, h` from `A5`.

```
t*t = (1324)(1324)
    = (42)(23)(31);(42)(23)(31)
    = (42)(23)(31);(42)(23)(31)
    = (42)(23)(31);(23)(23);(42)(23)(31)
                   ^^^^^^^^ inserted
    = (42)(23)|(31)(23)|(23)(42)|(23)(31)
          g   |    h   |   g'   |   h'

    = [(42)(23), (31)(23)]
```

Where both `(42)(23)`, and `(31)(23)` are members of `A5`.

### Writing 3-cycle as commutator

In the description of showing how to generate 3-cycles, we do this
explicitly.


### Writing 5-cycle as commutator


Let `s = (1 2 3 4 5)`. we once again find a square root of `s`. To build
this, we will build an element with the elements of `s` written with
gaps of `2`:

```
t = (1 _ _ _ _) 
  = (1 _ 2 _ _)  [+2 index]
  = (1 _ 2 _ 3)  [+2 index, wrap]
  = (1 4 2 _ 3)  [+2 index, wrap]
  = (1 4 2 5 3)  [+2 index, wrap]
```

It should be clear how `t*t = s`: When we take `s = t*t`, the resulting permutation `s`
will move an element `j = t[i]` to `k = t[i+2]`. But we have built `t` such 
that `t[i+2] = s[i+1]`. So we will move the element according to how `s` pleases:

```
t = (1 4 2 5 3)
t*t = 1 -> (4 skip) -> 2 
      2 -> (5 skip) -> 3
      3 -> (1 skip) -> 4
      3 -> (2 skip) -> 5
      5 -> (3 skip) -> 1
t*t = (1 2 3 4 5) = s
```

We will now use `t*t` to write the commutator:

```
s = t*t
  = (35)(52)(24)(41);(35)(52)(24)(41)  
  =
  =
  =
  = (1, 2)(3, 5)|(1, 5)(2, 4)|(3, 5)(1, 2)|(2, 4)(1, 5)

  = (1, 2)(3, 5)|(1, 5)(2, 4)|(3, 5)(1, 2)|(2, 4)(1, 5)
         g             h          g^{-1}       h^{-1}
```


### To think: relationship between square roots and commutators?


# Complex orthogonality in terms of projective geometry

If we think of complex vectors $p = [p_1, p_2]$, $q = [q_1, q_2]$ as belonging to
_projective space_: that is, $p \simeq p_1/p_2$, and $q \simeq q_1 / q_2$, we can
interpret orthogonality as:

$$
\begin{aligned}
p . q = 0 \\
p_1 \overline q_1 + p_2 \overline q_2 = 0 \\
p_1 / p_2 = - \overline{q_2} / \overline{q_1} \\
p = -1/\overline{q} = -q/|q| \\
\end{aligned}
$$


<img src="./static/riemann-sphere-conjugate.png">
If we imagine these as points on the Riemann sphere, TODO

#### References

- Visual Complex analysis by Tristan Needham

# Arithmetic sequences, number of integers in a closed interval

This is a cute reason for why when we count the number of integers in
the closed interval `[a, b]`, it's going to be `b - a + 1`. We setup
an arithmetic sequence with initial term `a`, common difference `1`. Now
we know that the `n`th term is `a + (n-1)d`. So, we get

```
a + (n-1)d = b
(n-1).1 = b - a
n = b - a + 1
```

#  [The arg function, continuity, orientation](#the-arg-function-continuity-orientation)

Let us think of the function $arg: \mathbb C \rightarrow \mathbb R$ as a multi
valued function, which maps each complex number to the set of possible
valid angles that generate it:

$$
arg(z) \equiv \{ t \in \mathbb R : |z|e^{i (\pi/2)t} = z  \}
$$

We plot the function here:

<img src="./static/arg-multi-value-circle.png">
<img src="./static/arg-multi-value-plot.png">


- Note that for every value $z \in C$, we get a _set_ of values associated
  to it.


#### Recovering single valued-ness

Now, the question is, can we somehow automatically recover single
valued-ness? kind of, by stipulating that for any given curve $c: [0, 1] \rightarrow \mathbb C$, 
the function $arg \circ c: [0, 1] \rightarrow \mathbb R$ is _continuous_. 

Let's try to investigate what happens if we move from `right` towards `bot`,
arbitrarily stipulating ("picking a branch") that `arg(right) = 0` as a sort
of basepoint.  

<img src="./static/arg-multi-value-branch-lower.png">

- Note that we were _forced_ to pick the value `arg(bot) = -1` from our
  considerations of continuity. No other value extends continuous from the
  right to the bottom.
- Also note that we got a *smaller* value: we move from `0 -> -1`: we decrease
  our value as we move clockwise.

This prompts the natural question:

> what happens if we move in the opposite direction?

#### Counter-clockwise movement

- Let's move counter-clockwise from `right`, arbitrarily picking the branch
  `arg(right) = 0` as before. This gives us:


<img src="./static/arg-multi-value-branch-upper.png">


- Note that once again, we were _forced_ to pick `arg(top) = 1` by continuity
  considerations.

- Also note that this time, we got a *larger* value: we move from `0 -> 1`: we
  increase our value as we move counter-clockwise


#### Multiple winding

the true power of this multi-valued approach comes from being able to handle
_multiple_ windings. Here the real meaning of being a multi-valued function shows
through. If we decide to go through the the loop _twice_, as:

```
bot -> right -> top -> left -> bot -> right -> top -> left
-1  -> 0     -> 1   -> 2    -> 3   -> 4     -> 5   -> 6
```

That is, we end up with the value `6`, which can only b



#### Orientation from continuity

There's something really elegant about being able to recover a notion of
"orientation" by simply:

1. Allowing multi-valued functions.
2. Forcing continuity constraints.
3. Interpreting increase/decrease in the value of the function.


#### Discretizing, gaining more insight

I was personally dis-satisfied with the above explanation, because it seemed
weird that we would need to depend on the history to define this function. We
can formalize this notion of history. Let's first discretize the situation,
giving us:

<img src="./static/discrete-multi-valued.png"/>

- We are on the space of the spokes, given by `a, b, c, d, e, f, g, h`.
- We have a function `f: Spoke -> Val` whose values are given on the spokes.
- We are interested in the path `p: Time -> Spoke`, `p = [a, b, c, d, e, f, g, h, a]`.
- If we evaluate the function `f` on the path `p`, we get `out: Time -> Val`, `out = [0, 1, 2, 3, 4, 5, 6, 7, 0]`.
- We have a "jump" from `7` to `0` in `out` as we cross from `h` to `a`. This is a
  discontinuity in `out` at time `7`.
- We want to fix this, so we make the function `f` multi-valued. 

<img src=./static/discrete-multi-valued-assign-multi-value.png>

- We assign both values `8` and `0` to the spoke `a`. We wish to define
  the evaluation of `f: Spoke -> 2^N` relative to path `p`. At time `t`, point
  `p[t]`, we pick any value in `f(p[t])` that makes `out[t]` continuous.

- So in this case, when we start, we have two choices for `out[0] = f(p[0]) = f(a)`: `0` and `8`.
  But we know that `out[1] = f(p[1]) = f(b) = 1`. Hence, for `out[0]` to be continuous, we must
  pick `out[0] = 0`.

- Similarly, at `out[8]` we have two choices: `0` and `8`. But we have that
  `out[7] = 7`, hence we pick `out[8] = 8`.

- Note that we say 'we pick the value' that makes `out` continuous.  This is
  not really rigorous. We can fix this by re-defining `f` in such a way
  that `f` is not `Spoke -> Val`, but rather it knows the full path:
  `f': (Time -> Spoke) -> Val`.

#### Making the theory path-dependent

We originally had:

```
path: Time -> Spoke
f: Spoke -> 2^Val -- multi-valued

-- | morally, not mathematically.
out: Time -> Val
out t = choose_best_value (f(path[t]))
```

But there was a vagueness in this `choose_best_value`. So we redefine it:

```
path: Time -> Spoke
f': (Time -> Spoke) -> Time -> Val
f'(path, tcur) = 
  argmax (\v -> |v - path[tcur-1]| + |v - path[tcur+1|)
         f(path[tcur])

out: Time -> Val
out = f'(path)
```

- The function `f'` that defines the value of the path has full
  access to the path itself!                                                      
- At time `tcur`, it attempts to pick the value in `f(path[tcur])` which
  makes the discontinuity as small as possible. It picks a value `v` from the
  possible values of `f(path[tcur])`. This `v` minimises the 
  of the distances from the previous time point (`|v - path[tcur-1]`), 
  and the distance from the next time point (`|v - path[tcur + 1]`).
- This provides a rigorous definition of what it means to "pick a value in the branch".
  This can clearly be extended to the continuous domain.

# Odd partitions, unique partitions

A well known identity in combinatorics is that the partitions `n = l1 + l2 + ... + ln`
where each `li` is odd is in bijectiion with a partition where each `li` is unique.
I really liked this bijection.


```
(15, 9, 9, 5, 5, 5, 3, 3, 3, 1, 1, 1, 1) [all odd]
=
(15, 9x2, 5x3, 3x3, 1x4) [group]
= 
(15x1, 9x2, 5x(2+1), 3x(2+1), 1x4) [expand base-2]
=
(15, 18, [10, 5], [6, 3], 4) [all unique]
```

# Continued fractions, mobius transformations

read [`ekmett/fractions`](https://github.com/ekmett/fractions) properly
and write detailed log about it, and the related math.


# Permutations-and-lyndon-factorization

For a string `s`, the Lyndon factorization writes `s` as the concatenation of
substrings `t1`, `t2`, ..., `tn`, such that:

- each `ti` is a simple word. That is, it is lexicographically smaller than all
  of its cyclic shifts.
- the words are in non-increasing order: `t1 >= t2 >= t3 ... >= tn`.

For example, given the word `banana`, the lyndon factorization is:

```
b; an; an; a; 
```

We can define a notation for writing permutation as:
- Each term in a cycle is written in _ascending_ order.
- Cycles are written in _descending_ order of the first element.
- Single element are ignored.

```
(7) (2 3) (1 4 5)
```

If we treat it as a string `723145`,
the duval algorithm provides the decomposition:

```
7; 23; 145; 
```

So, we can treat the duval algorithm as a way to recover the permutation given
the raw string. It's a nice way to _remember_ the definition of lyndon
decomposition if nothng else.

# Graphs are preorders

I wanted to record this fact for myself, so that I have reason to come back
to it as I learn more preorder theory. Perhaps there are certain graph theoretic
phenomena that make more sense when looked at from a preorder point of view.

# Crash course on DCPO: formalizing lambda calculus

In lambda calculus, we often see functions of the form $\lambda x \rightarrow x(x)$. We would
like a way to associate a "natural" mathematical object to such a function. The
most obvious choice for lambda calculus is to try to create a set $V$ of values
which contains its own function space: $(V  \rightarrow V) \subseteq V$. This
seems to ask for a set whose cardinality is such that $|V|^|V| = |V|$, which is
only possible if $|V| = 1$, ie $V$ is the trivial set $\{ * \}$.
However, we know that lambda calculus has at least two types of functions:
functions that terminate and those that don't terminate. Hence the trivial set
is *not* a valid solution.

However, there is a way out. The crucial insight is one that I shall explain by
analogy:

- We can see that the cardinality of $\mathbb R$ is different from the cardinality
   of the space of functions over it, $\mathbb R \rightarrow \mathbb R$.
- However, "the set of all functions" isn't really something mathematicians consider.
   One would most likely consider "the set of all _continuous_ functions" $\mathbb R \rightarrow \mathbb R$.
-  Now note that a function that is continuous over the reals is [determined by its values at the rationals](https://math.stackexchange.com/questions/379899/why-is-every-continuous-function-on-the-reals-determined-by-its-value-on-rationa).
   So, rather than giving me a continus function $f: \mathbb R \rightarrow \mathbb R$, you can
   give me a continuous function $f': \mathbb Q \rightarrow \mathbb R$ which I can Cauchy-complete,
   to get a function $\texttt{completion}(f') : \mathbb R \rightarrow \mathbb R = f$.
-  Now, [cardinality considerations](https://math.stackexchange.com/a/271641/261373)
   tell us that:

$$|\mathbb R^\mathbb Q| = (2^{\aleph_0})^{\aleph_0} = 2^{\aleph_0 \cdot \aleph_0} = 2^\aleph_0 = |R|$$

- We've won! We have a space $\mathbb R$ whose space of _continuous_ 
   functions $\mathbb R \rightarrow \mathbb R$ is isomorphic to $\mathbb R$.
- We bravely posit: all functions computed by lambda-calculus are continuous!
   Very well. This leaves us two questions to answer to answer: (1) over what space?
   (2) with what topology? The answers are (1) a space of partial orders 
   (2) with the [Scott topology](https://en.wikipedia.org/wiki/Scott_continuity)



### Difference between DCPO theory and Domain theory

- A DCPO (directed-complete partial order) is an algebraic structure that can
  be satisfied by some partial orders. This definition ports 'continuity'
  to partial orders.

- A domain is an algebraic structure of even greater generality than a DCPO.
  This attempts to capture the fundamental notion of 'finitely approximable'.

- The presentation of a domain is quite messy. The nicest axiomatization of
  domains that I know of is in terms of [information systems](https://en.wikipedia.org/wiki/Scott_information_system).
  One can find an introduction to these in the excellent book 
  ['Introduction to Order Theory' by Davey and Priestly](https://www.cambridge.org/core/books/introduction-to-lattices-and-order/946458CB6638AF86D85BA00F5787F4F4)


### Computation as fixpoints of continuous functions

### CPOs

- Given a partial order $(P, \leq)$. assume we have a subset $Q \subseteq P$. 
  A least upper bound $u$ of $Q$ is an element that is the smallest element in $P$
  which is larger than every element in $Q$.

- A subset $Q$ of $P$ is called as a chain if its elements can be put into order.
  That is, there is a labelling of elements of $Q$ into $q1, q2, \dots, qn$ such
  that $q1 \leq q2 \leq \dots \leq qn$.

### CCPOs

- A partially ordered set is called as a _chain complete partial order_ if
  each chain has a least upper bound.

- This is different from a lattice, where each _subset_ has a least upper bound.

- Every ccpo has a minimal element given by $completion(\emptyset) = \bot$.

- TODO: example of ccpo that is not a lattice


### Monotone map

- A function from $P$ to $Q$ is said to be monotone if $p \leq p' \implies f(p) \leq f(p')$.
- Composition of monotone functions is monotone.
- The image of a chain wrt a monotone function is a chain.
- A monotone function **need not preserve least upper bounds**. Consider:

$$
f: 2^{\mathbb N} \rightarrow 2^{\mathbb N}
f(S) \equiv
\begin{cases}
S & \text{$S$} is finite \\
S U \{ 0 \} &\text{$S$ is infinite}
\end{cases}
$$

This does not preserve least-upper-bounds. Consider the sequence of elements:

$$
A_1 = \{ 1\}, A_2 = \{1, 2\}, A_3 = \{1, 2, 3\}, \dots, A_n = \{1, 2, 3, \dots, n \}
$$

The union of all $A_i$ is $\mathbb N$.
Each of these sets is finite. 
Hence $f(\{1 \}) = \{1 \}$, $f(\{1, 2 \}) = \{1, 2\}$ and so on. Therefore:

$$
f(\sqcup A_i) = f(\mathbb  N) = \mathbb N \cup \{ 0 \}\\
\sqcup f(A_i) = \sqcup A_i = \mathbb N
$$

### Continuous function

- A function is continous if it is monotone and preserves all LUBs. This is
  only sensible as a definition on ccpos, because the equation defining it is:
  `lub . f  = f . lub`, where `lub: chain(P) \rightarrow P`. However, for `lub`
  to always exist, we need `P` to be a CCPO. So, the definition of continuous
  only works for CCPOs.
- The composition of continuous functions of chain-complete partially
  ordered sets is continuous. 

### Fixpoints of continuous functions

The least fixed point of a continous function $f: D \rightarrow D$ is:

$$\texttt{FIX}(f) \equiv \texttt{lub}(\{ f^n(\bot) : n \geq 0 \})$$


### $\leq$ as implication

We can think of $b \leq a$ as $b \implies a$. That is, $b$ has more information
than $a$, and hence implies $a$.

### References

- Semantics with Applications: Hanne Riis Nielson, Flemming Nielson.
- [Lecture notes on denotational semantics: Part 2 of the computer science Tripos](https://www.cl.cam.ac.uk/~gw104/dens.pdf)
- [Outline of a mathematical theory of computation](https://ropas.snu.ac.kr/~kwang/520/readings/sco70.pdf)
- [Domain theory and measure theory: Video](https://www.youtube.com/watch?v=UJrnhhRi2IE)



# Parallelisable version of maximum sum subarray

I learnt of a "prefix sum/min" based formulation from
[the solution to question D, codeforces educational round 88](https://codeforces.com/blog/entry/78116).

The idea is to start with the max prefix sum $opt$ (for optima)
as the difference of right minus
left:

$$
\begin{aligned}
&opt \equiv \max_{(L, R)}: \sum_{L \leq i \leq R} a[i] \\
&= \max_R: \left(\sum_{0 \leq i \leq R} a[i] - \min_{L \leq R}: \sum_{0 \leq i \leq L \leq R} a[i] \right) \\
\end{aligned}
$$

Which is then  expressed as: 
$$
\begin{aligned}
&asum[n] \equiv \sum_{0 \leq i \leq n} a[i]  \\
&opt = \max_R: (asum[R] - \min_{(L \leq R)}: asum[L])
\end{aligned}
$$

$$
\begin{aligned}
&aminsum[n] \equiv \min_{0\leq i \leq n} asum[i] \\
&opt = \max_R: (asum[R] - aminsum[R])
\end{aligned}
$$

Since $asum$ is a prefix-sum of $a$, and $amin$ is a prefix min of
$asum$, the whole thing is $O(n)$ serial, $O(\log n)$ parallel.
In haskell, this translates to:

```hs
let heights deltas = scanl (+) 0 deltas
let lowest_heights = scanl1 min . sums
let elevations xs = zipWith (-) (sums xs) (lowest_heights xs)
-- elevations [1, 2, 3, -2, -1, -4, 4, 6]
-- > [0,1,3,6,4,3,0,4,10]
let max_elevation deltas = max (elevation deltas)
best = max_elevations [1, 2, 3, -2, -1, -4, 4, 6]
```

`lowest_heights` keeps track of the sea level, while the
`elevations` computes the elevation from the lowest height. 
The maximum sum subarray will correspond to treating the elements of the array
as deltas, where we are trying to find the highest elevation. since elevation
is an integral (sum) of the deltas in height.


<img src="./static/max-sum-subarray.png">

# Thoughts on implicit heaps

Some musings I had on the ability to represent heaps as arrays, and in general,
the benifits of knowing the total number of elements.

- Knowing the total number of elements allows us to pre-ordain a memory layout.
  We can decide that for a node at index `i`, left child is at `2*i`, and
  right child is at `2*i+1`. This gives parent at `i//2`.

- This immediately gives us `O(1)` access to parent (`i//2`) and sibling `(i^1)`
  with no extra memory usage.                                                                                                                             S

- This cannot be done for data structures where we need to splice into
  the middle: For example, an implicit treap where we wish to splice sub-arrays
  together.

- On coding a heap, we can decide whether to use the left or right sibling by
  using `next = 2*i + predicate`. If `predicate = false = 0`, we will pick
  the left child, otherwise the right child. This allows us to compress
  some annoying if/then/elses into one-liners.

# Discriminant and Resultant

I had always seen the definition of a discriminant of a polynomial $p(x)$ as:
$$
Disc(p(x)) \equiv a_n^{(2n - n)} \prod_{i< j} (r_i - r_j)^2
$$

While it is clear _why_ this tracks if a polynomial has repeated roots
or not, I could never motivate to myself or remember this definition.

I learnt that in fact, this comes from a more general object, the **resultant**
of two polynomials $P(x), Q(x)$, which provides a new polynomial $Res(P(x), Q(x)$
which is zero iff $P, Q$ share a common root. Then, the discriminant is
defined as the resultant of a polynomial and its derivative. This makes far more
sense:

- If a polynomial has a repeated root $r$, then its factorization will
  be of the form $p(x) = (x - r)^2 q(x)$. The derivative of the polynomial 
  will have an $(x-r)$ term that can be factored out. 

- On the contrary, if a polynomial only has a root of degree 1, then the
  factorization will be $p(x) = (x - r) q(x)$, where $q(x)$ is not divisible by $(x-r)$.
  Then, the derivative will be $p'(x) = 1 \cdot q(x) + (x - r) q'(x)$. We cannot take $(x - r)$ common
   from this, since $q(x)$ is not divisible by $(x-r)$.

This cleared up a lot of the mystery for me.

### How did I run into this? Elimination theory.

I was trying to learn how elimination theory works: Given a variety
$V = \{ (x, y) : Z(x, y) = 0 \}$, how does one find a rational parametrization
$(p(t), q(t))$ such that  $Z(p(t), q(t)) = 0$, and $p(t), q(t)$ are
rational functions? That is, how do we find a rational parametrization of the
locus of a polynomial $Z(x, y)$? The answer is: use resultants! 

- We have two univariate polynomials $p(a; x), p(b; x)$, where the notation 
  $p(a; x)$ means that we have a polynomial $p(a; x) \equiv \sum_i a[i] x^i$.
  The resultant isa polynomial $Res(a; b)$ which is equal to $0$ when
  $p(a; x)$ and $p(b; x)$ share a common root.

- We can use this to eliminate variables. We can treat a bivariate polynomial $p(x, y)$
  as a univariate polynomial $p'(y)$ over the ring $R[X]$. This way, given two
  bivariate polynomial $p(a; x, y)$, $q(b; x, y)$, we can compute their resultant,
  giving us conditions to detect for which values of $a, b, x$, there exists
  a common $y$ such that $p(a; x, y)$ and $(q, x, y)$ share a root. If $(a, b)$
  are constants, then we get a polynomial $Res(x)$ that tracks whether $p(a; x, y)$
  and $q(a; x, y)$ share a root.

- We can treat the implicit equation above as two equations, $x - p(t) = 0$, 
  $y - q(t) = 0$. We can apply the method of resultants to project out $t$
  from the equations.

### 5 minute intro to elimination theory.

Recall that when we have a linear system $Ax = 0$, the system has a non-trivial
solution iff $|A| = 0$. Formally: $x \neq 0 \iff |A| = 0$. Also, the
ratio of solutions is given by:

$$x_i / x_j = (-1)^{i+j} |A_i|/|A_j|$$



If we have two polynomials $p(a; x) = a_0 + a_1 x + a_2 x^2$, and
$q(b; x) = b_0 + b_1x + b_2 x^2$, then the system $p(a; x)$, $q(b; x)$ has
a simeltaneous zero iff:

$$
\begin{aligned}
&\begin{bmatrix}
a_2 & a_1 & a_0 & 0 \\
0 & a_2 & a_1 & a_0 \\
b_2 & b_1 & b_0 & 0\\
0 & b_2 & b_1 & b_0\\
\end{bmatrix}
\begin{bmatrix}                                             
1 \\ x \\ x^2 \\ x^3
\end{bmatrix}
= 0 \\
&A x = 0
\end{aligned}
$$

#### Big idea

The matrix is setup in such a way that any solution vector $v$ such that
$Qv = 0$ will be of the form $v = (\alpha^3, \alpha^2, \alpha, 1)$. That is,
the solution vector is a _polynomial_, such that $Qv = 0$. Since $Qv = 0$,
we have that $a_2 \alpha^2 + a_1 \alpha + a_0 = 0$, and $b_2 \alpha^2 + b_1 \alpha + b_0 = 0$.

#### Proof

- **Necessity** is clear. If we have some non trivial vector $v \neq 0$ such that
  $Qv = 0$, then we need $|Q| = 0$.

- **Sufficiency**: Since $|Q| = 0$, there is some vector $v = (w, x, y, z)$
  such that $Qv = 0$. 
  We need to show that this $v$ is non-trivial. If the polynomials $p(a;x)$,
  $q(b;x)$ are not equal, then we have that the rows which have coefficients
  from $p$ and $q$ are linearly independent. So, the pair of rows $(1, 3)$,
  and the pair $(2, 4)$ are linearly independent. This means that
  the linear system:

$$
a_2 w + a_1 x + a_0 y = 0 \\
b_2 w + a_1 x + a_0 y = 0 \\
$$

Similarly:

$$
a_2 x + a_1 y + a_0 z = 0 \\
b_2 x + a_1 y + a_0 z = 0 \\
$$

Since the coefficients of the two systems are the same, we must have that
$(w, x, y)$ and $(x, y, z)$ are linearly dependent. That is:

$$
(w, x, y) = \alpha (x, y, z) \\
w = \alpha x = \alpha^2 y = \alpha^3 z \\
$$

We can take $z = 1$ arbitrarily, giving us a vector of the form
$(w, x, y, z) = (\alpha^3, \alpha^2, \alpha, 1)$, which is the structure
of the solution we are looking for!


### References

- [CMU lectures on Math Fundamentals for Robotics](http://www.cs.cmu.edu/~me/811/notes/)

                                                    
# Polynomial root finding using QR decomposition

1. For a polynomial $p(x)$, build the companion matrix $P(x)$.
2. Show that the characteristic polynomial $cp(P)$ of the companion matrix $P(x)$ is indeed $p(x)$.
3. Find eigenvalues of $P(x)$, which will be roots of $p(x)$, since the
   eigenvalues of a matrix $M$ are the roots of its characteristic polynomial $cp(M)$.
4. We use QR since it is numerically stable. The $Q$ matrix discovered by QR
   is orthogonal, and hence does not disturb the covariance of the noise
   on matrix multiplication.


# A hacker's guide to numerical analysis

> Life may toss us ill-conditioned problems, but it is too short
> to settle for unstable algorithms. - D.P. O'Leary

### Measures of error

If $x$ is a number and $\hat x$ is its approximation, then the are two notions of
error:
1. absolute errror: $|x - \hat x|$.
2. relative error: $|x - \hat x|/|x|$. 

Since the relative error is invariant under scaling $(x \mapsto \alpha x)$, we
will mostly be interested in relative error.


### Significant digits

The significant digits in a number are the first nonzero digit and all
succeeding digits. Thus `1.7320` has five significant digits. `0.0491` has
only three significant digits.
**It is not transparent to me why this definition is sensible**.

### Correct Significant digits --- a first stab

We can naively define $\hat x$ agrees to $x$ upto $p$ significant digits
if $\hat x$ and $x$ round to the same number upto $p$ significant digits.
This definition is seriously problematic. Consider the numbers:

- $x = 0.9949$, $x_1 = 1.0$, $x_2 = 0.99$, $x_3 = 0.9950$
- $y = 0.9951$, $y_1 = 1.0$, $y_2 = 1.0$, $y_3 = 0.9950$

Here, $y$ has correct one and three significant digits relative to $x$,
but incorrect 2 significant digits, since the truncation at $x_2$ and $y_2$ 
do not agree even to the first significant digit.

### Correct Significant digits --- the correct definition

We say that $\hat x$ agress to $x$ upto $p$ significant digits if $|x - \hat x|$
is less than half a unit in the pth significant digit of $x$.

### Accuracy v/s precision

- Accuracy: absolute or relative error of a quantity.
- Precision: accuracy with which basic arithmetic `+, -, *, /` are performed.
  for floating point, measured by unit round-off (we have not met this yet).


**Accuracy is not limited by precision**: By using fixed precision arithmetic,
we can emulate arbitrary precision arithmetic. The problem is that often
this emulation is too expensive to be useful.

### Backward, Forward errors

Let $y = f(x)$, where $f: \mathbb R \rightarrow \mathbb R$. Let us compute $\hat y$ as an approximation to 
$y$, in an arithmetic of precision $u$. How do we measure the quality of $\hat y$?

1. In many cases, we maybe happy with an $\hat y$ such that the relative error between
   $y$ and $\hat y$ is equal to $u$: we did the best we can with the precision
   that was given. This is the **forward error**. 
2. An alternative question we can ask is, for what $\delta x$ do we have that 
   $\hat y = f(x + \delta x)$. That is, how far away from the input do we 
   need to stray, to get a matching output? There maybe many such $\delta x$,
   so we ask for $\min |\delta x|$. We can divide this error by $x$ as a 
   normalization factor. This is the **backward error**.

<img src="./static/forward-backward-error.png">

There are two reasons we prefer backward error.

1. It converts error analysis into "data analysis". The data itself tends
   to be uncertain. If the error given by the backward analysis is smaller
   than the data uncertainty, then we can write off our error as being
   too small. Since for all we know, we have 'fixed' the uncertain data
   with our small error.
2. It reduces the question of error analysis into perturbation theory,
   which is very well understood for a large class of problems.

### Backward stable

A method for computing $y = f(x)$ is called **backward stable**
if it produces a $\hat y$ with small backward error. That is, we need a 
small $\delta x$ such that $\hat y = f(x + \delta x)$.

### Mixed forward-backward error

We assume that addition and subtraction are backward stable, where $u$
is the number of significant digits to which our arithmetic operations
can be performed:

$$
x \pm y = x(1 + \Delta) \pm y(1 + \Delta) \forall |\Delta| \leq u
$$

Another type of error we can consider is that of the form:

$$                                                                              
\hat y + \delta y = f(x + \Delta x)
$$

That is, for a small perturbation in the output $(\delta y)$, we can get a
backward error of $\delta x$. This is called as **mixed forward backward error**.

<img src="./static/mixed-forward-backward-error.png">

We can say that an algorithm with mixed-forward-backward-error is stable iff:

$$
\begin{aligned}
&\hat y + \delta y = f(x + \Delta x) \\
&|\Delta y|/|\hat y| < \epsilon \\
&|\Delta x|/|\hat x| < \eta \\
&\text{$\epsilon, \eta$ are small}
\end{aligned}
$$

This definition of stability is useful when rounding errors are the dominant
form of errors.

### Conditioning

Relationship between forward and backward error is govered by _conditioning_:
the sensitivity of solutions to perturbations of data. Let us have an approximate
solution $\hat y = f(x + \delta x)$. Then:

$$
\begin{aligned}
&\hat y - y = f(x + \delta x) - f(x) = f'(x) \delta x + O((\delta x)^2) \\
&(\hat y - y)/y = (x f'(x)/f(x)) (\Delta x/x) + O((\Delta x)^2) \\
&(\hat y - y)/y = c(x) (\Delta x/x) + O((\Delta x)^2)\\
&c(x) \equiv |x f'(x)/f(x)|
\end{aligned}
$$

The quantity $c(x)$ measures the scaling factor to go from the relative
change in output to the relative change in input. Note that this is a property
of the function $f$, not any particular algorithm.

##### Example: $\log x$

If $f(x) = \log x$, then $c(x) = |(x (\log x)') / \log x| = |1/\log x|$. This
quantity is very large for $x \simeq 1$. So, a small change in $x$ can 
produce a drastic change in $\log x$ around $1$.

- Note the the _absolute_ change is quite small: $\log(x + \delta x) \simeq \log x + \delta x/x$.
  However, relative to $\log x$, this change of $\delta x/x$ is quite large.

##### Rule of thumb

We now gain access to the useful rule:

$$
\text{forward error} \lesssim \text{condition number} \times \text{backward error}
$$

- Glass half empty: Ill-conditioned problems can have large forward error.
- Glass half full: Well-conditioned problems do not amplify error in data.

### Forward stable

If a method produces answers with forward errors of similar magnitude to those
produced by a backward stable method, then it is called forward stable. 
**Backward stability implies forward stability, but not vice-versa** (TODO: why?)

### Cancellation

Consider the following program:

```cpp
#include <cmath>
#include <stdio.h>

int main() {
    double x = 12e-9;
    double c = cos(x);
    double one_sub_c = 1 - c;
    double denom = x*x;
    double yhat = one_sub_c / denom;

    printf("x:         %20.16f\n"
           "cx:        %20.16f\n"
           "one_sub_c: %20.16f\n"
           "denom:     %20.16f\n"
           "yhat:      %20.16f\n",
            x, c, one_sub_c, denom, yhat); 
}
```

which produces the output:

```
x:           0.0000000120000000
cx:          0.9999999999999999
one_sub_c:   0.0000000000000001
denom:       0.0000000000000001
yhat:        0.7709882115452477
```

This is __clearly wrong__, because we know that $(1-\cos x)/x^2) \leq 1/2$.
The reason for this terrible result is that:
- we know $\cos x$ to high accuracy, since $x$ was some fixed quantity.
- $1 - \cos x$ converted the **error** in $\cos x$ into its **value**.
- $1 - \cos x$ has only one significant figure.
- This makes it practically useless for anything else we are interested in doing.

In general:

$$
\begin{aligned}
&x \equiv 1 + \epsilon \text{error of order $\epsilon$} \\
&y \equiv 1 - x = \epsilon \text{value of order $\epsilon$} \\
\end{aligned}
$$

That is, subtracting values close to each other (in this case, $1$ and $x$)
converts **error order of magnitude** into **value order of magnitude**. 
Alternatively, it brings earlier errors into promience as values.

### Analysis of subtraction

We can consider the subtraction:

$$
\begin{aligned}
&x = a - b; \hat x = \hat a - \hat b \\
&\hat a = a(1 + \Delta a) \\
&\hat b = b(1 + \Delta b) \\
&\left| \frac{x - \hat x}{x} \right|  \\
&= \left| \frac{-a\Delta a - b\Delta b}{a - b} \right| \\
&= \frac{|-a\Delta a - b\Delta b|}{|a - b|} \\
&=  \frac{|a\Delta a + b\Delta b|}{|a - b|} \\
&\leq  \frac{\max(|\Delta a|, |\Delta b|) (|a| + |b|)}{|a - b|}
\end{aligned}
$$

This quantity will be large when $|a - b| \ll |a| + |b|$: that is, when
there is heavy cancellation in the subtraction to compute $x$. 

### Underflow

```cpp
#include <cmath>
#include <stdio.h>

int main() {
    double x = 1000;
    for(int i = 0; i < 60; ++i) {
        x = sqrt(x);
    }
    for(int i = 0; i < 60; ++i) {
        x = x*x;
    }
    printf("x: %10.20f\n", x);
}
```

This produces the output:

```
./sqrt-pow-1-12
...
x: 1.00000000000000000000
```

That is, even though the function is an identity function, the answer collapses
to `1`. What is happening?

### Computing $(e^x - 1)/x$
One way to evaluate this function is as follows:

```cpp
double f(double x) { return x == 0 ? 1 : (pow(M_E, x) - 1) / x; }
```

This can suffer from catastrophic cancellation in the numerator. When
$x$ is close to $0$, $e^x$ is close to 1, and $e^x - 1$ will magnify the
error in $e^x$.

```cpp
double f(double x) { 
   const double y = pow(M_E, x);
   return y == 1 ? 1 : (y - 1) / log(y);
}
```

This algorithm seems crazy, but there's insight in it. We can show that
the errors cancel! The idea is that neither $(y - 1)$ nor $\log y$ are
particularly good, the errors accumulated in them almost completely
cancel out, leaving out a good value:

$$
\text{assume $\hat y = 1$} \\
1 = \hat y \equiv e^x(1 + \delta) \\
\log 1 = \log (e^x ) + \log(1 + \delta) \\
x = -\log(1 + \delta) \\
x = -\delta + O(\delta^2)
$$

If $\hat y \neq 1$:

$$
\hat f = (\hat y - 1)/\log{\hat y} = (1+\epsilon_3)(\hat y - 1)(1 + \epsilon+1)/(\log \hat y(1 + \epsilon_2))
$$



### IEEE floating point fun: `+0` and `-0` for complex analysis

> Rather than think of `+0` and `-0` as distinct numerical values, think of
> their sign bit as an auxiliary variable that conveys one bit of information
> (or misinformation) about any numerical variable that takes on 0 as its
> value.

We have two types of zeroes, `+0` and `-0` in IEEE-754. These are used in some
cases. The most famous is that $1/+0 = +\infty$, while $1/-0 = -\infty$. Here,
we proceed to discuss some complex-analytic considerations.

> Therefore. implementers of compilers
> and run-time libraries bear a heavy burden of attention to detail
> if applications programmers are to realize the full benefit of the
> IEEE style of complex arithmetic. That benefit deserves Some
> discussion here if only to reassure implementers that their
> assiduity will be appreciated.

$$
\sqrt{-1 + 0 i} = +0 + i \\
\sqrt{-1 - 0 i} = +0 - i \\
$$
These will ensure that $\sqrt{z*} = (\sqrt{z})*$:


$$
\texttt{copysign}(1, +0) = +1 \\
\texttt{copysign}(1, -0) = -1 \\
$$

These will ensure that $\texttt{copysign}(x, 1/x) = x$ when $x = \pm \infty$.


An example is provided where the two limits:

$$
\begin{aligned}
&f(x + i0) = \lim_{y \rightarrow 0-} f(x + i y) \\
&f(x + i0) = \lim_{y \rightarrow 0-} f(x + i y) \\
\end{aligned}
$$

#### Complex-analytic considerations

The principal branch of a complex function is a way to select one branch
of a complex-function, which tends to be multi-valued. A classical example
is the argument function, where $\arg(r e^{i \theta} = \theta$. 
However, this is ambiguous: we can map $\theta \mapsto \theta + 2 \pi$
and still have the same complex number. So, we need to fix some standard.
We usually pick the "branch" where $0 \leq \theta < 2 \pi$.
In general, we need to carefully handle what happens to the function at
the discontinuity.


> What deserves to be undermined is blind faith in the power of Algebra. We
> should not believe that the equivalence class of expressions that all
> describe the same complex analytic function can be recognized by algebraic
> means alone, not even if relatively uncomplicated expressions are the only
> ones considered.


#### References
- Accuracy and stability of numerical algorithms
- [Branch Cuts for complex elementary functions, or much ado about Nothing's Sign Bit](https://people.freebsd.org/~das/kahan86branch.pdf)

# Mobius inversion on Incidence Algebras

Most of these functions are really defined on the _incidence algebra_ of
the poset $P$ with ground field $K$. An _incidence_ algebra $ I(P) $ is a
set of functions which maps intervals of $P$ to the ground field $K$. an
interval is a tuple $(x, y) \in P \times P$ such that $x \leq P$
(where the $\leq$ comes from the partial order on $P$). We have a product
structure which I denote $\star$, given by:

$$
(\alpha \star \beta)([x, z]) = \sum_{x \leq y \leq z} \alpha(x, y) \beta(y, z)
$$

A linear algebra way to look at this is to consider $|P| x |P|$ matrices over $K$
where the rows and columns are indexed by $P$.
The a function $\alpha: P \times P \rightarrow K$
can be written as the elements of the $P \times P$ matrix.
Then this convolution-like operator $\star$ is simply matrix multiplication.

We have three natural functions: 

(1) The characteristic function, which is the identity for $\star$:

$$
\delta([x, z]) \equiv 1 \texttt{ if } x = z \texttt{; } 0 \texttt{ otherwise }
$$


(2) the zeta function, which plays the role of the constant $1$:

$$
\zeta([x, z]) \equiv  1 \texttt{ if } x \leq z \texttt{; } 0 \texttt{ otherwise }
$$

(3) The inverse of the zeta function, the mobius function, a tool for mobius inversion:

$$
\begin{aligned}
&\mu([x, z])  = 1 \\
&\mu([x, z])  = - \sum_{x \leq y < z} \mu([x, y]) \\
\end{aligned}
$$


The mobius inversion theorem for posets states that $\zeta$ and $\mu$ as
defined above are convolutional inverses. that is, $\zeta \star \mu = \delta$.

This allows us to prove:

$$
\begin{aligned}
&g([x, z]) = \sum_{x \leq y \leq z} f([x, y]) \\
&g([x, z]) = \sum_{x \leq y \leq z} f([x, y]) \cdot 1 \\
&g([x, z]) = \sum_{x \leq y \leq z} f([x, y]) \cdot \zeta(y, z) \\
&g = f \star \zeta \\
&g \star \mu = f \star \zeta \star \mu \\
&g \star \mu = f \star \delta \\
&g \star \mu = f
\end{aligned}
$$

We have managed to find $f$ in terms of $g$, when previously we had $g$
in terms of $f$. 


**TODO**: we are usually interested in a _fixed_ $[x, z]$. What happens if we 
make this implicit? We may get nice notation for all of this!

### Sums as mobius inversion

We can derive the formula we had for integrals, that:

$$
F(i) = \sum_{0 \leq i \leq n} f(i) \iff f(k) = F(k) - F(k-1)
$$

by setting up mobius inversion on the usual partial order for the natural
numbers. For simplicity, I'll show the example on $[0, 1, 2, 3, 4]$. The example
immediately generalizes.

- We have the partial (well, total) order $P$: $0 < 1 < 2 < 3 < 4$. 
- We are given a function $f(\cdot)$ we wish to integrate. We define an
  auxiliary function $fi([x, y]) = f(y)$ which evaluates $f$ on the right
  endpoint.
- We can now define $F([x, z])$  as the sum of $f$ from $x$ to $z$:

$$
\begin{aligned}
&F([x, z]) \equiv \sum_{x \leq y \leq z} f(y) \\
&= \sum_{x \leq y \leq z} fi([x, y]) \\
&= \sum_{x \leq y \leq z} fi([x, y]) \cdot \zeta(y, z) \\
&= fi \star \zeta
\end{aligned}
$$

- This tells us that $f(n) = fi([0, n]) = (F \star \mu)([0, n])$:

$$
\begin{aligned}
&f(n) = fi([0, n]) \equiv  (F \star mu)[0, n] \\
&=  \sum_{0 \leq x \leq n} F([0, x]) \mu([x, n])
\end{aligned}
$$

- We note that we need to know the values of $\mu([x, n])$ for a _fixed_ n,
  for _varying_ x. Let us attempt to calculate $\mu([0, 4]), \mu([1, 4]), \mu([2, 4]), \mu([3, 4]), \mu([4, 4])$
  and see if this can be generalized:

$$
\begin{aligned}
& \mu([4, 4]) = 1 \text{ By definition} \\
& \mu([3, 4]) = - \left (\sum_{3 \leq x < 4} \right) \text{ By definition } \\
\end{aligned}
$$


# Finite differences and Umbral calculus

Umbral calculus lays out a large collection of "umbral" / "shadowy"
coincidences across combinatorics and calculus. Here, I'll lay out some of
these that I learnt from [Concrete Mathematics](https://en.wikipedia.org/wiki/Concrete_Mathematics).
I hope to use this for myself to motivate a bunch of combinatorics. I'll
provide an interesting proof of why $\sum{1 \leq k < n} k^2 = k(k-1)/2$
using this umbral calculus.

### Discrete Derivative: Forward difference

We begin by trying to build a discrete version of the derivative operator. The
derivative of `f` will be denoted using `f'`. The _forward_ difference
of $f: \mathbb R \rightarrow \mathbb R$ is defined as:

$$
\delta f: \mathbb R \rightarrow \mathbb R; (\delta f)(x) = f(x + 1) - f(x)
$$

Immediately, we can see that this operator is linear:

$$
\begin{aligned}
&\delta(f + g) 
  &= (f+g)(x+1) - (f+g)(x)  \\
  &= (f(x+1) - f(x)) + (g(x+1)-g(x))  \\
  &= (\delta f) + (\delta g)  \\
&\delta(\alpha f)(x) 
  &= (\alpha f)(x+1) - (\alpha f)(x) \\
  &= \alpha \cdot (f(x+1) - f(x))   \\
  &= \alpha (\delta f)
\end{aligned}
$$

it obeys a slightly corrupted version of the chain rule, $(fg)' = f' g + g' f$:

$$
\begin{aligned}
&\delta(fg)  \\
  &= (fg)(x+1) - (fg)(x)  \\
  &= f(x+1)g(x+1) - f(x)g(x) + 0 \\
  &= f(x+1)g(x+1) - f(x)g(x) + [f(x)g(x+1) - f(x)g(x+1)] \\
  &= g(x+1)[f(x+1) - f(x)] + f(x)[g(x+1) - g(x)] \\
  &= g(x+1)(\delta f)(x) + f(x) (\delta g)(x) \\
  &= (S \delta f)(x) + (f \delta g)(x) [(Sh)(x) \equiv h(x+1)] \\
  &= (S  \delta f + f \delta g)(x) \\
\end{aligned}
$$

We need this new $S$ operator to shift the function's input from $x$ to $x+1$.

### Falling factorial as polynomials

cool, now that we seem to have a linear derivative operator that behaves
roughly sanely, let's test it out! The first reasonable target is a polynomial,
so let's try $x^2$:

$$
\delta(x^2) = (x+1)^2 - x^2 = 2x + 1
$$

This is disappointing, it does not behave very well `:(` However, there _is_
an analogue that does well. This is the _falling factorial_, defined as:

$$
x^{(n)} \equiv x(x-1)(x-2)\cdots(x-n+1)
$$

For example:

$$
x^{(0)} = 1 \\
x^{(1)} = x \\
x^{(2)} = x(x-1) \\
x^{(3)} = x(x-1)(x-2) \\
$$

Let's try and apply our discrete difference $\delta$:

$$
\begin{aligned}
&\delta(x^{(2)})  \\
  & = (x+1)(x-1+1) - x(x-1) \\
  & = (x+1)(x) - x(x-1) \\
  & = x*2 = 2x(1) \\
&\delta(x^{(3)})  \\
  &= (x+1)(x-1+1)(x-2+1) - x(x-1)(x-2) \\
  &= (x+1)(x)(x-1) - x(x-1)(x-2) \\ 
  &= x(x-1)((x+1) - (x-2)) = 3x(x-1) = 3x^{(2)} \\
\end{aligned}
$$

These falling factorials look pretty unnatural though, why do we care?
Well, once we build some integral calculus, we can handle our problem
of $\sum_{1 \leq i < k} i^2$ using this calculus, by rewriting $i^2$
in terms of these falling factorials.

### Sums as discrete integrals

We want to think of $\sum_{0 \leq i < n} f(i)$ as the correct variant of
$\int_0^n f(i) di$. The most important property of an integral is
the fundamental theorem of calculus:

$$
\int_a^b f'(i) di = f(b) - f(a) \mapsto \sum_{a \leq i < b} (\delta f)(i) =?= f(b) - f(a)
$$

we can check if the assertion is true:

$$
\begin{aligned}
&\sum_{a \leq i < b} (\delta f)(i)  \\
&= [f(a+1) - f(a)] + [f(a+2) - f(a+1)] + [f(a+3)-f(a+2)] + \cdots + [f(b) - f(b-1)] \\
&= f(b) - f(a) \quad \text{(The sum telescopes)} 
\end{aligned}
$$

Sweet, so we just kicked a theory of calculus of the ground. Let's put
this to some use:

### Gauss' famous formula from discrete calculus

Let's begin by deriving the closed form for $[1\cdot(k-1)]$ naturals:
                                                
$$
\sum_{0 \leq i < n} i = \sum_{0 \leq i < n} i^{(1)} = i^{(2)}/2 \big|_{0}^n = n(n-1)/2
$$

Let's now derive the closed form form the sum of squares of $[1\cdot(k-1)]$:

$$
\begin{aligned}
&\sum_{0 \leq i < n} i^2  \\
&= \sum_{0 \leq i < n} i*(i-1) + i  \\
&= \sum_{0 \leq i < n} i^{(2)} + i^{(1)} \\
&= n^{(3)}/2 + n^{(2)}/2 \\
&= n(n-1)(n-2)/3 + n(n-1)/2 \\
&= n(n-1)(n/3 - 2/3 + 1/2) \\
&= n(n-1)(2n - 1)/6 \\
\end{aligned}
$$

Trying to perform this process in general does beg a question: how do we
convert from $x^n$ into some combination of rising and falling factorials?
It turns out that _Stirling Numbers_ will show up to aid this conversion.
But before that, let's see some more connections.

### $2^x$ as the combinatorial version of $e^x$

We want to find the analogue of the exponential function $e^x$, which
satisfies the equation $f'(x) = f(x)$. Setting this up in the discrete case:

$$
\begin{aligned}
&d'f(x) = f(x) |  f(0) = 1 \\
&f(x+1) - f(x) = f(x) | f(0) = 1 \\
&f(x+1) = 2f(x) | f(0) = 1 \\
&f(n) = 2^n
\end{aligned}
$$

What does this buy us? It gives us a nice proof that $\sum_{k} nCk = 2^n$.
It proceeds by taking the taylor of $e^x$, "combinatorializing it", and then
simplifying:

$$
\begin{aligned}
&e^x = \sum_{n=0}^\infty \frac{x^n}{n!} \\
&2^x = \sum_{n=0}^\infty \frac{x^{(n)}}{n!} \\
&     = \sum_{n=0}^\infty \frac{x*(x-1)*(x-2)*\cdots(x-n+1)}{n!} \\
&     = \sum_{n=0}^\infty \frac{x*(x-1)*(x-2)*\cdots(x-n+1)}{n!}
\end{aligned}
$$

### Harmonic series as the combinatorial version of logarithm

In the continuous case, we have that $\int 1/x = \log x$. In the
discrete case, we get $\sum_{i=1}^n 1/x \equiv H_n$, the sum of the
first $n$ harmonic numbers. This explains _why_ the harmonic numbers
keep showing up in different places across discrete math --- We're often
trying to integrate some kind of $1/x$ quantity.
This also may tell us that $H_n$ and $2^n$ are somewhat "weak inverses" of each other. 
I haven't thought about this weak inverse thing too much.

### Stirling numbers of the first kind for convering between polynomials and falling factorials

We can express $x^{(n)} = \sum_{k=0}^n [n, k] x^k$ where $[n, k]$ 
are the (yet to be defined) unsigned stirling numbers of the first kind. 
(aside: I wonder if this can be derived from some kind of mobius inversion).

We begin my in fact _defining_ the stirling numbers of the first kind, $[n, k]$
as the coefficients of the rising factorial:

$$
x^{(n)} = x(x+1)(x+2) \dots (x+n-1) = \sum_{i=0}^n [n, i] x^i
$$

The question as a combinatorialist is:

> what do the unsigned striling numbers of the first kind, $[n, i]$, count?

The answer is:

> $[n, i]$ counts the number of permutations of $n$ elements with $i$
> disjoint cycles.

There is a more evocative definition, which goes like this:

> $[n, i]$ counts the number of ways to seat $n$ people at $i$ 
> circular tables, such that no table is left empty.

For example, in the case of the permutations of the set $\{1, 2, 3\}$, 
we have the permutations:

$$
\begin{aligned}
(1)(2)(3) \text{3 cycles} \\
(12)(3) \text{2 cycles} \\
(1)(23) \text{2 cycles} \\
(2)(13) \text{2 cycles} \\
(132) \text{1 cycle} \\
(123) \text{1 cycle} \\
\end{aligned}
$$

So, this gives the counts:

- $[3, 1] = 2$
- $[3, 2] = 3$
- $[3, 3] = 1$

From the seating people perspective, here's how this goes:
- $[3, 1]$ is the number of ways to seat 3 people at 1 table. The first
  person sits at the table in only **one way**. The second person can sit to the
  left or to the right of the first person, but this is symmetric: they too
  have only **one way**. Now the third person can sit to the left of the first
  person or to the left of the second person. So there are **two ways**.
  In total, there are only two ways. **Key idea:** On a circular table, it
  only matters who is to your left, since there is no difference between left
  and right.
  The second person has two choices: they
- $[3, 3]$ is the number of ways to seat 3 people at 3 tables so that no table
  is empty. We are forced to place one person per table.
- $[3, 2]$ is the number of ways to seat 3 people at 2 tables so that no table
  is empty. So we will need to have two people on the first table,
  and then the final personal on the second table.
  Once we pick which two people sit together in the first table, we are done,
  because for upto two people, it doesn't matter how they sit at a table,
  the situation is symmetric.


These stirling numbers satisfy a recurrence:

$$
[n+1, k] = n[n, k] + [n, k-1]
$$

This can be seen combinatorially. If we want the number permutations of $n+1$ objects
with $k$ cycles, we can either:

1. Take the permutations of $n$ objects with $k-1$ cycles, $[n, k-1]$, and then
   insert the new $(n+1)$th object into a new cycle all by itself. That is,
   we create a new permutation where $p(n+1) = (n+1)$.
2. Take the permutation of $n$ objects with $k$ cycles, and insert this new $(n+1)$th
   object into any of the $k$ cycles. If the original permutation had `x -p-> y`,
   we can insert this new object as `x -p-> * -p->y` for any `x`. Thus, there are
   $n$ choices of locations to inser `*` --- as the image of all possible `x`s.
   This gives us the $n[n, k]$ term.

Another cute fact of the unsigned stirling numbers of the first kind $[n, k]$
is that since permutations are partitioned by their number of cycles, we have:

$$
\sum_{k=1}^n [n, k] = n!
$$



### References

- [Concrete Mathematics](https://en.wikipedia.org/wiki/Concrete_Mathematics)
- [Cornell 18.312: algebraic combinatorics](http://pi.math.cornell.edu/~levine/18.312/alg-comb-lecture-10.pdf)
- [An introduction to posets and mobius inversion](https://community.plu.edu/~edgartj/posetMobius.pdf)


# Permutahedron

The permutahedron over $n$ letters is a polytope which is defined as the convex
hull of all permutations of the point $(1, 2, \dots, n)$. 
For example, the permutahedron over 3 letters is the convex hull of the
points $(1, 2, 3), (1, 3, 2), (2, 1, 3), (2, 3, 1), (3, 1, 2), (3, 2, 1)$.


Here, we show that it can be embedded in $(d-1)$ dimensionl space, and that each point
$perm((1, 2, \dots n))$ is indeed a vertex of the convex hull. 

An example of a situation where a point is _not_ in the vertex of a convex hull
is `convexhull(1, 2, 3) = [1, 3]`. Note that `2` was used to generate the
convex hull, but is not a vertex since it is the convex combination of `1, 3`.
We wish to prove that such a situation does not happen in the case of the
permutahedron.

I have not seen an elementary proof that each point that is a permutation of
the original is a vertex, so I'm recording that proof out of interest.


### Showing that all permutations of $(1, 2, \dots, n)$ are vertices

#### Core idea

start by looking at index `i` of the "largest value" `N` in the point `P`.
Since it's the largest point, if it's a convex combination, all other points in
the convex combination must have the same "largest value" at that index `i`. So
we can now ignore the index `i` and get permutations of `[1..N-1]`

Repeat this process to prove that _all_ indexes of things in the convex sum
must be equal to `P`. But this is absurd, because all vertices are distinct.
Hence, the only way for this to work out is if we have only one point that we
are convex-summing over. That is, `P` _cannot_ be written as the convex sum of
two or more vertices.

#### Formal proof


Let us be working with permutations of `[1, 2, ..., N]`. Pick point `P`. Assume
`P` is in the convex sum of some `{ Xi }`.

Let `index(N, P)` be the index of number `N` in `P`. For example, if 
`P = [2, 3, 1]`, then 

```
index(2, P) = 0 (assuming 0-based indexing)
index(3, P) = 1
index(1, P) = 2
```

If `P` is the convex sum of vertices `{ Xi }`, all of them _must_ have that:

```
Xi[index(N, P)]  = N forall Xi in the convex sum
```


since `N` is the largest value that `X_I` can have at any index. The only way
to get the maximum value by a convex sum is for all values to be that maximum
value.

So, we can now ignore dimension `index(N, P)`, since _all the vertices_ `X_i`
involved in the convex combination and `P` have `index(N, P) = N`. If we
project out this dimension, we are left with permutation of `(1..N-1)`. 

Repeat the same process. We will need to have all `X_i` to have their value at
`index(N-1, P)` to be `N-1`. 

Keep doing this till we get that the dimensions of all points in `Xi` and `P`
are equal. But all the points in `{ Xi }` are distinct since they are
permutation of `[1..n]`. Hence, `{ Xi }` can contain only a single point, and
this point is `P`.

Hence, `P` cannot be written as the convex combination of other points. Hence,
`P` is a vertex.

#### Proof that convex sum of maximum must have maximum

Assume we have values `{v1, v2, ... vn}` where without loss of generality,
`v1 <= v2 <= ... <= vn`. We can always relabel otherwise.

Now we want to write `vn` as the convex sum of `{v1, v2, ... vn}`. We can draw this on
the number line as:

```
---[v1--v2--v3--...--vn]---
```

- A convex sum must be inside this line segment between `[v1--...--vn]` (`vn` is
  to the rightmost since it's known to be the largest value in `{v1...vn}`).
- So, if we try to write `vn` as the convex sum, we _must_ have the coefficient
  of `vn=1` and the coefficient of all other points `=0`, since any other
  combination will "pull the convex sum away from the right (where `vn` sits),
  towards the left".

# Lyndon + Christoffel = Convex Hull
Actual "real world" use-case of lyndon factorization, cribbed from here:

- [Lyndon + Christoffel = digitally convex](https://archipel.uqam.ca/8354/1/Reutenauer-2009a-preprint.pdf)
- Combinatorics on Words: Christoffel Words and Repetitions in Words

I wanted to learn a real-world use-case of lyndon factorization so I could
remember it. I found a whole bridge between combinatorics/strings and
discrete geometry (they call it "digital geometry") that I didn't know
existed before.


- If you have a line with rational slope $p/q$ and you want to draw a
  "discretized line" by connecting integer points in ZxZ, you can describe this
  discretized line as starting from $(0, 0)$, making moves $x$ (move up 1 unit
  along $x$-axis), $y$ (move up 1 unit along $y$-axis), finally reaching the point 
  $(p, q)$. For example, to reach the point $(2, 3)$, you can make the moves 
  $[x, x, x, y, y]$.

- A christoffel word is a word $w \in \{x, y \}^\star$ such that it hugs a line of
  rational slope $p/q$ as close as possible. Formally, there are no integer
  points between the line with slope $p/q$ starting from the origin, and the
  discretized line as described by $w$. An example picture:

<img src="./static/christoffel-word-example.png">

- It turns out that all primitive christoffel words are Lyndon words. I'm not
  100% sure what primitive is, but the take-away is that these primitive
  christoffel words represent discrete lines that are *good* approximations
  of lines.

- Now, we are given a discrete sequence of adjacent line segments going
  upwards, where the line segments are described by $x, y$ moves. We want to
  check if the discrete curve defined by them is well-approximating a convex
  polygon.

- We compute the lyndon factorization of the word. This splits the
  original line segment into a series of line segments, where each
  successive line segment has lower slope than the previous (since the
  lyndon decomposition splits words into non-decreasing lex order).

<img src="./static/lyndon-convex.png">

- We can then check that each word in the lyndon decomposition is a Christoffel
  word. If it is, then your sequence of moves describes a "good  discrete
  convex hull", since as described above, a christoffel word "hugs the line"
  well. 


### Bonus: slick characterization of line drawing

<img src="./static/christoffel-cyclic-7-4.png">


If we want to draw a line with slope `p/q = 4/7` using the lower approximation the idea
is that we keep taking `4` steps along `x`, and every time we "exceed" `7` steps
along `x`, we take a step along `y`.

This is the same as:
1. working in `Z/(4+7)Z`, starting from `0`, writing down multiples of `4` till we cycle back to `0`
2. marking an "increase" in a step with an `x`, and a "decrease" in a step
  with `y`.

The intuition is that once we walk `k*p` steps where `k*p >= q`, we want
to increment `y`. So, at first glance, we may believe we should consider
`Z/qZ`. However, this is misguided. Examples to enlighten:


1. Consider `x=1, y=0`. We should use `Z/1Z = { 0 }`: that is, we must keep
  moving along `0 -x -> 0 -x-> 0 -x-> ...`. This is unlike what happens if we choose
  `Z/0Z` (which is not a well-defined idea).
2. Consider `x=1,y=1`. We should use `Z/2Z`, so we keep going `0 -x-> 1 -y-> 0 -> ...`
  which will cause is to flip `x -> y -> x -> y -> ...`. 


In some sense, we are making sure that we can "start" with an `x` and see where that takes us.
In the `Z/1Z` case, we realise that we can keep taking `x`s. In the
`Z/2Z` case, we realise we need to flip between `x` and `x`.

Let's try to show this formally, where `k` is the smallest number
such that `kp >= q`. We'll also have concrete examples where
`p=2, q=7`. For the example, `k=4` since `kp = 4*2 = 8 > 7`. 
If we work in `Z/yZ = Z/7Z`, we will get the numbers:


```
Z:    0, p, 2p, ... (k-1)p, [q] kp 
Z/qZ: 0, p, 2p, ... (k-1)p, [q] (kp % q)
Z/7z: 0, 2,  4, ...      6, [7] (8 % 7 = 1)
```

But notice that we are inserting `x` _between_ numbers. So we will get:

```
Z:    0 -x-> p -x-> 2p, ... (k-1)p -y-> (k+1)p
Z/qZ: 0 -x-> p -x-> 2p, ... (k-1)p -y-> ((k+1)p % y)
Z/7z: 0 -x-> 2 -x->  4, ...      6 -y-> (8      % 7 = 1) 
         ^                            ^
      x since [0 < 2]              y since [6 > 1]
```

which gives us the moves:

```
Z/7Z: 0 -x-> 2 -x-> 4 -x-> 6 -y-> 8 % 7 = 1
```

We only get `3` occurences of `x`, after which on the next accumulation of `p`,
becomes an `8` which wraps around to a `1`. This is the age-old tension that exists
between **points** and **gaps**. For `k` points, there are `k-1` gaps. In our
case, we have `4` points `[0, 2, 4, 6]`, but this leaves us room for only
three gaps for three`x` moves, while in reality we need `4`.
We remedy this situation by giving ourselves space enough for _one_ more `x`, by changing from `Z/qZ`
to `Z/(p+q)Z`. We should look at this as creating space for another gap.


```
Z:        0, p, 2p, ... (k-1)p, [q] kp,  [q+p  ], (k+1)p
Z/(p+q)Z: 0, p, 2p, ... (k-1)p, [q] kp,  [q+p  ], (k+1)p % (p+q)    
Z/9z: 0, 2,  4, ...          6, [7]  8,  [7+2=9], (10    %    9=1)
```

which gives us the moves:

```
Z:        0 -x-> p -x-> ... (k-1)p -x-> kp -y-> (k+1)p
Z/(p+q)Z: 0 -x-> p -x-> ... (k-1)p -x-> kp -y-> (k+1)p % (p+q)
Z/9Z:     0 -x-> 2 -x-> ...      6 -x->  8 -y-> (   10 %     9 = 1)
             ^                             ^
           x since [0 < 2]               y since [8 > 1]

```

That is, we are able to get `k` occurences `x` between `0, p, ..,kp` which
has `(k+1)` points. Concretely, we have:

```
Z/9Z: 0 -x-> 2 -x-> 4 -x-> 6 -x-> 8 -y-> 1
```
where we have 4 occurences of `x` in between after which we have an occurence
of `y`, which is what we want when `x=2, y = 7`. We need to reach at least
`q=7` before we have exceeded our denominator and need to make a move
along `y`.


# Geometric proof of `e^x >= 1+x`, `e^(-x) >= 1-x`

Let's concentrate on the `e^x >= 1 + x` part. 

1. The tangent of `e^x` at `x = 0` is `1 + x`, since the taylor series
   of `e^x` truncated upto `x` is `1 + x`.
2. `e^x` is a strongly convex function, since `(e^x)'' = e^x` which is positive
   everywhere. Hence, `e^x` will always lie above its tangent.

Similarly for `e^(-x)`, working through the math:

1. `1 -x` is tangent at `x=0` to `e^(-x)`
2. `(e^(-x))'' = -(e^(-x))' e^(-x)` which is again positive everywhere, and
   hence, `e^(-x)` is strongly convex.




# Ranking and Sorting

We we want to sort an arrray `xs` and write the results into an array `ys`.
In both cases, the invariant to be satisfied is that `ys` is `xs` in ascending
order. I'll be considering two broad ways to implement such a thing:


- 1. **(RANK)** Index straight into `ys`, reindexed into `xs`. We name the reindexing
  array as `rs` (`rs` for _ranks_).

```cpp
for(int i = 0; i < N; ++i) {
   ys[rs[i]] = xs[i]
}
```

- 2. **(SELECT)** Reindex into `ys`, index straight into `xs`. 
  We name the reindexing array `ss` (`ss` for _selects_).

```cpp
for(int i = 0; i < N; ++i) {
   ys[i] = xs[ss[i]]
}
```

#### Defnition of rank

In the case of **(RANK)**, the specification is that the rank of an element `e`
is the number of elements that are:

1. less than `e`.
2. equal to `e` but occur before `e`.

This ensures that rank is a _permutation_: that is, every element `e` is given
a _unique_ index. 

```cpp
int rank(const int *xs, int i) { 
    int cnt = 0;
    for (int j = 0; j < N; ++j) {
        if (xs[j] < xs[i] || (xs[j] == xs[i] && j < i)) cnt += 1;
    }
    return cnt;
}

for(int i = 0; i < N; ++i) {
  rs[i] = rank(xs, i);
}
```

##### Rank: Alternative 1
An alternative way to look at our definition of rank is that we are
sorting the tuples  `(xs[i], i)` using lex ordering. So if two indeces
`i, j` have the same value, then we sort on the index.


##### Rank: Alternative 2
We could have also defined rank as:

```cpp
int rank(int *xs, int i) { 
    int cnt = 0;
    for (int j = 0; j < i; ++j) {
        if (xs[j] <= xs[i]) cnt += 1
    }
    return cnt;
}
```

I declined from doing so because I wanted to show the lex-ordering
interpretation of `rank` will be be useful later.

#### Definition of select

For **(SELECT)**, we'll need to think a little harder. Let's try to rewrite
our way to glory:

- 1. From definition of rank:

```cpp
ys[rs[i]] = xs[i]
```

- 2. move `i -> ss[i]` where `ss[i]` is guaranteed to be a permutation,
  so we will write each index eventually:

```cpp
ys[rs[ss[i]]] = xs[ss[i]]
```

- 3. Stipulate that `rs[ss[i]] = i`, since we want a `ys[i]`:

```cpp
ys[i] = xs[ss[i]]
```

This gives us necessary and sufficient conditions on how to find an `ss`:
`ss` must be a permutation that is an inverse permutation to `rs`.


#### How to invert a permutation?

How does one invert a permutation? We have a permutation `rs[i]` that maps
`i` to `rs[i]`. We want to find a new permutation `ss[i]` such that 

```
rs[ss[i]] = i
```

Equivalently:

```
// ss[i] is an index 'k'...
ss[i] = k 
// 'k' is the location of 'i' in rs.
rs[k] = i
```

So if we first tag each location of `rs` with its index, and then sort
with the values of `rs` being the keys, then `ss[i]` will be the values.

In pictures:

```
rs[i]          [3 4 0 1 2]
rs_tagged[i]   [(3, 0) (4, 1) (0, 2) (1, 3) (2, 4)]
rs_sorted[i]   [(0, 2) (1, 3) (2, 4) (3, 0) (4, 1)]
ss[i]          [    2      3      4      0      1 ]
rs[ss[i]]      [ rs[2]  rs[3]  rs[4]  rs[0]  rs[1]]
rs[ss[i]]      [    0      1      2      3      4 ]
```

#### Rank and Select are inverses

It's nice, there are a couple of miracles that lined up here:

- Rank starts with `r` and select starts with `s` so we get nice naming.
- Rank and select are true inverse permutations of each other.

#### Generalized rank and select are adjoint

We had to "fix" our definition of rank to avoid equal elements in the array.
Hence, we had the rule that we also sort by indexes if the elements are
equal. However, if we now decide to ignore this rule, we will then recreate
the classical _adjunction_ between rank and select.

#### References
- Richard Bird: Pearls of functional algorithm design



# Proof of minkowski convex body theorem

We can derive a proof of the minkowski convex body theorem starting from
Blichfeldt’s theorem.

#### Blichfeldt's theorem

This theorem allows us to prove that a set 
of large-enough-size in any lattice will have two points such that their
difference lies in the lattice. Formally, we have:

1. A lattice $L(B) \equiv \{ Bx : x \in \mathbb Z^n \}$ for some basis 
   $B \in \mathbb R^n$. The lattice $L$ is spanned by integer linear
   combinations of rows of $B$.
2. A body $S \subseteq R^n$ which **need not be convex!**, which 
   has volume greater than $\det(B)$. Recall that for a lattice $L(B)$,
   the volume of a fundamental unit / fundamental parallelopiped is $det(B)$.


Blichfeldt's theorem tells us that there exists two points $x_1, x_2 \in S$
such that $x_1 - x_2 \in L$.

##### Proof

The idea is to:

1. Chop up sections of $S$ across all translates of the fundamental parallelopiped
   that have non-empty intersections with $S$ back to the origin. This makes
   all of them overlap with the fundamental parallelopiped with the origin.
2. Since $S$ has volume great that $\det(B)$, but the fundamental paralellopiped
   only has volume $\det(B)$, points from two different parallelograms **must**
   overlap.
3. "Undo" the translation to find two points which are of the form $x_1 = l_1 + \delta$,
   $x_2 = l_2 + \delta$. they must have the same $\delta$ since they overlapped
   when they were laid on the fundamental paralellopiped. Also notice that $l_1 \neq l_2$
   since they came from two different parallograms on the plane!
4. Notice that $x_1 - x_2 = l_1 - l_2\in L \neq 0$, since we already argued
   that $l_1 \neq l_2$. This gives us what we want.

#### Minkowskis' Convex body Theorem from Blichfeldt's theorem

Consider a convex set $S \subseteq \mathbb R^n$
that is symmetric about the origin with volume greater than $2^n det(B)$.

Create a new set $T$ which is $S * 0.5$. Formally:

$$T \equiv S/2 = \{ (x_1/2, x_2, \dots, x_n/2)  : (x_1, x_2, \dots, x_n) \in S \}$$

We now see that $Vol(T) > det(B)$ to invoke  Blichfeldt's theorem.
Formally:

$$Vol(T) = 1/2^n Vol(S) > 1/2^n (2^n det(B)) = det(B)$$

We can apply Blichfeldt's theorem to get our hands on two points $x_1, x_2 \in T$
such that $x_1 - x_2 \in L$. 

$$
\begin{aligned}
&x_1 \in T \Rightarrow 2x_1 \in S ~(S = 2T) \\
&x_2 \in T \Rightarrow 2x_2 \in S ~(S = 2T) \\
&2x_2 \in S \Rightarrow -2x_2 \in S~\text{($S$ is symmetric about origin)} \\
&\frac{1}{2}(2x_1) + \frac{1}{2} (-2x_2) \in S~\text{($S$ is convex)}\\
&x_1 - x_2 \in S~\text{(Simplification)}\\
&\text{nonzero lattice point}~\in S \\
\end{aligned}
$$


#### References
- [Theorem of the day](https://www.theoremoftheday.org/GeometryAndTrigonometry/Minkowski/TotDMinkowski.pdf)


# Burrows Wheeler

We aim to get the $O(n)$ algorithm for burrows wheeler, by starting from the
naive $O(n^2)$ implementation and then slowly chipping away to get to the
fastest algorithm
                 
### String rotations

Given a string $s$ of length $n$, we can index it as $s[0]$, $s[1]$, upto
$s[n-1]$. We can now build a table consisting of _rotations_ of the string.
We'll define:

```hs
lrot :: [a] -> [a]
lrot [] = []; lrot (x:xs) = xs ++ [x]
```

We can build a table of left-rotations:

```
foobar
oobarf
obarfo
barfoo
arfoob
rfooba
```

We can immediately notice that it's a _symmetric matrix_. We can prove
this as follows. We write $lrot(rot, s)$ as an array such that:

$$
lrot(rot, s)[i] = s[(rot + i) % n] \text{where $n = |s|$}
$$

Now, we note that on row $r$ of our array we have the string $lrot(r, s)$.
So the value at row $r$, column $c$ is $lrot(r, s)[c] = s[(r + c)%n]$.
But this is symmetric in $c, r$ so can be written as $s[(c + r)%n]$,
which is equal to $lrot(c, s)[r]$. Formally:

$$
lrot(r, s)[c] = s[(r + c) %n] = s[(c + r)%n] = lrot(c, s)[r]
$$

### Sorts of string rotations

We're next interested in considering _sorted order_ of the string
rotations. For example, in the case of the string "here, there",
all the rotations are:

```
here-there  0
ere-thereh  1
re-therehe  2
e-thereher  3
-therehere  4
therehere-  5
herehere-t  6
erehere-th  7
rehere-the  8
ehere-ther  9
```

which is calculated with the help of the following haskell code:

```hs
lrot :: [a] -> [a]
lrot [] = []; lrot (a:as) = as ++ [a]

lrots :: [a] -> [[a]]; lrots as = take (length as) (iterate lrot as)

main =  putStrLn $ intercalate "\n"  
  (zipWith (\s i -> s <> "  " <> show i)
           (lrots "here-there") [0,1..])
```

If we now *sort* these rotations, we get:

```
-therehere  0
e-thereher  1
ehere-ther  2
ere-thereh  3
erehere-th  4
here-there  5
herehere-t  6
re-therehe  7
rehere-the  8
therehere-  9
```

we produce this by chainging the above definition of `main` to:

```
main =  putStrLn $ intercalate "\n"  
  (zipWith (\s i -> s <> "  " <> show i)
           -- | extra `sort` here
           (sort $ lrots "here-there") [0,1..])
```

Let's look at the **final column** of that table. We have:

```
-thereher|e|  0
e-therehe|r|  1
ehere-the|r|  2
ere-there|h|  3
erehere-t|h|  4
here-ther|e|  5 <- ORIGINAL STRING
herehere-|t|  6
re-thereh|e|  7
rehere-th|e|  8
therehere|-|  9

0123456789
errhhetee-
```

Now, we'll show how to write a _really cool_ function call `bwt` such that:

```hs
bwtinv ("errhhetee-",5) = "here-there"
```

The `5` is the index of the original string in the list. That is, given
the jumbled up last-column and the index of the original string, we're
able to reconstruct the original string. The reason this is useful is
that the jumbled string `"errhhetee-"` is easier to compress: it has
long runs of `r`, `h`, and `e` which makes it easier to compress.

The process we performed of rotating, sorting the rotations and taking
the final column is the Burrows-Wheeler transform. in code:

```hs
import Data.List
lrot :: [a] -> [a]
lrot [] = []; lrot (a:as) = as ++ [a]

lrots :: [a] -> [[a]]
lrots as = take (length as) (iterate lrot as)

findix :: Eq a => a -> [a] -> Int
findix a as = length (takeWhile (/= a) as)

lastcol :: [[a]] -> [a]; lastcol = map last

bwt :: Eq a => Ord a => [a] -> ([a], Int)
bwt as = let as' = (sort . lrots) as in (lastcol as', findix as as')
```

Now we need to understand how `bwtinv` is defined and what it does.
The definition is:

```
import Control.Arrow (&&&)

bwtinv :: Eq a => Ord a => ([a], Int) -> [a]
bwtinv (as, k) = recreate as !! k

-- recreate · lastcol · sort · rots = sort · rots
recreate :: (Eq a, Ord a) => [a] -> [[a]]
recreate as = recreate' (length as) as

recreate' :: (Eq a, Ord a) => Int -> [a] -> [[a]]
recreate' 0 = map (const [])
recreate' n = hdsort . consCol . (id &&& recreate' (n-1))


hdsort :: Ord a => [[a]] -> [[a]]
hdsort = let cmp (x:xs) (y:ys) = compare x y
         in sortBy cmp 

consCol :: ([a], [[a]]) -> [[a]]
consCol = uncurry (zipWith (:))
```

OK, so much for the code. what does it _do_?

The idea is that:
- we recreate the entire matrix from the last column using `recreate`
  and take the `k`th element.

- `recreate` apprents a copy of the initial last column to a matrix of
  columns, and then sorts this.



#### References
- Richard Bird: Pearls of functional algorithm design


# Intuitionstic logic as a Heytig algebra

_open sets_ form a Heytig Algebra, which is a lattice plus an implication
operator. So it's stronger than a lattice, but weaker than a boolean algebra.
Formally, a Heytig algebra over a set $X$ is a collection $(L, \lor, \land, \Rightarrow)$
where $(X, \lor, \land)$ form a lattice, and $\Rightarrow$ obeys the axiom

$$
\Rightarrow: L \rightarrow L; (c \land a) \leq b \iff c \leq (a \Rightarrow b)
$$

In any topological space $(U, \tau)$ ($U$ for universe set)
the open sets of that space form a Heytig algebra.
Here, set-union and set-intersection become the lattice join and lattice meet.
We define a "weak complement" denoted by $\lnot$ which is defined as:

$$
\lnot A \equiv \texttt{interior}(A^C)
$$

We need the $\texttt{interior}$ to make sure that we're left with an open
set. Also, this $\lnot$ is not really a complement, since we won't have that
$\lnot \lnot A = A$. but, more on that later!

We write open intervals with round parenthesis:

```
    A
--(===)--
```

$\lnot A$ of the above set $A$ becomes the open interval that is in the
interior of $A$ complement.


```
--(===)-- A
==]---[== A complement
==)---(== Not A
```

Now, we can try to ask, when is $\lnot \lnot A = U$ (where $U$ is the universe
set or the full space). If we consider a set containing a single point,
then we will have:


```
==)(== A 
------------ Not A  
============ Not (Not A)
```
in words:

$$
\begin{aligned}
&A = U \setminus \{ 1 \} \\
&\lnot A = \texttt{interior}(A^c) = \texttt{interior}(\{ 1 \}) = \emptyset \\
&\lnot \lnot A = \texttt{interior}((\lnot A)^c) = \texttt{interior}(\emptyset^c) = \texttt{interior}(U) = U \\
\end{aligned}
$$

So in some sense, the law of excluded middle is "almost true": It holds that $A \simeq \lnot \lnot A$,
where $A$ excludes a set of points of measure zero.
This is really interesting, since it gives some sort of oddball probabilistic
flavour to things where if we blind ourselves to measure-0 sets, then $\lnot \lnot A = A$.


Now, we look at implication. The implication $A \Rightarrow B$ is the largest
set open $C$ such that $C \land A = B$. In pictures:

```
---(========)----- A
---------(=====)-- B
---------(==)----- A && B
===)-----(======== A -> B
```

The reason this is true is that from the definition:

$$
\begin{aligned}
&\Rightarrow: L \rightarrow L;  c \leq (a \Rightarrow b) \iff (c \land a) \leq b \\
&\text{replacing $\leq$ with $=$ for insight:} \\
&\Rightarrow: L \rightarrow L;  c = (a \Rightarrow b) \iff (c \land a) = b  \\
\end{aligned}
$$

Alternatively, we can use the fact that in regular boolean algebra:
                    
$$a \Rightarrow b = \lnot a \lor b$$

to derive $A -> B$:

```
---(========)----- A
===)--------(===== NOT A
---------(=====)-- B
[Extend B to everything that doesn't include
  more of A than already included]
===)-----(======== NOT A or B = A -> B
```


#### `a -> b` as `a` contained in `b`:

We'll show that `a -> b` is true/top/the full real line if and only if
`a` is contained in `b`. We can show this using $\lnot a \lor b$ definition:

1. $a \leq b$ (given)
2. Since $a \leq b$, $\lnot a \geq \lnot b$, since $\lnot$ reverses inclusion order.
3. $x \geq y$ implies that $x \lor p \geq y \lor p$ for all p, since $p$ is 
   on both sides.
4. Specializing to $x = \lnot a$, $y = \lnot b$, $p = b$ gives us
   $\lnot a \lor b \geq \lnot b \lor b$
5. $\lnot b \lor b$ is universe $U$
6. $\lnot a \lor b \geq U$, which means it's equal to $U$ (nothing can be greater than $U$).

We can also show this geometrically:

```
----------(===)---- A
------(==========) B
----------(===)---- A && B
[Extend B to everything that doesn't include
  more of A than already included.
  But all of A is
  already included!]
================== A -> B
```


#### reading `curry`, `uncurry` using `a -> b` as containment:

`curry`, `uncurry` are the adjunction/isomorphism:

```
((c,a) -> b) ~ (c -> (a -> b))
```

Read this as:

```
( c     ,         a)     ->         b
(c `intersection` a) `contained in` b
```

if and only if

```
c      ->        (a       ->      b)
c `contained in` (a `implication` b)
```

That is, we have "read" `curry/uncurry` as:

$$
c \land a \leq b \iff c \leq a \Rightarrow b
$$

which was the definition of $\Rightarrow$ we wanted!



##### References

- [Email by Olaf Klinke on haskell-cafe](https://mail.haskell.org/pipermail/haskell-cafe/2020-May/132297.html)

# Edit distance

This implementation of edit distance crystallizes the fact that when computing
edit distance, we only ever move forwards on solving the problem. we _do not_
store the results of the overlapping computations, though we could. Rather,
the goal of this implementation is to capture the traversal pattern necessary
for edit distance into a `Cursor`, and to view the edit distance problem from
the point of view of this `Cursor`. 

The problem setting is that we have a source string, a destination
string, and we wish to perform operations that convert the source
string into the destination string. The operations allowed are to:

- Insert a character from the destination to the source.
- Remove a character from the source.
- Replace a character in the source with a character from the destination.

We want to minimise the number of operations to be used. 
Let's see how we model this.


```hs
{-# LANGUAGE ViewPatterns #-}
type Ix = Int; type DestIx = Ix; type SrcIx = Ix;
data Move = InsertFromDest DestIx |
            RemoveFromSrc SrcIx |
            ReplaceSrcWithDest SrcIx DestIx
        deriving(Show)
```

Our cost model says that each move costs `1`. We are charged for every
move we make. We are to minimize the number of operations.

```hs
movescost :: [Move] -> Int; movescost = length
```

We model this as us having a `Cursor` which contains  list `[a]` and information
about where we are in the list as an `Ix`. 
This is the same as a `Zipper` for a list, except that in this case, we only
allow ourselves to walk forward. 

```hs
data Cursor a = Cursor Ix [a]
```


- `cdone` tells is if we have completely consumed a cursor.
- `cix` tells us the index of the cursor.
- `cval` lets us dereference a cursor.
- `incr` lets us move a cursor to the next array entry.
- `cursor` converts a list into a `Cursor` at the first index.

```hs
cdone :: Cursor a -> Bool; cdone (Cursor ix vs) = ix >= length vs
cix :: Cursor a -> Ix; cix (Cursor ix _) = ix
cval :: Cursor a -> a; cval c@(Cursor ix vs) = vs !! ix
incr :: Cursor a -> Cursor a; incr (Cursor ix vs) = Cursor (ix+1) vs
cursor :: [a] -> Cursor a; cursor = Cursor 0
```

We implement `edit`, that tells us how to edit the source string into
the destination string. The convention is `edit <src-str> <dest-str>`.

```hs
-- | decide how to get ixth character of bs from our as.
edit :: Eq a => Cursor a -> Cursor a -> [Move]
```

- 1. If both strings have been consumed, then no moves are to be made.

```hs
edit (cdone -> True) (cdone -> True) = []
```

- 2. If the destination string has been fully matched while the source string
   has not, then remove characters from the source string.

```hs
edit a@(cdone -> False) b@(cdone -> True) = 
  (RemoveFromSrc (cix a)):edit (incr a) b
```

- 3. If the source string has run out of characters while the destination string
   still has characters, insert characters from the destination string.

```hs
edit a@(cdone -> True) b@(cdone -> False) = 
  (InsertFromDest (cix b)):edit a (incr b)
```

- 4. Otherwise, we have characters remaining in both strings. Try the
   options of (1) replacing a source character with a destination 
   character (2) removing a character from the source and continuing,
   and (3) if the current characters match, then keep the match and try
   to combine characters that come later in the string. We pick the
   best out of these using the `argmin` combinator.

```hs
edit a b =  
  let nomatch = argmin movescost 
                (ReplaceSrcWithDest (cix a) (cix b):edit (incr a) (incr b))
                (RemoveFromSrc (cix a):edit (incr a) b) 
  in case cval a == cval b of
      True -> argmin movescost nomatch (edit (incr a) (incr b))
      False -> nomatch 
```
      
The helper used for finding minimum according to a cost model.

```hs
argmin :: (a -> Int) -> a -> a -> a
argmin f a a' = if (f a) < (f a') then a else a'
```

# Evolution of bee colonies (TODO)

This kind of culture that beehives have is called as 'eusociality'.
I'm interested in this because I want to understand what alien societies might
look like, and what selection pressures are required to have bee-like societies
evolve. Many sci-fi books (Ender's game for example) depict aliens with such
a society, but tend to be hazy on how this state of affairs came to be.


- [Evolution of eusociality](https://en.wikipedia.org/wiki/Evolution_of_eusociality)


# Best practices for array indexing

These are rules I'm going to follow when I solve problems on 
[codeforces](https://codeforces.com/). I've arrived at these rules by repeatedly
noticing the kinds of mistakes I make and attempting to adopt conventions
to eliminate these.

##### Rule 1: Half-open intervals

Intervals are only represented as `[begin, past-the-end)` That is, we start at
`begin`, include numbers `begin+1, begin+2, ...`, upto, **but excluding**
`past-the-end`.

So, for example, `[0, 3) = [0, 1, 2]`, while `[0, 1) = [0]`, and `[0, 0) = []`.


I am not allowed to use `[begin, end]`, or `(before-begin, past-the-end)` or
any such variation I represent and think of intervals.

##### Rule 2: No relational operators when using `for/while/do while` loops.

When I write my loop conditions, I am not allowed to use relational operators.
I must only write `i != n` or `i == m`.
I am not allowed to write `i < n`, `i <= n`, `i > n`, `i >= n` for my `for` loops.


##### Rule 3: The loop iterator lives in "getting to" space:

The loop iterator `i` in `for(int i = a; i != b; ++i)` is to be thought of as
getting to/living right before" the values `[a, a+1, a+2, ... b-1]`. In
ASCII-art:

```
|| a-1 || a   || a+1 || ... || b-1 ||  b  || b+1 ||
       ^^     ^^     ^^            ^^
     (i=a) (i=a+1)  (i=a+2) ...   (i=b)
```

##### Ruel 4: One always reads loops according to the above rules

```c
for(int i = begin; i != past-the-end; ++i) {
  // NO: i from begin to past-the-end.
  // YES: [i _getting to_ the beginning] till [i _getting_ past-the-end]
}
```

#### The rationale for banning relational operators

There is a strong difference in qualia between `i < n` and `i != n`. The former
makes on aware of when the loop runs; the latter of when the loop quits.

I wish to be cognizant of the precisely when a loop quits. 
On writing `i != past-the-end`, I know that we quit as soon as we
**get past the end**. This feels much clearer than being aware that the loops
runs as long as `i < n`.

#### half-open indexing: length <-> index

The first advantage of these conventions is that 
`[begin, past-the-end)` is the same as `[begin, begin+length)`. I've found this
to be of great help to flit between length-based-thoughts and
indexing-based-thoughts.


#### half-open indexing: `0` length

The second almost trivial point is that `[begin, begin+length)` holds when
`length` is **zero**. That is,

```c
for(int i = begin; i != begin + 0; ++ i) { ... }
```

does the right thing and iterates over no elements.


#### half-open indexing: `-ve` length

The third neat point is that `[begin, begin+length)` holds even when `length`
is **negative**. Hence, if we want to index the last two elements of an
array, we recall that we start from index `(n-1)`, and we want a segment
of length `-2` from there, so our loop is:


```c
for(int i = n-1; i != (n-1) + -2; i--) {
 // loops over the correct segment.
}
```


#### half-open indexing: splitting an array

Finally, this convention helps when attempting to take the beginning part
of a list and the rest of the list. If we want to split an array into
two segments at some index `len`,

- The first sub-array is `[0, len)` since it starts at location `0` and has
  length `len`.
- Since we have taken `len` elements, the second sub-array must have length
  `n-len`. It must start at index `len` since `len` is past-the-end for the
  first sub-array. So, the second sub-array has indeces `[len, n-len)`.

Notice how we used _both_ the "length view" and the "past the end" view to
quickly derive the bounds of the second array from the first array.

#### half-open indexing: uniformly generate power-of-2 intervals.

If we want intervals of length $2^n$: `1, 2, 4, 8, ...` which is common if one
is building data structures such as segment trees and fenwick trees, 
in a half-open representation, this literally becomes `[a, a+1)`, 
`[a, a+2)`, `[a, a+4)` and so on. On the other hand, if one wants
to use closed interval based indexing, one needs to generate the
series $2^n - 1$, which is `[a, a+0]`, `[a, a+3]`, `[a, a+7]` which is
slightly more finicky.

#### How to deal with strides

If there's a loop

```c
for(int i = 0; i < 5; i += 2) { ... }
```

the naive `i != 5` translation will not work since `i` only takes
on even numbers `[0, 2, 4, 6, ...]`. For this, we can perform a
simple transformation and always make sure our loop variables increment
by `1`. In a compiler, this is often called as "canonicalizing the loop
induction variable". In LLVM the canonicalization is
[performed by the `-indvars` pass](https://llvm.org/docs/Passes.html#indvars-canonicalize-induction-variables).
The above example canonicalized becomes:

```c
// btc = backedge taken count. How many times we have
// gone past the "back edge" of the loop to go back to the
// beginning of the loop.
for(int btc = 0; btc != 5 / 2; btc += 1) { const int i = btc * 2; }
```


#### In conclusion

These are rules that I dreamed up after noticing my idiosyncracies in
loop-writing.



# Algebraic structure for vector clocks

_I_ update my time, ie, union(time me, time me), I get an element that's one up the lattice.
When I union with someone else, I get the max. So we have an algebraic structure
which is $(L, \leq, next: L \rightarrow L)$ where `next` is monotone for `(L, <=)`.
The  induced union operator $\cup: L \times L \rightarrow L$ is:

$$
x \cup y \equiv \begin{cases} \texttt{next}(x) & x = y  \\ \max(x, y) & x \neq y \end{cases}
$$

- Is the total ordering on vector clocks *not* isomorphic to the total ordering on $\mathbb{R}$?


This also shows up in the case of the "Gallager-Humblet-Spira Algorithm" and
the fragment-name-union-rule.

# Networks are now faster than disks

I learnt of this counter-intutive fact first from this
[usenix article no SQL](https://www.usenix.org/legacy/publications/login/2011-10/openpdfs/Burd.pdf).
On checking up, it seems to actually be true. 

[Jeff Dean's keynote at LADIS 2009](https://research.cs.cornell.edu/ladis2009/talks/dean-keynote-ladis2009.pdf) report these numbers:

- Round trip within same datacenter: 500,000 ns
- Disk seek: 10,000,000 ns [regular disk]

On the other hand, a commentor on [this discussion at serverfault](https://serverfault.com/questions/238417/are-networks-now-faster-than-disks)
mentioned that SSDs might be much faster, and the numbers bear out:

- Read 4K randomly from SSD: 150,000 ns
- Round trip within same datacenter: 500,000 ns
- Disk seek: 10,000,000 ns [regular disk]

# Einstein-de Haas effect

I learnt of this from hacker news. This is some crazy experiment that shows
that the 'quantum angular momentum' (spin) and the 'classical angular momentum'
need to be conserved _together_ for physics to work out:

> There's an experiment that transfers that angular momentum all the way up to
> macroscopic levels. By magnetizing a cylinder of iron, all the spins start
> pointing in the same direction. By conservation of angular momentum, the
> cylinder itself has to start spinning in the opposite direction. I'm very
> fond of this experiment, because it magnifies a strange quantum phenomenon to
> the classical level.

So, my understanding of the experiment is:

- classical angular momentum and quantum angular momentum are related.
- quantum angular momentum is decomposed into spin and orbital angular momentum.
- for something like iron, spin is 96% of magnetization
- angular momentum is proportional to magnetization
- So, the experiment measures the _spin_ (mostly) in terms of the classical
  spinning of the cylinder.


##### References

- [Einstein-de Hass effect on Wikipedia](https://en.m.wikipedia.org/wiki/Einstein%E2%80%93de_Haas_effect)


	
	
# Rank-select as adjunction

We will introduce two operations `rank`, `select`, --- these are used to
build memory-efficient data structures that can still be queried quickly.

We will show how `rank` and `select` are adjoint. This will also us to also
consider `coselect`, which is a variation of `select` that is not commonly
discussed.

```hs
{-# LANGUAGE GeneralizedNewtypeDeriving #-}

import Data.List
newtype Count = Count Int deriving(Eq, Show, Ord, Num)
newtype Ix = Ix Int deriving(Eq, Show, Ord, Num)


eqscan :: Eq a => a -> [a] -> [Count]
eqscan a0 as = map Count $ scanl (+) 0 [if a0 == a then 1 else 0 | a <- as]

-- | finds the index `Ix` in `as` at which `a` has occured
-- | for the `Count`th time.
select :: Eq a => a -> [a] -> Count -> Maybe Ix
select a0 as c = Ix <$> findIndex (== c) (eqscan a0 as)

-- | finds the number of times `a` has occured in `as` till `Ix`.
rank :: Eq a => a -> [a] -> Ix -> Count
rank a as (Ix ix) = (eqscan a as) !! ix
```

Given this, we can prove that `select` and `rank` are adjunctions. There
are different ways to think about this. My favourite way to is to notice
that an `Ix` (index) is much "finer" information than `Count`. Hence,
the concrete domain must be `Ix`, the abstract domain must be `Count`,
and rank-select is an abstract interpretation!

##### Co-select

We can build another version of `select` called `co-select` that scans
from the right. Alternatively, it finds on the reverse list:

```
coselect :: Eq a => a -> [a] -> Count -> Maybe Ix
coselect a0 as c = Ix <$> findIndex (== c) (reverse (eqscan a0 as))
```

Thanks to Edward Kmett for teaching me this.


# Bounding chains: uniformly sample colorings

We wish to _uniformly sample_ `k` colorings of a graph $G$ with maximum degree
$\Delta$. Hence, we require $k \geq \Delta + 1$. To perform this sampling,
we use MCMC to sample from a markov chain whose states are $k$-colorings of $G$,
whose stationary distribution is the uniform distribution over valid colorings.


The issue with MCMC techniques is that we never know when our chain has reached
the stationary state. To ensure we receive uniformly distributed samples,
we built a "bounding chain" $W$ which has the following properties:

- States of $W$ cover states of $X$ [ie, state space of $W$ are subsets of the state space of $X$].
- $W$'s convergence to a stationary state can be checked.
- Upon convergence of $W$, state of $W$ = state of $X$.

We will in fact run the $W$ chain, and prove that running the $W$ chain
is equivalent to running a 'shadow' of the $X$ chain, and that stationary
states of the $W$ chain correspond to stationary sates of the $X$ chain.

Let $X$ be the chain whose states are valid $k$ colorings of $G$. In one step
of the chain $X$, we choose a vertex $v$ uniformly at random; we then choose a
color $c'_v$ uniformly at random for $v$ that makes it a proper coloring. The vertex
$v$ is changed to this new color $c'$. This is a symmetric proposal distribution,
Hence this chain has the uniform distribution over $k$-colorings to be
the stationary state.

Sampling exactly from this chain is hard: construct an initial state $X_0$
amounts to finding some valid $k$ coloring which in itself might be
challenging. Worse, we do not know whether the chain $X$ has reached a
stationary state or not.

##### Bounding Chain

We construct a new chain $W$ (the bounding chain of $X$), whose states are _sets of colors_ for
vertices in $G$. Formally, the states of $W$ are functions $Vert(G) \rightarrow 2^C$ where
$Vert(G)$ denotes the vertices of $G$; $C$ the set of colors. The transition
will be to pick a vertex $v$ uniformly at random. Then, pick a new set of
legal colors $C'_v$ for $v$, such that:

- It is guaranteed that if $X$ were transitioning on $v$, the
  color $c'_v$ that would be picked by $X$ for $v$ is a member of $C'_v$. [state is covered]
- The size of the set $C'_v$ attempts to be smaller than the current set of colorings $C_v$. [convergence]

We describe the transition function next. But first, we need an alternate
lens on the transitions of $X$ that is amenable to massaging. 

#### Equivalent description of the transitions of $X$:

1. Choosing a color uniformly at random from the set of valid colors
   for a vertex.
2. Choosing colors from $C$ without replacement until we get a color 
   that is a valid color. 

We claim that (1) and (2) have the same probability distribution.

Abstracting slightly, we state:

1. Probability of choosing an element $t \in T$ uniformly from  $T \subseteq S$.
   This has probability $1/|T|$.
2. Probability of choosing a particular element $t \in T$, by picking elements
   from $S$ without replacement until we get some element in $T$.

(1) and (2) have the same probability distribution.

##### Proof by induction:

Process (2) in code is the following:

```py
def process(S, T):
  assert(issubset(T, S)) # precondition
  s = np.random.choice(S) # uniform choice over S.
  if s in T: return s # |T|/|S| prob. to enter `if`.
  else:
    # (1 - |T|/|S|) to enter `else`
    Snext = S.remove(s); return process(Snext, T) 
```


We claim that the probability that `process(S, T) = t0` for a fixed `t0` in `T`
is $1/|T|$. We create a new function `indicator` to express this:



```py
def indicator(t0, S, T):
  assert(t0 in T) # precondition
  assert(issubset(T, S)) # precondition

  return t0 == process(S, T)
```

Let's push in `t0 ==` into the definiton of `process` after inling `process`.
This gives us:

```py
def indicator(t0, S, T):
  assert(t0 in T) # precondition
  assert(issubset(T, S)) # precondition

  s = np.random.choice(S)
  if s in T:
    # T/S prob. for x in T
    return t0 == s # 1/|T| prob. for t0 == x
  else:
    #  (1 - |T|/|S|) to reach else branch.
    Snext = S.remove(s); return process(Snext, T) 

```

Now, we write down the recurrence for the probability that we are trying
to compute: $P(t0, S, T)$ is the probability that `indicator(t0, S, T)` returns
`True`. Alternatively, it's the probability that `process(S, T)` returns `t0`.

```
P(t0, S, T) = prob. that process(S, T) = t0
P(t0, T, T) = T/|T| * 1/|T| = 1/|T| [base case]
P(t0, S, T) = 1/|S| + (1 - |T|/|S|) * P(t0, |S|-1, T) [induction]
```

We assume for induction that `P(t0, |S|-1, T) = 1/|T|`. On substitution into `[induction]`,
we get:

```
P(t0, S, T) 
= 1/|S| + (1 - |T|/|S|) * P(t0, |S|-1, T) [induction]
= 1/|S| + (1 - |T|/|S|) * 1/|T| 
= 1/|S| + (1/|T| - 1/|S|)s
= 1/|T|
```
Which is indeed the same probability as (1):

> 1. Choosing an element uniformly from a subset $T$ = `1/|T|`.

##### Proof by program analysis, Version 1

```py
def process(S, T):
  s = np.random.choice(S)
  if s in T: return s
  else return process(S.remove(s), T)
```

Notice that the last return is tail-call. This program can be rewritten as:

```py
def process(S, T):
  while True:
    s = np.random.choice(S)
    if s in T: return s
    S = S.remove(s)
```

As previously, we create an `indicator` function and study its behaviour:

```py
def indicator(t0, S, T):
  assert(t0 in T) # precondition
  assert(issubset(T, S)) # precondition

  while True:
    s = np.random.choice(S)
    if s in T: return t0 == s
    S = S.remove(s)
```

We know that this programs only returns a value from the line:
- `if s in T: return t0 == s`

We now compute `P(process(S, T) == t0)`.
Whatever the return value of `indicator`, we can assume that it occured within
the `if` condition. We can use this to compute:

```
P(indicator(t0, S, T) = True)
 = P(t0 == s | s in T) [program only returns in this case]
 = 1/|T|
```

##### Proof by program analysis, Version 2


Alternatively, we can also analyze this as we did in the _first_ proof,
using the rule:

```py
def f():
  return if cond1 then cond2 else cond3
```

will have probability:

```
P(cond1) * P(cond2|cond1) + P(not cond1) * P(cond3|not cond1)
```

Using this, we can analyze `indicator `as:

```
P(indicator(t0, S, T) = True)
 = P(s in T) * P(t0 == s |s in T) + 
    P(s not in T) * P(indicator(t0, S.remove(s), T) | s not in T)
 = |T|/|S| * 1/|T| + 
    (|S|-|T|)/|S| * P(indicator(t0, S.remove(s), T))
 = 1/|S| + (|S|-|T|)/|S| * 1/|T| [by induction]
 = 1/|T|
```

#### Sampling using the above definition

Recall that $State(X) \equiv V \rightarrow C$, $State(W) \equiv V \rightarrow 2^C$.
Let $x[~], w[~]$ be the states of some run in the markov chains.

We start by having $x[0]$ to be _any_ valid k-coloring of $G$, and $w[0]$ to
be the state where all vertices have all possible colors; $w[0] \equiv \_ \mapsto C$.
Clearly, $x[0] \in w[0]$.


By induction we assume that $x[n-1] \in w[n-1]$. We must now calculate a
$w[n], x[n]$ such that (1) $x[n] \in w[n]$, (2) $x[n]$'s proposal is symmetric. 
(3) $w[n]$'s proposal is symmetric.

##### Occluded set $O$

Define $O \subseteq C$ (for occluded) be the set colors that might possibly
be blocked for $v$ from our view of `w`. Note that this is an
**over-approxmation**: that is, there may be colors that are not blocked for `v`, which we
believe to be blocked from `w`'s point of view.

$$O \equiv  \{ c \in C : (v, \alpha) \in E, c \in w[n-1](\alpha) \}$$

##### Allowed set $A$

Define $A \subset C$ (for allowed) to be $C - O$. Note that $A$ is
an **under-approxmation**, since `O` was an _over-approximation_. That is:
- Any color in `A` is definitely a legal color for `v` in `x[n]`.  
- There are colors which are legal for `v` in `x[n]` that is not in `A`.

##### S: the sequence of states for transition

Now, we pick elements of $C$ in sequence till we get an element of `A`.
call this sequence $S$. 

We will at worst pick $\Delta + 1$ elements for $S$, since the max-degree
of the graph is $\Delta$.

##### Transition

Let $i$ be the first index in $S$ where we get a color that is _truly legal_
for $v$ in $x[n]$. Note that such an index will always exist: We pick
elements into $S$ till we get an element in $A$, and elements of $A$ are 
always legal. However, there can be elements which are not in $A$ that
are still legal for $v$ in $x[n]$, since $A$ is an under-approximation.

- We assign $x[n](v) = i$. So, `x` only cares about `S[:i]`.
- We assign  $w[n](v) = A$. So, `W` cares about the entire sequence.

By the lemma proven, we know that this process of picking colors `C` 
in a sequence till we get a color that is legal for $v$ at index $i$
is the same as picking uniformly at random from the set of colors that are legal for 
$v$. 


#### An example
For example, we could have:

```
X | p:2 --- q:4
W | p:{1, 2} --- q:{4, 5}

we are sampling q:

O = {1, 2}
A = {3, 4, 5}
S = [2, 1, 3]

X | p:1 -- q:2 
W | p:{1, 2} -- q:{1, 2, 3}
```

If we analyze `S = [2, 1, 3]` we notice that:

```
2: invalid for W(p:[1, 2]), invalid for X(p:2)    
1: invalid for W, valid for X  
3: valid for W, valid for X
```

So, what we are really sampling ix:
- A _prefix_ sequence `SX = [1]` (for Xs transition)
- A _leftover_ sequence `SW = [2, 3]` (for Ws transition)


To transition `X`, we can safely drop `SW`. However, to transition `W` correctly,
we generate more elements in the sequence, till we hit a "safe" element.


#### An optimisation on picking colors: why we need a blocking set


Define the set $B \subseteq C$ (for blocked) which governs which values
$x[n]$ **surely cannot take** from our view of $w[n-1]$.
Note that $B$ is an **under-approximation**. `v` might have
more colors that are blocked than what `w` sees.

$$B \equiv \{ c \in C : (v, \alpha) \in E, w[n-1](\alpha) = \{c\} \}$$
       
Rather than sampling colors from `C` till we get an element of `A`, we can
sample colors from `C/B`. We know that the colors in `B` can **never** be used 
by $X$, since the colors in `B` are those that we know are blocked **for sure**.

This is used in the theoretical analysis of the paper.

#### Termination

We terminate when $W$ has "trapped" $X$. That is, $|w[n](v)| = 1$ forall $v \in V$.
In such a case, the states of $W$ is equal to states of $X$. This is
a coalescence (as it occurs in coupling from the past). From the coupling
from the past theory, we know that we have reached a stationary state of $A$
when this happens.


#### Pseudocode

```hs
-- | colors, vertices, edges
cs :: [C]; cs = ...
vs :: [V]; vs = ...
es :: [(V, V); es = ...


-- | definitely not allowed
blocked :: (V -> [C]) -> (V -> [C])
blocked v2cs v0 = concat [v2cs w | (v, w) <- es, v == v0, length (v2cs w) == 1]


-- | maybe not allowed
occluded :: (V -> [C]) -> (V -> [C])
occluded v2cs v0 = concat [v2cs w | (v, w) <- es, v == v0]

-- | definitely allowed from Ws point of view
allowed :: (V -> [C]) -> (V -> [C])
allowed v2cs = cs \\ occluded v2cs 

-- | perturb the color function to another function
perturb :: (V -> [C]) -> Rand (V -> [C])
perturb v2cs = do $ 
  randv <- uniform_rand vs
  randc_for_v <- uniform_rand (allowed v2cs v)
  return $ \v -> if v == randv then randc_for_v else v2cs v
  

-- | check if we are done
terminated :: (V -> [C]) -> Bool
terminated v2cs = all [length (v2cs v) == 1 | v <- vs]

-- | generate chain
chain :: (V -> [C]) -> Rand [V -> [C]]
chain f = do
  if terminated f 
  then [] else do 
    f;' <- perturb f; fs <- chain f'; return (f:fs)

-- | return a sample
sample :: (V -> [C]) -> Rand (V -> [C])
sample = last . chain

```



##### References

- [Exact Sampling and Approximate Counting Techniques](https://dl.acm.org/doi/10.1145/276698.276709)

# Coupling from the past

##### Relationship between CFTP and reset transitions

##### References
- [Dan piponi, running from the past](http://blog.sigfpe.com/2018/10/running-from-past.html)
- [Coupling from the past, a user's guide](https://pdfs.semanticscholar.org/622e/a9c9c665002670ff26119d1aad5c3c5e0be8.pdf)


# Word problems in Russia and America

- [link to article by *Andrei Toom*](http://toomandre.com/travel/sweden05/WP-SWEDEN-NEW.pdf)

scathing critique of how ameriacn math education is screwed:
 also, interesting
anecdote about how looking for 'reality' in mathematical problems may in fact
break student's ability to think in the abstract! This is a deep insight.

# Encoding mathematical hieararchies

I've wanted to learn how the SageMATH system is organized when it comes to math
hieararchies. I also wish to learn how `lean4` encodes their hiearchies. I know
how mathematical components does it. This might help narrow in on what what the
"goldilocks zone" is for typeclass design.

##### References

- [Slides : Infrastructure for generic code in `SageMath`](https://cicm-conference.org/2016/slides/I3.pdf)
- [Tabled typeclass resolution](https://arxiv.org/abs/2001.04301)
- [Mathematical components, the book](https://math-comp.github.io/mcb/)



# Learning code by hearing it

I learnt of this from an amazing discussion on HackerNews, where a sighted
programmed, who is going blind, asked the community if he could remain
a software engineer. An answer by `kolanos` read:

> You can definitely continue as a software engineer. I'm living proof. ...
> For example, as you get better with a
> screen reader, you'll be bumping the speech rate up to 1.75-2X normal speech.
> ... Typos will be easily spotted as they just won't "sound right". It will be
> like listening to a familiar song and then hitting an off note in the melody.
> **And this includes code**. Also, because code is no longer represented
> visually as blocks, 
> you'll find you're **building an increasingly detailed memory model of your code**.  
> Sighted people do this, too, but they tend to visualize in their mind. When
> you abandon this two dimensional representation,
> **your non-visual mental map suffers no spatial limits**. You'll be amazed
> how good your memory will get without the crutch of sight.

I find this incredibly fascinating. I think I'm going to try this: I'll listen
to lectures on `1.5-2x` anyway, so this may work just as well. I'm planning
on trying this with the MLIR codebase, which I want to get to know intimately.
I'll write updates on how this goes.

[Drew DeVault](https://drewdevault.com/) also posted links to tools/scripts
for programming without needing visual feedback:
- [vimspeak.vim](https://git.sr.ht/~sircmpwn/dotfiles/tree/master/lib/vim/vimspeak.vim)
  for, if I understand correctly, speaking out loud the current state
  [which buffer, which mode, what line], as well as reading out text from
  the buffer.
- [An extension to the Sway tiling window manager](https://git.sr.ht/~sircmpwn/dotfiles/tree/master/bin/swaytalk)
  for providing audio cues.

I also learnt about [emacspeak](http://emacspeak.sourceforge.net/), which
supposedly works well for an audio-based-workflow.


- [https://news.ycombinator.com/item?id=22919455]

### Setting up festival

It seems that festival is the best(?) TTS engine for linux. One should
1. install `festival`
2. install the voice packs, given by the name `festvox-*`.
3. The best (?) festival voice is supposedly in the package `festvox-us-slt-hts`,
   with voice name `voice_cmu_us_slt_arctic_hts`. The pacakge is also available at
   the debian site: https://packages.debian.org/sid/all/festvox-us-slt-hts/download
4. edit the festival config file `/etc/festival.scm` and add a line

```
; the ' is important to escape the string
; (set! voice_default '<voice-name>)
(set! voice_default 'voice_cmu_us_slt_arctic_hts)
```

### Setting up SVOX pico2wave

- Ubuntu package: `sudo apt install libttspico-utils`
- Run instructions: 

```
#!/bin/bash
pico2wave -w=/tmp/test.wav "$1"
aplay /tmp/test.wav
rm /tmp/test.wav
```



# Your arm can be a spinor

I tend to forget the name of this trick. It exhibits spinors in real life:
a system that needs to rotate by 720 degrees to return back to its
original state, versus the usual 360 tha we are generally used to. We need
to consider our entire arm + cup we are holding as a system for this to work.

- ['Plate trick'](https://en.wikipedia.org/wiki/Plate_trick)
- [Baliense cup trick](https://www.youtube.com/watch?v=Rzt_byhgujg)


# Self modifying code for function calls: Look ma, I don't need a stack!

If one does not have recursive calls, one can eliminate the need to push
return addresses on a call stack by writing self-modifying code ---
I leant of this from TAOCP, volume 1. 
Knuth shows this off once he introduces `MIXAL`, his fantasy
aseembly language in which TAOCP programs are written.

I'll explain the usual way one performs call-return, then explain the nifty
self-modifying-code way. I think this is the cleanest, most accessible
example of self-modifying-code that I know. 

#### The traditional solution for `call/ret`

We wish to have function `f` call function `g`. For `g` to be able to
return control to `f`, `f` pushes a return address into the call stack,
that `g` pops and `jmp`s to `f`s body. In code:

```text
START_F:
      ...
L0    push addr(L0); location of instr to be run after call.
      jmp START_G
L1:   <code after call>

=========

g's body
START_G:
      ...
      retloc = pop ; pop location to jump to
RETG: jmp retloc

```


Rather than `push` ing and `pop` ing, we can _rewrite_ the code of `g`, to
_change_ `retloc` before a call to `g`. In made-up-pseudocode, here's what that
would look like:


#### The jump based solution

```text
* f's body
START_F:
      ...
L0    store loc(RETG) assemble(jmp addr(L1))
      jmp START_G
L1:   <code after call>

=========

* g's body
START_G:
      ...
RETG: <###-to-be-filled-dummy-###>
```

instead of having a call stack, before `f` calls g, `f` modify `g`'s code at location `RETG`
into a `jmp` instruction by `store` ing the instruction `jmp addr(L1)`.
This effectively creates a 'custom' `g` that knows how  to return
control flow into `f`.

```
* g's body (after execution of L0)
START_G:
      ...
RETG: jump addr(L1)
```

This way, we have obviated the need for a `push/pop` sequence, by directly
modifying `g`'s code. This is really neat --- we replace the overhead of
a `push/pop` with a single `store`.

#### Why recursion breaks.

We don't actually need a call stack, as long as we don't want to write recursive functions.
We can't have recursion, or more generally "re-entrance": consider a call chain of the form:

- `A -> B -> C -> B`.
- during `A -> B`, `A` will scribble a `<return to A>` into `B`.
- during  `B -> C`, `B` will scribble a `<return to  B>` into `C`.
- during `C -> B`, `C` will scribble `<return to C>` into `B`,
  **destroying the previous `<return to A>` **.
- This creates a cycle, where `C` will attempt to return to `B`
  and vice versa.


# Adjunctions as advice

An adjunction `F |- U` allows us to go from `F a -> x` to `a -> U x`. We 
can look at this as shifting the "before-advice" from the _input_ to an 
"after advice" of the _output_, where I'm using
<!-- [advice in the CLOS/LISP sense](https://en.wikipedia.org/wiki/Advice_(programming)) -->

Also, to remember this, we can write it as:

```
F a <--F--- a
|           |
v           v
x ----U--> U x
```

Where `F` is for `F`ree and `U` is for forgetf`U`l.
Recall that if `F` is free and `U` is forgetful, then `U(F(x)) = x`, since
adding more structure through the free functor and then stripping it away gives
us the object back. We can prove that if `U(F(x)) = x` and `U, F` are functors,
then we have a function `fwd: (f a -> x) -> (a -> u x)` as:

```
f      :: (f a -> x) 
fmap   :: (p   -> q) -> (u p     -> u q)
fmap   :: (p   -> q) -> (u ( p ) -> u q)
fmap f :: (f a -> x) -> (u (f a) -> u x) 
fmap f :: (f a -> x) -> (a       -> u x) [using u (f a) = a]
```




#### References

- [Profunctor optics: the categorical approach, `33:00` onwards](https://www.youtube.com/watch?v=l1FCXUi6Vlw)



# Reversible computation as groups on programs

If we consider a language like [`Janus`](https://en.wikipedia.org/wiki/Janus_(time-reversible_computing_programming_language)
where every program is reversible, we can then get a group structure on
programs with the identity program not computing anything at all, the inverse
performing the reverse operation. 

Alternatively, one can use the trick from quantum mechanics of using anciliary
qubits to build reversible classical gates. 

The question is, do either of these approaches allow for better-than-STOKE
exploration of the program space? Ie, can we somehow exploit the 
discrete group structure (in the case of Janus) or the Lie group structure
of the unitary group (as in the QM case) to find programs in far quicker ways?

# Blazing fast math rendering on the web

So, I've shifted the blog to be static-site-generated using a
static-site-generator written by yours truly. The code clocks in at around a
thousand lines of C++:

- [bollu/bollu.github.io/builder/builder.cpp](https://github.com/bollu/bollu.github.io/tree/master/builder/builder.cpp)

What did I gain?

1. My generator is a real compiler, so I get errors on math and markdown
  malformation.
2. I can write math that _loads_ instantly on your browser, using no MathJax,
   KaTeX or any client side processing, _nor_ the need to fetch images, which looks like this:

$$
h(x) \equiv 
\begin{cases} 
\int_{i=0}^\infty f(x) g(x) dx & x > 0 \\
\sum_{i=0}^\infty f(x) + g(x) & \text{otherwise}
\end{cases}
$$

#### Why?

My blog is a [single 9000 line markdown file](https://github.com/bollu/bollu.github.io/blob/master/README.md),
rendered as a _single HTML page_, so I 
_need it to compile fast, render fast, render beautiful_. 
Existing tools compromise on one or the other.

#### No seriously, why a single markdown file?

I need a single file to edit, so I can rapidly jot down new ideas. This is 
the essence of why I'm able to log most of what I study: 
_because it's seamless_.

Far more importantly, it provides **spatio-temporal locality**. I add things
in chronological order to tbe blog, as I learn thing. If I need to recall
something I had studied, go to that location in the blog 
_based on a sense of when_. 

When I do get to a location I want, the scrollbar gives me a sense of 
_where I am_ in the file.  this is important to me, since it hepls me reason
spatially about what i know and what I've learnt. It's someting I love about
books, and deeply miss when navigtaing the web.I'm determined to keep this
spatio-temporal locality on my little slice of the internet.

#### Why is this awful?

As elegant as this model is to _edit_, it's awful for browsers to render. The
file used to take on the order of minutes for all the math to finish
rendering. MathJax (and KaTeX) painfully attempt to render each
math block. As they do, the page jumps around until everything has settled.
As this is happening, your CPU throttles, your lap or hand gets warm,
and the page is stuck. Clearly not great UX.

I still want math. What do I do?  The solution is easy: Approximate the math
rendering using ASCII/UTF-8 characters!  There are tools that do this ---
[`hevea`](http://hevea.inria.fr/) is one of them. Unfortunately, there is no
markdown-based-blogging-platform that uses this, so I _had_ to write my own.

#### The cure

The solution is easy. I wrote the tool. The page you're reading it
is rendered using the tool. All the math renders in under a second because
it's nothing crazy, it's just text and tables which browsers know how to
render. No JavaScript necessary. snappy performance. Whoo!

#### The details: Writing my own Markdown to HTML transpiler.

the final transpiler clocks in at `1300Loc` of C++,
which is very small for a feature-complete markdown-to-HTML piece of code
that's blazing fast, renders math correctly, and provides error messages.

#### Quirks fixed, features gained.

I got quite a bit "for free" as I wrote this, fixing mild annoyances
and larger pain points around using github + markdown for publishing on
the web:

- I really don't want tables, but I do want the ability to write vertical bars 
  `|` freely in my text. Unfortunately, github _insists_ that those are tables,
   and completely wrecks rendering.

- I get line numbers in code blocks now, which Github Flavoured Markdown
  did not have.

- I get error messages on incorrectly closed bold/italic/code blocks, using
  heuristics that prevent them from spanning across too many lines.

- I get error messages on broken latex, since all my latex passes through
  `hevea`. This is awesome, since I no longer need to refresh my browser,
  wait for mathjax to load, go make myself tea (remember that mathjax was slow?),
  and then come back to see the errors.

- I can get error messages if my internal document links are broken. To be
  fair, my tool doesn't currently give me these errors, but it can (and soon
  will).

- In general, I get _control_, which was something I did not have with
  rendering directly using Github, or using someone else's tool.

#### Choice of language

I choose to write this in C-style-C++, primarily because I wanted the tool
to be fast, and I'd missed writing C++ for a while. I really enjoy how
stupid-simple C style C++ turns out to be: the C++ papers over some of C's
annoyances (like formatted output for custom types), while still preserving the
KISS feeling of writing C++.

**Why not Rust?** I freely admit that rust might have been a sane choice as
well.  unfortunately, asking rust to treat UTF-8 string as a "ball of bytes" is
hard, when it's stupidly easy with C. Plus, I wanted to use arena-style-allocation
where I make _huge_ allocations in one go and then don't think about memory,
something that I don't have control over in Rust. I don't have any segfaults
(yet, perhaps), thanks to UBSAN and ASAN. I find Rust to have more impedance
than C on small applications, and this was indeed small.


#### Performance

Everything _except_ the latex to HTML is blazing fast. Unfortunately,
calling `hevea` is slow, so I implemented a caching mechanism to make using
`hevea` not-slow. `hevea` does not have an API, so I need to `fork` and
talk to its process which is understandably flow. I built a "key-value-store"
(read: serialize data into a file) with the stupidly-simple approach of writing
an append-only log into a file. `hevea` is a pure function conceptally,
since on providing the same latex input it's going to produce the same HTML
output, so it's perfectly safe to cache it:

```cpp
const char DB_PATH[]="./blogcache.txt";
unordered_map<ll, const char *> G_DB;
void loadDB() {
    G_DB = {};
    FILE *f = fopen(DB_PATH, "rb");
    ...
    while (!feof(f)) {
        ll k, len;
        fread(&k, sizeof(ll), 1, f); if (feof(f)) break;
        fread(&len, sizeof(ll), 1, f);
        ...
        char *buf = (char *)calloc(sizeof(char), len + 2);
        fread(buf, sizeof(char), len, f);
        ...
    }
    fclose(f);
};

const char *lookup_key(ll k) {
    unordered_map<ll, const char *>::iterator it = G_DB.find(k);
    if (it == G_DB.end()) { return nullptr; } return it->second;
};

void store_key_value(const ll k, KEEP const char *v, const ll len) {
    assert(G_DB.count(k) == 0);
    G_DB.insert(make_pair(k, strdup(v)));

    FILE *f = fopen(DB_PATH, "ab");
    assert(f != nullptr && "unable to open DB file");
    fwrite(&k, sizeof(ll), 1, f);
    fwrite(&len, sizeof(ll), 1, f);
    fwrite(v, sizeof(char), len, f);
    fclose(f);
}
```

#### For the future

I plan to rip out `hevea` and write my own `latex -> HTML` converter for
the _subset of LaTeX I actually use_. `hevea`'s strength is its downfall:
It can handle all of LaTeX, which means it's really slow. If I can concentrate
on a small subset, I don't need to play caching tricks, and I can likely
optimise the layout further for my use-cases.

I also want colored error messages, because who doesn't?

I'll probably gradually improve my static site generator over time. Once it's
at a level of polish where I'm happy with it, I'll spin it out as a separate
project.

#### Conclusions

Am I glad I did it? Yes, purely because my chunk of the internet aligns with
how I want it to be, and that makes me $\epsilon$ more happy.

I think of it as an investment into future me, since I can extend the
markdown and the transpiler in the way _I_ want it to be.

# VC dimension

Consider a ground set $X$. Let the space of all possible binary classifications
be the function space $C \equiv \{ f \mid f : X \rightarrow \pm 1 \}$.
Now, a hypothesis class $H$ is a subset of $C$. For example, some model
such as "return $+1$ if a point is inside a region, $-1$ otherwise" is a subset
of the full class $C$.

The VC dimension of $H$ measures how good $H$ is generating different classification.
We first need the notion of shattering to define this.

A subset $S \subseteq X$ of the ground set shatters a hypothesis class $H$
if the function $act_S$ has full range, where $act_S$ is defined as:

$$
act_S: H \rightarrow |S|^{\{0, 1\}}
act_S(h) = (h(s_0), h(s_1), h(s_2), \dots, h(s_n))
$$

That is, the hypothesis class $H$ can classify all the subsets of $S$.

Now the **VC dimension of the hypothesis class $H$ of a ground set $X$** is
the size of **largest possible $S \subseteq X$** such that $S$ is shattered
by $H$.

#### Correct interpretation
- We need _just one set_ $S$ of size $n$ to be shattered by $H$. We get
  to pick the set $S$.

#### Subtletly 1:
- We do not need _all sets_ of size $n$ to be shattered by $H$.

We **can** have the case where:

- All sets of size 3 are shattered by H
- Only one set of size 4 is shattered by H. All other sets of size 4 are not.
- Only one size of size 5 is shattered by H. All other sets of size 5 are not.
- No set of size 6 is shattered by H.

In this case, the VC dimension of $H$ is **5, not 3**.

#### Subtletly 2:

We **cannot** have the case where:
- All sets of size 3 are shattered by H
- No set of size 4 is shattered by H
- Some set of size 5 is shattered by H

For contradiction, let $S$ be the set of size $5$ that is shattered by $H$.
Let $T \subsetneq S$, $|T| = 4$. Now, $H$ shatters $T$ since $H$ shatters $S$.
Hence, Some set of size 4 has been shattered. Contradiction, since we assumed
that no set of size 4 is shattered by $H$.

So, to prove that sets of size $(\geq n)$ cannot be shattered, it suffices
to prove that sets of size equal to $n$ cannot be shattered.

#### Growth of number of sets shattered in $|S|$ for $S \subseteq X$ for a fixed $H$.

If we fix a hypothesis class $H$ for $X$, and we want to understand how $H$
varies over subsets of $X$, the idea is this:

Let $S$ be a set that is the maximum sized set that is shattered by $X$. ie,
$|S| = Vcdim(H)$ and $H$ shatters $S$.

Now, the idea is this:

- For subsets $T \subseteq S$, $|act_T(H)| = 2^{|T|}$ -- exponential.
- For subpersets $S \subsetneq Sup$, $|act_{Sup}(H) = Comb(|Sup|, |S)$ -- polynomial.

We can show that this exponential/polynomial behaviour happens in general
for $S \subseteq X$. 

# Symplectic version of classical mechanics

#### Basics, symplectic mechanics as inverting $\omega$:

I've never seen this kind of "inverting $\omega$" perspective written down
anywhere.  Most of them start by using the inteior product $i_X \omega$ without
ever showing where the thing came from. This is my personal interpretation of
how the symplectic version of classical mecanics comes to be.

If we have a non-degenerate, closed 
two-form $\omega: T_pM \times T_pM \rightarrow \mathbb R$.

Now, given a hamiltonian $H: M \rightarrow \mathbb R$, we can construct a
vector field $X_H: M \rightarrow TM$ under the definition:

$$
\begin{aligned}
&\text{partially apply $\omega$ to see $\omega$ as a mapping from $T_p$ to $T_p^*M$} \\
&\omega2: T_p M \rightarrow T_p*M \equiv \lambda (v: T_p M). \lambda (w: T_p M) . \omega(v, w) \\
&\omega2^{-1}: T_p^*M \rightarrow T_p M; dH: M \rightarrow T_p* M \\
&X_H \equiv \lambda (p: M) \rightarrow \omega2^{-1} (dH(p)) \\
&(p: M) \xrightarrow{dH} dH(p) : T_p*M \xrightarrow{\omega2^{-1}} \omega2^{-1}(dH(p)): T_pM \\
&X_H = \omega2^{-1} \circ dH
\end{aligned}
$$

This way, given a hamiltonian $H: M \rightarrow \mathbb R$, we can construct
an associated vector field $X_H$, in a pretty natural way.

We can also go the other way. Given the $X$, we can build the $dH$
under the equivalence:

$$
\begin{aligned}
&\omega2^{-1} \circ dH  = X_H\\
&dH = \omega2(X_H) \\
&\int dH  = \int \omega2(X_H)  \\
&H = \int \omega2(X_H) 
\end{aligned}
$$

This needs some demands, like the one-form $dH$ being integrable. But this
works, and gives us a bijection between $X_H$ and $H$ as we wanted.

We can also analyze the definition we got from the previous manipulation:
$$
\begin{aligned}
&\omega2(X_H) =  dH \\
&\lambda (w: T_p M) \omega(X_H, w) = dH \\
&\omega(X_H, \cdot) = dH \\
\end{aligned}
$$

We can take this as a _relationship_ between $X_H$ and $dH$. Exploiting
this, we can notice that $dH(X_H) = 0$. That is, moving along $X_H$ does
not modify $dH$:

$$
\begin{aligned}
&\omega2(X_H) =  dH \\
&\lambda (w: T_p M) \omega(X_H, w) = dH \\
&dH(X_H) = \omega(X_H, X_H) = 0 ~ \text{$\omega$ is anti-symmetric}
\end{aligned}
$$

#### Preservation of $\omega$

We wish to show that $X_H^*(\omega) = \omega$. That is, pushing forward
$\omega$ along the vector field $X_H$ preserves $\omega$.

TODO.


#### Moment Map

Now that we have a method of going from a vector field $X_H$ to a Hamiltonian
$H$, we can go crazier with this. We can _generate vector fields_ using
Lie group actions on the manifold, and then look for hamiltonians corresponding
to this lie group. This lets us perform "inverse Noether", where for a given
choice of symmetry, we can find the Hamiltonian that possesses this symmetry.

We can create a map from the Lie algebra $\mathfrak{g} \in \mathfrak{G}$ to
a vector field $X_{\mathfrak g}$, performing:

$$
\begin{aligned}
&t : \mathbb R \mapsto e^{t\mathfrak g} : G \\
&t : \mathbb R \mapsto \phi(e^{t\mathfrak g}) : M \\
&X_{\mathfrak g} \equiv \frac{d}{dt}(\phi(e^{t\mathfrak g}))|_{t = 0}: TM
\end{aligned}
$$

We can then attempt to recover a hamiltonian $H_{\mathfrak g}$ from
$X_{\mathfrak g}$. If we get a hamiltonian from this process, then it
will have the right symmetries.


# Theorems for free

These are personal notes I made of a custom notation for denoting the relations
from the theorems for free paper. I developed the notation since I wanted
to keep track of what types are floating around and what the relations are doing.

We interpret types as sets.  If elements belong to the relation, ie, if `(a, a') ∈ R ⊂ AxA`,
we will denote this as `a[A -R- A']a'`. We will now write down some inference
rules:

1. We define `ReflB` as `a[Bool ReflB Bool]a`
2. We define `ReflI` as `i[Int ReflI Int]i`
3. The product of two relations `[A R B]`, `[X S Y]` is called as `RxS`,
   and is defined as: `(a,x)[AxX RxS BxY](b,y)` iff: `∀ abxy, a[A R B]b ∧ x[X S Y]y`.
4. The list space of a `[A R B]` is called `[A* [A R B] B*]`, 
   and is defined as: `la[A* [A R B] B*]lb` iff:
   `∀ la lb, |la| = |lb| ∧ (∀ i, la[i][A R B]lb[i])`
5. The function space of two relations`[A R B]`, `[X S Y]` is called `[A->X R->S B->Y]`,
   and is defined as: `f[A->X R->S B->Y]g` iff: `∀ a b, a[A R B]b => f(a)[X S Y]g(b)`.
6. The type family space of two relations is a function that takes
   a relation `[A R B]` and produces a new relation: 
   `g[FA | [A R B] | FB]h`. The relation takes as parameter a relation `[A R B]`
    for each choice.
7. The space of relations of `∀X.F(X)` is a relation defined by:
   `g[A->FA | ∀X.F(X) [FA [A R B] FB]| B->FB]h`
    `∀ A B R, (g A)[FA | [A R B] |  FB](h B)`.

#### Parametricity theorem

The parametricity thm states that for all terms `(r: R)`, we can deduce
`r[R rel(R) R]r` where `rel(R)` is the relation that fits the type, and is
derived from the above rules.

#### Parametricity for lists when the relation is a function:

The list space of a `[A R B]` is called `[A* [A R B] B*]`, 
and is defined as: `la[A* [A R B] B*]lb` iff:
- `∀ la lb, |la| = |lb| ∧ (∀ i, la[i][A R B]lb[i])`

Now, let us take a special case where `[A R B]` is a function `δ: A -> B`. That is:
- `a[A R B]b` iff `δ(a) = b`.

If this is the case, then we can simplify the math to be:

- `la[A* [A R B] B*]lb <=> ∀ la lb, |la| = |lb| ∧ (∀ i, la[i][A R B]lb[i])`
- `la[A* [A R B] B*]lb <=> ∀ la lb, |la| = |lb| ∧ (∀ i, δ(la[i]) = lb[i]`
- `la[A* [A R B] B*]lb <=> ∀ la lb, map δ la = lb`

#### Parametricity to prove rearrangements

- `r[∀ X. X* -> X*]r`
- `(r A)[A*->A*  | [A*->A* [A R B] B*->B*] |  B*->B*](r B)`
- `as[A* [A R B]  B*]bs => (r A as)[A* [A R B] B*](r B bs)`
- Pick `[A R B]` to be a _function_ `δ: A -> B`. Ie, `a[A R B]b` iff `δ(a) = b`.
- This lets us convert all occrences of `α[A R B]ω` into `ω = δ(α)`.
- Hence, `as[A* [A R B]  B*]bs` becomes `map δ as = bs`.
- Hence, `(r A as)[A* [A R B] B*](r B bs)` becomes `map δ (r A as) = (r B bs)`
- In toto, this let us replace `bs` with `map δ as`. We derive:
- `map δ (r A as) = (r B bs)`
- `map δ (r A as) = (r B (map δ as)`
- `map δ . (r A) = (r B) . map δ`
- Replace `bs[i]` with `δ(as[i])`to get result:
   `δ(r A as[i]) = r B δ(as[i])`, which was indeed what we were looking for.


#### References
- [Theorems for free by Phil Wadler](https://ecee.colorado.edu/ecen5533/fall11/reading/free.pdf)

# How to reason with half-open intervals

I've always found code that uses half-open intervals far harder to write
than using closed intervals. For example, when performing string processing,
I prefer to write `closed` over `halfopen` since I find it easier
to think about:

```cpp
void closed(int begin, int end, char *c) { //easier
  for(int i = begin; i <= end; ++i) {... }
}

void open(int begin, int len, char *c) { //harder
  for(int i = begin; i < begin + len; ++i) { ... }
}
```

However, I realised that by changing how I think about this to:

```cpp
void open(int begin, int len, char *c) { //harder
  for(int i = begin; i != begin + len; ++i)
}
```

It somehow made it way easier to grok.

- I had problems with `<` since I would
  mentally shift from `i < begin + len` to `i <= begin + len - 1`. Making
  this move would then make _all other reasoning_ harder, since I had
  keep switching between the `<` and `<=` point of view.

- On the other hand, when using `i != begin + len`, there was a single location
  to focus on: the point `begin + len`, and what happens when `i` reaches it.

Of course, this is old had to anyone who performs loop optimisatison: LLVM
internally converts most comparisons into the `a != b` form, because it's
easier to analyse. It took me this long it's easier for me to _think_
in this viewpoint as well.


# How does one build a fusion bomb?

I haven't found anything on the internet that describes how to build
a fusion bomb; it's almost as if this information has been supressed
by governments. However, I'm curious --- would a physics grad student
studying nuclear physics or explosives have the theoretical know-how to
precisely build one, given the raw materials? Or is there some
"secret sauce" that's necessary?

I read on wikipedia that most countries classify the details:

> Detailed knowledge of fission and fusion weapons is classified to some
> degree in virtually every industrialized nation. In the United States,
> such knowledge can by default be classified as "Restricted Data",
> even if it is created by persons who are not government employees or
> associated with weapons programs, in a legal doctrine known as "born secret".

# Christoffel symbols, geometrically

Suppose we have a manifold $M$. of dimension $d$ that has been embedded isometrically
into $\mathbb R^n$. So we have a function $e: \mathbb R^d \rightarrow \mathbb R^n$
which is the embedding. We will identify $M$ to be the subspace $Im(e)$.

Recall that $\partial_{x_i} e : \mathbb R^d \rightarrow \mathbb R^n$
is defined as:

$$
\begin{aligned}
&\partial_{x_i}e : \mathbb R^d \rightarrow \mathbb R^n \\
&[\partial {x_i}e](p) \equiv
 \lim_{\delta x \rightarrow 0} \frac{e(p + (x_0=0, x_1=0\dots, x_i=\delta_x, \dots, x_n=0)) - e(p)}{\delta x}
\end{aligned}
$$

Note that it is a function of type $\mathbb R^d \rightarrow \mathbb R^n$.


- The tangent space at point $p \in Image(e)$ is going to be spanned by
  the basis $\{ \partial_{x_i}e \vert_p : \mathbb R^n \}$.
- The metric tensor of $M$,
 $g_{ij} \equiv \langle \frac{\partial e}{\partial x_i} \vert \frac{\partial e}{\partial x_j} \rangle$.
 That is, the metric tensor "agrees" with the dot product of the
 ambient space $\mathbb R^n$.
- A vector field $V$ on the manifold $M$ is by definition a combination of
  the tangent vector fields. $V(p_0) \equiv v^j(p_0) \partial_{x_j} e(p_0)$


We can calculate the derivaive of this vector field as follows:

$$
\begin{aligned}
&\frac{V(p)}{\partial x^i} = \partial_{x_i} \left[ v^j(p) \partial_{x_j} e \right] \\
&= v^j \cdot \partial_{x_i} \partial_{x_j} e + \partial_{x_j}e \cdot \partial_{x_i} v^j
\end{aligned}
$$

We choose to rewrite the second degree term in terms of the tangent
space, and some component that is normal to us that we have no
control over.

$$
(\partial_{x_i} \partial_{x_j} e )(p) \equiv \Gamma^k_{ij} \partial_{x_k} e + \vec{n}
$$

This gives us the Christoffel symbols as "variation of second derivative _along_
the manifold.


#### Relationship to the Levi-Cevita connection

The covariant derivative defined by the Levi-Cevita connection is the derivative
that contains the projection of the full derivative in $\mathbb R^n$ onto
the tangent space $T_p M$. This is defined by the equations:

$$
\begin{aligned}
 &\nabla_{e_i} V \equiv \partial_{x_i} V - \vec{n}  \\
 &= \Pi_{\vec{n}^\bot} \left [v^j \cdot \partial_{x_i} \partial_{x_j} e + \partial_{x_j}e \cdot \partial_{x_i} v^j \right] \\
 &= \Pi_{\vec{n}^\bot} \left[ v^j \cdot (\Gamma^k_{ij} \partial_{x_k} e + \vec{n})+ \partial_{x_j}e \cdot \partial_{x_i} v^j \right] \\
 &= v^j \cdot (\Gamma^k_{ij} \partial_{x_k} e + \vec 0) + \partial_{x_j}e \cdot \partial_{x_i} v^j \\
 &= v^j \cdot (\Gamma^k_{ij} \partial_{x_k} e + \vec 0) + \partial_{x_k}e \cdot \partial_{x_i} v^k \\
 &= v^j \cdot \Gamma^k_{ij} \partial_{x_k} e  + \partial_{x_k}e \cdot \partial_{x_i} v^k \\
 &= \partial_{x_k} e \left( v^j \cdot \Gamma^k_{ij}  + \partial_{x_i} v^k \right) \\
\end{aligned}
$$



#### References

- [The wikipedia page on Covariant derivative](https://en.wikipedia.org/wiki/Covariant_derivative#Informal_definition_using_an_embedding_into_Euclidean_space)

# A natural vector space without an explicit basis

On learning about infinite dimensional vector spaces, one learns that
we need to use the axiom of choice to assert that every such vector space
has a basis; indeed, it's equivalent to the AoC to assert this. However,
I had not known any "natural" examples of such a vector space till I studied
the proof of the barvinok algorithm. I produce the example here.

Consider a space such as $S \equiv \mathbb R^3$. Now, consider the vector
space spanned by the indicator functions of polyhedra in $S$. that's a mouthful,
so let's break it down.

A polyhedra is defined as a set of points that is defined by linear
inequalities: $P \equiv \{ x \in S : a_i \cdot x \leq b_i, i \in [1\dots n] \}$,
for all $a_i \in S$, $b \in \mathbb R$.

The indicator functions are of the form:

$$
[poly]: S \rightarrow \mathbb R;
[poly](x) \equiv
\begin{cases} 1 & x \in poly \\
0 & \text{otherwise} \end{cases}
$$

we can define a vector space of these functions over $\mathbb R$, using
the "scaling" action as the action of $\mathbb R$ on these functions:


The vector space $V$ is __defined__ as the span of the indicator functions
of all polyhedra. It's clearly a vector space, and a hopefully intuitive
one. However, note that the set we generated this from (indicators of polyhedra)
don't form a basis since they have many linear dependencies between them.
For example, one can write the equation:

```
*---*   *-*   *-*   *
|###|   |#|   |#|   |
|###| = |#| + |#| - |
|###|   |#|   |#|   |
*---*   *-*   *-*   *
```


# Cache oblivious B trees

Central idea: assume a memory model where computation is free, only cost
is pulling data from cache into memory. Cache has total size $M$, can hold
blocks of size $B$. So it can hold $M/B$ blocks of main memory. Memory memory
has infinite size. Cost is number of transfers.

We assume that the algorithm _does not know M or B_. We assume that the cache
replacement strategy is optimal (kick out block that is going to be used
farthest in the future). This is an OK assumption to make since an LRU cache
using _twice_ the memory of a "oracular" cache performs equally well (citation?)


These data structures are cool since they essentially "Adapt" to varying cache
hierarchies and even multiple level cache hierarchies.

We study how to build cache-oblivious B-trees.

#### Building optimal cache-oblivious B trees to solve search

- We use a balanced BST. We want to find an order to store nodes in memory
  such that when we search for an element, we minimize number of blocks
  we need to pull in.
- All standard orders such as level order, pre-order, post-order fail.
- Corrrect order is "VEB (Van Em De Boas) order": carve a tree at the middle
  level of its edges. Layout a "triangle" or smaller collection
  of nodes linearly. Then Recursively layout the trees, linearly in memory.
- Supposedly if the number of nodes is $N$, we wil have roughly $\sqrt(N)$
  nodes on the top, and then $\sqrt(N)$ _triangles_ at the bottom.

#### Analysis Claim: we need to pull $O(\log_B N)$ blocks for any $B$ for any search query

$N$ is the number of nodes in the BST. Note that in the analysis, _we know what B is_,
even though the _algorithm does not_.

- We look at a particuar level of recursion. We will call it a "level of detail"
  straddling B.
- We will have large triangles of size $\geq B$, inside which there are smaller
  triangles of size $\leq B$ (reminds me of sierpinski).
- We know that the algorithm recursively lays it out, and triangle stores
  everything "inside" it _in a contiguous region_. So we stop at the
  requisite size where we know that the tree's triangles themselves
  contain triangles which fit into the block size.
- A little triangle of size less than B can live in at most two memory blocks
  by straddling a block boundary: by eg. having $(B-1)$ bits in one block
  and a single bit in another block.

```
1 2 3 4 5 6 7 8 <- index
|     |       | <- boundary
|-xxxxxxx-----| <-  data
```

- The question is that on a root-to-leaf bpath, how many such triangles do
  we need to visit. Since we repeatedly divide the nodes in half 
  _with respect to height_ until the little triangle has number of nodes less
  than $B$, the height is going to be $O(\log B)$ since it's still a binary tree.
- total height in $O(\log N)$.
- so height of "chunked tree" where we view each triangle as a single node
  is $\log N / \log B = \log_B n$.
- **insight**: ou data structure construction in some sense permits us to
  "binary search on $B$" since we divide the data structure into levels
  based on $B$. if $B = N$, then the full data structure fits into memory
  and we're good.

#### Black box: ordered file maintainince

We need a black box: ordered file maintainance (linked list for arrays)

- Store $n$ elements in specified order in an array of linear size $O(N)$.
  Array permits gaps.
- updates: delete element, insert elements between 2 elements.
- cannot do this in linear time, but we can move elements in an interval of
  size $\log^2(N)$ amortized.
- We need $O(1)$ scans for the data structure.

#### Next: _dynamic_ BST (inserts and deletes): layout

we take a VEB static tree on top of an ordered file. Tree is a segtree
that has max of nodes. Leaves are the members of the ordered file.

#### Updates

- search for node.
- update ordered file.
- propogate updates into the tree. This will have to be done in post-order
  because we need the leaves to be fixed before we can update the parent
  `max`.

#### Updates: analysis.

- look at level of detail that straddles $B$.
- Let us look at the bottom 2 levels.
- Note that when we perform post-order inside a triangle that has 3 triangles
  of size $\leq B$, we need to alternate between parent triangle and child triangle.
  Since the parent triangle is of size $\leq B$ and can therefore take
  at most $2B$ blocks of memory, similarly the child can take at most $2B$
  blocks of memory.
- So if our cache can hold $4$ blocks of memory, we're done.
  We won't need to kick anything out when performing the post-order
  traversal.
- For levels that are above the bottom 2 levels, we're still OK. there
  are not many triangles! / not many nodes! (`1:16:00` in the video)





#### References

- [Erik demaine, advanced data structures, lecture 7: Memory hiearchy: models, cache oblivious B trees](https://courses.csail.mit.edu/6.851/fall17/lectures/L07.html?notes=5)

# Krohn-Rhodes decomposition

We denote partial functions with $X \rightharpoonup Y$ and total functions
with $X \rightarrow Y$.

A set $X$ equipped with a binary operator
$\star: X \times X \rightarrow X$ which is closed and associative
is a semigroup.

#### Partial function semigroup

For a ground set $X$, the set of partial functions $Pf(X) \equiv \{ f: X \rightharpoonup X \}$
along with function composition forms a semigroup. This is in fact stronger
than a semigroup. There exists:

- An identify function $e_x: X \rightarrow X; e_X(x) = x$
- A zero function $\theta_x: X \rightharpoonup X; \theta_x(x) = \texttt{undef}$, where by
  $\texttt{undef}$ we mean that it is _undefined_.

#### Transformation semigroup(TS)

Let $Q$ be a set. Let $S \subseteq Pf(Q)$ be a sub-semigroup of $Pf(Q)$.
Then the semigroup $X \equiv (Q, S)$ is called as the
 _transformation semigroup_(X) of states $Q$.

- The elements of $Q$ are called states of $X$
- while  the elements of $S$ are called  _actions_ of $X$.
- The set $Q$ itself is called as the _underlying set_ of $X$.
- For a fixed transformation semigroup $X$, we will write $Q_X$ and $S_X$
  to refer to its states and actions.


We call $X \equiv (Q, S)$ as a _transformation monoid_ if $S$ contains $1_Q(q) = q$.

##### Subtlety of being a transformation monoid.

There is some subttlety here. Just because $S$ is a monoid does not mean that
it that is a _transformation monoid_. It must have the identity element of
$Pf(Q)$ to be called a transformation monoid. For example, consider the
set $Q \equiv \\{ a, b \\}$ and the transformation semigroup $S \equiv \\{ f \equiv \alpha \mapsto b \\}$.
Now the set $S$ is indeed a monoid with identity element as $f: Q \rightarrow Q$.
however, $f \neq 1_Q$ , andh ence, $S$ is a not a _transformation monoid_.



##### Examples of transformation semigroups

1. $(X, \{ \theta(x) = \texttt{undef} \})$. The semigroup with the empty transformation.
2. $(X, \emptyset)$, the semigroup with _no_ transformations.


#### Semigroup action

We sometimes wish to represent a semigroup using an action/transformation semigroup
on a ground set $X$. So, given some semigroup $(T, \times)$ that needs to be represented,
if we can find a morphism $r: T \rightarrow Pf(X)$ ($r$ for representation)
such that:

- $ r(t_1 + t_2) = r(t_1) \circ r(t_2)$. [$r$ is a semigroup morphism].
- $t_1 \neq t_2 \implies \exists x \in X$ such that $r(t_1)(x) \neq r(t_2)(x)$.
  [Faithfulness].

Put more simply, $t_1 \neq t_2 \implies r(t_1) \neq r(t_2)$ where we define
function equality extensionally: $f = g \equiv \forall x, f(x) = g(x)$.


#### Embedding actions into the transformation semigroup
We often wish to represent some semigroup $S$ as the transformation semigroup
of some set of states $Q$. We can achieve this by proving a morphism:

- $r: S \rightarrow Pf(Q)$ that is faithful.

Then, we can treat elements of $S$ as elements of $Pf(Q)$.


#### Completion of a transformation semigroup

Given a transformation semigroup $X \equiv (Q, S)$ we can _complete_ it
by adding a new sink state $\bot$, and then converting all partial
functions in $S$ to total functions that transition to $\bot$. We have that
$\bot \cdot s = s \cdot \bot ~ \forall s \in S$.

We denote the completion as $X^c \equiv (Q^c, S^c)$.



#### Coverings

Let $X \equiv (Q_X, S_X)$ and $Y \equiv (Q_Y, S_Y)$ be transformation
semigroups. Let $\phi \subseteq Q_Y \times Q_X$ be a relation. Let $s_x \in S_X$
and $s_y \in S_Y$. Then, if the following diagram commutes:

$$
\begin{array}{ccc}
a & \rightarrow & b \\
\downarrow & & \downarrow \\
x & \rightarrow & y \\
\end{array}
$$

If $s_x(\phi(q_y)) = \phi(t_y(q_y))$ then we say that $t_y$ covers $s_x$ relative to $\phi$.
We imagine the $t_y$ lying above $s_x$, being projected down by $\phi$.

If a fixed $\phi$, for all $s_x \in S_X$ there exists a $t_y \in S_Y$ such that
$t$ covers $s$ relative to $\phi$, then we say that $\phi:$ is a 
_relation of automata_.

- If $\phi: Q_Y \rightarrow Q_X$ is surjective,
  then we say that $\phi$ is a __relational covering__ and write: $X \triangleleft_{\phi} Y$.
- If $\phi \subseteq Q_Y \times Q_X $ is _both_ surjective and partial,
  then we say that $\phi$ is a __covering__ and write: $X \prec_\phi Y$
- If $X \prec_\phi Y$, we say that $Y$ dominates $X$, or $Y$ covers $X$, or
  $X$ divides $Y$.

#### Checking coverings and generating subsets

We note that for a given covering $\phi$, if $s_x$ is covered by $t_y$
and $p_x$ is covered by $q_y$, then $s_x \circ t_x$ is covered by $t_y \circ q_y$.

Thus, to check if $X$ is covered by $Y$, we simply need to check if 
__some generating subset of $X$ is covered by $Y$__.

#### Checking coverings of representations

Let us assume we have a representation of a transformation semigroup
given with a semigroup $\Sigma$, a transformation semigroup
$X \equiv (Q_X, S_X)$, and a representation $r: \Sigma \rightarrow S_X$ that is
faithful.

Now, to check that $X$ is covered by another $Y$, it suffices to check that
there exists a $t_y \in Y$ for each $\sigma \in X$ such that $r(\sigma)$ is
covered by this $t_y$.

#### Companion relation
Given a relation $\phi: Y \rightarrow X$, then we define:

$$
\Sigma \equiv \{ (s, t) : t \in T_Y \text{ covers } s \in S_X \}
$$

Recall compositions of elements are covered by a composition
of their coverings. Hence, if $(s, t), (s', t') \in \Sigma$, then
$(ss', tt') \in \Sigma$. thus, $\Sigma$ is a subsemigroup of $S_X \times S_Y$.

We can regard $\Sigma$ as the graph of a relation $\phi' \subseteq Q_Y \times Q_X$.
This will be called as __companion relation__ of $\phi$.

#### Wreath products

Let $X \equiv (Q_X, S_X)$ and $Y \equiv (Q_Y, S_Y)$. We're going to define a large
product $X \wr Y$.

We begn with the set $W \equiv S_X^{Q_Y} \times S_Y$, where
$S_X^{Q_Y} \equiv \{ f : Q_Y \rightarrow S_X \}$.
The wreath product then becomes:

$$
X \wr Y \equiv (Q_X \times Q_Y, W)
$$

with the action of $W$ on an element of $Q_X \times Q_Y$ being defined as:

$$
(f : Q_Y \rightarrow S_X, s_y : S_Y) (q_x : Q_X, q_Y : Q_Y) \equiv ( f(q_y)(q_x) , s_y (q_y))
$$

it's a "follow the types" sort of definition, where we edit the right component
as $r_y \mapsto t_y(r_y)$ since that's all we can do. In the case of
the left component, we have a $q_x$, and we need to produce another element
in $Q_X$, so we "must use $f$". The only way to use $f$ is to feed it
a $t_y$. This forces us into the above definition.


##### Composition of wreath products

To show that its closed under composition, let's consider $(f, s_y), (g, t_y) \in W$
with $f, g: Q_Yg \rightarrow S_X$, and $s_y, t_y \in S_Y$. The result is
going to be:

$$
(f, s_y)  (g, t_y) =  (\lambda q_y. f(q_y) \circ g(q_y), t_y \circ u_y)
$$

#### Equivalences of subsets of states

Let $X = (Q, S)$ be a transition system. Given subsets $(a, b, \subseteq Q)$,
we shall write $b \leq a$ if either $b \subseteq a$ or there exists some $s \in S$
such that $b \subseteq sa$, where $s(a) \equiv \{ s(a_i) : a_i \in a\}$. We can
define an equivalence relation $a \sim b \iff a \leq b \land b \leq a$.

##### Note
$ b \leq a \implies |b| \leq |a|$, since 
$b \leq a$ means that $b \subseteq s(a)$. Note that $s$ is actually a
function $s: Q \rightarrow Q$, and a function mapped over a set can only
ever decrease the number of elements in a set, since a function can only
xglomp elements together; it can never break an element apart into two.
Hence, $b \subseteq sa \subseteq a$, and thus $|b| \leq |a|$.


Similiarly, $a \leq b \implies |a| \leq |b|$. Therefore, $b \sim a$ means
that $|b| = |a|$.

##### Theorem
for all $a, b \in Q_X$ such that
$a ~ b$ such that $b \subseteq s(a)$, we show that $b = s(a)$, and there exists
a $t \in S_X$ such that $a = t(b)$.

##### Proof
Since $b \subseteq s(a) \subseteq a$ and $|b| = |a|$, $b = s(a)$.
Therefore $s$ is a permutation. Hence, $s$ is invertible and there exists
an inverse permutation $t$ such that $a = t(b)$. We now need to show that
$t \in S_X$. To do this, first note that if the order of the permutation
$s$ is $n$, then $t = s^{n-1}$, since $t \circ s = s^{n-1} \circ s = 1_S$.
Since the semigroup $S$ is closed under composition $t = s^{n-1}$ is in $S$,
since it is $s$ composed with itself  $(n-1)$ times.

#### Subset families of interest

We will be interest in a family of subsets of $Q_X$ called $A$, of the form:
- all sets of the form $s(Q)$ for all $s \in S_X$
- the set $Q$
- the empty set $\emptyset$
- all the singleton sets $\{ q \}$ for all $q \in Q$.

In the above set, we have $\leq$ and $\sim$ as defined above.

We note that the set $A$ is **closed under the action of all $s \in S_X$**.
For example, the empty set is taken to the empty set. All singleton
sets are taken to other singleton sets. For the full set $Q$, we add
the sets $s(Q)$ for all $s \in S_X$.

#### Height function

A height function for a transition system $X \equiv (Q_X, S_X)$ is a function
$h: A \rightarrow \mathbb Z$ such that:


1. $h(\emptyset) = -1$.
2. $h(\{ q \}) = 0 \forall q \in Q$.
3. $a \sim b \implies h(a) = h(b)$ for all $a, b \in A$.
4. $b < a \implies h(b) < h(a)$ for all $a, b \in A$.

The notation $b < a \equiv (b \leq a) \land \lnot (a \leq b)$.

(3) + (4) imply that two elements of the same height are either equivalent
or incomparable.

#### Pavings and bricks

for $a \in A$ such that $|a| > 1$, we denote by $B_a$ the set of all $b \in A$
what are maximal subsets of $a$. That is, if $b \in B_a$ then $b \subsetneq a$,
and $\not \exists c, b \subsetneq c \subsetneq a$. Equivalently, if there
exists a $c$ such that $b \subseteq c \subseteq a$, then $b = c$ or $b = a$.

Note that we can assert that $a = \cup_{b \in B_a} b$. This is because $B_a$
contains all the singletons of $Q_X$. so we can begin by writing $a$ as
a union of singletons, and then merging elements of $B_a$ into larger elements
of $B$, terminating when we cannot merge any more elements of $B_a$.

- The set $B_a$ is called as the **paving of $a$**.
- The elements of $B_a$ are called as the **bricks of $a$**.

#### Group of permutations for $a \in A$

Let us assume that there exists a $s \in S$ such that $s(a) = a$. Let $A_a$
be the set of all elements in $A$ contained in $a$:
$A_a = \{ A_i : A_i \in A, A_i \subseteq a \}$.

Recall that the set $A$ was closed under the action of all $s$, and hence,
since $s$ is a permutation of $a$, this naturally extends into a
permutation of $A_a$: $s A_a = A_a$. Now note that this induces a permutation
of the set $B_a$. This creates a transition system:

$$
\begin{aligned}
&G_a \equiv \{ s \in S : s a = a \} \\
&H_a \equiv (B_a, G_a) \\
\end{aligned}
$$

We have already shown how if $s \in S$ defines a permutation of some set $X$
by its action, then its inverse also exists in $S$. So, this means that
$G_a$ is in fact a transition _group_ that acts on $B_a$.

It might turn out that $G_a = \emptyset$. However, if $G_a \neq \emptyset$,
then as stated above, $G_a$ is a group.

We will call such a transition group a **generalized transition group**, since
either $G_a = \emptyset$ or $G_a$ is a group.


Now, the generalized transition group $H_a$ is called as the
**holonomy transition system** of $a$, and the group $G_a$ is called as
the **holonomy group** of $a$.


We have that $G_a \prec S$ since $G_a$ is a quotient of the sub-semigroup
$\{ s | s \in S, as = a \}$. (TODO: so what? why does this mean that it's $\prec$?)

##### Theorem:

If $a \sim b$, then $H_a \simeq H_b$ (similar subsets have isomorphic holonomy transition systems).

##### Proof:

Let us assume that $a \neq b$. since $a \sim b$, we have elements
of the form $s, s^{-1} \in S$ such that $b = s(a)$, $a = s^{-1}(b)$.

Recall that for $b_a \in B_a$ is such that for a member $g \in G_a$,
$g(b_a) = b_a$. $B_b$ must have the element $s(b_a) $  [TODO!]

#### Holonomy decomposition

Let $X \equiv (Q, S)$ be a transition system and let $h$ be a height
function for $X$, such that $h(Q) > 0$. For a fixed $i$,
let $a_1, a_2, \dots a_k$ be the representatives of equivalence classes of
elements of $A$ of height equal to $i$. We define:

$$
H_i^\lor \equiv H_{a_1} \lor H_{a_2} \dots \lor H_{a_n}
$$


#### Inductive hypothesis for coverings

We will say a relational covering $X \triangleleft_{\phi} Y$ is **of rank $i$**
with respect to a given height function $h$ if $\phi$ relates states in $Y$
to subsets of states in $x$ that are members of $A$ and have rank at most i.
Formally, for each $p \in Q_Y$, we have that $\phi(p) \in A$ and$h(\phi(p)) \leq i$.


We prove that if $X \triangleleft_{\phi} Y$ is a relational covering of rank $i$,
then $X \triangleleft_{\phi} \overline{H_i^\lor} \wr Y$ is a relational covering
of rank $i - 1$.

The proof is a proof by induction.

##### Base case:

Start with the relational covering with $Q_Y = \{ 0 \}, S_Y = \{ id \}$,
and the cover $\phi(0) = Q_X$. Clearly, this has rank $n$ since the height
of $Q_X$ is $n$, and $\phi$ is inded a covering, since the only transition
that $Y$ can make (stay at the same state) is simulated by any transition
in $S_X$ [TODO: is this really the argument?]

For induction, assume $X \triangleleft_{\phi} Y$ is a relational covering of rank $i$
with respect to some height function $h$. $X\equiv (Q_X, S_X)$ and
$Y \equiv (Q_Y, S_Y)$. We define
- $QY_i \equiv \{ q_y : q_y \in Q_Y, h(\phi(q_y)) = i \}$
- $QY_< \equiv \{ q_y : q_y \in Q_Y, h(\phi(q_y)) < i \}$


We know that $A$ contains elements of height exactly $i$. Let $a_1, a_2, \dots a_k$
be representatives of sets of of height $i$ in $A$. Thus, for each $qy_i \in QY_i$,
we have that:

- $\phi(qy_i) = a_j$ for a **unique** $1 \leq j \leq k$.
- We select elements $u, \overline{u} \in S$ such that $u(\phi(qy_i)) = a_j$
  and $\overline{u}(a_j) = \phi(qy_i)$.

We will show how to establish a relational covering:
- $X \triangleleft_{\phi} \wr \overline{H_i^\lor} Y$ using a relation:
- $\phi \subseteq [(B_{a_1} \cup B_{a_2} \cup \dots B_{a_k})\times Q_Y ] \times Q_X$

#### References

- Automata, Languages and Computation by Elinberg.
- [On the Krohn-Rhodes decomposition theorem by Oded Maler](http://www-verimag.imag.fr/~maler/Papers/kr-new.pdf)
- [Ideas of the Holonomy Decomposition of Finite Transformation Semigroups](http://www.egri-nagy.hu/pdf/holonomy_general.pdf)
- [Nine chapters on the semigroup art](http://www-groups.mcs.st-andrews.ac.uk/~alanc/pub/c_semigroups/c_semigroups_a4.pdf)
- [Computational holonomy decompositions of transformation semigroups](http://www.biomicsproject.eu/file-repository/category/CompHolonomy.pdf)
- [Algebraic Hierarchical Decomposition of finite automata: webpage with links to implementations](http://graspermachine.sourceforge.net/)
- [`sgpdec` library on github](https://github.com/gap-packages/sgpdec)
- [Computational semigroup theory blog](https://compsemi.wordpress.com/)
- [Compact notation for semigroup/automata](https://arxiv.org/pdf/1306.1138.pdf)

# Proving block matmul using program analysis

It's a somewhat well-known fact that given matrix multiplication: $O = AB$
where $O \in \mathbb R^{2n \times 2m}$ ($O$ for output),
$A \in \mathbb R^{2n \times r}, B \in \mathbb R^{r \times 2m}$ are matrices.

We can also write this as follows:

$$
\begin{bmatrix} o_{11} & o_{12} \\ o_{21} & o_{22} \end{bmatrix} =
\begin{bmatrix} a_{11} & a_{12} \\ a_{21} & a_{22} \end{bmatrix}
\begin{bmatrix} b_{11} & b_{12} \\ b_{21} & b_{22} \end{bmatrix}
=
\begin{bmatrix}
a_{11} b_{11} + a_{12} b_{21} & a_{11} b_{12} + a_{12} b_{22} \\
a_{21} b_{11}+ a_{22} b_{21} & a_{21} b_{12} + a_{22} b_{22}
\end{bmatrix}
$$

When written as code, the original matrix multiplication is:

```cpp
// a:[2N][2Z] b:[2Z][2M] -> out:[2N][2M]
int matmul(int N, int Z, int M, int a[N][Z], int b[Z][M], int out[N][M]) {
  for(int i = 0; i < 2*N; ++i) {
    for(int j = 0; j < 2*M; ++j) {
      for(int k = 0; k < 2Z; ++k) out[i][j] += a[i][k] * b[k][j]
    }
  }
}
```

and the block-based matrix multiplication is:

```cpp
// a:[2N][2Z] b:[2Z][2M] -> out:[2N][2M]
int matmulBlock(int N, int Z, int M, int a[N][Z], int b[Z][M], int out[N][M]) {
  for (int BI = 0; BI < 2; ++BI) {
    for (int BJ = 0; BJ < 2; ++BJ) {
      for(int i = BI*N; i < BI*N+N; ++i) {
        for(int j = BJ*M; j < BJ*M+M; ++j) {
          for(int k = 0; k < 2Z; ++k) { out[i][j] += a[i][k] * b[k][j] }
        }
      }
    }
  }
}
```

we wish to show that both of these programs have the _same semantics_.
We will do this by appealing to ideas from program analysis.

#### The key idea

We will consider the statement:

```cpp
out[i][j] += a[i][k] * b[k][j]
```

as occuring at an abstract "point in time" $(i, j, k)$ in the `matmul` function.
I also occurs at an abstract "point in time" $(BI, BJ, i', j', k')$ in
the `matmulBlock` function.

We will then show that the loops `for(i...) for(j...) for(k...)` are fully
parallel, and hence we can reorder the loops any way we want.

Then, we will show that the ordering imposed by $(BI, BJ, i', j', k')$
is a reordering of the original $(i, j, k)$ ordering. We do this by
showing that there is a bijection:

$$
(i=i_0, j=j_0, k=k_0) \rightarrow (BI=i_0/N, BJ=j_0/N, i=i_0\%N, j=j_0\%N, k=k_0)
$$

Thus, this bijection executes all loops, and does so without affecting the
program semantics.

#### Schedules

We'll zoom out a little, to consider some simple programs and understan
how to represent parallelism.

```cpp
void eg1(int N, int M, int out[N][M]) {
for(int i = 0; i < N; ++i) {
  for(int j = 1; j < M; ++j) {
    out[i][j] = out[i][j-1];
  }
}
```

Notice that this program is equivalent to the program with the $i$ loop
reversed:

```cpp
void eg1rev(int N, int M, int out[N][M]) {
for(int i = N-1; i >=0; --i) {
  for(int j = 1; j < M; ++j) {
    out[i][j] = out[i][j-1];
  }
}
```

What's actually _stopping_ us from reversing the loop `for(j...)`? it's
the fact that the value of, say, `out[i=0][j=1]` _depends_ on
`out[i=0][j=0]`. We can see that in general, `out[i=i_0][j=j_0]` _depends_
on `out[i=i_0][j=j_0-1]`. We can represent this by considering a
_dependence set_:

$$
\{ \texttt{write}:(i_0, j_0-1) \rightarrow \texttt{write}:(i_0, j_0) \}
$$

in general, we can reorder statements as long as we do not change
the _directions_ of the arrows in the dependence set.

We can imagine the scenario as follows:

```
^
| (1, 0)->(1, 1)->(1, 2)->(1, 3) ...
| (0, 0)->(0, 1)->(0, 2)->(0, 3) .... 
(i, j) --> 
```


#### Dependence structure of `matmul`.

#### Fully parallel, reordering

[TODO]


#### References

- Optimizing Compilers for Modern Architectures: A Dependence-based Approach
- [Polyhedral compilation](http://polyhedral.info/)


# Why I like algebra over analysis

Midnight discussions with my room-mate
[Arjun P](https://researchweb.iiit.ac.in/~arjun.p/).

This tries to explore what it is about algebra that I find appealing.

I think the fundamental difference to me comes down to flavour ---
analysis and combinatorial objects feel very "algorithm", while Algebra feels
"data structure".

To expand on the analogy, a proof technique is like an algorithm, while an
algebraic object is like a data structure. The existence of an algebraic object
allows us to "meditate" on the proof technique as a separate object that does
not move through time. This allows us to "get to know" the algebraic object,
independent of how it's used. So, at least for me, I have a richness of
feeling when it comes to algebra that just doesn't shine through with analysis.
The one exception maybe reading something like "by compactness", which has
been hammered into me by exercises from Munkres :)

Meditating on a proof technique is much harder, since the proof technique
is necessarily intertwined with the problem, unlike a data structure which
to some degree has an independent existence.


This reminds me of the quote: "“Art is how we decorate space;
Music is how we decorate time.”. I'm not sure how to draw out the
tenuous connection I feel, but it's there.

Arjun comes from a background of combinatorics, and my understanding of his
perspective is that each proof is a technique unto itself. Or, perhaps
instantiating the technique for each proof is difficult enough that abstracting
it out is not useful enough in the first place.

A good example of a proof technique that got studied on its own right in
combinatorics is the probabilistic method. A more reasonable example is that of
the Pigeonhole principle, which still requires insight to instantiate in
practise.

Not that this does not occur in algebra either, but there is something in
algebra about how just meditating on the definitions. For example,
Whitney trick that got pulled out of the proof of the Whitney embedding
theorem.

To draw an analogy for the haskellers, it's the same joy of being able to write
down the type of a haskell function and know exactly what it does, enough that
a program can automatically derive the function (djinn). The fact that we know
the object well enough that just writing the type down allows us to infer the
_program_, makes it beautiful. There's something very elegant about the
_minimality_ that algebra demands. Indeed, this calls back to another quote:
"perfection is achieved not when there is nothing more to add, but when there
is nothing left to take away".

I'm really glad that this 2 AM discussion allowed me to finally pin down
why I like algebra.

# `using` for cleaner function type typedefs

I've always struggled with remembering the syntax for function type typedefs:

```cpp
typedef RETTY (*FNTYNAME)(ARGTY1, ARGTY2, ..., ARGTYn);
```

we can now use `using` for a far more pleasant syntax:

```cpp
using FNTYNAME = RETTY(ARGTY1, ARGTY2, ..., ARGTYn);
```

which is also intuitive. You write down the "type"
on the right hand side, and give it a name on the left.

This is not strictly the same, since the `typedef`
`typedefs` `FNTYNAME` to a _function pointer type_, while
the C++ version typedefs the _function type_. I prefer
the latter at any rate, since I dislike the fact
that the usual typedef tends to hide the fact that a
function pointer is some pointer-like-thing.


# A walkway of lanterns (TODO)

### Semidirect products

- $(\alpha \equiv \{ a, b, \dots\}, +, 0)$
- $(\omega \equiv \{ X, Y, \dots\}, \times, 1)$
- $\cdot ~: ~\omega \rightarrow Automorphisms(\alpha)$

- [How to twist pointers without breaking them](https://www.cse.iitk.ac.in/users/ppk/research/publication/Conference/2016-09-22-How-to-twist-pointers.pdf)

- rotations: $\mathbb Z 5$
- reflection: $\mathbb Z 2$

- $D_5 = \mathbb Z5 \rtimes \mathbb Z2$

$$
\begin{aligned}
\begin{bmatrix}
1 & 0 \\
a & X
\end{bmatrix}
\begin{bmatrix}
1 & 0 \\
b & Y
\end{bmatrix}
=  \begin{bmatrix}
1 & 0 \\
a + X \cdot b & XY
\end{bmatrix}
\end{aligned}
$$

- $(Y \mapsto b) \xrightarrow{act} (X \mapsto a)$

- $XY \mapsto a + X \cdot b$


### A walkway of lanterns

- Imagine $\mathbb Z$ as a long walkway. you start at 0. You are but a poor lamp lighter.
- Where are the lamps? At each $i \in \mathbb Z$, you have a lamp that is either on, or off. So you have $\mathbb Z2$.

- $L \equiv \mathbb Z \rightarrow \mathbb Z2$ is our space of lanterns. You can act on this space by either moving using $\mathbb Z$, or toggling a lamp using $\mathbb Z2$. $\mathbb Z2^{\mathbb Z} \rtimes \mathbb Z$

- $g = (lights:\langle-1, 0, 1\rangle,  loc:10)$
- $move_3: (lights: \langle \rangle, loc: 3)$
- $move_3 \cdot g =  (lights:\langle-1, 0, 1\rangle,  loc:13)$
- $togglex = (lights:\langle 0, 2 \rangle, loc: 0)$
- $togglex \cdot g = (lights: \langle -1, 0, 1, 13, 15 \rangle, loc:13)$
- $toggley = (lights: \langle -13, -12 \rangle, loc:0)$
- $toggley\cdot g= (lights:\langle -1 \rangle, loc:13)$




# Natural transformations

<img  src="./static/natural-transformation.png">


I don't find people who draw "all three parts" of the natural transformation:
the catories $C$, $FC$, and $GC$, and then show the relationship between
them, so I made this for my own reference.


# The hilarious commentary by dinosaure in OCaml git

the [Ocaml-git](https://github.com/mirage/ocaml-git/) project is a
re-implementation of `git` in `OCaml`. It's well-written, and I was
walking through the codebase, when I found absolutely amazing, hilarious,
and deep comments from `dinosaure`. I really enjoyed reading through the
codebase, and the existence of these comments made it more humane to read.
I don't know who `dinosaure` is, but I'm really glad they wrote the comments
they did, it really made my day.

##### The one that takes a stab at Haskell for fun

```
(* XXX(dinosaure): ...we can fix this detail but
I'm lazy like haskell. TODO! *)
```

##### The academic one that broken-links to a paper

```
(* XXX(dinosaure): see this paper
https://github.com/ocamllabs/papers/blob/master/irmin/2014.08.matthieu/rapport.pdf *)
```

##### The one about the frustrations of bug-hunting

```
(* XXX(dinosaure): [~chunked:false] is mandatory, I don't want to explain
why (I lost one day to find this bug) but believe me. *)
```

##### The one about a potential heisenbug

```
(* XXX(dinosaure): if, one day, we find a bug about the serialization of the
IDX file, may be it's about this function (stable/unstable sort). *)
```

##### The requisite comment in french for an OCaml project

```
(* XXX(dinosaure): bon ici, c'est une note compliqué, j'ai mis 2 jours
à fixer le bug. Donc je l'explique en français, c'est plus simple.
En gros, [Helper.MakeDecoder] utilise ce buffer comme buffer interne
pour gérer les alterations. Ce qui ce passe, c'est que dans la
fonction [refill], il s'agit de compléter à partir d'un [input]
(typiquement [zl]) le buffer interne. C'est finalement un
__mauvais__ jeu entre un [Cstruct.t] et un [Bigarray].
Il s'agit de connaître la véritable taille du [Bigarray] et de
rajouter avec [blit] le contenu de l'[input] si la taille du
[Bigarray] (et pas du [Cstruct]) est suffisante.
Avant, cette modification, [zl], [de] et [io] partagaient le même
[Bigarray] découpé (avec [Cstruct]) en 3. Donc, dans le
[MakeDecoder], [refill] considérait (pour des gros fichiers faisant
plus de 0x8000 bytes) que après [de], nous avions encore de la
place - et dans ce cas, nous avions [io].
Ainsi, on [blit]ait [zl] dans [de+sizeof(de) == io], et finalement,
on se retrouvait à essayer de décompresser ce que nous avions
décompressé. (YOLO).
Donc, on considère maintenant [de] comme un [Cstruct.t] et un
[Bigarray] physiquement différent pour éviter ce problème.
Cependant, il faudrait continuer à introspecter car j'ai
l'intuition que pour un fichier plus gros que [2 * 0x8000], on
devrait avoir un problème. Donc TODO. *)
```

###### The deep one

```
(* XXX(dinosaure): at the end, we don't care if we lost something. *)
```

# How to link against MLIR with CMake

Since `MLIR` hasn't setup the nice tooling that LLVM has around `CMake`
as far as I can tell, one needs to actually _know_ `CMake` to link against
`MLIR`. However, as is well known, `CMake` incantations are handed down
by preists who spend the better part of their lives studying the tome
that is the CMake manual. I, an unlucky soul had to go on this adventure,
and I hope to spare you the trouble.

I wished to link against a static library build of MLIR. The secret
lies in the `find_library` call:

```
#If the variable has been set by -DMLIR_INCLUDE_PATH, then keep it.
#Otherwise fallback to the environment variable $MLIR_INCLUDE_PATH.
#if neither, then *shrug*.
IF(NOT MLIR_INCLUDE_PATH)
    set (MLIR_INCLUDE_PATH $ENV{MLIR_INCLUDE_PATH})
endif()

#Resolve for:
#- a library target called `MLIRAnalysis`
#- asking to link against `libMLIAnalysis.a`
#- using the variable MLIR_INCLUDE_PATH which as we saw before
##  is either an environment variable or a cmake option
target_include_directories(languagemodels PRIVATE ${MLIR_INCLUDE_PATH})
```

I cribbed the actual things to link against from the path
[`mlir/examples/Toy/Ch2/CMakeLists.txt`](https://github.com/llvm/llvm-project/blob/master/mlir/examples/toy/Ch2/CMakeLists.txt)
which helpfully lists MLIR things it needs to link against.

The full `CMakeLists` is here:

```
cmake_minimum_required(VERSION 3.5)
project(languagemodels)

set(CMAKE_CXX_STANDARD 14)

## I don't want to use find_package since I want proper control over where my LLVM comes from.
## find_package(LLVM REQUIRED)

add_executable(languagemodels
        rnn.cpp codegenc.h lang.h codegenmlir.h)

## Attempt to take these as command line arguments. IF that fails,
## lookup environment.
IF(NOT MLIR_INCLUDE_PATH)
    set (MLIR_INCLUDE_PATH $ENV{MLIR_INCLUDE_PATH})
endif()

IF(NOT MLIR_LIBRARY_PATH)
    set (MLIR_LIBRARY_PATH $ENV{MLIR_LIBRARY_PATH})
endif()

target_include_directories(languagemodels PRIVATE ${MLIR_INCLUDE_PATH})
find_library(MLIRAnalysis MLIRAnalysis ${MLIR_LIBRARY_PATH})
find_library(MLIRIR MLIRIR ${MLIR_LIBRARY_PATH})
find_library(MLIRParser MLIRParser ${MLIR_LIBRARY_PATH})
find_library(MLIRSideEffects MLIRSideEffects ${MLIR_LIBRARY_PATH})
find_library(MLIRTransforms MLIRTransforms ${MLIR_LIBRARY_PATH})
find_library(LLVMCore LLVMCore ${MLIR_LIBRARY_PATH})
find_library(LLVMSupport LLVMSupport ${MLIR_LIBRARY_PATH})

## debugging to check if it's been set properly
message(MLIR_INCLUDE_PATH ${MLIR_INCLUDE_PATH})
message(MLIR_LIBRARY_PATH ${MLIR_LIBRARY_PATH})
message(MLIRAnalysis ${MLIRAnalysis})

target_link_libraries(languagemodels
        ${MLIRAnalysis}
        ${MLIRIR}
        ${MLIRParser}
        ${MLIRSideEffects}
        ${MLIRTransforms}
        ${LLVMCore}
        ${LLVMSupport})
```



# Energy as triangulaizing state space

This comes from The wild book by John Rhodes, which I anticipate I'll be posting more of in the coming weeks.

#### Experiments

Let an experiment be a tuple of the phase space $X$, action space $A$,
and an action of the actions onto the phase space
$\curvearrowright: A \times X \rightarrow X$. We will write
$x' = a \curvearrowright x$ to denote the new state of the system
$x$. So the experiment $E$ is the data
$E \equiv (X, A, \curvearrowright : A \times X \rightarrow X)$.

#### Coordinate systems.

The existence of the action $\curvearrowright$ allows us to
write the evolution of the system recursively:

$x_{t+1} = a \rightarrow x_t$.

However, to understand the final state $x_{t+1}$, we need to essentially
"run the recursion", which does not permit us to 
_understand the experiment_.

What we really need is the ability to "unroll" the loop. To quote:

> Informally, understanding an experiment $E$ means
> introducing coordinates into phase space of $E$ which are in triangular form
> under the action of the inputs of $E$.

#### Conservation laws as triangular form

We identify certain interesting invariants of a system by two criteria:

1. The parameter $Q(t)$ determines some obviously important aspects of
   the system. That is, there is a deterministic function $M(Q(t))$ which
   maps $Q(t)$ to "measure" some internal state of the system.
2. If the values of such a  parameter $Q$ is known at time $t_0$ (denoted $Q(t_0)$)
    and it is also known what inputs are presented to the
    system from time $t$ to time $t + \epsilon$
    (denoted $I[t_0, t_0 + \epsilon]$), then the new value of $Q$ is a
    deterministic function of $Q(t_0)$ and $I[t_0, t_0+ \epsilon]$.


Such parameters allow us to understand a system, since they are deterministic
parameters of the evolution of the system, while also provding a way to
measure some internal state of the system using $M$.

For example, consider a system $x$ with an energy function $e(x)$. If we
perform an action $a$ on the system $x$, then we can predict the action
$e(x' = a \curvearrowright x)$ given just $e(x)$ and $a$ --- here,
$(x' = a \curvearrowright x)$ is the action of the system $a$ on $x$.

> In general, conservation principles give a first coordinate
> of a triangularization. In the main a large part of physics can be viewed as
> discovering and introducing functions $e$ of the states $q$ of the
> system such that under action $a$, $e(a \curvearrowright q)$ depends
> only on $e(q)$ and $a$, and **not** on $q$.


#### Theory: semidirect and wreath products

- For semidirect products, I refer you to
    [the cutest way to write semidirect products](#the-cutest-way-to-write-semidirect-products)
    [Line of investigation to build physical intuition for semidirect products](#line-of-investigation-to-build-physical-intuition-for-semidirect-products).

#### Symmetries as triangular form

> We first heuristically indicate the construction involved in going from the
> group of symmetries to the triangularization, and then precisely write it out
> in all pedantic detail.

Let an experiment be $E \equiv (X, A, \curvearrowright)$. Then we define $\Pi$
is a _symmetry_ of $E$ iff:

1. $\Pi: X \rightarrow X$ is a permutation of $X$.
2. $\Pi$ commutes with the action of each $a$:
       $ \Pi(a \curvearrowright x) = a \curvearrowright \Pi(x) $.

We say that the theory $E$ is _transitive_ (in the action sense) if for
all $x_1, x_2 \in X, x_1 \neq x_2$, there exists $a_1, a_2, \dots a_n$
such that $ x_2 = a_n \curvearrowright \dots (a_1 \curvearrowright x_1) $.

Facts of the symmetries of a system:

1. We know that the symmetries of a theory $E$ form a group.
2. If $E$ is transitive, then each symmetry $\Pi$ is a regular permutation
   --- If there exists an $x$ such that $\Pi(x_f) = x_f$ (a fixed point), then
   this implies that $\Pi(x) = x$ for _all_ $x$.
3. Let the action split $X$ into disjoint orbits $O_1, O_2, \dots O_k$ from whom
   we choose representatives $x_1 \in O_1, x_2 \in O_2, \dots x_k \in O_k$.
   Then, if $E$ is transitive, there is _exactly one_ action that sends a
   particular $x_i$ to a particular $x_j$. So, on fixing _one component_
   of an action, we fix _all components_.

To show that this gives rise to a triangulation, we first construct
a semigroup of the actions of the experiment:
$S(E) \equiv \{ a_1 \dots a_n : n \geq 1 \text{~and~} a_i \in A \}$.

Now, let $G = Sym(E)$, the full symmetry group of $E$. One can apparently
express the symmetry group in terms of:

$$(X, S) \leq (G, G)  \wr (\{ O_1, O_2, \dots O_k\}, T)$$


# The cutest way to write semidirect products

Given two monoids $(M, +, 0_M)$ and $(N, \times, 1_N)$, and a
homomorphism $\phi: N \rightarrow End(M)$, where $End(M)$
is the endomorphism group of $M$. We will notate $\phi(n)(m)$ as $n \cdot m \in M$.

Now the semidirect product $M \ltimes_\phi N$ is the set $M \times N$ equipped
with the multiplication rule:

- $(m, n) (m', n') = (m + n \cdot m', nn')$

This can also be written down as:

$$
\begin{bmatrix}
1 & 0 \\ m & n
\end{bmatrix}
\begin{bmatrix}
1 & 0 \\ m' & n'
\end{bmatrix} =
\begin{bmatrix}
1 & 0 \\ m + n \cdot m' & n \times n'
\end{bmatrix}
$$

This way of writing down semidirect products as matrices makes many things
immediately clear:

- The semidirect product is some kind of "shear" transform, since that's
  what a shear transformation looks like, matrix-wise.
- The resulting monoid $M \ltimes_{\phi} N$ has identity $(0_M, 1_N)$,
  since for the matrix to be identity, we need the 2nd row to be $(0, 1)$.
- The inverse operation if $(M, N)$ were groups would have to be such that

$$
\begin{bmatrix} 1 & 0 \\ m + n \cdot m' & n \times n' \end{bmatrix} =
\begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}
$$

Hence:
- $nn' = 1$ implies that $n' = 1/n$.
- $m + n m' = 0$ implies that $m' = -m/n$.

which is indeed the right expression for the inverse.



# My Favourite APLisms

#### identity matrix
```
n←3 ⋄ id ← n n ⍴(1,n⍴0) ⋄ id
```

This relies heavily on `⍴` replicating its arguments.


#### histogram
```
xs←(1 1 3 3 3 6) ⋄ n←(⌈/xs)⍴0 ⋄ n[xs]+←1 ⋄ n
```

The use of `n[x] +←1` will stably write `+1` as many times as there are repeated
indexes in `xs`.

#### String matching / parity as fold `≠`:


```
]disp str ← (1 0 0 1 0 0 0 0 1 0 1 0 0 0) ⋄ 2 1 ⍴ ((⊂ str) ⍪ ⊂((≠\str)))
┌→──────────────────────────┐
↓1 0 0 1 0 0 0 0 1 0 1 0 0 0│
├~─────────────────────────→┤
│1 1 1 0 0 0 0 0 1 1 0 0 0 0│
└~─────────────────────────→┘
```

# Proof of chinese remainder theorem on rings

#### General operations on ideals
We have at our hands a commutative ring $R$, and we wish to study the ideal
structure on the ring. In particular, we can combine ideals in the following
ways:

1. $I + J \equiv \{ i + j : \forall i \in I, j \in J \}$
2. $I \cap J \equiv \{ x : \forall x \in I \land x \in J \}$
3. $I\oplus J \equiv \{ (i, j) : \forall i \in I \land j \in J \}$
4. $IJ \equiv \{ ij : \forall i \in I \land j \in J \}$

We have the containment:

$$
IJ \subseteq I \cap J \subseteq I, J \subseteq I + J \subseteq R
$$

#### $IJ$ is a ideal, $IJ \subseteq I \cap J$

it's not immediate from the definition that $IJ$ is an ideal. The idea is
that given a sum $\sum_k i_k j_k \in IJ$, we can write each $i_k j_k = i'_k$,
since the ideal $I$ is closed under multiplication with $R$. This gives
us $\sum i'_k = i'' \in I$. Similarly, we can interpret $\sum_k i_k j_k = \sum_k j'_k = j''k \in J$.

Hence, we get the containment $IJ \subseteq I \cap J$.

#### $I \cap J subseteq I$, $I \cap J \subseteq J$

Immediate from the inclusion function.

#### $I, J \subseteq I + J$

Immediate from inclusion

#### CRT from an exact sequence

There exists an exact sequence:

$$
\begin{aligned}
0 \rightarrow I \cap J \xrightarrow{f} I \oplus J \xrightarrow{g} I + J \rightarrow 0 \\
&f(r) = (r, r) \\
&g((i, j)) = i + j
\end{aligned}
$$

We are forced into this formula by considerations of dimension. We know:

$$
\begin{aligned}
&dim(I \oplus J) = dim(I) + dim(J) \\
&dim(I + J) = dim(I) + dim(J) - dim(I \cap J) \text{[inclusion-exclusion]} \\
&dim(I + J) = dim(I \oplus J) - dim(I \cap J) \\
&dim(I + J) - dim(I \oplus J) + dim(I \cap J) = 0\\
&V - E + F = 2
\end{aligned}
$$

By analogy to euler characteristic which arises from homology, we need to have
$I \oplus J$ in the middle of our exact sequence. So we must have:

$$
0 \rightarrow ? \rightarrow I \oplus J \rightarrow ?\rightarrow 0
$$

Now we need to decide on the relative ordering between $I \cap J$ and $I + J$.
- There is  no _universal_ way to send $I oplus J \rightarrow I \cap J$. It's
  an unnatural operation to restrict the direct sum into the intersection.
- There is a _universal_ way to send $I \oplus J \rightarrow I + J$: sum
  the two components. This can be seen as currying the addition operation.

Thus, the exact sequence _must_ have $I + J$ in the image of $I \oplus J$. This
forces us to arrive at:

$$
0 \rightarrow I \cap J \rightarrow I \oplus J \rightarrow I + J \rightarrow 0
$$

The product ideal $IJ$ plays no role, since it's not possible to define a 
product of modules _in general_ (just as it is not possible to define
a product of vector spaces). Thus, the exact sequence better involve
module related operations.  We can now recover CRT:

$$
\begin{aligned}
0 \rightarrow I \cap J \xrightarrow{f} I \oplus J \xrightarrow{g} I + J \rightarrow 0 \\
0 \rightarrow R \xrightarrow{f} R \oplus R \xrightarrow{g} R \rightarrow 0 \\
0 \rightarrow R / (I \cap J) \rightarrow R/I \oplus R /J \rightarrow R/(I + J) \rightarrow 0
\end{aligned}
$$



#### References

- [I learnt the material from this course on commutative algebra from IIT bombay](https://www.youtube.com/watch?v=YxyxP894MLk).


# monic and epic arrows

This is trivial, I'm surprised it took me _this long_ to internalize this fact.

When we convert a poset $(X, \leq)$ into a category, we stipulate that
$x \rightarrow y \iff x \leq y$.

If we now consider the category $Set$ of sets and functions between sets,
and arrow $A \xrightarrow{f} B$ is a function from $A$ to $B$. If $f$ is
monic, then we know that $|A| = |Im(f)| \leq |B|$. That is, a monic arrow
behaves a lot like a poset arrow!

Similarly, an epic arrow behaves a lot like the arrow in the inverse poset.
I wonder if quite a lot of category theoretic diagrams are clarified by thinking
of monic and epic directly in terms of controlling sizes.

# The geometry of Lagrange multipliers
If we want to minise a function $f(x)$ subject to the constraints $g(x) = c$,
one uses the method of lagrange multipliers. The idea is to consider a new
function $L(x, \lambda) = f(x) + \lambda (c - g(x))$. Now, if one has a local maxima
$(x^\star, y^\star)$, then the conditions:

1. $\frac{\partial L}{\partial x} = 0$: $f'(x^\star) - \lambda g'(x^\star) = 0$.
2. $\frac{\partial L}{\partial \lambda} = 0$: $g(x^\star) = c$.

Equation (2) is sensible: we want our optima to satisfy the constraint that
we had originally imposed. What is Equation (1) trying to say?
Geometrically, it's asking us to keep $f'(x^\star)$ parallel to $g'(x^\star)$.
Why is this a good ask?

Let us say that we are at an $(x_0)$ which is a feasible point ($g(x_0) = c$).

We are interested in wiggling
$(x_0) \xrightarrow{wiggle} (x_0 + \vec\epsilon) \equiv x_1$.

- $x_1$ is still feasible: $g(x_1) = c = g(x_0)$.
- $x_1$ is an improvement: $f(x_1) > f(x_0)$.

- If we want $g(x_1)$ to not change, then we need $g'(x_0) \cdot \vec \epsilon = 0$.
- If we want $f(x_1)$ to be larger, we need $f'(x_0) \cdot \vec \epsilon > 0$.

If $f'(x_0)$ and $g'(x_0)$ are parallel, then attempting to improve $f(x_0 + \vec \epsilon)$
by change $g(x_0 + \vec \epsilon)$, and thereby violate the constraint
$g(x_0 + \epsilon) = c$.

# Efficient tree transformations on GPUs (TODO)

All material lifted straight from [Aaron Hsu's PhD thesis](https://scholarworks.iu.edu/dspace/handle/2022/24749). I'll be converting
APL notation to C++-like notation.


#### Tree repsentation as multi-dimensional ragged nested arrays

We're interested in this tree:
```
      ∘
┌──┬──┴────┐
a  b       c
│ ┌┴┐  ┌───┼───┐
p q r  s   t   u
  │    │   |
  │   ┌┴┐ ┌┴┐
  v   w x y z
```

I'll be writing APL commands in front of a `$` to mimic bash, and I'll
write some arrays as multi-line. To run them, collapse them into a single
line. The `ast` object is represented in memory as:
```
$ ast ← ('∘'
           ('a' ('p'))
           ('b'
             ('q' ('v'))
             ('r'))
           ('c'
             ('s' ('w' 'x'))
             ('t' ('y' 'z'))
             ('u')))
$ ]disp ast
┌→┬──┬────────┬───────────────────┐
│∘│ap│┌→┬──┬─┐│┌→┬──────┬──────┬─┐│
│ │  ││b│qv│r│││c│┌→┬──┐│┌→┬──┐│u││
│ │  │└─┴─→┴─┘││ ││s│wx│││t│yz││ ││
│ │  │        ││ │└─┴─→┘│└─┴─→┘│ ││
│ │  │        │└─┴─────→┴─────→┴─┘│
└─┴─→┴───────→┴──────────────────→┘
```

Here's how read the array representation. Look at the top level of the tree.
we have a root node with three children:

```
      ∘
┌──┬──┴────┐
a  b       c

┌→┬──┬────────┬─────────────┐
│∘│  │        │             │
│ │ a│   b    │     c       │
│ │  │        │             │
└─┴─→┴───────→┴────────────→┘
```

With the first `∘` being the root node, and the three adjacent cells
being the children.

Next, we look at how `x` is represented. This is predictably recursive. Let's
see the subtree under `x`:

```
      ∘
┌──┬──┴────┐
a  b       c
│
p

┌→┬──┬────────┬─────────────┐
│∘│ap│        │             │
│ │  │  b     │   c         │
│ │  │        │             │
└─┴─→┴───────→┴────────────→┘

```

Similarly for `y`:

```
      ∘
┌──┬──┴────┐
a  b       c
│ ┌┴┐
p q r

┌→┬──┬────────┬─────────────┐
│∘│ap│┌→┬──┬─┐│             │
│ │  ││b│q │r││   c         │
│ │  │└─┴─→┴─┘│             │
└─┴─→┴───────→┴────────────→┘
```

And so on, leading to the final representation:

```
      ∘
┌──┬──┴────┐
a  b       c
│ ┌┴┐  ┌───┼───┐
p q r  s   t   u
  │    │   |
  │   ┌┴┐ ┌┴┐
  v   w x y z
┌→┬──┬────────┬───────────────────┐
│∘│ap│┌→┬──┬─┐│┌→┬──────┬──────┬─┐│
│ │  ││b│qv│r│││c│┌→┬──┐│┌→┬──┐│u││
│ │  │└─┴─→┴─┘││ ││s│wx│││t│yz││ ││
│ │  │        ││ │└─┴─→┘│└─┴─→┘│ ││
│ │  │        │└─┴─────→┴─────→┴─┘│
└─┴─→┴───────→┴──────────────────→┘
```


Note that for this representation to work, we need to be able to:

- nest arrays inside arrays.
- have subarrays of different sizes (ragged arrays)
- of different _nesting depths_ --- so it's really not even an array?

I don't understand the memory layout of this, to be honest. I feel like to
represent this in memory would still rely on pointer-chasing, since we need
to box all the arrays. This is possibly optimised by APL to not be too bad.

#### The depth vector representation

```
      ∘             0
┌──┬──┴────┐
a  b       c        1
│ ┌┴┐  ┌───┼───┐
p q r  s   t   u    2
  │    │   |
  │   ┌┴┐ ┌┴┐
  v   w x y z       3
```

If we visit this tree and record depths in pre-order `(node left right)`, we
arrive at the list:

```
(∘:0
  (a:1 (p:2)) (b:1 (q:2 (v:3)) (r:2))
  (c:1 (s:2 (w:3 x:3)) (t:2 (y:3 z:3)) (u:2)))
```

formatted as:

```
(∘:0
  (a:1
    (p:2))
  (b:1
    (q:2 (v:3))
    (r:2)
  )
  (c:1 (s:2 (w:3 x:3))
       (t:2 (y:3 z:3))
       (u:2))
)
```

This linearlized is the list:

```
    (∘ a p b q v r c s w x t y z u)
d ← (0 1 2 1 2 3 2 1 2 3 3 2 3 3 2)

      ∘             0
┌──┬──┴────┐
a  b       c        1
│ ┌┴┐  ┌───┼───┐
p q r  s   t   u    2
  │    │   |
  │   ┌┴┐ ┌┴┐
  v   w x y z       3
```


To convert the `ast` object into a depth vector representation, we can
use the following call:

```
$ ast ← ('∘' ('a' ('p')) ('b' ('q' ('v')) ('r')) ('c' ('s' ('w' 'x')) ('t' ('y' 'z')) ('u')))
$ d ← ∊0{(⊢,(⍺+1)∇⊣)/⌽⍺,1↓⍵}ast
0 1 2 1 2 3 2 1 2 3 3 2 3 3 2
```

Let's break this down:

TODO

#### Inverted tables

We represent data associated with our nodes as follows:

```
$ data ← ⍪ ¨d(15⍴'T')(↑15⍴⊂'n.')
$ ]disp data
┌→┬─┬──┐
│0│T│n.│
│1│T│n.│
│2│T│n.│
│1│T│n.│
│2│T│n.│
│3│T│n.│
│2│T│n.│
│1│T│n.│
│2│T│n.│
│3│T│n.│
│4│T│n.│
│2│T│n.│
│3│T│n.│
│4│T│n.│
│2↓T↓n.↓
└→┴→┴─→┘
```

This is the same thing as a
[structure of arrays (SOA) representation](https://en.wikipedia.org/wiki/AoS_and_SoA#Structure_of_Arrays),
where each array of information (eg, the depth at `data[1]`, the `T`
information at `data[2]`) are each _arrays_ which can be accessed well on SIMD
instructions.

#### AST representation

TODO

#### Path matrices

We want information of how to go up and down the tree in ideally constant time.
We store this information in what is known as a _path matrix_.

For our recurring example, the path matrix is:

```
∘ a p b q v r c s w x t y z u | preorder traversal
──────────────────────────────────────────────────
∘ ∘ ∘ ∘ ∘ ∘ ∘ ∘ ∘ ∘ ∘ ∘ ∘ ∘ ∘ | depth=0
- a a b b b b c c c c c c c c | depth=1
- - p - q q r - s s s t t t u | depth=2
- - - - - v - - - w x - y z - | depth=3

      ∘             0
┌──┬──┴────┐
a  b       c        1
│ ┌┴┐  ┌───┼───┐
p q r  s   t   u    2
  │    │   |
  │   ┌┴┐ ┌┴┐
  v   w x y z       3
```

To efficiently compute this, we first replace every value in
our tree with its preorder traversal visit time. This changes
the tree to:

```
              ∘:0                               0
┌──────────┬──┴─────────────────┐
a:1        b:3                 c:7              1
│      ┌───┴───┐     ┌──────────┼───────┐
p:2    q:4     r:6   s:8        t:11    u:14    2
       │             │          │
       │          ┌──┴──┐     ┌─┴───┐
       v:5        w:9   x:10  y:12  z:13        3
```

The values we store in the tree are the integers. The old labels
are represented for clarity.

The path matrix for this tree is:

```
0  1  2  3  4  5  6  7  8  9 10 11 12 13 14  | preorder traversal
────────────────────────────────────────────────────────────
0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  | depth=0
-  1  1  3  3  3  3  7  7  7  7  7  7  7  7  | depth=1
-  -  2  -  4  4  6  -  8  8  8 11 11 11 14  | depth=2
-  -  -  -  -  5  -  -  -  9 10  - 12 13  -  | depth=3

              ∘:0                               0
┌──────────┬──┴─────────────────┐
a:1        b:3                 c:7              1
│      ┌───┴───┐     ┌──────────┼───────┐
p:2    q:4     r:6   s:8        t:11    u:14    2
       │             │          │
       │          ┌──┴──┐     ┌─┴───┐
       v:5        w:9   x:10  y:12  z:13        3
```

#### Rendering the depth information in 2D

We use the incantation:

```
$ d ← (0 1 2 1 2 3 2 1 2 3 3 2 3 3 2)
$ ((⍳≢d)@(d,¨⍳≢d)) ((⌈/d) (≢d))⍴'-'
0 - - - - - - - - -  -  -  -  -  -
- 1 - 3 - - - 7 - -  -  -  -  -  -
- - 2 - 4 - 6 - 8 -  - 11  -  - 14
- - - - - 5 - - - 9  -  - 12  -  -
- - - - - - - - - - 10  -  - 13  -
```

Let's break this down (the symbol ` ` means a lamp, for commenting/illumination)


```
$ ⍳ 3 ⍝ iota: make a list of n elements:.
1 2 3
```

```
$ d
0 1 2 1 2 3 2 1 2 3 4 2 3 4 2

$ ≢d ⍝ tally: ≢`. count no. of elements in d:
15
```

```
⍳≢d  ⍝ list of elements of len (no. of elements in d).
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
```

```
$ ]disp (1 2 3),(4 5 6) ⍝ ,:concatenate
┌→────┬─────┐
│1 2 3│4 5 6│
└~───→┴~───→┘
```

```
]disp (1 2 3) ,¨ (4 5 6)
┌→──┬───┬───┐
│1 4│2 5│3 6│
└~─→┴~─→┴~─→┘
```

The use of `¨` needs some explanation. `¨` is a higher order function which
takes a function and makes it a mapped version of the original function.
So, `,¨` is a function which attemps to map the concatenation operator.
Now, given two arrays `(1 2 3)`
and `(4 5 6)`, `(1 2 3) ,¨ 4 5 6` attemps to run `,` on each pair
`1 and 4`, `2 and 5`, `3 and 6`. This gives us tuples `((1 4) (2 5) (3 6))`.
So, for our purposes, `zip ← ,¨`.

```
]disp (d,¨⍳≢d) ⍝ zip d with [1..len d].
┌→──┬───┬───┬───┬───┬───┬───┬───┬───┬───┬────┬────┬────┬────┬────┐
│0 0│1 1│2 2│1 3│2 4│3 5│2 6│1 7│2 8│3 9│4 10│2 11│3 12│4 13│2 14│
└~─→┴~─→┴~─→┴~─→┴~─→┴~─→┴~─→┴~─→┴~─→┴~─→┴~──→┴~──→┴~──→┴~──→┴~──→┘
```

```
$ ((⌈/d) (≢d))⍴'-' ⍝ array of dim (max val in d) x (no. of elem in d)
---------------
---------------
---------------
---------------
```

- `⌈` is the maximum operator and `/` is the fold operator, so
  `⌈/d` finds the maximum in `d`. Recall that `(≢d)` find the no. of
   elements in `d`. `⍴` reshapes an array to the desired size. We pass it
   a `1x1` array containing only `-`, which gets reshaped into a
   `(⌈/d) x (≢d)` sizes array of `-` symbols.


TODO: explain @ and its use

#### Creating the path matrix

```
$ ⎕IO ← 0 ⍝ (inform APL that we wish to use 0-indexing.)
$ d ← (0 1 2 1 2 3 2 1 2 3 3 2 3 3 2)
$ PM ← ⌈\((⍳≢d)@(d,¨⍳≢d))(((⌈/d+1)(≢d))⍴0)

0 0 0 0 0 0 0 0 0 0  0  0  0  0  0
0 1 1 3 3 3 3 7 7 7  7  7  7  7  7
0 0 2 2 4 4 6 6 8 8  8 11 11 11 14
0 0 0 0 0 5 5 5 5 9 10 10 12 13 13

      0               0
┌──┬──┴───────┐
1  3          7       1
│ ┌┴┐  ┌──────┼───┐
2 4 6  8     11   14  2
  │    │      |
  │   ┌┴─┐   ┌┴──┐
  5   9  10  12  13   3
```

The incantation can be broken down into:


- `(((⌈/d+1)(≢d))⍴0)` is used to create a `max(d+1)x|d|` dimension array of zeros.
   Here, the rows define depths, and the columns correspond to tree nodes
   which for us are their preorder indexes.

```
$ grid←(⌈/d+1) (≢d) ⍴ 0
$ grid
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
```

- `((d ,¨ ⍳≢d))` creates an array of pairs `(depth, preindex)`. We will use
  this to fill index `(d, pi)` with the value `pi`.

```
$ writeixs ← (d,¨⍳≢d)
$ ]disp writeixs
┌→──┬───┬───┬───┬───┬───┬───┬───┬───┬───┬────┬────┬────┬────┬────┐
│0 0│1 1│2 2│1 3│2 4│3 5│2 6│1 7│2 8│3 9│3 10│2 11│3 12│3 13│2 14│
└~─→┴~─→┴~─→┴~─→┴~─→┴~─→┴~─→┴~─→┴~─→┴~─→┴~──→┴~──→┴~──→┴~──→┴~──→┘
```

- `ixgrid ← ((⍳≢d)@writeixs) grid` rewrites at index `writeixs[i]` the value (`(i≢d)[i]`).

```
$ ixgrid ← ((⍳≢d)@writeixs) grid
$ ixgrid
0 0 0 0 0 0 0 0 0 0  0  0  0  0  0
0 1 0 3 0 0 0 7 0 0  0  0  0  0  0
0 0 2 0 4 0 6 0 8 0  0 11  0  0 14
0 0 0 0 0 5 0 0 0 9 10  0 12 13  0
```

- Finally, `⌈` is the maximum operator, and `\` is the [prefix scan]() operator,
  so `⌈\ixgrid` creates a prefix scan of the above grid to give us our
  final path matrix:

```
$ PM ← ⌈\ixgrid
$ PM
0 0 0 0 0 0 0 0 0 0  0  0  0  0  0
0 1 1 3 3 3 3 7 7 7  7  7  7  7  7
0 0 2 2 4 4 6 6 8 8  8 11 11 11 14
0 0 0 0 0 5 5 5 5 9 10 10 12 13 13
```

#### Using the path matrix:  distance of a node from every other node.

Note that the maximum distance between two nodes is to climb
all the way to the top node, and then climb down:

```
dmax ← depth(a) + depth(b)
```

If we know the lowest common ancestor of two nodes,
then the distance of one node to another is:

```
dcorrect ← dist(a, lca(a, b)) + dist(b, lca(a, b))
```

So, we can compute the depth as:

```
dcorrect ← dist(a, lca(a, b)) + dist(lca(a, b), b)
 = dist(a, lca(a, b)) + depth(lca(a, b)) +
   dist(b, lca(a, b)) + depth(lca(a, b)) +
   -2 * depth(lca(a, b))
 = depth(a) +
   depth(b) +
   -2 * depth (lca(a, b))
```

[TODO: picture]
[TODO: finish writing this]


#### Parent vector representation

A parent vector is a vector of length `n` where `Parent[i]` denotes an
index into `Parent`. Hence, the following condition will return 1
if V is a parent vector.

For example, for our given example, here is the parent vector:

```
d ← (0  1  2  1  2  3  2  1  2  3  3  2  3  3  2) │ depths
    (∘  a  p  b  q  v  r  c  s  w  x  t  y  z  u) │ values
p ← (∘  ∘  a  ∘  b  q  b  ∘  c  s  s  c  t  t  c) │ parents
    (0  1  2  3  4  5  6  7  8  9 10 11 12 13 14) | indexes
P ← (0  0  1  0  3  4  3  0  7  8  8  7 11 11  7) │ parent indices



              ∘:0                               0
┌──────────┬──┴─────────────────┐
a:1        b:3                 c:7              1
│      ┌───┴───┐     ┌──────────┼───────┐
p:2    q:4     r:6   s:8        t:11    u:14    2
       │             │          │
       │          ┌──┴──┐     ┌─┴───┐
       v:5        w:9   x:10  y:12  z:13        3
```


The condition a parent vector must satisfy is:

```
∧/V ∊(⍳≢V) ⍝ [All elements of V belong in the list [1..len(V)] ]
```

- `V ∊ (⍳≢V)` will be a list of whether each element in v belongs (`∊`) to the list
  `(⍳≢V) = [1..len(V)]`
- Recall that `/` is for reduction, and `∧/` is a boolean `AND` reduction.
  Hence, we compute whether each element of the vector `V` is in the range `[1..len(V)]`.
- We add the constraint that root notes that don't have a parent simply
  point to themselves. This allows us to free ourselves from requiring
  some kind of `nullptr` check.


The root node (parent of all elements) can be found using the fixpoint operator (`⍨`):

```
I←{(⊂⍵)⌷⍺} ⍝ index into the left hand side param using right hand side param
I⍣≡⍨p ⍝ compute the fixpoint of the I operator using ⍨ and apply it to p
```



#### Converting from depth vector to parent vector, Take 1

As usual, let's consider our example:

```
d ← (0  1  2  1  2  3  2  1  2  3  3  2  3  3  2) │ depths
    (∘  a  p  b  q  v  r  c  s  w  x  t  y  z  u) │ values
p ← (∘  ∘  a  ∘  b  q  b  ∘  c  s  s  c  t  t  c) │ parents
    (0  1  2  3  4  5  6  7  8  9 10 11 12 13 14) | indexes
P ← (0  0  1  0  3  4  3  0  7  8  8  7 11 11  7) │ parent indices



              ∘:0                               0
┌──────────┬──┴─────────────────┐
a:1        b:3                 c:7              1
│      ┌───┴───┐     ┌──────────┼───────┐
p:2    q:4     r:6   s:8        t:11    u:14    2
       │             │          │
       │          ┌──┴──┐     ┌─┴───┐
       v:5        w:9   x:10  y:12  z:13        3
```

Note that the depth vector already encodes parent-child information.
- The parent of node `i` is a node `j` such that `d[j] = d[i] - 1` and
  `j` is the closest index to the left of `i` such that this happens.

For example, to compute the parent of `t:11`, notice that it's at depth `2`.
So we should find all the nodes from `d[0..11]` which have depths equal to
`2`, and then pick the rightmost one. This translates to the expression:

```
$ d ← (0  1  2  1  2  3  2  1  2  3  3  2  3  3  2)
$ t ← 11   ⍝ target node
$ ixs ← ⍳t   ⍝ array indexes upto this node
  0 1 2 3 4 5 6 7 8 9 10
$ d[ixs]   ⍝ depths of nodes to the left of the given node t
  0 1 2 1 2 3 2 1 2 3 3
$ d[ixs]  = d[t]-1  ⍝ boolean vector of nodes whose depth is that of t's parent
  0 1 0 1 0 0 0 1 0 0 0
$ eqds ← ⍸ (d[ixs] = d[t]-1)  ⍝ array indexes of nodes whose depth is that of t's parent
  1 3 7
$ ⌽ eqds ⍝ reverse of array indexes to extract `7`
  7 3 1
$ ⊃ ⌽ eqds ⍝ first of the reverse of the array indexes to extract `7`
  7
$ (⌽⍸(d[⍳t] = d[t]-1))[0]  ⍝ APL style one-liner of the above
```

While this is intuitive, this does not scale: It does not permit us to find
the parent of all the nodes _at once_ --- ie, it is not parallelisable
over choices of `t`.

#### Converting from depth vector to parent vector, Take 2 (Or scan idiom)

Imagine we have a list of `0`s and `1`s, and we want to find the _index_ of
the rightmost `1` value. For example, given:

```
       0 1 2 3 4 5 6 7 8 9 10 11 12
$ a ← (0 0 1 0 0 0 1 0 1 0  0  0  0)
```

we want the answer to be `f a = 8`. We saw an implementation in terms of
`f←{(⌽⍸⍵)[0]}` in Take 1.
(recall that `⍵` is the symbol for the right-hand-side argument of a function).

We're going to perform the same operation slightly differently. Let's consider
the series of transformations:

```
⍝      0 1 2 3 4 5 6 7 8 9 10 11 12
$ a ← (0 0 1 0 0 0 1 0 1 0  0  0  0) ⍝ original array

$ ⌽a  ⍝ reverse of a
  0 0 0 0 1 0 1 0 0 0 1 0 0

$ ∨\ ⌽a ⍝ prefix scan(\) using the OR(∨) operator. Turn all
        ⍝ entries after the first 1 into a 1
  0 0 0 0 1 1 1 1 1 1 1 1 1

$ +/ (∨\ ⌽a)  ⍝ sum over the previous list, counting number of 1s
  9

$ ¯1 +  (+/ (∨\ ⌽a))  ⍝ subtract 1 from the previous number
  8
```

Why the hell does this work? Well, here's the proof:

- On running `⌽a`, we reverse the `a`. The last 1 of `a` at index $i$
  becomes the first $1$ of `⌽a` at index $i' \equiv n-i$.
- On running  `∨\ ⌽a`, numbers including and after the first 1
  become `1`. That is, all indexes $j \geq i'$ have 1 in them.
- On running `+/ (∨\ ⌽a)`, we sum up all 1s. This will give us $n-i'+1$ 1s.
  That is, $n-i'+1 = n-(n-i)+1 =i+1$.
- We subtract a $1$ to correctly find the $i$ from $i+1$.

This technique will work for __every row of a matrix__. This is paramount,
since we can now repeat this for the depth vector we were previously
interested in for each row, and thereby compute the parent index!


#### Converting from depth vector to parent vector, Take 3 (full matrix)

We want to extend the previous method we hit upon to compute the parents
of all nodes in parallel. To perform this, we need to run the moral
equivalent of the following:

```
$ ⎕IO ← 0 ⍝ 0 indexing
$ d ← (0  1  2  1  2  3  2  1  2  3  3  2  3  3  2) ⍝ depth vector
$ t ← 11 ⍝ node we are interested in
$ a←d[⍳t]=d[t]-1  ⍝ boolean vector of nodes whose depth is that of t's parent
  0 1 0 1 0 0 0 1 0 0 0
$ ¯1 +  (+/ (∨\ ⌽a)) ⍝ index of last 0 of boolean vector
7
```

for _every single choice of t_. To perform this, we can build a 2D matrix
of `d[⍳t]=d[t]-1` where `t` ranges over `[0..len(d)-1]` (ie, it ranges
over all the nodes in the graph).

We begin by using:

```
$ ⎕IO ← 0 ⋄ d ← (0  1  2  1  2  3  2  1  2  3  3  2  3  3  2) ⍝ depths
$ ]display ltdepth ← d ∘.> d ⍝ find `d[i] > d[j]` for all i, j.
┌→────────────────────────────┐
↓0 0 0 0 0 0 0 0 0 0 0 0 0 0 0│
│1 0 0 0 0 0 0 0 0 0 0 0 0 0 0│
│1 1 0 1 0 0 0 1 0 0 0 0 0 0 0│
│1 0 0 0 0 0 0 0 0 0 0 0 0 0 0│
│1 1 0 1 0 0 0 1 0 0 0 0 0 0 0│
│1 1 1 1 1 0 1 1 1 0 0 1 0 0 1│
│1 1 0 1 0 0 0 1 0 0 0 0 0 0 0│
│1 0 0 0 0 0 0 0 0 0 0 0 0 0 0│
│1 1 0 1 0 0 0 1 0 0 0 0 0 0 0│
│1 1 1 1 1 0 1 1 1 0 0 1 0 0 1│
│1 1 1 1 1 0 1 1 1 0 0 1 0 0 1│
│1 1 0 1 0 0 0 1 0 0 0 0 0 0 0│
│1 1 1 1 1 0 1 1 1 0 0 1 0 0 1│
│1 1 1 1 1 0 1 1 1 0 0 1 0 0 1│
│1 1 0 1 0 0 0 1 0 0 0 0 0 0 0│
└~────────────────────────────┘
```

- Note that `gt[i][j] = 1` iff `d[j] < d[i]`. So, for a given row (`i = fixed`), the `1s`
  nodes that are at lower depth (ie, potential parents).

- If we mask this to only have those indeces where `j <= i`, then the
  last one in each row will be such that `d[last 1] = d[i] - 1`. Why? Because
  the node that is closest to us with a depth less than us _must_ be our parent,
  in the preorder traversal.

```
$ ⎕IO ← 0 ⋄ d ← (0  1  2  1  2  3  2  1  2  3  3  2  3  3  2) ⍝ depths
$ ]display left ←  (⍳3) ∘.> (⍳3) ⍝ find `i > j` for all i, j.
┌→────┐
↓0 0 0│
│1 0 0│
│1 1 0│
└~────┘
```

Combining the three techniques, we can arrive at:

```
$ ⎕IO ← 0 ⋄ d ← (0  1  2  1  2  3  2  1  2  3  3  2  3  3  2) ⍝ depths
$ ltdepth ← d ∘.> d ⍝ find `d[i] > d[j]` for all i, j.
$ preds ←  (⍳≢d) ∘.> (⍳≢d) ⍝ predecessors: find `i > j` for all i, j.
$ pred_higher ←  ltdepth ∧ left   ⍝ predecessors tht are higher in the tree
$  parents_take_3 ← ¯1 +  +/∨\⌽pred_higher  ⍝ previous idiom for finding last 1.
¯1 0 1 0 3 4 3 0 7 8 8 7 11 11 7
```

For comparison, the actual value is:

```
    (0   1  2  3  4  5  6  7  8  9 10 11 12 13 14)  | indexes
d ← (0   1  2  1  2  3  2  1  2  3  3  2  3  3  2)  │ depths
P ← (0   0  1  0  3  4  3  0  7  8  8  7 11 11  7)  │ parent indices
    (¯1  0  1  0  3  4  3  0  7  8  8  7 11 11  7) | parents, take 3

              ∘:0                               0
┌──────────┬──┴─────────────────┐
a:1        b:3                 c:7              1
│      ┌───┴───┐     ┌──────────┼───────┐
p:2    q:4     r:6   s:8        t:11    u:14    2
       │             │          │
       │          ┌──┴──┐     ┌─┴───┐
       v:5        w:9   x:10  y:12  z:13        3
```
We have an off-by-one error for the `0` node! That's easily fixed, we simply
perform a maximum with `0` to move `¯1 -> 0`:

```
$  parents_take_3 ← 0⌈  ¯1 +  +/∨\⌽pred_higher
0 0 1 0 3 4 3 0 7 8 8 7 11 11 7
```

So, that's our function:

```
parents_take_3 ← 0⌈  ¯1 +  +/∨\⌽ ((d∘.>d) ∧ (⍳≢d)∘.>(⍳≢d))
0 0 1 0 3 4 3 0 7 8 8 7 11 11 7
```

Note that the time complexity for this is dominated by having to calculate
the outer products, which even given infinite parallelism, take $O(n)$ time.
We will slowly chip away at this, to be far better.

#### Converting from depth vector to parent vector, Take 4 (log critial depth)
We will use the Key(`⌸`) operator which allows us to create key value pairs.

```
$ d ← 0 1 2 1 2 3 2 1 2 3 3 2 3 3 2
$ ]disp (⍳≢d) ,¨ d ⍝ zip d with indexes
┌→──┬───┬───┬───┬───┬───┬───┬───┬───┬───┬────┬────┬────┬────┬────┐
│0 0│1 1│2 2│3 1│4 2│5 3│6 2│7 1│8 2│9 3│10 3│11 2│12 3│13 3│14 2│
└~─→┴~─→┴~─→┴~─→┴~─→┴~─→┴~─→┴~─→┴~─→┴~─→┴~──→┴~──→┴~──→┴~──→┴~──→┘
```

```
$ d ← 0 1 2 1 2 3 2 1 2 3 3 2 3 3 2
$ ]display b ← {⍺ ⍵}⌸d  ⍝ each row i has tuple (i, js): d[js] = i
┌→──────────────────┐
↓   ┌→┐             │
│ 0 │0│             │
│   └~┘             │
│   ┌→────┐         │
│ 1 │1 3 7│         │
│   └~────┘         │
│   ┌→────────────┐ │
│ 2 │2 4 6 8 11 14│ │
│   └~────────────┘ │
│   ┌→───────────┐  │
│ 3 │5 9 10 12 13│  │
│   └~───────────┘  │
└∊──────────────────┘
```

In fact, it allows us to apply an arbitrary function to combine keys and values.
We will use a function that simply returns all the values for each key.

```
$ d ← 0 1 2 1 2 3 2 1 2 3 3 2 3 3 2
$ ]display b ← {⍵}⌸d ⍝ each row i contains values j such that d[j] = i.
┌→──────────────┐
↓0 0  0  0  0  0│
│1 3  7  0  0  0│
│2 4  6  8 11 14│
│5 9 10 12 13  0│
└~──────────────┘
```

Our first try doesn't quite work: it winds up trying to create a numeric matrix,
which means that we can't have different rows of different sizes. So, the
information that _only_ index `0` is such that `d[0] = 0` is lost. What we
can to is to wrap the keys to arrive at:

```
$ d ← 0 1 2 1 2 3 2 1 2 3 3 2 3 3 2
$ ]display b ← {⊂⍵}⌸d ⍝ d[b[i]] = i
┌→───────────────────────────────────────────┐
│ ┌→┐ ┌→────┐ ┌→────────────┐ ┌→───────────┐ │
│ │0│ │1 3 7│ │2 4 6 8 11 14│ │5 9 10 12 13│ │
│ └~┘ └~────┘ └~────────────┘ └~───────────┘ │
└∊───────────────────────────────────────────┘
```
Consider the groups `b[2] = (2 4 6 8 11 14)` and `b[3] = (5 9 10 12 13)`. All of `3`'s parents
are present in `2`. Every element in `3` fits at some location in `2`. Here is what
the fit would look like:

```
b[2]  2 4 _ 6 8 _  _ 11 __ __ 14   (nodes of depth 2)
b[3]      5     9  10   12 13      (leaf nodes)
          4     8   8   11 11      (parents: predecessor of b[3] in b[2])

              ∘:0                               0
┌──────────┬──┴─────────────────┐
a:1        b:3                 c:7              1
│      ┌───┴───┐     ┌──────────┼───────┐
p:2    q:4     r:6   s:8        t:11    u:14    2
       │             │          │
       │          ┌──┴──┐     ┌─┴───┐
       v:5        w:9   x:10  y:12  z:13        3
```

We use the Interval Index(`⍸`) operator to solve the problem of finding the
parent / where we should sqeeze a node from `b[3]` into `b[2]`
(This is formally known as the
[predecessor problem](https://en.wikipedia.org/wiki/Predecessor_problem))

```
⍝ left[a[i]] is closest number < right[i]
⍝ left[a[i]] is the predecessor of right[i] in left[i].
$ a ← (1 10 100 1000) ⍸ (1 2000 300 50 2 )
0 3 2 1 0
```

Now, we can use the technology of predecessor to find parents
of depth 3 nodes among the depth 2 nodes:

```
$ depth2 ← 2 4 6 8 11 14
$ depth3 ← 5 9 10 12 13 ⍝ parents (from chart): 4 8 8 11 11
$ depth3parentixs ← depth2 ⍸ depth3
$ depth3parents  ← depth2[depth3parentixs]
4 8 8 11 11

              ∘:0                               0
┌──────────┬──┴─────────────────┐
a:1        b:3                 c:7              1
│      ┌───┴───┐     ┌──────────┼───────┐
p:2    q:4     r:6   s:8        t:11    u:14    2
       │             │          │
       │          ┌──┴──┐     ┌─┴───┐
       v:5        w:9   x:10  y:12  z:13        3
```

We need to know one-more APL-ism: the `2-scan`. When we write
a usual scan operation, we have:

```
$ ⍳5
1 2 3 4 5
```
```
$ +/⍳5 ⍝ reduce
15
```

```
$ 2+/⍳5 ⍝ apply + to _pairs_ (2 = pairs)
3 5 7 9 ⍝ (1+2) (2+3) (3+4) (4+5)
```

```
$ 3+/⍳5 ⍝  apply + to 3-tuples
6 9 12 ⍝ (1+2+3) (2+3+4) (3+4+5)
```

We begin by assuming the parent of `i` is `i` by using `p←⍳≢d`.

```
$ d ← (0 1 2 1 2 3 2 1 2 3 3 2 3 3 2)
$ d2nodes ← {⊂⍵}⌸d
┌→┬─────┬─────────────┬─────────────┐
│1│2 4 8│3 5 7 9 12 15│6 10 11 13 14│
└→┴~───→┴~───────────→┴~───────────→┘
$ p←⍳≢d
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
```

Now comes the biggie:
```
$ findparent ← {parentixs ← ⍺⍸⍵ ⋄ p[⍵]←⍺[parentixs]}
```
- `⍺` is the list of parent nodes.
- `⍵` is the list of current child nodes.
- We first find the indexes of our parent nodes by using
  the `pix ← parent ⍸ child` idiom.
- Then, we find the actual parents by indexing into
  the parent list: `pix[parentixs]`.
- We write these into the parents of the child using:
  `p[children] ← parent[parent ⍸ child]`


This finally culminates in:
```
$ d←0 1 2 1 2 3 2 1 2 3 3 2 3 3 2
$ p←⍳≢d ⋄ d2nodes←{⊂⍵}⌸d ⋄ findp←{pix ← ⍺⍸⍵ ⋄ p[⍵]←⍺[pix]} ⋄ 2findp/d2nodes ⋄ p
0 0 1 0 3 4 3 0 7 8 8 7 11 11 7


    (0   1  2  3  4  5  6  7  8  9 10 11 12 13 14)  | indexes
d ← (0   1  2  1  2  3  2  1  2  3  3  2  3  3  2)  │ depths
P ← (0   0  1  0  3  4  3  0  7  8  8  7 11 11  7)  │ parent indices
              ∘:0                               0
┌──────────┬──┴─────────────────┐
a:1        b:3                 c:7              1
│      ┌───┴───┐     ┌──────────┼───────┐
p:2    q:4     r:6   s:8        t:11    u:14    2
       │             │          │
       │          ┌──┴──┐     ┌─┴───┐
       v:5        w:9   x:10  y:12  z:13        3
```

Which can be further golfed to:
```
$ p⊣2{p[⍵]←⍺[⍺⍸⍵]}⌿⊢∘⊂⌸d⊣p←⍳≢d
0 0 1 0 3 4 3 0 7 8 8 7 11 11 7
```

The total time complexity of this method assuming infinite parallelism is as follows:
```
$ p←⍳≢d ⋄ d2nodes←{⊂⍵}⌸d ⋄ findp←{pix ← ⍺⍸⍵ ⋄ p[⍵]←⍺[pix]} ⋄ 2findp/d2nodes ⋄ p
```
- `(p←⍳≢d)` can be filled in `O(1)` time.
- `(d2nodes←{⊂⍵}⌸d)` is searching for keys in a small integer domain, so this is `O(#nodes)` using
  radix sort as far as I know. However, the thesis mentions that this can be done in
  `O(log(|#nodes|))`. I'm not sure how, I need to learn this.
- For each call of `findp`, the call `(pix ← ⍺⍸⍵)` can be implemented using binary search
  leading to a logarthmic complexity in the size of `⍺` (since we are looking up
  for predecessors of `⍵` in `⍺`).
- The time complexity of the fold `2findp/d2nodes` can be done entirely in parallel
  since all the writes into the `p` vector are independent: we only write the
  parent of the current node we are looking at.


### 3.4: Computing nearest Parent by predicate

I'm going to simplify the original presentation by quite a bit.


```
     a b c d e f g h i  | names
     0 1 2 3 4 5 6 7 8  | indexes
P ← (0 0 1 2 0 4 5 6 7) | parents
X ← (0 1 0 0 1 1 0 0 0) | marked nodes

     a:0
┌────┴───┐
b:1(X)   e:4(X)
|        |
c:2      f:5(X)
|        |
d:3      g:6
         │
         h:7
         |
         i:8
```

We want to find nodes marked as `X` that are the closest parents to a
given node. The `X` vector is a boolean vector that has a `1` at
the index of each `X` node: `(b, e, f)`. So, the indexes `(1, 4, 5)`
are `1` in the `X` vector.

The output we want is the vector:

```
      0 1 2 3 4 5 6 7 8  | indexes
      a b c d e f g h i  | names
PX ← (0 0 1 1 0 4 5 5 5) | closest X parent index
      a a b b a e f f f  | closest X parent name

    a:0
┌────┴───┐
b:1(X)   e:4(X)
|        |
c:2      f:5(X)
|        |
d:3      g:6
         │
         h:7
         |
         i:8
```

The incantation is:

```
$ I←{(⊂⍵)⌷⍺} ⍝ index LHS by RHS | (100 101 102 103)[(3 1 2)] := 103 101 102
$ PX ← P I@{X[⍵]≠1} ⍣ ≡ P
0 0 1 1 0 4 5 5 5
```

TODO. At any rate, since this does not require any writes and purely reads,
and nor does it need any synchronization, this is fairly straightforward
to implement on the GPU.

### 3.5: Lifting subtrees to the root

Once we have marked our `X` nodes, we now wish to lift entire subtrees of `X`
up to the root.
-  This pass displays how to lift subtrees and add new nodes to replace the subtree's original nodes.
- Luckily, there are no _sibling_ relationships that need to be maintained since
  we are uprooting an entire subtree.
- There are no _ordering constraints_ on how the subtrees should be arranged at
  the top.
- Hence, we can simply add new nodes to the _end_ of the tree (in terms of the preorder traversal).
  Adding to the middle of the tree will be discussed later.

There is some good advice in the thesis:
> When using APL primitives this way, it may be good to map
> their names and definitions to the domain of trees. For example,
> the primitive `⍸Predicate` is read as "the nodes where `Predicate` holds"
> and not as "the indexes where `Predicate` is 1".

For example, given the tree:

```
      0 1 2 3 4 5  | indexes
      a b c d e f  | names
P  ← (0 0 1 0 3 4) | parents
X  ← (0 1 0 1 1 0) | X nodes
PX ← (0 0 1 0 3 4) | closest X parent index

    a:0
┌────┴───┐
b:1(X)   d:3(X)
|        |
c:2      e:4(X)
         |
         f:5
```

we want the transformed tree to be:

```
    a:0
┌────┴───┐
bp:1(X)   ep:4(X)
---------
b:1(X)
|
c:2
---------
e:4
|
fp:5
---------
f:5(X)
|
g:6
```

We first look for nodes that need to be lifted.  There are:
- Non-root nodes (ie, nodes whose parents are not themselves: `p≠(⍳≢p)`)
- Which have the property `X`.

```
nodes←⍸(X ∧ p≠(⍳≢p))  ⍝ ⍸:pick indexes.
```

### 3.6: Wrapping Expressions
### 3.7: Lifting Guard Test Exprsessions
### 3.8: Couting rank of index operators
### 3.9: Flattening Expressions
### 3.10: Associating Frame slots and variables
### 3.11: Placing frames into a lexical stack
### 3.12: Recording Exported names
### 3.13: Lexical Resolution

### 5.2.1 Traversal Idioms
### 5.2.2 Edge Mutation Idioms
### 5.2.3 Node Mutation Idioms

# Things I wish I knew when I was learning APL

- For pasting multi-line code,
  [there is a bug in the bug tracker for RIDE](https://github.com/Dyalog/ride/issues/323).
  For multi-line dfns, one can use `∇`. For multi-line values, I don't know yet.

- Operators in APL terminology (such as `¨`) are higher order functions.
  Thus, an operator allows one to modify known functions.

- Use `]disp` and `]display` to understand the structure of APL arrays.

- Set `]box on -style=max` to _always enable_ drawing arrays with `]display`.
  This is supremely useful as a newbie to understand array structure.

- Set `]box on -trains=parens` to render trains as trees. Super
  helpful when attempting to grok `train` code.

- Set `]boxing on` to enable boxing for trains, arguments, everything.

# Every ideal that is maximal wrt. being disjoint from a multiplicative subset is prime

I ran across this when reading another question on math.se, so I
[posted this proof for verification](https://math.stackexchange.com/questions/3570129/proof-verification-request-complement-of-multiplicative-set-is-ideal-iff-the-id) just to be sure I wasn't missing
something.

We wish to characterise prime ideals as precisely those that are disjoint from
a multiplicative subset $S \subseteq R$. That is:

- An ideal $P$ is prime iff $P = R \setminus S$, where $S$ is a multiplicative subset
  that cannot be made larger (ie, is maximal wrt to the $\subseteq$ ordering).

I'll be using the definition of prime as:

- An ideal $P$ is prime if for all $x, y \in R$,
  $xy \in P \implies x \in P \lor y \in P$.


#### Prime ideal implies complement is maximal multiplicative subset:

Let $S = \equiv R \setminus P$ be the complement of the prime ideal $P \subsetneq R$
in question.
- Since $P \neq R$, $1 \not \in $P. (if $1 \in P$, then every element $x . 1 \in P$
  since $P$ is an ideal, and must be closed under multiplication with the
  entire ring). Hence, $1 \in S$.
- For any $x, y \in S$, we need $xy \in S$ for $S$ to be mulitplicative.
- For contradiction, let us say that $x, y \in S$ such that $xy \not \in S$.
  Translating to $P$, this means that $x, y \not \in P$ such that $xy \in P$.
  This contradictions the definition of $P$ being prime.

#### Ideal whose complement is maximal multiplicative subset implies ideal is prime.

- Let $I$ be an ideal of the ring $R$ such that its complement $S \equiv R / I$
  is a maximal multiplicative subset.
- Let $i_1 i_2 \in I$. For $I$ to be prime,
  we need to show that $i_1 \in I$ or $i_2 \in I$.
- For contradiction, let $i_1, i_2 \not \in I$.
  Thus, $i_1, i_2 \in S$. Since $S$ is multiplicative, $i_1 i_2 \in S$. That is,
  $i_1 i_2 \not \in I$ (since $I$ is disjoint from $S$).
- But this violates our assumption that $i_1 i_2 \in I$. Hence, contradiction.


# Getting started with APL

- Install [Dyalog APL](https://www.dyalog.com/download-zone.htm).
- Setup [RIDE](https://github.com/Dyalog/ride), the IDE for dyalog APL.
  This IDE comes with auto complete, good key bindings, a top bar chock-full of
  information of all the APL symbols. It's really well designed and a pleasure
  to use.
- Follow the [Dyalog tutorial](https://tutorial.dyalog.com/), solving it
  chapter by chapter.
- Bookmark [APLCart](https://aplcart.info/), a collection of APL idioms, and
  refer to it when in need.
- Ask questions at [the APL orchard](https://chat.stackexchange.com/rooms/52405/the-apl-orchard)

# SpaceChem was the best compiler I ever used

It's kind of sad that this is the case, but on thinking about this, I realised
that the SpaceChem game was essentially a compiler, and it was such a pleasure
to learn how to use and debug --- the visual nature of it made it amazing to
find out.

# Mnemonic for Kruskal and Prim

I often forget which is which, so I came up with this:

- Prim is very prim and proper, and therefore doesn't spread herself out. She
  picks out the minimum spanning tree one vertex at a time.


# Legendre transform

<img  src="./static/legendre.png">


# Cartesian Trees

Cartesian trees construct a tree $T = C(A)$ given an array $A$, such that
range minimum query (RMQ) on the array $A$ is equivalent to the lowest common ancestor (LCA)
of the nodes of the tree $T$.


<img src="./static/cartesian-tree.svg">

Note that the tree looks like a _min-heap_.

To see the connection to LCA, if we want to find the range minimum in the range containing the
elements `[12, 10, 20, 15, 18]` of the array, the minimum is `10`, which is
indeed the lowest common ancestor of the nodes of `12` and `18` in the tree.

#### Building a Cartesian tree in linear time:

#### Converting LCA to RMQ

We can go the other way, and convert an LCA problem into a RMQ problem. We
perform an inorder traversal of the nodes, scribbling down the
depth of the node ([Link to lecture at 15:30](https://youtu.be/0rCFkuQS968?t=934)).
We ask for the _argmin_ version of RMQ, that gives us the _index_ of
the node with the lowest depth. This gives us the index of where the node lives.

#### Universe reduction in RMQ

We can have an arbitrary ordered universe, on which we want to perform RMQ.
We can convert this to LCA by using a cartesian tree, and then convert to
a "clean" RMQ (by using the LCA -> RMQ using depth conversion). This now
will give us way faster operations (since we now have integers).

#### `+-1` RMQ:

We want the differences between nodes to have a difference of only `+-1`. We
had a much wider gap. Here, we perform an Euler tour (walk the tree DFS search order),
and sribble down every vertex we visit.

To find the LCA, we perform the RMQ on the locations of the _first_ occurence
of the node. (I think we don't actually need the first occurence, any
occurence will do).

#### References

- Material shamelessly written down from
  [Eric Demaine's excellent (MIT 6.851 Advanced Data Structures): Lecture 15](https://www.youtube.com/watch?v=0rCFkuQS968)
- Image of the tree [taken from WikiMedia](https://upload.wikimedia.org/wikipedia/commons/d/d5/Cartesian_tree.svg)




# DFS numbers as a monotone map

Really, we want a partial order that is defined with the tree as the
Hasse diagram. However, performing operations on this is hard. Hence,
the DFS numbering is a good monotone map from this partial order
to the naturals, which creates a total order.

I want to think about this deeper, I feel that this might be a good way
to think about the `low` numbers that show up in
[tarjan's algorithm for strongly connected components](https://en.wikipedia.org/wiki/Tarjan%27s_strongly_connected_components_algorithm)

This also begs the question: can we use other partial orders, that chunk
some information, but don't lose _all_ the information as going to a total
order (the naturals) does?

# Self attention? not really

The code is taken from [The annotated transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html)
which explains the "attention is all you need paper".

On skimming the code, one sees the delightful line of code:

```py
class EncoderLayer(nn.Module):
  "Encoder is made up of self-attn and feed forward (defined below)"
  def __init__(self, size, self_attn, feed_forward, dropout):
     super(EncoderLayer, self).__init__()
     self.self_attn = self_attn
     self.feed_forward = feed_forward
     self.sublayer = clones(SublayerConnection(size, dropout), 2)
     self.size = size
  def forward(self, x, mask):
    "Follow Figure 1 (left) for connections."
    x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
    return self.sublayer[1](x, self.feed_forward)
```

where the line:

```py
x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))
```

seems to imply that we are, indeed, performing a self attention with the same
value `x` as the query, key, and value.

However, reading the code of the self-attention (or the paper) leads
one to realise:

```py
class MultiHeadedAttention(nn.Module):
  def __init__(self, h, d_model, dropout=0.1):
    "Take in model size and number of heads."
    super(MultiHeadedAttention, self).__init__()
    assert d_model % h == 0
    # We assume d_v always equals d_k
    self.d_k = d_model // h
    self.h = h
    self.linears = clones(nn.Linear(d_model, d_model), 4)
    self.attn = None
    self.dropout = nn.Dropout(p=dropout)

  def forward(self, query, key, value, mask=None):
    "Implements Figure 2"
    if mask is not None:
        # Same mask applied to all h heads.
        mask = mask.unsqueeze(1)
    nbatches = query.size(0)

    # 1) Do all the linear projections in batch from d_model => h x d_k
    query, key, value = \
        [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)
         for l, x in zip(self.linears, (query, key, value))]

    # 2) Apply attention on all the projected vectors in batch.
    x, self.attn = attention(query, key, value, mask=mask,
                             dropout=self.dropout)

    # 3) "Concat" using a view and apply a final linear.
    x = x.transpose(1, 2).contiguous() \
         .view(nbatches, -1, self.h * self.d_k)
    return self.linears[-1](x)
```

where we notice:

```py
# 1) Do all the linear projections in batch from d_model => h x d_k
query, key, value = \
  [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)
   for l, x in zip(self.linears, (query, key, value))]

# 2) Apply attention on all the projected vectors in batch.
x, self.attn = attention(query, key, value, mask=mask,
                         dropout=self.dropout)
```

where we see that `query, key, value` are being linearly transformed
before being used. Hence, an input of $(x, x, x)$ is transformed
to $(q', k', v') = (Qx, Kx, Vx)$ where $Q, K, V$ are arbitrary matrices.

Next, when we pass these into attention, the output we get is:

$$
\text{softmax}(q', k'^T) v = (Q x) (K x)^T (V x) = Q x x^T K^T V x
$$

the code below is the same thing, spelled out:


```
def attention(query, key, value, mask=None, dropout=None):
    "Compute 'Scaled Dot Product Attention'"
    d_k = query.size(-1)
    scores = torch.matmul(query, key.transpose(-2, -1)) \
             / math.sqrt(d_k)
    if mask is not None:
        scores = scores.masked_fill(mask == 0, -1e9)
    p_attn = F.softmax(scores, dim = -1)
    if dropout is not None:
        p_attn = dropout(p_attn)
    return torch.matmul(p_attn, value), p_attn
```

So It's not _really_ self attention: it's more like: modulated attention
to self `:)`


# Coarse structures

A coarse structure on the set $X$ is a collection of relations on $X$:
$E \subseteq 2^{X \times X}$ (called as _controlled sets_ / _entourages_)
such that:

- $(\delta \equiv \{ (x, x) : x \in X \}) \in  E$.
- Closed under subsets: $\forall e \in E, f \subset e \implies f \in E$.
- Closed under transpose: if $e \in E$ then $(e^T \equiv \{ (y, x) : (x, y) \in e \}) \in E$.
- Closed under finite unions.
- Closed under composition: $\forall e, f \in E, e \circ f \in E$, where $\circ$
  is composition of relations.

The sets that are controlled are "small" sets.

The bounded coarse structure on a metric space $(X, d)$ is the set of all relations
such that there exists a uniform bound such that all related elements are within
that bounded distance.
$$
(e \subset X \times X) \in E \iff \exists \delta \in \mathbb R, \forall (x, y) \in E, d(x, y) < \delta
$$


We can check that the functions:
- $f: \mathbb Z \rightarrow \mathbb R, f(x) \equiv x$ and
- $g: \mathbb R \rightarrow \mathbb Z, g(x) \equiv \lfloor x \rfloor$

are coarse inverses to each other.

I am interested in this because if topology is related to semidecidability,
then coarse structures (which are their dual) are related to..?

#### References
- [What is a.. coarse structure by AMS](http://www.ams.org/notices/200606/whatis-roe.pdf)

# Matroids for greedy algorithms (TODO)

#### Definitions of matroids

A matrioid $M$ is a set $X$ equipped with an independence set $I \subseteq 2^X$.
- The empty set is independent: $\emptyset \in I$.
- The independence set is downward-closed/closed under subsets:  $ \forall i \in I, \forall i' \subseteq i, i' \in I$.
- For any independent sets $A, B \in I$, if $\vert A \vert$ is larger than
  $\vert B \vert$, then we must be able to add an element from
  $a \in A$ into $B' \equiv B \cup {a}$ such that $B'$ is both independent and larger than $B$:
  $B' \in I \land \vert B' \vert > \vert B \vert$. (**The exchange property**)

#### Example 1: Linearly independent sets
Let $V$ be a vector space. The independent sets $I$ are of the form:


$$ I \equiv \{ S \subseteq V ~:~ \text{vectors in $S$ are lineary independent} \} $$

This is an independence system because the empty set is linearly independent,
and subsets of a linearly independent collection of vectors will be linearly
independent.

The exchange property is satisfied because of linear algebraic reasons.

#### Example 2: The graphic/cyclic Matroid: Matroid of Forests

Let $G = (V, E)$ be a graph. Then collections of edges of the form:

$$ I \equiv \{ F \subseteq E : \text{$F$ contains no cycles} \} $$

is an independence system because the empty forest is a forest, and
a subset of edges of a forest continues to be a forest.

To check the exchange property, TODO

#### Example 3: The partition matroid

Consider the partition matroid $M \equiv (E, I)$, where we have a
partitioning of $E$ known as $E_i$, and numbers $k_i$ the
independence set consists of subsets $F$ which have at most $k_i$
elements in common with each $E_i$.
$$
I \equiv \{ F \subseteq E  : \forall i = 1, \dots N, \vert F \cap E_i \vert \leq k_i \}
$$

The independence axioms are intuitively satisfied, since our constraints on picking
edges are of the form $\vert F \cap E_i \vert \leq k_i$, which will continue to
hold as $F$ becomes smaller.

For the exchange axiom, let $\vert Y \vert > \vert X \vert$. Then, we can assert that for some index
$i$, it must be the case that $\vert Y \cap E_i \vert > \vert X \cap E_i \vert$. Hence,
we can add an element in $E_i \cap (Y / X)$ into $X$ whilst still maintaining independence.


#### Bases and Circuits

- **Bases** are the maximal independent sets of $I$ (ordered by inclusion). On adding an element into a basis element, they
  will become dependent. They are called bases by analogy with linear algebra.

- **Circuits** are minimal dependent sets of $I$. This comes from analogy with trees: if we remove an element
  from any circuit (loop) in a graph, what we are left with is a tree.

A matroid can be completely categorized by knowing either the bases or the circuits of that matroid.

#### Unique Circuit property
- **Theorem**: Let $M \equiv (E, I)$ be a matroid, and let $S \in I, e \in E$ such that $S \cup \{e \} \not \in I$.

Then, there exists a **unique circuit** $C \subseteq S \cup \{ e \}$.

That is, when we go from independent to dependent by adding an element, we will
have a **single, unique circuit**. For example, when we add an edge into a
forest to create a cycle, this cycle will be unique!

##### Proof

Let $C_1, C_2$ be circuits
created when $e$ was added into $S$, where $C_1$ is the **largest** circuit of $S$,
and $C_2$ is the **smallest** circuit of $S$.

Notice that $C_1, C_2$ __must__ contain $e$ ---
if they did not, then $C_1, C_2$ would be circuits in
$S$, contradicting the assumption that $S$ is independent.

Recall that $C_1, C_2$ are both circuits, which means that removing even a
single element from them will cause them to become independent sets.

Let us contemplate $C \equiv C_1 \cup C_2$. Either $C = C_1$ in which
case we are done.

Otherwise, $\vert C \vert > \vert C_1 \vert$, $\vert C \vert > \vert C_2 \vert$.

Otherwise, consider $C' \equiv C \ \{ e \} = (C_1 \cup C_2) \ \{e\} = (C_1 \ \{e\}) \cup (C_2 \ \{ e \})$.
- $C' \subseteq S$, since $C_1 \ \{e\}, C_2 \ \{e\} \subseteq S$.
- $S$ is an independent set, all of whose subsets are independent by
  definition.  So $C'$ is an independent set.
- $\vert C' \vert \geq \vert C_1 \vert$, $\vert C' \vert \geq \vert C_2 \vert$.

Now, we consider $C$. Clearly, this is a dependent set,
since $C_1 \subsetneq C$, and $C_1$ is a dependent set.

Since, $C = C' \cup \{e \}$, this means that $C'$ is a maximally independent set.
Since $C'$ does not contain $e$, $C' = S$.


#### Rank functions

A rank function of a matroid $M \equiv \langle X, I \rangle$
is a function:

$$
r: 2^X \rightarrow \mathbb N : r(S) = \max \{ \vert T \vert : T \subseteq S \land T \in I \}
$$

That is, for any subset $S \subseteq X$, $r(S)$ is the cardinality of the
largest independent subset of $S$.

- In the matroid of linearly independent sets of vectors, the rank of
  a set of vectors is the dimension of their spanning set.


In this matroid, the

TODO: picture


#### Intersection of matroids is not necessarily a matroid:

```
M1 = < d {[(a) (b)] c}>
```

```
M2 = < {d [(a) (b)]} c>
```

The intersection of these two matroids will be:

```
M1 cap M2 = < d [(a) (b)] c>
```

This is not a matroid because the exchange property fails. There's no
way to go from `[a, b]` to `< d a b c >` by exchanging one element.



#### Bipartite matching as matroid intersection

Matchings in a bipartite graph $G = (V, E)$ with partition $(A, B)$ arise
as the intersection of the independent sets of two matroids.
We will denote by $\delta: V \rightarrow 2^E$ the function which takes
a vertex to the set of edges incident on that vertex.

Let $M_A$ be a _partition matroid_: $M_A \equiv (E, I_A)$ where $I_A$ is:
$$
I_A \equiv \{ F \subseteq E : \vert F \cap \delta(a) \vert \leq 1 \forall a \in A \}
$$
That is, in $I_A$, every independent set has for each vertex of $A$, at most
one edge incident. We need to check that this is an independent set.
The empty set of no edges is independent. If some collection of edges are
such that they have at most one edge incident, then removing edges can
only _decrease_ incidence. Hence, it's also downward closed.


TODO: add picture

Similarly, we define $M_B \equiv (E, I_B)$:
$$
I_B \equiv \{ F \subseteq E : \vert F \cap \delta(b) \vert \leq 1 \forall b \in B \}
$$

Now, notice that any collection of edges $F \in I_A \cap I_B$ is a legal
matching, since the edges cover all vertices of $A$ and $B$ at most once.
The largest element of $I_A \cap I_B$ is the _maximum matching_ that we
are looking for.

#### Largest common independent set

Given two matroids $M_1 \equiv (E, I_1)$, $M_2 \equiv (E, I_2)$, with rank
functions $r_1$ and $r_2$. Let $S \in I_1 cap I_2$ and let $F \subseteq E$.
-  $\vert S \vert = \vert S \cap F \vert + \vert S \cap (E / F) \vert$.


#### References:
- [Michel Goeman's standalone notes on matroids](http://math.mit.edu/~goemans/18433S11/matroid-notes.pdf)
- [Michel Goeman's standalone notes on matroid intersection](http://math.mit.edu/~goemans/18433S11/matroid-intersect-notes.pdf)
- [Lecture 11 of Michel Goeman's lecture on Advanced Combinatorial Optimisation](https://math.mit.edu/~goemans/18438F09/lec11.pdf)
- [Video lecture on fixed-parameter tractability and matroid interesction](https://www.youtube.com/watch?v=BA7ZUz5c3V0)
- [FTP Lecture 25: introduction to matroids](https://www.youtube.com/watch?v=6uGcXMjse20)
- [FTP lecture 26: Faster matroid intersection](https://www.youtube.com/watch?v=eq0nb3C9JWU)

# Grokking Zariski

There's a lot written on the Zariski topology on the internet, but most
of them lack explicit examples and pictures. This is my attempt to
communicate what the Zariski topology looks like, from the perspectives
that tickle my fancy (a wealth of concrete examples,
topology-as-semi-decidability, and pictures).

#### The Zariski topology

Recall that the Zariski topology is defined by talking about what its
closed sets are. The common zero sets of a family of polynomials are
the closed sets of the Zariski topology. Formally, the topology $(\mathbb R^n, \tau)$
has as closed sets:

$$
\{ x \in \mathbb R^n : \forall f_i \in \mathbb R[X_1, X_2, \dots X_n],  f_i(x) = 0  \}
$$

Open sets (the complement of closed sets) are of them form:

$$
\{ x \in \mathbb R^n : \exists f_i \in \mathbb R[X_1, X_2, \dots X_n],  f_i(x) \neq 0  \} \in \tau
$$

The empty set is generated as $\{ x \in \mathbb R^n : 0 \neq 0 \}$ and the
full set is generated as $\{ x \in \mathbb R^n : 1 \neq 0 \}$.


#### Semi-decidability

Recall that in this view of topology, for a space $(X, \tau)$, for every
open set $O \in \tau$, we associate a turing machine $T_O$ which semi-decides
inclusion. That is, if a point is in $O$ then it halts with the output `IN-SET`.
if the point is not in $O$, $T_O$ infinite loops. Formally:

$$
\begin{aligned}
x &&\in O \iff \text{$T_O$ halts on input $x$} \\
x &&\not \in O \iff \text{$T_O$ does not halts on input $o$}
\end{aligned}
$$

Alternatively, for a closed set $C \in \tau$, we associate a a turing machine
$T_C$ which semi-decides exclusion. That is, if a point is _not_ in $C$
it halts with the output "NOT-IN-SET". If the point is in $C$, the turing
machine $T_C$ infinite loops.

Now in the case of polynomials, we can write a function that semidecides
exclusion from closed sets:

```cpp
# return NOT-IN-SET of x is not a zero of the polynomial
def is_not_in_zeros(poly, x0):
  precision = 0 # start with zero precision
  while True:
    if poly(x0[:precision]) != 0: return NOT-IN-SET
    precision += 1 # up the precision
```

Since we can only evaluate a polynomial up to some finite precision, we
start with zero precsion and then gradually get more precise. If some
$x0$ is _not_ a root of $poly$, then at some point, we will have
that $poly(x0) /neq 0$. If $x0$ is indeed a root, then we will never halt
this process; We will keep getting `poly(x0[:precision]) = 0` for all
levels of precision.

#### `Spec(R)`

- To setup a topology for the prime spectrum of a ring, we define the topological
  space as $Spec(R)$, the set of all prime ideals of $R$.
- The closed sets of the topology are $\{ V(I) : I \text{is an ideal of } R \}$,
  where the function $V: \text{Ideals of } R \rightarrow 2^{\text{Prime ideals of } R}$
  each ideal to the set of prime ideals that contain it. Formally,
  $V(I) = \{ p \in Spec(R) : I \subseteq p \}$. 
- We can think of this differently, by seeing that we can rewrite the condition
  as  $V(I) = \{ P \in Spec(R) : I \xrightarrow{P} 0 \}$: On rewriting using the prime ideal $P$, we send the ideal $I$ to $0$.
- Thus, the closed sets of $Spec(R)$ are precisely the 'zeroes of polynomials' / 'zeroes of ideals'.
- To make the analogy precise, note that in the polynomial case, we imposed a 
  topology on $\mathbb R$ by saying that the closed sets were $V(p_i) = \{ x \in \mathbb R : p(x) = 0 \}$
  for some polynomial $p \in \mathbb R[x]$. 
- Here, we are saying that the closed sets are $V(I) = \{ x \in Spec(R) : I(x) = 0 \}$
  for some ideal $I \in R$. so we are looking at  ideals as functions
  from the prime ideal to the reduction of the ideal. That is, $I(P) = I/P$. 

#### $Spec(\mathbb Z)$ from this perspective

Since $\mathbb Z$ is a PID, we can think of numbers instead of ideals. The above
picture asks us to think of a number as a function from a prime to a reduced
number. $n(p) = n \% p$. We then have that the closed sets are those primes
which can zero out some number. That is:

$$
\begin{aligned}
V(I) = \{ x \in Spec(\mathbb Z) : I(x) = 0 \}
V((n)) = \{ (p) \in Spec(\mathbb Z) : (n)/(p) = 0 \}
V((n)) = \{ (p) \in Spec(\mathbb Z) : (n) \mod (p) = 0 \}
\end{aligned}
$$

So in our minds eye, we need to imagine a space of prime ideals (points), which
are testing with all ideals (polynomials). Given a set of prime ideals (a tentative locus, say a circle),
the set of prime ideals is closed if it occurs as the zero of some collection of ideas 
(if the locus occurs as the zero of some collection of polynomials). 


#### Nilpotents of a scheme

- Consider the functions $f(x) = (x - 1)$ and $g(x) = (x - 1)^2$. as functions on $\mathbb R$.
  They are indistinguishable based on Zariski, since their zero sets are
  the same ($\{ 1 \}$).

- If we now move to the scheme setting, we get two different schemes: $R_g \equiv \mathbb R[X] / (x - 1) \simeq \mathbb R$,
  and $R_g \equiv R[X] / (x - 1)^2$. 

- In the ring $R_g$, we have an element $(x-1)$
  such that $(x-1)^2 = 0$, which is a nilpotent. This "picks up" on the repeated
  root.

 - So the scheme is stronger than Zariski, as it can tell the difference
   between these two situations. So we have a kind of "infinitesimal thickening"
   in the case of $R_g$.
   [For more, check the `math.se` question: 'Geometric meaning of the nilradical'](https://math.stackexchange.com/questions/3751728/geometric-meaning-of-the-nilradical)

- Another example is to consider (i) the pair of polynomials $y = 0$
  (the x-axis) and $y = \sqrt(x)$.
  The intersection is the zero set of the ideal
  $(y, y^2 - x) = (y, 0 - x) = (y, x)$.

- Then consider (ii) the pair of $y = 0$ (the x-axis) and $y = x^2$.
  Here, we have "more intersection" along
  the x-axis than in the previous case, as the parabola is "aligned" to the x-axis.
  The intersection is the zero set of the ideal
  $(y, y - x^2) = (y, 0 - x^2) = (y, x^2)$.

- So (i) is governed by $\mathbb R[X, Y] / (y, x)$, while (ii) is governed by $\mathbb R[X, Y] /(y, x^2)$
  which has a nilpotent $x^2$. This tells us that in (ii), there is an
  "infinitesimal thickening" along the $x$-axis
  of the intersection.

# My preferred version of quicksort

Wikipedia lists the implementation of quicksort as:

```cpp
algorithm quicksort(A, lo, hi) is
    if lo < hi then
        p := partition(A, lo, hi)
        quicksort(A, lo, p - 1)
        quicksort(A, p + 1, hi)

algorithm partition(A, lo, hi) is
    pivot := A[hi]
    i := lo
    for j := lo to hi do
        if A[j] < pivot then
            swap A[i] with A[j]
            i := i + 1
    swap A[i] with A[hi]
    return i
```

Here, the indeces `[lo..i-1]` have values less than the pivot, while
`[i..j]` are great or equal to the pivot.

##### The version I prefer

```cpp
// #define SWAP(ix, ix2) { int t = a[ix]; a[ix] = a[ix2]; a[ix2] = t; }
// sorts the interval [l, r]
void qs(int l, int r) {
    if (r - l < 0) return;
    int part = a[r]; // the partition

    // a[getill...n] >= part (getill = greater or equal till)
    // starts at r since we know that a[r] >= (partition=a[r])
    int getill = r;
    // a[l..lttill] < part (lttill = less or equal till.
    // starts at (l-1) since we do not know about any value < partition
    int lttill = l-1;


    // loop until they start probing into the other set
    while(!(lttill+1 >=getill || getill-1 <=lttill)) {
        // if the speculated element is < partition
        if (a[getill-1] < part) {
            // swap the value at getill-1 will the slot at lttill+1
            SWAP(getill-1, lttill+1);
            // increment lttill, since we KNOW that the
            // value at lttill+1 = a[getill-1] is < part
            lttill++;
        } else {
            // all we know is that a[getill-1] < part, so we can engulf
            // the region into
            getill--;
        }
    }
    // the partitions must be next to each other, since we have engulfed everything
    assert(getill - lttill == 1);
    // move the partition value to the center.
    SWAP(getill, r);

    // recurse:solve [l..littil] (leave getill=part alone) solve [getill+1..r]
    qs(l, lttill);
    qs(getill+1, r);
}
```

This implementation to me makes very clear to me what information is "known":
- The segments that is strictly less than the partition.
- The segment that is strictly great or equal the partition.

It also makes clear what is being "probed"/"tentative":
- anything we are accessing as `+-1` is not known yet, we are feeling out
  the boundaries of our partitions.

The termination condition is clear: when one partition starts reaching into
the other partitions resources, its done.

Due to using closed intervals everywhere, it's very easy to see precisely
what data starts and ends where.

What version of quicksort do you prefer? Drop me an email!

# Geometric proof of Cauchy Schwarz inequality

<img src="./static/cauchy-schwarz.svg">

- All credit goes to `p0a` on `##math` on freenode for teaching me this proof!

Here's one fun application of Cauchy-Schwarz. We can apply it to two vectors
$x=(\sqrt a, \sqrt b)$ and $y=(\sqrt b, \sqrt a)$ to derive the AM-GM
inequality:




# Dataflow analysis using Grobner basis

This was a quick experiment in using Grobner basis to model situations. We
can represent our dataflow analysis constraints in terms of polynomial
rewrites over $F_2$.

Given the program:

```py
p = { 0: ["=", "x", 'y'],
      1: ['br', 2, 100],
      2: ['=', 'z', 'x'],
      3: ['br', 2],
      100: ['ret', 'z'] }
```

whose semantics I hope are fairly straightforward --- the dictionary represents
instruction locations. Instructions proceed sequentially. branch moves
control flow around. Note that `br` can branch to multiple locations,
since we are not control-flow sensitive.

The idea is that since in a dataflow analysis, we need information at
each variable at each program point, we can create a ring of polynomials
over $F_2$ for each variable at each program point. So in this case,
we wold need:

```
R = F_2[x0, y0, z0, x1, y1, z1, x2, y2, z2, x3, y3, z3, x100, y100, z100]
```

We then add elements into the ideal that represents our constraints.
For example, to perform dataflow analysis, we need to add constraints
about how if a variable `z` is alive, all variables that are used
to compute `z` at `100` are alive. This sets up equations that may
have cycles (in the case of loops).

These are usually resolved using the
[Kildall algorithm](https://en.wikipedia.org/wiki/Data-flow_analysis#An_iterative_algorithm).

However, we can also ask SAGE to kindly solve the Grobner basis. I hypothesize
that the "easy" dataflow problems out to be [toric ideals](https://hal.inria.fr/inria-00074446/document)
which admit much faster solutions.



# Fenwick trees and orbits

I learnt of a nice, formal way to prove the correctness of Fenwick
trees in terms of orbits that I wish to reproduce here.

One can use a Fenwick tree to perform cumulative sums
$Sum(n) \equiv \sum_{i=0}^n A[i]$, and updates $Upd(i, v) \equiv A[i] += v$. Naively,
cumulative sums can take $O(n)$ time and updates take $O(1)$ time.

A Fenwick tree can perform _both_ in $\log(n)$. In general, we can perform
any monoid-based catenation and update in $\log(n)$, **as long as our queries**
start from the 0th index till some index $n$. So we can only handle monoidal
fold queries of the form $\sum_{i=0}^n$ and point updates.

#### organization

We allow indexes $[1, 2, \dots n]$. The node with factorization $i \equiv 2^k \times l$,
$2 \not \vert l$ (that is, $k$ is the highest power of $2$ in $i$)
is responsible for the interval $[i-2^k+1, i] = (i-2^k, i]$.


I'm going to state all the manipulations in terms of prime factorizations,
since I find it far more intuitive than bit-fiddling. In general, I want
to find a new framework to discover and analyze bit-fiddling heavy algorithms.

Some examples of the range of responsibility of an index are:

- $1 = 2^0 \times 1 = (0, 1]$ (Subtract $2^0 = 1$)
- $2 = 2\times 1 = (0, 2]$ (Subtract $2^1 = 2$)
- $3 = 3 = (2, 3]$
- $4 = 2^2 = (0, 4]$
- $5 = 5 = (4, 5]$
- $6 = 2\times 3 = (4, 6]$
- $7 = 7 = (6,7]$
- $8 = 2^3 = (0,8]$
- $9 = 9 = (8, 9]$
- $10 = 2\times 5 = (8, 10]$
- $11 = 11 = (10, 11]$
- $12 = 2^2\times 3 = (8, 12]$
- $13 = 13 = (12, 13]$
- $14 = 2\times 7 = (12, 14]$
- $15 = 15 = (14, 15]$
- $16 = 2^4 = (0, 16]$

<img src="./static/fenwick-structure.gif">


#### query

To perform a cumulative sum, we need to read from the correct overlap regions
that cover the full array. For example, to read from $15$, we would want
to read:

- $a[15] = (14, 15], a[14] = (12, 14], a[12] = (8, 12], a[8] = (0, 8]$.

So we need to read the indices:
- $15=2^0 \cdot 15 \xrightarrow{-2^0} 14=2^1 \cdot 7 \xrightarrow{-2^1} 12=2^2\cdot3 \xrightarrow{-2^2} 8=2^3\cdot1 \xrightarrow{-2^3} 0$

At each  location, we strip off the value $2^r$. We can discover this value
with bit-fiddling: We claim that $a \& (-a) = 2^r$.

Let $a \equiv \langle x 1 0^r \rangle$. We wish to extract the output as $2^r = \langle 1 0^r \rangle$,
which is the power of 2 that we need to subtract from $a$ to strip the rightmost $1$.
We get:

$$
\begin{aligned}
&-a = \lnot a + 1 = x01^r + 1 = \overline{x}10^r \\
&a \& (-a) = a \& (\lnot a + 1) = (x 10^r) \& (\overline{x}10^r) = 0^{|\alpha|}10^r = 2^r
\end{aligned}
$$


$$
a - (a \& (-a)) = \langle x 1 0^r \rangle - \langle 1 0^r \rangle = \langle x 0 0^r \rangle
$$

That is, we successfully strip off the trailing $1$.
Armed with the theory, our implemtation becomes: 

```cpp
#define LSB(x) x&(-x)
int a[N];
int q(int i) {
    int s = 0;
    while (i > 0) { 
        s += a[i];
        i -= LSB(i); // strip off trailing 1.
    }
    return s;
}

```

#### update

To perform an update at $i$, we need to update all locations which on querying
overlap with $i$. For example, to update the location $9$, we would want to
update:

- $a[9] = (8, 9], a[10] = (8, 10], a[12] = (8, 12], a[16] = (0, 16]$.

So we need to update the indices:

- $9=2^0 \cdot 9 \xrightarrow{+2^0} 10=2^1 \cdot 5 \xrightarrow{+2^1} 12=2^2\cdot3 \xrightarrow{+2^2} 16=2^4\cdot1 \xrightarrow{+2^4} \dots$

We use the same bit-fiddling technique as above to strip off the value $2^r$


```cpp
#define LSB(x) x&(-x)
int tree[N];
int u(int i, int v) {
    while (i < N) { tree[i] += v; i += LSB(i); }
}
```


#### correctness

We wish to analyze the operations $Query(q) \equiv \sum_{i=1}^q a[i]$, and
$Update(i, val) \equiv a[i]~\texttt{+=}~val$. To do this, we are allowed to maintain
an auxiliary array $d$ which we will manipuate. We will stipulate the
conditions of operations on $d$ such that they will reflect the values of
$Query$ and $Update$, albeit much faster.

We will analyze the algorithm in terms of orbits. We have two operators, one
for update called $U$, and one for query called $Q$. Given an index $i$,
repeatedly applying the query operator gives us the indeces we need to read and
accumulate from the underlying array $a$ to get the total sum $a[0..i]$:

- $Query(i) = \sum_i d[Q^i(q)]$

Given an index $u$, repeatedly applying the update operator $U$ gives us all
the indeces we need to add the change to update:
- $Update(i, val) = \forall j~, d[U^j(i)]~\texttt{+=}~ val$

For query and update to work, we need the condition that:
- $q \geq u \iff \left\vert \{ Q^i(q)~:~ i \in \mathbb{N} \} \cap \{ U^i(u)~:~i \in \mathbb{N} \} \right\vert = 1$

That is, if and only if the query index $q$ includes the update location $u$,
will the orbits intersect.

The intuition is that we want updates at an index $u$ to only affect queries
that occur at indeces $q \geq u$. Hence, we axiomatise that for an update
to be legal, it must the orbits of queries that are at indeces greater than it.

We will show that our operators:
- $Q(i=2^r\cdot a) = i - 2^r = 2^r(a-1)$
- $U(j=2^s\cdot b) = j + 2^{s} = 2^{s}(b+1)$

do satisfy the conditions above.

For a quick numerical check, we can use the code blow to ensure
that the orbits are indeed disjoint:
```py
# calculate orbits of query and update in fenwick tree

def lsb(i): return i & (-i)
def U(i): return i + lsb(i)
def Q(i): return i - lsb(i)
def orbit(f, i):
    s = set()
    while i not in s and i > 0 and i < 64:
        s.add(i); i = f(i)
    return s

if __name__ == "__main__":
    for q in range(1, 16):
        for u in range(1, 16):
            qo = orbit(Q, q); uo = orbit(U, u)
            c = qo.intersection(uo)
            print("q:%4s | u:%4s | qo: %20s | uo: %20s | qu: %4s" %
                  (q, u, qo, uo, c))

        print("--")
```

##### Case 1: $q = u$

We note that $Q$ always decreases the value of $q$, and $u$ always increases
it. Hence, if $q = u$, they meet at this point, and
$\forall i, j \geq 1, \quad Q^i (q) \neq U^j(u)$.
Hence, they meet exactly once as required.

##### Case 2: $q < u$

As noted above, $q$ always decreases and $u$ always increases, hence in this
case they will never meet as required.


##### Case 3: $q > u$

Let the entire array have size $2^N$.
Let $q = \texttt{e1 f\_q}, u = \texttt{e0 f\_u}$, where
$\texttt{e, f\_q, f\_u}$ may be empty strings.

Notice that $Q$ will always strip away rightmost ones in $f_q$,
leading to $q = \texttt{e10...0}$ at some point.

Similarly, $U$ will keep on adding new rightmost ones, causing the
state to be $u = \texttt{e01...10...0} \xrightarrow{U} \texttt{e100...}$.

Hence, at some point $q = u$.

#### References

- [Fenwick trees on PolyMath](http://michaelnielsen.org/polymath1/index.php?title=Updating_partial_sums_with_Fenwick_tree)
- [Hacker's delight](https://doc.lagout.org/security/Hackers%20Delight.pdf)

# Dirichlet inversion

We call all functions $f: \mathbb Z \rightarrow \mathbb R$ as
_arithmetic functions_, since they operate on the integers.

We introduce an operator $f \star g: \mathbb Z \rightarrow \mathbb R$.
It is defined by:
- $(f \star g)(n) \equiv \sum_{d \vert n} f(d) g(n/d)$

We will show that the set of arithmetic functions forms a group
under the operator $\star$, with identity:

$$id_\star(n) \equiv \lfloor 1/n \rfloor = \begin{cases} 1 & n = 1 \\ 0 & \text{otherwise} \end{cases}$$


The reason all of this is interesting is that the inverse of the constant function $1(n) \equiv 1$
is going to be this function called as the mobius function $\mu$:

$$
\mu(n=p_1^{\alpha_1} p_2^{\alpha_2} \dots p_r^{\alpha_r}) \equiv
\begin{cases}
  0 & \text{if any $\alpha_i > 1$} \\
  (-1)^{\alpha_1 + \alpha_2 + \dots + \alpha_r} & \text{if all $\alpha_i \in \{ 0, 1 \}$}
\end{cases}
$$

The mobius function will allow us to perform _mobius inversion_:

$$
\begin{aligned}
  f(n) &\equiv \sum_{d \vert n} g(d) = \sum_{d \vert n} g(d) 1(n/d) = g \star 1 \\
  f \star 1^{-1} &=  g \star 1 \star 1^{-1} \\
  f \star \mu &= g
\end{aligned}
$$

That is, we originally had $f$ defined in terms of $g$. We can
recover an expression for $g$ in terms of $f$.

### The algebra of multiplicative functions

We claim that the set of functions $\{ \mathbb Z \rightarrow \mathbb C \}$
is a commutative group, with the group operation $\star$ such that:

- $(f \star g)(n) \equiv \sum_{d \vert n} f(d) g(n/d)$.

with the identity element being $id_\star(n) \equiv \lfloor 1 / n \rfloor$. The idea
is that if $(n = 1)$, then $\lfloor 1/1 \rfloor = 1$, and for any other
number $n > 0$, $1/n < 1$, hence $\lfloor 1/n \rfloor = 0$.

### verification of $istar$ being the identity
$$
\begin{aligned}
&(f \star id_\star)(n) \equiv \sum_{d \vert n} f(d) id_\star(n/d) \\
&= f(n) id_\star(1) + \sum_{d \vert n, d > 1} f(n) id_\star(d) \\
&= f(n) \cdot 1 + \sum_{d \vert n, d > 1} f(n) \cdot 0 \\
&= f(n) \\
\end{aligned}
$$

### associativity, commutativity of $\star$

To prove associativity, it's better to write the formula as:
$$
(f \star g)(n) \equiv \sum_{d \vert n} f(n) g(n/d) = \sum_{xy = n} f(x) g(y)
$$

From this rewrite, it's clear that $(f \star g \star h)(n)$ will unambiguously
sum over tripes $(x, y, z)$ such that $xyz = n$. I leave the working-this-out
to you. This should also make the commutativity immediate. Summing over pairs
of the form $f(x) g(y) : xy = n$ is the same as summing over $f(y) g(x) : yx = n$.



### Existence of inverse

We can show that an inverse exists by showing that a formula for it exists; The 
idea is to construct one by induction. 

Clearly, for a given function $f$, we need the inverse $f^{-1}$ to be such that
$(f \star f^{-1})(n) = id_\star$. Hence:

$$
\begin{aligned}
&(f \star f^{-1})(1) = id_\star(1) = 1 \\
&f(1) f^{-1}(1) = 1 \\
& f^{-1}(1) \equiv 1 / f(1)\\
\end{aligned}
$$

Great, we have a base case; We can now compute $f^{-1}(n)$ inductively, assuming
we know the value of $f^{-1}(d)$ for all $d \vert n$.

$$
\begin{aligned}
&(f \star f^{-1})(n) = id_\star(1) = 0 \\
&\sum_{d \vert n} f(d) f^{-1}(n/d) = 0 \\
&f(1) f^{-1}(n) + \sum_{d \vert n, d < n} f(d) f^{-1}(n/d) = 0 \\
&f^{-1}(n) = -\frac{\sum_{d \vert n, d < n} f(d) f^{-1}(n/d)}{f(1)} 
\end{aligned}
$$

### $\mu$ as the inverse of the $one$ function


### Mobius inversion

Now that we know that $\mu = \texttt{const 1}^{-1}$, we can use this fact
to perform _mobius inversion_:

$$
f(n) \equiv \sum_{d \vert n} g(n/d) = \texttt{const 1} \star g
$$

We have $f$ written in terms of $g$. We can now write $g$ in terms of $f$:

$$
\begin{aligned}
&f(n)  = \texttt{const 1} \star g \\
&f \star \texttt{const 1}^{-1} = g \\
&g = f \star \mu \\
&g = \sum_{d \vert n} f(d) \mu(n/d)
\end{aligned}
$$

### $n = \sum_{d \vert n} \phi(d)$

$$
\begin{array}{|c|c|c|c|}
d & \{ 1 \leq x \leq 12 : (x, 12) = d \} & \{ 1 \leq x \leq 12: (x/d, 12/d) = 1\} & \text{size of set} \\
1 & \{ 1, 5, 7, 11 \} & (x, 12) = 1 & 4 \\
2 & \{2, 10 \} & (x/2, 6) = 1& 2 \\
3 & \{3, 9 \} & (x/3, 4) = 1 & 2 \\
4 & \{4, 8 \} & (x/4, 3) = 1 & 2 \\
6 & \{ 6 \} & (x/6, 2) = 1 & 1 \\
12 & \{ 12 \} (x/12, 1) = 1 & 1
\end{array}
$$

Notice that the sizes of sets that we are calculating, for example,
$|\{ 1 \leq x \leq 12 : (x/2, 6) = 1 \}| =  \phi(6)$. Summing over all of
what we have, we've counted the numbers in $[1, 2, \dots, 12]$ in two ways ---
one directly, and the other by partitioning into equivalence classes:

$$ 12 = \phi(1) + \phi(2) + \phi(3) + \phi(4) + \phi(6) + \phi(12) = \sum_{d \vert 12} \phi(12/d) $$

In general, the same argument allows us to prove that:

$$ n = \sum_{d \vert n} n/d $$

### Using mobius inversion on the euler totient function


### Other arithmetical functions and their relations


# Incunabulum for the 21st century: Making the J interpreter compile in 2020

This is me trying to understand the fabled interpreter of the `J` language
working, so I could absorb Arthur Whitney's style of writing C: it's
cryptic, short, and fits in a page. [I learnt of this from the `J` language page](https://code.jsoftware.com/wiki/Essays/Incunabulum),
which comes with the quote:

> One summer weekend in 1989, Arthur Whitney visited Ken Iverson at Kiln Farm
> and produced—on one page and in one afternoon—an interpreter fragment on the
> AT&T 3B1 computer. I studied this interpreter for about a week for its
> organization and programming style; and on Sunday, August 27, 1989, at about
> four o'clock in the afternoon, wrote the first line of code that became the
> implementation described in this document.
> Arthur's one-page interpreter fragment is as follows:

#### The original source

```c
typedef char C;typedef long I;
typedef struct a{I t,r,d[3],p[2];}*A;
#define P printf
#define R return
#define V1(f) A f(w)A w;
#define V2(f) A f(a,w)A a,w;
#define DO(n,x) {I i=0,_n=(n);for(;i<_n;++i){x;}}
I *ma(n){R(I*)malloc(n*4);}mv(d,s,n)I *d,*s;{DO(n,d[i]=s[i]);}
tr(r,d)I *d;{I z=1;DO(r,z=z*d[i]);R z;}
A ga(t,r,d)I *d;{A z=(A)ma(5+tr(r,d));z->t=t,z->r=r,mv(z->d,d,r);
 R z;}
V1(iota){I n=*w->p;A z=ga(0,1,&n);DO(n,z->p[i]=i);R z;}
V2(plus){I r=w->r,*d=w->d,n=tr(r,d);A z=ga(0,r,d);
 DO(n,z->p[i]=a->p[i]+w->p[i]);R z;}
V2(from){I r=w->r-1,*d=w->d+1,n=tr(r,d);
 A z=ga(w->t,r,d);mv(z->p,w->p+(n**a->p),n);R z;}
V1(box){A z=ga(1,0,0);*z->p=(I)w;R z;}
V2(cat){I an=tr(a->r,a->d),wn=tr(w->r,w->d),n=an+wn;
 A z=ga(w->t,1,&n);mv(z->p,a->p,an);mv(z->p+an,w->p,wn);R z;}
V2(find){}
V2(rsh){I r=a->r?*a->d:1,n=tr(r,a->p),wn=tr(w->r,w->d);
 A z=ga(w->t,r,a->p);mv(z->p,w->p,wn=n>wn?wn:n);
 if(n-=wn)mv(z->p+wn,z->p,n);R z;}
V1(sha){A z=ga(0,1,&w->r);mv(z->p,w->d,w->r);R z;}
V1(id){R w;}V1(size){A z=ga(0,0,0);*z->p=w->r?*w->d:1;R z;}
pi(i){P("%d ",i);}nl(){P("\n");}
pr(w)A w;{I r=w->r,*d=w->d,n=tr(r,d);DO(r,pi(d[i]));nl();
 if(w->t)DO(n,P("< ");pr(w->p[i]))else DO(n,pi(w->p[i]));nl();}

C vt[]="+{~<#,";
A(*vd[])()={0,plus,from,find,0,rsh,cat},
 (*vm[])()={0,id,size,iota,box,sha,0};
I st[26]; qp(a){R  a>='a'&&a<='z';}qv(a){R a<'a';}
A ex(e)I *e;{I a=*e;
 if(qp(a)){if(e[1]=='=')R st[a-'a']=ex(e+2);a= st[ a-'a'];}
 R qv(a)?(*vm[a])(ex(e+1)):e[1]?(*vd[e[1]])(a,ex(e+2)):(A)a;}
noun(c){A z;if(c<'0'||c>'9')R 0;z=ga(0,0,0);*z->p=c-'0';R z;}
verb(c){I i=0;for(;vt[i];)if(vt[i++]==c)R i;R 0;}
I *wd(s)C *s;{I a,n=strlen(s),*e=ma(n+1);C c;
 DO(n,e[i]=(a=noun(c=s[i]))?a:(a=verb(c))?a:c);e[n]=0;R e;}

main(){C s[99];while(gets(s))pr(ex(wd(s)));}
```

It's a lot to take in --- it's quite breathtaking really, the way it all
hangs together in one page.

#### The attempt to get it run

Unfortunately, this does not work if we try to get it to run in 2020. I decided
to read the code and understand what would happen. I managed to read enough
to understand that the code `a=~3` ought to create an array with values `[0 1 2]`.
On attempting to _run_ this however, we get:

```
$ gcc -O0 -g -std=c89 -fsanitize=address -fsanitize=undefined incunabulum.c -o bin/incunabulum && ./bin/incunabulum
...
(many many GCC warnings elided)
...
a=~3
=================================================================
==23726==ERROR: AddressSanitizer: heap-buffer-overflow on address
  0x60300000eff0 at pc 0x000000402be3 bp 0x7ffe6dde6b70 sp 0x7ffe6dde6b60
WRITE of size 8 at 0x60300000eff0 thread T0
    #0 0x402be2 in wd /home/bollu/work/w/incunabulum.c:40
    #1 0x402d28 in main /home/bollu/work/w/incunabulum.c:42
    #2 0x7f7ae901082f in __libc_start_main (/lib/x86_64-linux-gnu/libc.so.6+0x2082f)
    #3 0x400ca8 in _start (/home/bollu/w/bin/incunabulum+0x400ca8)
...
SUMMARY: AddressSanitizer: heap-buffer-overflow /home/bollu/work/w/incunabulum.c:40 wd
...
==23726==ABORTING
```

oops! The code uses a lot of punning between `int`
and `int*`. These assumptions break now that we're in 64-bit. The patch to
get this to work is:

#### the patch

```diff
diff --git a/incunabulum.c b/incunabulum.c
index 2cae744..778e35a 100644
--- a/incunabulum.c
+++ b/incunabulum.c
@@ -1,11 +1,11 @@
-typedef char C;typedef long I;
+typedef char C;typedef long long I;
 typedef struct a{I t,r,d[3],p[2];}*A;
 #define P printf
 #define R return
 #define V1(f) A f(w)A w;
 #define V2(f) A f(a,w)A a,w;
 #define DO(n,x) {I i=0,_n=(n);for(;i<_n;++i){x;}}
-I *ma(n){R(I*)malloc(n*4);}mv(d,s,n)I *d,*s;{DO(n,d[i]=s[i]);}
+I *ma(n){R(I*)malloc(n*8);}mv(d,s,n)I *d,*s;{DO(n,d[i]=s[i]);}
 tr(r,d)I *d;{I z=1;DO(r,z=z*d[i]);R z;}
 A ga(t,r,d)I *d;{A z=(A)ma(5+tr(r,d));z->t=t,z->r=r,mv(z->d,d,r);
  R z;}
@@ -34,9 +34,10 @@ I st[26]; qp(a){R  a>='a'&&a<='z';}qv(a){R a<'a';}
 A ex(e)I *e;{I a=*e;
  if(qp(a)){if(e[1]=='=')R st[a-'a']=ex(e+2);a= st[ a-'a'];}
  R qv(a)?(*vm[a])(ex(e+1)):e[1]?(*vd[e[1]])(a,ex(e+2)):(A)a;}
-noun(c){A z;if(c<'0'||c>'9')R 0;z=ga(0,0,0);*z->p=c-'0';R z;}
-verb(c){I i=0;for(;vt[i];)if(vt[i++]==c)R i;R 0;}
+I noun(c){A z;if(c<'0'||c>'9')R 0;z=ga(0,0,0);*z->p=c-'0';R z;}
+I verb(c){I i=0;for(;vt[i];)if(vt[i++]==c)R i;R 0;}
 I *wd(s)C *s;{I a,n=strlen(s),*e=ma(n+1);C c;
  DO(n,e[i]=(a=noun(c=s[i]))?a:(a=verb(c))?a:c);e[n]=0;R e;}

 main(){C s[99];while(gets(s))pr(ex(wd(s)));}
+
```

#### It runs!

After applying the patch, we manage to get the interpreter to run!

```
./bin/incunabulum
a=~3
3
0 1 2
```

#### The lock screen

I liked it so much that I took a screenshot and made it my lock screen.

<img src="./static/screenshot-j-incunabulum.png">

#### Thoughts

I'm really fascinated by the code. I loved I could simply stare the screenshot
to absorb the code. There was no scrolling involved.  The variables are
well-named (to the extent I understand the code), and it's clearly extremely
well thought out. If there's someone who understands some of the thorny
aspects of the code:

- What is the `t` variable really tracking?
- How does one create a multi-dimensional array easily?
- What are some interesting programs one can run with this mini-interpreter?

I'd be really glad to know the details. Please leave 
[an issue or a pull request against the repo](https://github.com/bollu/bollu.github.io/issues/new).

I'm going write a dissection of the code once I fully understand it, since I
couldn't find explanaing the code on the internet.

Until then, enjoy the monolith of code!


# An example of a sequence whose successive terms get closer together but isn't Cauchy (does not converge)

#### The problem
Provide an example of a sequence $a_n: \mathbb N \rightarrow \mathbb R$
such that $\lim_{n \rightarrow \infty} \vert a_{n+1} - a_n \vert \rightarrow 0$,
but $\lim_{n, m \rightarrow \infty, m > n} |a_n - a_m| \neq 0$. That is,
proide a series where the distances between successive terms converges to zero,
but where distances between terms that are "farther apart than 1" does
not converge to 0. That is, the sequence is not _Cauchy_.

#### Regular solution: Harmonic numbers

The usual solution is to take the harmonic numbers,
$H_n \equiv \sum_{i=1}^n 1/i$. Then, we show that:

$$
\begin{aligned}
\lim_{n \rightarrow \infty} \left| H_{n+1} - H_n \right|
&= \left| \frac{1}{n+1} - \frac{1}{n} \right| \\
&= \frac{1}{(n+1)n} \rightarrow 0
\end{aligned}
$$

$$
\begin{aligned}
&\lim_{n \rightarrow \infty} \left| H_{2n} - H_n \right| \\
&= \left|\frac{1}{2n} - \frac{1}{n} \right| \\
&= \sum_{i=n+1}^{2n} \frac{1}{n+1} + \frac{1}{n+2} + \dots + \frac{1}{2n} \\
&\geq \sum_{i=n+1}^{2n} \frac{1}{2n} + \frac{1}{2n} + \dots + \frac{1}{2n} \\
&\geq \frac{n}{2n} = \frac{1}{2} \neq 0 \text{on} x \rightarrow \infty
\end{aligned}
$$


#### Memorable solution: logarithm

We can much more simply choose $a_n = \log(n)$. This yields the simple
calculation:

$$
\begin{aligned}
&\lim_{n \rightarrow \infty} a_{n+1} - a_n = \log(n+1) - \log(n) \\
&= \log((n+1)/n)) \\
&= \log(1 + 1/n) \xrightarrow{n \rightarrow \infty} \log(1) = 0
\end{aligned}
$$

while on the other hand,


$$
\begin{aligned}
\lim_{n \rightarrow \infty} a_{2n} - a_n 
= \log(2n) - \log(n)
= \log(2) + \log(n) - \log(n)
= \log 2 \neq 0
\end{aligned}
$$

I find this far cleaner conceptually, since it's "obvious" to everyone
that $a_n = \log(n)$ diverges, while the corresponding fact for $H_n$
is hardly convincing. We also get straightforward equalities everywhere,
instead of inequalities.

I still feel that I don't grok what precisely fails here, in that, my intuition
still feels that the local condition _ought_ to imply the Cauchy condition:
if $a_n$ tells $a_{n+1}$ to not be too far, and $a_{n+1}$ tells $a_{n+2}$,
surely this _must_ be transitive?

I have taught my instincts to not trust my instincts on analysis, which is a
shitty solution :) I hope to internalize this someday.

__EDIT:__ I feel I now understand what's precisely happening
after ruminating a bit.

The Cauchy convergence criterion allows us to drop a finite number
of terms, and then capture _everything after that point_ in a ball
of radius $\epsilon$. As $\epsilon$ shrinks, _all_ the terms in the
sequence are "squeezed togeher".

In the $a_{n+1} - a_n$ case, only successive terms must maintain
an $\epsilon$ distance. But as the $\log$ example shows, you can steadily
plod along, keeping $\epsilon$ ball next to $\epsilon$ ball, to reach:

$$
\lim_{n \rightarrow \infty} \lim_{\epsilon \rightarrow 0} f(n) \cdot \epsilon
$$
whose behaviour can do unexpected things depending on the choice of $n$.

# Krylov subspace method

<!-- https://www.youtube.com/watch?v=R9DHmkCE9oI -->

This is a class of methods used to solve $Ax = b$, where $A$ is sparse.
Krylov subspace methods are a class of methods which use the idea of a
Krylov subspace. There is conjugate gradient (CG), GMRES (Generalized minimal
residual method).

$$
K_m(A, v) \equiv span \{ v, Av, A^2v, \dots, A^m v\}
$$

Clearly, $K_m \subseteq K_{m+1}$, and there is a maximum $K_N$ that we can span
(the full vector space). We are interested in the smallest index $M$
such that $K_M = K_{M+1}$.

We notice that $K_M$ is invariant under the action of $A$.


Now, let's consider:
$$
\begin{aligned}
K_m(A, x) &\equiv span \{x, Ax, A^2x, \dots A^m x \} \\
        &= span \{ A^{-1} b, b, Ab, \dots A^{m-1} x \} \qquad \text{(substitute $x = A^{-1}b$)} \\
        &= A span \{ A^{-1} b, b, Ab, \dots A^{m-1} b\} \qquad \text{(Invariance of Krylov subspace)} \\
        &= span \{b, Ab, \dots A^m b\}  \\
        &= K_m(A, b)
\end{aligned}
$$

We learnt that $Ax = b$ has a solution in $K_m(A, b)$. Using this, we can build
solvers that exploit the Krylov subspace. We will describe GMRES and CG.

## Generalized minimal residual --- GMRES

We wish to solve $Ax = b$ where $A$ is sparse and $b$ is normalized. The $n$th
Krylov subspace is $K_n(A, b) \equiv span~\{b, Ab, A^2b, \dots, A^nb  \}$.

We approximate the actual solution with a vector $x_n \in K_n(A, b)$. We
define the _residual_ as $r_n \equiv A x_n - b$.

## Conjugate gradient descent

# Good reference to the Rete pattern matching algorithm

The [Rete pattern matching algorithm](https://en.wikipedia.org/wiki/Rete_algorithm)
is an algorithm that allows matching a huge number of rules with a huge database
of "facts".

MLIR ("multi-language intermediate representation") is a new technology that
hopes to centralize much of the research and development of various compilers
into a single authoritative source. The major claim-to-fame is that it allows
one to mix various "dialects" (much as Racket does). So, to a first order
approximation, MLIR is "JSON for compiler intermediate representations".

What MLIR gets right is _tooling_. They take the experience that the LLVM project
has mined for the last decade and a half, and bake many of the good stuff that
came with LLVM right in. For example, MLIR comes in-built with a pretty printer,
a notion of types, a notion of "attributes", SSA, enforced provenance
tracking of code (so one can _always_ know what the original source code was
that led to some assembly). Sound engineering might see MLIR succeed where
many others failed.

I was reminded of Rete since the MLIR folks are trying to solve the pattern
matching problem in general for their [Generic DAG Rewriter](https://mlir.llvm.org/docs/GenericDAGRewriter/).

They currently just use a worklist based algorithm. I'm trying to understand
if Rete can be used instead. Rete is famous for being hard to understand,
so I began a quest to look for good sources to implement it. I found a great
[PhD thesis written by Robert B. Doorenboos](http://reports-archive.adm.cs.cmu.edu/anon/1995/CMU-CS-95-113.pdf),
which quips:

> Since the Rete match algorithm provides the starting point for much of the work in this thesis,
> this chapter describes Rete. Unfortunately, most of the descriptions of Rete in the literature
> are not particularly lucid,1 which is perhaps why Rete has acquired \a reputation for extreme
> differentialculty."(Perlin, 1990b) To remedy this situation, this chapter describes Rete in a tutorial
> style, rather than just briey reviewing it and referring the reader to the literature for a full
> description. We will first give an overview of Rete, and then discuss the principle data structures
> and procedures commonly used to implement it. High-level pseudocode will be given for many
> of the structures and procedures, so that this chapter may serve as a guide to readers who want
> to implement rete (or some variant) in their own systems.

I now have a reference to an accessible description of this stuff. I might
implement Rete to understand it, so that it's part of my toolkit if I ever
need it.

# Leapfrog Integration

We have a system we wish to simulate using hamilton's equations:

$$
\begin{aligned}
\frac{\partial q}{\partial t} = \frac{\partial H}{\partial p}|_{(p_0, q_0)} \\
\frac{\partial p}{\partial t} = -\frac{\partial H}{\partial q}|_{(p_0, q_0)} \\
\end{aligned}
$$

We want to simulate a system using these differential equations. We will begin
with some initial position and momentum $(q_0, p_0)$, evaluate
$\frac{\partial q}{\partial t} \rvert_{(q_0, p_0)}$, $\frac{\partial p}{\partial t} \rvert_{(q_0, p_0)}$, and use
these to find $(q_{next}, p_{next})$. An integrator is a general algorithm
that produces the next position and momentum using current information:

$$
(q_{next}, p_{next}) =
  I \left(q_0,
    p_0,
    \frac{\partial q}{\partial t}\rvert_{(q_0, p_0)},
    \frac{\partial p}{\partial t}\rvert_{(q_0, p_0)} \right)
$$

The design of $I$ is crucial: different choices of $I$ will have different
trade-offs for accuracy and performance. Another interesting property
we might want is for $I$ to be a _symplectic integrator_ --- that is,
it preserves the total energy of the system. For example, here's a plot
of the orbits of planets using two integrators, one that's symplectic (leapfrog)
and one that isn't (Euler)


<img src="./static/leapfrog-vs-euler.png">

Notice that since leapfrog attempts to keep energy conserved, the orbits stay
as orbits! On the other hand, the euler integrator quickly spirals out, since
we lose energy during the integration. Note that this is 
_not an issue of numerical precision_: The euler integrator is ineherently 
such that over long timescales, it will lose energy. On the other hand, the
leapfrog integrator will _always remain stable_, even with very large timesteps
and low precision.

I present the equations of the leapfrog integrator, a proof sketch that it
is symplectic, and the code listing that was used to generate the above plot.
Often, code makes most ideas very clear!

#### The integrator


#### Code listing

##### Incantations
```py
# Run HMC with a particular choice of potential
import numpy as np
from matplotlib.animation import FuncAnimation
import matplotlib.pyplot as plt
import numpy.linalg
```

```py
# dq/dt = dH/dp|_{p0, q0}
# dp/dt = -dH/dq|_{p0, q0}
def leapfrog(dhdp, dhdq, q0, p0, dt):
    p0 += -dhdq(q0, p0) * 0.5 * dt

    # full step position
    # q += dt * p
    q0 += dhdp(q0, p0) * dt

    # half step position
    p0 += -dhdq(q0, p0) * 0.5 * dt
    return (q0, p0)
```

For reference, we also implement an euler integrator, that uses the derivative
to compute the position and momentum of the next timestep independently.

```py
def euler(dhdp, dhdq, q, p, dt):
    pnew = p + -dhdq(q, p) * dt
    qnew = q + dhdp(q, p) * dt
    return (qnew, pnew)
```


Finally, we implement `planet(integrator, n, dt)` which simulates gravitational
potential and usual kinetic energy, using the integrator given by `integrator`
for `n` steps, with each timestep taking `dt`.

```py
def planet(integrator, n, dt):
    STRENGTH = 0.5

    # minimise potential V(q): q, K(p, q) p^2
    q = np.array([0.0, 1.0])
    p = np.array([-1.0, 0.0])

    # H = STRENGTH * |q| (potential) + p^2/2 (kinetic)
    def H(qcur, pcur): return STRENGTH * np.linalg.norm(q) + np.dot(p, p) / 2
    def dhdp(qcur, pcur): return p
    def dhdq(qcur, pcur): return STRENGTH * 2 * q / np.linalg.norm(q)

    qs = []
    for i in range(n):
        print("q: %10s | p: %10s | H: %6.4f" % (q, p, H(q, p)))
        (q, p) = integrator(dhdp, dhdq, q, p, dt)
        qs.append(q.copy())
    return np.asarray(qs)
```


We plot the simulations using `matplotlib` and save them.
```py
NITERS = 15
TIMESTEP = 1

print("planet simulation with leapfrog")
planet_leapfrog = planet(leapfrog, NITERS, TIMESTEP)

plt.rcParams.update({'font.size': 12, 'font.family':'monospace'})
fig, ax = plt.subplots()
print(planet_leapfrog)
ax.plot(planet_leapfrog[:, 0], planet_leapfrog[:, 1], label='leapfrog',
        linewidth=3, color='#00ACC1')
print("planet simulation with euler")
planet_euler = planet(euler, NITERS, TIMESTEP)
ax.plot(planet_euler[:, 0], planet_euler[:, 1], label='euler',
        linewidth=3, color='#D81B60')

legend = plt.legend(frameon=False)
ax.set_title("leapfrog v/s euler: NITERS=%s dt=%s" % (NITERS, TIMESTEP))
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
plt.savefig("leapfrog-vs-euler.png")
plt.show()
```

# Comparison of forward and reverse mode AD

Quite a lot of ink has been spilt on this topic. My favourite reference
is the one by [Rufflewind](https://rufflewind.com/2016-12-30/reverse-mode-automatic-differentiation).

However, none of these examples have a good stock of examples for the diference.
So here, I catalogue the explicit computations between computing forward
mode AD and reverse mode AD.

In general, in forward mode AD, we fix how much the inputs wiggle with
respect to a parameter $t$. We figure out how much the output wiggles
with respect to $t$. If $output = f(input_1, input_2, \dots input_n)$,
then $\frac{\partial output}{\partial t} = \sum_i \frac{\partial f}{\partial input_i} \frac{\partial input_i}{\partial dt}$.

In reverse mode AD, we fix how much the parameter $t$ wiggles with
respect to the output. We figure out how much the parameter $t$
wiggles with respect to the inputs.
If $output_i = f_i(input, \dots)$, then $\frac{\partial t}{\partial input} = \sum_i \frac{\partial t}{\partial output_i} \frac{\partial f_i}{input}$.
This is a much messier expression, since we need to accumulate the data
over all outputs.

Essentially, deriving output from input is easy, since how to compute an output
from an input is documented in one place. deriving input from output is
annoying, since many outputs can depent on a single output.

The upshot is that if we have few "root outputs" (like a loss function),
we need to run AD once with respect to this, and we will get the wiggles
of _all inputs_ at the same time with respect to this output, since we
compute the wiggles output to input.

The first example of `z = max(x, y)` captures the essential difference
between the two approached succinctly. Study this, and everything else will make
sense.


#### Maximum: `z = max(x, y)`


- Forward mode equations:

$$
\begin{aligned}
z &= max(x, y) \\
\frac{\partial x}{\partial t} &= ? \\
\frac{\partial y}{\partial t} &= ? \\
\frac{\partial z}{\partial t}
  &= \begin{cases}
        \frac{\partial x}{\partial t} & \text{if $x > y$} \\
        \frac{\partial y}{\partial t} & \text{otherwise} \\
    \end{cases}
\end{aligned}
$$

We can compute $\frac{\partial z}{\partial x}$ by setting $t = x$.
That is, $\frac{\partial x}{\partial t} = 1, \frac{\partial y}{\partial t} = 0$.
Similarly, can compute $\frac{\partial z}{\partial y}$ by setting $t = y$.
That is, $\frac{\partial x}{\partial t} = 1, \frac{\partial y}{\partial t} = 0$.
If we want both gradients $\frac{\partial z}{\partial x}, \frac{\partial z}{\partial y}$,
we will have to **rerun the above equations twice** with the two initializations.

In our equations, we are saying that we know how sensitive
the inputs $x, y$ are to a given parameter $t$. We are deriving how sensitive
the output $z$ is to the parameter $t$ as a composition of $x, y$. If
$x > y$, then we know that $z$ is as sensitive to $t$ as $x$ is.


- Reverse mode equations:

$$
\begin{aligned}
z &= max(x, y) \\
\frac{\partial t}{\partial z} &= ? \\
\frac{\partial t}{\partial x}
  &= \begin{cases}
    \frac{\partial t}{\partial z} & \text{$if x > y$} \\
    0 & \text{otherwise}
  \end{cases} \\
\frac{\partial t}{\partial y}
  &= \begin{cases}
    \frac{\partial t}{\partial z} & \text{$if y > x$} \\
    0 & \text{otherwise}
  \end{cases}
\end{aligned}
$$

We can compute $\frac{\partial z}{\partial x}, \frac{\partial z}{\partial y}$
**in one shot** by setting $t = z$. That is, $\frac{\partial z}{\partial t} = 1$.

In our equations, we are saying that we know how sensitive
the parameter $t$ is to a given output $z$. We are trying to see
how sensitive $t$ is to the inputs $x, y$. If $x$ is active (ie, $x > y$),
then $t$ is indeed sensitive to $x$ and $\frac{\partial t}{\partial x} = 1$.
Otherwise, it is not sensitive, and $\frac{\partial t}{\partial x} = 0$.


#### sin: `z = sin(x)`

- Forward mode equations:

$$
\begin{aligned}
z &= sin(x) \\
\frac{\partial x}{\partial t} &= ? \\
\frac{\partial z}{\partial t}
  &= \frac{\partial z}{\partial x} \frac{\partial x}{\partial t} \\
  &= cos(x) \frac{\partial x}{\partial t}
\end{aligned}
$$

We can compute $\frac{\partial z}{\partial x}$ by setting $t = x$.
That is, setting $\frac{\partial x}{\partial t} = 1$.

- Reverse mode equations:

$$
\begin{aligned}
z &= sin(x) \\
\frac{\partial t}{\partial z} &= ? \\
\frac{\partial t}{\partial x}
  &= \frac{\partial t}{\partial z} \frac{\partial z}{\partial x} \\
  &= \frac{\partial t}{\partial z} cos(x)
\end{aligned}
$$


We can compute $\frac{\partial z}{\partial x}$ by setting $t = z$.
That is, setting $\frac{\partial z}{\partial t} = 1$.

#### addition: `z = x + y`:

- Forward mode equations:

$$
\begin{aligned}
z &= x + y \\
\frac{\partial x}{\partial t} &= ? \\
\frac{\partial y}{\partial t} &= ? \\
\frac{\partial z}{\partial t}
  &= \frac{\partial z}{\partial x} \frac{\partial x}{\partial t} +
    \frac{\partial z}{\partial y} \frac{\partial y}{\partial t} \\
  &= 1 \cdot \frac{\partial x}{\partial t} + 1 \cdot \frac{\partial y}{\partial t}
  = \frac{\partial x}{\partial t} + \frac{\partial y}{\partial t}
\end{aligned}
$$


- Reverse mode equations:

$$
\begin{aligned}
z &= x + y \\
\frac{\partial t}{\partial z} &= ? \\
\frac{\partial t}{\partial x}
  &= \frac{\partial t}{\partial z} \frac{\partial z}{\partial x} \\
  &= \frac{\partial t}{\partial z} \cdot 1 = \frac{\partial t}{\partial z} \\
\frac{\partial t}{\partial y}
  &= \frac{\partial t}{\partial z} \frac{\partial z}{\partial y} \\
  &= \frac{\partial t}{\partial z} \cdot 1 = \frac{\partial t}{\partial z}
\end{aligned}
$$


#### multiplication: `z = xy`

- Forward mode equations:

$$
\begin{aligned}
z &= x y \\
\frac{\partial x}{\partial t} &= ? \\
\frac{\partial y}{\partial t} &= ? \\
\frac{\partial z}{\partial t}
  &= \frac{\partial z}{\partial x} \frac{\partial x}{\partial t} +
    \frac{\partial z}{\partial y} \frac{\partial y}{\partial t} \\
  &= y \frac{\partial x}{\partial t} + x \frac{\partial y}{\partial t}
\end{aligned}
$$

- Reverse mode equations:

$$
\begin{aligned}
z &= x y \\
\frac{\partial t}{\partial z} &= ? \\
\frac{\partial t}{\partial x}
  &= \frac{\partial t}{\partial z} \frac{\partial z}{\partial x}
  = \frac{\partial t}{\partial z} \cdot y \\
\frac{\partial t}{\partial y}
  &= \frac{\partial t}{\partial z} \frac{\partial z}{\partial y}
  = \frac{\partial t}{\partial z} \cdot x
\end{aligned}
$$


#### subtraction: `z = x - y`:

- Forward mode equations:

$$
\begin{aligned}
z &= x + y \\
\frac{\partial x}{\partial t} &= ? \\
\frac{\partial y}{\partial t} &= ? \\
\frac{\partial z}{\partial t}
  &= \frac{\partial z}{\partial x} \frac{\partial x}{\partial t} -
    \frac{\partial z}{\partial y} \frac{\partial y}{\partial t} \\
  &= 1 \cdot \frac{\partial x}{\partial t} - 1 \cdot \frac{\partial y}{\partial t}
  = \frac{\partial x}{\partial t} - \frac{\partial y}{\partial t}
\end{aligned}
$$

- Reverse mode equations:

$$
\begin{aligned}
z &= x - y \\
\frac{\partial t}{\partial z} &= ? \\
\frac{\partial t}{\partial x}
  &= \frac{\partial t}{\partial z} \frac{\partial z}{\partial x} \\
  &= \frac{\partial t}{\partial z} \cdot 1 = \frac{\partial t}{\partial z} \\
\frac{\partial t}{\partial y}
  &= \frac{\partial t}{\partial z} \frac{\partial z}{\partial y} \\
  &= \frac{\partial t}{\partial z} \cdot -1 = -\frac{\partial t}{\partial z}
\end{aligned}
$$


# An invitation to homology and cohomology, Part 1 --- Homology

There are many introductions to homology on the internet, but none of them
really met my criteria for being simple, picture filled, and getting the
basic ideas across. I feel that Hatcher might come closest to what I want
(and where I originally learnt the material), but their description of homology
is surrounded by the context of Algebraic Topology, while really, simplicial
homology is accessible to anyone who has seen some linear algebra and group
theory. This is my attempt to get the ideas across.

Let's first try to understand what we're trying to do here. We want to detect
holes in a space, broadly construed. We focus in _simplicial complexes_, which
are collections of triangles and triangle-like objects in higher (and lower)
dimensions. We define what holes are for these simplicial complexes, and we then
try to find algebraic objects that allow us to "detect" these holes.

### Simplices

- A 0-simplex is a point

```
*
```

- A 1-simplex is a line

```
*===*
```

- A 2-simplex is a filled triangle

```
   *
  / \
 *---*
```

- A $k$-dimensional simplex is the convex hull of $k+1$
  linearly independent points $(u_i \in \mathbb R^{k+1})$
  in $k+1$ dimensional space.  

$$S_k \equiv \left \{ \sum \theta_i u_i ~\mid~ \theta_i \geq 0, ~ \sum_i \theta_i = 1 \right \} $$

### Simplicial complexes

A simplicial complex $K$ is a collection of simplices where:
- (1) Every boundary of a simplex from $K$ is in $K$
- (2) The intersection of any two simplices in $K$ is also in $K$

Examples of simplicial complexes:

- Every simplex is trivially a simplicial complex.

<img src="static/simplices/complex-0-simplices.svg" width="50">
- A collection of points is a simplicial complex with all simplices of degree $0$.

<img src="static/simplices/complex-unfilled-triangle.svg" width="50">
- An unfilled triangle is a simplicial complex with simplices of degree $0$, $1$.

<img src="static/simplices/complex-unfilled-butterfly.svg" width="50">
- Non-triangular shapes such  as this "butterfly" are also simplicial complexes,
  this one of degree $0$, $1$.

<img src="static/simplices/complex-half-filled-butterfly.svg" width="50">
- This is the same shape as the unfilled butterly, except now containing a
  simplex of degree 2: the filling in of the bottom of the butterfly.


Non-examples of simplicial complexes are:

<img src="static/simplices/non-simplex-1.svg" width="50">
- This does not contain the point at the lower-left corner, which should exist
  since it is a boundary of the straight line. This violates rule (1):
  Every boundary of a simplex from $K$ is in $K$


<img src="static/simplices/non-simplex-2.svg" width="50">
- This does not contain the points which are at the intersection of the
  triangle and the line. This violates rule (2):
  The intersection of any two simplices in $K$ is also in $K$.

### Holes in a space: Homology of a triangle

Let's consider the simplest possible case of computing the homlogy, and we
do so, we will expand on what homology _is_, and what we're trying to do.

<img src="static/simplices/homology-triangle-edges.svg">

Look at the triangle above. We have the red, green, and blue vertices, which
I'll notate $r, g, b$. We also have the edges that are orange ($o$), cyan ($c$), and
magenta ($m$).

What we are interested in doing is to be able to detect the "hole" in the
triangle in between the edges `o-m-c`. That is, we want some algorithm which
when offered the representation of the triangle, can somehow detect the hole.
Note that the hole doesn't really depend on the length of the edges. We can
"bend and stretch" the triangle, and the hole will still exist. The only way
to destroy the hole is to either _cut_ the triangle, or _fill in_ the triangle.

We first need to agree on an abstract _representation_ of the triangle,
which ideally does not change if we were to stretch out the edges,
before we can discuss how we can detect the existence of the hole.

##### Representation of the triangle: boundary operators

We first describe the shape of the triangle in terms
of two sets, $E$ and $V$ representing the edges and the vertices, and
a function $\partial_{EV}$, called as the
boundary operator, which tells us how edges
are glued to vertices.

We first have a ground set of edges $E \equiv \\{o, m, c\\}$ and a set of
vertices $V \equiv \\{r, g, b \\}$.

What we now need is to know how the edges are connected to the vertices,
since that's what really makes a triangle. We would like to say something
like "the boundary of the edge $o$ has points $r, g$". In fact, we have
slightly more information than that: the _orientation_. So what we
really ought to be saying is "the edge $o$ points from $g$ to $r$".

To do this, we create a map from $o$ to $r - g$, where we think of $o$
as a "vector", pointing from $g$ to $r$. But hang on, what _is_ $r - g$?
we don't have a mathematical structure on $V$ that lets us add and subtract
vertices. So, we _create_ a new set $\mathcal V$, which represents linear
combinations of vertices in $V$. Similarly, anticipating some future
development, we also _create_ a new set $\mathcal E$ of linear combinations
of edges $E$.

##### Formal definition of the boundary operator

We define $\mathcal E \equiv \mathbb Z \times \mathbb Z \times \mathbb Z$
that represents linear combinations of edges. For example, $(1, 2, 3) \in \mathcal E$
represents $o + 2m + 3c$ --- that is, take 1 copy of the orange edge, 2
copies of the magenta edge, and 3 copies of the cyan edge.

We define $\mathcal V \equiv \mathbb Z \times \mathbb Z \times \mathbb Z$
which represents linear combinations of vertices. For example,
$(1, -1, 2) \in V$ represents $r - g + 2b$ --- that is, take a copy of the
red vertex, subtract the green vertex, and add two copies of the blue vertex.

The boundary operator $\partial_{EV}: \mathcal{E} \rightarrow \mathcal V$ is
depicted in the picture. This operator sends edges to their _boundary_, and is
therefore called the _boundary operator_.  The _boundary_ of an edge describes
the edge in terms of vertices, just like we would describe a direction vector
(to borrow physics parlance) by subtracting points.

The action of the operator on a linear combination of edges is:

$$
\begin{aligned}
&\partial_{EV}: \mathcal E \rightarrow \mathcal V \\
&\partial_{EV}(1, 0, 0) \equiv (1, -1, 0) \qquad o \mapsto r - g \\
&\partial_{EV}(0, 1, 0) \equiv (-1, 0, 1) \qquad m \mapsto b - r \\
&\partial_{EV}(0, 0, 1) \equiv (0, 1, -1) \qquad c \mapsto b - g \\
&\text{(Extend using linearity)} \\
&\partial_{EV}(s, t, u) \equiv
  s \partial_{EV}(1, 0, 0) +
  t \partial_{EV}(0, 1, 0) +
  u \partial_{EV}(0, 0, 1) = (s - t, u - s, t - u)
\end{aligned}
$$

Now, notice that to traverse the cycle, we should traverse the orange edge,
then the magenta edge, then the cyan edge, in that direction. That is,
the cycle can be thought of as $o + m + c$. However, how do we _detect_ this
cycle? The key idea is that if we look at the
_image of the cycle $o + m + c$ under the boundary operator_ $\partial_{EV}$,
we will get $0$! For us to have completed a cycle, we must have both
entered and exited each vertex, so the total sum must be $0$.

Formally:

$$
\begin{aligned}
  &\partial_{EV}(s, t, u) \equiv (s - t, u - s, t - u) \\
  &o + m + c = (1, 1, 1) \in \mathcal E \quad
  \partial_{EV}((1, 1, 1) = (1 - 1, 1 - 1, 1 - 1) = (0, 0, 0)
\end{aligned}
$$

##### Formal definition of cycles

This is very nice, since we have converted the topological invariant
of a _hole in the space_ into an algebraic invariant of "linear combination
of edges that map to 0". That is, we want to consider all thoose loops
that belong to the _kernel_ of $\partial_{EV}$. (Terminology:
the kernel of a linear transformation is the set of all things in the domain
which map to zero)

So, we define (tentatively) the first homology group:

$$
\begin{aligned}
H_1 \equiv Kernel(\partial_{EV}) \equiv
\left \{ (a, b, c) \in \mathcal E \mid \partial_EV((a, b, c)) = (0, 0, 0) \right \}
\subset \mathcal E
\end{aligned}
$$

If we try to compute this, we will have to have:

$$
\begin{aligned}
H_1 &\equiv Kernel(\partial_{EV}) \\
&= \{ (s, t, u) ~\mid~ \partial_{EV}(s, t, u) = (0, 0, 0) ~ s, t, u \in \mathbb Z \} \\
&= \{ (s, t, u) ~\mid~ (s-t, u-s, t-u) = (0, 0, 0) ~ s, t, u \in \mathbb Z  \} \\
&= \{ (s, t, u) ~\mid~ s = t = u \quad s, t, u \in \mathbb Z \} \\
&= \{ (x, x, x) ~\mid~ x \in \mathbb Z \} \simeq \mathbb Z
\end{aligned}
$$

So, we know that we have a $\mathbb Z$ worth of cycles in our triangle, which
makes sense: We can go clockwise (positive numbers)
and counter-clockwise (negative numbers) around the triangle,
and we can go as many times as we wish, so we have $\mathbb Z$ as the
number of cycles.

that is, it's the linear combination of edges that map to zero through the
boundary map. Note that this also includes combinations such as _two_ loops
around the triangle, such as $o + m + c + o + m + c$.

### (No) Holes in a space: Homology of a _filled_ triangle

<img src="static/simplices/homology-triangle-faces.svg">

In this case, notice that the triangle is _filled_ with a face $f$.
Therefore, the "hole" that we had previously is now filled up, and does not
count anymore. So, we now need to amend our previous definition of $H_1$ to
kill the hole we had detected.

The idea is that the hole we had previously is now the
_boundary of the new face $f$_.
Since it is the boundary of a "filled in" region, it does not count anymore,
since we can "shrink the hole" across the face to make it a non-loop.
Hence, we need to quotient our $H_1$ with the boundary of the face.

Formally, what we do is we create another group $\mathcal F \equiv \mathbb Z$,
which counts copies of our face $f$, and we define another boundary operator,
such that the boundary of the face $f$ is $o + m + c$.

$$
\begin{aligned}
&\partial_{FE} : \mathcal F \rightarrow \mathcal E \\
&\partial_{FE}(1) \equiv (1, 1, 1)  \\
&\text{(Extend using linearity)} \\
&\partial_{FE}(c) \equiv c \partial(1) = (c, c, c)
\end{aligned}
$$

Now, we should notice that the _image_ of $\partial_{FE}$ is a loop
$(o + m + c)$, which lies ie the _kernel_ of $\partial_{EV}$. This is a
general feature of homology, so it bears repeating:

- $Image(\partial_{FE}) \subset Kernel(\partial_{EV})$
- $\partial_{FE} \circ \partial_{EV} = 0$
- The above equation is sometimes stylishly (somewhat misleadingly) written as
  $\partial^2 = 0$. More faithfully, one can write $\partial_{EV} \circ \partial_{FE} = 0$.

Now, since the image of $\partial_{FE}$ lies entirely in the kernel of $\partial_{EV}$,
we can construct $H_1$ as:

- $H_1 \equiv Kernel(\partial_{EV}) / Image(\partial_{FE}) \subset E$




# An invitation to homology and cohomology, Part 2 --- Cohomology

<!--
f is closed <=> df = 0
f is exact <=> f = dg
-->

<img src="static/simplices/cohomology-triangle-vertices.svg">

Once again, we have our humble triangle with vertices $V = \{r, g, b\}$,
edges $E = \{o, m, c \}$, faces $F = \{ f \}$ with boundary maps $\partial_{EV}$,
$\partial_{FE}$:

- $\partial_{FE}(f)= o + m + c$
- $\partial_{EV}(o) = r - g$
- $\partial_{EV}(m) = b - r$
- $\partial_{EV}(c)= g - b$

We define a function $h_v: V \rightarrow \mathbb R$ on the vertices as:
-  $h_v(r) = 3$, $h_v(g) = 4$, $h_v(b) = 10$.

We now learn how to _extend_ this function to the higher dimensional objects,
the edges and the faces of the triangle.

To extend this function to the edges, we define a new function:

- $h_e: E \rightarrow R$
- $h_e(e) \equiv \sum_i \alpha_i h_v(v_i)$ where $\partial_{EV} e = \sum_i \alpha_i v_i$

Expanded out on the example, we evaluate $h_v$ as:

- $h_e(o) \equiv d h_v(o)  = h_v(r) - h_v(g) = 3 - 4 = -1$
- $h_e(m) \equiv d h_v(m)  = h_v(b) - h_v(r) = 10 - 3 = +7$
- $h_e(c) \equiv d h_v(c)  = h_v(g) - h_v(b) = 4 - 10 = -6$

More conceptually, we have created an _operator_ called $d$ (the **coboundary operator**)
which takes functions defined on vertices to functions defined on edges. This
uses the boundary map on the edges to "lift" a function on the vertices to a
function on the edges.  It does so by assigning the "potential difference" of
the vertices to the edges.


- $d: (V \rightarrow \mathbb R) \rightarrow (E \rightarrow \mathbb R)$
- $d(h_v) \equiv h_e$, $h_e(e) \equiv \sum_i \alpha_i f(v_i)$ where $\partial_{EV} e = \sum_i \alpha_i v_i$


We can repeat the construction we performed above, to construct another operator
$d : (E \rightarrow \mathbb R) \rightarrow (F \rightarrow \mathbb R)$, defined
in _exactly the same way_ as we did before. For example, we can evaluate:

- $h_f \equiv d(h_e)$
- $h_f(f) \equiv d h_e(f) = h_e(o) + h_e(m) + h_e(c) = -1 + 7 -6 = 0$

What we have is a chain:

- $h_v \xrightarrow{d} h_e \xrightarrow{d} h_f$

Where we notice that $d^2 = d \circ d = 0$, since the function $h_f$ that we have gotten
evaluates to zero on the face $f$. We can prove this will happen _in general_,
for any choice of $h_v$.
(it's a good exercise in definition chasing).


Introducing some terminology, A differential form $f$ is said to be a **closed differential form**
iff $df = 0$.

In our case, $h_e$ **is closed**, since $d h_e = h_f = 0$. On the other hand
$h_v$ is **not closed**, since $d h_v = h_e \neq 0$.

The intuition for why this is called "closed" is that its coboundary vanishes.

## Exploring the structure of functions defined on the edges

Here, we try to understand what functions defined on the edges can look like,
and their relationship with the $d$ operator. We discover that there are
some functions $g_e: E \rightarrow \mathbb R$ which can be realised as the differential
of another function $g_v: V \rightarrow \mathbb R$. The differential
forms such as $g_e$ which can be generated a $g_v$ through the $d$ operator
are called as **exact differential forms**. That is, $g_e = d g_v$ _exactly_,
such that there is no "remainder term" on applying the $d$ operator.

<img src="static/simplices/cohomology-triangle-edges.svg">

We take an example of a differential form that is _not exact_, which has been
defined on the edges of the triangle above. Let's call it $h_e$.

It is defined on the edges as:
- $h_e(c) = 3$
- $h_e(m) = 2$
- $h_e(o) = 1$

We can calcuate $h_f = d h_e$ the same way we had before:
- $h_f(f) \equiv d h_e(f) = h_e(o) + h_e(m) + h_e(c) = 3 + 1 + 2 = 6$.

Since $d h_e \neq 0$, this form is not exact.

Let's also try to generate $h_e$ from a potential. We arbitrarily fix the
potential of $b$ to $0$. That is, we fix $h_v(b) = 0$, and we then try to
see what values we are forced to values of $h_v$ across the rest of the triangle.

- $h_v b = 0$
- $h_e(c) = h_v(g) - h_v(b)$. $h_v(g) =  h_v(b) + h_e(c) = 0 + 3 = 3$.
- $h_e(o) = h_v(r) - h_v(g)$. $h_v(r) =  h_v(g) + h_e(o) = 3 + 1 = 4$.
- $h_e(m) = h_v(b) - h_v(r)$ $2 = 0 - 4$. This is a contradiction!
- Ideally, we need $h_v(b) = 6$ for the values to work out.


Hence, there can exist no such $h_v$ such that $h_e \equiv d h_v$.
The interesting thing is, when we started out by assigning $h_v(b) = 0$,
we could make _local choices_ of potentials that seemed like they would fit
together, but they failed to fit _globally_ throughout the triangle. This
failure of _locally consistent choices_ to be _globally consistent_ is
the essence of cohomology.

## Cohomology of half-filled butterfly

<img  src="static/simplices/cohomology-half-filled-butterfly.svg">

Here, we have vertices $V \equiv \\{ r, g, b, b, p \\}$, edges
$E \equiv \\{rb, gr, bg, m, o, c \\}$ and faces $F \equiv \\{ f \\}$.

Here, we see a differential form $h_e$ that is defined on the edges,
and also obeys the equation $dh_e = 0$ (Hence is closed). However, it
_does not have an associated potential energy_ to derive it from. That is,
there cannot exist a certain $h_v$ such that $d h_v = h_e$.


So, while every exact form is closed, _not every_ closed form is exact.

Hence, this $g$ that we have found is a non-trivial element of $Kernel(d_{FE}) / Image(d_{EV})$,
since $dh_e = 0$, hence $h_e \in Kernel(d_{FE})$, while there does not exist
a $h_v$ such that $d h_v = h_e$, hence it is _not quotiented_ by the image of
$d_{EV}$.

So the failure of the space to be fully filled in (ie, the space has a hole),
is measured by the _existence of a function $h_e$ that is closed but not exact!_

This reveals a deep connection between homology and cohomology, which is
made explicit by the [Universal Coefficient Theorem](https://en.wikipedia.org/wiki/Universal_coefficient_theorem)

# Stuff I learnt in 2019

I write these retrospective blog posts every year since 2017. I tend to post a
collection of papers, books, and ideas I've stumbled across that year.
Unfortunately, this year, the paper list will be sparser, since I lost some
data along the way to the year, and hence I don't have links to everything I
read. So this is going to be a sparser list, consisting of things that I found
_memorable_.

I also re-organised my website, letting the link die, since keeping it up was
taking far too many cycles (In particular, CertBot was far too annoying to
maintain, and the feedback of hugo was also very annoying). I now have a
_single_ file, the
[`README.md`of the `bollu/bollu.github.io`](https://github.com/bollu/bollu.github.io)
repo,
to which I add notes on things I find interesting. I've bound the `i` alias
(for idea) on all my shells everywhere, to open the `README.md` file, wait
for me to write to it, run a `git commit` so I can type out a commit, and
then push. This has been _massive_ for what I manage to write down: I feel
like I've managed to write down a lot of one-liners / small facts that I've
picked up which I would not otherwise. I'm attempting to similarly pare down
other friction-inducing parts of my workflow. Suggestions here would be very
welcome!


If there's a theme of the year (insofar as my scattered reading has a
theme...), it's "lattices and geometry". Geometry in terms of differential
geometry, topology, and topoi. Lattices in the sense of a bunch of abstract
interpretation and semantics.

#### Course work: optimisation theory, quantum computation, statistics

My course work was less interesting to me this time, due to the fact that I had
chosen to study some wild stuff earlier on, and now have to take reasonable stuff
to graduate. However, there were courses that filled in a lot of gaps in my
self-taught knowledge for me, and the ones I listed were the top ones in that
regard.

I wound up reading
[Boyd on optimisation theory](https://web.stanford.edu/~boyd/cvxbook/),
[Nielsen and Chuang](http://mmrc.amss.cas.cn/tlb/201702/W020170224608149940643.pdf) for quantum computation,
where I also
[solved a bunch of exercises in Q#](https://github.com/bollu/quantum-course-exercises)
which was very fun and rewarding. I'm beginning to feel that learning quantum
computation is the right route to grokking things like entanglement and
superposition, unlike the physics which is first of all much harder due to
infinite dimensionality, and less accessible since we can't _program_ it.

#### Formal research work: Compilers, Formal verification, Programming languages

My research work is on the above topics, so I try to stay abreast of what's
going on in the field. What I've read over the past year on these topics is:


- [`A^2I`: meta-abstract interpretation](https://popl19.sigplan.org/details/POPL-2019-Research-Papers/71/A-2-I-Abstract-2-Interpretation).
  This paper extends the theory of abstract interpretation to perform abstract
  interpretation on program analyses themselves. I'm not sure how _useful_ this
  is going to be, as I still hold on to the belief that AI as a framework is
  too general to allow one to prove complex results. But I am still interested
  in trying to adapt this to some problems I have at hand. Perhaps it's going
  to work.


- [Cubicial Agda](https://dl.acm.org/citation.cfm?id=3341691). This paper introduces
  cubical type theory and its implementation in Agda. It appears to solve many
  problems that I had struggled with during my formalization of loop
  optimisations: In particular, dealing with Coinductive types in Coq, and that
  of defining quotient types / setoids. Supposedly, cubical Agda makes dealing
  with Coinduction far easier. It allows allows the creation of "real" quotient
  types that respect equality, without having to deal with `setoid` style
  objects that make for large Gallina terms. I don't fully understand how the
  _theory_ works: In particular, as far as I can tell, the synthetic interval
  type `I` allows one to only access the start and end points (`0` and `1`),
  but not anything in between, so I don't really see how it allows for
  interpolation.  I also don't understand how this allows us to make Univalence
  computable.  I feel I need to practice with this new technology before I'm
  well versed, but it's definitely a paper I'm going to read many, many times
  till I grok it.


- [Naive Cubical type theory](https://arxiv.org/abs/1911.05844). This paper
  promises a way to perform informal reasoning with cubical type theory, the
  way we are able to do so with, say, a polymorphic type theory for lambda
  calculus. The section names such as "how do we think of paths",
  "what can we do with paths", inspire confidence

- [Call by need is Clairvoyant call by value](https://icfp19.sigplan.org/details/icfp-2019-papers/26/Call-By-Need-is-Clairvoyant-Call-By-Value). This key insight is to notice that call by need
  is "just" call by value, when we evaluate only those values that are
  eventually forced, and throw away the rest. Thus, if we had an oracle that
  tells us which values are eventually forced, we can convert call by need into
  call by value, relative to this oracle. This cleans up many proofs in the
  literature, and might make it far more intuitive to teach call by need to
  people as well. Slick paper, I personally really enjoyed reading this.

- [Shift/Reset the Penultimate Backpropagator](https://arxiv.org/abs/1803.10228)
  This paper describes how to implement backprop using delimited continuations.
  Also, supposedly, using staging / building a compiler out of this paradigm
  allows one to write high performance compilers for backprop without having
  to suffer, which is always nice.


- [Closed forms for numerical loops](https://www.cs.princeton.edu/~zkincaid/pub/popl19a.pdf)
  This paper introduces a new algebra of polynomials with exponentials. It then
  studies the eigenvalues of the matrix that describes the loop, and tries to
  find closed forms in terms of polynomials and exponentials. They choose
  to only work with rationals, but not extensions of rational numbers
  (in terms of field extensions of the rationals). Supposedly, this is easier
  to implement and reason about. Once again, this is a paper I'd like to
  reimplement to understand fully, but the paper is well-done!


- [Composable, sound transformations of Nested recursion and loops](https://engineering.purdue.edu/Papers/Sundararajah.pdf).
  This paper attempts to bring ideas from polyhedral compilation
  into working with nested recursion. They create a representation using
  multitape finite automata, using which they provide a representation for
  nested recursion. I was somewhat disappointed that it does not handle
  mutual recursion, since my current understanding is that one can always
  convert nested recursion into a "reasonable" straight line program by
  simply inlining calls and then re-using polyhedral techniques.


- [Reimplementation of `STOKE` at `bollu/blaze`.](https://github.com/bollu/blaze/blob/master/notebooks/tutorial.ipynb)
  I reimplemented the [STOKE: stochastic superoptimisation](http://stoke.stanford.edu/)
  paper, and much to my delight, it was super-effective at regenerating common
  compiler transformations. I want to use this to generate loop optimisations
  as well, by transforming a polyhedral model of the original program.


#### Internship at [Tweag.io](http://tweag.io/) over the summer: Hacking on Asterius (Haskell -> WebAssembly compiler)

- [Blog post on the progress made by me hacking on Austerius over at Tweag](https://www.tweag.io/posts/2019-09-12-webassembly-internship.html)

I really enjoyed my time at Tweag! It was fun, and
[Shao Cheng](https://github.com/TerrorJack)
was a great mentor. I must admit that I was somewhat distracted, by all the new
and shiny things I was learning thanks to all the cool people there `:)` In
particular, I wound up bugging
[Arnaud Spiwack](http://assert-false.net/arnaud/),
[Simeon Carstens](http://simeon-carstens.com/),
and [Matthias Meschede](https://github.com/mmesch)
quite a bit, about type theory, MCMC sampling, and signal processing of storm
clouds.

I wound up reading a decent chunk of GHC source code, and while I can't link
to specifics here, I understood a lot of the RTS much better than I did before.
It was an enlightening experience, to say the least, and being paid to hack on
a GHC backend was a really fun way to spend the summer.

It also led me to fun discoveries, such as
[how does one debug debug info?](https://github.com/ghc/ghc/blob/535a26c90f458801aeb1e941a3f541200d171e8f/compiler/cmm/Debug.hs#L458)


I also really loved Paris as a city. My AirBnb host was a charming artist who
suggest spots for me around the city, which I really appreciated. Getting
around was disorienting for the first week or so, due to the fact that I could
not (and still do not) really understand how to decide in which direction to
walk inside the subways to find a particular line 
_going in a particular direction_.

The city has some great spots for quiet work, though! In particular, the
[Louvre Anticafe](https://www.anticafe.eu/lieux/louvre-paris-75001/)
was a really nice place to hang out and grab coffee. The model is great: you
pay for hours spent at the Anticafe, with coffee and snacks free. They also
had a discount for students which I gratefully used.
I bumped into interesting artists, programmers, and students who were open for
conversation there. I highly recommend hanging out there.

#### Probabilistic programming & giving a talk at FunctionalConf

This was the first talk I'd ever given, and it was on probabilistic programming
in haskell. In particular, I explained the
[`monad-bayes`](https://github.com/adscib/monad-bayes) approach of
doing this, and why this was profitable.
[The slides are available here](https://github.com/bollu/functionalconf-2019-slides-probabilistic-programming/blob/master/slides.pdf).


It was a fun experience giving a talk, and I'd like to do more of it, since I
got a lot out of attempting to explain the ideas to people. I wish I had more
time, and had a clearer idea of who the audience was. I got quite a bit of
help from [Michael Snoyman](https://www.snoyman.com/) to whip the talk into
shape, which I greatly appreciated.

The major ideas of probabilistic programming as I described it are
from Adam Scibior's thesis:

- [Adam Scibior: Formally justified and modular Bayesian inference for probabilistic programs](https://www.cs.ubc.ca/~ascibior/assets/pdf/thesis.pdf)

Along the way, I and others at tweag read the other major papers in the space,
including:

- [Church, a language for generative models](https://arxiv.org/pdf/1206.3255),
  which is nice since it describes it's semantics in terms of sampling. This is
  unlike Adam's thesis, where they define the denotational semantics in terms
  of measure theory, which is then approximated by sampling.
- [Riemann Manifold Langevin and Hamiltonian Monte Carlo](https://pdfs.semanticscholar.org/16c5/06c5bb253f7528ddcc80c72673fabf584f32.pdf)
  which describes how to perform Hamiltonian Monte Carlo on the 
  _information geometry_ manifold.  So, for example, if we are trying to sample 
  from gaussians, we sample from a 2D Riemannian manifold with parameters mean 
  and varince, and metric as the [Fisher information metric](https://en.wikipedia.org/wiki/Fisher_information_metric).
  This is philosophically the "correct" manifold to sample from, since it
  represents the intrinsic geometry of the space we want to sample from.
- [An elementary introduction to Information geometry by Frank Nielsen](https://arxiv.org/pdf/1808.08271.pdf)
  something I stumbled onto as I continued reading about sampling from
  distributions. The above description about the "correct" manifold for
  gaussians comes from this branch of math, but generalises it quite a bit
  further. I've tried to reread it several times as I gradually gained maturity
  in differential geometry. I can't say I understand it just yet, but I hope to
  do so in a couple of months. I need more time for sure to meditate on the
  objects.
- [Reimplementation of `monad-bayes`](https://github.com/bollu/shakuni).
  This repo holds the original implementation on which the talk is based on.
  I read through the `monad-bayes` source code, and then re-implemented the
  bits I found interesting. It was a nice exercise, and you can see
  the git history tell a tale of my numerous mis-understandings of MCMC methods,
  till I finally got what the hell was going on.

#### Presburger Arithmetic

Since we use a bunch of [presburger arithmetic](https://en.wikipedia.org/wiki/Presburger_arithmetic)
for [polyhedral compilation](http://polyhedral.info/)
which is a large research interest of mine, I've been trying to build a
"complete" understanding of this space. So this time, I wanted to learn
how to build good solvers:

- [`bollu/gutenberger`](https://github.com/bollu/gutenberger) is a decision
  procedure for Presburger arithmetic that exploits their encoding as finite
  automata. One thing that I was experimenting with was that we only use
  numbers of finite bit-width, so we can explore the entire state space
  of the automata and then perform NFA reduction using
  [DFA minimisation](https://en.wikipedia.org/wiki/DFA_minimization). The
  reference I used for this was the excellent textbook
  [Automata theory: An algorithmic approach, Chapter 10](https://www7.in.tum.de/~esparza/autoskript.pdf)
- [The taming of the semi-linear set](http://www.lsv.fr/~haase/documents/ch16.pdf)
  This uses a different encoding of presburger sets, which allows them to bound
  a different quantity (the norm) rather than the bitwidth descriptions. This allows
  them to compute _exponentially_ better bounds for some operations than
  were known before, which is quite cool. This is a paper I keep trying to
  read and failing due to density. I should really find a week away from civilization
  to just plonk down and meditate upon this.

##### Open questions for which I want answers

I want better references to being able to _regenerate_ the inequalities
description from a given automata which accepts the presburger set automata.
This will allow one to smoothly switch between the _geometric_ description
and the _algebraic_ description. There are some operations that only work
well on the geometry (such as optimisation), and others that only work well on
the algebraic description (such as state-space minimisation). I have not found
any good results for this, only scattered fragments of partial results.
If nothing else, I would like some kind of intuition for _why this is hard_.

Having tried my stab at it, the general impression that I have is that the
space of automata is much larger than the things that can be encoded as
presburger sets. Indeed, it was shown that automata accept numbers which
are ultimately periodic.

-  first order logic + "arithmetic with +" + (_another operation I cannot recall_).
   I'm going to fill this in once I re-find the reference.

But yes, it's known that automata accept a language that's broader than just
first order logic + "arithmetic with +", which means it's hard to dis-entangle
the presburger gits from the non-presburger bits of the automata.


#### Prolog

I wanted to get a better understading of how prolog works under the hood, so I began
re-implementing the [WAM: warren abstract machine](http://wambook.sourceforge.net/).
It's really weird, this is the _only stable reference_ I can find to implementing
high-performance prolog interpreters. I don't really understand how to chase the
paper-trail in this space, I'd greatly appreciate references. My implementation
is at [`bollu/warren-cpp`](https://github.com/bollu/warren-cpp/). Unfortunately,
I had to give up due to a really hard-to-debug bug.

It's crazy to debug this abstract machine, since the internal representation gets
_super convoluted_ and hard to track, due to the kind of optimised encoding it
uses on the heap.

If anyone has a better/cleaner design for implementing good prologs, I'd love
to know.

Another fun paper I found in this space thanks to Edward Kmett was
[the Rete matching algorithm](http://www.drdobbs.com/architecture-and-design/the-rete-matching-algorithm/184405218),
which allows one to declare many many pattern matches, which are then "fused"
together into an optimal matcher that tries to reuse work across failed
matchers.

#### General Relativity

This was on my "list of things I want to understand before I die", so I wound
up taking up an Independent Study in university, which basically means that
I study something on my own, and visit a professor once every couple weeks,
and am graded at the end of the term. For GR, I wound up referencing a wide
variety of sources, as well as a bunch of pure math diffgeo books. I've read
everything referenced to various levels. I feel I did take away the core
ideas of differential and Riemannian geometry. I'm much less sure I've grokked
general relativity, but I can at least read the equations and I know all the
terms, so that's something.

- [The theoretical minimum by Leonard Susskind](https://theoreticalminimum.com/courses/general-relativity/2012/fall).
  The lectures are breezy in style, building up the minimal theory (and no proofs)
  for the math, and a bunch of lectures spent analysing the physics. While I wish
  it were a little more proof heavy, it was a really great reference to learn the
  basic theory! I definitely recommend following this and then reading other
  books to fill in the gaps.
- [Gravitation by Misner Thorne and Wheeler](https://en.wikipedia.org/wiki/Gravitation_(book))
  This is an imposing book. I first read through the entire thing (Well, the parts I thought I needed),
  to be able to get a vague sense of what they're going for. They're rigorous in
  a very curious way: It has a bunch of great _physics_ perspectives of looking
  at things, and that was invaluable to me. Their view of forms as "slot machines"
  is also fun. In general, I found myself repeatedly consulting this book for
  the "true physical" meaning of a thing, such as curvature, parallel transport,
  the equation of a geodesic, and whatnot.
- [Differential Geometry of Curves and Surfaces by do Carmo](http://www2.ing.unipi.it/griff/files/dC.pdf)
  This is the best book to intro differential geometry I found. It throws away
  all of the high powered definitions that "modern" treatments offer, and
  starts from the ground up, building up the theory in 2D and 3D. This is amazing,
  since it gives you small, computable examples for things like
  "the Jacobian represents how tangents on a surface are transformed locally".
- [Symplectic geometry & classical mechanics by Tobias Osborne](https://www.youtube.com/watch?v=pXGTevGJ01o&list=PLDfPUNusx1EoVnrQcCRishydtNBYU6A0c)
  This lecture series was great, since it re-did a lot of the math I'd seen
  in a more physicist style, especially around vector fields, flows, and
  Lie brackets. Unfortunately for me, I never even _got_ to the classical
  mechanics part by the time the semester ended. I began
  [taking down notes in my repo](https://github.com/bollu/notes/blob/master/diffgeo/main.pdf),
  which I plan to complete.
- [Introduction to Smooth manifolds: John Lee](https://sites.math.washington.edu/~lee/Books/ISM/)
  This was a very well written _mathematical_ introduction to differential geometry.
  So it gets to the physically important bits (metrics, covariant derivatives)
  far later, so I mostly used it as a reference for problems and more rigour.
- [Einstein's original paper introducing GR, translated](http://hermes.ffn.ub.es/luisnavarro/nuevo_maletin/Einstein_GRelativity_1916.pdf)
  finally made it click as to _why_
  he wanted to use tensor equations: tensor equations of the form `T = 0` are
  invariant in _any coordinate system_, since on change of coordinates, `T`
  changes by a multiplicative factor! It's a small thing in hindsight, but it
  was nice to see it explicitly spelled out, since as I understand, no one
  among the physicists knew tensor calculus at the time, so he had to introduce
  all of it.

#### Discrete differential geometry

I can't recall how I ran across this: I think it was because I was trying to
get a better understanding of Cohomology, which led me to Google for
"computational differential geometry", that finally led me to Discrete
differential geometry.

It's a really nice collection of theories that show us how to discretize
differential geometry in low dimensions, leading to rich intuitions and
a myriad of applications for computer graphics.

- [The textbook by Kennan Crane on the topic](https://www.cs.cmu.edu/~kmcrane/Projects/DDG/paper.pdf)
  which I read over the summer when I was stuck (more often than I'd like) in
  the Paris metro. The book is very accessible, and requires just some
  imagination to grok. Discretizing differential geometry leads to most things
  being linear algebra, which means one can calculate things on paper easily.
  That's such a blessing.
- [Geodesics in Heat](https://arxiv.org/pdf/1204.6216)
  explores a really nice way to discover geodesics by simulating the heat
  equation for a short time. The intuition is that we should think of the heat
  equation as describing the evolution of particles that are performing random
  walks. Now, if we simulate this system for a short while and then look at the
  distribution, particles that reach a particular location on the graph 
  _must have taken the shortest path_, since any longer path would not have 
  allowed particles to reach there. Thus, the distribution of particles at 
  time `dt` does truly represent distances from a given point.  The paper
  explores this analogy to find accurate geodesics on complex computational
  grids. This is aided by the use of differential geometry, appropriately
  discretized.
- [The vector heat method](https://arxiv.org/pdf/1805.09170.pdf)
  explores computing the parallel transport of a vector across a discrete
  manifold efficiently, borrowing techniques from the 'Geodesics in Heat'
  paper.
- [Another paper by Kennan Crane: Lie group integrators for animation and control of vehicles](https://www.cs.cmu.edu/~kmcrane/Projects/LieGroupIntegrators/paper.pdf)
  This paper describes a general recipe to tailor-make integrators for a system
  of constraints, by directly integrating over the lie group of the
  configuration space.  This leads to much more stable integrators. I have some
  misguided hope that we can perhaps adapt these techniques to build better FRP
  (functional reactive programming) systems, but I need to meditate on this a
  lot more to say anything definitively.




#### Synthetic differential geometry

It was [Arnaud Spiwack](http://assert-false.net/arnaud/)
who pointed me to this. It's a nice axiomatic
system of differential geometry, where we can use physicist style proofs of
"taking stuff upto order `dx`", and having everything work upto mathematical
rigor.

The TL;DR is that we want to add a new number called `dx` into the reals,
such that `dx^2 = 0`. But if such a number did exist, then clearly `dx = 0`.
However, the punchline is that to prove that `dx^2 = 0 => dx = 0` requires
the use of contradiction!

So, if we banish the law of excluded middle (and therefore no longer use
proof by contradiction), we are able to postulate the existence of a new
element `dx`, which obeys `dx^2 = 0`. Using this, we can build up the
whole theory of differential geometry in a pleasing way, without having to
go through the horror that is real analysis. (I am being hyperbolic, but really,
real analytic proofs are not pleasant).

[I began formalizing this in Coq and got a formalism going: `bollu/diffgeo`](https://www.github.com/bollu/diffgeo).

Once I was done with that, I realised I don't know how to exhibit _models_ of
the damn thing! So, reading up on that made me realise that I need around 8
chapters worth of a grad level textbook (the aptly named
[Models of Smooth Infinitesimal Analysis](https://link.springer.com/book/10.1007/978-1-4757-4143-8)).

I was disheartened, so I [asked on `MathOverflow`](https://mathoverflow.net/questions/346385/constructing-computable-synthetic-differential-geometry)
(also my first ever question there), where I learnt about tangent categories and
differential lambda calculus. Unfortunately, I don't have the bandwidth to read
another 150-page tome, so this has languished.


### Optimisation on Manifolds

I began reading
[Absil: Optimisation on matrix manifolds](http://www.eeci-institute.eu/GSC2011/Photos-EECI/EECI-GSC-2011-M5/book_AMS.pdf)
which describes how to perform optimisation / gradient descent on
_arbitrary Riemannian manifolds_, as well as closed forms for well-known
manifolds. The exposition in this book is really good, since it picks a
concrete manifold and churns out all the basic properties of it manually. The
only problem I had with the books was that there were quite a few gaps (?) in
the proofs -- perhaps I missed a bunch.

This led me to learn Lie theory to some degree, since that was the natural
setting for many of the proofs. I finally saw _why_ anyone gives a shit about
the tangent space at the identity: because it's _easier to compute!_ For a
flavour of this, 
[consider this question on `math.se` by me that asks about computing tangent spaces of $O(n)$](https://math.stackexchange.com/questions/3389983/explicit-description-of-tangent-spaces-of-on).

#### AIRCS workshop

I attended the
[AI risk for computer scientists](https://intelligence.org/ai-risk-for-computer-scientists/)
workshop hosted by
[MIRI (Machine intelligence research institute)](https://intelligence.org/) in
December. Here, a bunch of people were housed at a bed & breakfast for a
week, and we discussed AI risk, why it's potentially the most important thing
to work on, and anything our hearts desired, really. I came away with new
branches of math I wanted to read, a better appreciation of the AI risk
community and a sense of what their "risk timelines" were, and some
explanations about sheaves and number theory that I was sorely lacking. All in
all, it was a great time, and I'd love to go back.

#### P-adic numbers

While I was on a particularly rough flight back from the USA to India when
coming back from the AIRCS workshop, I began to read the textbook
[Introduction to p-adic numbers by Fernando Gouvea](https://www.springer.com/gp/book/9783540629115),
which fascinated me, so I then
[wrote up the cool parts introduced in the first two chapters as a blog post](http://bollu.github.io/#a-motivation-for-p-adic-analysis).
I wish to learn more about the p-adics and p-adic analysis, since they
seem to be deep objects in number theory.

In particular, a question that I thought might have a somewhat trivial answer
([why do the p-adics use base p in defining norm](https://math.stackexchange.com/questions/3482489/why-does-the-p-adic-norm-use-base-p))
turned out to have answers that were quite deep, which was something
unexpected and joyful!

#### Topology of functional programs

- [Slides by Martın Escardo](http://cs.ioc.ee/ewscs/2012/escardo/slides.pdf)
- [Synthetic topology of data types and classical spaces](https://pdf.sciencedirectassets.com/272990/1-s2.0-S1571066104X00177/1-s2.0-S1571066104051357/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEJP%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIGQAb828p1io4csznEej60j0PwJteuXf7OoHLSCDhkUTAiEA9ITs1JrUEOE%2Ft%2Fl5TI9ZkNLUfBIx42IZ%2FoAqQpdX4twq2AII6%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARACGgwwNTkwMDM1NDY4NjUiDBQOxJ3s3HCbVxSheCqsAt65yorZMMtIhLF7ML5sJQ9S5wZxBayKDrRkUKOjSzXxtQWebXs70FXhhpToXKvJoDrLgsqDzdF%2FAshZY%2FkDUep6KILxKnYxCBrBINhjFqxDlRZH0s1Y991RgCyNNnwmFI%2BrH70lSrV0OxQ9Z5WdXXPDkTLXv8512Xz%2BJn5DqEqdqD49FLbOuHl6PRM0TnYyNJkLBXNVwt75kkGkaTfdgmgiqh7YpcXcHlbqI2oqNcaxFDewXwKDCC7qWD6ECclLgszoeOXOtRI91nvNac8%2BLV4bXkKLXpd99H94N2vXPUPz99p6oqfdY9ixtcfI9POFX8agUilYjXKVhAWk4FSzzzMqbtZLBfkCZT4ffDTxRgL52yD%2FmL5E0Pe4mczVlUoB5DKoB8Lkitrt0BumQzDr4ffvBTrQAjVRuzG5V0CC%2Fd1t%2BUMPkrywaYytbrXCZ%2BkDo0xDBqsljY8DaGIiFINr8BEEpT7UX42GRhcDzpnOnztdAOTea3qZ3SmXJwgEoh0aiz%2B87MmsC57s0Q%2F%2B%2FDDvHBY3zLCrz7rdewXOgk6VxI9d5mhG3Du1dwPRbgOe798S2waDCD8LQA3rw7w5wNGa9Uv3xtNVH%2BHw%2FXcQ6OiubO4GL9mK8U5g7TVPh1hLB26XBQooKJ564VGf4J9VqWxjlx3NicVhqnFlGevNJNKyVLiyRsRCyQGMV59%2BXqUwdEMQZYWLbfUwELNz1NKfWumvu9BXC5jjsJgNx%2FRERSb7hqT1svMJU91o%2FHtatGAnPvVjYaNthha9O9jm%2BG9nw1vMsdyJ0asI5w5SrlsEyb5C7Vk7aLBcHAEi3XPRhivY1Q4hZAN0xY9VfEZrF%2FoM9HCGxr5cYs%2BP9w%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20191221T113658Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTY6QRXTPOC%2F20191221%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=8a26656e8f8c8772afdc2ae6caa9b583fd59a8ee6303d9770d25b4a3d8a6291f&hash=42518d3e5cc1e77ed961c359d0ea8f59bd582d1e5f13d69c3eeb2563a6c82abd&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1571066104051357&tid=spdf-584e8188-4806-44bb-a118-9b63a53caaff&sid=f53691052392834d3e18a62484e2909639a9gxrqb&type=client)

Both of these describe a general method to transfer all topological ideas as
statements about _computability_ in a way that's far more natural (at least for
me, as a computer scientist). The notion of what a continuous function "should
be" (keeping inverse images of open sets open) arises naturally from this
computational viewpoint, and many proofs of topology amount to finding
functional programs that fit a certain type. It's a great read, and I feel gave
me a much better sense of what topology is trying to do.

- [I've written some exposition on this topic](http://bollu.github.io/#topology-is-really-about-computation--part-1),
  which maybe a more accessible read than the links above, since it tries to
  distill the fundamental idea into a blog post.

#### Philosophy

I've wanted to understand philosophy as a whole for a while now, at least
enough to get a general sense of what happened in each century. The last year,
I meandered through some philosophy of science, which led me to some really
wild ideas (such as that of
[Paul Feyerabend's 'science as an anarchic enterprise'](https://en.wikipedia.org/wiki/Epistemological_anarchism)
which I really enjoyed).

I also seem to get a lot more out of audio and video than text in general, so
I've been looking for podcasts and video lectures. I've been following:

- [The history of philosophy without any gaps](https://historyofphilosophy.net/)
  for a detailed exposition on, say, the greeks, or the arabic philosophers.
  Unfortunately, this podcast focuses on far too much detail for me to have been
  able to use it as a way to get a broad idea about _philosophy_ in itself.

- [Philosophize This! by Stephen West](http://philosophizethis.org/)
  Is a good philosophy podcast for a _broad_ overview of different areas
  of Philosophy. I got a lot out of this, since I was able to get a sense
  of the progression of ideas in (Western) Philosophy. So I now know what
  [Phenomenology](https://plato.stanford.edu/entries/phenomenology/) is,
  or what Foucault was reacting against.


I also attempted to read a bunch of philosophers, but the only ones I could
make a good dent on were the ones listed below. I struggled in writing this
section, since it's much harder to sanity check my understanding of philosophy,
versus mathematics, since there seems to be a range of interpretations of the
same philosophical work, and the general imprecise nature of language doesn't
help here at all. So please take all the descriptions below with some salt
to taste.

- [Discipline and Punish by Michel Foucault](https://en.wikipedia.org/wiki/Discipline_and_Punish)
  Here, Foucault traces the history of the criminal justice system of society,
  and how it began as something performed 'on the body' (punishment),
  which was then expanded to a control 'of the mind' (reform). As usual,
  the perspective is fun, and I'm still going through the book.

- [Madness and Civilization by Michel Foucault](https://en.wikipedia.org/wiki/Madness_and_Civilization)
  which attempts to chronicle how our view of madness evolved as society did.
  It describes how madmen, who were on the edges of society, but still
  "respected" (for exmaple, considered as 'being touched by the gods') were
  pathologized by the Renaissance, and were seen as requiring treatment. I'm
  still reading it, but it's enjoyable so far, as a new perspective for me.


- [The value of science by Henri Poincare](https://en.wikipedia.org/wiki/The_Value_of_Science).
  Here, he defends the importance of experimentation, as well as the value of
  intuition to mathematics, along with the importance of what we consider
  formal logic. It's a tough read sometimes, but I think I got something out of
  it, at least in terms of perspective about science and mathematics.

#### Information theory

I've been on a quest to understand information theory far better than I
currently do. In general, I feel like this might be a much better way to
internalize probability theory, since it feels like it states probabilistic
objects in terms of "couting" / "optimisation of encodings", which is a
perspective I find far more natural.

Towards this aim, I wound up reading:

- [Information theory, Learning, and inference algorithms](http://www.inference.org.uk/mackay/itila/book.html)
  This book attempts to provide the holistic view I was hoping for. It has
  great illustrations of the basic objects of information theory. However,
  I was hoping that the three topics would be more "unified" in the book,
  rather than being presented as three separate sections with some amount
  of back-and-forth-referencing among them. Even so, it was a really fun read.

- [Elements of information theory](http://www.cs-114.org/wp-content/uploads/2015/01/Elements_of_Information_Theory_Elements.pdf)

#### Building intuition for Sheaves, Topoi, Logic

I don't understand the trifecta of sheaves, topoi, geometry, and logic, and
I'm trying to attack this knot from multiple sides at once.

- [Understanding networks and their behaviours using sheaf theory](https://arxiv.org/pdf/1308.4621)
- [Sheaves, objects, and distributed systems](https://www.sciencedirect.com/science/article/pii/S1571066108005264)
- [Sheaves are the canonical data strucure for sensor integration](https://arxiv.org/pdf/1603.01446.pdf)
- [Elementary applied topology, Chapter 9: Sheaves](https://www.math.upenn.edu/~ghrist/EAT/EATchapter9.pdf)
- [Sheaf theory: The mathematics of data fusion (video) (link to HackerNews)](https://news.ycombinator.com/item?id=13677308)

All of these provide geometric viewpoints of what sheaves are, in low-dimensional
examples of graphs which are easy to visualize. I'm also trudging through the
tome:

- [Sheaves in geometry and logic: A first introduction to Topos theory](https://www.springer.com/gp/book/9780387977102)

which appears to follow the "correct path" of the algebraic geometers, but this
requires a lot of bandwidth.

- [The Rising Sea: foundations of algebraic geometry by Ravi Vakil](http://math.stanford.edu/~vakil/216blog/FOAGnov1817public.pdf)

This is a hardcore algebraic geometry textbook, and is arguably
_great for studying sheaves_ because of it. Sheaves are Chapter 2, and allows
one to see them be developed in their "true setting" as it were. In that
Grothendeick first invented sheaves for algebraic geometry, so it's good to
see them in the home they were born in. Once again, this is a book I lack
bandwidth for except to breezily read it as I go to bed. I did get something
out from doing this. I'm considering taking this book up as an independent
study, say the first four chapters. I'll need someone who knows algebraic
geometry to supervise me, though, which is hard to find in an institute geared
purely for computer science. (If anyone on the internet is kind enough to
volunteer some of their time to answer questions, I'll be very glad! Please
email me at `rot13(fvqqh.qehvq@tznvy.pbz)`)

#### The attic

This section contains random assortments that I don't recall how I stumbled
across, but too cool to not include on the list. I usually read these in bits
and pieces, or as bedtime reading right before I go to bed to skim.  I find
that skimming such things gives me access to knowing about tools I would not
have known otherwise. I like knowing the existence of things, even if I don't
recall the exact thing, since knowing that something like `X` exists has saved me
from having to reinvent `X` from scratch.

- [Group Theory: Birdtracks, Lie's and Exceptional Groups by Predrag Cvitanovic](http://www.cns.gatech.edu/GroupTheory/version9.0/GroupTheory.pdf)
  is an exposition of Lie theory using some notation called as "Birdtrack notation",
  which is supposedly a very clean way of computing invariants, inspired by
  Feynmann notation. The writing style is informal and pleasant, and I decided
  to save the book purely because the first chapter begins with
  "Basic Concepts: A typical quantum theory is constructed from a few building blocks...".
  If a book considers building quantum theories as its starting point, I really
  want to see where it goes.

- [Elementary Applied topology by Robert M Ghirst](https://www.math.upenn.edu/~ghrist/notes.html)
  I wouldn't classify the book as elementary because it skims over too much to be
  useful as a reference, but it's great to gain an intuition for what, say,
  homology or cohomology is. I am currently reading the section on Sheaf theory,
  and I'm getting a lot out of it, since it describes how to write down, say,
  min-cut-max-flow or niquist-shannon in terms of sheaves. I don't grok it yet,
  but even knowing this can be done is very nice. The book is a wonderful
  walkthrough in general.


- [On polysemous mathematical illustration by Robert M Ghirst](https://icerm.brown.edu/video_archive/?play=2034)
  This is a talk on the wonderful illustrations by the above author, about
  the different types of mathematical illustrations one can have, and different
  "levels of abstraction".

- [Mathematical Impressions: The illustrations of AT Femenko](http://chronologia.org/en/math_impressions/poster016.html)
  These are _beautiful_ illustrated pictures of various concepts in math, which
  tend to _evoke_ the feeling of the object, without being too direct about it.
  For example, consider "gradient descent" below. I highly recommend going
  through the full gallery.


- [Gradient Descent](http://chronologia.org/art/math/123a176.jpg)
  <img width=200 height=200 src="http://chronologia.org/art/math/123a176.jpg">

- [Topological Zoo](http://chronologia.org/art/math/077a011.jpg)
  <img width=200 height=200 src="http://chronologia.org/art/math/077a011.jpg">

- [Persistent Homology in Multivariate Data Visualization](https://bastian.rieck.me/research/Dissertation_Rieck_2017.pdf)
  This is the PhD dissertation of [Bastian Rieck](https://bastian.rieck.me/),
  who's now a postdoc at ETH. I deeply enjoyed reading it, since it pays
  a lot of attention to the _design_ of analyses, and how to interpret
  topological data. I really enjoyed getting a good sense of how one can
  use persistent homology to understand data, and the trade-offs between
  [Vietoris-Rips complex](https://en.wikipedia.org/wiki/Vietoris%E2%80%93Rips_complex)
  and the [Cech complex](https://en.wikipedia.org/wiki/%C4%8Cech_complex).

- [An introduction to Geometric algebra](https://arxiv.org/pdf/1205.5935.pdf)
  I fell in love with geometric algebra, since it provides a really clean way
  to talk about _all possible subspaces_ of a given vector space. This provides
  super slick solutions to many geometry and linear algebra problems. The
  way I tend to look at it is that when one does linear algebra, there's a strict
  separation between "vectors" (which are elements of the vector space), and,
  say, "hyperplanes" (which are _subspaces_ of the vector space), as well as
  objects such as "rotations" (which are _operators_ on the vector space).
  Geometric algebra provides a rich enough _instruction set_ to throw all
  these three distinct things into a blender. This gives a really concise
  language to describe all phenomena that occurs in the vector space world ---
  which, let's be honest, is _most_ tractable phenomena! I had a blast
  reading about GA and the kinds of operators it provides.

- [Circuits via Topoi](https://arxiv.org/pdf/1807.07159). This paper attempts
  to provide an introduction to topos theory by providing a semantics for
  both combinational and sequential circuits under a unifying framework. I keep
  coming back to this article as I read more topos theory. Unfortunately, I'm
  not "there yet" in my understanding of topoi. I hope to be next year!


- [Fearless Symmetry](https://press.princeton.edu/books/paperback/9780691138718/fearless-symmetry)
  This is definitely my favourite non-fiction book that I've read in 2019, hands
  down. The book gives a great account of the mathematical objects that went
  into Wiles' book of Fermat's last theorem. It starts with things like
  "what is a permutation" and ends at questions like "what's a reciprocity law"
  or "what's the absolute galois group". While at points, I do believe the book
  goes far too rapidly, all in all, it's a solid account of number theory
  that's distilled, but not in any way diluted. I really recommend reading this
  book if you have any interest in number theory (or, like me, a passing
  distaste due to a course on elementary number theory I took, with proofs that
  looked very unmotivated). This book made me decide that I should, indeed,
  definitely learn algebraic number theory, upto at least
  [Artin Reciprocity](https://en.wikipedia.org/wiki/Artin_reciprocity_law).


- [Rememberance of Earth's past trilogy by Liu Cixin](https://en.wikipedia.org/wiki/Remembrance_of_Earth%27s_Past)
  While I would not classify this as "mind-blowing" (which I do classify Greg
  Egan books as), they were still a solidly fun read into how humanity would
  evolve and interact with alien races. It also poses some standard solutions
  to the Fermi Paradox, but it's done well. I felt that the fact that it was
  translated was painfully obvious in certain parts of the translation, which
  I found quite unfortunate. However, I think book 3 makes up in grandeur for
  whatever was lost in translation.

- [Walkaway by Cory Doctorow](https://en.wikipedia.org/wiki/Walkaway_(Doctorow_novel))
  The book is set in a dystopian nightmare, where people are attempting to
  "walk away" from society and set up communes, where they espouse having
  a post-scarcity style economy based on gifting. It was a really great
  description of what such a society could look like. I took issue with some
  weird love-triangle-like-shenanigans in the second half of the book, but
  the story arc more than makes up for it. Plus, the people throw a party
  called as a "communist party" in the first page of the book, which grabbed
  my attention immediately!

- [PURRS: Parma University Recurrence Relation Solver](http://www.cs.unipr.it/purrs/)
  I wanted better tactics for solving recurrences in Coq, which led me into
  a rabbit hole of the technology of recurrence relation solving. This was the
  newest _stable_ reference to a complete tool that I was able to find. Their
  references section is invaluable, since it's been vetted by them
  actually implementing this tool!

- [Term rewriting and all that](https://www21.in.tum.de/~nipkow/TRaAT/).
  I read this book purely for its description of Groebner bases and the Bucchberger
  algorithm in a way that _made sense_ for the first time.
  [I've written about this more extensively before](http://bollu.github.io/#what-the-hell-is-a-grobner-basis-ideals-as-rewrite-systems)
  so I'm not going to repeat myself here. In general, I think it's a great book
  that's worth reading, if nothing else, for at least the chapter on Groebner
  bases.

- [Lucid: The dataflow programming language](http://worrydream.com/refs/Wadge%20-%20Lucid,%20the%20Dataflow%20Programming%20Language.pdf)
  This document is the user manual of Lucid. I didn't fully understand the
  book, but what I understood as their main argument is that full access too
  looping is un-necessary to perform most of the tasks that we do. Rather,
  one can provide a "rich enough" set of combinators to manipulate streams
  that allows one to write all programs worthy of our interest.

- [Bundle Adjustment — A Modern Synthesis](https://hal.inria.fr/inria-00548290/document)
  I learnt about Bundle Adjustment from a friend taking a course on robotics.
  The general problem is to reconstruct the 3D coordinates of a point cloud
  given 2D projections of the points and the camera parameters, as the camera
  moves in time. I found the paper interesting since it winds up invoking a
  decent amount of differential geometric and gauge theoretic language to
  describe the problem at hand. I was unable to see why this vocabulary helped
  in this use-case, but perhaps I missed the point of the paper. It was hard to
  tell.

#### Conclusions

I always feel a little wrong posting this at the end of every year, since I
feel that among the things I cover under "read", I've internalized some things
far better than others: For example, I feel I understannd Riemannian geometry
far better than I do General Relativity. I try to put up the caveats at the
beginning of each section, but I'd really like a way to communicate my
confidence without reducing readability.


The final thing that I wish for is some kind of reading group? It's hard
to maintain a group when my interests shift as rapidly as they do, which
was one of the reason I really loved the AIRCS workshop: They were people
who were working on formal methods, compilers, type theory, number theory,
embedded systems, temporal logic... It was very cool to be in a group of
people who had answers and intuitions to questions that had bugged me for
some time now. I wonder if attending courses at a larger research university
feels the same way. My uni is good, but we have quite small population, which
almost by construction means reduced diversity.

I also wish that I could openly add more references to repos I've been working
on for a while now, but I can't due to the nature of academia and publishing.
This one bums me out, since there's a long story of a huge number of commits
and trial-by-fire that I think I'll be too exhausted to write about once the
thing is done.

Sometimes, I also wish that I could spend the time I spend reading _disparate_
topics on _focused reading on one topic_. Unfortunately, I feel like I'm not
wired this way, and the joy I get from sampling many things at the same time
and making connections is somehow much deeper than the joy I get by deeply
reading one topic (in exclusion of all else). I don't know what this says
about my chances as a grad student in the future `:)`.


# A motivation for p-adic analysis

I've seen the definitions of p-adic numbers scattered around on the internet,
but this analogy as motivated by the book
[p-adic numbers by Fernando Gouvea](https://www.springer.com/gp/book/9783540629115)
really made me understand why one would study the p-adics, and why the
definitions are natural. So I'm going to recapitulate the material, with the
aim of having somoene who reads this post be left with a sense of why it's
profitable to study the p-adics, and what sorts of analogies are fruitful when
thinking about them.

We wish to draw an analogy between the ring $\mathbb C[X]$, where $(X - \alpha)$
are the prime ideals, and $\mathbb Z$ where $(p)$ are the prime ideals. We wish
to take all operations one can perform with polynomials, such as generating
functions ($1/(X - \alpha) = 1 + X + X^2 + \dots$ ),
taylor expansions (expanding aronund $(X - \alpha)$),
and see what their analogous objects will look like in $\mathbb Z$
relative to a prime $p$.

#### Perspective: Taylor series as writing in base $p$:

Now, for example, given a prime $p$, we can write any positive integer $m$
in base $p$, as $(m = \sum_{i=0}^n a_i p^i)$ where $(0 \leq a_i \leq p - 1)$.

For example, consider $m = 72, p = 3$. The expansion of 72 is
$72 = 0\times 1 + 0 \times 3 + 2 \times 3^2 + 2 \times 3^3$.
This shows us that 72 is divisible by $3^2$.

This perspective to take is that this us the information local to prime $p$,
about what order the number $m$ is divisible by $p$,
just as the taylor expansion tells us around $(X - \alpha)$ of a polynomial $P(X)$
tells us to what order $P(X)$ vanishes at a point $\alpha$.

#### Perspective: rational numbers and rational functions as infinite series:

Now, we investigate the behaviour of expressions such as
- $P(X) = 1/(1+X) = 1 - X + X^2 -X^3 + \dots$.

We know that the above formula is correct formally from the theory of
generating functions.  Hence, we take inspiration to define values for
_rational numbers_.

Let's take $p \equiv 3$, and we know that $4 = 1 + 3 = 1 + p$.

We now calculate $1/4$ as:

$$
1/4 = 1/(1+p) = 1 - p + p^2 - p^3 + p^4 - p^5 + p^6 + \cdots
$$

However, we don't really know how to interpret $(-1 \cdot p)$, since we assumed
the coefficients are always non-negative. What we can do is to rewrite $p^2 = 3p$,
and then use this to make the coefficient positive. Performing this transformation
for every negative coefficient, we arrive at:


$$
\begin{aligned}
1/4 &= 1/(1+p) = 1 - p + p^2 - p^3 + p^4 + \cdots \\
&= 1 + (- p + 3p) + (- p^3 + 3p^3)  +  \cdots \\
&= 1 + 2p + 2p^3 + \cdots
\end{aligned}
$$

We can verify that this is indeed correct, by multiplying with $4 = (1 + p)$
and checking that the result is $1$:

$$
\begin{aligned}
&(1 + p)(1 + 2p + 2p^3 + \cdots) \\
&= (1 + p) + (2p + 2p^2) + (2p^3 + 2p^4) + \cdots \\
&= 1 + 3p + 2p^2 + 2p^3 + 2p^4 + \cdots \\
&\text{(Rewrite $3p = p \cdot p = p^2$)} \\
&= 1 + (p^2 + 2p^2) + 2p^3 + 2p^4 + \cdots \\
&= 1 + 3p^2 + 2p^3 + 2p^4 + \cdots \\
&\text{(Rewrite $3p^2 = p^3$ and collect $p^3$)} \\
&= 1 + 3p^3 + 2p^4 + \cdots \\
&= 1 + 3p^4 + \cdots \\
&= 1 + \cdots = 1
\end{aligned}
$$

What winds up happening is that all the numbers after $1$ end up being cleared
due to the carrying of $(3p^i \mapsto p^{i+1})$.

This little calculation indicates that we can also define take the $p$-adic
expansion of _rational numbers_.

#### Perspective: -1 as a p-adic number

We next want to find a p-adic expansion of -1, since we can then expand
out theory to work out "in general". The core idea is to "borrow" $p$, so
that we can write -1 as $(p - 1) - p$, and then we fix $-p$, just like we fixed
$-1$. This eventually leads us to an infinite series expansion for $-1$. Written
down formally, the calculation proceeds as:

$$
\begin{aligned}
-1 &= -1 + p - p  \qquad \text{(borrow $p$, and subtract to keep equality)} \\
&= (p - 1) - p \qquad \text{(Now we have a problem of $-p$)} \\
&= (p - 1) - p + p^2 - p^2  \\
&= (p - 1) + p(p - 1) - p^2 \\
&= (p - 1) + p(p - 1) - p^2 + p^3 - p^3 \\
&= (p - 1) + p(p - 1) + p^2(p - 1) - p^3 \\
&\text{(Generalizing the above pattern)} \\
-1 &= (p - 1) + p(p - 1) + p^2(p - 1) + p^3(p - 1) + p^4(p - 1) + \cdots \\
\end{aligned}
$$

This now gives us access to negative numbers, since we can formally multiply
the series of two numbers, to write $-a = -1 \cdot a$.


Notice that this definition of $-1$ also curiously matches the 2s complement
definition, where we have $-1 = 11\dots 1$. In this case, the expansion is
_infinite_, while in the 2s complement case, it is finite. I would be very
interested to explore this connection more fully.

#### What have we achieved so far?

We've now managed to completely reinterpret all the numbers we care about in
the rationals as power series in base $p$. This is pretty neat. We're next
going to try to _complete_ this, just as we complete the rationals to get
the reals. We're going to show that we get a _different_ number system on
completion, called $\mathbb Q_p$.

To perform this, we first look at how the $p$-adic numbers help us solve
congruences mod p, and how this gives rise to completions to equations such
as $x^2 - 2 = 0$, which in the reals give us $x = \sqrt 2$, and in $\mathbb Q_p$
give us a different answer!

#### Solving $X^2 \equiv 25 \mod 3^n$

Let's start by solving an equation we already know how to solve:
$X^2 \equiv 25 \mod 3^n$.

We already know the solutions to $X^2 \equiv 25 \mod 3^n$ in $\mathbb Z$ are
$X \equiv \pm 5 \mod 3^n$.

Explicitly, the solutions are:
- $X \equiv 3 \mod 3$
- $X \equiv 5 \mod 9$
- $X \equiv 5 \mod 27$
- At this point, the answer remains constant.

This was somewhat predictable. We move to a slightly more interesting case.

#### Solving $X = -5 \mod 3^n$

The solution sets are:
- $X \equiv -5 \equiv 1 \mod 3$
- $X \equiv -5 \equiv 4 = 1 + 3 \mod 9$
- $X \equiv -5 \equiv 22 = 1 + 3 + 2 \cdot 9 \mod 27$
- $X \equiv -5 \equiv 76 = 1 + 3 + 2 \cdot 9 + 2 \cdot 27 \mod 81$



This gives us the infinite 3-adic expansion:

- $X = -5 = 1 + 1\cdot 3 + 2\cdot 3^2 + 2\cdot 3^3 + \dots$

Note that we can't really _predict_ the digits in the 3-adic sequence of -5,
but we can keep expanding and finding more digits.

Also see that the solutions are "coherent". In that, if we look at the
solution mod 9, which is $4$, and then consider it mod 3, we get $1$. So,
we can say that given a sequence of integers $0 \leq \alpha_n \leq p^n - 1$,
**$\alpha_n$ is p-adically coherent sequence** iff:

- $ \alpha_{n+1} = \alpha_n \mod p^n$.


#### Viewpoint: Solution sets of $X^2 = 25 \mod 3^n$

Since our solution sets are coherent, we can view the solutions as a tree,
with the expansions of $X = 5, X = -5 \mod 3$ and then continuing onwards
from there. That is, the sequences are

- $2 \rightarrow 5 \rightarrow 5 \rightarrow 5 \rightarrow \dots$
- $1 \rightarrow 4 \rightarrow 22 \rightarrow 76 \rightarrow \dots$

#### Solving $X^2 \equiv 2 \mod 7^n$

We now construct a solution to the equation $X^2 = 1$ in the 7-adic system,
thereby showing that $\mathbb Q_p$ is indeed strictly _larger_ than $\mathbb Q$,
since this equation does not have rational roots.

For $n=1$, we have the solutions as $X \equiv 3 \mod 7$, $X \equiv 4 \equiv -3 \mod 7$.

To find solutions for $n = 2$, we recall that we need our solutions to be consistent
with those for $n = 1$. So, we solve for:
- $(3 + 7k)^2 = 2 \mod 49$, $(4 + 7k)^2 = 2 \mod 49$.

Solving the first of these:

$$
\begin{aligned}
(3 + 7k)^2 &\equiv 2 \mod 49 \\
9 + 42 k + 49k^2 &\equiv 2 \mod 49 \\
9 + 42 k + 0k^2 &\equiv 2 \mod 49 \\
7 + 42 k &\equiv 0 \mod 49 \\
1 + 6 k &\equiv 0 \mod 49 \\
k &\equiv 1 \mod 49
\end{aligned}
$$

This gives the solution $X \equiv 10 \mod 49$. The other branch ($X = 4 + 7k$)
gives us $X \equiv 39 \equiv -10 \mod 49$.

We can continue this process indefinitely (_exercise_), giving us the sequences:

- $3 \rightarrow 10 \rightarrow 108 \rightarrow 2166 \rightarrow \dots$
- $4 \rightarrow 39 \rightarrow 235 \rightarrow 235 \rightarrow \dots$

We can show that the sequences of solutions we get satisfy the equation
$X^2 = 2 \mod 7$. This is so by construction. Hence, $\mathbb Q_7$ contains
a solution that $\mathbb Q$ does not, and is therefore strictly bigger, since
we can already represent every rational in $\mathbb Q$ in $\mathbb Q_7$.


#### Use case: Solving $X = 1 + 3X$ as a recurrence

Let's use the tools we have built so far to solve the equation $X = 1 + 3X$.
Instead of solving it using algebra, we look at it as a recurrence $X_{n+1} = 1 + 3X_n$.
This gives us the terms:
- $X_0 = 1$
- $X_1 = 1 + 3$
- $X_2 = 1 + 3 + 3^2$
- $X_n = 1 + 3 + \dots + 3^n$

In $\mathbb R$, this is a divergent sequence. However, we know that the
solution so $1 + X + X^2 + \dots = 1/(1-X)$, at least as a generating function.
Plugging this in, we get that the answer should be:

- $1/(1 - 3) = -1/2$

which is indeed the correct answer.

Now this required some really shady stuff in $\mathbb R$. However, with a change
of viewpoint, we can explain what's going on. We can look at the above series
as being a series in $\mathbb Q_3$.  Now, this series does _really_ converge,
and by the same argument as above, it converges to $-1/2$.

The nice thing about this is that a dubious computation becomes a legal one
by changing one's perspective on where the above series lives.

#### Viewpoint: 'Evaluation' for p-adics

The last thing that we need to import from the theory of polynomials
is the ability to _evaluate_ them: Given a rational function $F(X) = P(X)/Q(X)$,
where $P(X), Q(X)$ are polynomials, we can
evaluate it at some arbitrary point $x_0$, as long as $x_0$ is not a zero
of the polynomial $Q(X)$.

We would like a similar function, such that for a fixed prime $p$, we obtain
a ring homomorphism from $\mathbb Q \rightarrow \mathbb F_p^x$, which we will
denote as $p(x_0)$, where we are imagining that we are "evaluating" the prime
$p$ against the rational $x_0$.

We define the value of $x_0 = a/b$ at the prime $p$ to be equal to
$ab^{-1} \mod p$, where $b b^{-1} \equiv 1 \mod p$. That is, we compute the
usual $ab^{-1}$ to evaluate $a/b$, except we do this $(\mod p)$, to stay with
the analogy.

Note that if $b \equiv 0 \mod p$, then we cannot evaluate
the rational $a/b$, and we say that $a/b$ has a pole at $p$. The order
of the pole is the number of times $p$ occurs in the prime factorization of $b$.

I'm not sure how profitable this viewpoint is, so I
[asked on math.se](https://math.stackexchange.com/questions/3483369/profit-of-definition-evaluation-of-a-rational-at-a-p-adic),
and I'll update this post when I recieve a good answer.


#### Perspective: Forcing the formal sum to converge by imposing a new norm:

So far, we have dealt with infinite series in base $p$, which have terms
$p^i, i \geq 0$.
Clearly, these sums are divergent as per the usual topology on $\mathbb Q$.
However, we would enjoy assigning analytic meaning to these series. Hence, we
wish to consider a new notion of the absolute value of a number, which makes it
such that $p^i$ with large $i$ are considered small.


We define the absolute value for a field $K$ as a function
$|\cdot |: K \rightarrow \mathbb R$. It obeys the axioms:


1. $\lvert x \rvert = 0 \iff x = 0$
2. $\lvert xy \rvert =  \lvert x \rvert  \lvert y \rvert$ for all $x, y \in K$
3. $\lvert x + y \rvert \leq \lvert x \rvert + \lvert y \rvert$, for all $x, y \in K$.


We want the triangle inequality so it's metric-like, and the norm to be
multiplicative so it measures the size of elements.

The usual absolute value $\lvert x \rvert \equiv \\{ x : x \geq 0; -x : ~ \text{otherwise} \\}$ satisfies
these axioms.

Now, we create a new absolute value that measures primeness. We first introduce
a gadget known as a valuation, which measures the $p$-ness of a number. We use
this to create a norm that makes number smaller as their $p$-ness increases.
This will allow infinite series in $p^i$ to converge.

#### p-adic valuation: Definition

First, we introduce
a valuation $v_p: \mathbb Z - \\{0\\} \rightarrow \mathbb R$, where $v_p(n)$ is
the power of the prime $p^i$ in the prime factorization of $n$. More formally,
$v_p(n)$ is the unique number such that:

- $n = p^{v_p(n)} m$, where $p \nmid m$.
- We extend the valuation to the rationals by defining $v_p(a/b) = v_p(a) - v_p(b)$.
- We set $v_p(0) = +\infty$. The intuition is that $0$ can be divided by $p$
  an infinite number of times.

The valuation gets larger as we have larger powers of $p$ in the prime
factorization of a number. However, we want the norm to get _smaller_. Also,
we need the norm to be multiplicative, while $v_p(nm) = v_p(n) + v_p(m)$, which
is additive.


To fix both of these, we create a norm by exponentiating $v_p$.
This converts the additive property into a multiplicative property. We
exponentiate with a negative sign so that higher values of $v_p$ lead to
smaller values of the norm.

#### p-adic abosolute value: Definition

Now, we define the **p-adic absolute value** of a number $n$ as
$|n|_p \equiv p^{-v_p(n)}$.

- the norm of $0$ is $p^{-v_p(0)} = p^{-\infty} = 0$.
- If $p^{-v_p(n)} = 0$, then $-v_p(n) = \log_p 0 = -\infty$, and hence $n = 0$.
- The norm is multiplicative since $v_p$ is additive.
- Since $v_p(x + y) \geq \min (v_p(x), v_p(y)), |x + y|_p \leq max(|x|_p, |y|_p) \leq |x|_p + |y|_p$.
  Hence, the triangle inequality is also satisfied.

So $|n|_p$ is indeed a norm, which measures $p$-ness, and is smaller as $i$
gets larger in the power $p^i$ of the factorization of $n$, causing our
infinite series to converge.

There is a question of why we chose a base $p$ for $|n|_p = p^{v_p(n)}$. It would
appear that any choice of $|n|_p = c^{v_p(n)}, c > 1$ would be legal.
[I asked this on `math.se`](https://math.stackexchange.com/questions/3482489/why-does-the-p-adic-norm-use-base-p),
and the answer is that this choosing a base $p$ gives us the nice formula

$$
\forall x \in \mathbb Z, \prod_{\{p : p~\text{is prime}\} \cup \{ \infty \}} |x|_p = 1
$$

That is, the product of all $p$ norms and the usual norm
(denoted by $\lvert x \rvert_\infty $ )
give us the number 1. The reason is that the $ \lvert x\rvert_p $ give us
multiples $p^{-v_p(x)}$,
while the usual norm $\lvert x \rvert_\infty$ contains a multiple
$p^{v_p(x)}$, thereby cancelling each other out.


#### Conclusion

What we've done in this whirlwind tour is to try and draw analogies between
the ring of polynomials $\mathbb C[X]$ and the ring $\mathbb Z$, by trying
to draw analogies between their prime ideals: $(X - \alpha)$ and $(p)$. So,
we imported the notions of generating functions, polynomial evaluation, and
completions (of $\mathbb Q$) to gain a picture of what $\mathbb Q_p$ is like.

We also tried out the theory we've built against some toy problems, that shows
us that this point of view maybe profitable. If you found this interesting,
I highly recommend the book
[p-adic numbers by Fernando Gouvea](https://www.springer.com/gp/book/9783540629115).



# Line of investigation to build physical intuition for semidirect products

To quote wikipedia:
> In crystallography, the space group of a crystal splits as the semidirect
> product of the point group and the translation group if and only if the space
> group is symmorphic

The if and only if is interesting: The geometry ofthe crystal lattice truly
appears to capture the structure of the semidirect product. It's a discrete
object as well, which makes it way easier to visualize. I'm going to hunt down
the definitions involved so I can finally feel like I truly understand semidirect
products from the "action" perspective.

# Topology is really about computation --- part 2

Here, we're going to describe whatever I've picked up of sheaves in the past
couple of weeks. I'm trying to understand the relationship between sheaves,
topoi, geometry, and logic. I currently see how topoi allows us to model logic,
and how sheaves allow us to model geometry, but I see nothing about the
relationship! I'm hoping that writing this down will allow me to gain some
perspective on this.

### What is a sheaf?

Let's consider two sets $P, A$, $P \subseteq A$. Now, given a function
$f: A \rightarrow X$, we can restrict this function to $ A_P: P \rightarrow X $.
So, we get to _invert the direction_:

$$
(P \subseteq A) \iff (f: A \rightarrow X) \rightarrow (f_P: P \rightarrow X)
$$

We should now try to discover some sort of structure to this "reversal"
business. Perhaps we will discover a contravariant functor! (Spoiler: we will).


# Topology is really about computation --- part 1

Most people believe that topology is about some notion of "nearness" or
"closeness", which has been abstracted out from our usual notion of
continuity that we have from a metric space. Here, I make the claim that
topology is really about _computation_, and more specifically, _decidability_.
These are not new ideas. I learnt of this from a monograph 
[Synthetic topology of data types and classical spaces. Martın Escardo](https://www.cs.bham.ac.uk/~mhe/papers/entcs87.pdf).
This does not seem very well known, so I decided to write about it.

The idea is this: We have turing machines which can compute things. We then
also have a set $S$. Now, a topology $\tau \subset 2^S$ precisely encodes
which of the subsets of $S$ can be separated from the rest of the space by a turing machine.
Thus, a discrete space is a very nice space, where every point can be separated
from every other point. An indescrete space is one where no point can be separated.

Something like the reals is somewhere in between, where we can separate
stuff inside an open interval from stuff clearly outside, but there's some
funny behaviour that goes on at the boundary due to things like `(0.999... = 1)`,
which we'll see in detail in a moment.

#### Semidecidability

A subset $Q\subseteq S$ is _semidecidable_, if there exists a turing machine
$\hat Q: Q \rightarrow \{ \bot, \top \}$, such that:

$$
\begin{aligned}
\hat Q(q) = \top \iff q \in Q \\
\hat Q(q) = \bot \iff q \notin Q \\
\end{aligned}
$$

Where $\top$ signifies stopping at a state and returning `TRUE`, and
$\bot$ signifies _never halting at all_!. So, the subset $Q$ is
_semidedicable_, in that, we will halt and say `TRUE` if the element
belongs in the set. But if an element does not belong in the set, we are
supposed to never terminate.

#### Deep dive: semidecidability of the interval $(1, 2)$

Let's start with an example. We consider the interval $I = (1, 2)$, as a
subset of $\mathbb{R}$.Let the turing machine recieve the real number
as a function $f: \mathbb N \rightarrow \{0, 1, \dots 9\}$, such that
given a real number ${(a_0 \cdot a_1 \cdot a_2 \dots)}$, this is encoded as a
function ${f_a(i) = a_i}$.

We now build a turing machine $\hat I$ which when given the input the function $f_a$,
semi-decides whether ${a \in I}$.

Let's consider the numbers in $I$:

$$
\begin{aligned}
&0 \rightarrow \texttt{NO} \\
&0.\overline{9} \rightarrow \texttt{NO} \\
&1.00\dots \rightarrow \texttt{NO} \\
&1.a_1 a_2 \dots \rightarrow \texttt{YES} \\
&1.\overline{9} \rightarrow \texttt{NO} \\
&2.0 \rightarrow \texttt{NO} \\
&2.a_1 a_2 \rightarrow \texttt{NO}
\end{aligned}
$$

So, we can write a turing machine (ie, some code) that tries to decide whether
a real number $a$'s encoding $f_a$ belongs to the interval $I = (1, 2)$
as follows:

```py
def decide_number_in_open_1_2(f):
  # if the number is (1.abcd)
  if f(0) == 1:
    # (1.0...0<NOT0>) | look for the <NOT0>
    # If the number is 1.00..., do not terminate.
    if f(1) == 0: while f(i) == 0: i += 1
    # (1.99...9<NOT9>) | look for the <NOT9>
    # If the number is 1.99..., do not terminate.
    if f(1) == 9:  while f(i) == 9: i += 1 
    else: return
    return
  # if the number is not 1.abcd, do not terminate
  while True: pass
```

Hence, we say that the interval $I = (1, 2)$ is _semi-decidable_, since we
have a function
$\hat I \equiv \texttt{decide-number-in-open-1-2}$
such that
$\hat I (f_a) \text{ terminates } \iff a \in I$.
We don't make _any claim_ about
what happens if $a \notin I$. This is the essence of semidecidability: We
can precisely state when elements in the set belong to the set, but not
when they don't.

### Semi decidability in general

To put this on more solid ground, we define a topology on a set $S$ by considering
programs which recieve as input elements of $S$, suitably encoded. For example,
the way in which we encoded real numbers as functions from the index to the
digit. Similarly, we encode other mathematical objects in some suitable way.

Now, we define:

- For every program $P$ which takes as inputs elements in $S$, the set
  ${halts(P) \equiv \\{ s \in S \vert P(s) \text{halts} \\}}$ is called as a
  _semidecidable set_.

- Alternatively, we can say for a subset ${T \subset S}$, if there
  exists a program ${\hat T}$, such that
  ${s \in T \iff \hat T(s) \text{ halts}}$, then $T$ is semi-dedecidable.

These are just two viewpoints on the same object. In one, we define the
set based on the program. In the other, we define the program based on the
set.

### Semi decidability of the empty set and the universe set.

The empty set is semi-decidable, due to the existence of the program:
```py
def semidecide_empty(x):
  while True: continue
```


The universe set is semi-decidable, due to the existence of the program:
```py
def semidecide_univ(x): return
```

### Semi decidability of the union of sets

infinite unions of sets are semi decidable, since we can "diagonalize" on
the steps of all programs. That way, if any program halts, we will reach
the state where it halts in our diagonalized enumeration.



Let `A00, A01... A0n` be the initial states of the machines. We are trying to
semidecide whether any of them halt. We lay out the steps of the machines
in an imaginary grid:

```
A00 A01 A02 ... A0n
A10 A11 A12 ... A1n
A20 A21 A22 ... A2n
Am0 Am1 Am2 ... Amn
```

For example, machine `A0` has states:

```
A00 -> A10 -> .. -> Am0
```
We can walk through the combined state-space of the machines as:

```
A00
A01 A10
A02 A11 A20
A03 A12 A21 A30
...
```

Where on the `k`'th line, we collect all states $A_{ij}$ such that $(i + j = k)$.

Now, if any of the machines have a state that is `HALT`, we will reach the
state as we enumerate the diagonals, and the machine that explores the
combined state space can also return `HALT`.

### Semi decidability of the intersection of sets

infinite intersections of sets are _not_ semi decidable, since by running
these programs in parallel, we cannot know if an infinite number of programs
halt in finite time. We _can_ tell if _one_ of them halts, but of if _all_
of them halt.

For example, consider the sequence of machines produced by `machine_creator`:

```py
# creates a machine that stops after n steps
def machine_creator(n):
    # f terminates after n steps
    def f(x):
      for _ in range(n):
        continue
    return

    return f
```

We wish to check if the intersection of all `machine_creator(n)` halt, for all
$n \geq 0, n \in \mathbb N$. Clearly, the answer is an infinite number of steps,
even though every single machine created by `machine_creator` halts in a
finite number of steps.

### An even deeper dive: re-examining the topology of the reals

We generally think of the topology of reals as being generated from the
base of intervals $(a, b)$. But really, this is a perverse perspective
from the point of view of computation.

Structurally speaking, the only comparison operator we have on the reals
is a $<$ operator. So we should ideally start by taking as a base
the sets $(-\infty, r)$. This is elegant, because:
1. it relates to the order theoretic notion of [downward closed set](https://en.wikipedia.org/wiki/Upper_set)
2. [By yoneda](https://math.stackexchange.com/a/37209/261373), the downward closed set $(-\infty, r)$ contains the exact same order theoretic information as $r$ itself.
3. It makes our "code" easier to write:

```
z = 10 # arbitrary fixed integer
def is_in_downward_closed_set(x_int, x_frac):
    """
    return true if x_int.x_frac < z
    """
    if x_int < z:
        i = 0
        while True:
           elif x_frac[i] == 9: i += 1 # examine next number.
           else: return True # x_frac[i] < r_frac[i]
    else:
        # loop forever
        loop()

def loop(): while True: pass
```

#### References
- [Synthetic topology of data types and classical spaces. Martın Escardo](https://www.cs.bham.ac.uk/~mhe/papers/entcs87.pdf)

# PSLQ algorithm: finding integer relations between reals

An algorithm to find _integer_ relations between _real_ numbers. It was
apparently named "algorithms of the century" by Computing in science and
engineering.

- [Wolfram link](http://mathworld.wolfram.com/PSLQAlgorithm.html)

# Geometric characterization of normal subgroups
> $Stab(Orb(x)) = Stab(x) \iff Stab(x) \text{ is normal}$

> $\forall x' \in Orb(x), Stab(x') = Stab(x) \iff Stab(x) \text{ is normal}$


#### Forward: if the stabilizer is normal, then all elements in the orbit have the same stabilizer

Let a group $G$ act on a set $X$ with action $(~\dot~) : G \times X \rightarrow X$.
Let $H \subseteq G$ be the stabilizer of a point $x \in X$. Now, let
$K = kHk^{-1}$, a conjugacy class of $H$. Clearly, the element $(k \cdot x)$
in the orbit of $x$ is stabilized by $K$.

If the group $H$ is normal, then $K = H$. So every element in the orbit of $x$
is stabilized by $H$.

#### Interaction of stablizer and the orbit:

> $Stab(g \cdot x) = g Stab(x) g^{-1}$

> $g^{-1} Stab(g \cdot x) g = Stab(x)$

-  Proof of $s \in Stab(x) \implies gsg^{-1} \in Stab(g \cdot x)$:
   The action of $gsg^{-1}$ on $g \cdot x$ is:
   $(g \cdot x \rightarrow_{g^-1} x \rightarrow_s x \rightarrow_g g \cdot x)$.

- Proof of $s' \in Stab(g \cdot x) \implies g^{-1}s'g \in Stab(x)$:
  The action of $g^{-1}s'g$ on $x$ is:
  $(x \rightarrow_{g} g \cdot x \rightarrow_{s'} g \cdot x \rightarrow_{g^{-1}} x)$.

Hence, both containments are proved.

#### Backward: if all elements in the orbit have the same orbit, then the stabilizer is normal.

From the above equation $Stab(g \cdot x) = g Stab(x) g^{-1}$. If the
entire orbit has the same stabilizer, $Stab (g \cdot x) = Stab(x)$. Hence,
we get $Stab(x) = g Stab(x) g^{-1}$, proving that it's normal.

# Handy characterization of adding an element into an ideal, proof that maximal ideal is prime

##### The characterization

Let $I$ be an ideal. The ideal generated by adding $(a \in R)$ to $I$ is
defined as $A \equiv (I \cup \{ a\})$. We prove that $A = I + aR$.


$$
\begin{aligned}
&(I \cup \{a \})  \\
&= \quad \{ \alpha i + \beta a | i \in I, \alpha, \beta \in R \} \\
&= \quad \{ i' + \beta a | i' \in I, \alpha, \beta \in R \} \qquad \text{($I$ is closed under multiplication by $R$)} \\
&= I + aR
\end{aligned}
$$

##### Quotient based proof that maximal ideal is prime

An ideal $P$ is prime iff the quotient ring $R/P$ is an integral domain. An
ideal $M$ is maximal $R/M$ is a field. Every field is an integral domain,
hence:

$M \text{ is maximal } \implies R/M \text{ is a field } \implies R/M \text {is an integral domain} \implies M \text{ is prime}$.

I was dissatisfied with this proof, since it is not ideal theoretic: It argues
about the behaviour of the quotients. I then found this proof that argues
purly using ideals:

#### Ideal theoretic proof that maximal ideal is prime

##### Sketch
Let $I$ be a maximal ideal. Let $a, b \in R$ such that $ab \in I$. We need
to prove that $a \in I \lor b \in I$. If $a \in I$, the problem is done.
So, let $a \notin I$. Build ideal $A = (I \cup {a})$. $I \subsetneq A$. Since
$I$ is maximal, $A = R$. Hence, there are solutions for
$1_R \in A \implies 1_r \in I + aR \implies \exists i \in I, r \in R, 1_R = i  + ar$.
Now, $b = b \cdot 1_R = b(i + ar) = bi + (ba)r \in I + IR = I$. ($ba \in I$ by assumption).
Hence, $b \in I$.


##### Details

let $i$ be a maximal ideal. let $a, b \in r$ such that $ab \in i$. we need
to prove that $a \in i \lor b \in i$.

if $a \in i$, then the problem is done. so, let $a \notin i$. consider
the ideal $A$ generated by adding $a$ into $I$. $A \equiv (I \cup \{a\})$.

We have shown that $A = I + aR$. Hence, $I + a0 = I \subset A$.
Also, $0 + ac \dot 1 = a \in A$, $a \neq I$ \implies $A \neq I$. Therefore,
$I \subsetneq A$. Since $I$ is maximal, this means that $A = R$

Therefore, $I + aR = R$. Hence, there exists some $i \in I, r \in R$ such
that $i + ar = 1_R$.

Now, $b = b \cdot 1_R = b \cdot (i + ar) = bi + (ba) r \in I + IR = I$ Hence,
$b \in I$.



# Radical ideals, nilpotents, and reduced rings

##### Radical Ideals
A radical ideal of a ring $R$ is an ideal such that
$\forall r \in R, r^n \in I \implies r \in I$.
That is, if any power of $r$ is in $I$, then the element
$r$ also gets "sucked into" $I$.

##### Nilpotent elements
A nilpotent element of a ring $R$ is any element $r$ such that there exists
some power $n$ such that $r^n = 0$.

Note that every ideal of the ring contains $0$. Hence, if an ideal $I$
of a ring is known to be a radical ideal, then for any nilpotent $r$,
since $\exists n, r^n = 0 \in I$, since $I$ is radical, $r \in I$.

That is, _a radical ideal with always contain all nilpotents!_ It will
contain other elements as well, but it will contain nilpotents for sure.

##### Radicalization of an ideal
Given a ideal $I$, it's radical idea $\sqrt I \equiv \{ r \in R, r^n \in I \}$.
That is, we add all the elements $I$ needs to have for it to become a radical.

Notice that the radicalization of the zero ideal $I$ will precisely contain
all nilpotents. that is, $\sqrt{(0)} \equiv \{ r \in R, r^n = 0\}$.

##### Reduced rings
A ring $R$ is a reduced ring if the only nilpotent in the ring is $0$.

##### creating reduced rings (removing nilpotents) by quotienting radical ideals
Tto remove nilpotents of the ring $R$, we can create $R' \equiv R / \sqrt{(0}$. Since
$\sqrt{(0)}$ is the ideal which contains all nilpotents, the quotient ring $R'$ will contain
no nilpotents other than $0$.

Similarly, quotienting by any larger radical ideal $I$ will remove all nilpotents
(and then some), leaving a reduced ring.

> A ring modulo a radical ideal is reduced

##### Integral domains
a Ring $R$ is an integral domain if $ab = 0 \implies a = 0 \lor b = 0$. That is,
the ring $R$ has no zero divisors.

##### Prime ideals

An ideal $I$ of a ring $R$ is a prime ideal if
$\forall xy \in R, xy \in I \implies x \in I \lor y \in I$. This generalizes
the notion of a prime number diving a composite: $p | xy \implies p | x \lor p | y$.

##### creating integral domains by quotenting prime ideals

Recall that every ideal contains a $0$. Now, if an ideal $I$ is prime, and if
$ab = 0 \in I$, then either $a \in I$ or $b \in I$ (by the definition of prime).

We create $R' = R / I$. We denote $\overline{r} \in R'$ as the image of $r \in R$
in the quotient ring $R'$.

The intuition is that quotienting by a  $I$, since if $ab = 0 \implies a \in I \lor b \in I$,
we are "forcing" that in the quotient ring $R'$, if $\overline{a} \overline{b} = 0$, then either
$\overline{a} = 0$ or $\overline{b} = 0$, since $(a \in I \implies \overline a = 0)$,
and $b \in I \implies \overline b = 0)$.

> A ring modulo a prime ideal is an integral domain.


I learnt of this explanation from this
[excellent blog post by Stefano Ottolenghi](http://quickmathintuitions.org/relationship-between-reduced-rings-radical-ideals-and-nilpotent-elements/).

# My disenchantment with abstract interpretation

When I first ran across the theory of abstract interpretation, it seemed magical:
Define two functions, check that they're monotone maps, and boom, we have
on our hands an analysis.

However, the problem appears to be that in reality, it's not as simple. Here is
the list of issues I've run across when trying to use abstract interpretation
for a "real world" use-case:


First of all, all interesting lattices are infinte height, requiring some
choice of widening.  Defining a good widening is a black art.  Secondly, while
there is a lot of theory on combining abstract domains (reduced products and
the like), it seems hard to deploy the theory in the real world.

I read a fair bit into the theory of abstract acceleration, where the idea is
that instead of widening indiscriminately, if our theory is powerful enough to
compute an exact closed form, we choose to do so. However, the problem is that
this regime does not "fit well" into abstract interpretation: We have the
abstract interpreter on the one hand, and then the acceleration regime on the
other, which is a separate algorithm. So the full analysis looks something
like:

```python
def analyze(program):
  analysis = {}
  for loop in inner to outer:
     loop_data = abstract_interpret(loop)
     analaysis.append(accelerate(loop))
  return analysis
```

That is, what used to be a nice theory of just "do things in any order and
it will converge", now becomes a new algorithm, that uses abstract interpretation
as a subroutine. This was not the hope I had! I wanted to _get away_ from having
to do proofs by analyzing an algorithm, this was the entire promise: Define
a lattice well enough and the proof is guaranteed. Rather, what I had
imagined was:

```python
def analyze(program):
  return abstract_interpret_using_acceleration_domain(program)
```

Now this `acceleration_domain` maybe frightfully complicated, but I'm willing
to pay that price, as long as it's an honest-to-god abstract interpretation.
This was a huge bummer for me to find out that this is not the case.


# Computing equivalent gate sets using grobner bases

Here's a fun little problem, whose only solution I know involves a fair
bit of math and computer algebra:

We are given the grammar for a language `L`:

```
E = T +_mod8 E | T -_mod8 E | T
T = V | V ^ V | V ^ V ^ V
V = 'a1' | 'a2' | ...
```


where `+_mod8` is addition modulo 8, `-_mod8` is subtraction modulo 8,
and `^` is XOR.

This language is equipped with the obvious
evaluation rules, corresponding to those of arithmetic. We are guaranteed
that during evaluation, the variables `a_i` will only have values `0` and `1`.
Since we have addition, we can perform multiplication by a constant
by repeated addition. So we can perform `3*a` as `a+a+a`.


We are then given the input expression `(a0 ^ a1 ^ a2 ^ a3)`. We wish
to find an equivalent expression in terms of the above language `L`.

We think of `E` as some set of logic gates we are allowed to use, and we are
trying to express the operation `(a0 ^ a1 ^ a2 ^ a3)` in terms of these gates.

The first idea that I thought was that of employing a grobner basis,
since they essentially embody rewrite rules modulo polynomial equalities, which
is precisely our setting here.

In this blog post, I'm going to describe what a grobner basis is and why it's
natural to reach for them to solve this problem, the code, and the eventual
solution.

As a spolier, the solution is:

```
a^b^c^d =
-a - b + c + 3*d - 3*axorb - axorc
+ axord - bxorc + bxord + 3*cxord
- 3*axorbxorc - axorbxord
+ axorcxord + bxorcxord
```

Clearly, this contains only additions/subtractions and multiplications by
a constant.

If there's some principled way to derive this (beyond throwing symbolic
algebra machinery), I'd really love to know ---
[Please raise an issue with the explanation!](https://github.com/bollu/bollu.github.io/issues)

##### What the hell is Grobner Basis?

The nutshell is that a grobner basis is a way to construct rewrite rules which
also understand arithmetic (I learnt this viewpoint from the book "Term
rewriting and all that". Fantastic book in general). Expanding on the
nutshell, assume we have a term rewriting system:

```
A -> -1*B -- (1)
C -> B^2  -- (2)
```

over an alphabet `{A, B, C}`.

Now, given the string `C + AB`, we wish to find out if it can be rewritten to
`0` or not. Let's try to substitute and see what happens:

```
C + AB -2-> B^2 + AB -1-> B^2 + (-1*B)B
```

At this point, we're stuck! we don't have rewrite rules to allow us to
rewrite `(-1*B)B` into `-B^2`. Indeed, creating such a list would be
infinitely long. But if we are willing to accept that we somehow have
the rewrite rules that correspond to polynomial arithmetic, where we view
`A, B, C` as variables, then we _can_ rewrite the above string to 0:

```
B^2 + (-1*B)B -> B^2 - B^2 -> 0
```

A Grobner basis is the algorithmic / mathematical machine that allows us
to perform this kind of substitution.

In this example, this might appear stupid: what is so special? We simply
substituted variables and arrived at `0` by using arithmetic. What's
so complicated about that? To understand why this is not always so easy,
let's consider a pathological, specially constructed example


##### A complicated example that shatters dreams

Here's the pathological example:

```
A -> 1     -- (1)
AB -> -B^2 -- (2)
```

And we consider the string `S = AB + B^2`.  If we blindly apply the
first rule, we arrive at:

```
S = AB + B^2 -1-> 1B + B^2 = B + B^2 (STUCK)
```

However, if we apply `(2)` and then `(1)`:

```
S = AB + B^2 -2-> -B^2 + B^2 -> 0
```

This tells us that we _can't just apply the rewrite rules willy-nilly_.
It's sensitive to the _order_ of the rewrites! That is, the rewrite system
is not [confluent](https://en.wikipedia.org/wiki/Confluence_(abstract_rewriting)).


The grobner basis is a function from rewrite systems to rewrite systems.
When given a rewrite system `R`, it produces a _new_ rewrite system `R'`
that _is confluent_. So, we can apply the rewrite rules of `R'` in any order,
and we guaranteed that we will only get a 0 from `R'` if and only if
we could have gotten a `0` from `R` for all strings.

We can then go on to phrase this whole rewriting setup in the language of
ideals from ring theory, and that is the language in which it is most
often described. I've gone into more depth on that perspective here: 
["What is a grobner basis? polynomial factorization as rewrite systems"](#what-the-hell-is-a-grobner-basis-ideals-as-rewrite-systems).

Now that we have a handle on what a grobner basis is, let's go on to solve
the original problem:


##### An explanation through a slightly simpler problem

I'll first demonstrate the idea of how to solve the original problem
by solving a slightly simpler problem:

> Rewrite `a^b^c` in terms of `a^b`, `b^c`, `c^a` and the same `+_mod8` instruction
> set as the original problem. The only difference this time
> is that we do _not_ have `T -> V ^ V ^ V`.


The idea is to construct the polynomial ring over `Z/8Z` (integers modulo 8) with
variables as `a, b, c, axorb, bxorc, axorc`. Now, we know that `a^b = a + b - 2ab`. So,
we setup rewrite rules such that `a + b - 2ab -> axorb`, `b + c - 2bc -> bxorb`,
`c + a - 2ca -> cxora`.


We construct the _polynomial_ `f(a, b, c) = a^b^c`, which
has been written in terms of addition and multiplication, defined
as `f_orig(a, b, c) = 4*a*b*c - 2*a*b - 2*a*c - 2*b*c + a + b + c`. We then
rewrite `f_orig` with respect to our rewrite rules. Hopefully, the rewrite
rules should give us a clean expression in terms of one variable and
two-variable `xor`s. There is the danger that we may have some term
such as `a * bxorc`, and we do get such a term (`2*b*axorc`) in this case,
but it does not appear in the _original_ problem.



```py
# Create ring with variables a, b, c, axorb, bxorc, axorc
R = IntegerModRing(8)['a, b, c, axorb, bxorc, axorc']
(a, b, c, axorb, bxorc, axorc) = R.gens()


# xor of 2 numbers as a polynomial
def xor2(x, y): return x + y - 2*x*y

# xor of 3 numbers as a polynomial
def xor3(x, y, z): return xor2(x, xor2(y, z))

# define the ideal which contains relations:
# xor2(a, b) -> axorb, xor2(b, c) -> bxorc, xor2(a, c) -> axorc
# we also add the relation (a^2 - a = 0 => a = 0 or a = 1)
# since we know that our variables are only {0, 1}
I = ideal((axorb - xor2(a, b), bxorc - xor2(b, c), axorc - xor2(a, c), a*a-a, b*b-b, c*c-c))

# the polynomial representing a^b^c we wish to reduce
f_orig = xor3(a, b, c)

# we take the groebner basis of the ring to reduce the polynomial f.
IG = I.groebner_basis()

# we reduce a^b^c with respect to the groebner basis.
f_reduced = f_orig.reduce(IG)

print("value of a^b^c:\n\t%s\n\treduced: %s" % (f_orig, f_reduced))

# Code to evaluate the function `f` on all inputs to check correctness
def evalxor2(f):
    for (i, j, k) in [(i, j, k) for i in [0, 1] for j in [0, 1] for k in [0, 1]]:
      ref = i^^j^^k
      eval = f.substitute(a=i, b=j, c=k, axorb=i^^j, bxorc=j^^k, axorc=i^^k)
      print("%s^%s^%s: ref(%s) =?= f(%s): %s" %
        (i, j, k, ref, eval, ref == eval))

# check original formulation is correct
print("evaulating original f for sanity check:")
evalxor2(f_orig)

# Check reduced formulation is correct
print("evaulating reduced f:")
evalxor2(f_reduced)
```

Running the code gives us the reduced polynomial `-2*b*axorc + b + axorc`
which unfortunately contains a term that is `b * axorc`. So, this approach
does not work, and I was informed by my friend that she is unaware
of a solution to this problem (writing `a^b^c` in terms of smaller xors and
sums).


The full code output is:

```
value of a^b^c:
	4*a*b*c - 2*a*b - 2*a*c - 2*b*c + a + b + c
	reduced: -2*b*axorc + b + axorc
evaulating original f for sanity check:
0^0^0: ref(0) =?= f(0): True
0^0^1: ref(1) =?= f(1): True
0^1^0: ref(1) =?= f(1): True
0^1^1: ref(0) =?= f(0): True
1^0^0: ref(1) =?= f(1): True
1^0^1: ref(0) =?= f(0): True
1^1^0: ref(0) =?= f(0): True
1^1^1: ref(1) =?= f(1): True
evaulating reduced f:
0^0^0: ref(0) =?= f(0): True
0^0^1: ref(1) =?= f(1): True
0^1^0: ref(1) =?= f(1): True
0^1^1: ref(0) =?= f(0): True
1^0^0: ref(1) =?= f(1): True
1^0^1: ref(0) =?= f(0): True
1^1^0: ref(0) =?= f(0): True
1^1^1: ref(1) =?= f(1): True
```

That is, both the original polynomial and the reduced polynomial match
the expected results. But the reduced polynomial is not in our language `L`,
since it has a term that is a _product_ of `b` with `axorc`.


##### Tacking the original problem.

We try the exact same approach to the original problem of expressing
`a ^ b ^ c ^ d`. We find that the reduced polynomial is

```
-a - b + c + 3*d - 3*axorb - axorc
+ axord - bxorc + bxord + 3*cxord
- 3*axorbxorc - axorbxord
+ axorcxord + bxorcxord
```

which happily has no products between terms! It also passes our sanity
check, so we've now found the answer.

The full output is:
```
value of a^b^c^d:
	4*a*b*c + 4*a*b*d + 4*a*c*d + 4*b*c*d
      - 2*a*b - 2*a*c - 2*b*c - 2*a*d
      - 2*b*d - 2*c*d + a + b + c + d
reduced: -a - b + c + 3*d - 3*axorb
      - axorc + axord - bxorc + bxord
      + 3*cxord - 3*axorbxorc
      - axorbxord + axorcxord + bxorcxord
evaluating original a^b^c^d
0^0^0^0: ref(0) =?= f(0): True
0^0^0^1: ref(1) =?= f(1): True
0^0^1^0: ref(1) =?= f(1): True
0^0^1^1: ref(0) =?= f(0): True
0^1^0^0: ref(1) =?= f(1): True
0^1^0^1: ref(0) =?= f(0): True
0^1^1^0: ref(0) =?= f(0): True
0^1^1^1: ref(1) =?= f(1): True
1^0^0^0: ref(1) =?= f(1): True
1^0^0^1: ref(0) =?= f(0): True
1^0^1^0: ref(0) =?= f(0): True
1^0^1^1: ref(1) =?= f(1): True
1^1^0^0: ref(0) =?= f(0): True
1^1^0^1: ref(1) =?= f(1): True
1^1^1^0: ref(1) =?= f(1): True
1^1^1^1: ref(0) =?= f(0): True
evaluating reduced a^b^c^d
0^0^0^0: ref(0) =?= f(0): True
0^0^0^1: ref(1) =?= f(1): True
0^0^1^0: ref(1) =?= f(1): True
0^0^1^1: ref(0) =?= f(0): True
0^1^0^0: ref(1) =?= f(1): True
0^1^0^1: ref(0) =?= f(0): True
0^1^1^0: ref(0) =?= f(0): True
0^1^1^1: ref(1) =?= f(1): True
1^0^0^0: ref(1) =?= f(1): True
1^0^0^1: ref(0) =?= f(0): True
1^0^1^0: ref(0) =?= f(0): True
1^0^1^1: ref(1) =?= f(1): True
1^1^0^0: ref(0) =?= f(0): True
1^1^0^1: ref(1) =?= f(1): True
1^1^1^0: ref(1) =?= f(1): True
1^1^1^1: ref(0) =?= f(0): True
```

##### code for `a^b^c^d` reduction:


```py
def xor3(x, y, z): return xor2(x, xor2(y, z))

R = IntegerModRing(8)['a, b, c, d, axorb, axorc, axord, bxorc, \
        bxord, cxord, axorbxorc, axorbxord, axorcxord, bxorcxord']

(a, b, c, d, axorb, axorc, axord, bxorc, bxord, cxord, axorbxorc, \
        axorbxord, axorcxord, bxorcxord) = R.gens()
I = ideal((axorb - xor2(a, b),
           axorc - xor2(a, c),
           axord - xor2(a, d),
           bxorc - xor2(b, c),
           bxord - xor2(b, d),
           cxord - xor2(c, d),
           axorbxorc - xor3(a, b, c),
           axorbxord - xor3(a, b, d),
           axorcxord - xor3(a, c, d),
           bxorcxord - xor3(b, c, d),
           a*a-a,
           b*b-b,
           c*c-c,
           d*d-d
           ))
IG = I.groebner_basis()
f_orig = (xor2(a, xor2(b, xor2(c, d))))
f_reduced = f_orig.reduce(IG)
print("value of a^b^c^d:\n\t%s\n\treduced: %s" % (f_orig, f_reduced))

def evalxor3(f):
    for (i, j, k, l) in [(i, j, k, l) for i in [0, 1] \
                           for j in [0, 1] \
                           for k in [0, 1] \
                           for l in [0, 1]]:
      ref = i^^j^^k^^l
      eval = f.substitute(a=i, b=j, c=k, d=l,
                          axorb=i^^j, axorc=i^^k,
                          axord=i^^l, bxorc=j^^k,
                          bxord=j^^l, cxord=k^^l,
                          axorbxorc=i^^j^^k, axorbxord=i^^j^^l,
                          axorcxord=i^^k^^l, bxorcxord=j^^k^^l)
      print("%s^%s^%s^%s: ref(%s) =?= f(%s): %s" %
        (i, j, k, l, ref, eval, ref == eval))

print("evaluating original a^b^c^d")
evalxor3(f_orig)


print("evaluating reduced a^b^c^d")
evalxor3(f_reduced)
```

##### Closing thoughts

This was a really fun exercise: Around a hundred lines of code illuminates
the use of machinery such as grobner basis for solving real-world problems!
I really enjoyed hacking this up and getting nerd sniped.


# The janus programming language --- Time reversible computation

- [Wiki link](https://en.wikipedia.org/wiki/Janus_(time-reversible_computing_programming_language)
- [Original letter to Landlauer](http://tetsuo.jp/ref/janus.pdf)

I found out it's called Janus, since Janus is the god of doorways in greek
mythology. Hence, he is also the god of duality and transitions --- he
_literally_ looks both into the future and into the past.

> He is usually depicted as having two faces, since he looks to the future and
> to the past.

An apt name for the language!

# `A = B` --- A book about proofs of combinatorial closed forms


The book explains algorithms on solving closed forms for combinatorial
recurrences, by means of [Zeilberger's algorithm](http://mathworld.wolfram.com/ZeilbergersAlgorithm.html).

The book is written by Zeilberger himself, and supposedy also teaches one Maple.
I'd like to learn the algorithm, since it might be useful eventually for
Groebner basis / loop analysis shenanigans I like to play as part of
my work on compilers.

- [Download link here](https://www.math.upenn.edu/~wilf/AeqB.pdf)

# Generating `k` bitsets of a given length `n`:

The problem is to generate all bitvectors of length `n` that have `k` bits
set. For example, generate all bitvectors of length `5` that have `3` bits
set.

I know that an algorithm exists in Hacker's delight, but I've been too sick
to crack open a book, so I decided to discover the algorithm myself. The one
I came up with relies on looking at the numbers moving at a certain velocity,
and them colliding with each other. For example, let us try to generate all
`5C3` combinations of bits.


We start wih:
```
#1           count of position
a b c d e    positions
1 1 1 0 0    bitset
< - - - -    velocity
```

Where the `<` represents that the `1` at position `a` is moving leftwards.
Our arena is _circular_, so the leftmost `1` can wrap around to the right.
This leads to the next state

```
#2
a b c d e
0 1 1 0 1
- - - - <
```

We continue moving left peacefully.

```
#3
a b c d e
0 1 1 1 0
- - - < -
```

whoops, we have now collided with a block of `1`s. Not to worry, we simply
transfer our velocity by way of collision, from the `1` at `d` to the `1` at `b`.

I denote the transfer as follows:
```
#3
a b c d e
0 1 1 1 0  original state
- - - < -
- < < < -  transfer of velocity
- < - - -  final state after transfer of velocity
```

The `1` at `b` proceeds along its merry way with the given velocity

```
#4
a b c d e
1 0 1 1 0
< - - - -
```

Once again, it wraps around, and suffers a collision

```
#5
a b c d e
0 0 1 1 1
- - - - - < (collision, transfer)
- - < < < transfer of velocity
- - < - - final state after transfer of velocity
```

This continues:

```
0 1 0 1 1  #6
- < - - -
1 0 0 1 1  #7
< - - - - (collision, transfer velocity)
< - - < <
- - - < -
1 0 1 0 1 #8
- - < - -
1 1 0 0 1 #9
- < - - - (colision, transfer velocity
< < - - <
- - - - <
1 1 0 1 0 #10
- - - < -
1 1 1 0 0 #11: wrap around to initial state
```

I don't have a proof of correctness, but I have an intuition that this
should generate all states. Does anyone have a proof?

_EDIT:_ [this algorithm does not work](https://math.stackexchange.com/questions/3398241/correctness-proof-for-algorithm-to-generate-k-bitsets-of-n-bits-nck),
since it will keep clusters of $k-1$ bits next to each other, when a
bit hits a cluster of $k - 1$ bits.  For completeness, I'm going to draft out
the usual algorithm in full:

### Usual Algorithm

Let's consider the same example of `5C3`:

```
   a b c d e
1| 0 0 1 1 1 (LSB)
```

We start with all bits at their lowest position. Now, we try to go to
the next smallest number, which still has 3 bits toggled. Clearly, we need
the bit at position `b` to be 1, since that's the next number. Then,
we can keep the lower 2 bits `d, e` set to 1, so that it's still as small a
number as possible.

```
   a b c d e
2| 0 1 0 1 1 (LSB)
```

Once again, we now move the digit at `d` to the digit at `c`, while keeping
the final digit at `e` to make sure it's still the smallest possible.

```
   a b c d e
3| 0 1 1 0 1 (LSB)
```

Now, we can move the `1` at `e` to `d`, since that will lead to the smallest
increase:

```
   a b c d e
4| 0 1 1 1 0 (LSB)
```

At this point, we are forced to move to location `a`, since we have exhausted
all smaller locations. so we move the `1` at `b` to `a`, and then reset all
the other bits to be as close to the LSB as possible:

```
   a b c d e
5| 1 0 0 1 1 (LSB)
```

Continuing this process gives us the rest of the sequence:

```
    a b c d e
5 | 1 0 0 1 1
6 | 1 0 1 0 1
7 | 1 0 1 1 0
8 | 1 1 0 0 1 (note the reset of d!)
9 | 1 1 0 1 0
10| 1 1 1 0 0
```
# Bondi k-calculus

- [Link here](https://en.wikipedia.org/wiki/Bondi_k-calculus)

An alternative formalism to derive special relativity geometrically,
resting purely on hypotehses about the way light travels.

However, I've not been able to prove the correctness of the assumptions made,
by using coordinate geometry. I suspect this is because I will need to use
hyperbolic geometry for the "side lengths" to work out.


Indeed, I found another source, called as [The k-calculus fiddle](http://bearsoft.co.uk/Kcalc.html)
which attempts to discredit k-calculus. The author of the above blog writes at
the end:

> In asking Ray D'Inverno's permission to use his book as the example of
> k-calculus, he was kind enough to point out that the arguments I have given
> are invalid. Chapter 2 of his book should be read through to the end and then
> reread in the light of the fact that the geometry of space and time is
> Minkowskian. Euclidean geometry should not be used in interpreting the
> diagrams because their geometry is Minkowskian.

which seems to imply that we need to use hyperbolic geometry for this.

# Topology as an object telling us what zero-locus is closed:

- [Idea from this amazing post on `math.se`](https://math.stackexchange.com/questions/53852/is-there-a-way-of-working-with-the-zariski-topology-in-terms-of-convergence-limi)

# Vivado toolchain craziness 

I found this file as I was cleaning up some old code, for a project to implement
a [fast K/V store on an FPGA](https://github.com/AakashKT/CuckooHashingHLS),
so I thought I should put this up for anyone else who stumbles on the
same frustrations / errors. I'm not touching this particular toolchain again
with a 10-foot pole till the tools stabilize by *a lot*.

##### Vivado HLS issues


- Unable to create BRAM for fields such as `bool`, `int16`. The data buses
  will be `8/16` bits long, with error:

```
[BD 41-241] Message from IP propagation TCL of /blk_mem_gen_7: set_property
error: Validation failed for parameter 'Write Width A(Write_Width_A)' for BD
Cell 'blk_mem_gen_7'. Value '8' is out of the range (32,1024) Customization
errors found on 'blk_mem_gen_7'. Restoring to previous valid configuration.
```

- I had an array of structs:

```cpp
struct S {
    bool b;
    int16 x;
    int16 y;
}
```

This gets generated as 3 ports for memory, of widths `1`, `16`, `16`. Ideally,
I wanted *one* port, of width `16+16+1=33`, for each struct value.
However, what was generated were three ports of widths `1`, `16`, and `16`
which I cannot connect to BRAM.

- `data_pack` allows us to create one port of width `16+16+1=33`

- Shared function names allocated on BRAM causes errors in synthesis:


```cpp
struct Foo {...};
void f (Foo conflict) {
    #pragma HLS interface bram port=conflict
}

void g (Foo conflict) {
    #pragma HLS interface bram port=conflict
}
```

- Enums causes compile failure in RTL generation  (commit `3c0d619039cff7a7abb61268e6c8bc6d250d8730`)
- `ap_int` causes compile failurre in RTL generation (commit `3c0d619039cff7a7abb61268e6c8bc6d250d8730`)
- `x % m` where `m != 2^k` is very expensive -- there must be faster encodings of modulus?
- How to share code between HLS and vivado SDK? I often wanted to share constant values between
  my HLS code and my Zynq code.
- Can't understand why array of structs that were packed does not get deserialized correctly. I had to manually
  pack a struct into a `uint32`. For whatever reason, having a `#pragma pack` did something to the representation of the struct
  as far as I can tell, and I couldn't treat the memory as just a raw `struct *` on the other side:


```cpp
// HLS side
struct Vec2  { int x; int y};
void f(Vec2 points[NUM_POINTS]) {
	#pragma HLS DATA_PACK variable=points
    #pragma HLS INTERFACE bram port=points

    points[0] = {2, 3};
}

// Host side
Vec2 *points = (Vec2 *)(0xPOINTER_LOCATION_FROM_VIVADO);

int main() {
    // points[0] will *not* be {2, 3}!
}
```

- If I change my IP, there is no way to preserve the current connections in the
  GUI why just updating the "changed connections". I'm forced to remove the IP
  and add it again (no, the Refresh IP button does not work).
- On generating a new bitstream from Vivado, Vivado SDK tries to reload the config,
  fails at the reloading (thinks `xil_print.h` doesn't exist), and then fails to compile code.
  Options are to either restart Vivado SDK, or refresh `xil_print.h`.


- It is entirely unclear what to version control in a vivado project, unless one
  has an omniscient view of the _entire toolchain_. I resorted to `git add` ing
  everything, but this is a terrible strategy in so many ways.


#### SDAccel bugs

**[link to tutorial we were following](https://www.xilinx.com/support/documentation/sw_manuals/xilinx2017_1/ug1028-sdsoc-intro-tutorial.pdf)**
- The executable is named `.exe` while it's actually an ELF executable (The SDAccel tutorials say it is called as `.elf`)
- the board is supposed to automatically boot into linux, which it does not. One is expected to call `bootd` manually (for "boot default") so it boots ito linux. (The SDAccel tutorials say it automatically boots into it)
- At this point, the SD card is unreadable. It took a bunch of time to figure out that the SD card needs to be mounted by us, and has the mount name `/dev/mmcblk0p1`. (The SDAccel tutorials say that it should be automatically mounted)
- At this point, we are unable to run `hashing.elf`. It dies with a truly bizarre error: `hashing.elf: command not found`. This is almost un-googleable, due to the fact that the same problem occurs when people don't have the correct file name.
- I rewrote `ls` with `hashing.elf` to see what would happen, because I conjectured that the shell was able to run `coreutils`.
- This dies with a different error `ls: core not found`. I'd luckily seen this during my android days, and knew this was from busybox.
- This led me to google "busybox unable to execute executable", which led me to this [StackOverflow link](https://stackoverflow.com/questions/1562071/how-can-i-find-which-elf-dependency-is-not-fulfilled) that clued me into the fact that the ELF interpreter is missing.
- When I discovered this, I wound up trying to understand how to get the right ELF interpreter. `readelf -l <exe name>` dumps out `[Requesting program interpreter: /lib/ld-linux-armhf.so.3]`. So, I bravely copied: `cp /lib/ld-linux.so.3 /lib/ld-linux-armhf.so.3`.
- Stuff is *still* broken, but I now get *useful* error messages:

```
zynq> /hashing.elf
/hashing.elf: error while loading shared libraries:
libxilinxopencl.so: cannot open shared object file: No such file or directory
```

At this point, clearly we have some linker issues (why does `xocc` not correctly statically link? What's up with it? Why does it expect it to be able to load a shared library? **WTF is happening**). do note that this is _not_ the way the process
is supposed to go according to the tutorial!
- Of course, there's no static library version of `libxilinxopencl.so`, so that's a dead end. I'm completely unsure if the tutorial even makes sense.
- This entire chain of debugging is full of luck.

- [Link talking about generating `BOOT` file](https://www.xilinx.com/html_docs/xilinx2018_2/sdsoc_doc/compiling-and-running-applications-on-arm-processor-hjy1504034381720.html)


At some point, I gave up on the entire enterprise.

# What the hell _is_ a Grobner basis? Ideals as rewrite systems

##### A motivating example

The question a Grobner basis allows us to answer is this: can the polynomial
$p(x, y) = xy^2 + y$ be factorized in terms of $a(x, y) = xy + 1, b(x, y) = y^2 - 1$,
such that $p(x, y) = f(x, y) a(x, y) + g(x, y) b(x, y)$ for some _arbitrary_ polynomials
$f(x, y), g(x, y) \in R[x, y]$.

One might imagine, "well, I'll divide and see what happens!" Now, there are two
routes to go down:

- $xy^2 + y = y(xy + 1) = y a(x, y) + 0 b(x, y)$. Well, problem solved?
- $xy^2 + y = xy^2 - x + x + y = x (y^2 - 1) + x + y = x b(x, y) + (x + y)$. Now what? we're stuck, and we can't apply `a(x, y)`!

So, clearly, the _order_ in which we perform of factorization / division starts
to matter! Ideally, we want an algorithm which is _not sensitive_ to the order
in which we choose to apply these changes. $x^2 + 1$.


##### The rewrite rule perspective


An alternative viewpoint of asking "can this be factorized", is to ask
"can we look at the factorization as a rewrite rule"? For this perspective,
notice that "factorizing" in terms of $xy + 1$ is the same as being
able to set $xy = -1$, and then have the polynomial collapse to zero.
(For the more algebraic minded, this relates to the fact that $R[x] / p(x) \sim R(\text{roots of p})$).
The intuition behind this is that when we "divide by $xy + 1$", really what
we are doing is we are setting $xy + 1 = 0$, and then seeing what remains. But
$xy + 1 = 0 \iff xy = -1$. Thus, we can look at the original question as:

How can we apply the rewrite rules $xy \rightarrow -1$, $y^2 \rightarrow 1$,
along with the regular rewrite rules of polynomial arithmetic to the polynomial
$p(x, y) = xy^2 + y$, such that we end with the value $0$?

Our two derivations above correspond to the application of the rules:

- $xy^2 + y \xrightarrow{xy = -1} -y + y = 0$
- $xy^2 + y \xrightarrow{y^2 = 1} x + y \nrightarrow \text{stuck!}$

That is, our [rewrite rules are not confluent](https://en.wikipedia.org/wiki/Confluence_(abstract_rewriting))

The grobner basis is a mathematical object, which is a  _a confluent set of rewrite rules_
for the above problem. That is, it's a set of polynomials which manage to find
the rewrite $p(x, y) \xrightarrow{\star} 0$, regardless of the order in which
we apply them. It's also _correct_, in that it only rewrites to $0$ if the
original system had _some way_ to rewrite to $0$.

###### The buchberger's algorithm

We need to identify
[critical pairs](https://en.wikipedia.org/wiki/Critical_pair_(logic)),
which in this setting are called as S-polynomials.

Let $f_i = H(f_i) + R(f_i)$ and $f_j = H(f_j) + R(f_j)$. Let $m = lcm(H(f_i), H(f_j))$,
and let $m_i, m_j$ be monomials such that $m_i \cdot H(f_i) = m = m_j \cdot H(f_j)$.
The S-polynomial induced by $f_i, f_j$ is defined as $S(f_i, f_j) = m_i f_i - m_i f_j$.


##### References
- [The term rewriting perspective is from the book "term rewriting and all that"](https://www21.in.tum.de/~nipkow/TRaAT/)
- [Sympy has excellent reading material on grobner basis](https://mattpap.github.io/masters-thesis/html/src/groebner.html)


# [Lie bracket versus torsion](lie-bracket-versus-torsion)


<img src="static/lie-bracket-versus-torsion.png">

This picture _finally_ made the difference between these two things clear.
The lie bracket moves along the _flow_, while the torsion moves along
_parallel transport_.

This is why the sides of the parallelogram that measure torsion form,
well, a parallelogram: we set them up using parallel transport.

On the other hand, the lie bracket measures the actual failure of the parallelogram
from being formed.

# [Blog post: Weekend paper replication of STOKE, the stochastic superoptimizer](https://github.com/bollu/blaze/blob/master/notebooks/tutorial.ipynb)

Click the title to go to the post. We replicate the `STOKE` paper in haskell,
to implement a superoptimiser based on MCMC methods.

# Collapsing `BlockId`, `Label`, `Unique`:

We have this hiearchy of `BlockId`, `Label`, and `Unique` that can be
collapsed.


# Spatial partitioning data structures in molecular dynamics

- [Cell lists](https://en.wikipedia.org/wiki/Cell_lists)
- [Verlet lists](https://en.wikipedia.org/wiki/Verlet_list)

appear to be version of spatial hierarchical data structures for fast
interaction computation. Apparently, multipole expansions are not useful
in this case since multipole expansions are useful to take into account
long range effects, but not short range effects.


# Vector: Arthur Whitney and text editors

- http://archive.vector.org.uk/art10501320


# Representing CPS in LLVM using the `@coro.*` intrinsics

This is part of a larger thread --- [Adding CPS call support to LLVM](http://lists.llvm.org/pipermail/llvm-dev/2017-April/112212.html) where there is a large discussion on the correct design of how to teach LLVM about CPS.

Gor Nishanov proided the above example of encoding CPS using the llvm `coro` instructions.

- https://gist.github.com/bollu/e0573dbc145028fb42f89e64c6dd6742

# Bug in the LLVM code generator: Lowering of `MO_Add2` and `MO_AddWordC`

[Both of these are lowered the same way](https://github.com/ghc/ghc/blob/bf73419518ca550e85188616f860961c7e2a336b/compiler/llvmGen/LlvmCodeGen/CodeGen.hs#L817),
but they should be different.

In particular, `GHC.Prim` explains:
- [`AddWordC#`](http://hackage.haskell.org/package/ghc-prim-0.5.3/docs/GHC-Prim.html#v:addWordC-35-) returns `(result, carry)`
- [`PlusWordC#`](http://hackage.haskell.org/package/ghc-prim-0.5.3/docs/GHC-Prim.html#v:plusWord-35-) returns `(carry, result)`

Honestly, this is confusing, but I guess there's some story to having two separate primops for this?


# Discrete random distributions with conditioning in 20 lines of haskell

```hs
newtype D a = D { unD :: [(a, Double)] } deriving(Eq, Show, Ord)

instance Functor D where
    -- fmap :: (a -> b) -> D a -> D b
    fmap f (D xs) = D $ fmap (\(a, d) -> (f a, d)) xs

instance Monad D where
    return x = D $ [(x, 1.0)]
    -- f :: a -> (D b)
    (D as) >>= f = D $ do -- list monad
                      (a, p) <- as
                      (b, p2) <- unD (f a)
                      return $ (b, p * p2)

-- [(a, 0.5), (b, 0.5)]
-- [(a, 0.3), (a, 0.2), (b, 0.1), (b, 0.4)]
--
instance Applicative D where
    pure = return
    ff <*> fa = do
        f <- ff
        a <- fa
        return $ f  a

condition :: Bool -> D ()
condition True = D [((), 1.0)]
condition False = D [((), 0.0)]


dice :: D Int
dice = let p = 1.0 / 6 in D $ [(x, p) | x <- [1..6]]


dice_hard :: D Int
dice_hard = do
    x <- dice
    condition $ x > 3
    return $ x


main :: IO ()
main = do
    print dice
    print dice_hard
```

This gives the output:

```
D {unD = [(1,0.16666666666666666),
          (2,0.16666666666666666),
          (3,0.16666666666666666),
          (4,0.16666666666666666),
          (5,0.16666666666666666),
          (6,0.16666666666666666)]}

D {unD = [(1,0.0),
          (2,0.0),
          (3,0.0),
          (4,0.16666666666666666),
          (5,0.16666666666666666),
          (6,0.16666666666666666)]}
```

Notice that `D a ~= WriterT (Product Float) []`!

# Everything you know about word2vec is wrong

The classic explanation of `word2vec`, in skip-gram, with negative sampling,
in the paper and countless blog posts on the internet is as follows:

```
while(1) {
   1. vf = vector of focus word
   2. vc = vector of context word
   3. train such that (vc . vf = 1)
   4. for(0 <= i < negative samples):
           vneg = vector of word *not* in context
           train such that (vf . vneg = 0)
}
```

Indeed, if I google "word2vec skipgram", the results I get are:
- [The wikipedia page which describes the algorithm on a high level](https://en.wikipedia.org/wiki/Word2vec#Training_algorithm)
- [The tensorflow page with the same explanation](https://www.tensorflow.org/tutorials/representation/word2vec)
- [The towards data science blog which describes the same algorithm](https://towardsdatascience.com/word2vec-skip-gram-model-part-1-intuition-78614e4d6e0b)

the list goes on. However, __every single one of these implementations is wrong__.

The original word2vec `C` implementation does _not_ do what's explained above,
and is _drastically different_. Most serious users of word embeddings, who use
embeddings generated from `word2vec` do one of the following things:

1. They invoke the original C implementation directly.
2. They invoke the `gensim` implementation, which is _transliterated_ from the
   C source to the extent that the variables names are the same.

Indeed, the `gensim` implementation is the 
__only one that I know of which is faithful to the C implementation__.

### The C implementation

The C implementation in fact maintains _two vectors for each word_, one where
it appears as a focus word, and one where it appears as a context word.
(Is this sounding familiar? Indeed, it appears that GloVe actually took this
idea from `word2vec`, which has never mentioned this fact!)

The setup is incredibly well done in the C code:

- An array called `syn0` holds the vector embedding of a word when it occurs
  as a _focus word_. This is __random initialized__.

```cpp
https://github.com/tmikolov/word2vec/blob/20c129af10659f7c50e86e3be406df663beff438/word2vec.c#L369
  for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++) {
    next_random = next_random * (unsigned long long)25214903917 + 11;
    syn0[a * layer1_size + b] =
       (((next_random & 0xFFFF) / (real)65536) - 0.5) / layer1_size;
  }

```

- Another array called `syn1neg` holds the vector of a word when it occurs
  as a _context word_. This is __zero initialized__.

```cpp
https://github.com/tmikolov/word2vec/blob/20c129af10659f7c50e86e3be406df663beff438/word2vec.c#L365
for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++)
  syn1neg[a * layer1_size + b] = 0;
```

- During training (skip-gram, negative sampling, though other cases are
  also similar), we first pick a focus word. This is held constant throughout
  the positive and negative sample training. The gradients of the focus vector
  are accumulated in a buffer, and are applied to the focus word
  _after it has been affected by both positive and negative samples_.

```cpp
if (negative > 0) for (d = 0; d < negative + 1; d++) {
  // if we are performing negative sampling, in the 1st iteration,
  // pick a word from the context and set the dot product target to 1
  if (d == 0) {
    target = word;
    label = 1;
  } else {
    // for all other iterations, pick a word randomly and set the dot
    //product target to 0
    next_random = next_random * (unsigned long long)25214903917 + 11;
    target = table[(next_random >> 16) % table_size];
    if (target == 0) target = next_random % (vocab_size - 1) + 1;
    if (target == word) continue;
    label = 0;
  }
  l2 = target * layer1_size;
  f = 0;

  // find dot product of original vector with negative sample vector
  // store in f
  for (c = 0; c < layer1_size; c++) f += syn0[c + l1] * syn1neg[c + l2];

  // set g = sigmoid(f) (roughly, the actual formula is slightly more complex)
  if (f > MAX_EXP) g = (label - 1) * alpha;
  else if (f < -MAX_EXP) g = (label - 0) * alpha;
  else g = (label - expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP / 2))]) * alpha;

  // 1. update the vector syn1neg,
  // 2. DO NOT UPDATE syn0
  // 3. STORE THE syn0 gradient in a temporary buffer neu1e
  for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1neg[c + l2];
  for (c = 0; c < layer1_size; c++) syn1neg[c + l2] += g * syn0[c + l1];
}
// Finally, after all samples, update syn1 from neu1e
https://github.com/tmikolov/word2vec/blob/20c129af10659f7c50e86e3be406df663beff438/word2vec.c#L541
// Learn weights input -> hidden
for (c = 0; c < layer1_size; c++) syn0[c + l1] += neu1e[c];
```

### Why random and zero initialization?

Once again, since none of this actually explained in the original papers
_or on the web_, I can only hypothesize.

My hypothesis is that since the negative samples come from all over the text
and are not really weighed by frequency, you can wind up picking _any word_,
and more often than not, _a word whose vector has not been trained much at all_.
If this vector actually had a value, then it could move the actually important
focus word randomly.

The solution is to set all negative samples to zero, so that 
_only vectors that have occurred somewhat frequently_ will affect the representation 
of another vector.

It's quite ingenious, really, and until this, I'd never really thought of
how important initialization strategies really are.


### Why I'm writing this

I spent two months of my life trying to reproduce `word2vec`, following
the paper exactly, reading countless articles, and simply not succeeding.
I was unable to reach the same scores that `word2vec` did, and it was not
for lack of trying.

I could not have imagined that the paper would have literally fabricated an
algorithm that doesn't work, while the implementation does something completely
different.

Eventually, I decided to read the sources, and spent three whole days convinced
I was reading the code wrong since literally everything on the internet told me
otherwise.

I don't understand why the original paper and the internet contain zero
explanations of the _actual_ mechanism behind `word2vec`, so I decided to put
it up myself.

This also explains GloVe's radical choice of having a separate vector
for the negative context --- they were just doing what `word2vec` does, but
they told people about it `:)`.

Is this academic dishonesty? I don't know the answer, and that's a heavy
question. But I'm frankly incredibly pissed, and this is probably the last
time I take a machine learning paper's explanation of the algorithm
seriously again --- from next time, I read the source _first_.

# Hamiltonian monte carlo, leapfrog integrators, and sympletic geometry

This is a section that I'll update as I learn more about the space, since I'm studying
differential geometry over the summer, I hope to know enough about "sympletic manifolds".
I'll make this an append-only log to add to the section as I understand more.

##### 31st May

- To perform hamiltonian monte carlo, we use the hamiltonian and its
  derivatives to provide a momentum to our proposal distribution --- That is,
  when we choose a new point from the current point, our probability
  distribution for the new point is influenced by our current momentum.

- For some integral necessary within this scheme, Euler integration doesn't cut it
  since the error diverges to infinity

- Hence, we need an integrator that guarantees that the energy of out system is
  conserved.  Enter the leapfrog integrator. This integrator is also 
  _time reversible_ -- We can run it forward for `n` steps, and then run it
  backward for `n` steps to arrive at the same state.  Now I finally know how
  Braid was implemented, something that bugged the hell out of 9th grade me
  when I tried to implement Braid-like physics in my engine!

- The actual derivation of the integrator uses Lie algebras, Sympletic
  geometry, and other diffgeo ideas, which is great, because it gives me
  motivation to study differential geometry `:)`

- Original paper: [Construction of higher order sympletic integrators](https://www.sciencedirect.com/science/article/abs/pii/0375960190900923)

##### Simulating orbits with large timesteps

<img src="./static/leapfrog-vs-euler.png">

Clearly, the leapfrog integrator preserves energy and continues to move
in an orbit, while the euler integrator goes batshit and causes orbits
to spiral outwards. Full code is available below. More of the code is
spent coaxing matplotlib to look nice, than doing the actual
computation.

```py
import numpy as np
import matplotlib.pyplot as plt
import numpy.linalg

# dq/dt = dH/dp | dp/dt = -dH/dq (a = -del V)
def leapfroge(dhdp, dhdq, q, p, dt):
    p += -dhdq(q, p) * 0.5 * dt # halfstep momentum
    q += dhdp(q, p) * dt # fullstep position
    p += -dhdq(q, p) * 0.5 * dt # halfstep momentum
    return (q, p)

def euler(dhdp, dhdq, q, p, dt):
    pnew = p + -dhdq(q, p) * dt
    qnew = q + dhdp(q, p) * dt

def planet(integrator, n, dt):
    STRENGTH = 0.5

    q = np.array([0.0, 1.0]); p = np.array([-1.0, 0.0])

    # H = STRENGTH * |q| (potential) + p^2/2 (kinetic)
    def H(qcur, pcur): return STRENGTH * np.linalg.norm(q) + np.dot(p, p) / 2
    def dhdp(qcur, pcur): return p
    def dhdq(qcur, pcur): return STRENGTH * 2 * q / np.linalg.norm(q)

    qs = []
    for i in range(n):
        (q, p) = integrator(dhdp, dhdq, q, p, dt)
        qs.append(q.copy())
    return np.asarray(qs)

NITERS = 15
TIMESTEP = 1

plt.rcParams.update({'font.size': 22, 'font.family':'monospace'})
fig, ax = plt.subplots()

planet_leapfrog = planet(leapfroge, NITERS, TIMESTEP)
ax.plot(planet_leapfrog[:, 0], planet_leapfrog[:, 1], label='leapfrog',
        linewidth=3, color='#00ACC1')
planet_euler = planet(euler, NITERS, TIMESTEP)
ax.plot(planet_euler[:, 0], planet_euler[:, 1], label='euler',
        linewidth=3, color='#D81B60')

legend = plt.legend(frameon=False)
ax.set_title("leapfrog v/s euler: NITERS=%s dt=%s" % (NITERS, TIMESTEP))
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
plt.show()
plt.savefig("leapfrog-vs-euler.png")
```

# Small Haskell MCMC implementation

We create a simple monad called `PL` which allows for a single operation: sampling
from a uniform distribution. We then exploit this to implement MCMC using metropolis hastings,
which is used to sample from arbitrary distributions. Bonus is a small library to render sparklines
in the CLI.

For next time:

- Using applicative to speed up computations by exploiting parallelism
- Conditioning of a distribution wrt a variable

### Source code
```hs
{-# LANGUAGE GeneralizedNewtypeDeriving #-}
{-# LANGUAGE GADTs #-}
{-# LANGUAGE StandaloneDeriving #-}
{-# LANGUAGE FlexibleContexts #-}
{-# LANGUAGE FlexibleInstances #-}
{-# LANGUAGE UndecidableInstances #-}
{-# LANGUAGE DeriveFunctor #-}
import System.Random
import Data.List(sort, nub)
import Data.Proxy
import Control.Monad (replicateM)
import qualified Data.Map as M


-- | Loop a monadic computation.
mLoop :: Monad m =>
      (a -> m a) -- ^ loop
      -> Int -- ^ number of times to run
      -> a -- initial value
      -> m a -- final value
mLoop _ 0 a = return a
mLoop f n a = f a >>= mLoop f (n - 1)


-- | Utility library for drawing sparklines

-- | List of characters that represent sparklines
sparkchars :: String
sparkchars = "_▁▂▃▄▅▆▇█"

-- Convert an int to a sparkline character
num2spark :: RealFrac a => a -- ^ Max value
  -> a -- ^ Current value
  -> Char
num2spark maxv curv =
   sparkchars !!
     (floor $ (curv / maxv) * (fromIntegral (length sparkchars - 1)))

series2spark :: RealFrac a => [a] -> String
series2spark vs =
  let maxv = if null vs then 0 else maximum vs
  in map (num2spark maxv) vs

seriesPrintSpark :: RealFrac a => [a] -> IO ()
seriesPrintSpark = putStrLn . series2spark

-- Probabilities
-- ============
type F = Float
-- | probability density
newtype P = P { unP :: Float } deriving(Num)

-- | prob. distributions over space a
newtype D a = D { runD :: a -> P }

uniform :: Int -> D a
uniform n =
  D $ \_ -> P $ 1.0 / (fromIntegral $ n)

(>$<) :: Contravariant f => (b -> a) -> f a  -> f b
(>$<) = cofmap

instance Contravariant D where
  cofmap f (D d) = D (d . f)

-- | Normal distribution with given mean
normalD :: Float ->  D Float
normalD mu = D $ \f -> P $ exp (- ((f-mu)^2))

-- | Distribution that takes on value x^p for 1 <= x <= 2.  Is normalized
polyD :: Float -> D Float
polyD p = D $ \f -> P $ if 1 <= f && f <= 2 then (f ** p) * (p + 1) / (2 ** (p+1) - 1) else 0

class Contravariant f where
  cofmap :: (b -> a) -> f a -> f b

data PL next where
    Ret :: next -> PL next -- ^ return  a value
    Sample01 :: (Float -> PL next) -> PL next -- ^ sample uniformly from a [0, 1) distribution

instance Monad PL where
  return = Ret
  (Ret a) >>= f = f a
  (Sample01 float2plnext) >>= next2next' =
      Sample01 $ \f -> float2plnext f >>= next2next'

instance Applicative PL where
    pure = return
    ff <*> fx = do
        f <- ff
        x <- fx
        return $ f x

instance Functor PL where
    fmap f plx = do
         x <- plx
         return $ f x

-- | operation to sample from [0, 1)
sample01 :: PL Float
sample01 = Sample01 Ret


-- | Run one step of MH on a distribution to obtain a (correlated) sample
mhStep :: (a -> Float) -- ^ function to score sample with, proportional to distribution
  -> (a -> PL a) -- ^ Proposal program
  -> a -- current sample
  -> PL a
mhStep f q a = do
 	a' <- q a
 	let alpha = f a' / f a -- acceptance ratio
 	u <- sample01
 	return $ if u <= alpha then a' else a

-- Typeclass that can provide me with data to run MCMC on it
class MCMC a where
    arbitrary :: a
    uniform2val :: Float -> a

instance MCMC Float where
	arbitrary = 0
	-- map [0, 1) -> (-infty, infty)
	uniform2val v = tan (-pi/2 + pi * v)


{-
-- | Any enumerable object has a way to get me the starting point for MCMC
instance (Bounded a, Enum a) => MCMC a where
     arbitrary = toEnum 0
     uniform2val v = let
        maxf = fromIntegral . fromEnum $ maxBound
        minf = fromIntegral . fromEnum $ minBound
        in toEnum $ floor $ minf + v * (maxf - minf)
-}


-- | Run MH to sample from a distribution
mh :: (a -> Float) -- ^ function to score sample with
 -> (a -> PL a) -- ^ proposal program
 -> a -- ^ current sample
 -> PL a
mh f q a = mLoop (mhStep f q) 100  $ a

-- | Construct a program to sample from an arbitrary distribution using MCMC
mhD :: MCMC a => D a -> PL a
mhD (D d) =
    let
      scorer = (unP . d)
      proposal _ = do
        f <- sample01
        return $ uniform2val f
    in mh scorer proposal arbitrary


-- | Run the probabilistic value to get a sample
sample :: RandomGen g => g -> PL a -> (a, g)
sample g (Ret a) = (a, g)
sample g (Sample01 f2plnext) = let (f, g') = random g in sample g' (f2plnext f)


-- | Sample n values from the distribution
samples :: RandomGen g => Int -> g -> PL a -> ([a], g)
samples 0 g _ = ([], g)
samples n g pl = let (a, g') = sample g pl
                     (as, g'') = samples (n - 1) g' pl
                 in (a:as, g'')

-- | count fraction of times value occurs in list
occurFrac :: (Eq a) => [a] -> a -> Float
occurFrac as a =
    let noccur = length (filter (==a) as)
        n = length as
    in (fromIntegral noccur) / (fromIntegral n)

-- | Produce a distribution from a PL by using the sampler to sample N times
distribution :: (Eq a, Num a, RandomGen g) => Int -> g -> PL a -> (D a, g)
distribution n g pl =
    let (as, g') = samples n g pl in (D (\a -> P (occurFrac as a)), g')


-- | biased coin
coin :: Float -> PL Int -- 1 with prob. p1, 0 with prob. (1 - p1)
coin p1 = do
    Sample01 (\f -> Ret $ if f < p1 then 1 else 0)


-- | Create a histogram from values.
histogram :: Int -- ^ number of buckets
          -> [Float] -- values
          -> [Int]
histogram nbuckets as =
    let
        minv :: Float
        minv = minimum as
        maxv :: Float
        maxv = maximum as
        -- value per bucket
        perbucket :: Float
        perbucket = (maxv - minv) / (fromIntegral nbuckets)
        bucket :: Float -> Int
        bucket v = floor (v / perbucket)
        bucketed :: M.Map Int Int
        bucketed = foldl (\m v -> M.insertWith (+) (bucket v) 1 m) mempty as
     in map snd . M.toList $ bucketed


printSamples :: (Real a, Eq a, Ord a, Show a) => String -> [a] -> IO ()
printSamples s as =  do
    putStrLn $ "***" <> s
    putStrLn $ "   samples: " <> series2spark (map toRational as)

printHistogram :: [Float] -> IO ()
printHistogram samples = putStrLn $ series2spark (map fromIntegral . histogram 10 $  samples)


-- | Given a coin bias, take samples and print bias
printCoin :: Float -> IO ()
printCoin bias = do
    let g = mkStdGen 1
    let (tosses, _) = samples 100 g (coin bias)
    printSamples ("bias: " <> show bias) tosses



-- | Create normal distribution as sum of uniform distributions.
normal :: PL Float
normal =  fromIntegral . sum <$> (replicateM 5 (coin 0.5))


main :: IO ()
main = do
    printCoin 0.01
    printCoin 0.99
    printCoin 0.5
    printCoin 0.7

    putStrLn $ "normal distribution using central limit theorem: "
    let g = mkStdGen 1
    let (nsamples, _) = samples 1000 g normal
    -- printSamples "normal: " nsamples
    printHistogram nsamples


    putStrLn $ "normal distribution using MCMC: "
    let (mcmcsamples, _) = samples 1000 g (mhD $  normalD 0.5)
    printHistogram mcmcsamples

    putStrLn $ "sampling from x^4 with finite support"
    let (mcmcsamples, _) = samples 1000 g (mhD $  polyD 4)
    printHistogram mcmcsamples
```

### Output

```
***bias: 1.0e-2
   samples: ________________________________________█_█________
***bias: 0.99
   samples: ███████████████████████████████████████████████████
***bias: 0.5
   samples: __█____█__███_███_█__█_█___█_█_██___████████__█_███
***bias: 0.7
   samples: __█__█_█__███_█████__███_█_█_█_██_█_████████__█████
normal distribution using central limit theorem:
_▄▇█▄_
normal distribution using MCMC:
__▁▄█▅▂▁___
sampling from x^4 with finite support
▁▁▃▃▃▄▅▆▇█_

```

# The smallest implementation of reverse mode AD (autograd) ever:

```hs
{-# LANGUAGE GeneralizedNewtypeDeriving #-}
import qualified Data.Map.Strict as M

-- | This file can be copy-pasted and will run!

-- | Symbols
type Sym = String
-- | Environments
type E a = M.Map Sym a
-- | Newtype to represent deriative values
type F = Float
newtype Der = Der { under :: F } deriving(Show, Num)

infixl 7 !#
-- | We are indexing the map at a "hash" (Sym)
(!#) :: E a -> Sym -> a
(!#) = (M.!)

-- | A node in the computation graph
data Node =
  Node { name :: Sym -- ^ Name of the node
       , ins :: [Node] -- ^ inputs to the node
       , out :: E F -> F -- ^ output of the node
       , der :: (E F, E (Sym -> Der))
                  -> Sym -> Der -- ^ derivative wrt to a name
       }

-- | @ looks like a "circle", which is a node. So we are indexing the map
-- at a node.
(!@) :: E a -> Node -> a
(!@) e node = e M.! (name node)

-- | Given the current environments of values and derivatives, compute
-- | The new value and derivative for a node.
run_ :: (E F, E (Sym -> Der)) -> Node -> (E F, E (Sym -> Der))
run_ ein (Node name ins out der) =
  let (e', ed') = foldl run_ ein ins -- run all the inputs
      v = out e' -- compute the output
      dv = der (e', ed') -- and the derivative
  in (M.insert name v e', M.insert name dv ed')  -- and insert them

-- | Run the program given a node
run :: E F -> Node -> (E F, E (Sym -> Der))
run e n = run_ (e, mempty) n

-- | Let's build nodes
nconst :: Sym -> F -> Node
nconst n f = Node n [] (\_ -> f) (\_ _ -> 0)

-- | Variable
nvar :: Sym -> Node
nvar n = Node n [] (!# n) (\_ n' -> if n == n' then 1 else 0)

-- | binary operation
nbinop :: (F -> F -> F)  -- ^ output computation from inputs
 -> (F -> Der -> F -> Der -> Der) -- ^ derivative computation from outputs
 -> Sym -- ^ Name
 -> (Node, Node) -- ^ input nodes
 -> Node
nbinop f df n (in1, in2) =
  Node { name = n
       , ins = [in1, in2]
       , out = \e -> f (e !# name in1) (e !# name in2)
       , der = \(e, ed) n' ->
                 let (name1, name2) = (name in1, name in2)
                     (v1, v2) = (e !# name1, e !# name2)
                     (dv1, dv2) = (ed !# name1 $ n', ed !# name2 $ n')
                     in df v1 dv1 v2 dv2
       }

nadd :: Sym -> (Node, Node) -> Node
nadd = nbinop (+) (\v dv v' dv' -> dv + dv')

nmul :: Sym -> (Node, Node) -> Node
nmul = nbinop (*) (\v (Der dv) v' (Der dv') -> Der $ (v*dv') + (v'*dv))

main :: IO ()
main = do
  let x = nvar "x" :: Node
  let y = nvar "y"
  let xsq = nmul "xsq" (x, x)
  let ten = nconst "10" 10
  let xsq_plus_10 = nadd "xsq_plus_10" (xsq, ten)
  let xsq_plus_10_plus_y = nadd "xsq_plus_10_plus_y"  (xsq_plus_10, y)
  let (e, de) = run (M.fromList $ [("x", 2.0), ("y", 3.0)]) xsq_plus_10_plus_y
  putStrLn $ show e
  putStrLn $ show $ de !@ xsq_plus_10_plus_y $ "x"
  putStrLn $ show $ de !@ xsq_plus_10_plus_y $ "y"
```

Yeah, in ~80 lines of code, you can basically build an autograd engine. Isn't
haskell so rad?


# Timings of passes in GHC, and low hanging fruit in the backend:

- One can use `-v3` to get pass timings.
- Apparently, GHC spends a lot of time in the simplifier, and time
  spend in the backend is peanuts in comparison to this.

To quote `AndreasK`:

> - Register allocation, common block elimination, block layout and pretty printing are the "slow" things in the backend as far as I remember.
> - There are also a handful of TODO's in the x86 codegen which still apply. So you can try to grep for these.
> - Strength reduction for division by a constant

- [NCG generates slow loop code](https://gitlab.haskell.org/ghc/ghc/issues/9041)

# Varargs in GHC: `T7160.hs`

A comment from this test case tells us why the function `debugBelch2` exists:

```hs
ghc/testsuite/tests/rts/T7160.hs
-- Don't use debugBelch() directly, because we cannot call varargs functions
-- using the FFI (doing so produces a segfault on 64-bit Linux, for example).
-- See Debug.Trace.traceIO, which also uses debugBelch2.
foreign import ccall "&debugBelch2" fun :: FunPtr (Ptr () -> Ptr () -> IO ())
```

The implementation is:

```c
ghc/libraries/base/cbits/PrelIOUtils.c

void debugBelch2(const char*s, char *t)
{
    debugBelch(s,t);
}
```

```
ghc/rts/RtsMessages.c

RtsMsgFunction *debugMsgFn  = rtsDebugMsgFn;
...

void
debugBelch(const char*s, ...)
{
  va_list ap;
  va_start(ap,s);
  (*debugMsgFn)(s,ap);
  va_end(ap);
}
```
# Debugging debug info in GHC


I wanted to use debug info to help build a better debugging experience
within [`tweag/asterius`](http://github.com/tweag/asterius). So, I was
reading through the sources of `cmm/Debug.hs`.
I'd never considered how to debug debug-info, and I found the information
tucked inside a cute note in GHC (`Note [Debugging DWARF unwinding info]`):

> This makes GDB produce a trace of its internal workings. Having gone this far,
> it's just a tiny step to run GDB in GDB. Make sure you install debugging
> symbols for gdb if you obtain it through a package manager.

- [Link to GHC sources](https://github.com/ghc/ghc/blob/535a26c90f458801aeb1e941a3f541200d171e8f/compiler/cmm/Debug.hs#L458)


# GHC LLVM code generator: Switch to unreachable

The [switch to out of range](https://github.com/ghc/ghc/blob/master/compiler/llvmGen/LlvmCodeGen/CodeGen.hs#L1102)
code generator switches to the first label. It should be more profitable
to switch to a `unreachable` block. That way, LLVM can take advantage of UB.

# Concurrency in Haskell

Great link to the GHC wiki that describes the concurrency primitives
"bottom up": https://gitlab.haskell.org/ghc/ghc/wikis/lightweight-concurrency

# Handy list of differential geometry definitions

There are way too many objects in diffgeo, all of them subtly connected.
Here I catalogue all of the ones I have run across:

##### Manifold

A manifold $M$ of dimension $n$ is a topological space. So, there is a
topological structure $T$ on $M$. There is also an _Atlas_, which is a family
of _Chart_s that satisfy some properties.

##### Chart

A chart is a pair $(O \in  T , cm: O -> \mathbb R^n$. The $O$ is an open set of the
manifold, and $cm$ ("chart for "m") is a continuous mapping from $O$ to $\mathbb R^n$
under the subspace topology for $U$ and the standard topology for $\mathbb R^n$.

#####  Atlas

An _Atlas_ is a collection of _Chart_s such that the charts cover the manifold,
and the charts are pairwise compatible. That is, $A = \{ (U_i, \phi_i) \}$, such
that $\cup{i} U_i = M$, and $\phi_j \circ phi_i^{-1}$ is smooth.

##### Differentiable map

$f: M \to N$ be a mapping from an $m$ dimensional manifold to an $n$ dimensional
manifold. Let $frep = cn \circ f \circ cm^{-1}: \mathbb R^m -> \mathbb R^n$
where $cm: M \to \mathbb R^m$ is a chart for $M$, $cn: N \to \mathbb R^n$
is a chart for $N$. $frep$ is $f$ represented
in local coordinates. If $frep$ is smooth for all choices of $cm, cn$,
then $f$ is a differentiable map from $M$ to $N$.

##### Curve:

Let $I$ be an open interval of $\mathbb R$ which includes the point `0`.  A Curve is a
differentiable map $C: (a, b) \to M$ where $a < 0 < b$.

##### Function: (I hate this term, I prefer something like Valuation):

A differentiable mapping from $M$ to $R$.


##### Directional derivative of a function `f(m): M -> R` with respect to a curve `c(t): I -> M`, denoted as `c[f]`.

Let `g(t) = (f . c)(t) :: I -c-> M -f-> R = I -> R`.
This this is the value `dg/dt(t0) = (d (f . c) / dt) (0)`.

##### Tangent vector at a point `p`:

On a `m` dimensional manifold `M`, a tangent vector at a point `p` is an
equivalence class of curves that have `c(0) = p`, such that `c1(t) ~ c2(t)` iff
:

- For a (all) charts `(O, ch)` such that `c1(0) ∈  O`, `d/dt (ch . c1: R -> R^m) = d/dt (ch . c2: R -> R^m)`.

 That is, they have equal derivatives.

##### Tangent space(`TpM`):

The set of all tangent vectors at a point `p` forms a vector space `TpM`.
We prove this by creating a bijection from every curve to a vector `R^n`.

Let `(U, ch: U -> R)` be a chart around the point `p`, where `p ∈ U ⊆ M`. Now,
the bijection is defined as:

```
forward: (I -> M) -> R^n
forward(c) = d/dt (c . ch)

reverse: R^n -> (I -> M)
reverse(v)(t) = ch^-1 (tv)
```

##### Cotangent space(`TpM*`): dual space of the tangent space / Space of all linear functions from `TpM` to `R`.

- Associated to every function `f`, there is a cotangent vector, colorfully
  called `df`. The definition is `df: TpM -> R`, `df(c: I -> M) = c[f]`. That is,
  given a curve `c`, we take the directional derivative of the function `f`
  along the curve `c`. We need to prove that this is constant for all vectors
  in the equivalence class and blah.

######  Pushforward `push(f): TpM -> TpN`

Given a curve `c: I -> M`, the pushforward
is the curve `f . c : I -> N`. This extends to the equivalence classes
and provides us a way to move curves in `M` to curves in `N`, and thus
gives us a mapping from the tangent spaces.

This satisfies the identity:

```
push(f)(v)[g] === v[g . f]
```

##### Pullback `pull(f): TpN* -> TpM*`

Given a linear functional `wn : TpN -> R`, the pullback is defined as
` wn . push(f) : TpM -> R`.


This satisfies the identity:

```
(pull wn)(v) === wn (push v)
(pull (wn : TpN->R): TpM->R) (v : TpM) : R  = (wn: TpN->R) (push (v: TpM): TpN) : R
```



##### Lie derivation

##### Lie derivation as lie bracket


# Lazy programs have space leaks, Strict programs have time leaks

Stumbled across this idea while reading some posts on a private discourse.
- Continually adding new thunks without forcing them can lead to a space leak,
  aka the dreaded monadic parsing backtracking problem.

- Continually _running_ new thunks can lead to a "time leak", where we spend
  far too much time running things that should not be run in the first place!

This is an interesting perspective that I've never seen articulated before, and
somehow helps make space leaks feel more... palatable? Before, I had no
analogue to a space leak in the strict world, so I saw them as a pathology. But
with this new perspective, I can see that the strict world's version of a space
leak is a time leak.

# Presburger arithmetic can represent the Collatz Conjecture

An observation I had: the function

```
f(x) = x/2      if (x % 2 == 0)
f(x) = 3x + 1   otherwise
```

is a Presburger function, so by building better approximations to the
transitive closure of a presburger function, one could get better answers
to the Collatz conjecture. Unfortunately, ISL (the integer set library) of today
is not great against the formidable foe.

The code:

```cpp
#include <isl/set.h>
#include <isl/version.h>
#include <isl/map.h>
#include <isl/aff.h>
#include <isl/local_space.h>
#include <isl/constraint.h>
#include <isl/space.h>

int main() {
    isl_ctx *ctx = isl_ctx_alloc();
    const char *s = "{ [x] -> [x / 2] : x >= 1 and x % 2 = 0; [x] -> [3 * x + 1] : x % 2 = 1}";

    isl_map *m = isl_map_read_from_str(ctx, s);

    isl_map_dump(m);

    int b = 0;
    isl_map *p = isl_map_transitive_closure(m, &b);
    p = isl_map_coalesce(p);
    printf("exact: %d\n", b);
    printf("map:\n");
    isl_map_dump(p);
    printf("map's range:\n");
    isl_set_dump(isl_set_coalesce(isl_map_range(isl_map_copy(p))));
    // print("map's range intersect 1: %d\n");


}

```

Produces the somewhat disappointing, and yet expected output:

```
$ g++ isl.c -lisl -Lisl-0.20/.libs -o isl -I/usr/local/include/ && ./isl
{ [x] -> [o0] : (2o0 = x and x > 0) or (exists (e0 = floor((1 + x)/2): o0 = 1 + 3x and 2e0 = 1 + x)) }
exact: 0
map:
{ [x] -> [o0] : (o0 < x and o0 > 0) or (exists (e0 = floor((x)/2), e1 = floor((2 + o0)/6), e2, e3, e4 = floor((-x + o0 + e2 - e3)/4): 2e0 = x and 6e1 = 2 + o0 and x >= 2 and 4e4 >= -3 - x + o0 + e2 - e3 and 4e4 >= 4 - x + o0 - 2e2 + 2e3 and 4e4 <= -x + o0 + e2 - e3)) or (exists (e0 = floor((x)/2), e1, e2, e3 = floor((-x + o0 + e1 - e2)/4): 2e0 = -1 + x and o0 > 0 and 4e3 >= -3 - x + o0 + e1 - e2 and 4e3 >= 3 - x + o0 - 2e1 + 2e2 and 4e3 <= -x + o0 + e1 - e2)) or (exists (e0 = floor((x)/2), e1, e2, e3 = floor((-x + o0 + e1 - e2)/4): 2e0 = x and x >= 2 and o0 > 0 and 4e3 >= -3 - x + o0 + e1 - e2 and 4e3 >= 3 - x + o0 - 2e1 + 2e2 and 4e3 <= -x + o0 + e1 - e2)) or (exists (e0 = floor((x)/2), e1 = floor((2 + o0)/6): 2e0 = -1 + x and 6e1 = 2 + o0 and o0 < x)) or (exists (e0 = floor((x)/2), e1 = floor((2 + o0)/6): 2e0 = x and 6e1 = 2 + o0 and x >= 2 and o0 <= -2 + x)) or (exists (e0 = floor((x)/2), e1 = floor((2 + o0)/6), e2, e3, e4 = floor((-x + o0 + e2 - e3)/4): 2e0 = -1 + x and 6e1 = 2 + o0 and 4e4 >= -3 - x + o0 + e2 - e3 and 4e4 >= 3 - x + o0 - 2e2 + 2e3 and 4e4 <= -x + o0 + e2 - e3)) }
map's range:
{ [i0] : i0 > 0 or exists (e0 = floor((2 + i0)/6): 6e0 = 2 + i0) }
```

I've yet to check that the image contains a `1` for every choice of `x`.


# Using compactness to argue about covers

I've always seen compactness be used by _starting_ with a possibly infinite
coverm and then _filtering it_ into a finite subcover. This finite
subcover is then used for finiteness properties (like summing, min, max, etc.).

I recently ran across a use of compactness when one _starts_ with the set
of _all possible subcovers_, and then argues about why a cover cannot be built
from these subcovers if the set is compact. I found it to be a very cool
use of compactness, which I'll record below:

#### Theorem:

If a family of compact, countably infinite sets `S_a` have all
_finite intersections_ non-empty, then the intersection of the family `S_a`
is non-empty.

#### Proof:

Let `S = intersection of S_a`. We know that `S` must be compact since
all the `S_a` are compact, and the intersection of a countably infinite
number of compact sets is compact.

Now, let `S` be empty. Therefore, this means there must be a point `p ∈ P`
such that `p !∈ S_i` for some arbitrary `i`.


#### Cool use of theorem:

We can see that the cantor set is non-empty, since it contains a family
of closed and bounded sets `S1, S2, S3, ...` such that  `S1 ⊇ S2 ⊇ S3 ...`
where each `S_i` is one step of the cantor-ification. We can now see
that the cantor set is non-empty, since:

1. Each finite intersection is non-empty, and will be equal to the set that
   has the highest index in the finite intersection.
2. Each of the sets `Si` are compact since they are closed and bounded subsets of `R`
3. Invoke theorem.


# Japanese Financial Counting system

- [Wikipedia](https://en.wikipedia.org/wiki/Japanese_numerals#Formal_numbers)

Japanese contains a separate kanji set called `daiji`, to prevent people
from adding strokes to stuff previously written.

```
#  |Common |Formal
1  |一     |壱
2  |二     |弐
3  |三     |参
```


# Stephen wolfram's live stream

- [Twitch.tv link](https://www.twitch.tv/videos/408653972)


I've taken to watching the live stream when I have some downtime and want
some interesting content.

The discussions of Wolfram with his group are great, and they bring up
_really_ interesting ideas (like that of cleave being very irregular).

# `Cleave` as a word has some of the most irregular inflections
- cleave
- clove
- cleaved
- clave
- cleft

# McCune's single axiom for group theory

[Single Axioms for Groups and Abelian Groups with Various Operations](http://ftp.mcs.anl.gov/pub/tech_reports/reports/P270.pdf)
provides a single axiom for groups. This can be useful for some ideas I have
for training groups, where we can use this axiom as the loss function!

# `Word2Vec` C code implements gradient descent really weirdly
I'll be posting snippets of the original source code, along with a
link to the Github sources. We are interested in exploring the skip-gram
implementation of Word2Vec, with negative sampling, without hierarchical
softmax. I assume basic familiarity with word embeddings and the skip-gram
model.

#### Construction of the sigmoid lookup table

```cpp
// https://github.com/tmikolov/word2vec/blob/master/word2vec.c#L708

expTable = (real *)malloc((EXP_TABLE_SIZE + 1) * sizeof(real));
for (i = 0; i < EXP_TABLE_SIZE; i++) {
  expTable[i] = exp((i / (real)EXP_TABLE_SIZE * 2 - 1) *
                    MAX_EXP);  // Precompute the exp() table
  expTable[i] =
      expTable[i] / (expTable[i] + 1);  // Precompute f(x) = x / (x + 1)
}
```
Here, the code constructs a lookup table which maps `[0...EXP_TABLE_SIZE-1]`
to `[sigmoid(-MAX_EXP)...sigmoid(MAX_EXP)]`. The index `i` first gets mapped
to `(i / EXP_TABLE_SIZE) * 2 - 1`, which sends `0` to `-1` and `EXP_TABLE_SIZE`
to `1`. This is then rescaled by `MAX_EXP`.

#### Layer initialization

- `syn0` is a global variable, initialized with random weights in the range of
  `[-0.5...0.5]`. It has dimensions `VOCAB x HIDDEN`.  This layer holds the
   hidden representations of word vectors.

```cpp
// https://github.com/imsky/word2vec/blob/master/word2vec.c#L341
a = posix_memalign((void **)&syn0, 128,
               (long long)vocab_size * layer1_size * sizeof(real));
...

// https://github.com/imsky/word2vec/blob/master/word2vec.c#L355
for (a = 0; a < vocab_size; a++)
        for (b = 0; b < layer1_size; b++) {
            next_random = next_random * (unsigned long long)25214903917 + 11;
            syn0[a * layer1_size + b] =
                (((next_random & 0xFFFF) / (real)65536) - 0.5) / layer1_size;
        }
```


- `syn1neg` is a global variable that is zero-initialized. It has dimensions
  `VOCAB x HIDDEN`. This layer also holds hidden representations of word vectors,
  _when they are used as a negative sample_.

```cpp
// https://github.com/imsky/word2vec/blob/master/word2vec.c#L350
a = posix_memalign((void **)&syn1neg, 128,
                   (long long)vocab_size * layer1_size * sizeof(real));
...
for (a = 0; a < vocab_size; a++)
    for (b = 0; b < layer1_size; b++) syn1neg[a * layer1_size + b] = 0;
```

- `neu1e` is a temporary per-thread buffer (Remember that the `word2vec` C code
  use CPU threads for parallelism) which is zero initialized. It has dimensions
  `1 x HIDDEN`.

```cpp
// https://github.com/imsky/word2vec/blob/master/word2vec.c#L370
real *neu1e = (real *)calloc(layer1_size, sizeof(real));
```

#### Backpropogation

Throughout `word2vec`, no 2D arrays are used. Indexing of the form
`arr[word][ix]` is manually written as `arr[word * layer1_size + ix]`. So, I
will call `word * layer1_size` as the "base address", and `ix` as the "offset
of the array index expression henceforth.

Here, `l1` is the base address of the word at the center of window (the focus
word).  `l2` is the base address of either the word that is negative sampled
from the corpus, or the word that is a positive sample from within the context
window.

`label` tells us whether the sample is a positive or a negative sample.
`label = 1` for positive samples, and `label = 0` for negative samples.

```cpp
// zero initialize neu1e
// https://github.com/imsky/word2vec/blob/master/word2vec.c#L419
for (c = 0; c < layer1_size; c++) neu1e[c] = 0;
...
// loop through each negative sample
// https://github.com/imsky/word2vec/blob/master/word2vec.c#L508
if (negative > 0)  for (d = 0; d < negative + 1; d++) {
  ...
  // https://github.com/imsky/word2vec/blob/master/word2vec.c#L521
  // take the dot product: f=  syn0[focus] . syn1neg[context]
  for (c = 0; c < layer1_size; c++) f += syn0[c + l1] * syn1neg[c + l2];

  // compute: g = (label - sigmoid(2f - 1)) * alpha
  // g is computed using lookups into a lookup table and clamping for
  // efficiency.
  if (f > MAX_EXP) g = (label - 1) * alpha;
  else if (f < -MAX_EXP) g = (label - 0) * alpha;
  else
  g = (label - expTable[(int)((f + MAX_EXP) *
                              (EXP_TABLE_SIZE /
                               MAX_EXP / 2))]) * alpha;
  // Now that we have computed the gradient:
  // `g = (label - output) * learningrate`,
  // we need to perform backprop. This is where the code gets weird.

  for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1neg[c + l2];
  for (c = 0; c < layer1_size; c++) syn1neg[c + l2] += g * syn0[c + l1];
  } // end loop through negative samples
// Learn weights input -> hidden
for (c = 0; c < layer1_size; c++) syn0[c + l1] += neu1e[c];
```

- We have _two_ vectors for each word, one called `syn0[l1 + _]` and
  the other `syn1neg[l2 + _]`. The `syn1neg` word embedding is used whenever
  a word is used a negative sample, and is not used anywhere else. Also,
  the `syn1neg` vector is zero initialized, while the `syn0` vectors are
  randomly initialized.

- The values we backprop with `g * syn1neg[l2 + _]`, `g * syn0[l1 + _]` are
  _not_ the correct gradients of the error term! The derivative of a sigmoid
  is `dsigmoid(x)/dx = sigmoid(x) [1 - sigmoid(x)]`. The `[1 - sigmoid(x)]`
  is nowhere to be seen, let alone the fact that we are using
  `sigmoid(2x - 1)` and not regular sigmoid. Very weird.

- We hold the value of `syn0` constant throughout all the negative samples,
  which was not mentioned in any tutorial I've read.

The paper does not mentioned these implementation details, and neither
does _any blog post that I've read_. I don't understand what's going on,
and I plan on updating this section when I understand this better.


# Arthur Whitney: dense code


- Guy who wrote a bunch of APL dialects, write code in an eclectic style
  that has very little whitespace and single letter variable names.
- Believes that this allows him to hold the entire program in his head.
- Seems legit from my limited experience with APL, haskell one-liners.
- [The b programming language](http://kparc.com/b/readme.txt). It's quite
  awesome to read the sources. For example, [`a.c`](http://kparc.com/b/a.c)

- [A history of APL in 50 functions](https://www.jsoftware.com/papers/50/) ---
  A great list of APL snippets that solve classical problems.

# How does one work with arrays in a linear language?

Given an array of qubits `xs: Qubit[]`, I want to switch to little endian.
Due to no-cloning, I can't copy them! I suppose I can use recursion to build
up a new "list". But this is not the efficient array version we know and love
and want.

The code that I want to work but does not:
```csharp
function switchEndian(xs: Qubit[]): Unit {
    for(i in 0..Length(xs) - 1) {
        Qubit q = xs[i]; // boom, this does not work!
        xs[i] = xs[Length(xs) - 1 - i]
        xs[Length(xs) - 1 - i] = q;
    }
}
```

On the other hand, what _does work_ is to setup a quantum circuit that
performs this flipping, since it's a permutation matrix at the end of
the day. But this is very slow, since it needs to simulate the "quantumness"
of the solution, since it takes `2^n` basis vectors for `n` qubits.

However, the usual recursion based solution works:
```csharp
function switchEndian(xs: Qubit[]): Qubit[] {
    if(Length(xs) == 1) {
        return xs;
    } else {
        switchEndian(xs[1..(Length(xs) - 1)] + xs[0]
    }
}
```

This is of course, suboptimal.

I find it interesting that in the linear types world, often the "pure" solution
is _forced_ since mutation very often involves temporaries / copying!

(I'm solving assignments in [qsharp](https://docs.microsoft.com/en-us/quantum/)
for my course in college)

# Linear optimisation is the same as linear feasibility checking
Core building block of effectively using the ellipsoid algorithm.

- If we posess a way to check if a point $p \in P$ where $P$ is a polytope, we
  can use this to solve optimisation problems.
- Given the optimisation problem maximise $c^Tx$ subject to $Ax = b$, we can
  construct a new _non-emptiness_ problem. This allows us to convert optimisation
  into _feasibility_.
- The new problem is $Ax = b, A^Ty = c, c^Tx = b^T y$. Note that by duality,
  a point in this new polyhedra will _be an optimal solution to the above linear program_.
  We are forcing $c^Tx = b^Ty$, which will be the optimal solution, since the
  solution where the primal and dual agree is the optimal solution by strong
  duality.
- This way, we have converted a _linear programming_ problem into a
  _check if this polytope is empty_ problem!

# Quantum computation without complex numbers

I recently learnt that the Toeffili and Hadamard gates are universal for
quantum computation. The description of these gates involve no complex numbers.
So, we can write any quantum circuit in a "complex number free" form. The caveat
is that we may very well have _input qubits_ that require complex numbers.


Even so, a large number (all?) of the basic algorithms shown in Nielsen and
Chaung can be encoded in an entirely complex-number free fashion.

I don't really understand the ramifications of this, since I had the intuition
that the power of quantum computation comes from the ability to express
complex phases along with superposition (tensoring). However, I now have
to remove the power from going from R to C in many cases. This is definitely
something to ponder.

- [Dorit Aharonov: A Simple Proof that Toffoli and Hadamard are Quantum Universal](https://arxiv.org/pdf/quant-ph/0301040)


# Linguistic fun fact: Comparative Illusion

I steal from wikipedia:

> Comparative Illusion, which is a grammatical illusion where certain
> sentences seem grammatically correct when you read them, but upon further
> reflection actually make no sense.

For example: "More people have been to Berlin than I have."


# Long-form posts:
## Reading
- [2018 reading](content/blog/stuff-i-learnt-this-year-2018.md)
- [2017 reading](content/blog/papers-I-read-and-loved-in-2017.md)

## Haskell
- [Reading the `structs` library](content/blog/reading-kmett-structs.md)
- [Reading the `machines` library (TODO)](content/blog/machines/reading-kmett-machines.md)
- [Explaining STG(TODO)](stg-explained.md)

## Simplexhc (STG -> LLVM compiler) progress
- [proc points suck / making GHC an order of magnitude faster](content/blog/ghc-micro-optimisations-or-why-proc-points-suck.md)
- [dec 2017](this-month-in-simplexhc-dec-2017.md)
- [oct 29 2017](this-week-in-simpexhc-oct-29-2017.md)
- [july 2017](this-week-in-simplexhc-07-2017.md)
- [july 6th 2017](this-week-in-simplexhc-2017-07-06.md)
- [announcement](content/blog/announcing-simplexhc.md)

## GSoC (2015)
- [proposal](content/blog/gsoc-vispy.md)
- [week 1](content/blog/gsoc-vispy-week-1-and-2.md)
- [week 3 and 4](content/blog/gsoc-vispy-week-3-and-4.md)
- [week 5](content/blog/gsoc-vispy-week-5.md)
- [week 6](content/blog/gsoc-vispy-week-6.md)
- [week 7](content/blog/gsoc-vispy-week-7.md)
- [final report](content/blog/gsoc-vispy-report-6.md)

# Big list of emacs

- `M-q`: `fill-paragraph`: make stuff 80 column, at least in text.  so this is not that bad.
- `C-u C-space`: go back to where you were in the file.
- `C-x r t`: `string-rectangle`. insert new text in a rectangle
     [ergoemacs ascii art](http://ergoemacs.org/emacs/emacs_string-rectangle_ascii-art).  I bind this to `C-x r i` for `insert`.
- `C-x r k`: delete column of text. For `kill`.
- `C-x space`: `rectangle-mark-mode` to select rectangles. `C-space` to lay down mark.
   I bind it to `C-x r r`.

#### Org
- `C-c C-c`: org-capture into code snippet.
- `C-c C-d`: open org-capture list.
- `C-c C-o`: follow a link.

#### Auctex

- `C-c C-a`: compile file.
- `C-c backtick`: go to error.
- `C-c C-v`: view file.
- `M-x TeX-error-overview`: see all errors
- `C-c C-s`: enter section
- `C-c C-e`: enter environment (stuff in between `\begin{}...\end{}`)
- `M-g n`: goto next error. `M-g p`: goto previous error.

## Magit
- `C-x g`: pop up magit

## LSP mode

```emacs
(define-key lsp-mode-map (kbd "C-c l") lsp-command-map)
```

- `C-c l g r`: goto ref
- `C-c l g g`: goto definition


## Eshell

- `C-c C-r`: go to output.
- `C-u C-c C-r`: narrow to output.
- `cd = ` gives a list to go do.
- Using `C-c =` gives a completion list.

## Dired

- `dired-jump`: open current file in dired.

## Gripes

#### `markdown-mode` lags when I open a paren `[for a link`.

I suppose this is because
it's attempting to match it, and is unable to figure out
what to match to. I now edit markdown in `text-mode`.

#### `ctrl-backspace`/`backward-kill-word` kills far too much.

- [reference `emacs.se`](https://emacs.stackexchange.com/questions/30401/backward-kill-word-kills-too-much-how-to-make-it-more-intelligent)

The answer seems to be:
yes, it kills a word. You can redefine what a word is,
and break lots of other stuff in the process, or redefine
what `ctrl-backspace` does. However, as a non-expert, it's hard
to say what redefining this will mean. Will it still interact
with history the same way?


#### there is no centralized notion of `C-o` (go back to where I came from).

- [reference `emacs.se`](https://emacs.stackexchange.com/questions/9908/can-cursor-jump-back-to-the-previous-position)
- [reference `stackoverflow`](https://stackoverflow.com/questions/4918707/in-emacs-how-to-go-back-to-previous-line-position-after-using-semantic-jump-to)

Instead, it differentiates between "go back in buffer" versus
"go back across buffers".

This is extremely confusing when one is attempting to read
code and understand control-flow: I want a _unified_ way
to say "go forward in my history; OK go back" when I am
exploring code. I don't *want* to keep track of whether
I came to this buffer from the same buffer or another buffer.
The fact that emacs needs this is moronic.

Furthermore, once a mark is popped, it is lost forever. In vim, one can
navigate backwards and forwards across movement. This is not possible with
emacs.

#### Scrolling half a page is broken

- [reference `emacs.se`](https://emacs.stackexchange.com/questions/27698/how-can-i-scroll-a-half-page-on-c-v-and-m-v)
- [reference `emacswiki`](https://www.emacswiki.org/emacs/HalfScrolling)

There is no inbuilt functionality to scroll half a page. The canonical 
reference points to this:

```lisp
(autoload 'View-scroll-half-page-forward "view")
(autoload 'View-scroll-half-page-backward "view")
(global-set-key (kbd "C-d") 'View-scroll-half-page-forward)
(global-set-key (kbd "C-u") 'View-scroll-half-page-backward)
```

However, this does not work well. On press `C-u` to go to
the top of the file, it does not move the cursor to the
top completely; once  _the first line is in view_
(with my cursor still on line 30),
emacs obstinately refuses to scroll up with a 'beginning of buffer'
message. I'm sure there's more `elisp` I can write to fix this,
but the fact that something like moving-half-a-page
is rocket science just rubs me the wrong way.

This code that is given in `emacswiki` also
has the exact same issue, I don't understand
how the poster says they come from vim and
did not notice this inconsistency.

```lisp
(defun zz-scroll-half-page (direction)
  "Scrolls half page up if `direction' is non-nil, otherwise will scroll half page down."
  (let ((opos (cdr (nth 6 (posn-at-point)))))
    ;; opos = original position line relative to window
    (move-to-window-line nil)  ;; Move cursor to middle line
    (if direction
	(recenter-top-bottom -1)  ;; Current line becomes last
      (recenter-top-bottom 0))  ;; Current line becomes first
    (move-to-window-line opos)))  ;; Restore cursor/point position

(defun zz-scroll-half-page-down ()
  "Scrolls exactly half page down keeping cursor/point position."
  (interactive)
  (zz-scroll-half-page nil))

(defun zz-scroll-half-page-up ()
  "Scrolls exactly half page up keeping cursor/point position."
  (interactive)
  (zz-scroll-half-page t))


(global-set-key (kbd "C-d") 'zz-scroll-half-page-down)
(global-set-key (kbd "C-u") 'zz-scroll-half-page-up)
```

#### Default encoding is weird: `chinese-iso-8bit`

- [`emacs.se reference`](https://emacs.stackexchange.com/questions/34322/set-default-coding-system-utf-8)

Why in the world is this the option that shows up by default?
There are so many better options, with `utf-8` being the
sanest of them all; this is a nice spherical cow of
the problems with emacs: too much stuff, too like sanity.

The spell is:

```
(set-language-environment "UTF-8")
```

##### linum lags on large files

`global-linum-mode` lags on very long files.

##### emacs lags on long lines

`emacs` lags given very long lines.

[A comment by `eli-zaretskli` on reddit](https://old.reddit.com/r/emacs/comments/9qtpak/what_would_it_take_to_make_emacs_perform_well_on/)
says:

> That is true, but the "fix" part misses the point. There's nothing wrong with
> the current algorithms, they just cannot handle these situations better than
> they already do. The main problem that makes redisplay slow in these cases is
> that, given a cursor motion command, such as `C-n` or `M-v`, the display engine
> needs first to find where in the buffer that command puts point. And that is
> non-trivial when variable-size fonts are supported and variable-size
> characters (or images) can be anywhere on display.


So there's a fundamental problem. He continues:

> ... we are talking about one of the following two
> alternatives: Add new members to the data structures used by the display
> engine, that would allow it to find good approximations for buffer positions
> corresponding to given screen coordinates, then augment the algorithms to
> generate and use this additional data.  edesign the display code to use a
> model that is entirely different from the current simple 2D canvas. 


##### emacs' single threading causes pauses on auto-complete/company

##### emacs crashes on attempting to open an SVG file

- [Link to `emacs` bug repo about segfault](http://emacs.1067599.n8.nabble.com/bug-29581-26-0-90-SVG-file-can-cause-emacs-to-crash-imagemagick-td443659.html)

My `emacs --version` says:
```
╰─$ emacs --version
GNU Emacs 26.2
Copyright (C) 2019 Free Software Foundation, Inc.
GNU Emacs comes with ABSOLUTELY NO WARRANTY.
You may redistribute copies of GNU Emacs
under the terms of the GNU General Public License.
For more information about these matters, see the file named COPYING.
```

I ran it with `emacs -q`. The bactrace points at a segfault in `ImageMagick`:

```
Fatal error 11: Segmentation fault
Backtrace:
emacs[0x50fdc9]
emacs[0x4f61f7]
emacs[0x50e77e]
emacs[0x50ea83]
emacs[0x50eac0]
/lib/x86_64-linux-gnu/libpthread.so.0(+0x11390)[0x7f213756b390]
/usr/lib/x86_64-linux-gnu/ImageMagick-6.8.9/modules-Q16/coders/svg.so(+0xb8b8)[0x7f211676e8b8]
/usr/lib/x86_64-linux-gnu/libMagickCore-6.Q16.so.2(ReadImage+0x198)[0x7f213d439a18]
/usr/lib/x86_64-linux-gnu/libMagickWand-6.Q16.so.2(MagickReadImage+0x6a)[0x7f213d90ba3a]
emacs[0x5e65fc]
emacs[0x5eed1d]
emacs[0x5ef1a0]
emacs[0x56cf26]
emacs[0x5a5ff8]
emacs[0x56ce93]
emacs[0x5a5ff8]
emacs[0x56ce93]
emacs[0x5a5ff8]
emacs[0x56ce93]
emacs[0x5a5ff8]
emacs[0x56ce93]
emacs[0x5a5ff8]
emacs[0x56ce93]
emacs[0x5a5ff8]
emacs[0x56ce93]
emacs[0x5a5ff8]
emacs[0x56ce93]
emacs[0x5a5ff8]
emacs[0x56ce93]
emacs[0x5a5ff8]
emacs[0x56ce93]
emacs[0x5a5ff8]
emacs[0x56ce93]
emacs[0x5a5ff8]
emacs[0x56ce93]
emacs[0x5a5ff8]
emacs[0x56ce93]
emacs[0x568c9d]
emacs[0x56cf26]
emacs[0x56eb24]
emacs[0x56904e]
...
[3]    7224 segmentation fault (core dumped)  emacs -q ~/work/IIIT-H-Code/softwarefoundations/project
```

This is tagged as "not a bug" --- because
"if imagemagick crashes, there is no recourse".



# Big list of Coq

Things in Coq that I keep forgetting, and are hard to lookup.

#### Manually set the value of an existential

```
instantiate
```
	
#### Rename an expression with an identifier throughout the proof

```
set (ident := expr) in *
```

This is useful to not lose information when `destruct` ing.

# Big list of writing

#### Books about charming sentences and how to construct them

#### Active v/s passive vocabulary

- passive vocabulary: Words one knows and can understand from context.
- active vocabulary: Words one uses actively while speaking.

The key to good writing for those who read a lot is to expand their
active vocabulary to match their passive vocabulary.

- A useful exercise is to look for synonyms during speech; This way,
  one forces an enlargening of active vocabulary. 

- Moulding one's inner mologoue to reach the ideal 'Voice' might also be
  benificial; However, there is a tendency that speech is not the same as
  writing --- very few people speak as they write. I wish to write like my idol
  (David Foster Wallace), who does speak like he writes. I surmise it's
  worthwhile to mould my inner speech to align with how my writing is supposed
  to be.

#### Punctuation

Should one use punctuation, or shoud not? How much should one use punctuation?
What range of punctuation should one use --- from the common`,` and `.`, all the
way up to `:`, `;`, and `---`. 

There appear to be three distinct schools of thought. 

- The first school of thought is prescriptive;
  They hold the belief that one must use _as much_ punctuation as is necessary to 
  accurately transcribe cadence.

- The second school are the moderates. Too much of
  punctuation can leave writing stilted, or worse, give it an appearance of putting
  on a veneer of respectability. Use as much punctation as is necessary, they say.

- The third school of thought is anarchic and recommend no punctuation at all
  except for `.` as this is a terrific way to get a sense for how to place
  words as one is forced to switch up vocabulary based on the cadence one
  wishes for instead of relying on artificial markers afforded by our system of
  writing.

#### English grammar

- [english club](https://www.englishclub.com/grammar/pronouns-relative.htm)
- [ginger software: grammar rules](https://www.gingersoftware.com/content/grammar-rules/)
- [Literary devices](https://literarydevices.net/)

I couldn't really find a good "grammar book", so I decided
to simply poll friends every time I came across a word that I 
didn't know. Assumes knowledge of `noun`, `pronoun`,
`verb`, `adjective`.


#### Pronoun resolution

- cataphora: later reference, anaphora: past reference?

The connection between this and `catamorphism`/`anamorphism`
is something I wish to explore.

- `let ([x 5]) (+ x 3))`: `x` is anaphora resolution.


# Big list of Latex


#### write text under some equation --- variable under max or argmax

```
y = \underset{x \in X}{\max} f(x)
```

#### Spell check

```
ispell yourfile.tex
aspell --mode=tex -c yourfile.tex
hunspell -l -t -i utf-8 yourfile.tex
```


# Big list of Architecture 

I have an interest in architecture and how it might relate to software.
While the two are quite different, I feel that a deep look at both could
be useful for both discplines. I think my favourite building to date
has been [fallingwater](https://en.wikipedia.org/wiki/Fallingwater). Here are
things on architecture I wish to read and/or have read:

- The way buildings learn.
- The sciences of the artifical.
- The timeless way of building.
- Eisenman
- [Why you hate contemporary architecture](https://www.currentaffairs.org/2017/10/why-you-hate-contemporary-architecture): 
  An article that provides points of view and a broad set of link on further
  reading to how architecture reached the 'contemporary', almost
  'uncomfortable' style it has today. Some choice quotes:

> There was a good reason why, historically, religious architecture has been
> the most concerned with beauty for beauty’s sake; the more time is spent
> elegantly decorating a cathedral, the more it serves its intended function of
> celebrating God’s glory, whereas the more time is spent decorating an office
> building, the less money will be left over for the developer. 

- The Geography of Nowhere: The Rise and Decline of America's Man-Made Landscape

- This place is not a place of honor... no highly esteemed deed is commemorated
  here... nothing valued is here. Design to ward off people for nuclear waste.

- [we forbit what we value most](https://www.strongtowns.org/journal/2017/11/20/we-forbid-what-we-value-most)

# Big list of Recipes 

#### Babish recipes

- [Binging with babish: Shwarma makes pita](https://www.youtube.com/watch?v=iErqWGwso7o)
- Chicken breast: https://www.youtube.com/watch?v=hR6agVkRRUo&list=PLopY4n17t8RBuyIohlCY9G8sbyXrdEJls&index=106

#### Upma

- start with ghee, sesame seeds, curry leaves, red + green chili, ginger garlic
  paste, hing (asaefodita).
- finely chopped onion, allow this to caramelize.
- A dash of turmeric for depth.
- Add in the rava, allow it to cook/heat.
- Add in tomato and a little water when it's done heating. Allow tomato to cook.
- Add in more water, cover with a lid, and let it come to a boil. Keep stirring
  to prevent clumps.
- Garnish with coriander.

#### General Coconut based thickening agent


- A few methi seeds (pungent, deep scent)
- some coriander seeds (mild herbal scent) 
- Chopped up red chilis (heat, spice, color)
- Chopped up green chilis (spice)
- Chopped up green chilis (spice)
- Chopped up garlic (some; strong, garlicky flavour and scent)

Heat the spices with oil to create a fragrant mix (Tadka[Hindi] / Oggarane[Kannada]).


- Grated coconut
- Salt (to taste)

Finally, throw in the above heated spices into the blender along with the
grated coconut and blend all of it. It turns into a thick red paste.


#### Breadfruit Sambhar


- Heat up oil.
- Fry **sesame seeds, cumin seeds, curry leaves, a tiny cinnamon stick** first. 
- Once fried, add in **garlic** to taste. 
- After garlic has fried as well, saute **onions** till golden. 
- Finely chop **tomatoes** and add it to the sauteed onions. Cover with a lid
- till the tomatoes release all their water.
- Now that we have a solid flavour base, pour in water to cook the breadfruit.
- Add in the **chopped breadfruit** --- chop the breadfruit in thin slices
- along the center; the center has interesting texture we wish to maximize. 
- Add in the **[General coconut based thickening agent](#general-coconut-based-thickening-agent)**.
- Also add salt to taste.
- Cover with a lid. Allow breadfruit, water, and thickening agent to come to a boil.
- Lower flame to low. Allow breadfruit to soften and cook.
- Once breadfruit is cooked, pour in **coconut milk**. Continue cooking for
  ten minutes.

#### Rava Dosa
- Mix bombay rava, maida/refined flour(2 tablespoons), rice flour (2 tablespoons),
  curd/buttermilk(100ml), salt (2 tablespoon), water (2 cups). Mix to form wet batter.
- We add the bombay rava for softness, refined flour as glue, and rice flour for
  crispiness. Curd for sourness and thickening.
- Next, heat up some oil, fry sesame seeds, finely chopped onions, curry leaves,
  asaefoedita, garlic. Add all of this into the batter mix.
- Allow batter to ferment overnight in the fridge.
- Make pancakes the next day.

#### Kerela style chicken curry

- Chop ginger and garlic roughly, boil chicken, salt, pepper-ginger-garlic-turmeric.
- Grate coconut finely, Roast grated coconut in a heated iron pan. Once well roasted,
  kill heat, add chili and coriander powder and salt, and mix.
- Next, fry thinly sliced onions in coconut oil.
- Add the onions in as a garnish at the last step.

#### Chutney

- Green chili
- Dried Coconut  pieces
- Salt
- Blend
- Add tamarind and water
- Blend 

#### Regular dosa batter:

- Grind coconut pieces
- Add dosa rice (2 cups)
- Add some water (100ml)
- Blend
- Salt
- Add more water (300ml).

# Big list of history

##### Crusades were a thing of the past by the time of the fall of Constatinople. (1453)

So the historian (Dr. Mario Philippedes) says on netflix's
rise of the empires:the Ottoman empire.
The crusades were roughly from 1000 to 1200.

##### undermine

Comes from miners digging under the walls. Learnt this from
'Rise of Empires: Ottoman'.

> The mining under the tunnel for the offensive (the Ottomans) was by serbian
> silver miners.  John Grant is the engineer during the siege of constantinople
> for the defense of the Byzantines/romans. He put barrels of water, and looked
> at the water ripples to figure out where the digging was going on. To quote:
> In pretty much all of history you will find a random British person, perhaps
> Scotsman involved in a war

                                                                                       
##### decephalized

> We need to clone decephalized humans and livestock.  With thousands of
> brainless bodies kept alive on life support, you have test subjects for a
> limitless number of experiments that would have never been possible before.
> You also create a never-ending O negative blood supply and organ harvesting
> program.  It the case of decephalized animals, you also get cruelty free
> meat. And that's how you bootstrap the program and port it to the human
> model.

##### demagoguery

The ancient Greeks had a word for our modern systems “demagoguery” which
equates to charismatic liars manipulating gullible people to vote against their
own good

##### laconic

Named after the spartans.

# Big list of words

Contains words that I write, and ones that I enjoy.

> Attention is all you need /
> productivity /
> sprighty, fleeting attention /

##### gesamtkunstwerk

A Gesamtkunstwerk (German: [gəˈzamtˌkʊnstvɛʁk], literally "total artwork",
frequently translated as "total work of art", "ideal work of art",
"universal artwork", "synthesis of the arts", "comprehensive artwork", or
"all-embracing art form") is a work of art that makes use of all or many art
forms or strives to do so. The term is a German loanword which has come to be
accepted in English as a core term in aesthetics.



##### anodyne

not likely to cause offence or disagreement and somewhat dull.
> "anodyne music"

#### syncretism

I ran into the word in the description of the electronic artist 'Jaenga'.

> human technological syncretism ...


**Meaning:** the amalgamation or attempted amalgamation of different religions,
cultures, or schools of thought.

#### absurd

The word “absurd” has a number of standard connotations: outlandish, crazy,
amazing, freakish. It comes from the Latin absurdum, meaning “out of tune,”
extraordinary. This, however, is not the way that Albert Camus meant the term
when he coined l’absurd as a philosophical concept in 1942. To Camus, the
absurd was strangely normal, a state of affairs that describes the human
condition—in a nutshell, the utter dissonance between the human quest for
meaning in life and the silent indifference of the universe

#### opprobrium

> public disgrace arising from shameful conduct.
> "the opprobrium of being closely associated with gangsters"

##### Pyretology

study of fevers

##### Soubrette

an actress or other female performer playing a lively, flirtatious role in a play or opera.


##### fiat

> fiat lux.

Let there be light

##### eudaimonia 

happiness as a result of fulfilling one's purpose (eudaimonia)


##### ubac/adret

> ubac "shady side of a mountain" and adret "sunny side of a mountain" (which
> are of French origin). Used to translate yin/yang.

##### Metier

> a profession or occupation.
> "the boy must begin to learn his métier as heir to the throne"


##### Livery

> a special uniform worn by a servant, an official, or a member of a City Company.
> "yeomen of the guard wearing a royal red and gold livery"


##### intransigence

> refusal to change one's views or to agree about something.
> Example: The underlying reason for the prolongation of the war is intransigence on all sides.
> Example from Downton Abbey: the aristocracy did not progress by their intransigence.


##### pip
> Pips are small but easily countable items, such as the dots on dominoes and
> dice, or the symbols on a playing card that denote its suit and value.
> Pip cards are the cards from 2..10 in a deck.


##### pusillanimity

> lack of courage or determination; timidity.
> "the pusillanimity of his answer surprised me"


##### Askefise

> one who blows on ashes to bring them to flame


# Big list of Music

- Clipping: Experimental story telling hip-hop
- Aesop Rock: Crazy large vocabulary, interesting hip-hop
- Red hot Chili Peppers: Love John Frusciante's riffs.

# Big list of Social Science 

- [HN link for quote below](https://news.ycombinator.com/item?id=24265400)

> Social justice and "fairness" is rarely one of the main goals of a
> meritocracy. The main goal of a meritocracy is peak performance. NFL teams
> select the "best" quarter-backs not because it's most fair, but because it
> will produce the most wins. Universities grant tenure to the most productive
> professors, because that will enhance the University's reputation. Hospitals
> hire the best doctors, because they can save the most lives. A society should
> delegate its most important responsibilities to its smartest/most-knowledgable
> members, because they can best lead society through worldly challenges.
> 
> Which is not to say that Social Justice isn't important. It is vital. But you
> don't get to it by hiring the wrong people in the wrong roles. A meritocracy
> excels at producing wealth - Universal Basic Income, Universal Healthcare,
> Unemployment Insurance, better Public Schooling... these are the kind of Social
> Justice programs that best distribute the wealth back to society.

# Big list of clojure 

### Neovim/Conjure/Coc-Conjure

```
Plug 'neoclide/coc.nvim', {'branch': 'release'}
Plug 'Olical/conjure'
let g:coc_global_extensions = ['coc-conjure']
let maplocalleader = ","
let g:conjure#mapping#eval_current_form = "er"
let g:conjure#mapping#eval_root_form = "ee"
let g:conjure#mapping#def_word = "d"
let g:conjure#mapping#eval_visual = "E"
let g:conjure#mapping#eval_motion = "E"
```

- evaluate OUTERMOST at point `<localleader>ee` [I find this very useful]
- evaluate INNERMOST at point `<localleader>er` [I find this not so useful]
- evaluate WORD at point: `<localleader>ew`
- lookup documentation: `<localleader>K`
- goto definition: `<localleader>d`
- evaluate selection in visual mode `<localleader>E`
- split vertical:  `<localleader> lv`
- auto complete `C-x C-o`
- I fucking love `parinfer`.
- [tutorial](https://oli.me.uk/getting-started-with-clojure-neovim-and-conjure-in-minutes/)
- On using multi-methods, make sure to refresh!

### Emacs/CIDER

- [Cheat sheet](https://github.com/mlakewood/cider-cheatsheet/blob/master/cheat.md)
- Switch between REPL and file: `C-c C-z`
- Go to previous location: `M-,`
- Go back inside file: `C-u C-SPC`
- Go back across files: `C-x C-SPC`
- Switch to REPL: `C-c C-z`
- Eval buffer: `C-c C-k` 
- Docs: `C-c C-d C-d`
- Goto symbol: `M.`
- Eval last sexp: `C-c C-e` / `C-x C-e`
- eval last definition: `C-c C-c`

# Big list of quotes

> Knuth says something similar (on his web page I think). He says he doesn't
> read email because email is good for people who want to stay on top of things
> but he wants to get to the bottom of things.

> "In the past everything was better, even the future" (K. Valentin, translated)


> You never rise to the occasion, you sink to the level of your training.

> "the mark of an enlightened mind is the ability to entertain ideas without
> accepting them"

> The most intelligent creature in the universe is a rock.
> None would know it because they have lousy I/O.


> Now symmetry and consistency are convertible terms - thus Poetry
> and Truth are one ~ Noether's theorem?

> Science is a differential equation. Religion is a boundary condition.
>(Alan Turing, quoted in J.D. Barrow, “Theories of everything”)

> (I really detest the use of the word "training" in relation to professional
> activities. Training is what you do to dogs. What you should be doing with
> people is educating them, not training them. There is a big, big difference.)
> ~ Ron Garret at JPL

> “Simulated consciousness" was as oxymoronic as "simulated addition.”


> A cylinder will roll like a sphere in one direction but not roll like a cube
> in the other. That doesn't make it a sphere and a cube at the same time. It
> makes it something different. (in analogy to wave-particle duality)


> Talent hits a target no one else can hit; Genius hits a target no one else
> can see..

> Raising your floor (consistency) is just as important as raising your ceiling
> (skill)

> "The sky is the limit, so lets build rockets!"


> The manner in which the mathematician works his way towards discovery by
> shifting his confidence from intuition to computation and back again from
> computation to intuition, while never releasing his hold on either of the
> two, represents in miniature the whole range of operations by which
> articulation disciplines and expands the reasoning powers of man. (Personal
> Knowledge, 131)

> Everyone knows that putting a untrained business major in charge of a
> squadron of soldiers would end badly. He might be able skate by until they
> got into combat, maybe, but after that they wouldn’t listen to him for long.
> But for some reason we think that putting an mba in charge of an engineering
> team is a good idea.

> "On and on you will go, making sense of the world, forming notions of order,
> and being surprised in ways large and small by their failure, forever." —
> Albert Burneko on Wile E. Coyote.

> "There is a special providence that protects idiots, drunkards, children, and
> the United States of America." ~ Otto van bismarck

> "Never believe anything in politics until it has been officially denied" 
> ~ Otto von Bismarck


> A good proof is one that makes us wiser. -- Yuri Manin


> Keep things in their Gauss given order. -- Gilbert Strang


> It is interesting to see where people insist proximity to a subject makes one
> informed, and where they insist it makes them biased. It is interesting that
> they think it’s their call to make. [in the context of 'as a male, you don't
> get a say about toxic masculinity' v/s other 'viewpoints'] ~ [medium article link](https://medium.com/@jencoates/i-am-a-transwoman-i-am-in-the-closet-i-am-not-coming-out-4c2dd1907e42)


> "Feeding two birds with one scone"
> Peta recommended version of "killing two birds with one stone"


> the first sign of civilization in an ancient culture was a femur
> that had been broken and then healed ~ Margaret Mead 

> The mistake of many adults is confusing serious with solemn.

> I hate greek drama. You know, wher everything happens off-stage. 
> ~Downton abbey, s02e01

> you have to speculate to accumulate

> It's so reassuring to see the future unfurl, as long as you remember
> that it bears no resemblance to the past.

> Sybil, vulgarity is no substitute for wit. ~  Violet, Downton Abbey

> "Why dwell on that now?" "Because I want to feel the pleasure of telling you I
> told you so".


> The law, in its majestic equality, forbids rich and poor alike to sleep under
> bridges, to beg in the streets, and to steal loaves of bread.”


> 'The history of transistors is the history of solving Schrödinger's equation in various materials.' -- Leon Lederman

> tradition that contested poems would be thrown into a pool. The better poems
> would float. Now you know why you shouldn't write dense prose. ~ History of india podcast

> children cried with hunger. Women plaited their braids without flowers. ~ History of india podcast.

> "There is a spooky quality about the ability of mathematicians to get there
> ahead of physicists. It's as if when Neil Armstrong first landed on the moon
> he found in the lunar dust the footsteps of Jules Verne" - Steven Weinberg on
> old math being applied in physics

> You can try; trying is the first step of failure ~ GM Ben finegold on mating sequences.

> Some folks prefer the carrot, I the stick. So I will use my considerable
> expertise to stick it to you.

> "Machine learning is like money laundering for bias"

> Criticism is prejudice made plausible.” - H.L. Mencken

> David Marquet's credos from "Turn The Ship Around!". Don't ask "Are we
> ready?"; instead, ask "How ready are we?".  Everything needs to be phrased so
> as to invite people to express the knowledge they have, rather than demanding
> what amounts to a declaration of
> tribal identity.

> You can't just go around recognizing what people don't understand. That's
> what got Socrates killed. You've gotta make them understand what they don't
> understand without making them want to kill you. That's what makes a great
> teacher / leader / etc.

> 'Every work of art is an uncommitted crime.' - Adorno.


> Policies are nice but at the end of the day we need folks to set an example
> (rather than being made an example of)


> “The math students dropped out because they could not understand anything. Of
> course, I didn’t understand anything either, but non-math students have a
> different standard of what it means to understand something,” Huh said. “I
> did understand some of the simple examples he showed in classes, and that was
> good enough for me.”
> https://www.quantamagazine.org/a-path-less-taken-to-the-peak-of-the-math-world-20170627/

> "you're such a dick!". 
> "I'm moby goddamn dick, and you're swimming in my water".

> When people thought the earth was flat, they were wrong. When people thought
> the earth was spherical, they were wrong. But if you think that thinking the
> earth is spherical is just as wrong as thinking the earth is flat, then your
> view is wronger than both of them put together.


> "Ethereum has said they're moving from Proof of Work to Stake; I'm not
> surprised, given the Ethereum developers seem to abhor Work in all of its
> forms, including making progress on Ethereum itself"

# Empathy

> Oof, I don't really know what to say right now but I'm glad you told me

- [Brene brown on empathy](https://www.youtube.com/watch?v=1Evwgu369Jw)
- [It's not about the nail](https://www.youtube.com/watch?v=-4EDhdAHrOg)



# Big list of Vim 

### Using `:grep` and friends

```
:grep <grep-invocation> 
```

- This will populate the error window. 
- Open the error window with `:copen`.
- Thanks to `vim-unimpaired`, going next/previous is as easy as `[q` and `]q`
  (`q` for `quickfix`).

##### sed matching syntax


- `\<word\>`: match word starting and ending.

##### vim motion mnemonics

- f<char> - (f)ind a character forward in a line and move to it
    - T<char> - find a character backward in a line and move un(t)il it
- t<char> - find a character forward in a line and move un(t)il it (one character before)
    - F<char> - (f)ind a character backward in a line and move to it


##### vim unimpaired for loclist movement


- `]q` /`[q`: move loclist.

##### vim-ninja-feet for motions using text objects

With it installed, add [ or ] between the operator and text object to specify
which end you wish edit: press c]i} to perform the edit you describe.

-`a)`: a parentheses block
-`i)`: inner parentheses block
-`a]`: a bracketed block
-`i]`: inner bracketed block
-`a}`: a brace block
-`i}`: inner brace block


# Big list of Chess

- On Lichess, goto `sound -> speech` to be able to HEAR moves! Similarly,
  enable notation everywhere in preferences to get used to reading moves in
  notation.

- [How to defend `e5` in king's indian defense](https://www.youtube.com/watch?v=jAwSBrLk3Uw)
- [King and pawn versus king](https://www.youtube.com/watch?v=OzskUgwPCEg&list=PLVWaFpMwtaGiBxi79IUqnqn67WF5g5PR4&index=27)
- [All about forks](https://www.youtube.com/watch?v=51vnCWXXLGc&list=PLVWaFpMwtaGiBxi79IUqnqn67WF5g5PR4&index=49)

- Good linux app: `scid vs pc`. Seems to contain engines .
- Keep king on a *diagonal* 2 squares away from the knight to ensure safety.
- Pro tip for king+queen checkmate : always keep the queen at a position as if u r trying to give a check with a knight.
- knight+bishop: Bishop B7, King to B8. Knight to D7, and that's checkmate

# Big list of shitposting

> ~ Siddharth, you said you're wired that way and thus can't believe in religion.
> So you can't change yourself, thus you're pure.
> Therefore, all you need is a [monad](https://en.wikipedia.org/wiki/Monad_(philosophy))
> to change the immutable into the mutable --- Thus, embrace the Leibniz.

# Cardistry


#### Currently learning

Plan: finish cardistry bootcamp, learn card control from 52kards.
- [Hot shot](https://www.youtube.com/watch?v=ZmXMgJGtgts)
- [Sybil](https://www.youtube.com/watch?v=s6F3Em7McOs&list=PLIYzPFCPrDTDGSbF0Epp7_ZGCCSsUVM1d&index=20)
- [Straddle pass control by Champion Magic](https://www.youtube.com/watch?v=Hp-lpNJAo5Q)
- [Card control chris ramsay](https://www.youtube.com/watch?v=NCUfHRvCJj0)
- [Riffle shuffle from 52kards](https://www.youtube.com/watch?v=uW8zMwJF5ys)
- [False riffle shuffle by 52kards](https://www.youtube.com/watch?v=sLIS4c2dUwc)

#### Next
- [Basic passes: control top card, prereq for color change](https://www.youtube.com/watch?v=yM-m6j2WuL4)
- [Push off second deal](https://www.youtube.com/watch?v=i5JlED3erBY)
- [Bertram color change](https://www.youtube.com/watch?v=omcbLkcQkBk)
- [Tenkai palm](https://www.youtube.com/watch?v=fsy1FA2n1RY)
- [Flourish: Flirt](https://www.youtube.com/watch?v=tFb7gCgsqcQ)
- [Ekatarina list of tutorials](https://www.youtube.com/watch?v=XGCCqdr6r08&list=PLUCOIt3_dATNX4A4W4pBMr7MERO64-aBL)
- [Hot shot sandwhich: magic trick](https://www.youtube.com/watch?v=RJjzc1w7u5I)
- [Chris Ramsay list of tutorials](https://www.youtube.com/watch?v=vM1_u-A4zgk&list=PLNZrOW6NuocraONXJjyPrDcGnHJt5dUJV)

#### Hiatus (too difficult for now)

- [Lepaul spread](https://www.youtube.com/watch?v=0s6beNSX-L0)

#### Learnt

- [How to get started?](https://www.youtube.com/watch?v=g8mbn7TLATA) 
   1. Basic grips (School of Cardistrys youtube channel and start from their first video "grips) 2. Cuts 3. Flourishes

- [Basics: grips](https://www.youtube.com/watch?v=bt0RumRuwGQ)

1.  Dealer's  / Mechanic's grip (thumb left, index top, others right)
2. Straddle Grip (pinky bottom, index top, thumb left, others right)
3. Biddle Grip
4. End Grip (two index fingers opposing each other) 
5. "Z" Grip


- Basics: Thumb Fan: key ingredients are (a) hold the palming hand straight so
  fingers don't intervene, (b) thumb grip should be strong to allow index finger
  to go wild, (c) pull with the index finger in a semicircular arc.
  I practiced this for two weeks till it suddenly snapped into place.

- [Overhand Shuffle](https://www.youtube.com/watch?v=0_aY0jC8DY4)
- [Overhand Shuffle: controlling the top card](https://www.youtube.com/watch?v=VkE8fNFBUw8)
- [Basic Cardistry: Charlier Cut](https://www.youtube.com/watch?v=BNC_DD9XccI&list=PLIYzPFCPrDTDGSbF0Epp7_ZGCCSsUVM1d&index=2):
  Cut, pick it up, slide, hold. Dealer's grip little finger is useful to keep the non-picked-up part of deck from sliding!
- Basic Cardistry: Thumb cut
- [Chinese deal](https://www.youtube.com/watch?v=FYGY-Z2qQVY)
- [Hindu Shffle: control](https://www.youtube.com/watch?v=P_C1clIaOX4)
- [Basic Cardistry: Revolution Cut](https://www.youtube.com/watch?v=4modjrvBopw)

#### Long term
- [Cardistry bootcamp](https://www.youtube.com/watch?v=bt0RumRuwGQ&list=PLIYzPFCPrDTDGSbF0Epp7_ZGCCSsUVM1d)
- [Basics: Scissor cut](https://www.youtube.com/watch?v=z9YkyM0hG3M)
- Basics: Swing Cut
- Basics: Card spring
- Basics: Pressure Fan
- Basics: Faro Shuffle
- Basics: Sybil Cut
- Basics: Werm
- Basics: Hot Shot Cut

#### Resources

- [Cardistry forum at theory11](https://www.theory11.com/forums/cat/general-discussion/)
- [Deceptionary: card stacks](https://www.deceptionary.com/aboutstacks.html)

> Eight kings threatened to save,
> nine fine ladies for one sick knave. 8–K–3–10–2–7–9–5–Q–4–A–6–J)

- [Deceptionary: suit order](https://www.deceptionary.com/aboutsuits.html)

- [Kruskal card trick](http://www.ams.org/publicoutreach/feature-column/fcarc-mulcahy6)

- [Big list of card mnemonics on wikipedia](https://en.wikipedia.org/wiki/List_of_playing-card_nicknames)

# Poems to memorize
- [Ode on the Death of the Duke of Wellington](https://www.bartleby.com/246/385.html)


# X86

##### Mnemonical for CCall
```
%rdi:   Diane's
%rsi:   Silk
%rdx:   dress
%rcx:   costs
%r8:    $8
%r9:    9
```

##### Mnemonic for syscall calling convention
```
* rax  system call number  - All (system, can make universal quantification!)
* rdi  arg0 - Diane's
* rsi  arg1 - Silk
* rdx  arg2 - Dress
* r10  arg3 (uses r10 instead of rcx)
* r8   arg4 - 8$
* r9   arg5 - 9
```

# Big list of writing/paper writing thoughts

- Strongest words ought to start and begin a sentences. A re-phrasing I made:
 "Thus, we know that `pr-ty` lives in UNIV because of correctness of `synth`" into
 "Correctness of `synth` guarantees that `pr-ty` lives in UNIV".
- There is low satisfaction of finishing and understanding a section, it seems
  to flow a little too continuous.
- Align figures to either all left or all right.
- In structure, label references to future sections are non existent, so it
  would help assure the reader in section x that you will talk more about the
  uses of this in section y.

# Big list of interpersonal thoughts
-  What do you have in mind? works well to get to know what the other person
   would like.
- So the way I see it, is that as soon as you are
  naming something, people may ask things like "What
  is X exactly? What is X composed of?". So I can
  clearly see reviewers ask "What is DSL composed
  of?", but if we wouldn't name it, I wouldn't expect
  reviewers to ask "What is the python interface composed of?"


# Big list of common lisp

```lisp
;; to change package, goto SLIME, type `,` for `, set package`.
(declaim (optimize (speed 0) (safety 3) (debug 3)))
(defpackage :rasterizer1 (:use :common-lisp))
```

- [Paredit cheat sheet](https://www.emacswiki.org/emacs/PareditCheatsheet)
- [SLIME tutorial](https://www.youtube.com/watch?v=_B_4vhsmRRI)
- First thing to do: `slime-sync-package-and-default-directory` (`C-c ~`) to setup package and `cwd`.
- SLIME + parinfer + SBCL is quite a pleasant emacs lisp experience.
- LISPY-mode interface: eval expr (`e`), jump to definition (`F`), go back (`D`)
- SLIME debugger: abort(`a`), continue(`c`), quit(`q`),  goto frame source (`v`), toggle frame details (`t`),
  navigate next/prev frame(`n`, `p`), begin/end (`<`,`>`),
  inspect condition (`c`), interactive evaluate at frame (`:`)
- SLIME REPL: send expr to repl(`C-c C-y`), switch to repl (`C-c C-z`), eval last expr (`C-x C-e`), trace (`C-c C-t`)
- SMILE REPL debug: trace (`C-c C-t`). Write `(break)` in code and then run expression to enter debugger,
  step into (`s`), step over (`x`), step till return (`o`), restart frame (`r`), return from frame (`R`),
  eval in frame (`e`)
- SLIME compile: compile whole file (`C-c C-k`), eval defun (`C-c C-c`), trace (`C-c C-t`).
- SIME docs: lookup on hyperref (`C-c C-d h`)
- SLIME goto: edit definition (`M-.`), come back (`M-,`). Find all references (`M-?`)
- TODO: consider [Sly](https://github.com/joaotavora/sly) rather than SLIME?
- SLIME repl options: set current working directory (`,!d`), set package
  (`,push-package <package-name>`). Alternatively, execute `(swank:set-default-directory "/path/to/desired/cwd/")`
- SLIME Restart: [`M-x slime-restart-inferior-lisp`](https://stackoverflow.com/questions/3725595/reset-state-in-common-lisp),
    or call [`(progn (unload-feature 'your-lib) (load-library "your-lib"))`](https://emacs.stackexchange.com/a/26606/28600)
- [SLIME force re-evaluation of `defvar`, use `M-x slime-eval-defun` (`C-M-x`)](https://emacs.stackexchange.com/questions/2298/how-do-i-force-re-evaluation-of-a-defvar).



##### Toys

> Special variables (Mutable globals) should be surrounded by asterisks. These are called earmuffs.
> (defparameter *positions* (make-array ...))

```lisp
(assert (condition)
       (vars-that-can-be-edited))
;; https://lispcookbook.github.io/cl-cookbook/error_handling.html#handler-case-vs-handler-bind
(defun divide (x y)
  (assert (not (zerop y))
          (y)   ;; list of values that we can change.
          "Y can not be zero. Please change it") ;; custom error message.
  (/ x y))
```

- [common lisp libraries read-the-docs](https://common-lisp-libraries.readthedocs.io/asdf/)
- [Code eval play loop: livecoding opengl things](https://github.com/cbaggers/cepl)
- Consider [lispy](https://github.com/abo-abo/lispy)  instead of `parinfer`.
- [`cl-repl`](ros install koji-kojiro/cl-repl) for quick command line hackery.
- stdlib is large.

- Loading new libraries:

```
(ql:quickload "str")
```

# Big list of Agda

- Load/check file: `C-c C-l`.
- Show goals: `C-c C-?`.
- Accept goal value: `C-c C-SPACE`
- forward goal: `C-c C-f`
- backward goal: `C-c C-b`
- Normal form: `C-c C-n`
- see how to write symbol: `M-x quail-show-key`.
- Within goal: Case split: `C-c C-c`.
- Within goal: Refine: `C-c C-r`. Partial give: makes new holes for missing arguments
- Within goal: Type: `C-c C-t`.
- Within goal: Deduce type: `C-c C-d`.
- Within goal: Information: `C-c C-;`.


# Big list of Hacker news 

> She told me that I was what she calls institutionally poor. That I had been
> conditioned thru my childhood to think like a poor person and in doing so you
> send out unconscious signals to others. She told me this because she came up
> similar. She told me that it causes you to over analyze and over estimate
> risk and therefore you will not take the bold moves that people that don't
> have to worry do. That while you can change the world and everyone see it. If
> you hold onto the fear on meeting your net under you, that you will never
> extract your true value from other. So I said, so you are going to pay me my
> fair value, she laughed and said no, I got you for a very good deal. 3 Days
> latter I walked into her office, with my resignation letter and told her I
> had an offer from another company. She said, now you get it, how much did
> they offer. I told her, and she said I will double that if you stay.



> Here's a discontinuity irl that I read about: you bite into an apple and find
> a worm. Disgusting. But worse would be to find 1/2 a worm, worse still 1/4 of
> a worm, etc... continuity would imply the worst case scenario is biting into
> an apple and not finding a worm.

> PORT (wine) is always LEFT at sea, but never left at dinner.
> L for LEFT, is close to P for PORT. R for RIGHT, is close to S for STARBOARD


> Mona Lisa was special in part because it was uncommon for people to smile. In
> Middle Ages, someone smiling a lot would be perceived as stupid. That's why
> facial expressions in medieval imagery are so serious. Today, being surprised
> a lot is often taken as a sign of stupidity, whereas in ancient Greece an owl
> was the bird of Athena, the goddess of wisdom. Because, obviously, an owl is
> always surprised, and surprise is the first step to understanding.

# Big list of speaking / oration

my only other critique, =which is good in general, but try to force yourself to
speak slower than you want to.

taking time to build a diagram is the best way to convey knowledge


learning to be comfortable with silences while speaking doesn't come naturally to anyone.


Some kids grow up on football. I grew up on public speaking (as behavioral
therapy for a speech impediment, actually). If you want to get radically better
in a hurry: 1) If you ever find yourself buffering on output, rather than
making hesitation noises, just pause. People will read that as considered
deliberation and intelligence. It's outrageously more effective than the
equivalent amount of emm, aww, like, etc. Practice saying nothing.  Nothing is
often the best possible thing to say. (A great time to say nothing: during
applause or laughter.) 2) People remember voice a heck of a lot more than they
remember content. Not vocal voice, but your authorial voice, the sort of thing
English teachers teach you to detect in written documents. After you have found
a voice which works for you and your typical audiences, you can exploit it to
the hilt.  I have basically one way to start speeches: with a self-deprecating
joke. It almost always gets a laugh out of the crowd, and I can't be nervous
when people are laughing with me, so that helps break the ice and warm us into
the main topic.  3) Posture hacks: if you're addressing any group of people
larger than a dinner table, pick three people in the left, middle, and right of
the crowd. Those three people are your new best friends, who have come to hear
you talk but for some strange reason are surrounded by great masses of mammals
who are uninvolved in the speech. Funny that. Rotate eye contact over your
three best friends as you talk, at whatever a natural pace would be for you.
(If you don't know what a natural pace is, two sentences or so works for me to
a first approximation.) Everyone in the audience -- both your friends and the
uninvolved mammals -- will perceive that you are looking directly at them for
enough of the speech to feel flattered but not quite enough to feel creepy.  4)
Podiums were invented by some sadist who hates introverts. Don't give him the
satisfaction. Speak from a vantage point where the crowd can see your entire
body.  5) Hands: pockets, no, pens, no, fidgeting, no. Gestures, yes. If you
don't have enough gross motor control to talk and gesture at the same time (no
joke, this was once a problem for me) then having them in a neutral position in
front of your body works well.  6) Many people have different thoughts on the
level of preparation or memorization which is required. In general, having
strong control of the narrative structure of your speech without being wedded
to the exact ordering of sentences is a good balance for most people. (The fact
that you're coming to the conclusion shouldn't surprise you.) 7) If you
remember nothing else on microtactical phrasing when you're up there, remember
that most people do not naturally include enough transition words when speaking
informally, which tends to make speeches loose narrative cohesion. Throw in a
few more than you would ordinarily think to do. ("Another example of this...",
"This is why...", "Furthermore...", etc etc.).

Use `for little c in big C` to say things like `for c ∈ C`
