<!DOCTYPE html><meta charset='UTF-8'><html><head><link rel='alternate' type='application/rss+xml' href='feed.rss' title='A universe of sorts'/><link rel='stylesheet' href='katex/katex.min.css'    integrity='sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X'    crossorigin='anonymous'><!-- The loading of KaTeX is deferred to speed up page rendering --><link rel='stylesheet' href='prism/prism.css'><title> A Universe of Sorts </title><style>@font-face {font-family: 'Blog Mono'; src: url('/static/iosevka-fixed-extended.ttf');}@font-face {font-family: 'Blog Sans'; src: url('/static/Exo2-Regular.ttf');}@font-face {font-family: 'Blog Serif'; src: url('/static/Revans-Regular.ttf');}html { font-size: 100%; }html,body { text-size-adjust: none; -webkit-text-size-adjust: none; -moz-text-size-adjust: none; -ms-text-size-adjust: none; } body { background: linear-gradient(to right, #1565C0 0%, #1565C0 50%, #E91E63 50%,   #E91E63 99%);  color: #000000;  font-family: Tahoma, 'Blog Serif', serif;  font-size: 14px;  margin-top: 0px;  max-width: 100%; overflow-x: hidden; }
h1, h2, h3, h4, h5 { font-family: Tahoma, 'Blog Mono', monospace; }img { display:block; width: 100%; max-width: 800px; height: auto }.container { overflow-x: auto; overflow-y: hidden;  max-width: 80ex; text-align: justify;              margin-top: 0px; height: 100%; min-height: 100%;             padding-left: 50px; padding-right: 50px; background: #FFFFFF;}@media (max-width: 480px) {   .container { margin-left: 1%; margin-right: 1%; }  body { font-size: 30px; }  } @media (max-width: 1024px) {  .container { margin-left: 1%; margin-right: 1%; }  body { font-size: 30px; }}@media (min-width: 1024px) { .container { margin-left: 25%; margin-right: 20%; } }.image { }
a:hover { color: #1a73e8; text-decoration: underline;  }
a { color: #1a73e8; text-decoration: none; }
a:visited { color: #1a73e8; text-decoration: none; }
a:active { color: #1a73e8; text-decoration: none; }

blockquote { margin-left: 0px; margin-right: 0px; } pre, .latexblock, blockquote { border-left-color:#BBB;  border-left-style: solid;      border-left-width: 5px; }pre, blockquote { padding-left: 10px; }
pre { font-family: 'Blog Mono', monospace; font-size: 90%;  }pre {  overflow-x: auto; }.latexblock, blockquote, pre { margin-top: 10px; margin-bottom: 10px; padding-bottom: 5px; padding-top: 5px; background-color: #FFFFFF; }.latexblock { line-height: 1em }
pre, kbd, samp, tt{ font-family:'Blog Mono',monospace; }.inline { white-space: nowrap; background:#efefef; }ul, ol { list-style-position: inside; padding-left: 0; }ul { list-style-type: disclosure-closed; }</style></head><body><div class='container'><h2><a id=stuff-i-learnt-in-2022 href='#stuff-i-learnt-in-2022'> § </a><span class='centered'> Stuff I learnt in 2022 </h2> 
 <span class='centered'>2022 was a weird year for me. I moved from India to Edinburgh to pursue 
 <span class='centered'>my PhD, and a lot of the year was (and still is) getting used to 
 <span class='centered'>what it even means to be a PhD student. Here's a run down of the 
 <span class='centered'>things I learnt this year, and what the experience of doing this was.  
 <h4><a id=semantics-of-mlir-in-lean href='#semantics-of-mlir-in-lean'> § </a><span class='centered'> Semantics of MLIR in Lean </h4> 
 <span class='centered'>The first project I took up was to define the semantics of  <a href=https://mlir.llvm.org/><span class='centered'>MLIR </a>, 
 <span class='centered'>a new compiler infrastructure in the  <a href=https://leanprover-community.github.io/><span class='centered'>Lean4 </a> proof 
 <span class='centered'>assistant, titled boringly as  <a href=https://github.com/opencompl/lean-mlir><span class='centered'><code class='inline'>opencompl/lean-mlir</code></a>.  
 <span class='centered'>While working on the project, I did a bunch of useful things:  
 <ul><li><span class='centered'><span class='centered'> I helped write the  <a href=https://github.com/arthurpaulino/lean4-metaprogramming-book><span class='centered'>Lean metaprogramming.book </a>, <span class='centered'>an open-source book on using Lean's powerful metaprogramming facilities. </li><li><span class='centered'><span class='centered'> I read through  <a href=https://github.com/digama0/lean-type-theory><span class='centered'>Mario Carneiro's thesis, models of dependently typed programming languages </a><span class='centered'>which explains Lean's metatheory and a proof of consistency of Lean. I quite liked this thesis, since it provides <span class='centered'>a very readable set-theoretic semantics for Lean! </li></ul> 
 <h4><a id=lean-oss-work href='#lean-oss-work'> § </a><span class='centered'> Lean OSS work </h4> 
 <span class='centered'>I also began contributing to the proof assistant itself. 
 <span class='centered'>In particular, I've been slowly chipping away at adding  <a href=https://github.com/leanprover/lean4/pull/1837><span class='centered'>LLVM support </a>, 
 <span class='centered'>which got merged on the 31st, right before new years! The hardest part was learning a huge amount 
 <span class='centered'>about low-level linkers, loaders, and other cross platform shenanigans. The sources I leaned against 
 <span class='centered'>most were:  
 <ul><li><span class='centered'><span class='centered'> The  <a href=https://cmake.org/documentation/><span class='centered'>CMake manual </a>, which actually makes CMake sensible. I quite like CMake now, <span class='centered'>since I actually understand its semantics. </li><li><span class='centered'><span class='centered'>  <a href=http://14.99.188.242:8080/jspui/bitstream/123456789/12311/1/LinkerLoader.mca.pdf><span class='centered'>Linkers and Loaders </a>, to learn <span class='centered'>a ton of the arcane details of how precisely loading works. </li><li><span class='centered'><span class='centered'> The  <a href=https://www.gnu.org/software/binutils/><span class='centered'>GNU binutils </a>, which were a lifesaver in debugging weird linker visibility issues. </li></ul> 
 <h4><a id=partial-evaluation href='#partial-evaluation'> § </a><span class='centered'> Partial Evaluation </h4> 
 <span class='centered'>I was also interested in improving the performance of the code generator, and was frustrated that we in compilers 
 <span class='centered'>kept rediscovering basic optimisation techniques over an over again. Partial Evaluation seemed like a powerful 
 <span class='centered'>technique to prevent this waste, and I thus began reading the literature on partial evaluation. The best 
 <span class='centered'>book I found was called  <a href=https://www.itu.dk/people/sestoft/pebook/jonesgomardsestoft-a4.pdf><span class='centered'>Partial evaluation and automatic program generation </a>, 
 <span class='centered'>and I  <a href=https://github.com/bollu/halfred><span class='centered'>implemented the algorithms from the book </a>. However, I haven't had the time 
 <span class='centered'>to integrate these back into lean proper. Plans for next year!  
 <h4><a id=adjoint-school-and-category-theory href='#adjoint-school-and-category-theory'> § </a><span class='centered'> Adjoint School And Category Theory </h4> 
 <span class='centered'>I wanted to learn more category theory, since I felt it was important as a type theorist in training 
 <span class='centered'>to be fluent with category theory.  
 <ul><li><span class='centered'><span class='centered'> I was reading  <a href=https://link.liverpool.ac.uk/portal/Categorical-logic-and-type-theory-Bart/zctzUzjlvJk/><span class='centered'>Categorical logic </a><span class='centered'>by Bart Jacobs, which describes how to reason about type theory using the <span class='centered'>machinery of  <a href=https://en.wikipedia.org/wiki/Fibred_category><span class='centered'>fibered categories </a>. </li><li><span class='centered'><span class='centered'> I attended  <a href=https://adjointschool.com/><span class='centered'>Adjoint School </a>, a summer school for applied category theorists, which was <span class='centered'>a blast. I learnt a lot from it, and read a bunch of papers from it! </li><li><span class='centered'><span class='centered'> I loved the paper  <a href=https://arxiv.org/abs/2005.12798><span class='centered'>Opinion Dynamics on Discourse Sheaves </a>, which describes how to setup <span class='centered'>a 'discourse sheaf', a sheaf structure on a graph which models private versus public opinions. The punchline is that harmonic <span class='centered'>functions lead to 'harmonious' discourse amongst participants in the model! </li><li><span class='centered'><span class='centered'> Ohad pointed me to  <a href=https://arxiv.org/abs/1701.02547><span class='centered'>Probabilistic models via quasi borel spaces </a>, which builds <span class='centered'>quasi-borel spaces, which is a closed cartesian category where one can interpret simply typed lambda calculus. <span class='centered'>This gives a nice denotational footing to probabilistic programming. </li></ul> 
 <span class='centered'>But to be honest, what I really took away from this was that I  <i><span class='centered'>don't enjoy </i>
 <span class='centered'>category theory as much as I enjoy geometry. Thus, I'm going to try to align 
 <span class='centered'>next year such that I get to read more geometric concepts!  
 <h4><a id=logic href='#logic'> § </a><span class='centered'> Logic </h4> 
 <span class='centered'>I wanted to learn logic and model theory, so I read George Boolos' 
 <span class='centered'>book  <a href=https://www.cambridge.org/core/books/computability-and-logic/440B4178B7CBF1C241694233716AB271><span class='centered'>"Computability and Logic" </a>. 
 <span class='centered'>My two favourite theorems were:  
 <ul><li><span class='centered'><span class='centered'> The  <a href=https://en.wikipedia.org/wiki/Compactness_theorem><span class='centered'>Compactness theorem </a>, which points to the finiteness of <span class='centered'>the proof system we use, and how this impacts the logic itself. </li><li><span class='centered'><span class='centered'> The  <a href=https://en.wikipedia.org/wiki/L%C3%B6wenheim%E2%80%93Skolem_theorem><span class='centered'>Lowenheim Skolem </a> theorem, which shows that <span class='centered'>first order logic cannot control the size of its models. </li></ul> 
 <span class='centered'>I also wanted to learn what forcing was about, so I tried 
 <span class='centered'>to read through the literature:  
 <ul><li><span class='centered'><span class='centered'> I began by reading  <a href=https://link.springer.com/chapter/10.1007/978-3-642-41422-0_37#Abs1><span class='centered'>Jech: Axiom of Choice </a>, which <span class='centered'>was far too terse to grok, so I switched to reading the next lecture notes. </li><li><span class='centered'><span class='centered'>  <a href=https://arxiv.org/pdf/2208.13731.pdf><span class='centered'>Independence of CH: an intuitive explanation </a> was a readable account of the  <span class='centered'>machinery of forcing! I wanted to get the account of forcing from the point of view of topi, for which I started reading <span class='centered'>the next book. </li><li><span class='centered'><span class='centered'>  <a href=https://link.springer.com/book/10.1007/978-1-4612-0927-0><span class='centered'>Sheaves in geometry and logic </a> is a textbook on topos theory, which <span class='centered'>provide an account of forcing by building an object called a  <a href=https://toddtoddtodd.net/T%20Schmid%20-%20Toposes,%20Sets,%20and%20Cohen%20Forcing,%20an%20Overview.pdf><span class='centered'>cohen topos </a>. I didn't manage to get through enough of the book to really understand what the <span class='centered'>chapter on the cohen topos was doing, but I did get the vague idea. We seem <span class='centered'>to build a topos, and then use the internal logic of the topos to mimic the <span class='centered'>model we are building. The machinery of topos theory allows us to easily <span class='centered'>control the internal logic, thereby adding the axioms to ZF. </li></ul> 
 <h4><a id=frex href='#frex'> § </a><span class='centered'> Frex </h4> 
 <span class='centered'><a href=https://twitter.com/aleph_kappa?lang=en><span class='centered'>Ohad Kammar </a> is a senior research fellow here at Edinburgh who I really enjoy 
 <span class='centered'>talking to. He told me about a project he works on,  <code class='inline'>frex</code>, which stands for 
 <span class='centered'>"free extensions". The TL;DR is that they wish to study how to write down simplifiers / computer algebra systems 
 <span class='centered'>in a principled fashion. Their paper  <a href=https://www.cl.cam.ac.uk/~jdy22/papers/partially-static-data-as-free-extension-of-algebras.pdf><span class='centered'>Partially static data as free extensions of algebras </a> is a super readable account of their ideas. I quite enjoyed re-implementing 
 <span class='centered'>the basic version in Haskell. I wish to implement their more recent, more complex dependently-typed version of the 
 <span class='centered'>theory in Lean.  
 <h4><a id=ideas-in-type-theory-and-proof-assistants href='#ideas-in-type-theory-and-proof-assistants'> § </a><span class='centered'> Ideas in type theory and proof assistants </h4> 
 <span class='centered'>Since I'm here at Edinburgh, I keep getting stray recommendations on things to read. 
 <span class='centered'>A big shout-out to 
 <span class='centered'><a href=https://github.com/goens><span class='centered'>Andres Goens </a>, 
 <span class='centered'><a href=https://github.com/ChrisHughes24><span class='centered'>Chris Hughes </a>,  
 <span class='centered'><a href=https://github.com/jasigal><span class='centered'>Jesse Sigal </a>, 
 <span class='centered'><a href=https://www.inf.ed.ac.uk/people/staff/Justus_Matthiesen.html><span class='centered'>Justus Mathiessen </a>, 
 <span class='centered'><a href=https://leodemoura.github.io/about.html><span class='centered'>Leonardo De Moura </a>, 
 <span class='centered'><a href=https://poisson.chat/><span class='centered'>Li-yao Xia </a>,  
 <span class='centered'><a href=https://github.com/digama0><span class='centered'>Mario Carneiro </a>, 
 <span class='centered'><a href=https://twitter.com/aleph_kappa?lang=en><span class='centered'>Ohad Kammar </a>, and  
 <span class='centered'><a href=https://github.com/lephe/><span class='centered'>Sebastien Michelland </a> for many of these pointers.  
 <ul><li><span class='centered'><span class='centered'>  <a href=http://www2.math.uu.se/~palmgren/universe.pdf><span class='centered'>On Universes in Type Theory </a> describes the difference between russel and tarski <span class='centered'>style universes. </li><li><span class='centered'><span class='centered'>  <a href=https://hackage.haskell.org/package/idris-1.1.0/docs/Idris-Core-CaseTree.html><span class='centered'>Case trees </a> are a data structure which are used <span class='centered'>in Coq and Idris to manage dependent pattern matching. </li><li><span class='centered'><span class='centered'>  <a href=https://leanprover.github.io/theorem_proving_in_lean/inductive_types.html?highlight=recursor#defining-the-natural-numbers><span class='centered'>primitive recursors </a> in Lean </li><li><span class='centered'><span class='centered'>  <a href=https://arxiv.org/abs/1701.04391><span class='centered'>congruence closure in intensional type theories </a> describes how to extend the naive <span class='centered'>congruence closure algorithm in the presence of definitional equalities between types. </li><li><span class='centered'><span class='centered'> Difference between  <a href=https://wonks.github.io/type-theory-reading-group/papers/proc92-coquand.pdf><span class='centered'>match+fix, as introduced by Theirrey Coquand in 'Pattern Matching with Dependent Types' </a> ,   <code class='inline'>termination_by</code>, and primitive recursion. </li><li><span class='centered'><span class='centered'> The idea of full abstraction, which asks the question of when operational and denotational semantics agree, <span class='centered'>first studied by  <a href=https://pdf.sciencedirectassets.com/271538/1-s2.0-S0304397500X0240X/1-s2.0-0304397577900445/main.pdf><span class='centered'>Gordon Plotkin for PCF </a></li><li><span class='centered'><span class='centered'>  <a href=https://github.com/andrejbauer/notes-on-realizability><span class='centered'>Andrej Nauer's notes on realizability </a>, which very cleanly describes <span class='centered'>the theory of realisability models, where one studies mathematical objects equipped with computational structure. this naturally <span class='centered'>segues into discussions of models of computation and so forth. </li><li><span class='centered'><span class='centered'>  <a href=https://www.semanticscholar.org/paper/Functional-pearl%3A-i-am-not-a-number--i-am-a-free-McBride-McKinna/833cf29aa614fa26348a505f3b9a3832e1d47dd4><span class='centered'>I am not a number, I am a free variable </a> describes "locally nameless", a technique to manage names when implementing proof assistants. </li><li><span class='centered'><span class='centered'> Higher order unification is necessary when implementing the elaborator for a proof assistant. Unfortunately, <span class='centered'><a href=https://www.ps.uni-saarland.de/Publications/documents/SpiesForster_2019_UndecidabilityHOU.pdf><span class='centered'>the full problem is also undecidable </a></li><li><span class='centered'><span class='centered'> Luckily for us,  <a href=https://github.com/Saizan/miller><span class='centered'>Miller found a fragment called 'pattern unification' </a>, where unification is indeed <span class='centered'>decidable. The key idea is to add a 'linearity' constraint which ensures that variables are not repeated into the pattern match, which <span class='centered'>makes even higher-order patterns decidable. </li><li><span class='centered'><span class='centered'> The  <a href=https://beluga-lang.readthedocs.io/en/latest/><span class='centered'>Beluga Proof Assistant </a> is a proof assistant whose logic allows one to reify <span class='centered'>contexts. This means that one can write shallow embeddings of programming languages, have all the nice power of the proof assistant, <span class='centered'>while still reasoning about binders! I found the way in which Beluga makes <span class='centered'>such invasive changes to the metatheory in order to allow reasoning about <span class='centered'>binders to be very enlightening. </li><li><span class='centered'><span class='centered'> The  <a href=https://www.cl.cam.ac.uk/~jrh13/hol-light/tutorial.pdf><span class='centered'>HOL light </a> proof assistant and  <a href=https://isabelle.in.tum.de/><span class='centered'>Isabelle/HOL </a><span class='centered'>are both based on higher order logic, and alternate, untyped foundations for <span class='centered'>proof assistants. I feel it's important for me to know the various ideas <span class='centered'>folks have tried in building proof assistants, and I was glad to have been <span class='centered'>pointed to Isabelle and HOL. I want to spend some time this year (2023) to <span class='centered'>learn Isabelle and HOL well enough that I can prove something like strong <span class='centered'>normalization of STLC in them. </li><li><span class='centered'><span class='centered'>  <a href=https://arxiv.org/pdf/1710.08326.pdf><span class='centered'>Fitch style modal logics </a> are a systematic way to build type theories with <span class='centered'>modalities in them. These are typically used to create type theories that can reason about resources, such as  <span class='centered'>concurrent access or security properties. The paper provides a unified account of how to build such type theories, and <span class='centered'>how to prove the usual slew of results about them. </li><li><span class='centered'><span class='centered'>  <a href=http://www.chargueraud.org/research/2020/seq_seplogic/seq_seplogic.pdf><span class='centered'>Minimal implementation of separation logic: Separation Logic for Sequential Programs </a> explains how to write a small separation logic framework embedded in a dependently typed progrmaming language. <span class='centered'>I  <a href=https://github.com/bollu/slf/blob/main/Separation.lean#L1934><span class='centered'>translated the original from Coq to Lean </a>, and the whole thing clocks in at <span class='centered'>around 2000 LoC, which is not too shabby to bootstrap a full 21st century <span class='centered'>theory of reasoning about parallelism! </li><li><span class='centered'><span class='centered'>  <a href=https://pdf.sciencedirectassets.com/272575/1-s2.0-S0890540100X02428/1-s2.0-089054019190066B/main.pdf><span class='centered'>Telescopic Mappings in Typed Lambda Calculus </a> builds the theory of telescopes, which is the basic notation that's used when describing binders in dependent type theory. <span class='centered'>I had no idea that this had to be developed; I shudder to think how ugly notation was before this paper! I can't help but  <span class='centered'>feel that this paper did for dependent type theory what einstein summation convention did for tensor calculus: provide compact <span class='centered'>notation for the uninteresting bits to allow us to to talk about the interesting bits well. </li><li><span class='centered'><span class='centered'> When talking to Leonardo, I learnt that the hardest part of implementing a homotopical theorem prover <span class='centered'>was the elaboration of pattern matching.  <a href=https://jesper.sikanda.be/files/pattern-matching-without-K.pdf><span class='centered'>Pattern matching without K </a><span class='centered'>explains how to do this, and also made clear for me at what step <span class='centered'><a href=https://ncatlab.org/nlab/show/uniqueness+of+identity+proofs><span class='centered'>UIP </a> is used <span class='centered'>during pattern matching --- when refining on indexes of a type. </li><li><span class='centered'><span class='centered'>  <a href=https://arxiv.org/abs/2103.07543><span class='centered'>The garden of forking paths to reason about lazy programs </a> describes how to use <span class='centered'><a href=https://www.cs.nott.ac.uk/~pszgmh/clairvoyant.pdf><span class='centered'>Clairvoyant call by value </a> to reason about laziness in a convenient fashion. </li></ul> 
 <h4><a id=computational-group-theory href='#computational-group-theory'> § </a><span class='centered'> Computational group theory </h4> 
 <span class='centered'>I was confused about what I should pick for my PhD topic, and I briefly flirted with the idea 
 <span class='centered'>of working on computational group theory. I genuinely loved a bunch of the papers in this space, 
 <span class='centered'>but alas, I couldn't see myself seriously working on these, due to the lack of a clear and focused 
 <span class='centered'>problem that I coulf work on. I did read some cool papers regardless:  
 <ul><li><span class='centered'><span class='centered'>  <a href=https://www.sciencedirect.com/science/article/pii/S074771711400056X><span class='centered'>A practical model for computing with matrix groups </a><span class='centered'>describes algorithms that form the crux of computational matrix group theory. </li><li><span class='centered'><span class='centered'>  <a href=https://dl.acm.org/doi/abs/10.1145/1145768.1145811><span class='centered'>A data structure for a uniform approach to computations with finite groups </a><span class='centered'>provides a data structure that unifies algorithms for the two ways of representing groups computationally: (1) as subgroups <span class='centered'>of the symmetric group, which is given as a  <a href=https://en.wikipedia.org/wiki/Strong_generating_set><span class='centered'>strong generating set </a>, <span class='centered'>and (2) as matrices. These two approaches are radically different under the hood, but the paper provides a unified API to <span class='centered'>deal with both. </li><li><span class='centered'><span class='centered'>  <a href=https://webspace.maths.qmul.ac.uk/r.a.wilson/pubs_files/MDurham.pdf><span class='centered'>Computing in the monster </a> describes <span class='centered'>how to perform computations in the monster group, a group that's so large that naively trying to write down elements would <span class='centered'>take two gigabytes of memory.  </li></ul> 
 <h4><a id=automated-theorem-proving href='#automated-theorem-proving'> § </a><span class='centered'> Automated theorem proving </h4> 
 <span class='centered'>I wound up reading a little on how to implement automated theorem provers (SAT/SMT solvers). 
 <span class='centered'>This space is huge, and I only got a cursory glance at it from the  <a href=https://www.decision-procedures.org/><span class='centered'>Decision procedures book </a>. 
 <span class='centered'>Even so, it was neat to learn the core ideas:   
 <ul><li><span class='centered'><span class='centered'>  <a href=https://en.wikipedia.org/wiki/DPLL_algorithm><span class='centered'>The DPLL algorithm for solving SAT </a></li><li><span class='centered'><span class='centered'>  <a href=https://en.wikipedia.org/wiki/Conflict-driven_clause_learning><span class='centered'>The CDCL strategy for refining SMT queries </a></li><li><span class='centered'><span class='centered'>  <a href=https://web.stanford.edu/class/cs357/lecture11.pdf><span class='centered'>The Nelson Oppen algorithm for mixing convex theories </a></li><li><span class='centered'><span class='centered'> The  <a href=https://logic4free.informatik.uni-kiel.de/llocs/Resolution_(first-order_logic><span class='centered'>First Order Resolution </a>) <span class='centered'>rule, which exploits <span class='centered'><a href=https://cs.stackexchange.com/a/9096/122524><span class='centered'>refutation-completeness </a> to <span class='centered'>build a SAT solver, </li><li><span class='centered'><span class='centered'> The  <a href=https://en.wikipedia.org/wiki/Superposition_calculus><span class='centered'>Superposition Calculus </a> for fast SAT solving, based on an extension <span class='centered'>of resolution. </li></ul> 
 <h4><a id=common-lisp href='#common-lisp'> § </a><span class='centered'> Common Lisp </h4> 
 <span class='centered'>I got turned off of writing scripts in Python because writing parallel 
 <span class='centered'>processing is a pain, so I did the obvious thing: picked up common lisp! 
 <ul><li><span class='centered'><span class='centered'> I mostly learnt lisp by reading  <a href=https://gigamonkeys.com/book/><span class='centered'>practical common lisp </a> and hanging out on  <code class='inline'>##lisp</code> on libera IRC. </li><li><span class='centered'><span class='centered'> I absolutely  <i><span class='centered'>loved </i> the REPL driven development enabled by <span class='centered'><a href=https://slime.common-lisp.dev/><span class='centered'><code class='inline'>emacs</code>+ <code class='inline'>slime</code></a>, and this has definitely <span class='centered'>set a gold standard for how programming language interaction ought to feel like. </li><li><span class='centered'><span class='centered'> I was floored by some of the comon lisp projects I saw, such as  <a href=https://github.com/cbaggers/cepl><span class='centered'>cepl </a>, the code-eval-play loop <span class='centered'>for rapid shader development! His  <a href=https://www.youtube.com/playlist?list=PL2VAYZE_4wRKKr5pJzfYD1w4tKCXARs5y><span class='centered'>videos are super cool </a>, <span class='centered'>and I highly recommend them to anyone who wants to get a flavour of LISP. </li><li><span class='centered'><span class='centered'> I'd like to work through  <a href=https://letoverlambda.com/><span class='centered'>Let over Lambda </a>, a book that explains all sorts of macro shenanigans! </li></ul> 
 <h4><a id=non-fiction-and-fiction href='#non-fiction-and-fiction'> § </a><span class='centered'> Non fiction and fiction </h4> 
 <span class='centered'>I wound up reading a bunch of sci-fi this year, since I wanted to work my way through 
 <span class='centered'>the Nebula award winners. My favourites were:  
 <ul><li><span class='centered'><span class='centered'> All Clear by Connie  Willis paints a great picture of the blitz during WW2. It feels surreal to have <span class='centered'>visited london and edinburgh and glasgow and all the other places that are name dropped in the book, <span class='centered'>it felt visceral. </li><li><span class='centered'><span class='centered'> The  <a href=https://en.wikipedia.org/wiki/Annihilation_(VanderMeer_novel><span class='centered'>Annihilation series </a>), which has <span class='centered'>the creepiest vibes in a book I've ever read. </li><li><span class='centered'><span class='centered'>  <a href=https://en.wikipedia.org/wiki/Accelerando><span class='centered'>Accelerando </a>, which had a really neat take on a resolution of the Fermi Paradox, <span class='centered'>and just an overall fun tone. </li><li><span class='centered'><span class='centered'>  <a href=https://www.gregegan.net/ALLSKIES/AllSkies.html><span class='centered'>The book of all skies </a> by <span class='centered'>Greg egan, which as usual explores a neat universe, this time with some kind <span class='centered'>of monodromy. </li><li><span class='centered'><span class='centered'> Honorary mention to  <a href=https://www.goodreads.com/book/show/25188109-perfect-state><span class='centered'>Perfect State by Brandon Sanderson </a>, a cute novella <span class='centered'>with a really neat twist at the end I didn't see coming. </li></ul> 
 <span class='centered'>As usual, I was reading some more sciencey things, this time on chemistry and nanotechnology, 
 <span class='centered'>which were the books 
 <span class='centered'><a href=https://www.amazon.co.uk/Ignition-Informal-Propellants-University-Classics/dp/0813595835><span class='centered'>Ignition! An informal history of rocket liquid propellants </a>, 
 <span class='centered'><a href=https://global.oup.com/academic/product/inventing-temperature-9780195337389?cc=gb&lang=en&><span class='centered'>Inventing Temperature </a>, and 
 <span class='centered'><a href=https://en.wikipedia.org/wiki/Engines_of_Creation><span class='centered'>Engines of creation </a>.  
 <h4><a id=looking-back href='#looking-back'> § </a><span class='centered'> Looking Back </h4> 
 <span class='centered'>When I started writing this blog post, I felt that I hadn't learnt as much as I 
 <span class='centered'>did in  <a href=https://bollu.github.io/stuff-i-learnt-in-2019.html><span class='centered'>2019 </a>. However, I 
 <span class='centered'>now see that I've learnt a bunch of things, just in a small domain (proof 
 <span class='centered'>assistants / type theory / logic). To be honest, this makes me kind of sad; I 
 <span class='centered'>miss learning different things, and I feel like I haven't gotten closer towards 
 <span class='centered'>some of my life goals of things I want to learn --- the standard model of 
 <span class='centered'>particle physics, the proof of resolution of singularities, and other such 
 <span class='centered'>goals. I'm going to try to make sure 2023 is more diverse in what I read, 
 <span class='centered'>to make sure I'm happy and sane, while continuing to become an expert in proof assistants  <code class='inline'>:)</code>. With that said, 
 <span class='centered'>I'd like to set concrete goals for 2023:  
 <ul><li><span class='centered'><span class='centered'> Learn enough QFT to know what the hell renormalization is. </li><li><span class='centered'><span class='centered'> Learn enough QED to be able to explain what a feynmann path integral is. </li><li><span class='centered'><span class='centered'> Get good enough at juggling to be able to juggle three balls consistenty. </li><li><span class='centered'><span class='centered'> Write  <a href=https://github.com/bollu/qoc><span class='centered'>my own proof kernel </a> for Lean. </li><li><span class='centered'><span class='centered'> Implement and write the paper about elaboration of mutual inductives for <span class='centered'>Lean, and start thinking about coinductives. </li><li><span class='centered'><span class='centered'> Continue working on Lean's LLVM backend, and make Lean the fastest functional <span class='centered'>programming language in the block. </li><li><span class='centered'><span class='centered'> Learn to cook a proper three course meal consistently. </li><li><span class='centered'><span class='centered'> Get good enough at  <a href=https://en.wikipedia.org/wiki/Djembe><span class='centered'>djembe </a> to play <span class='centered'><a href=https://afrodrumming.com/djembe-rhythm-kuku/><span class='centered'>kuku </a> consistently. </li><li><span class='centered'><span class='centered'> Get good enough at the guitar to strum Snow and Can't Stop well enough. </li><li><span class='centered'><span class='centered'> Build a routine for shuffle dancing, so that I can dance consistently to a song. </li><li><span class='centered'><span class='centered'> Learn to rock climb well enough that I can do V4's consistently. </li></ul> 
 <span class='centered'>That looks like an ambitious list, and I'm glad it is. I'd like my years to be full of 
 <span class='centered'>interesting challenges and neat things I can point to at the end of year! With that said, happy new year!  
 <script src="https://utteranc.es/client.js"        repo="bollu/bollu.github.io"        issue-term="pathname"        label="question"        theme="github-light"        crossorigin="anonymous"        async></script></container></body></html>