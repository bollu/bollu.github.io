% References: 
% -----------
% https://www.sv.uio.no/econ/personer/vit/bardh/dokumenter/econ5200-notes-harstad.pdf
%http://lcm.csa.iisc.ernet.in/gametheory/md1-dec07.pdf
%http://lcm.csa.iisc.ernet.in/ecomm/Part_D_GameTheory_and_Mechanism_Design_Lecture_Notes/ch1-intro.pdf

\documentclass[11pt]{book}
%\documentclass[10pt]{llncs}
%\usepackage{llncsdoc}
\usepackage[sc,osf]{mathpazo}   % With old-style figures and real smallcaps.
\linespread{1.025}              % Palatino leads a little more leading
% Euler for math and numbers
\usepackage[euler-digits,small]{eulervm}
\usepackage{physics}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{makeidx}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{listing}
\usepackage{minted}
\evensidemargin=0.20in
\oddsidemargin=0.20in
\topmargin=0.2in
%\headheight=0.0in
%\headsep=0.0in
%\setlength{\parskip}{0mm}
%\setlength{\parindent}{4mm}
\setlength{\textwidth}{6.4in}
\setlength{\textheight}{8.5in}
%\leftmargin -2in
%\setlength{\rightmargin}{-2in}
%\usepackage{epsf}
%\usepackage{url}

\usepackage{booktabs}   %% For formal tables:
                        %% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
                        %% http://ctan.org/pkg/subcaption
\usepackage{enumitem}
%\usepackage{minted}
%\newminted{fortran}{fontsize=\footnotesize}

\usepackage{xargs}
\usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}

\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=blue,
    filecolor=blue,
    linkcolor=blue,
    urlcolor=blue
}

\usepackage{epsfig}
\usepackage{tabularx}
\usepackage{latexsym}
\newcommand\ddfrac[2]{\frac{\displaystyle #1}{\displaystyle #2}}
\newcommand{\N}{\ensuremath{\mathbb{N}}}
\newcommand{\R}{\ensuremath{\mathbb R}}
\renewcommand{\P}[1]{\ensuremath{\mathbb{P} \left[ #1 \right] }}
\newcommand{\coT}{\ensuremath{T^*}}
\newcommand{\Lie}{\ensuremath{\mathfrak{L}}}
\newcommand{\pushforward}[1]{\ensuremath{{#1}_{\star}}}
\newcommand{\pullback}[1]{\ensuremath{{#1}^{\star}}}

\newcommand{\pushfwd}[1]{\pushforward{#1}}
\newcommand{\pf}[1]{\pushfwd{#1}}

\newcommand{\boldX}{\ensuremath{\mathbf{X}}}
\newcommand{\boldY}{\ensuremath{\mathbf{Y}}}

\DeclareMathOperator*{\argmin}{argmin} % no space, limits underneath in displays
\DeclareMathOperator*{\argmax}{argmax} % no space, limits underneath in displays


\newcommand{\G}{\ensuremath{\mathcal{G}}}
% \newcommand{\braket}[2]{\ensuremath{\left\langle #1 \vert #2 \right\rangle}}


\def\qed{$\Box$}
\newtheorem{corollary}{Corollary}
\newtheorem{theorem}[corollary]{Theorem}
\newtheorem{definition}[corollary]{Definition}
\newtheorem{lemma}[corollary]{Lemma}
\newtheorem{observation}[corollary]{Observation}
\newtheorem{proof}[corollary]{Proof}
\newtheorem{remark}[corollary]{Remark}
\newtheorem{example}[corollary]{Example}

\title{Game theory}
\author{Siddharth Bhat}
\date{Spring 2020}


\begin{document}
\maketitle
\tableofcontents

\chapter{Introduction}


TODO: find out and write about: 
Extrinsic form representation of a game
$\Gamma \equiv \langle N, T, Z, o, A, s, u_i, \mathcal{H}\rangle$
where $N$ is number of players, $T$ is game tree, $Z$ is leaves, $o$ is owner
function, $A$ is actions, $s$ is transition, $u_i$ is player function, $\mathcal H$
is information sets. An information set contains equivalence classes
of states that the player cannot distinguish between. There can be ambiguity
due to missing information. Perfect information game is one where all
information sets are singleton. For example, chess is perfect information.
Example of partial information is card games.

Next, we look at strategies. A strategy is a computable function by which
each player selects their actions.

Game tree for matching coins with observation:
$S_A: \{ 1 \} \rightarrow \{H, T\}$. $S_B: \{2, 3\} \rightarrow \{H, T \}$.


Game tree for matching coins without observation:
$S_A: \{ 1 \} \rightarrow \{H, T\}$. $S_B: \{\{2, 3\}\} \rightarrow \{H, T \}$.

We let $S \equiv S_1 \times S_2 \times \dots \times S_n$. This a set containing
all possible strategies, called as a "strategy profile", $s \in S$. We
write $s$ as $s \equiv (s_i, s_{-i})$, where $s_{-i}$ is cute notation for
"the rest of the players". For example, if $s \equiv (s_1, s_2, s_3)$ we can 
notate $s = (s_2, s_{-2}) = (s_2, s_1, s_3)$.

We will currently focus on pure strategies, where we have a deterministic
function per strategy.


\section{Normal form games}
Another representation for games is called as strategic form / matrix form / 
normal form games.  Here, a game $\Gamma \equiv \langle N, (S_i)_{i \in N}, (u_i: S \rightarrow \R)_{i \in N} \rangle$.
$N$ is the number of players, $S_i$ are strategies for each player, $u_i$ 
are the utility functions / payoffs for each player. $u_i$ maps each
strategy profile $s$ how worth it it is for player $i$ if
the game proceeds with strategy profile $s$.

\subsection{Normal form for matching coins with observation}
\begin{align*}
   &S_a \equiv \{ S_a^1 (H), S_a^2 (T)\} \\
   &S_b \equiv \{ S_b^1 (HH), S_b^2 (HT), S_b^3 (TH), S_b^4 (TT) \} \\
   &u_a: S \rightarrow \R \\
   &u_a((s_a^1, s_b^1)) = +10 \qquad (H, HH) \\
   &u_a((s_a^1, s_b^2)) = +10 \qquad (H, HT) \\
   &u_a((s_a^1, s_b^3)) = -10 \qquad (H, TH) \\
   &u_a((s_a^1, s_b^4)) = -10 \qquad (H, TT) \\ 
   &u_a((s_a^2, s_b^1)) = -10 \qquad(T, HH) \\
   &u_a((s_a^2, s_b^2)) = +10 \qquad(T, HT)\\
   &u_a((s_a^2, s_b^3)) = -10 \qquad(T, TH) \\
   &u_a((s_a^2, s_b^4)) = +10 \qquad(T, TT) \\
\end{align*}

Alternate representation of same game:
$$
\begin{tabular}{ccccc}
    $s_b \rightarrow$ & HH & HT & TH & TT \\ 
    H & (10, -10) & (10, -10)  & (-10, +10)    & (-10, +10)   \\
    T &  (-10, 10)   &  (10, -10)  & (-10, 10)   &  (10, -10)  \\
\end{tabular}
$$


\subsection{Normal form for matching coins without observation}

$$
\begin{tabular}{ccccc}
    $s_a \rightarrow$  & H & T & \\
    H & (10, -10) & (-10, 10) \\ 
    T &  (-10, 10) & (10, -10)
\end{tabular}
$$


\subsection{Normal form for prisoners dilemma}

$C$ for confess, $NC$ for not confess.

$$
\begin{tabular}{ccccc}
     & C & NC & \\
    C & (-5, -5) & (-1, -10) \\ 
    NC &  (-10, -1) & (-2, -2)
\end{tabular}
$$

\chapter{Game analysis}
Rationality implies that each player is motivated to maximise his own payoff.
Intelligent implies that player can take into account all available
information. An intelligent and rational player implies that every player will
attempt to maximise their utility.

\subsection{Common knowledge and puzzles about common knowledge}
\begin{definition}
    \emph{Common knowledge} --- Player knows it. Every player knows that every player
    knows it. Every player knows that every player knows that
    every player knows it.
    $\forall k \in \N, (\text{Every player knows that})^k$ every player knows it.
\end{definition}

If we have an island with two water streams and all humans and intelligent,
rational and cannot speak. They have a rule that says that if a person has a
blue mark on their forehead, the drink water from a stream farther away. One
day, a visitor, who knows the above fact, shouts "why is a person with a blue
mark drinking water here?" The next day, no one comes to the stream. What changed?
The only difference before and after is that it is now common knowledge that
there is one person with a blue mark drinking water at the stream. This


Some one imagined two positive whole numbers $1 \leq a, b \leq 20$. He tells the sum of these
two numbers to mathematician $A$, the product of these numbers to mathematician $B$.
$A$ tells $B$ that there is no way for $B$ to know the sum. Then $B$ exclaims
"But I know the sum now!", to which $A$ exclaims "and now I know the product".

\subsection{Strongly dominated strategy}

Given a game $\Gamma \equiv \langle N, (S_i), (u_i) \rangle$, a strategy
$s_i \in S_i$ is said to be strongly dominated by a strategy $s_i' \in S_i$
if:

$$
u_i(s_i, s_{-1}) < u_i(s_i', s_{-i})~ \forall s_{-i} \in S_{-i}
$$

\subsection{Strongly dominant strategy}

Given a game $\Gamma \equiv \langle N, (S_i), (u_i) \rangle$, a strategy
$s_i^\star$ is said to be strongly dominant if it strongly dominates every
other strategy $s_i \in S_i$.

$$
\forall s_i \in S_i, s_i \neq s_i^\star \implies ~ u_i(s_i, s_{-1}) < u_i(s_i^\star, s_{-i})~ \forall s_{-i} \in S_{-i}, 
$$

Note that to analyze strongly dominated and strongly dominant strategies,
we only need $u_i$, the utility of the $i$th player. Hence, to analyze
dominance of strategies, we can get away with writing the utility of
just a single player.

$$
\begin{tabular}{ccc}
    & L & R \\
  A & 6, - & 7, - \\
  B & 5, - & 6, - \\
  C & 4, - & 6, - \\
\end{tabular}
$$

$L, R$ are moves of the player.
$A, B, C$ are stratgies with utilities filled
in.

$A$ strongly dominate $C$, $A$ strongly dominates $B$. $B$ does \emph{not}
strongly dominate $C$, since on the $R$ action, we have $6$ for both $B$ and $C$.
Hence, $A$ is the strongly dominant strategy. Note that there need not always
exist a strongly dominant strategy:

$$
\begin{tabular}{ccc}
    & L & R \\
  A & 6, - & 7, - \\
  B & 7, - & 6, - \\
\end{tabular}
$$

Neither $A$ nor $B$ are strictly better than the other.

\subsection{Weakly dominated strategy}

Given a game $\Gamma \equiv \langle N, (S_i), (u_i) \rangle$, a strategy
$s_i \in S_i$ is said to be weakly dominated by a strategy $s_i' \in S_i$
if:

$$
u_i(s_i, s_{-1}) \leq u_i(s_i', s_{-i})~ \forall s_{-i} \in S_{-i}
$$

with strict inequality for at least one $s_{-i}$. 


\subsection{Weakly dominant strategy}

Given a game $\Gamma \equiv \langle N, (S_i), (u_i) \rangle$, a strategy
$s_i^\star$ is said to be weakly dominant if it weakly dominates every
other strategy $s_i \in S_i$.

$$
\forall s_i \in S_i, s_i \neq s_i^\star \implies ~ u_i(s_i, s_{-1}) \leq u_i(s_i^\star, s_{-i})~ \forall s_{-i} \in S_{-i}, 
$$

with strict inequality for at least one $s_{-i}$. 

Once again, a weakly dominant strategy need not always exist:
$$
\begin{tabular}{ccc}
    & L & R \\
  A & 6, - & 7, - \\
  B & 7, - & 6, - \\
\end{tabular}
$$

\subsection{Very weakly dominated strategy}

Given a game $\Gamma \equiv \langle N, (S_i), (u_i) \rangle$, a strategy
$s_i \in S_i$ is said to be very weakly dominated by a strategy $s_i' \in S_i$
if:

$$
u_i(s_i, s_{-1}) \leq u_i(s_i', s_{-i})~ \forall s_{-i} \in S_{-i}
$$

Note that we do not have the strict inequality requirement anymore. This
is now a true partial order.

\subsection{Example of strong dominance in prisoners dilemma}
$$
\begin{tabular}{ccccc}
     & C & NC & \\
    C & (-5, -5) & (-1, -10) \\ 
    NC &  (-10, -1) & (-2, -2)
\end{tabular}
$$
Here, $C$ is the strongly dominant strategy for both players.


\subsection{Another game}
$$
\begin{tabular}{ccccc}
      & a & b & c \\
    A & 5 & 5 & 5 \\
    B & 4 & 5 & 5\\
    C & 4 & 4 & 4
\end{tabular}
$$

There does not exist a strongly dominant strategy.
$A$ is weakly dominant. $C$ is weakly dominated by both $A, B$.

\subsection{Can there exist two weakly dominant strategies?}
No there cannot. If $A$ is a weakly dominant strategies, then
assume $A[i] > B[i]$.If $A[i] > B[i]$, then $B$ cannot weakly dominate 
$A$, since for $B$ to dominate $A$ we need $B[j] \geq A[j]~ \forall j$,
but $B[i] < A[i]$.


\subsection{Strongly (Weakly) Dominant Strategy Equilibrium}
A strategy profile $(s_1^\star, s_2^\star, \dots, s_n^\star)$ is called as a strongly
dominant strategy equilibrium of the game $\Gamma \equiv \langle N, (S_i), (U_i) \rangle$ iff
the strategy $s_i^\star$ is a strongly dominating strategy for player $i$.

Recall the example of Prisoners dilemma ---

$$
\begin{tabular}{ccccc}
     & C & NC & \\
    C & (-5, -5) & (-1, -10) \\ 
    NC &  (-10, -1) & (-2, -2)
\end{tabular}
$$

\chapter{Lecture 2}
Missed! write this down. TODO!

\section{Review of lecture 2}

Two player zero sum games. $N = \{1, 2\}$. $u_1 = - u_2$. Also called
matrix games since the game can be represented as a matrix. $a_{ij}$ is
the utility for row player playing row $i$, column player is playing
column $j$.

We showed that we are not guaranteed a dominant strategy. Hence, we need
to look at other types of equilibria.

Here, we define saddle points. 

\chapter{Equilibrium in two-player zero-sum games}
\section{Saddle points}
Given a matrix $A$, $(i^*, j^*)$ is a saddle point iff:
\begin{align*}
    &a_{i^\star j^\star } \leq a_{i^\star K} \qquad \forall K = 1, 2, \dots, n \\
    &a_{i^\star j^\star } \geq a_{L j^\star } \qquad \forall L = 1, 2, \dots, m \\
\end{align*}
That is, $a_{i^\star j^\star }$ is the maximum in the column $j^\star$, minimum in the column
$i^\star $.


Let's now analyze the setting and try to deduce when a saddle point
exists from the entries of the matrix. For this, we define:
\begin{align*}
&u_R \equiv \max_i \min_j a_{ij} \\
&u_c \equiv \min_j \max_i a_{ij}
\end{align*}

\begin{lemma}
    If there are multiple saddle points, $(i_1, j_1)$ and $(i_2, j_2)$, then
    $a_{i_1 j_1} = a_{i_2 j_2}$
\end{lemma}
\begin{proof} 
    Let $a[c][d], a[p][q]$ be two saddle points. By definition, a saddle
    point is greater than everything else on the same row, and less than
    everything else on the same column.

    \begin{align*}
        \begin{bmatrix}
        (c, d)   & > & (c, q) \\
        \wedge & & \vee \\
        (p, d) & < & (p, q)
        \end{bmatrix}
    \end{align*}

    We see that $(c, d) > (c, q) > (p, q)$, and $(c, d) < (p, d) < (p, q)$,
    which implies $(c, d) = (p, q)$.
\end{proof}

\begin{lemma}
    $u_r \leq u_c$
\end{lemma}
\begin{proof} TODO \end{proof}

\begin{lemma}
    $u_r = u_c \implies $~saddle point exists for $A$.
\end{lemma}
\begin{proof} 
Consider $u_R \equiv \max_i \min_j a[i][j]$. Let us introduce a symbol
$minR(i) \equiv min_j a[i][j]$ Hence, $u_R = max_i minR(i)$. This shows us
that $u_R$ is the minimum value in its row.

Similarly, we consider $u_C \equiv \max_i \min_j a[i][j]$. As before, introduce
$maxC(j) \equiv max_i a[i][j]$ Hence, $u_C = min_j maxC(j)$.Hence, $u_C$ is 
the maximum value in its column (Notice the duality). 

Let $(c, d)$ be the index of $u_R$, and $(p, q)$ be the index of $u_C$.

Now consider the matrix:

\begin{align*}
    \begin{bmatrix}
    (c, d)   & < & (c, q) \\
     & & \wedge \\
     & & (p, q)
    \end{bmatrix}
\end{align*}

Hence, $(c, d) \leq (c, q)$ (Since $u_R = a[c][d]$ is minimum in its row).
$(c, q) \leq(p, q)$ (Since $u_C = a[p][q]$ is maximum in its column).  
Therefore, $u_R = (c, d) \leq (c, q) \leq (p, q) = u_C$.
\end{proof}

\begin{lemma}
    $u_r = u_c \iff $~saddle point exists for $A$.
\end{lemma}
\begin{proof} TODO \end{proof}

\subsection{Analysis of saddle points}
If a saddle points exists, then the row player is maximising her minimum
assured gain. The column player is minimising her worst loss. 

If such a saddle point exists, it is called as an equilibrium. The strategy 
that achieves this is the \textbf{mini-max} strategy.

\subsubsection{Single saddle point}

\begin{tabular}{cccc}
    \footnotesize{A $\downarrow$ B $\rightarrow$} & L & M & R \\
    T & 1 & 2 & 1 \\
    M & 0 & -1 & 2 \\
    B & -1 & 0 & -2 \\
\end{tabular}
$(u_r \equiv 2, u_c \equiv 2)$.

\subsubsection{Multiple saddle points}

\begin{tabular}{cccc}
    & L & M & R \\
    T & 0 & 2 & 0 \\
    M & -1 & 5 & 2 \\
    B & 0 & 5 & 0 \\
\end{tabular}
There are 4 saddle points: $(T, L), (T, R), (B, L), (B, R)$.


\subsubsection{Matching coins --- no saddle point}

\begin{tabular}{ccc}
      & H & T \\
    H & 10 & -10 \\
    T & -10 & 10
\end{tabular}
$(u_R \equiv -10, u_c \equiv 10)$ --- no saddle point!

Here, notice that no deterministic strategy can win. What we should do is to
use a randomized strategy where we play $H$ or $T$ with equal probability.

\section{Mixed strategies}

As the matching coins example shows, we need to use a randomized strategy
so we are not exploited. What we can do is to maximise expected utility:

The expected utility of the row player is going to be $\P{H, H} - \P{H, T} - \P{T, H} + \P{T, T}$.

The mixed strategy space consists of probability distributions over pure strategies.
$$\Delta(S) \equiv \left\{ (p_1, p_2, \dots p_k) \mid |S| = k \quad p_i \geq 0 \quad \sum_i p_i = 1\right\}$$

We denote mixed strategies with $\sigma_i \in \Delta(S_i)$, and mixed
strategy profiles as $\sigma \equiv  (\sigma_1, \sigma_2, \dots \sigma_n) \in \prod_i \Delta(S_i)$


We calculate the expected utility as:
\begin{align*}
    U_i(\sigma_i, \sigma_{-i}) \equiv
    \sum_{s_{-1} \in S_{-i}} 
p_{i_1} p(s_{-i}) u(a_{i_1}, s_{-i}) +
p_{i_2} p(s_{-i}) u(a_{i_2}, s_{-i}) + \dots +
    p_{i_k} p(s_{-i}) u(a_{i_k}, s_{-i})
\end{align*}

For two-player zero-sum games, we refer to mixed strategies as 
$p \equiv (p_1, \dots, p_m)$,
$q \equiv (q_1, \dots q_n)^T$. This leads us to \textbf{Utility theory}.


\section{Axiomatic description of utility theory}
Let $X$ be the set of outcomes. $\geq$ (TODO: curly, need to find this) be the
preference of the player over the set of outcomes.
We define $\left( x_1 \sim x_2 \equiv x_1 \geq x_2 \land x_2 \geq x_1 \right)$.

TODO: find formal definition of a lottery.

\begin{itemize}
    \item Completeness: every pair of outcomes is ranked.
    \item Transitivity: $x_1 \geq x_2 \land x_2 \geq x_3 \implies x_1 \geq x_3$.
    \item Substitutability: if $x_1 \sim x_2$, then any lottery in which $x_1$
        is substituted by $x_2$ is equally preferred.
    \item Decomposability: If two lotteries assign the same probability to
        each outcome, then the player is indifferent between these two lotteries.
    \item Monotonicity: If $x_1 > x_2$ and $p > q$, then $[x_1: p, x_2 : 1- p] \geq [x_1 : q, x_2 : 1 - q ]$.
    \item Continuity: If $x_1 > x_2 > x_3$, then there exists $p \in [0, 1]$
        such that $x_2 \sim [x_1: p, x_3: 1 - p]$.
\end{itemize}

\begin{theorem}
    Von Neumann and Morgenstern: Given a set of outcomes $X$ has a preference
    relation on $X$ that satisfies the above axioms, there exists a utility function
    $u: X \rightarrow [0, 1]$ such that:
    \begin{itemize}
        \item $u(x_1) \geq u(x_2) \iff x_1 \geq x_2$
        \item $U([x_1: p_1, x_2:p_2, \dots x_m:p_m]) = \sum_{j=1}^m p_j u(x_j)$
    \end{itemize}
\end{theorem}



\section{Best response function}
Let $\Gamma \equiv (N, S_{i \in N}, u: \prod_i S_i \rightarrow R)$ be a normal
for game. We define the best response function for player $i$ as:
\begin{align*}
   r_i: S_{-i} \rightarrow S_i
    \qquad r_i(s_{-i}) \equiv \argmax_{s_i \in S_i}  u(s_i, s_{-i})
\end{align*}

That is, under a fixed strategy for all of $i$'s opponents, the best response
function $r_i(s_{-i})$ tells us the best move we can make.


\section{Nash equilibrium}

A strategy profile $s \equiv (s_1, s_2, \dots s_n)$ is a Nash equilibrium
if $s_i$ is the best response to $s_{-i}$ for all $i$.


\section{Writing down the Nash Equilibirum in terms of an LP}
Let $K_i$ be the set of actions that player $i$ will take (the support).
Let $p_i[s]$ be the probability for player $i$ to take action $s \in S_i$.

We need the conditions:
\begin{itemize}
    \item $\forall s \not \in K_i, p_i[s] = 0$
    \item $\sum p_i s = w_i$
\end{itemize}


\section{Kakutani fixed point theorem}
consider a relation $R: \Sigma \rightrightarrows \Sigma$ such that:
\begin{itemize}
    \item $\Sigma$ is compact, convex, and nonempty.
    \item $R(\sigma)$ is nonempty.
    \item $R(\sigma)$ is convex.
    \item $R$ has a closed graph.
\end{itemize}

under these conditions, $R$ is guaranteed to have a fixed point.

\section{Existence of Nash equilibrium}
We prove this using the Kakutani fixed point theorem.


\section{Existence of Nash equilibrium (Insightful version)}
We prove this using the Brouwer fixed-point theorem. While this requires
us to roll up our sleeves a little bit, the fixpoint is far more constructive,
in the sense that it tells us what the fixpoint is actually, well, fixing.

consider the correspondence
\begin{align*}
    R: Sigma \rightarrow 2^{Sigma} \qquad R(\sigma) \equiv [r_i(\sigma_{-i})]_{i \in N}
\end{align*}

That is, for each strategy profile $\sigma$, we relate it to the set
of strategy profiles that are best responses against this profile.

Now note that a nash equilibrium is a fixed point of this relation.
We will show that the above relation $R$ satisfies the assumptions
of the Kakatuni fixed point theorem, and is hence a fixed point.


\section{LP formulation for 2 player zero sum game}
\section{Lemke Howson theorem for computing mixed-strategy nash eqm}
\section{Mechanism design}
We consider a setting:

\begin{align*}
    &N \equiv \text{Set of players} \\
    &X  \equiv \text{Alternatives} \\
    &\Theta_{i \in N} \equiv \text{private information of player $i$} \\
    &\phi: \prod_i \Theta_i \rightarrow \mathbb R \equiv \text{prior probability over private information} \\
    &u_{i \in N}: \prod_i \Theta_i \times X \rightarrow \mathbb R \equiv \text{utility of player $i$} \\
\end{align*}

A mechanism is a tuple:
\begin{align*}
    &\Gamma \equiv (S_{i \in N}, g) \\
    &S_{i \in N} \equiv \text{strategies of each player $i$} \\
    &g: \prod_i S_i \rightarrow X \equiv \text{an outcomes function}
\end{align*}
A mechanism tells us what actions a player can take, and what the outcome
of each action is.

We often want the mechanism to be designed to optimised a particular social good:
\begin{align*}
    f: \prod_i \Theta_i \rightarrow X \equiv \text{Social choice function} \\
\end{align*}

That is, given knowledge of what players \emph{truly want}, we know what
outcome we are interested in. In this setting, we are then to design 
a mechanism $(S_i, g)$ which will encourage a situation where rational players
will take action dictated by $f$.

Sometimes, we will denote $S_i$ by $\hat \Theta_i$, since any action the
player can take can be mathematically modeled as a deterministic function
of their state. Hence, if we allow players to lie and publish 
a $\hat \Theta_i$, which is their reporting of their private $\Theta_i$, it's
equivalent to a setting where players have arbitrary $S_i$.

\chapter{March 23rd}

We can either relax DSIC or relax rich preference structure. We decided
to look at quasi-linear environments where we relax preferences. A popular
example of this is auctions.

$X = \{ (k, t_1, \dots, t_n) : k \in K, t_i \in \R, \sum_i t_i \leq 0 \}$

$t_i$ is monetary transfer receives by agent $i$.

$u_i(x, \theta_i) = v_i(k, \theta_i) + t_i$. Linear in $t_i$, hence
the setting is quasi-linear. Often it is even $k_i \cdot \theta_i + t_i$ --- these
settings are known as linear settings.

\section{Examples of SCF in quasi-linear settings}
\begin{itemize}
    \item[Players] Seller and two buyers
    \item [Types / Private information / valuations] Seller $\Theta_0 = \{ 0 \}$. Byers = $\theta_1 =\theta_2 = [0, 1]$.
\end{itemize}

\section{Allocative efficiency}
an SCF $f()$ is allocative efficient if it maximises sum of valuations
of agents. We assume such a maxima does exist.
$k^{\star}(\theta) \in \arg \max_{k \in K} \sum_{i=1}^n v_i(k, \theta_i)$

We also want budget balance:

$\sum_{i=1}^n t_i(\theta) = 0$.

\section{Properties of SCF(Social choice function) in quasi-linear settings}

\begin{lemma}
All SCFs in quasi-linear settings are non dictatorial.
\end{lemma}

because $\sum_i t_i < 0$, we can increase payment for the dictator by using
$t_i + \frac{e}{n - 1}$ and decrease everyone else to $t_i - \frac{e}{n-1}$.
So, there is always an outcome that is better for a dictator. Hence,
the best outcome cannot have a dictator.

\section{Ex-post efficiency}
in quasi linear, scf is exp-post efficient iff if is allocatively efficient
and strictly budget balanced. We have to prove that $EPE \implies AE + SBB$,
and also $AE + SBB \implies EPE$.

Suppose $f = (k, t)$ is EPE but not SBB. So there exists a $\theta$ such that 
$\sum_i t_i(\theta) < 0$. Hence, there exists at least
one agent $j$ such that $t_j < 0$. (If everyone is positive, sum cannot be less than 0).

Now consider a new allocation $X' = (k, t')$ where 

$t'_j(\theta) = 
\begin{cases}
    t_j(\theta) -  \sum_i t_i(\theta)/n & \text{if $t_j(\theta) < 0$} \\
    t_j(\theta) & \text{otherwise}
\end{cases}
$ 

Hence, $u'_j(k, t') > u_j(k, t)$ for such $j$ where $t_j(\theta) < 0$.
For other agents, $u'_j(k, t') = u'_j(k, t)$.

This means that $(k. t')$ pareto dominates $(k. t)$. This is a contradiction
to the assumption that $f$ was EPE, since we constructed an outcome where
one agent does better, and others don't do worse.

We now argue that f must be allocatively efficient, if  f is EPE. For contradiction,
let us assume that $f$ is not AE.
That means that there is a $k^\star$ such that
$\sum_i v_i(k^\star, \theta) > v_i (k, \theta)$.

Define $t_i'(\theta)  = v_i(k, \theta) - t_i (\theta) - \sum_j \theta_j(k^\star, \theta) + \epsilon$
where $\epsilon < \sum_j v_j(k^star, \theta) - theta_j (k, \theta)$.

Note that $v_i(k, \theta) - t_i (\theta)  = u_i(k, t)$. 
Now note that
$u_i(k^\star, t') = u_i(k, t) + \epsilon/n$, where $\epsilon$ is positive.
Hence, $u_i(k^\star, t') > u_i(k, t)$. 

We need to check that $t'$ is feasible: ie, $\sum_i t_i' < 0$.

$$
\sum_i t_i' = \sum_i v_i(k, theta) - \sum v_j(k^\star, \theta) + \sum_i t_i(\theta) \leq 0??
$$

Also note that for all $i$, $u_i(k^\star, t') > u_i(k, t)$. This is contradiction
to the fact that $f$ is APE. Hence, $f$ must be AE.

\section{Other way round: if $f$ is AE + SBB, then it is EPE}

For this, we will need to prove a lemma:

\begin{lemma}
If $f: \Theta \rightarrow X$ st $\forall \theta \in \Theta$,
$$
\sum_i u_i(f(\theta), \theta_i) \geq \sum_i u_i(x, \theta_i) \forall x \in X
$$
then $f$ is EPE.

The key idea is to write $u_i = v_i + t_i$, an we can get rid of $t_i$ since
$f$ is SBB.
\end{lemma}

\section{First price versus second price auction}
First price: reporting valuation truthfully is not an equilibrium. Second
price: truthful reporting is equilibrium.

How do we generalize this to more situations? The key idea is that in a second
price auction, our payment is independent of what we report. The allocation
might depend on our payment, but payment does not. How can we have more
DSIC mechanisms?

\section{Groves theorem}
TODO: fill up groves theorem



Three families A B C, can go to Munnar or Simla. 


\begin{tabular}{l r r l}
  &  Manali &  Shimoga & \\
Alice & -1 &  10 & \\
Bob & 5  & -2  & \\
Claire & 5  & 4  & (Claire is a kid, loves vacations) \\
\end{tabular}

We want to get this information truthfully, by using VCG/Groves mechanism.

there are two outcoomes, M or S . If we go to M, the tuility is 5+5-1=9. If
we choose S, it is 10-2+4=12. so S is allocatively efficient.



\begin{tabular}{l r r r r r r r}
    & $\{ A \}$  & $\{ B \}$   & $\{ C \}$  &  $\{ A, B \}$ & $\{ A, C \}$ & $\{ B, C  \}$ & $\{  A, B, C \}$ \\
$P_1$  & 10 & 0   & 5  &  10  &  20 &   5  &  20 \\
$P_2$  & 0  & 9   & 15  &  9  &  15 &  20  &  20 \\
$P_3$  & 10 &  2   & 2  &  10  &  12 &  2  &   28 \\
$P_4$  & 8  &  3   & 3  &  8  &   8 &   3  &    8
\end{tabular}


Giving $A$ to $P_1$ and $BC$ to $P_2$ gives $10 + 20 = 30$.


A direct revelation mechanism in which $f$ satisfies allocative efficiency
and the groves payment scheme is knows as the groves mechanism.

before this, there is another mechanism called as Clarke's mechanism

\section{Clarke's mechanism}

$h_i(\theta_i) = \sum_{j \neq i} v_j(k_{-i}^\star(\theta_{-i}, \theta_j)) \forall \theta_{-i} \in \Theta_{-i}$

That is, each agent $i$ receives
$$
t_i(\theta) = \sum_{j \neq i}(v_j(k^\star(\theta), \theta_j)) - \sum_{j \neq i} v_j(k^\star_{-i}(\theta_{-i}), \theta_j))
$$

This works for combinatorial auctions as well. It's a generalization
of second-price auction.

\begin{tabular}{l r r l}
  & M & S & \\
A &-1  &10 &  \\
B & 5  &-2 & \\
C & 5 & 4 &  (C is a kid, loves vacations) \\
\end{tabular}

For player A, first consider:

\begin{tabular}{l r r l}
   & M  & S & \\
A  & -  & -  & \\
B  & 5  & -2 & \\
C  & 5  & 4  & (C is a kid, loves vacations) \\
\end{tabular}

AE is M. 

Following clarke mechanism:

$$
t_A = [valuation of remaining agents at allocatively efficient outcome without A](-2+4) - [valuation of remaining agents at allocatively efficient outcome with A][5+5] = 8
$$


for player B, first consider:

\begin{minted}{text}
A -1  10
B  -  -
C  5  4  (C is a kid, loves vacations)
   M  S
\end{minted}

AE is S.

So, $t_B = 0$

Similarly, $t_C = 0$.

\chapter{March 26th}

$AE + SBB \implies EPE$

Free disposal.

Groves mechanism is DSIC.

Proof by contradiction. Assume $f$ is not DSIC. Hence there exists an $i, \theta, \theta', \theta_{-i}$
such that:

$$
u_i(f(\theta^{i'}, \theta_{-i}), \theta_i) > u_i(f(\theta^{i}, \theta_{-i}), \theta_i)
$$

Clarke's pivotal mechanism. This mechanism aplied to combinatorial setting
is called as generalized vickery auction when.

Is a DSIC also a BIC? Yes.

$$
Vickery (single item auction) \subseteq GVN (combinatorial auction ) \subseteq Clarke \subseteq Groves \subseteq DSIC \subseteq BIC
$$

Groves theorem says $Groves \subseteq AC \cap DSIC$
Green-laffont proved that $AE \subseteq DSIC \subseteq Groves$ 
 

Green-laffont also proved the Green-Laffont impossibility theorem:
that $AE \cap DSIC \cap SBB = \emptyset$.

EPE = ex-post efficient.

\chapter{March 30th}

$N$ players, $\Theta_i$ iid. $k_i(\theta) = 1$ if agent gets the objects, $0$
otherwise. $t_i(\theta) = $ payment received by agent $i$. 
$u_i(\theta) = k_i(\theta) - t_i(\theta)$

\end{document}
