\newcommand{\ptime}{\texttt{P}}
\newcommand{\coptime}{\texttt{co-P}}
\newcommand{\nptime}{\texttt{NP}}
\newcommand{\conptime}{\texttt{co-NP}}
\newcommand{\pspace}{\texttt{PSPACE}}
\newcommand{\logspace}{\texttt{L}}
\newcommand{\nlogspace}{\texttt{NL}}
\newcommand{\conlogspace}{\texttt{co-NL}}
\newcommand{\ph}{\texttt{PH}}
\newcommand{\pathproblem}{\texttt{PATH}}
\newcommand{\copathproblem}{\overline{\texttt{PATH}}}
\newcommand{\clique}{\texttt{CLIQUE}}
\newcommand{\maxclique}{\texttt{MAXCLIQUE}}
\newcommand{\sat}{\texttt{SAT}}
\newcommand{\phtime}{\texttt{PH}}
\chapter{LogSpace}
\section{The languages \logspace~\& \nlogspace}

$\logspace \equiv DPSACE(\log (n))$, $\nlogspace \equiv NSPACE(\log(n))$


\textbf{Open problem: \logspace~versus \nlogspace}.

$\logspace \subset \ptime$ since configuration space is $2^{O(\log(n))} = O(n)$,
hence we can brute force the configuration space.

\subsection{\nlogspace-completeness}
A language $A$ is \nlogspace-complete if:
\begin{itemize}
    \item $A \in \nlogspace$
    \item $B \in \nlogspace, B \leq_L A$
\end{itemize}

Note that $B \leq_L A$ uses a mapping reduction: $\exists f: \Sigma^* \to \Sigma^*$,
$f$ converts inputs of $B$ to inputs of $A$ in log-space.

$f$ must be \textbf{implicitly computable}: That is, the problem of generating
the $i$-th bit should be done in $\logspace$.


\section{The \pathproblem~problem}
$\pathproblem = \{ \langle G, s, t \rangle~\vert~\exists s \to t~\text{path in}~G \}$

\begin{theorem}
    $\pathproblem \in \nlogspace$
\end{theorem}

\begin{proof}
We perform the naive solution --- We try to explore all possible path possibilities for $s \to t$.
\end{proof}

\begin{theorem}
    $A \in \nlogspace \implies A \leq_{\logspace} \pathproblem$
\end{theorem}
\begin{proof}
    Since $A \in \nlogspace$, there exists an NDTM $M$ which decides $A$ by
    using $O(\log(n))$ space.


    We try to walk through the configuration graph of $M$ (henceforth called $Config_M$, from which
    we can try to find the path from the initial configuration to the
    final configuration. We can then try to solve
    $\pathproblem(Config_M, c_{init}, c_{final})$, which will tell us
    whether an accepting path exists.
\end{proof}

\section{Verifiers}
A turing machine $T$ verifies language $L$ if $L = \{ w~\vert~ \exists c, V(w, c)~\text{accepts} \}$.
Note that if $\forall w, |c| = 0$, then $L$ is decidable (that is, no advice is needed).

\begin{theorem}
    if $L \in nptime$, then $L$ has an efficient verifier.
\end{theorem}
\begin{proof}
    Let $N$ be a NDTM that decides $L$. Notice that the accepting path of $L$
    is poly.

    We create a certificate $c$ for $V(w, c)$ to be the address of the
    accepting path. 
\end{proof}

\begin{theorem}
    if $L$ has an efficient verifier, then $L \in \nptime$
\end{theorem}
\begin{proof}
    Let $V$ be the verifier.
    Let $N$ be the NDTM we are constructing that decides $L$. 
    $N$ guesses the certificate $\overline{c}$ and then runs $N(w) = V(w, \overline{c})$.
\end{proof}


\section{\conptime}

$\conptime \equiv \{ L^c~\vert~L \in \nptime \}$
Since $\sat \in \nptime$, $\sat^c \in \conptime$. How do we convince someone
that something is \textbf{not} satisfiable?

Let's look at this from the verifier perspective: The certificate of all
outputs is pretty useless, since that is exponential. So, we need a
short certificate which allows us to decide whether a given \sat~problem is
unsolvable.

Since $\ptime = \coptime$ (since there is no non-determinism, we can simply flip the answer),
hence $\ptime = \coptime \subseteq \conptime$


Let's take a closer look at the verifiers:
\begin{itemize}
    \item $L \in \nptime, w \in L \iff \exists c, V(w, c) = 1$
    \item $L \in \conptime, w \in L \iff \forall c, V(w, c) = 0$
\end{itemize}

So, we get some sort of duality between $\forall$ and $\exists$.

\section{\clique}
\begin{align*}
    \clique &= \{ \langle G, k \rangle~\vert~G~\text{has a clique of size}~K \} \\
    \maxclique &= \{ \langle G, k \rangle~\vert~G~\text{has a clique of size}~K, \text{ does not have a clique of size } K+1 \}\\
    \langle G, k \rangle &\in \maxclique \iff \exists c, V(G, k, c) = 1 \land \forall u, W(G, k+1, u) = 0\\
    \langle G, k \rangle &\in \maxclique \iff \exists u_1, u_2, M(G, k, u_1, u_2) = 1
\end{align*}

This new class is called as $\Sigma_2^p$.


\begin{align*}
    L &\in \Sigma_i^p \iff \exists u_1 \forall u_2 \exists u_3 \forall u_4 \dots, Q_i u_i, M(w, u_i)  = 1 \\
    L &\in \Pi^p \iff \forall u_1 \exists u_2 \forall u_3 \exists u_4 \dots, Q_i u_i, M(w, u_i)  = 1 \\
\end{align*}

$\nptime = \Sigma^p_1$, $\conptime = \Pi_1^p$

We can now ask question between levels of the PH --

$\Sigma_{i+1}^p \supseteq_? \Sigma_i^p$ -- Intuitively, the higher the $i$, the
more restricted the question!

If we can show that  $\Sigma_{i+1}^p= \Sigma_i^p$, then $\forall k \in \mathbb{N}, \Sigma_{i+k}^p= \Sigma_i^p$
(ie, we can "collapse" the hierarchy)
\textbf{Sid question: why does the hierarchy collapse?}
$PH = \cup_i \Sigma_i^p$


We know the existence of a $\Sigma_i^p$-complete problem for \textit{every $i$}.

\subsection{\phtime-completness}

If there exists a language $L$ which is \phtime-complete, then the hierarchy collapses,
ie, $\exists i, \Sigma_{i+1}^p = \Sigma_i^p$.

The current conjecture is that the polynomial hierarchy does not collapse -- Hence,
there does not exist a \phtime-complete problem.

\subsection{$\phtime \subset \pspace$}

\subsubsection{Ramification}
We know that $TQBF$ is \pspace-complete. If $TQBF \in \phtime$, then we
have a $\phtime$-complete algorithm (which cannot exist, due to the conjecture).

\begin{theorem}the existence of a \phtime-complete problem collapses \phtime
\end{theorem}
\begin{proof}
    Let $L$ be the \phtime-complete problem. We know $\exists i$, 
    $L \in \Sigma_i^p$. Now, for any $k \in \mathbb{N}$, we can reduce problem
    $\Sigma_k^p$ to $L$. Hence, I can reduce all $k > i$ to $k = i$, and then
    solve it at level $i$. Hence, the \phtime~will collapse at level $i$.
\end{proof}

\section{\conlogspace}
$\copathproblem \in \conlogspace$.

What about $\nlogspace~vs~\conlogspace$?

\subsection{Verifiers for \nlogspace, \conlogspace}
Let us look at it in terms of verifiers:

Can we define \nlogspace~in terms of verifiers? Yes, we can, if we can ensure
a \textit{read-once certificate}.

\begin{align*}
    w &\in \nlogspace \iff \exists u, V_{once}(w, u) = 1 \\
    w &\in \conlogspace \iff \forall u, V_{once}(w, u) = 0 \\
\end{align*}

How do we give a cerificate for \textbf{no path?}

However, we now know that $\nlogspace = \conlogspace$
