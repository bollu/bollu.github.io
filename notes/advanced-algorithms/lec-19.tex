\chapter{Proofs by existence}

We continue to observe proofs by existence. 

\section{Example 2 of expanders}
We have a bipartite graph $G \equiv (L, R, E)$ such that:
\begin{itemize}
\item $|L| = n$
\item $|R| = 2^{\log^2 n} \equiv n^{\log n}$
\item Every susbet of $\frac{n}{2}$ vertices of $L$ has at least $2^{\log^2 n} - n$
\item no vertex of $R$ has more than $12 \log^2 n$ neighbours
\end{itemize}

We want to show the existence of such a bipartite graph by existence.

Let every vertex of $L$ choose $d$ neighbours in $R$ independently,
uniformly at random. Choices are made with replacement. Repeat edges are
merged into a single edge.


We want every vertex in $L$ to pick $d$ vertices of $R$. To aid this
computation, let us imagine $L' = nd$, such that each vertex in $L'$ has
$d$ copies of vertices of $L$. Now, each vertex in $L'$ picks one vertex in $R$.
Expected number of edges for each vertex in $R$ will be $\frac{n d}{r}$

\begin{align*}
    \Pr(deg(v) \geq 12 \log^2 n) = \Pr(deg(v) \geq (1 + 5)12 \log^2 n) \leq e^{-2 \log^2 n}
\end{align*}

\textbf{Derivation in Motwani and raghavan}

We want to compute size of neighbour set for a given subset of $L$:

$S \subset L$, $|S| = \frac{n}{2}$, $T \subset R$
\begin{align*}
    \Pr(N(S) \subset T) \leq \frac{|T|}{r}^{|S| d} = (1 - \frac{n}{2^{\log^2 n}}^\frac{nd}{2}
\end{align*}


\begin{align*}
    \Pr(\exists S \exists T N(S) \subset T) \leq {n \choose |S|} {r \choose |T|} (1 - \frac{n}{r})^\frac{nd}{2}
\end{align*}

..

\section{CNF and \maxsat}

In CNF, each clause is a disjunction of literals. The formula is a conjunction
of clauses. $\texttt{CNF} \equiv \text{product of sums}$


We show that for $m$ clauses, there is a truth assignment that satisfies
at least $\frac{m}{2}$ clauses.

\begin{itemize}
    \item Consider a random assignment of truth values to variables
    \item consider a clause $C_i$ of $k$ variables
    \item $C_i$ is not satisfied with probability $2^{-k}$
    \item Define the random variable $Z_i \equiv \text{$C_i$ is sat}$
    \item $\E{Z_i} = \Pr{\text{$C_i$ is sat}} = 1 - 2^{-k}$
    \item Let $Z \equiv \text{number of clauses satisfied}$, $Z = \sum_i Z_i$
    \item $\E{Z} = \sum_i \E{Z_i} = m(1 - 2^{-k}) \geq m/2$ as $k \geq 1$
\end{itemize}

The problem to maximise the satisfying clauses is called as \maxsat.

For any problem instance $I$, define $m^*(I)$ to be the maximum number
of clauses to be satisfied. Let $m(I)$ be the expected number oc clauses that
can be satisfied by a randomized algorithm $A$

the ratio $\frac{m^A(I)}{m^*(I)}$ is the performance of the algorithm $A$.

We seek algorithms for whom this ratio is close to $1$. The previous approach
establishes that $\frac{1}{2}$ can be the ratio.

We will establish an algorithm with ratio $\frac{3}{4}$.

\subsection{ILP formulation}

We write the problem as an ILP problem, we then relax the ILP to an LP. We
round the solution from LP to get integrality constraints. We will loose some
quality at this step.

Consider a clause $C_i$. An indicator variable $Z_i \in \{0, 1\}$ is used to define
whether $C_i$ is satisfied or not. We need to maximise $\sum_i Z_i$

For each variable $x_j \in \{T, F\}$, create an indicator variable $y_j \in \{0, 1\}$

Since each variable can appear in pure or complemented form, we reason about these
separately. 

$$C_{i+} \equiv \text{indeces of variables that appear in pure form in $C_i$}$$
$$C_{i-} \equiv \text{Indeces of variables that appear in complemented form in $C_i$}$$

\begin{align*}
    &\text{Maximize $\sum_i Z_i$} \\
    &\text{Subject to}~\sum_{j \in C_{i+}} y_j + \sum_{j \in C_{i-}} (1 - y_j) \geq z_i \\
    &y_i, z_i \in \{0, 1\}
\end{align*}

Next, in the ILP relaxation, we allow $y_i, z_i \in [0, 1]$.

We will use $u_i \sim y_i$, where $u_i$ is the LP relaxation, and $v_i \sim z_i$, where
$v_i$ is the LP relaxation.

Notice that $\sum_i v_i$ is an upper bound on the number of clauses to be
satisfier. But $u_i$ is not integral, so they don't correspond to truth assignments.

\textbf{Key Idea: We set $y_i$ to $1$ with probability $u_i$}.


\subsection{Algebra to show that we did good, kid}
We now estimate the probability that $C_i$ is satisfied: We will show that a clause $C_i$
with $k$ literas is satisfied with probability $1 - (1 - 1/k)^k v_i$


Let us assume that wlog all variables in $C_i$ appear in the pure form:
$$
C_i = x_1 \lor x_2 \lor \dots x_k \sim \text{LP:}~ (u_1 + u_2 + \dots u_k \geq v_i)
$$

Note that $C_i$ is unsat if $x_1, x_2, \dots x_k = 0$. So, $C_i$ is unsat with
probability $\prod_j (1 - u_j)$. Hence, $C_i$ is sat with probability $1 - \prod_j (1 - u_j)$


We claim that the above problem for $C_i$ is minimized when $u_j = v_i/k$, for each $j$.
(take exponent of sat probability and calculus)

So, the probability of interest is $p = 1 - (1 - v_i/k)^k$. We now claim that 
$$p(k) \geq 1(1 - 1/k)^k z~~\forall z \in [0, 1]$$. We need to use convexity.


\subsection{Next steps}
We have algo 1 that guarantees an approximation ratio of at least $\frac{1}{2}$.
algo 2 guarantees an approximation ratio of $1 - (1 - 1/k)^k$. 

We can now combine them, by either running both algorithms and then taking the
max, or deciding which algorithm to use by using a random fair coin.

In both cases, we can show that the expected performance raio to be at least 3/4
